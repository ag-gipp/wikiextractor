<doc id="938699" url="https://en.wikipedia.org/wiki?curid=938699" title="Kingdom of Mysore">
Kingdom of Mysore

The Kingdom of Mysore was a kingdom in southern India, traditionally believed to have been founded in 1399 in the vicinity of the modern city of Mysore. The kingdom, which was ruled by the Wodeyar family, initially served as a vassal state of the Vijayanagara Empire. With the decline of the Vijayanagara Empire (c. 1565), the kingdom became independent. The 17th century saw a steady expansion of its territory and during the rule of Narasaraja Wodeyar I and Chikka Devaraja Wodeyar, the kingdom annexed large expanses of what is now southern Karnataka and parts of Tamil Nadu to become a powerful state in the southern Deccan.

The kingdom reached the height of its economic and military power and dominion in the latter half of the 18th century under the de facto ruler Haider Ali and his son Tipu Sultan. During this time, it came into conflict with the Marathas, the Nizam of Hyderabad, the Kingdom of Travancore and the British, which culminated in the four Anglo-Mysore Wars. Success in the first Anglo-Mysore war and a stalemate in the second was followed by defeat in the third and fourth. Following Tipu's death in the fourth war of 1799, large parts of his kingdom were annexed by the British, which signalled the end of a period of Mysorean hegemony over southern Deccan. The British restored the Wodeyars to their throne by way of a subsidiary alliance and the diminished Mysore was transformed into a princely state. The Wodeyars continued to rule the state until Indian independence in 1947, when Mysore acceded to the Union of India.

Even as a princely state, Mysore came to be counted among the more developed and urbanised regions of India. This period (1799–1947) also saw Mysore emerge as one of the important centres of art and culture in India. The Mysore kings were not only accomplished exponents of the fine arts and men of letters, they were enthusiastic patrons as well, and their legacies continue to influence music and art even today.

Sources for the history of the kingdom include numerous extant lithic and copper plate inscriptions, records from the Mysore palace and contemporary literary sources in Kannada, Persian and other languages. According to traditional accounts, the kingdom originated as a small state based in the modern city of Mysore and was founded by two brothers, Yaduraya (also known as Vijaya) and Krishnaraya. Their origins are mired in legend and are still a matter of debate; while some historians posit a northern origin at Dwarka, others locate it in Karnataka. Yaduraya is said to have married Chikkadevarasi, the local princess and assumed the feudal title "Wodeyar" ("lit", "Lord"), which the ensuing dynasty retained. The first unambiguous mention of the Wodeyar family is in 16th century Kannada literature from the reign of the Vijayanagara king Achyuta Deva Raya (1529–1542); the earliest available inscription, issued by the Wodeyars themselves, dates to the rule of the petty chief Timmaraja II in 1551.

The kings who followed ruled as vassals of the Vijayanagara empire until the decline of the latter in 1565. By this time, the kingdom had expanded to thirty-three villages protected by a force of 300 soldiers. King Timmaraja II conquered some surrounding chiefdoms, and King "Bola" Chamaraja IV ("lit", "Bald"), the first ruler of any political significance among them, withheld tribute to the nominal Vijayanagara monarch Aravidu Ramaraya. After the death of Aravidu Aliya Rama Raya, the Wodeyars began to assert themselves further and King Raja Wodeyar I wrested control of Srirangapatna from the Vijayanagara governor ("Mahamandaleshvara") Aravidu Tirumalla – a development which elicited, if only "ex post facto", the tacit approval of Venkatapati Raya, the incumbent king of the diminished Vijayanagar empire ruling from Chandragiri. Raja Wodeyar I's reign also saw territorial expansion with the annexation of Channapatna to the north from Jaggadeva Raya – a development which made Mysore a regional political factor to reckon with.

Consequently, by 1612–13, the Wodeyars exercised a great deal of autonomy and even though they acknowledged the nominal overlordship of the Aravidu dynasty, tributes and transfers of revenue to Chandragiri stopped. This was in marked contrast to other major chiefs "Nayaks" of Tamil country who continued to pay off Chandragiri emperors well into the 1630s. Chamaraja VI and Kanthirava Narasaraja I attempted to expand further northward but were thwarted by the Bijapur Sultanate and its Maratha subordinates, though the Bijapur armies under Ranadullah Khan were effectively repelled in their 1638 siege of Srirangapatna. Expansionist ambitions then turned southward into Tamil country where Narasaraja Wodeyar acquired Satyamangalam (in modern northern Coimbatore district) while his successor Dodda Devaraja Wodeyar expanded further to capture western Tamil regions of Erode and Dharmapuri, after successfully repulsing the chiefs of Madurai. The invasion of the Keladi Nayakas of Malnad was also dealt with successfully. This period was followed by one of complex geo-political changes, when in the 1670s, the Marathas and the Mughals pressed into the Deccan.

Chikka Devaraja (r. 1672–1704), the most notable of Mysore's early kings, who ruled during much of this period, managed to not only survive the exigencies but further expanded territory. He achieved this by forging strategic alliances with the Marathas and the Mughals. The kingdom soon grew to include Salem and Bangalore to the east, Hassan to the west, Chikkamagaluru and Tumkur to the north and the rest of Coimbatore to the south. Despite this expansion, the kingdom, which now accounted for a fair share of land in the southern Indian heartland, extending from the Western Ghats to the western boundaries of the Coromandel plain, remained landlocked without direct coastal access. Chikka Devaraja's attempts to remedy this brought Mysore into conflict with the "Nayaka" chiefs of Ikkeri and the kings ("Rajas") of Kodagu (modern Coorg); who between them controlled the Kanara coast (coastal areas of modern Karnataka) and the intervening hill region respectively. The conflict brought mixed results with Mysore annexing Periyapatna but suffering a reversal at Palupare.

Nevertheless, from around 1704, when the kingdom passed on to "Muteking" ("Mukarasu") Kanthirava Narasaraja II, the survival and expansion of the kingdom was achieved by playing a delicate game of alliance, negotiation, subordination on occasion, and annexation of territory in all directions. According to historians Sanjay Subrahmanyam and Sethu Madhava Rao, Mysore was now formally a tributary of the Mughal empire. Mughul records claim a regular tribute ("peshkash") was paid by Mysore. However, historian Suryanath U. Kamath feels the Mughals may have considered Mysore an ally, a situation brought about by Mughal–Maratha competition for supremacy in southern India. By the 1720s, with the Mughal empire in decline, further complications arose with the Mughal residents at both Arcot and Sira claiming tribute. The years that followed saw Krishnaraja Wodeyar I tread cautiously on the matter while keeping the Kodagu chiefs and the Marathas at bay. He was followed by Chamaraja Wodeyar VII during whose reign power fell into the hands of prime minister ("Dalwai" or "Dalavoy") Nanjarajiah (or Nanjaraja) and chief minister ("Sarvadhikari") Devarajiah (or Devaraja), the influential brothers from Kalale town near Nanjangud who would rule for the next three decades with the Wodeyars relegated to being the titular heads. The latter part of the rule of Krishnaraja II saw the Deccan Sultanates being eclipsed by the Mughals and in the confusion that ensued, Haider Ali, a captain in the army, rose to prominence. His victory against the Marathas at Bangalore in 1758, resulting in the annexation of their territory, made him an iconic figure. In honour of his achievements, the king gave him the title "Nawab Haider Ali Khan Bahadur".

Haider Ali has earned an important place in the history of Karnataka for his fighting skills and administrative acumen. The rise of Haidar came at a time of important political developments in the sub-continent. While the European powers were busy transforming themselves from trading companies to political powers, the Nizam as the "subedar" of the Mughals pursued his ambitions in the Deccan, and the Marathas, following their defeat at Panipat, sought safe havens in the south. The period also saw the French vie with the British for control of the Carnatic—a contest in which the British would eventually prevail as British commander Sir Eyre Coote decisively defeated the French under the Comte de Lally at the Battle of Wandiwash in 1760, a watershed in Indian history as it cemented British supremacy in South Asia. Though the Wodeyars remained the nominal heads of Mysore during this period, real power lay in the hands of Haider Ali and his son Tipu.

By 1761, the Maratha menace had diminished and by 1763, Haider Ali had captured the Keladi kingdom, defeated the rulers of Bilgi, Bednur and Gutti, invaded the Malabar in the south and conquered the Zamorin's capital Calicut with ease in 1766 and extended the Mysore kingdom up to Dharwad and Bellary in the north. Mysore was now a major political power in the subcontinent and Haider's meteoric rise from relative obscurity and his defiance formed one of the last remaining challenges to complete British hegemony over the Indian subcontinent—a challenge which would take them more than three decades to overcome.

In a bid to stem Haidar's rise, the British formed an alliance with the Marathas and the Nizam of Golconda, culminating in the First Anglo-Mysore War in 1767. Despite numerical superiority Haider Ali suffered defeats at the battles of Chengham and Tiruvannamalai. The British ignored his overtures for peace until Haider Ali had strategically moved his armies to within five miles of Madras (modern Chennai) and was able to successfully sue for peace. In 1770, when the Maratha armies of Madhavrao Peshwa invaded Mysore (three wars were fought between 1764 and 1772 by Madhavrao against Haider, in which Haider lost), Haider expected British support as per the 1769 treaty but they betrayed him by staying out of the conflict. The British betrayal and Haider's subsequent defeat reinforced Haider's deep distrust of the British—a sentiment that would be shared by his son and one which would inform Anglo-Mysore rivalries of the next three decades. In 1777, Haider Ali recovered the previously lost territories of Coorg and Malabar from the Marathas. Haider Ali's army advanced towards the Marathas and fought them at the Battle of Saunshi and came out victorious during the same year.

By 1779, Haider Ali had captured parts of modern Tamil Nadu and Kerala in the south, extending the Kingdom's area to about 80,000 mi² (205,000 km²). In 1780, he befriended the French and made peace with the Marathas and the Nizam. However, Haider Ali was betrayed by the Marathas and the Nizam, who made treaties with the British as well. In July 1779 Haider Ali headed an army of 80,000, mostly cavalry, descending through the passes of the Ghats amid burning villages, before laying siege to British forts in northern Arcot starting the Second Anglo-Mysore War. Haider Ali had some initial successes against the British notably at Pollilur, the worst defeat the British suffered in India until Chillianwala, and Arcot, until the arrival of Sir Eyre Coote]], when the fortunes of the British began to change. On 1 June 1781 Coote] struck the first heavy blow against Haider Ali in the decisive Battle of Porto Novo. The battle was won by Coote against odds of five to one, and is regarded as one of the greatest feats of the British in India. It was followed up by another hard-fought battle at Pollilur (the scene of an earlier triumph of Haider Ali over a British force) on 27 August, in which the British won another success, and by the rout of the Mysore troops at Sholinghur a month later. Haider Ali died on 7 December 1782, even as fighting continued with the British. He was succeeded by his son Tipu Sultan who continued hostilities against the British by recapturing Baidanur and Mangalore.

By 1783 neither the British nor Mysore were able to obtain a clear overall victory. The French withdrew their support of Mysore following the peace settlement in Europe. Undaunted, Tipu, popularly known as the "Tiger of Mysore", continued the war against the British but lost some regions in modern coastal Karnataka to them. The Maratha–Mysore War occurred between 1785 and 1787 and consisted of a series of conflicts between the Sultanate of Mysore and the Maratha Empire. Following Tipu Sultan's victory against the Marathas at the Siege of Bahadur Benda, a peace agreement was signed between the two kingdoms with mutual gains and losses. Similarly, the treaty of Mangalore was signed in 1784 bringing hostilities with the British to a temporary and uneasy halt and restoring the others' lands to the status quo ante bellum. The treaty is an important document in the history of India, because it was the last occasion when an Indian power dictated terms to the British, who were made to play the role of humble supplicants for peace. A start of fresh hostilities between the British and French in Europe would have been sufficient reason for Tipu to abrogate his treaty and further his ambition of striking at the British. His attempts to lure the Nizam, the Marathas, the French and the King of Turkey failed to bring direct military aid.

Tipu's successful attacks in 1790 on the Kingdom of Travancore, a British ally, was an effective victory for him, however it resulted in greater hostilities with the British which resulted in the Third Anglo-Mysore War. In the beginning, the British made gains, taking the Coimbatore district, but Tipu's counterattack reversed many of these gains. By 1792, with aid from the Marathas who attacked from the north-west and the Nizam who moved in from the north-east, the British under Lord Cornwallis successfully besieged Srirangapatna, resulting in Tipu's defeat and the Treaty of Srirangapatna. Half of Mysore was distributed among the allies, and two of his sons were held to ransom. A humiliated but indomitable Tipu went about re-building his economic and military power. He attempted to covertly win over support from Revolutionary France, the Amir of Afghanistan, the Ottoman Empire and Arabia. However, these attempts to involve the French soon became known to the British, who were at the time fighting the French in Egypt, were backed by the Marathas and the Nizam. In 1799, Tipu died defending Srirangapatna in the Fourth Anglo-Mysore War, heralding the end of the Kingdom's independence. Modern Indian historians consider Tipu Sultan an inveterate enemy of the British, an able administrator and an innovator.

Following Tipu's fall, a part of the kingdom of Mysore was annexed and divided between the Madras Presidency and the Nizam. The remaining territory was transformed into a Princely State; the five-year-old scion of the Wodeyar family, Krishnaraja III, was installed on the throne with chief minister ("Diwan") Purnaiah, who had earlier served under Tipu, handling the reins as regent and Lt. Col. Barry Close taking charge as the British Resident. The British then took control of Mysore's foreign policy and also exacted an annual tribute and a subsidy for maintaining a standing British army at Mysore. As Diwan, Purnaiah distinguished himself with his progressive and innovative administration until he retired from service in 1811 (and died shortly thereafter) following the 16th birthday of the boy king.
The years that followed witnessed cordial relations between Mysore and the British until things began to sour in the 1820s. Even though the Governor of Madras, Thomas Munro, determined after a personal investigation in 1825 that there was no substance to the allegations of financial impropriety made by A. H. Cole, the incumbent Resident of Mysore, the Nagar rebellion (a civil insurrection) which broke out towards the end of the decade changed things considerably. In 1831, close on the heels of the insurrection and citing mal-administration, the British took direct control of the princely state. For the next fifty years, Mysore passed under the rule of successive British Commissioners; Sir Mark Cubbon, renowned for his statesmanship, served from 1834 until 1861 and put into place an efficient and successful administrative system which left Mysore a well-developed state.

In 1876–77, however, towards the end of the period of direct British rule, Mysore was struck by a devastating famine with estimated mortality figures ranging between 700,000 and 1,100,000, or nearly a fifth of the population. Shortly thereafter, Maharaja Chamaraja X, educated in the British system, took over the rule of Mysore in 1881, following the success of a lobby set up by the Wodeyar dynasty that was in favour of rendition. Accordingly, a resident British officer was appointed at the Mysore court and a Diwan to handle the Maharaja's administration. From then onwards, until Indian independence in 1947, Mysore remained a Princely State within the British Indian Empire, with the Wodeyars continuing their rule.

After the demise of Maharaja Chamaraja X, Krishnaraja IV, still a boy of eleven, ascended the throne in 1895. His mother Maharani Kemparajammanniyavaru ruled as regent until Krishnaraja took over the reins on 8 February 1902. Under his rule, with Sir M. Vishweshwariah as his Diwan, the Maharaja set about transforming Mysore into a progressive and modern state, particularly in industry, education, agriculture and art. Such were the strides that Mysore made that Mahatma Gandhi called the Maharaja a "saintly king" ("Rajarishi"). Paul Brunton, the British philosopher and orientalist, John Gunther, the American author, and British statesman Lord Samuel praised the ruler's efforts. Much of the pioneering work in educational infrastructure that took place during this period would serve Karnataka invaluably in the coming decades. The Maharaja was an accomplished musician, and like his predecessors, avidly patronised the development of the fine arts. He was followed by his nephew Jayachamaraja whose rule came to an end when he signed the instrument of accession and Mysore joined the Indian Union on 9 August 1947.

There are no records relating to the administration of the Mysore territory during the Vijayanagara Empire's reign (1399–1565). Signs of a well-organised and independent administration appear from the time of Raja Wodeyar I who is believed to have been sympathetic towards peasants ("raiyats") who were exempted from any increases in taxation during his time. The first sign that the kingdom had established itself in the area was the issuing of gold coins ("Kanthirayi phanam") resembling those of the erstwhile Vijayanagara Empire during Narasaraja Wodeyar's rule.

The rule of Chikka Devaraja saw several reforms were effected. Internal administration was remodeled to suit the kingdom's growing needs and became more efficient. A postal system came into being. Far reaching financial reforms were also introduced. A number of petty taxes were imposed in place of direct taxes, as a result of which the peasants were compelled to pay more by way of land tax. The king is said to have taken a personal interest in the regular collection of revenues the treasury burgeoned to 90,000,000 "Pagoda" (a unit of currency) – earning him the epithet "Nine crore Narayana" ("Navakoti Narayana"). In 1700, he sent an embassy to Aurangazeb's court who bestowed upon him the title "Jug Deo Raja" and awarded permission to sit on the ivory throne. Following this, he founded the district offices ("Attara Kacheri"), the central secretariat comprising eighteen departments, and his administration was modeled on Mughal lines.

During Haider Ali's rule, the kingdom was divided into five provinces ("Asofis") of unequal size, comprising 171 taluks ("Paraganas") in total. When Tipu Sultan became the "de facto" ruler, the kingdom, which encompassed (62,000 mi²), was divided into 37 provinces and a total of 124 taluks ("Amil"). Each province had a governor ("Asof"), and one deputy governor. Each taluk had a headman called "Amildar" and a group of villages were in charge of a "Patel". The central administration comprised six departments headed by ministers, each aided by an advisory council of up to four members.

When the princely state came under direct British rule in 1831, early commissioners Lushington, Briggs and Morrison were followed by Mark Cubbon, who took charge in 1834. He made Bangalore the capital and divided the princely state into four divisions, each under a British superintendent. The state was further divided into 120 taluks with 85 taluk courts, with all lower level administration in the Kannada language. The office of the commissioner had eight departments; revenue, post, police, cavalry, public works, medical, animal husbandry, judiciary and education. The judiciary was hierarchical with the commissioners' court at the apex, followed by the "Huzur Adalat", four superintending courts and eight "Sadar Munsiff" courts at the lowest level. Lewin Bowring became the chief commissioner in 1862 and held the position until 1870. During his tenure, the property "Registration Act", the "Indian Penal code" and "Code of Criminal Procedure" came into effect and the judiciary was separated from the executive branch of the administration. The state was divided into eight districts – Bangalore, Chitraldroog, Hassan, Kadur, Kolar, Mysore, Shimoga, and Tumkur.

After rendition, C. V. Rungacharlu, was made the Diwan. Under him, the first Representative Assembly of British India, with 144 members, was formed in 1881. He was followed by K. Seshadri Iyer in 1883 during whose tenure gold mining at the Kolar Gold Fields began, the Shivanasamudra hydroelectric project was initiated in 1899 (the first such major attempt in India) and electricity and drinking water (the latter through pipes) was supplied to Bangalore. Seshadri Iyer was followed by P. N. Krishnamurti, who founded The Secretariat Manual to maintain records and the Co-operative Department in 1905, V. P. Madhava Rao who focussed on conservation of forests and T. Ananda Rao, who finalised the Kannambadi Dam project.

Sir M. Visvesvaraya, popularly known as the "Maker of Modern Mysore", holds a key place in the history of Karnataka. An engineer by education, he became the Diwan in 1909. Under his tenure, membership of the Mysore Legislative Assembly was increased from 18 to 24, and it was given the power to discuss the state budget. The Mysore Economic Conference was expanded into three committees; industry and commerce, education, and agriculture, with publications in English and Kannada. Important projects commissioned during his time included the construction of the Kannambadi Dam, the founding of the Mysore Iron Works at Bhadravathi, founding of the Mysore University in 1916, the University Visvesvaraya College of Engineering in Bangalore, establishment of the Mysore state railway department and numerous industries in Mysore. In 1955, he was awarded the Bharat Ratna, India's highest civilian honor.

Sir Mirza Ismail took office as Diwan in 1926 and built on the foundation laid by his predecessor. Amongst his contributions were the expansion of the Bhadravathi Iron Works, the founding of a cement and paper factory in Bhadravathi and the launch of Hindustan Aeronautics Limited. A man with a penchant for gardens, he founded the Brindavan Gardens (Krishnaraja Sagar) and built the Kaveri River high-level canal to irrigate in modern Mandya district.

In 1939 Mandya District was carved out of Mysore District, bringing the number of districts in the state to nine.

The vast majority of the people lived in villages and agriculture was their main occupation. The economy of the kingdom was based on agriculture. Grains, pulses, vegetables and flowers were cultivated. Commercial crops included sugarcane and cotton. The agrarian population consisted of landlords ("vokkaliga", "zamindar", "heggadde") who tilled the land by employing a number of landless labourers, usually paying them in grain. Minor cultivators were also willing to hire themselves out as labourers if the need arose. It was due to the availability of these landless labourers that kings and landlords were able to execute major projects such as palaces, temples, mosques, anicuts (dams) and tanks. Because land was abundant and the population relatively sparse, no rent was charged on land ownership. Instead, landowners paid tax for cultivation, which amounted to up to one-half of all harvested produce.

The Kingdom of Mysore reached a peak in economic power under Hyder Ali and Tipu Sultan, in the post-Mughal era of the mid-late 18th century. They embarked on an ambitious program of economic development, aiming to increase the wealth and revenue of Mysore. Under their reign, Mysore overtook the Bengal Subah as India's dominant economic power, with productive agriculture and textile manufacturing.

Tipu Sultan is credited with founding state trading depots in various locations of his kingdom. In addition, he founded depots in foreign locations such as Karachi, Jeddah and Muscat, where Mysore products were sold. During Tipu's rule French technology was used for the first time in carpentry and smithing, Chinese technology was used for sugar production, and technology from Bengal helped improve the sericulture industry. State factories were established in Kanakapura and Taramandelpeth for producing cannons and gunpowder respectively. The state held the monopoly in the production of essentials such as sugar, salt, iron, pepper, cardamom, betel nut, tobacco and sandalwood, as well as the extraction of incense oil from sandalwood and the mining of silver, gold and precious stones. Sandalwood was exported to China and the Persian Gulf countries and sericulture was developed in twenty-one centers within the kingdom.

The Mysore silk industry was initiated during the rule of Tipu Sultan. Later the industry was hit by a global depression and competition from imported silk and rayon. In the second half of the 20th century, it however revived and the Mysore State became the top multivoltine silk producer in India.

Under Tipu Sultan, Mysore enjoyed one of the world's highest real wages and living standards in the late 18th century, higher than Britain, which in turn had the highest living standards in Europe. Mysore's average per-capita income was five times higher than subsistence level, i.e. five times higher than $400 (1990 international dollars), or $2,000 per capita. In comparison, the highest national per-capita incomes in 1820 were $1,838 for the Netherlands and $1,706 for Britain.

This system changed under the British, when tax payments were made in cash, and were used for the maintenance of the army, police and other civil and public establishments. A portion of the tax was transferred to England as the "Indian tribute". Unhappy with the loss of their traditional revenue system and the problems they faced, peasants rose in rebellion in many parts of south India. After 1800, the Cornwallis land reforms came into effect. Reade, Munro, Graham and Thackeray were some administrators who improved the economic conditions of the masses. However, the homespun textile industry suffered during British rule, with the exception of the producers of the finest cloth and the coarse cloth which was popular with the rural masses. This was due to the manufacturing mills of Manchester, Liverpool and Scotland being more than a match for the traditional handweaving industry, especially in spinning and weaving.

The economic revolution in England and the tariff policies of the British also caused massive de-industrialization in other sectors throughout India and Mysore. For example, the gunny bag weaving business had been a monopoly of the Goniga people, which they lost when the British began ruling the area. The import of a chemical substitute for saltpetre (potassium nitrate) affected the Uppar community, the traditional makers of saltpetre for use in gunpowder. The import of kerosene affected the Ganiga community which supplied oils. Foreign enamel and crockery industries affected the native pottery business, and mill-made blankets replaced the country-made blankets called "kambli". This economic fallout led to the formation of community-based social welfare organisations to help those within the community to cope better with their new economic situation, including youth hostels for students seeking education and shelter. However, the British economic policies created a class structure consisting of a newly established middle class comprising various blue and white-collared occupational groups, including agents, brokers, lawyers, teachers, civil servants and physicians. Due to a more flexible caste hierarchy, the middle class contained a heterogeneous mix of people from different castes.

The early kings of the Wodeyar dynasty worshipped the Hindu god Shiva. The later kings, starting from the 17th century, took to Vaishnavism, the worship of the Hindu god Vishnu. According to musicologist Meera Rajaram Pranesh, King Raja Wodeyar I was a devotee of the god Vishnu, King Dodda Devaraja was honoured with the title "Protector of Brahmins" ("Deva Brahmana Paripalaka") for his support to Brahmins, and Maharaja Krishnaraja III was devoted to the goddess Chamundeshwari (a form of Hindu goddess Durga). Wilks ("History of Mysore", 1800) wrote about a "Jangama" (Veerashaiva saint-devotee of Shiva) uprising, related to excessive taxation, which was put down firmly by Chikka Devaraja. Historian D.R. Nagaraj claims that four hundred "Jangamas" were murdered in the process but clarifies that Veerashiava literature itself is silent about the issue. Historian Suryanath Kamath claims King Chikka Devaraja was a Srivaishnava (follower of Sri Vaishnavism, a sect of Vaishnavism) but was not anti-Veerashaiva. Historian Aiyangar concurs that some of the kings including the celebrated Narasaraja I and Chikka Devaraja were Vaishnavas, but suggests this may not have been the case with all Wodeyar rulers. The rise of the modern day Mysore city as a centre of south Indian culture has been traced from the period of their sovereignty. Raja Wodeyar I initiated the celebration of the Dasara festival in Mysore, a proud tradition of the erstwhile Vijayanagara royal family.

Jainism, though in decline during the late medieval period, also enjoyed the patronage of the Mysore kings, who made munificent endowments to the Jain monastic order at the town of Shravanabelagola. Records indicate that some Wodeyar kings not only presided over the "Mahamastakabhisheka" ceremony, an important Jain religious event at Shravanabelagola, but also personally offered prayers ("puja") during the years 1659, 1677, 1800, 1825, 1910, 1925, 1940, and 1953.

The contact between South India and Islam goes back to the 7th century, when trade between Hindu kingdoms and Islamic caliphates thrived. These Muslim traders settled on the Malabar Coast and married local Hindu women, and their descendants came to be known as "Mappillas". By the 14th century, Muslims had become a significant minority in the south, though the advent of Portuguese missionaries checked their growth. Haider Ali, though a devout Muslim, did not allow his faith to interfere with the administration of the predominantly Hindu kingdom. Historians are, however, divided on the intentions of Haider Ali's son, Tipu Sultan. It has been claimed that Tipu raised Hindus to prominent positions in his administration, made generous grants to Hindu temples and brahmins, and generally respected other faiths, and that any religious conversions that Tipu undertook were as punishment to those who rebelled against his authority. However, this has been countered by other historians who claim that Tipu Sultan treated the non-Muslims of Mysore far better than those of the Malabar, Raichur and Kodagu regions. They opine that Tipu was responsible for mass conversions of Christians and Hindus in these regions, either by force or by offering them tax incentives and revenue benefits to convert.

Prior to the 18th century, the society of the kingdom followed age-old and deeply established norms of social interaction between people. Accounts by contemporaneous travellers indicate the widespread practice of the Hindu caste system and of animal sacrifices during the nine-day celebrations (called "Mahanavami"). Later, fundamental changes occurred due to the struggle between native and foreign powers. Though wars between the Hindu kingdoms and the Sultanates continued, the battles between native rulers (including Muslims) and the newly arrived British took centre stage. The spread of English education, the introduction of the printing press and the criticism of the prevailing social system by Christian missionaries helped make the society more open and flexible. The rise of modern nationalism throughout India also affected Mysore.

With the advent of British power, English education gained prominence in addition to traditional education in local languages. These changes were orchestrated by Lord Elphinstone, the governor of the Madras Presidency. His plan became the constitution of the central collegiate institution or University Board in 1841. Accordingly, a high school department of the university was established. For imparting education in the interior regions, schools were raised in principal towns which eventually were elevated to college level, with each college becoming central to many local schools ("zilla" schools). The earliest English-medium schools appeared in 1833 in Mysore and spread across the region. In 1858, the department of education was founded in Mysore and by 1881, there were an estimated 2,087 English-medium schools in the state of Mysore. Higher education became available with the formation of Bangalore Central College in Bangalore (1870), Maharaja's College (1879), Maharani's College (1901) and the Mysore University (1916) in Mysore and the St. Agnes College in Mangalore (1921).

Social reforms aimed at removing practices such as sati and social discrimination based upon untouchability, as well as demands for the emancipation of the lower classes, swept across India and influenced Mysore territory. In 1894, the kingdom passed laws to abolish the marriage of girls below the age of eight. Remarriage of widowed women and marriage of destitute women was encouraged, and in 1923, some women were granted the permission to exercise their franchise in elections. There were, however, uprisings against British authority in the Mysore territory, notably the Kodagu uprising in 1835 (after the British dethroned the local ruler Chikkaviraraja) and the Kanara uprising of 1837. The era of printing heralded by Christian missionaries, notably Hermann Mögling, resulted in the founding of printing presses across the kingdom. The publication of ancient and contemporary Kannada books (such as the "Pampa Bharata" and the "Jaimini Bharata"), a Kannada-language Bible, a bilingual dictionary and a Kannada newspaper called "Kannada Samachara" began in the early 19th century. Aluru Venkata Rao published a consolidated Kannada history glorifying the achievements of Kannadigas in his book "Karnataka Gatha Vaibhava".

Classical English and Sanskrit drama, and native Yakshagana musical theater influenced the Kannada stage and produced famous dramatists like Gubbi Veeranna. The public began to enjoy Carnatic music through its broadcast via public address systems set up on the palace grounds. Mysore paintings, which were inspired by the Bengal Renaissance, were created by artists such as Sundarayya, Ala Singarayya, and B. Venkatappa.

The era of the Kingdom of Mysore is considered a golden age in the development of Kannada literature. Not only was the Mysore court adorned by famous Brahmin and Veerashaiva writers and composers, the kings themselves were accomplished in the fine arts and made important contributions. While conventional literature in philosophy and religion remained popular, writings in new genres such as chronicle, biography, history, encyclopedia, novel, drama, and musical treatise became popular. A native form of folk literature with dramatic representation called Yakshagana gained popularity. A remarkable development of the later period was the influence of English literature and classical Sanskrit literature on Kannada.

Govinda Vaidya, a native of Srirangapatna, wrote "Kanthirava Narasaraja Vijaya", a eulogy of his patron King Narasaraja I. Written in "sangatya" metre (a composition meant to be rendered to the accompaniment of a musical instrument), the book describes the king's court, popular music and the types of musical compositions of the age in twenty-six chapters. King Chikka Devaraja was the earliest composer of the dynasty. To him is ascribed the famous treatise on music called "Geetha Gopala". Though inspired by Jayadeva's Sanskrit writing "Geetha Govinda", it had an originality of its own and was written in "saptapadi" metre. Contemporary poets who left their mark on the entire Kannada-speaking region include the brahmin poet Lakshmisa and the itinerant Veerashaiva poet Sarvajna. Female poets also played a role in literary developments, with Cheluvambe (the queen of Krishnaraja Wodeyar I), Helavanakatte Giriyamma, Sri Rangamma (1685) and Sanchi Honnamma ("Hadibadeya Dharma", late 17th century) writing notable works.

A polyglot, King Narasaraja II authored fourteen Yakshaganas in various languages, though all are written in Kannada script. Maharaja Krishnaraja III was a prolific writer in Kannada for which he earned the honorific "Abhinava Bhoja" (a comparison to the medieval King Bhoja). Over forty writings are attributed to him, of which the musical treatise "Sri Tatwanidhi" and a poetical romance called "Saugandika Parinaya" written in two versions, a "sangatya" and a drama, are most well known. Under the patronage of the Maharaja, Kannada literature began its slow and gradual change towards modernity. Kempu Narayana's "Mudramanjusha" ("The Seal Casket", 1823) is the earliest work that has touches of modern prose. However, the turning point came with the historically important "Adbhuta Ramayana" (1895) and "Ramaswamedham" (1898) by Muddanna, whom the Kannada scholar Narasimha Murthy considers "a Janus like figure" of modern Kannada literature. Muddanna has deftly handled an ancient epic from an entirely modern viewpoint.

Basavappa Shastry, a native of Mysore and a luminary in the court of Maharaja Krishnaraja III and Maharaja Chamaraja X, is known as the "Father of Kannada theatre" ("Kannada Nataka Pitamaha"). He authored dramas in Kannada and translated William Shakespeare's "Othello" to "Shurasena Charite". His well-known translations from Sanskrit to Kannada are many and include "Kalidasa" and "Abhignyana Shakuntala".

Under Maharaja Krishnaraja III and his successors – Chamaraja X, Krishnaraja IV and the last ruler, Jayachamaraja, the Mysore court came to be the largest and most renowned patron of music. While the Tanjore and Travancore courts also extended great patronage and emphasised preservation of the art, the unique combination of royal patronage of individual musicians, founding of music schools to kindle public interest and a patronage of European music publishers and producers set Mysore apart. Maharaja Krishnaraja III, himself a musician and musicologist of merit, composed a number of "javalis" (light lyrics) and devotional songs in Kannada under the title "Anubhava pancharatna". His compositions bear the nom de plume ("mudra") "Chamundi'" or '"Chamundeshwari'", in honour of the Wodeyar family deity. His successor Chamaraja X founded the Oriental Library in 1891 to house music books and also commissioned phonograph recordings of several musicians for the palace library.

Under Krishnaraja IV, art received further patronage. A distinct school of music which gave importance to "raga" and "bhava" evolved. The Royal School of Music founded at the palace helped institutionalise teaching of the art. Carnatic compositions were printed and the European staff notation came to be employed by royal musicians. Western music was also encouraged – Margaret Cousins' piano concerto with the Palace Orchestra marked the celebrations of Beethoven's centenary in Bangalore. Maharaja Jayachamaraja, also a renowned composer of Carnatic "kritis" (a musical composition), sponsored a series of recordings of Russian composer Nikolas Medtner and others. The court ensured that Carnatic music also kept up with the times. Gramophone recordings of the palace band were made and sold commercially. Attention was paid to "technology of the concert". Lavish sums were spent on acquiring various instruments including the unconventional horn violin, theremin and calliaphone, a mechanical music player.

The Mysore court was home to several renowned experts ("vidwan") of the time. Veena Sheshanna, a court musician during the rule of Maharaja Chamaraja X, is considered one of the greatest exponents of the veena. His achievements in classical music won Mysore a premier place in the art of instrumental Carnatic music and he was given the honorific "Vainika Shikhamani" by Maharaja Krishnaraja Wodeyar IV. Mysore Vasudevacharya was a noted musician and composer in Sanskrit and Telugu from Mysore. He holds the unique distinction of being patronised by four generations of Mysore kings and rulers and for being court musician to three of them. H.L. Muthiah Bhagavatar was another musician-composer who adorned the Mysore court. Considered one of the most important composers of the post-Tyagaraja period, he is credited with about 400 compositions in Sanskrit, Kannada, Telugu and Tamil under the pen name "Harikesha". Among violinists, T. Chowdiah emerged as one of the most accomplished exponents of the time. He is known to have mastered the seven-stringed violin. Chowdiah was appointed court musician by Maharaja Krishnaraja Wodeyar IV in 1939 and received such titles as "Sangeeta Ratna" and "Sangeeta Kalanidhi". He is credited with compositions in Kannada, Telugu and Sanskrit under the pen name "Trimakuta".

The architectural style of courtly and royal structures in the kingdom underwent profound changes during British rule – a mingling of European traditions with native elements. The Hindu temples in the kingdom were built in typical South Indian Dravidian style – a modest version of the Vijayanagara building idiom. When in power, Tipu Sultan constructed a palace and a mosque in Srirangapatna, his capital. However, it is the city of Mysore that is best known for its royal palaces, earning it the nickname "City of Palaces". The city's main palace, the Mysore Palace, is also known as the Amba Vilas Palace. The original complex was destroyed by fire and a new palace was commissioned by the Queen-Regent and designed by the English architect Henry Irwin in 1897. The overall design is a combination of Hindu, Islamic, Indo-Saracenic and Moorish styles, which for the first time in India, used cast iron columns and roof frames. The striking feature of the exterior is the granite columns that support cusped arches on the portico, a tall tower whose finial is a gilded dome with an umbrella ("chattri") on it, and groups of other domes around it. The interior is richly decorated with marbled walls and a teakwood ceiling on which are sculptures of Hindu deities. The Durbar hall leads to an inner private hall through silver doors. This opulent room has floor planels that are inlaid with semi-precious stones, and a stained glass roof supported centrally by columns and arches. The marriage hall ("Kalyana mantapa") in the palace complex is noted for its stained glass octagonal dome with peacock motifs.

The Lalitha Mahal Palace was built in 1921 by E.W. Fritchley under the commission of Maharaja Krishnaraja IV. The architectural style is called "Renaissance" and exhibits concepts from English manor houses and Italian palazzos. The central dome is believed to be modelled on St. Paul's Cathedral in London. Other important features are the Italian marble staircase, the polished wooden flooring in the banquet and dance halls, and the Belgian cut glass lamps. The Jaganmohan Palace was commissioned in 1861 and was completed in 1910. The three-storeyed building with attractive domes, finials and cupolas was the venue of many a royal celebration. It is now called the Chamarajendra Art Gallery and houses a rich collection of artifacts.

The Mysore University campus, also called "Manasa Gangotri", is home to several architecturally interesting buildings. Some of them are in European style and were completed in the late 19th century. They include the Jayalakshmi Vilas mansion, the Crawford Hall, the Oriental Research Institute (built between 1887 and 1891) with its Ionic and Corinthian columns, and the district offices ("Athara Kutchery", 1887). The Athara Kutchery, which initially served as the office of the British commissioner, has an octagonal dome and a finial that adds to its beauty. The maharaja's summer palace, built in 1880, is called the Lokaranjan Mahal, and initially served as a school for royalty. The Rajendra Vilas Palace, built in the Indo-British style atop the Chamundi Hill, was commissioned in 1922 and completed in 1938 by Maharaja Krishnaraja IV. Other royal mansions built by the Mysore rulers were the Chittaranjan Mahal in Mysore and the Bangalore Palace in Bangalore, a structure built on the lines of England's Windsor Castle. The Central Food Technical Research Institute (Cheluvamba Mansion), built in baroque European renaissance style, was once the residence of princess Cheluvambaamani Avaru, a sister of Maharaja Krishnaraja IV. Its extensive pilaster work and mosaic flooring are noteworthy.

Most famous among the many temples built by the Wodeyars is the Chamundeshwari Temple atop the Chamundi Hill. The earliest structure here was consecrated in the 12th century and was later patronised by the Mysore rulers. Maharaja Krishnaraja III added a Dravidian-style gopuram in 1827. The temple has silver-plated doors with images of deities. Other images include those of the Hindu god Ganesha and of Maharaja Krishnaraja III with his three queens. Surrounding the main palace in Mysore and inside the fort are a group of temples, built in various periods. The Prasanna Krishnaswamy Temple (1829), the Lakshmiramana Swamy Temple whose earliest structures date to 1499, the Trinesvara Swamy Temple (late 16th century), the Shweta Varaha Swamy Temple built by Purnaiah with a touch of Hoysala style of architecture, the Prasanna Venkataramana Swami Temple (1836) notable for 12 murals of the Wodeyar rulers. Well-known temples outside Mysore city are the yali ("mythical beast") pillared Venkataramana temple built in the late 17th century in the Bangalore fort, and the Ranganatha temple in Srirangapatna.

Tipu Sultan built a wooden colonnaded palace called the Dariya Daulat Palace ("lit", "garden of the wealth of the sea") in Srirangapatna in 1784. Built in the Indo-Saracenic style, the palace is known for its intricate woodwork consisting of ornamental arches, striped columns and floral designs, and paintings. The west wall of the palace is covered with murals depicting Tipu Sultan's victory over Colonel Baillie's army at Pollilur, near Kanchipuram in 1780. One mural shows Tipu enjoying the fragrance of a bouquet of flowers while the battle is in progress. In that painting, the French soldiers' moustaches distinguish them from the cleanshaven British soldiers. Also in Srirangapatna is the Gumbaz mausoleum, built by Tipu Sultan in 1784. It houses the graves of Tipu and Haider Ali. The granite base is capped with a dome built of brick and pilaster.

The first iron-cased and metal-cylinder rocket artillery were developed by Tipu Sultan and his father Hyder Ali, in the 1780s. He successfully used these metal-cylinder rockets against the larger forces of the British East India Company during the Anglo-Mysore Wars. The Mysore rockets of this period were much more advanced than what the British had seen, chiefly because of the use of iron tubes for holding the propellant; this enabled higher thrust and longer range for the missile (up to range). After Tipu's eventual defeat in the Fourth Anglo-Mysore War and the capture of the Mysore iron rockets, they were influential in British rocket development, inspiring the Congreve rocket, which was soon put into use in the Napoleonic Wars.

According to Stephen Oliver Fought and John F. Guilmartin, Jr. in "Encyclopædia Britannica" (2008): 





</doc>
<doc id="938832" url="https://en.wikipedia.org/wiki?curid=938832" title="Resident Evil 2">
Resident Evil 2

Resident Evil 2 is a survival horror game developed and published by Capcom and released for the PlayStation in 1998. The player controls Leon S Kennedy and Claire Redfield, who must escape Raccoon City after its citizens are transformed into zombies by a biological weapon two months after the events of the original "Resident Evil." The gameplay focuses on exploration, puzzles, and combat; the main difference from its predecessor are the branching paths, with each player character having unique storylines and obstacles.

"Resident Evil 2" was directed by Hideki Kamiya, produced by Shinji Mikami—director of the first "Resident Evil"—and developed by a team of around 50 over 21 months. The initial version of the game, commonly referred to as "Resident Evil 1.5", differed drastically and was canceled when it was around two-thirds complete after Mikami decided it was inadequate. The final design introduced a more cinematic presentation.

"Resident Evil 2" received praise for its atmosphere, setting, graphics and audio, and it has appeared on several lists of the best games ever made; however, its controls, voice acting, inventory system and puzzles garnered some criticism. It is the best-selling "Resident Evil" game for a single platform, selling 4.96 million copies on PlayStation. It was ported to Windows, Nintendo 64, Dreamcast and GameCube, and a modified 2.5D version was released for the Game.com handheld. The story of "Resident Evil 2" was retold and built upon in several later games, and has been adapted into a variety of licensed works. It was followed by "" in 1999. A remake of the same name was released for PlayStation 4, Windows, and Xbox One in 2019.

As a survival horror game, "Resident Evil 2" features the same basic gameplay mechanics as its predecessor, "Resident Evil". The player explores a fictional city while solving puzzles and fighting monsters. The game's two protagonists may be equipped with firearms, but limited ammunition adds a tactical element to weapon use. On the status screen, the player can check the condition of the protagonists, use medicine to heal their wounds, and assign weapons. The characters' current health can also be determined by their posture and movement speed. For example, a character will hold their stomach in pain if wounded, and will limp slowly if on the verge of death. The protagonists may carry a limited number of items, and must store others in boxes placed throughout the game world, where they may later be retrieved. Each protagonist is joined by a support partner during the course of the story. These characters accompany the player in certain scenes, and occasionally become playable. Certain rooms contain typewriters that the player may use to save the game. However, each save expends one of a limited number of ink ribbons, which the player must collect in the game world. The graphics of "Resident Evil 2" are composed of real-time generated – and thus movable – polygonal character and item models, superimposed over pre-rendered backgrounds that are viewed from fixed camera angles. The game uses tank controls, meaning that pressing up moves the character in the direction they face, down reverses them, and left and right rotates them, regardless of the perspective of the camera.

The main addition over the preceding game is the "Zapping System", by which each of the two playable characters are confronted with different puzzles and storylines in their respective scenarios. After finishing the "A" scenario with one protagonist, a "B" scenario, in which the events are depicted from the other character's perspective, is unlocked. The player has the option of starting the "A" scenario with either of the two protagonists, resulting in a total of four different scenarios. Actions taken during the first playthrough affect the second. For example, the availability of certain items may be altered. After each game, the player receives a ranking based on the total time taken to complete the scenario, and on the number of saves and special healing items used. Depending on the player's accomplishments, bonus weapons and costumes may be unlocked as a reward. The original version of "Resident Evil 2" contains two stand-alone minigames: "The 4th Survivor" and "The To-fu Survivor". In both of these minigames, the player must reach the goal while fighting every enemy along the way with only the default item loadout. All later versions (except the Nintendo 64 version) add a third minigame, "Extreme Battle", which consists of four playable characters and three stages. 

On September 29, 1998, two months after the events of the first "Resident Evil", most citizens of the Midwestern American mountain community Raccoon City have been transformed into zombies by the T-virus, a biological weapon secretly developed by the pharmaceutical company Umbrella. Leon S. Kennedy, a police officer on his first day of duty, and Claire Redfield, a college student looking for her brother Chris, make their way to the Raccoon Police Department. They discover that most of the police force have been killed, and that Chris has left town to investigate Umbrella's headquarters in Europe. They split up to look for survivors and find a way out of the city. While searching for an escape route, Claire meets a little girl, Sherry Birkin, who is on the run from an unknown creature, and Leon encounters Ada Wong, who claims to be looking for her boyfriend John, an Umbrella researcher.

Raccoon City police chief Brian Irons had been bribed by Umbrella to hide evidence of the company's experiments in the outskirts of the city. He also concealed their development of the new G-virus, an agent capable of mutating a human into the ultimate bioweapon. Leon has multiple encounters with a Tyrant monster air-dropped into the Raccoon Police Department by Umbrella to seek the G-virus. Irons tries to murder Claire but is killed by a G-virus mutant in the police department. Thereupon, Claire and Sherry escape through the sewers and become separated. After splitting up with Leon, Ada comes upon Sherry and picks up a golden pendant the girl loses while running away. Further into the sewers, Ada reluctantly teams up with Leon again, after he insists on his duty to protect her. They encounter a middle-aged woman who fires at Ada, but Leon dives between them and takes a bullet himself. Ada ignores the unconscious Leon and follows the woman, who reveals herself to be Sherry's mother Annette and the wife of William Birkin, the Umbrella scientist who created the G-virus. In an attempt to protect his life's work from special agents sent by the Umbrella headquarters, he injected himself with the virus, which turned him into the malformed creature, "G" and is now chasing Sherry. Annette recognizes her daughter's pendant and attempts to take it from Ada. A fight ensues, during which Annette is thrown over a railing. Ada learns that the golden locket contains a sample of the G-virus, and later – taken over by her emotions – returns to Leon, tending to his bullet wound.

Meanwhile, Claire is reunited with Sherry and discovers that "G" has implanted his daughter with an embryo to produce offspring. Leon, Ada, Claire and Sherry advance through an abandoned factory connected to Umbrella's secret underground research facility. An attack by "G" leaves Ada heavily wounded, and Leon explores the laboratory to find something to treat her wounds. He is interrupted by a psychotic Annette, who explains to him that Ada's relationship with John was only a means of getting information about Umbrella: Ada is a spy sent to steal the G-virus for an unknown organization. Just as Annette is about to shoot Leon, the Tyrant appears, and she is forced to retreat. Ada returns to save Leon and battles the Tyrant – which falls into a pit of molten metal – seemingly at the cost of her own life. She confesses her love to Leon, who leaves behind her motionless body. Meanwhile, Annette tries to escape with another sample of the G-virus but is fatally wounded by her mutated husband. However, before she dies, she tells Claire how to create a vaccine that will stop the mutations caused by the embryo within Sherry. After preparing the cure, Leon and Claire reunite at an emergency escape train and inject Sherry with the vaccine, which saves her life. En route, Leon is assisted in terminating the now-mutated Tyrant by a woman in shadow and escapes with the G-virus in the pendant. "G"—now mutated into an agglomeration of flesh and teeth—follows Leon and Claire, but is destroyed when the train self-destructs. After escaping from the city with Sherry, Leon intends to take down Umbrella, while Claire continues to search for Chris. HUNK, one of the special agents sent by Umbrella, completes his G-virus retrieval mission.

Development of "Resident Evil 2" began one month after the completion of its predecessor in early 1996. The first footage of the game was shown at the V Jump Festival '96 in July. This early build, later dubbed ""Resident Evil 1.5"" by producer Shinji Mikami, differed drastically from the released version in its scenario, presentation and gameplay mechanics. Its plot followed the same basic outline as that of "Resident Evil 2", and featured a zombie outbreak in Raccoon City two months after the events of the first game. In this version of the story, however, Umbrella had already been closed down as a consequence of their illegal experiments. 

The development team sought to retain the level of fear from the original game, and introduced two characters who lacked experience with terrifying situations: Leon S. Kennedy, largely identical to his persona in the final build, and Elza Walker, a college student and motorcycle racer vacationing in Raccoon City, her hometown. Unlike the final version, the story paths of Leon and Elza did not cross, and each playable character had two support partners instead of just one. Leon received help from fellow police officer Marvin Branagh and a researcher named Linda – an early version of Ada – while Elza was aided by Sherry Birkin and a man named John, who appeared in "Resident Evil 2" as gun shop owner Robert Kendo.

Real-world examples influenced several character designs by artists Isao Ohishi and Ryoji Shimogama. For example, Ohishi based Leon on his bloodhound, and Annette Birkin was modeled after actress Jodie Foster. The police department in which "Resident Evil 1.5" began had a more modern and realistic design, and was smaller than the final building seen in "Resident Evil 2". There were more encounters with surviving policemen, such as a superior officer of Leon called Roy. The number of polygons used for enemy models was far lower than in the released version. This allowed many zombies to appear on the screen, a method of invoking fear in the player that recurred throughout "Resident Evil 1.5". Furthermore, the game employed dynamic music, and frequently applied alterations to the pre-rendered backgrounds in response to events during the gameplay. The playable characters could be equipped with gear, such as protective clothes that enhanced their defense and enabled them to carry more items. The characters' polygonal models were altered by costume changes and by damage received from enemies. 

The development was carried out by a 40- to 50-person group that would later be part of Capcom Production Studio 4. Director Hideki Kamiya led the team, which was composed of newer Capcom employees and over half of the staff from the original "Resident Evil". In the initial stages of development, producer Mikami often had creative disagreements with Kamiya, and tried to influence the team with his own direction. He eventually stepped back to an overseeing role as producer, and only demanded to be shown the current build once a month. Believing the game's assets to be good individually, but not yet satisfactory as a whole, Mikami expected that everything would coalesce in the three months leading up to the projected May 1997 release date. Shortly thereafter, however, "Resident Evil 1.5" was scrapped at a development stage of 60–80 percent. Mikami later explained that the game would not have reached the desired quality in the aforementioned period, and especially frowned upon the gameplay and locations for being "dull and boring".

The story of "Resident Evil 1.5", with which Mikami planned to end the series, was criticized by supervisor Yoshiki Okamoto, who found it to be too conclusive to allow for future installments. Instead, Okamoto proposed the creation of a fictional universe that would turn "Resident Evil" into a metaseries – similar to the "Gundam" and "James Bond" franchises – in which self-contained stories with common elements could be told. During a period in which the team made no progress rewriting the scenario, Okamoto was introduced to professional screenwriter Noboru Sugimura, who was enthusiastic about the first game's story. Sugimura was initially consulted on a trial basis, but Okamoto was impressed by the ease with which the writer came up with solutions to the problems that plagued the script, and soon asked him to compose the entire scenario for "Resident Evil 2". One fundamental modification to the story was the reworking of Elza Walker into Claire Redfield, in order to introduce a connection to the plot of the first game. To fulfill Capcom's sales plan of two million copies, director Kamiya tried to attract new customers with a more ostentatious and Hollywood-like story presentation. As Okamoto did not want to simply enforce the new direction, he had Sugimura discuss the plot revisions with Mikami and the development staff. The planners redesigned the game from the ground up to fit the changes, and the programmers and other remaining members of the team were sent to work on "Resident Evil Director's Cut", which was shipped with a playable preview disc of the new "Resident Evil 2" version in order to promote the sequel and to apologize to the players for its belated release.

Only a few assets from "Resident Evil 1.5" could be recycled, as the principal locations in the final build were made to look more extravagant and artistic, based on photographs taken of the interiors of Western-style buildings in Japanese cities. These environments were created with a software program called O2, and each background took two to three weeks to render. The maximum number of zombies displayed on the screen at one time was limited to seven, making it possible to use 450 polygons for the comparatively detailed models of Leon and Claire. The protagonists, instead of being given visible wounds, were made to limp slowly upon receiving heavy damage. Apart from the graphics, one of the most important new features was the "Zapping System", which was partly inspired by "Back to the Future Part II", a time travel-themed film sequel that offers a different perspective on the story of the original film. The voice-overs by the all-Canadian cast of "Resident Evil 2" were recorded before the actual cutscenes were completed, with each of the actors selected from a roster of ten people per role. Thereafter, the full-motion videos (FMVs) were created by filming stop motion animations of action figures, which were then rendered to completed pictures with computer graphics (CG) tools. Ada's movie model could not be finished in time. Thus, she is the only main character not to appear in a pre-rendered cutscene.

Several changes had to be made between the regional releases of "Resident Evil 2". The North American version contains more violent "game over" screens, which were removed from the Japanese "Biohazard 2". "Resident Evil 2" was also made more difficult than its Japanese equivalent to prevent rentals from affecting U.S. sales.

The music for "Resident Evil 2" was composed by Masami Ueda, Shusaku Uchiyama and Syun Nishigaki, with one track composed by Naoshi Mizuta. The compositions were meant to convey "desperation" as their underlying theme. In his role as lead composer, Ueda provided the motifs, while Uchiyama was responsible for the horror-themed music used for the investigation and movie scenes. The main theme of the score, a versatile three-note leitmotif, appears several times throughout the course of the story, being included in compositions such as "Prologue", "Raccoon City" and "The Third Malformation of G". Various musical styles, ranging from ambient horror music to industrial pieces, are used to represent the different environments of the game. For example, the streets of Raccoon City are emphasized with militaristic percussion-based music, while the police department features ominous piano underscores. Key events of the story are supported with orchestral and cinematic compositions – a move that was inspired by blockbuster films.

Two albums containing music from the game were released in January and August 1998, respectively. The first, "Biohazard 2 Original Soundtrack", is the main release and includes most of the significant compositions. The second, "Biohazard 2 Complete Track", largely encompasses less prevalent themes, but offers an orchestral medley and a second CD with sound effects and voice collections, as well as an interview with the sound staff. "Biohazard 2 Original Soundtrack" received an identical European CD, "Resident Evil 2 Original Soundtrack". In the North American album of the same name, the opening theme "The Beginning of Story" is split up into four individual tracks. Five orchestral arrangements of the game's music were included on the "Bio Hazard Orchestra Album", a recording of a live concert performed by the New Japan Philharmonic. Disc jockey Piston Nishizawa created electronic remixes for several of the compositions, which were later released as the album "Biohazard 2 Remix: Metamorphoses".

After its initial release for the PlayStation in January 1998, "Resident Evil 2" was reissued and ported to other systems, often gaining new features in the process. The first re-release was the "Dual Shock Ver.", which incorporated support for the vibration and analog control functions of the PlayStation's DualShock controller. Other additions include a new unlockable minigame called "Extreme Battle", and a "Rookie" mode that enables the player to start the main story with a powerful weapon that features infinite ammunition. The Japanese release of the "Dual Shock Ver." contained a "U.S.A. Version" mode based on the difficulty level of "Resident Evil 2"'s Western versions.

The "Dual Shock Ver." served as the basis for the majority of ports, such as the Windows 9x-based PC-CD version "Resident Evil 2 Platinum". Aside from retaining all previously added features, the PC version can be run in higher resolutions. A "Data Gallery" was added to the main menu, allowing the player to view movies, rough sketches, illustrations and 3D models. In February 2006, a Japan-exclusive, Windows XP-compatible PC-DVD re-release was published. Developed by Sourcenext, it included high-quality FMVs encoded at a resolution of 640×480 pixels. The Dreamcast version keeps the additions from the original PC release, and incorporates real-time display of the character's condition on the Visual Memory Unit peripheral. The Japanese edition of the Dreamcast port was given the subtitle "Value Plus" and came with a playable demo of "". An unmodified port of the "Dual Shock Ver." was released for the GameCube. The initial PlayStation version was re-released on the Japanese PlayStation Network in 2007, while the service's North American counterpart received the "Dual Shock Ver." two years later.

The Nintendo 64 version of "Resident Evil 2" differs most from the other releases as its one of the very few games released for the console to have FMVs, overcoming the limited storage space on the cartridge. The PlayStation version with two CD-ROMs of up to per disc, was faithfully replicated (with unique enhancements) on a Nintendo 64 Game Pak. Audio and video assets had to be more aggressively and creatively compressed, using novel techniques that shift the burden more toward the console's high real-time processing power. Over the course of twelve months and with a budget of $1 million, "Resident Evil 2" was ported to the console by a team led by nine full-time and one part-time personnel from Angel Studios. Further help was provided by ten staff from Capcom Production Studio 3 and Factor 5. This version offers features that were not included on any other system, such as alternate costumes, the ability to adjust the degree of violence and to change the blood color, a randomizer to place items differently during each playthrough, and a more responsive first-person control scheme. Additionally, the port features 16 new in-game documents known as the "Ex Files", written by Tetsuro Oyama. Hidden throughout the four scenarios, they reveal new information about the series' lore and connect the story of "Resident Evil 2" to those of the other installments, including some that hadn't even been released yet at the time. The Nintendo 64 version adjusts its display resolution depending on the number of polygonal models currently on screen, and supports the console's Expansion Pak accessory for a maximum resolution of 640×480 during gameplay. Other visual enhancements include smoother character animations and sharper, perspective-corrected textures for the 3D models. The Nintendo 64 version is the only one to use surround sound, with the soundtrack converted to Dolby Surround by Chris Hülsbeck, Rudolf Stember and Thomas Engel. The team reworked the sound set from the ground up to provide each instrument with a higher sample rate than on the PlayStation, thus resulting in higher-quality music. Some features from the other enhanced ports based on the "Dual Shock Ver." do not appear in the Nintendo 64 version, such as the "Extreme Battle" minigame. In 2018, Eurogamer called this "one of the most ambitious [and impressive] console ports of all time".

A port of "Resident Evil 2" for the Sega Saturn was developed internally at Capcom for a time, but technical difficulties led to its cancellation in October 1998. Tiger Electronics released a sprite-based 2.5D version for their Game.com handheld in late 1998. It included only Leon's story path, and removed several of the original game's core features. In February 2013, an unfinished build of "Resident Evil 1.5" was leaked onto the Internet. In Italy, "Resident Evil 2" was temporarily banned in 1999 following criticism from the political organization "Movimento Diritti Civili" (Civil Rights Movement) for its realistic depiction of violence, with the law enforcement agency Guardia di Finanza seizing over 5,500 unsold copies. After Sony Computer Entertainment asked for a re-examination of the seizure decree, the ban was lifted a few months later.

"Resident Evil 2" received critical acclaim. Its original PlayStation release holds an average score of 89 out of 100 points at Metacritic. The majority of reviews praised "Resident Evil 2" for its atmosphere, setting, graphics and audio, but criticized its controls, voice acting and certain gameplay elements.

IGN's Ricardo Sanchez thought that the game's atmosphere was "dead on", and claimed that "[the] graphics, sound effects, music and level design all work together to create a spooky, horror-filled world". Ryan Mac Donald of GameSpot shared the opinion, and found the game to be "like a product out of Hollywood". He believed that it was "more an interactive, cinematic experience than a video game". Writing for "Computer and Video Games", Paul Mallinson considered the game's atmosphere, story and film-like presentation its most outstanding features. Although he found its plot to be "far-fetched", he believed it was "kept down to earth by clever scripting and gritty storytelling". "GamePro" staff writer Mike Weigand called the narrative "engrossing and dramatic", and the dialogue "well-written" and "spell-binding". Sanchez, GameSpy's Brian Davis and Eurogamer's Martin Taylor praised the "Zapping System" for adding to the story and increasing the replay value. Mac Donald thought that the idea of actions in the first scenario affecting the second was "cool in concept", but underused in the game.

"Resident Evil 2" was also praised for its graphics, which many critics believed were a substantial improvement upon those of the first installment. Sanchez and Weigand thought that the pre-rendered backgrounds were an impressive leap ahead of those in the original "Resident Evil", thanks to their increased detail and interactivity. Mac Donald praised the model animations for having reached "true realism", and commended the game's use of body language as a means of seamlessly communicating the condition of the protagonists' health. Allgame's Shawn Sackenheim awarded its graphics the highest possible score, as he found the backgrounds to be "rendered to perfection", the cutscenes "a work of art" and the animation "fluid and eerie". The audio was well received by critics. Weigand cited it as an "excellent accompaniment to the visuals". Sanchez went as far as to say that "Resident Evil 2" "may have the best sound design yet for a console game". Sackenheim described the music and sound effects as "spot on perfect", and called the soundtrack "perfectly composed", while Mac Donald likened the game's use of audio to that of classic horror films.

A common point of criticism was the inventory system, which Sanchez called "a pain". He frowned upon the player's need to retrieve objects from item boxes, and Mac Donald criticized the system for being unrealistic, as the boxes are "[magically]" interconnected and all items take the same amount of space when being carried, regardless of their size. Furthermore, Mallinson and Mac Donald disapproved of certain puzzles, which they believed were out of place in a police station setting. Sanchez thought that the puzzles were paced better than in the first game, but also found them less interesting and too easy for experienced players. Sackenheim noted the game's brevity in his review, and remarked that the individual scenarios are not different enough to hold the interest of casual players until the end of the game. He found the controls to be "easy to pick up and play", while Sanchez thought that aiming weapons was difficult. Certain reviewers panned the voice acting, calling it "cheesy", "terrible" and "barbaric".

With the exception of the game's critically acclaimed Nintendo 64 port, most later releases of "Resident Evil 2" have received slightly lower scores than the PlayStation version. Weigand advised players who already owned "Resident Evil 2" to rent the "Dual Shock Ver." for the "Extreme Battle" minigame, and recommended that newcomers buy the updated edition instead of the original release. The Windows port was praised for its additional content, but criticized for not allowing the player to save at will, and for lacking updated backgrounds to fit the higher in-game resolution. Eurogamer said the PC's total elimination of CD-ROM load times make the game "extremely fun and simple". The Nintendo 64 version was widely commended for the technical achievement of fitting a two-disc game on a single cartridge. However, Taylor criticized this version for retaining scenes from the PlayStation version that were used to conceal loading times – a technical disadvantage of optical discs that cartridges do not share. A "GamePro" writer under the pseudonym "The Freshman" was impressed with the enhanced graphics of the Nintendo 64 port, but was disappointed by its heavily compressed CG FMVs. GameSpot's Joe Fielder found the compression to be forgivable given the cartridge format, and noted that the new exclusive features made up for the lack of the "Extreme Battle" mode. Eurogamer said the Nintendo 64's unique analog control "works supremely well to the point where it's borderline game-breaking". IGN reviewer Matt Casamassina applauded the implementation of Dolby Surround support, and called the Nintendo 64 release the "best version of the game". In 2018, Eurogamer called it "one of the most ambitious [and impressive] console ports of all time".

The clearer sound effects of the Dreamcast port were received well by Game Revolution's Shawn Sparks, who also remarked that the character models look slightly sharper. However, Steve Key of "Computer And Video Games" disliked the Dreamcast release's low-resolution backgrounds, which he thought made the characters stand out too much from the environments, and thus lessened the game's atmosphere. GameSpot staff writer James Mielke did not believe that the Dreamcast port was "an essential purchase", but still called it a "great game" at an attractively low price. The GameCube release was heavily criticized for its high price and dated graphics. However, "Four-Eyed Dragon" of "GamePro" noted its superior in-game visuals of any version of the game. Davis and 1UP.com's Mark MacDonald were disappointed by the port's lack of features that were included in the Nintendo 64 release. Peer Schneider of IGN found the 2.5D version for the Game.com to be frustrating and only "partially faithful" to the original release of "Resident Evil 2". Although he believed that its graphics and sound effects managed to recreate the original game's atmosphere to a certain extent, he thought that its controls were too "sluggish" to allow for an enjoyable experience.

"Resident Evil 2" has been held in high regard in the years following its initial release, and was named the fourth best game on the PlayStation by "Famitsu". "Electronic Gaming Monthly", IGN, "Empire", "Game Informer" and "Official UK PlayStation Magazine" included it in their lists of the 100 best games of all time; it came in 62nd, 58th, 49th, 34th and sixth place, respectively. Readers of "Retro Gamer" voted "Resident Evil 2" the 97th top retro game, with the staff noting that it was "considered by many to be the best in the long-running series". GameTrailers ranked it fourth on a list of the games that most needed remakes.

"Resident Evil 2" was promoted with a US$5 million advertising campaign. In Italy, the game reached 100,000 pre-orders, worth over 12 billion lire (about more than 6.6 million dollars). It became the fastest-selling video game in North America. On the weekend following its release, it sold 380,000 copies and grossed US$19 million. It therefore surpassed the revenue of all but one Hollywood movie at that time and broke previous sales records set by the video games "Final Fantasy VII" and "Super Mario 64". At the 1999 Milia festival in Cannes, it took home a "Gold" prize for revenues above €29 million in the European Union during the previous year. With 4.96 million copies sold, the PlayStation version of "Resident Evil 2" was a commercial success, and is the franchise's best-selling game on a single platform. 810,000 copies of the "Dual Shock Ver." were shipped by March 1999.

"Resident Evil 2" was the basis for several licensed works and later games. Ted Adams and Kris Oprisko loosely adapted it into the comics "Raccoon City – R.I.P." and "A New Chapter of Evil", which were released in the first and second issues of "Resident Evil: The Official Comic Book Magazine" in March and June 1998. The 60-issue Hong Kong comics "Biohazard 2" was published weekly from February 1998 to April 1999. A romantic comedy retelling of the game's story, centered on Leon, Claire and Ada, was released as the Taiwanese two-issue comic "Èlíng Gǔbǎo II" (lit. "Demon Castle II"). "Resident Evil: City of the Dead", a 1999 book written by author S. D. Perry, is a more direct adaptation of the narrative, and is the third release in her series of "Resident Evil" novelizations, published by Pocket Books in 1999.

The mobile game "Resident Evil: Uprising" contains a condensed version of the "Resident Evil 2" story, adapted by Megan Swaine. "", an on-rails shooter released for the Wii in 2009, includes a scenario named "Memories of a Lost City", which reimagines the original "Resident Evil 2" plot while retaining key scenes from the game's four scenarios. In 2008, "Resident Evil 5" producer Jun Takeuchi, who had previously worked on the series as weapons designer and graphics animator, alluded to the possibility of a full-fledged remake. Such a project had already been considered for the GameCube in 2002, but Mikami abandoned the idea as he did not want to delay the in-development "Resident Evil 4".

The story arcs introduced in "Resident Evil 2" continue in drama albums and later game releases. Kyoko Sagiyama, Junichi Miyashita, Yasuyuki Suzuki, Noboru Sugimura, Hirohisa Soda and Kishiko Miyagi – screenwriters employed by Capcom's former scenario subsidiary Flagship – created two radio dramas, "Chiisana Tōbōsha Sherry" (lit. "The Little Runaway Sherry") and "Ikiteita Onna Spy Ada" ("The Female Spy Ada Lives"). The dramas were broadcast on Radio Osaka in early 1999, and later released by publisher Suleputer as two separate CDs, "Biohazard 2 Drama Album". "Chiisana Tōbōsha Sherry" begins shortly after the events of the game. Sherry is separated from Claire while fleeing from Umbrella soldiers sent to kill all witnesses of the viral outbreak. Raccoon City is burned down by the U.S. Government and Umbrella in an attempt to cover up the disaster. Sherry seeks refuge in the neighboring town of Stone Ville, and later escapes to Canada with the help of a girl named Meg, who vows to help her reunite with Claire.

"Ikiteita Onna Spy Ada" is set a few days after "Resident Evil 2", and deals with Ada's mission to retrieve Sherry's pendant with the G-virus sample, which is said to be in the possession of Hunk in the backstory of the drama album. Ada intercepts the delivery of the locket in France, and kills Hunk and his men. As a consequence of an accidental T-virus leak in Loire Village, the destination of the delivery, Ada is forced to retreat to an old castle. Along with a unit of the French Air Force sent to burn down the village, she encounters Christine Henry, the Umbrella facility director who gave Hunk the order to deliver the G-virus to France. Jacob, the leader of the airborne unit, is revealed to be Christine's co-conspirator. However, he plans to keep the G-virus sample for himself, and shoots her. Philippe, another member of the unit, convinces Ada to give him the pendant, after which he injects himself with the G-virus to give himself the power to stop Jacob. Ada escapes and realizes her feelings for Leon, deciding to quit the spy business and return to him. The characters' story arcs are continued differently: Sherry is taken into custody by the U.S. Government immediately after the events of "Resident Evil 2", and Ada keeps the pendant with the G-virus and resumes her activities as a spy. Hunk successfully delivers a separate G-virus sample to Umbrella.

In August 2015, Capcom announced that a remake of "Resident Evil 2" was in development. Capcom unveiled the game at E3 2018, with trailers and gameplay footage, and announced a worldwide release date of January 25, 2019 for PlayStation 4, Xbox One and Windows. The game uses the RE Engine, which was also used for "", and replaces the tank controls and fixed camera angles with "over-the-shoulder" gameplay similar to "Resident Evil 4".



</doc>
<doc id="939555" url="https://en.wikipedia.org/wiki?curid=939555" title="Hartebeest">
Hartebeest

The hartebeest (; "Alcelaphus buselaphus"), also known as kongoni, is an African antelope. Eight subspecies have been described, including two sometimes considered to be independent species. A large antelope, the hartebeest stands just over at the shoulder, and has a typical head-and-body length of . The weight ranges from . It has a particularly elongated forehead and oddly shaped horns, short neck, and pointed ears. Its legs, which often have black markings, are unusually long. The coat is generally short and shiny. Coat colour varies by the subspecies, from the sandy brown of the western hartebeest to the chocolate brown of the Swayne's hartebeest. Both sexes of all subspecies have horns, with those of females being more slender. Horns can reach lengths of . Apart from its long face, the large chest and the sharply sloping back differentiate the hartebeest from other antelopes.

Gregarious animals, hartebeest form herds of 20 to 300 individuals. They are very alert and non-aggressive. They are primarily grazers, with their diets consisting mainly of grasses. Mating in hartebeest takes place throughout the year with one or two peaks, and depends upon the subspecies and local factors. Both males and females reach sexual maturity at one to two years of age. Gestation is eight to nine months long, after which a single calf is born. Births usually peak in the dry season. The lifespan is 12 to 15 years.

Inhabiting dry savannas and wooded grasslands, hartebeest often move to more arid places after rainfall. They have been reported from altitudes on Mount Kenya up to . The hartebeest was formerly widespread in Africa, but populations have undergone drastic decline due to habitat destruction, hunting, human settlement, and competition with livestock for food. Each of the eight subspecies of the hartebeest has a different conservation status. The Bubal hartebeest was declared extinct by the International Union for Conservation of Nature (IUCN) in 1994. While the populations of the red hartebeest are on the rise, those of the Tora hartebeest, already Critically Endangered, are falling. The hartebeest is extinct in Algeria, Egypt, Lesotho, Libya, Morocco, Somalia, and Tunisia; but has been introduced into Swaziland and Zimbabwe. It is a popular game animal due to its highly regarded meat.

The vernacular name "hartebeest" could have originated from the obsolete Afrikaans word "hertebeest", literally "deer beast". The name was given by the Boers, based on the resemblance of the antelope to deer. The first use of the word "hartebeest" in South African literature was in Dutch colonial administrator Jan van Riebeeck's journal "Daghregister" in 1660. He wrote: ""Meester Pieter ein hart-beest geschooten hadde" (Master Pieter [van Meerhoff] had shot one hartebeest)". Another name for the hartebeest is "kongoni", a Swahili word. "Kongoni" is often used to refer in particular to one of its subspecies—Coke's hartebeest.

The scientific name of the hartebeest is "Alcelaphus buselaphus". First described by German zoologist Peter Simon Pallas in 1766, it is classified in the genus "Alcelaphus" and placed in the family Bovidae. In 1979, palaeontologist Elisabeth Vrba supported "Sigmoceros" as a separate genus for Lichtenstein's hartebeest, a kind of hartebeest, as she assumed it was related to "Connochaetes" (wildebeest). She had analysed the skull characters of living and extinct species of antelope to make a cladogram, and argued that a wide skull linked Lichtenstein's hartebeest with "Connochaetes". However, this finding was not replicated by Alan W. Gentry of the Natural History Museum, who classified it as an independent species of "Alcelaphus". Zoologists such as Jonathan Kingdon and Theodor Haltenorth considered it to be a subspecies of "A. buselaphus". Vrba dissolved the new genus in 1997 after reconsideration. An MtDNA analysis could find no evidence to support a separate genus for Lichtenstein's hartebeest. It also showed the tribe Alcelaphini to be monophyletic, and discovered close affinity between the "Alcelaphus" and the sassabies (genus "Damaliscus")—both genetically and morphologically.
Eight subspecies are identified, of which two – "A. b. caama" and "A. b. lichtensteinii" – have been considered to be independent species. However, a 1999 genetic study by P. Arctander of the University of Copenhagen and colleagues, which sampled the control region of the mitochondrial DNA, found that these two formed a clade within "A. buselaphus", and that recognising these as species would render "A. buselaphus" paraphyletic (an unnatural grouping). The same study found "A. b. major" to be the most divergent, having branched off before the lineage split to give a combined "caama/lichtensteinii" lineage and another that gave rise to the remaining extant subspecies. Conversely a 2001 phylogenetic study, based on D–loop and cytochrome b analysis by Øystein Flagstad (of the Norwegian Institute for Nature Research, Trondheim) and colleagues, found that the southern lineage of "A. b. caama" and "A. lichtensteinii" diverged earliest. Analysis of skull structure supports partition into three major divisions: "A. b. buselaphus" division (nominate, also including "A. b. major" division), "A. b. tora" division (also including "A. b. cokii" and "A. b. swaynei") and "A. b. lelwel" division. Another analysis of cytochrome b and D-loop sequence data shows a notable affinity between the "A. b. lelwel" and "A. b. tora " divisions.

The eight subspecies, including the two controversial ones, are:


In 2000, a study scrutinised two major populations of the Swayne's hartebeest, from the Senkele Wildlife Sanctuary and the Nechisar National Park, for mitochondrial (D-loop) and nuclear (microsatellite) variability in an attempt to estimate the levels of genetic variation between the populations and within the subspecies. The results showed a remarkable differentiation between the two populations; that from the Senkele Wildlife Sanctuary showed more genetic diversity than the one from the Nechisar National Park. Another revelation was that the translocation of the individuals from the Senkele Wildlife Sanctuary in 1974 had not made a significant contribution to the gene pool of the Nechisar National Park. Additionally, the Swayne hartebeest populations were compared with a large red hartebeest population, and both subspecies were found to have a high degree of genetic variation. The study advocated in situ conservation of the Swayne's hartebeest and a renewed attempt at its translocation in order to conserve genetic diversity and increase its population size in both the protected areas.

The diploid number of chromosomes in the hartebeest is 40. Hybrids are usually reported from areas where ranges of two subspecies overlap. Hybrids between the Lelwel and Tora hartebeest have been reported in eastern Sudan and western Ethiopia, in a stretch southward from the Blue Nile to about 9° N latitude. A study proved a male hybrid of the red hartebeest and the blesbok ("Damaliscus pygargus") to be sterile. Sterility of the hybrid was attributed to difficulties in segregation during meiosis, indicated by azoospermia and a low number of germ cells in its seminiferous tubules.

There are three common cross-breeds between the subspecies:


The genus "Alcelaphus" emerged about 4.4 million years ago in a clade whose other members were "Damalops", "Numidocapra", "Rabaticeras", "Megalotragus", "Oreonagor", and "Connochaetes". An analysis using phylogeographic patterns within hartebeest populations suggested a possible origin of "Alcelaphus" in eastern Africa. "Alcelaphus" quickly radiated across the African savannas, replacing several previous forms (such as a relative of the hirola). Flagstad and colleagues showed an early split in the hartebeest populations into two distinct lineages around 0.5 million years ago – one to the north and the other to the south of the equator. The northern lineage further diverged into eastern and western lineages, nearly 0.4 million years ago, most probably as a result of the expanding central African rainforest belt and subsequent contraction of savannah habitats during a period of global warming. The eastern lineage gave rise to the Coke's, Swayne's, Tora and Lelwel hartebeest; and from the western lineage evolved the Bubal and western hartebeest. The southern lineage gave rise to Lichtenstein's and red hartebeest. These two taxa are phylogenetically close, having diverged only 0.2 million years ago. The study concluded that these major events throughout the hartebeest's evolution are strongly related to climatic factors, and that there had been successive bursts of radiation from a more permanent population—a refugium—in eastern Africa; this could be vital to understanding the evolutionary history of not only the hartebeest but also other mammals of the African savanna.

The earliest fossil record dates back to nearly 0.7 million years ago. Fossils of the red hartebeest have been found in Elandsfontein, Cornelia (Free State) and Florisbad in South Africa, as well as in Kabwe in Zambia. In Israel, hartebeest remains have been found in northern Negev, Shephelah, Sharon Plain and Tel Lachish. This population of the hartebeest was originally limited to the open country of the southernmost regions of the southern Levant. It was probably hunted in Egypt, which affected the numbers in the Levant, and disconnected it from its main population in Africa.

A large antelope with a particularly elongated forehead and oddly shaped horns, the hartebeest stands just over at the shoulder, and has a typical head-and-body length of . The weight ranges from . The tail, long, ends in a black tuft. The other distinctive features of the hartebeest are its long legs (often with black markings), short neck, and pointed ears. A study correlated the size of hartebeest species to habitat productivity and rainfall. The western hartebeest is the largest subspecies, and has a characteristic white line between the eyes. The red hartebeest is also large, with a black forehead and a contrasting light band between the eyes. The large Lelwel hartebeest has dark stripes on the front of its legs. Coke's hartebeest is moderately large, with a shorter forehead and longer tail in comparison to the other subspecies. Lichtenstein's hartebeest is smaller, with dark stripes on the front of the legs, as in the Lelwel hartebeest. The Swayne's hartebeest is smaller than the Tora hartebeest, but both have a shorter forehead and similar appearance.

Generally short and shiny, the coat varies in colour according to subspecies. The western hartebeest is a pale sandy-brown, but the front of the legs are darker. The red hartebeest is a reddish-brown, with a dark face. Black markings can be observed on the chin, the back of the neck, shoulders, hips and legs; these are in sharp contrast with the broad white patches that mark its flanks and lower rump. The Lelwel hartebeest is a reddish tan. Coke's hartebeest is reddish to tawny in the upper parts, but has relatively lighter legs and rump. Lichtenstein's hartebeest is reddish brown, though the flanks are a lighter tan and the rump whitish. The Tora hartebeest is a dark reddish brown in the upper part of the body, the face, the forelegs and the rump, but the hindlegs and the underbelly are a yellowish white. The Swayne's hartebeest is a rich chocolate brown with fine spots of white that are actually the white tips of its hairs. Its face is black save for the chocolate band below the eyes. The shoulders and upper part of the legs are black. Fine textured, the body hair of the hartebeest is about long. The hartebeest has preorbital glands (glands near the eyes) with a central duct, that secrete a dark sticky fluid in Coke's and Lichtenstein's hartebeest, and a colourless fluid in the Lelwel hartebeest.

Both sexes of all subspecies have horns, with those of females being more slender. Horns can reach lengths of ; the maximum horn length is , recorded from a Namibian red hartebeest. The horns of the western hartebeest are thick and appear U-shaped from the front and Z-shaped from the sides, growing backward at first and then forward, ending with a sharp backward turn. The horns of the red and the Lelwel hartebeest are similar to those of the western hartebeest, but appear V-shaped when viewed from the front. The Lichtenstein's hartebeest has thick parallel ringed horns, with a flat base. Its horns are shorter than those of other subspecies, curving upward then sharply forward, followed by an inward turn at an angle of about 45° and a final backward turn. The horns of Swayne's hartebeest are thin and shaped like parentheses, curving upward and then backward. The horns of the Tora hartebeest are particularly thin and spread out sideways, diverging more than in any other subspecies.

Apart from its long face, the large chest and the sharply sloping back differentiate the hartebeest from other antelopes. The hartebeest shares several physical traits with the sassabies (genus "Damaliscus"), such as an elongated and narrow face, the shape of the horns, the pelage texture and colour, and the terminal tuft of the tail. The wildebeest have more specialised skull and horn features than the hartebeest. The hartebeest exhibits sexual dimorphism, but only slightly, as both sexes bear horns and have similar body masses. The degree of sexual dimorphism varies by subspecies. Males are 8% heavier than females in Swayne's and Lichtenstein's hartebeest, and 23% heavier in the red hartebeest. In one study, the highest dimorphism was found in skull weight. Another study concluded that the length of the breeding season is a good predictor of dimorphism in pedicle (the bony structures from which the horns grow) height and skull weight, and the best predictor of the horn circumference.

Active mainly during daytime, the hartebeest grazes in the early morning and late afternoon, and rests in shade around noon. Gregarious, the species forms herds of up to 300 individuals. Larger numbers gather in places with abundant grass. In 1963, a congregation of 10,000 animals was recorded on the plains near Sekoma Pan in Botswana. However, moving herds are not so cohesive, and tend to disperse frequently. The members of a herd can be divided into four groups: territorial adult males, non-territorial adult males, young males, and the females with their young. The females form groups of five to 12 animals, with four generations of young in the group. Females fight for dominance over the herd. Sparring between males and females is common. At three or four years of age, the males can attempt to take over a territory and its female members. A resident male defends his territory and will fight if provoked. The male marks the border of his territory through defecation. 

Hartebeest are remarkably alert and cautious animals with highly developed brains. Generally calm in nature, hartebeest can be ferocious when provoked. While feeding, one individual stays on the lookout for danger, often standing on a termite mound to see farther. At times of danger, the whole herd flees in a single file after an individual suddenly starts off. Adult hartebeest are preyed upon by lions, leopards, hyenas and wild dogs; cheetahs and jackals target juveniles. Crocodiles may also prey on hartebeest.

The thin long legs of the hartebeest provide for a quick escape in an open habitat; if attacked, the formidable horns are used to ward off the predator. The elevated position of the eyes enables the hartebeest to inspect its surroundings continuously even as it is grazing. The muzzle has evolved so as to derive maximum nutrition from even a frugal diet. The horns are also used during fights among males for dominance in the breeding season; the clash of the horns is loud enough that it can be heard from hundreds of metres away. The beginning of a fight is marked with a series of head movements and stances, as well as depositing droppings on dung piles. The opponents drop onto their knees and, after giving a hammer-like blow, begin wrestling, their horns interlocking. One attempts to fling the head of the other to one side to stab the neck and shoulders with his horns. Fights are rarely serious, but can be fatal if they are.

Like the sassabies, hartebeest produce quiet quacking and grunting sounds. Juveniles tend to be more vocal than adults, and produce a quacking call when alarmed or pursued. The hartebeest uses defecation as an olfactory and visual display. Herds are generally sedentary, and tend to migrate only under adverse conditions such as natural calamities. The hartebeest is the least migratory in the tribe Alcelaphini (which also includes wildebeest and sassabies), and also consumes the least amount of water and has the lowest metabolic rate among the members of the tribe.

Several parasites have been isolated from the hartebeest. These parasites regularly alternate between hartebeest and gazelles or wildebeest. Hartebeest can be infected with theileriosis due to "Rhipicephalus evertsi" and "Theileria" species. South of the Sahara, common parasites include "Loewioestrus variolosus", "Gedoelstia cristata" and "G. hassleri". The latter two species can cause serious diseases such as encephalitis. However, parasites are not always harmful – 252 larvae were found in the head of one Zambian individual without any pathogenicity. Nematodes, cestodes, paramphistomes; and the roundworm "Setaria labiatopapillosa" have also been isolated from the hartebeest. In 1931, a red hartebeest in Gobabis (southwestern Africa) was infected with long, thin worms. These were named "Longistrongylus meyeri" after their collector, T. Meyer.
Hartebeest are primarily grazers, and their diets consist mostly of grasses. A study in the Nazinga Game Ranch in Burkina Faso found that the hartebeest's skull structure eased the acquisition and chewing of highly fibrous foods. The hartebeest has much lower food intake than the other members of Alcelaphini. The long thin muzzle of the hartebeest assists in feeding on leaf blades of short grasses and nibbling off leaf sheaths from grass stems. In addition to this, it can derive nutritious food even from tall senile grasses. These adaptations of the hartebeest enable the animal to feed well even in the dry season, which is usually a difficult period for grazers. For instance, in comparison with the roan antelope, the hartebeest is better at procuring and chewing the scarce regrowth of perennial grasses at times when forage is least available. These unique abilities could have allowed the hartebeest to prevail over other animals millions of years ago, leading to its successful radiation in Africa.

Grasses generally comprise at least 80 percent of the hartebeest's diet, but they account for over 95 percent of their food in the wet season, October to May. "Jasminum kerstingii" is part of the hartebeest's diet at the start of the rainy season. Between seasons, they mainly feed on the culms of grasses. A study found that the hartebeest is able to digest a higher proportion of food than the topi and the wildebeest. In areas with scarce water, it can survive on melons, roots, and tubers.

In a study of grass selectivity among the wildebeest, zebra, and the Coke's hartebeest, the hartebeest showed the highest selectivity. All animals preferred "Themeda triandra" over "Pennisetum mezianum" and "Digitaria macroblephara". More grass species were eaten in the dry season than in the wet season.

Mating in hartebeest takes place throughout the year, with one or two peaks that can be influenced by the availability of food. Both males and females reach sexual maturity at one to two years of age. Reproduction varies by the subspecies and local factors. Mating takes place in the territories defended by a single male, mostly in open areas. The males may fight fiercely for dominance, following which the dominant male smells the female's genitalia, and follows her if she is in oestrus. Sometimes a female in oestrus holds out her tail slightly to signal her receptivity, and the male tries to block the female's way. She may eventually stand still and allow the male to mount her. Copulation is brief and is often repeated, sometimes twice or more in a minute. Any intruder at this time is chased away. In large herds, females often mate with several males.

Gestation is eight to nine months long, after which a single calf weighing about is born. Births usually peak in the dry season, and take place in thickets – unlike the wildebeest, which give birth in groups on the plains. Though calves can move about on their own shortly after birth, they usually lie in the open in close proximity of their mothers. The calf is weaned at four months, but young males stay with their mothers for two and a half years, longer than in other Alcelaphini. Often the mortality rate of male juveniles is high, as they have to face the aggression of territorial adult males and are also deprived of good forage by them. The lifespan is 12 to 15 years.

Hartebeest inhabit dry savannas, open plains and wooded grasslands, often moving into more arid places after rainfall. They are more tolerant of wooded areas than other Alcelaphini, and are often found on the edge of woodlands. They have been reported from altitudes on Mount Kenya up to . The red hartebeest is known to move across large areas, and females roam home ranges of over , with male territories in size. Females in the Nairobi National Park (Kenya) have individual home ranges stretching over , which are not particularly associated with any one female group. Average female home ranges are large enough to include 20 to 30 male territories.

Each hartebeest subspecies is listed under a different conservation status by the IUCN. The species as a whole is classified as Least Concern by the IUCN. The hartebeest is extinct in Algeria, Egypt, Lesotho, Libya, Morocco, Somalia, and Tunisia.


Hartebeest are popular game and trophy animals as they are prominently visible and hence easy to hunt. Pictorial as well as epigraphic evidence from Egypt suggests that in the Upper Palaeolithic age, Egyptians hunted hartebeest and domesticated them. The hartebeest was a prominent source of meat, but its economic significance was lower than that of gazelles and other desert species. However, from the beginning of the Neolithic age, hunting became less common and consequently the remains of the hartebeest from this period in Egypt, where it is now extinct, are rare.

In a study on the effect of place and sex on carcass characteristics, the average carcass weight of the male red hartebeest was and that of females was . The meat of the animals from Qua-Qua region had the highest lipid content— per of meat. Negligible differences were found in the concentrations of individual fatty acids, amino acids, and minerals. The study considered hartebeest meat to be healthy, as the ratio of polyunsaturated to saturated fatty acids was 0.78, slightly more than the recommended 0.7.



</doc>
<doc id="941270" url="https://en.wikipedia.org/wiki?curid=941270" title="Giganotosaurus">
Giganotosaurus

Giganotosaurus ( ) is a genus of theropod dinosaur that lived in what is now Argentina, during the early Cenomanian age of the Late Cretaceous period, approximately 98 to 97 million years ago. The holotype specimen was discovered in the Candeleros Formation of Patagonia in 1993, and is almost 70% complete. The animal was named G. carolinii in 1995; the genus name translates as "giant southern lizard" and the specific name honours the discoverer, Rubén D. Carolini. A dentary bone, a tooth and some tracks, discovered before the holotype, were later assigned to this animal. The genus attracted much interest and became part of a scientific debate about the maximum sizes of theropod dinosaurs.

"Giganotosaurus" was one of the largest known terrestrial carnivores, but the exact size has been hard to determine due to the incompleteness of the remains found so far. Estimates for the most complete specimen range from a length of , a skull in length, and a weight of . The dentary bone that belonged to a supposedly larger individual has been used to extrapolate a length of . Some researchers have found the animal to be larger than "Tyrannosaurus", which has historically been considered the largest theropod, while others have found them to be roughly equal in size, and the largest size estimates for "Giganotosaurus" exaggerated. The skull was low, with rugose (rough and wrinkled) nasal bones and a ridge-like crest on the lacrimal bone in front of the eye. The front of the lower jaw was flattened, and had a downwards projecting process (or "chin") at the tip. The teeth were compressed sideways and had serrations. The neck was strong and the pectoral girdle proportionally small.

Part of the family Carcharodontosauridae, "Giganotosaurus" is one of the most completely known members of the group, which includes other very large theropods, such as the closely related "Mapusaurus" and "Carcharodontosaurus". "Giganotosaurus" is thought to have been homeothermic (a type of "warm-bloodedness"), with a metabolism between that of a mammal and a reptile, which would have enabled fast growth. It may have been relatively fast moving, with a calculated maximal running speed of . It would have been capable of closing its jaws quickly, capturing and bringing down prey by delivering powerful bites. The "chin" may have helped in resisting stress when a bite was delivered against prey. "Giganotosaurus" is thought to have been the apex predator of its ecosystem, and it may have fed on juvenile sauropod dinosaurs.

"Giganotosaurus" is thought to have been one of the largest theropod dinosaurs, but the incompleteness of its remains have made it difficult to estimate its size reliably. It is therefore impossible to determine with certainty whether it was larger than "Tyrannosaurus", for example, which has been considered the largest theropod historically. Different size estimates have been reached by several researchers, based on various methods, and depending on how the missing parts of the skeleton have been reconstructed. Length estimates for the holotype specimen have varied between , with a skull between long, a femur (thigh bone) between long, and a weight between . Fusion of sutures (joints) in the braincase indicates the holotype specimen was a mature individual. A second specimen, consisting of a dentary bone (part of the lower jaw) from a supposedly larger individual, has been used to extrapolate a length of , a skull long, and a weight of . Some writers have considered the largest size estimates for both specimens exaggerated. "Giganotosaurus" has been compared to an oversized version of the well-known genus "Allosaurus".

Though incompletely known, the skull of "Giganotosaurus" appears to have been low. The maxilla of the upper jaw had a long tooth row, was deep from top to bottom, and its upper and lower edges were almost parallel. The maxilla had a pronounced process (projection) under the nostril, and a small, ellipse-shaped fenestra (opening), as in "Allosaurus" and "Tyrannosaurus". The nasal bone was very rugose (rough and wrinkled), and these rugosities continued backwards, covering the entire upper surface of this bone. The lacrimal bone in front of the eye had a prominent, rugose crest (or horn) that pointed up at a backwards angle. The crest was ridge-like, and had deep grooves. The postorbital bone behind the eye had a down and backwards directed jugal process that projected into the orbit (eye opening), as seen in "Tyrannosaurus", "Abelisaurus", and "Carnotaurus". The supraorbital bone above the eye that contacted between the lacrimal and postorbital bones was eave-like, and similar to that of "Abelisaurus". The quadrate bone at the back of the skull was long, and had two pneumatic (air-filled) foramina (holes) on the inner side. 
The skull roof (formed by the frontal and parietal bones) was broad and formed a "shelf", which overhung the short supratemporal fenestrae at the top rear of the skull. The jaw articulated far behind the occipital condyle (where the neck is attached to the skull) compared to other theropods. The condyle was broad and low, and had pneumatic cavities. "Giganotosaurus" did not have a sagittal crest on the top of the skull, and the jaw muscles did not extend onto the skull roof, unlike in most other theropods (due to the shelf over the supratemporal fenestrae). These muscles would instead have been attached to the lower side surfaces of the shelf. The neck muscles that elevated the head would have attached to the prominent supraoccipital bones on the top of the skull, which functioned like the nuchal crest of tyrannosaurs. A latex endocast of the brain cavity of "Giganotosaurus" showed that the brain was similar to that of the related genus "Carcharodontosaurus", but larger. The endocast was long, wide, and had a volume of .

The dentary of the lower jaw expanded in height towards the front (by the mandibular symphysis), where it was also flattened, and it had a downwards projection at the tip (which has been referred to as a "chin"). The lower side of the dentary was concave, the outer side was convex in upper view, and a groove ran along it, which supported foramina that nourished the teeth. The inner side of the dentary had a row of interdental plates, where each tooth had a foramen. The Meckelian groove ran along the lower border. The curvature of the dentary shows that the mouth of "Giganotosaurus" would have been wide. It is possible that each dentary had twelve alveoli (tooth sockets). Most of the alveoli were about 3.5 cm (1.3 in) long from front to back. The teeth of the dentary were of similar shape and size, except for the first one, which was smaller. The teeth were compressed sideways, were oval in cross-section, and had serrations at the front and back borders, which is typical of theropods. The teeth were sigmoid-shaped when seen in front and back view. One tooth had nine to twelve serrations per millimetre (0.039 in). The side teeth of "Giganotosaurus" had curved ridges of enamel, and the largest teeth in the premaxilla (front of the upper jaw) had pronounced wrinkles (with their highest relief near the serrations).

The neck of "Giganotosaurus" was strong, and the axis bone (the neck vertebra that articulates with the skull) was robust. The rear neck (cervical) vertebrae had short, flattened centra (the "bodies" of the vertebrae), with almost hemispherical articulations (contacts) at the front, and pleurocoels (hollow depressions) divided by laminae (plates). The back (dorsal) vertebrae had high neural arches and deep pleurocoels. The tail (caudal) vertebrae had neural spines that were elongated from front to back and had robust centra. The transverse processes of the caudal vertebrae were long from front to back, and the chevrons on the front were blade-like. The pectoral girdle was proportionally shorter than that of "Tyrannosaurus", with the ratio between the scapula (shoulder blade) and the femur being less than 0.5. The blade of the scapula had parallel borders, and a strong tubercle for insertion of the triceps muscle. The coracoid was small and hook-shaped.

The ilium of the pelvis had a convex upper border, a low postacetabular blade (behind the acetabulum), and a narrow brevis-shelf (a projection where tail muscles attached). The pubic foot was pronounced and shorter at the front than behind. The ischium was straight and expanded hindwards, ending in a lobe-shape. The femur was sigmoid-shaped, and had a very robust, upwards pointing head, with a deep sulcus (groove). The lesser trochanter of the femoral head was wing-like, and placed below the greater trochanter, which was short. The fourth trochanter was large and projected backwards. The tibia of the lower leg was expanded at the upper end, its articular facet (where it articulated with the femur) was wide, and its shaft was compressed from front to back.

In 1993, the amateur fossil hunter Rubén D. Carolini discovered the tibia of a theropod dinosaur while driving a dune buggy in the badlands near Villa El Chocón, in the Neuquén province of Patagonia, Argentina. Specialists from the National University of Comahue were sent to excavate the specimen after being notified of the find. The discovery was announced by the palaeontologists Rodolfo Coria and Leonardo Salgado at a Society of Vertebrate Paleontology meeting in 1994, where science writer Don Lessem offered to fund the excavation, after having been impressed by a photo of the leg-bone. The partial skull was scattered over an area of about 10 square metres (110 sq ft), and the postcranial skeleton was disarticulated. The specimen preserved almost 70% of the skeleton, and included most of the vertebral column, the pectoral and pelvic girdles, the femora, and the left tibia and fibula. In 1995, this specimen (MUCPv-Ch1) was preliminarily described in "Nature" by Coria and Salgado, who made it the holotype of the new genus and species "Giganotosaurus carolinii" (parts of the skeleton were still encased in plaster at this time). The generic name is derived from the Ancient Greek words "gigas/γίγας" (meaning "giant"), "notos/νότος" (meaning "austral/southern", in reference to its provenance) and "-sauros/-σαύρος" (meaning "lizard"). The specific name honours Carolini, the discoverer. The holotype skeleton is now housed in the Ernesto Bachmann Palaeontological Museum in Villa El Chocón, which was inaugurated in 1995 at the request of Carolini. The specimen is the main exhibition at the museum, and is placed on the sandy floor of a room devoted to the animal, along with tools used by palaeontologists during the excavation. A mounted reconstruction of the skeleton is exhibited in an adjacent room.
One of the features of theropod dinosaurs that has attracted most scientific interest is the fact that the group includes the largest terrestrial predators of the Mesozoic Era. This interest began with the discovery of one of the first known dinosaurs, "Megalosaurus", named in 1824 for its large size. More than half a century later in 1905, "Tyrannosaurus" was named, and it remained the largest known theropod dinosaur for 90 years, though other large theropods were also known. The discussion of which theropod was the largest was revived in the 1990s by new discoveries in Africa and South America. In their original description, Coria and Salgado considered "Giganotosaurus" at least the largest theropod dinosaur from the southern hemisphere, and perhaps the largest in the world. They conceded that comparison with "Tyrannosaurus" was difficult due to the disarticulated state of the cranial bones of "Giganotosaurus", but noted that at , the femur of "Giganotosaurus" was 5 cm (2 in) longer than that of "Sue", the largest known "Tyrannosaurus" specimen, and that the bones of "Giganotosaurus" appeared to be more robust, indicating a heavier animal. They estimated the skull to have been about 1.53 m (5 ft) long, and the whole animal to have been 12.5 m (41 ft) long, with a weight of about .

In 1996, the palaeontologist Paul Sereno and colleagues described a new skull of the related genus "Carcharodontosaurus" from Morocco, a theropod described in 1927 but previously known only from fragmentary remains (the original fossils were destroyed in World War II). They estimated the skull to have been long, similar to "Giganotosaurus", but perhaps exceeding that of the "Tyrannosaurus" "Sue", with a 1.53 m (5 ft) long skull. They also pointed out that carcharodontosaurs appear to have had the proportionally largest skulls, but that "Tyrannosaurus" appears to have had longer hind limbs. In a 1995 interview for a "Science News" article entitled "New Beast Usurps "T. Rex" as King Carnivore", Sereno noted that these newly discovered theropods from South America and Africa competed with "Tyrannosaurus" as the largest predators, and would help in the understanding of Late Cretaceous dinosaur faunas, which had otherwise been very "North America-centric". In the same issue of "Science" in which "Carcharodontosaurus" was described, the palaeontologist Philip J. Currie cautioned that it was yet to be determined which of the two animals were larger, and that the size of an animal is less interesting to palaeontologists than, for example, adaptations, relationships, and distribution. He also found it remarkable that the two animals were found within a year of each other, and were closely related, in spite of being found on different continents. 
In a 1997 "Science News" interview, Coria estimated "Giganotosaurus" to have been 13.7 (45 ft) to 14.3 (47 ft) m long and weighing based on new material, larger than "Carcharodontosaurus". Sereno countered that it would be difficult to determine a size range for a species based on few, incomplete specimens, and both palaeontologists agreed that other aspects of these dinosaurs were more important than settling the "size contest". In 1998, the palaeontologist Jorge O. Calvo and Coria referred a partial left dentary containing some teeth (MUCPv-95) to "Giganotosaurus". It had been collected by Calvo near Los Candeleros in 1988 (found in 1987), who described it briefly in 1989, while noting it may have belonged to a new theropod taxon. Calvo and Coria found the dentary to be identical to that of the holotype, though 8% larger at 62 cm (24 in). Though the rear part of it is incomplete, they proposed that the skull of the holotype specimen would have been long, and estimated the skull of the larger specimen to have been long, the longest skull of any theropod.

In 1999, Calvo referred an incomplete tooth, (MUCPv-52), to "Giganotosaurus"; this specimen was discovered near Lake Ezequiel Ramos Mexia in 1987 by A. Delgado, and is therefore the first known fossil of the genus. Calvo further suggested that some theropod trackways and isolated tracks (which he made the basis of the ichnotaxon "Abelichnus astigarrae" in 1991) belonged to "Giganotosaurus", based on their large size. The largest tracks are long with a pace of , and the smallest is long with a pace of . The tracks are tridactyl (three-toed) and have large and coarse digits, with prominent claw impressions. Impressions of the digits occupy most of the track-length, and one track has a thin heel. Though the tracks were found in a higher stratigraphic level than the main fossils of "Giganotosaurus", they were from the same strata as the single tooth and some sauropod dinosaurs that are also known from the same strata as "Giganotosaurus".
In 2001, the physician-scientist Frank Seebacher proposed a new polynomial method of calculating body-mass estimates for dinosaurs (using body-length, depth, and width), and found "Giganotosaurus" to have weighed (based on the original length estimate). In their 2002 description of the braincase of "Giganotosaurus", Coria and Currie gave a length estimate of for the holotype skull, and calculated a weight of by extrapolating from the circumference of the femur-shaft. This resulted in an encephalization quotient (a measure of relative brain size) of 1.9. In 2004, the palaeontologist Gerardo V. Mazzetta and colleagues pointed out that though the femur of the "Giganotosaurus" holotype was larger than that of "Sue", the tibia was shorter at . They found the holotype specimen to have been equal to "Tyrannosaurus" in size at (marginally smaller than "Sue"), but that the larger dentary might have represented an animal of , if geometrically similar to the holotype specimen. By using multivariate regression equations, these authors also suggested an alternative weight of for the holotype and for the larger specimen, and that the latter was therefore the largest known terrestrial carnivore. 

In 2005, the palaeontologist Cristiano Dal Sasso and colleagues described new skull material (a snout) of "Spinosaurus" (the original fossils of which were also destroyed during World War II), and concluded this dinosaur would have been long with a weight , exceeding the maximum size of all other theropods. In 2006, Coria and Currie described the large theropod "Mapusaurus" from Patagonia; it was closely related to "Giganotosaurus" and of approximately the same size. In a 2007, the palaeontologists François Therrien and Donald M. Henderson found that "Giganotosaurus" and "Carcharodontosaurus" would both have approached in length and in weight (surpassing "Tyrannosaurus"), and estimated the "Giganotosaurus" holotype skull to have been long. They cautioned that these measurements depended on whether the incomplete skulls of these animals had been reconstructed correctly, and that more complete specimens were needed for more accurate estimates. They also found that Dal Sasso and colleagues' reconstruction of "Spinosaurus" was too large, and instead estimated it to have been long, weighing , and possibly as low as in length and in weight. They concluded that these dinosaurs had reached the upper biomechanical size limit attainable by a strictly bipedal animal. In 2010, the palaeontologist Gregory S. Paul suggested that the skulls of carcharodontosaurs had been reconstructed as too long in general.

In 2012, the palaeontologist Matthew T. Carrano and colleagues noted that though "Giganotosaurus" had received much attention due to its enormous size, and in spite of the holotype being relatively complete, it had not yet been described in detail, apart from the braincase. They pointed out that many contacts between skull bones were not preserved, which lead to the total length of the skull being ambiguous. They found instead that the skulls of "Giganotosaurus" and "Carcharodontosaurus" were exactly the same size as that of "Tyrannosaurus". They also measured the femur of the "Giganotosaurus" holotype to be long, in contrast to the original measurement, and proposed that the body mass would have been smaller overall. In 2013, the palaeontologist Scott Hartman published a Graphic Double Integration mass estimate (based on drawn skeletal reconstructions), wherein he found "Tyrannosaurus" ("Sue") to have been larger than "Giganotosaurus" overall. He estimated the "Giganotosaurus" holotype to have weighed , and the larger specimen . "Tyrannosaurus" was estimated to have weighed , and Hartman noted that it had a wider torso, though the two seemed similar in side view. He also pointed out that the "Giganotosaurus" dentary that was supposedly 8% larger than that of the holotype specimen would rather have been 6.5% larger, or could simply have belonged to a similarly sized animal with a more robust dentary. He conceded that with only one good "Giganotosaurus" specimen known, it is possible that larger individuals will be found, as it took most of a century to find "Sue" after "Tyrannosaurus" was discovered. In 2014, Nizar Ibrahim and colleagues estimated the length of "Spinosaurus" to have been over , by extrapolating from a new specimen scaled up to match the snout described by Dal Sasso and colleagues. This would make "Spinosaurus" the largest ever carnivorous dinosaur.

Coria and Salgado originally found "Giganotosaurus" to group more closely with the theropod clade Tetanurae than to more basal (or "primitive") theropods such as ceratosaurs, due to shared features (synapomorphies) in the legs, skull, and pelvis. Other features showed that it was outside the more derived (or "advanced") clade Coelurosauria. In 1996, Sereno and colleagues found "Giganotosaurus", "Carcharodontosaurus", and "Acrocanthosaurus" to be closely related within the superfamily Allosauroidea, and grouped them in the family Carcharodontosauridae. Features shared between these genera include the lacrimal and postorbital bones forming a broad "shelf" over the orbit, and the squared front end of the lower jaw.

As more carcharodontosaurids were discovered, their interrelationships became clearer. The group was defined as all allosauroids closer to Carcharodontosaurus than "Allosaurus" or "Sinraptor" by the palaeontologist Thomas R. Holtz and colleagues in 2004. In 2006, Coria and Currie united "Giganotosaurus" and "Mapusaurus" in the carcharodontosaurid subfamily Giganotosaurinae based on shared features of the femur, such as a weak fourth trocanther, and a shallow, broad groove on the lower end. In 2008, Sereno and the palaeontologist Stephen L. Brusatte united "Giganotosaurus", "Mapusaurus", and "Tyrannotitan" in the tribe Giganotosaurini. In 2010, Paul listed "Giganotosaurus" as ""Giganotosaurus" (or "Carcharodontosaurus") "carolinii"" without elaboration. "Giganotosaurus" is one of the most complete and informative members of Carcharodontosauridae.

The following cladogram shows the placement of "Giganotosaurus" within Carcharodontosauridae according to Sebastián Apesteguía et al., 2016:

Coria and Salgado suggested that the convergent evolution of gigantism in theropods could have been linked to common conditions in their environments or ecosystems. Sereno and colleagues found that the presence of carcharodontosaurids in Africa ("Carcharodontosaurus"), North America ("Acrocanthosaurus"), and South America ("Giganotosaurus"), showed the group had a transcontinental distribution by the Early Cretaceous period. Dispersal routes between the northern and southern continents appear to have been severed by ocean barriers in the Late Cretaceous, which led to more distinct, provincial faunas, by preventing exchange. Previously, it was thought that the Cretaceous world was biogeographically separated, with the northern continents being dominated by tyrannosaurids, South America by abelisaurids, and Africa by carcharodontosaurids. The subfamily Carcharodontosaurinae, in which "Giganotosaurus" belongs, appears to have been restricted to the southern continent of Gondwana (formed by South America and Africa), where they were probably the apex (top) predators. The South American tribe Giganotosaurini may have been separated from their African relatives through vicariance, when Gondwana broke up during the Aptian–Albian ages of the Early Cretaceous.

In 1999, the palaeontologist Reese E. Barrick and the geologist William J. Showers found that the bones of "Giganotosaurus" and "Tyrannosaurus" had very similar oxygen isotope patterns, with similar heat distribution in the body. These thermoregulatory patterns indicate that these dinosaurs had a metabolism intermediate between that of mammals and reptiles, and were therefore homeothermic (with a stable core body-temperature, a type of "warm-bloodedness"). The metabolism of an "Giganotosaurus" would be comparable to that of a mammalian carnivore, and would have supported rapid growth.

In 2001, the physicist Rudemar Ernesto Blanco and Mazzetta evaluated the cursorial (running) capability of "Giganotosaurus". They rejected the hypothesis by James Orville Farlow that the risk of injuries involved in such large animals falling while on a run, would limit the speed of large theropods. Instead they posed that the imbalance caused by increasing velocity would be the limiting factor. Calculating the time it would take for a leg to gain balance after the retraction of the opposite leg, they found the upper kinematic limit of the running speed to be . They also found comparison between the running capability of "Giganotosaurus" and birds like the ostrich based on the strength of their leg-bones to be of limited value, since theropods, unlike birds, had heavy tails to counterbalance their weight.

In 2002, Coria and Currie found that various features of the rear part of the skull (such as the frontwards slope of the occiput and low and wide occipital condyle) indicate that "Giganotosaurus" would have had a good capability of moving the skull sideways in relation to the front neck vertebrae. These features may also have been related to the increased mass and length of the jaw muscles; the jaw articulation of "Giganotosaurus" and other carcharodontosaurids was moved hindwards to increase the length of the jaw musculature, enabling faster closure of the jaws, whereas tyrannosaurs increased the mass of the lower jaw musculature, to increase the power of their bite.

In 2005 Therrien and colleagues estimated the relative bite force of theropods (estimates in absolute values like newtons were impossible) and found that "Giganotosaurus" and related taxa had adaptations for capturing and bringing down prey by delivering powerful bites, whereas tyrannosaurs had adaptations for resisting torsional stress and crushing bones. The bite force of "Giganotosaurus" was weaker than that of "Tyrannosaurus", and the force decreased hindwards along the tooth row. The lower jaws were adapted for slicing bites, and it probably captured and manipulated prey with the front part of the jaws. These authors suggested that "Giganotosaurus" and other allosaurs may have been generalised predators that fed on a wide spectrum of prey smaller than themselves, such as juvenile sauropods. The ventral process (or "chin") of the lower jaw may have been an adaptation for resisting tensile stress when the powerful bite was delivered with the front of the jaws against the prey.

The first known fossils of the closely related "Mapusaurus" were found in a bonebed consisting of several individuals at different growth stages. In their 2006 description of the genus, Coria and Currie suggested that though this could be due to a long term or coincidental accumulation of carcasses, the presence of different growth stages of the same taxon indicated the aggregation was not coincidental. In a 2006 "National Geographic" article, Coria stated that the bonebed was probably the result of a catastrophic event, and that the presence of mainly medium-sized individuals, with very few young or old, is normal for animals that form packs. Therefore, Coria said, large theropods may have hunted in groups, which would be advantageous when hunting gigantic sauropods.

"Giganotosaurus" was discovered in the Candeleros Formation, which was deposited during the Early Cenomanian age of the Late Cretaceous period, approximately 98 to 97 million years ago, although Holtz provided an earlier lower bound for its age of 99.6 million years. This formation is the lowest unit in the Neuquén Group, wherein it is part of the Río Limay Subgroup. The formation is composed of coarse and medium-grained sandstones deposited in a fluvial environment (associated with rivers and streams), and in aeolian conditions (effected by wind). Paleosols (buried soil), siltstones, and claystones are present, some of which represent swamp conditions.

"Giganotosaurus" was probably the apex predator in its ecosystem. It shared its environment with herbivorous dinosaurs such as the titanosaurian sauropod "Andesaurus", and the rebbachisaurid sauropods "Limaysaurus" and "Nopcsaspondylus". Other theropods include the abelisaurid "Ekrixinatosaurus", the dromaeosaurid "Buitreraptor", and the alvarezsaurid "Alnashetri". Other reptiles include the crocodyliform "Araripesuchus", sphenodontians, snakes, and the turtle "Prochelidella". Other vertebrates include cladotherian mammals, a pipoid frog, and ceratodontiform fishes. Footprints indicate the presence of large ornithopods and pterosaurs as well.



</doc>
<doc id="942346" url="https://en.wikipedia.org/wiki?curid=942346" title="Vampire: The Masquerade – Bloodlines">
Vampire: The Masquerade – Bloodlines

Vampire: The Masquerade – Bloodlines is a 2004 action role-playing video game developed by Troika Games and released by Activision for Microsoft Windows. Set in White Wolf Publishing's World of Darkness, the game is based on White Wolf's role-playing game "" and follows either a male or female character who is killed and subsequently revived as a fledgling vampire. The game depicts the fledgling's journey through the early 21st-century Los Angeles to uncover the truth behind a recently discovered relic that heralds the end of all vampires.

"Bloodlines" is presented from first- and third-person perspectives. The player assigns their character to one of several vampire clanseach with unique powers, customizes their combat and dialog abilities and progresses through "Bloodlines" using violent and nonviolent methods. The selection of clan affects how the player is perceived in the game world, and which powers and abilities they possess; this opens up different avenues of exploration and methods of interacting with or manipulating other characters. The player is able to complete side missions away from the primary storyline by moving freely between the available hubs: Santa Monica, Hollywood, downtown Los Angeles, and Chinatown.

Troika's 32-member team began development of "Bloodlines" in November 2001, as an indirect sequel to the previous year's "". Troika used Valve Corporation's Source game engine, then in development, which was being used for Valve's own "Half-Life 2". The game's production was turbulent, as the design's scope exceeded the available resources, and the team were left without a producer for nearly a year until Activision appointed David Mullich to the role, where he found designs and levels unfinished or abandoned. After three years in development with no end in sight and running over budget, Activision set a strict deadline for completion, and "Bloodlines" was released incomplete in November 2004.

Released in competition with "Half-Life 2" and several other titles, "Bloodlines" sold fewer than 80,000 copies during its initial release, which was considered a poor performance. It divided critics at the time; although they praised the game's writing and scale of choice, they criticized its technical flaws. It was Troika Games' last production before its failure in early 2005, when it was unable to secure additional projects. The game has a cult following as a rarely replicated example of gameplay and narrative, and contemporary reception recognises it as a flawed masterpiece. Since its original release in 2004, "Bloodlines" received post-release support from fans, supplying unofficial fixes and re-adding unused content.

"Bloodlines" is an action role-playing video game optionally presented from the first- or third-person perspective. Before the game begins, players create a male or female vampire character by selecting a vampire clan and configuring available points in three areas—Attributes, Abilities and Disciplines (vampiric powers)—or by answering questions, which create a character for the player. The player can select one of seven vampire clans: the powerful Brujah, the decadent Toreador, the insane Malkavian, the aristocratic Ventrue, the monstrously-deformed Nosferatu, the blood-magic wielding Tremere, or the animalistic Gangrel.

The player builds their character by spending acquired points to increase their ratings in the three areas. The points spent on Attributes and Abilities combine to determine a player's success or effectiveness in performing tasks such as using firearms, brawling, and lock-picking; for example, determining how accurate or how far the player can shoot, or if they can hack a computer. Attributes are represented by physical (strength, dexterity, and stamina), social (charisma, manipulation, and appearance), and mental (perception, intelligence, and wits). Abilities are talents (such as brawling and dodging), skills (such as firearms and melee) and knowledges (such as computers and investigation). The player is initially assigned points to spend in the three areas, with the amount they can spend determined by clan; for example, the Brujah can spend the most points on physical and skill attributes. During character creation, each upgrade costs one point. The upgrade cost increases as the game progresses. Each ability can be raised from zero to five, and it is impossible to accrue enough experience points to complete every skill (allowing the player to specialize or balance their character). Experience points are gained by completing quests, finding items or unlocking secret paths, rather than killing enemies, and are used to increase or unlock the character's statistics and abilities. The game features a main story, and optional side quests that can be completed at any time; the player is able to move between the available areas at will to revisit locations, characters, or merchants.

The player's clan affects their skills and powers. Although the attractive Toreadors receive bonuses for seduction and persuasion, opening additional dialog options, they are physically weak; the Nosferatu are forced to travel in the shadows or through sewers to avoid alerting humans, but receive bonuses to their intelligence and computer skills, which enables access to more information. The Malkavians have separate dialog options, reflecting their inherent insanity. Upgrading some skills provides additional dialog options; attractive and charismatic characters seduce to get their way, aggressive characters threaten, and others persuade their targets to cooperate.
Firearms combat is first-person, with character points assigned to the firearms skill determining the shot's accuracy and how long it takes to target an opponent. Melee combat is third-person, with access to weapons such as katanas and sledgehammers for melee combat, or pistols, crossbows and flamethrowers for firearm combat. If a player sneaks up on an opponent, they can perform an instant kill; weapons provide unique instant kill animations. The player can block attacks manually or automatically, by leaving their character idle. They can use stealth in missions by sneaking past guards and security cameras, picking locks, and hacking computers to locate alternative routes.

Each clan has specific Disciplines, which can be used in combat and to create approaches to quests. Although some powers overlap clans, no two clans share the same three Disciplines. More physical vampires can enhance themselves to become fast and lethal killers or summon spirit allies to attack their foes; others can mentally dominate their targets to force their cooperation or render themselves invisible to hide from detection; and others can boil their opponent's blood from afar. Some Disciplines, such as Auspex (which boosts perception, highlighting other characters' auras through obstacles) and Blood Buff (which temporarily upgrades strength, dexterity, stamina and lockpicking), are common to all vampires. Several abilities can be active at the same time. Blood is a primary currency in "Bloodlines", used to activate Disciplines and abilities. It is drained with each use, and can be replenished by drinking from rats, visiting blood banks or drinking from humans by attacking or seducing them; the player can feed on enemies during combat. Drinking from innocents for too long can kill them, costing a character humanity points.

Players are penalized for using certain vampiric abilities in front of witnesses; exposing their existence loses masquerade points, although additional masquerade points can be earned with quests and other actions. Violating the masquerade five times draws the ire of vampire hunters and loses the game. The player has humanity points, representing the vampire's humanity. Some actions cost humanity points; a low humanity score alters available dialog options to become more aggressive, and increases the chance of entering a frenzied state and embarking on a killing spree, when the vampire's blood is low. This frenzy can also be triggered by a large amount of damage. Like masquerade points, losing all humanity points ends the game, with the vampire becoming a mindless beast. Some areas, known as Elysium, prevent the use of Disciplines or weapons. Players can recruit a female ghoul, Heather, as a customizable servant who gives them blood, gifts, and money.

"Vampire: The Masquerade – Bloodlines" takes place in four areas of 21st-century Los Angeles: Santa Monica, Hollywood, Downtown Los Angeles, and Chinatown. Set in the World of Darkness, the game depicts a world in which vampires, werewolves, demons, and other creatures shape human history. The vampires are bound by a code to maintain their secrecy (forbidding the use of vampiric abilities in front of humans) and avoid unnecessary killing (to preserve the vampire's last shreds of humanity). The vampires are divided into seven clans of the Camarilla, the vampire government, with distinctive traits and abilities. The Toreadors are the closest to humanity, with a passion for culture; the Ventrue are noble, powerful leaders; the Brujah are idealists who excel at fighting; the Malkavians are cursed with insanity, or blessed with insight; the Gangrel are loners, in sync with their animalistic nature; the secretive, untrustworthy Tremere wield blood magic; and the monstrous Nosferatu are condemned to a life in the shadows to avoid humanity. The clans are loosely united by their belief in the Camarilla's goals and opposition to the Sabbat: vampires who revel in their nature, embracing the beast within. The Anarchs are a faction of idealistic vampires opposed to the Camarilla's political structure, believing that power should be shared by all vampires.

The main character of "Bloodlines", whom the player controls, is an unnamed fledgling vampire, transformed at the start of a game and belonging to one of the clans. The fledgling is employed by Sebastian LaCroix (voiced by Andy Milder), prince of Los Angeles' vampires. The fledgling's travels through the vampire world bring them into contact with other undead creatures such as the deformed information broker Bertram Tung, the Anarch Smiling Jack, and the mentally-unstable Voerman sisters, Jeanette and Therese. Chinatown is controlled by the Kuei-Jin, Asian vampires led by Ming-Xiao, who do not require blood and consider themselves superior to the other vampires.

The game begins with the player character, an unnamed human, being killed and resurrected as a fledgling vampire. For this unauthorized act, the fledgling and their Sire are brought before the Camarilla. The Sire is executed by order of LaCroix; the fledgling is spared the same fate by the intervention of the Anarch, Nines Rodriguez, and employed by the prince.

LaCroix sends the fledgling to Santa Monica to help his ghoul, Mercurio, destroy a Sabbat warehouse. Following their success the fledgling travels to downtown Los Angeles, meeting separately with Nines, LaCroix, and Jack. LaCroix tasks the fledgling with investigating a docked ship, the "Elizabeth Dane", for information about an Ankaran sarcophagus rumored to contain the body of an Antediluvian, one of the oldest and most powerful vampires, whose arrival would herald the vampire apocalypse, Gehenna. The fledgling discovers that the sarcophagus seems to have been opened from within.

Increased Sabbat activity coincides with the disappearance of the Malkavian chief, Alistair Grout. At Grout's mansion, the fledgling sees Nines leaving and discovers Grout's remains in the mansion with vampire hunter Grunfeld Bach, who denies involvement in Grout's death. Learning about Nines' presence at the mansion, LaCroix tells the other chiefs to approve Nines' execution. The fledgling is sent to the Museum of Natural History to recover the sarcophagus, but finds that it has been stolen. Jack later suggests to the fledgling that LaCroix wants the sarcophagus to drink the blood of the ancient within, gaining its power.

Believing that Gary, the Nosferatu chief, has stolen the sarcophagus, the fledgling is sent to Hollywood to find him; after locating a captured Nosferatu for Gary, he reveals that the sarcophagus was stolen by the Giovanni vampire clan. The fledgling infiltrates the Giovanni mansion and finds the sarcophagus guarded by the Kuei-Jin, who claim their leader, Ming-Xiao, has formed an alliance with LaCroix. The locked sarcophagus is returned to LaCroix's tower and Beckett, a vampire scholar, tells the fledgling that the only person who can open it has been abducted by Grunfeld to lure LaCroix. The fledgling kills Grunfeld and learns that the sarcophagus' key has been stolen.

The fledgling returns to LaCroix, learning that the Sabbat tried to steal the sarcophagus to destroy it and prevent Gehenna, and kills the Sabbat leader to disperse his followers. The fledgling is met by Ming-Xiao, who offers to form an alliance. Ming-Xiao reveals that she has the key, and LaCroix killed Grout to prevent his powerful insight from unveiling LaCroix's plans; Ming-Xiao changed into Nines at the mansion to frame him. Denying Ming-Xiao's claims, LaCroix rescinds the blood hunt on Nines and entrusts the fledgling with recruiting the Anarchs to punish the Kuei-Jin for murdering Grout. The fledgling finds Nines hiding in Griffith Park, and they are then attacked by a werewolf and Nines is badly injured. The fledgling escapes with Jack, who reveals that LaCroix has issued an execution order on the fledgling for framing Nines on orders from Ming-Xiao.

The end varies, depending on whom, if anyone, the fledgling allies with. If the fledgling supports LaCroix or Ming-Xiao, each sends the fledgling to kill the other. LaCroix opens the sarcophagus, to be killed with the fledgling by hidden explosives; Ming-Xiao betrays the fledgling, chaining them to the sarcophagus and sinking it in the ocean. Supporting the Anarchs or no one makes the fledgling kill Ming-Xiao and maim LaCroix, who is killed after he opens the sarcophagus. If the fledgling opens the sarcophagus, they die in the explosion. If the fledgling is a Tremere, they kill Ming-Xiao; LaCroix is replaced by Tremere leader Maximillian Strauss, and the sarcophagus is stored. Each ending has Jack watching from afar with the mummy taken from the coffin and the enigmatic taxi driver who transports the fledgling between locations, who says, "The blood of Caine controls our fate ... Farewell, vampire."

The development of "Vampire: The Masquerade – Bloodlines" began at Troika Games in November 2001. The developers wanted to put a role-playing game in a first-person setting, believing that the genre had become stale. Troika approached publisher Activision with its idea; Activision suggested using the "Vampire: The Masquerade" license used a year earlier in Nihilistic Software's "", which had experienced sufficient success to merit a sequel. Instead of developing a sequel to "Redemption", the development team researched the White Wolf property, including the game's rules and its storylines. Troika was a small game studio, with five developers and a total staff of thirty-two (including lead writer Brian Mitsoda, who joined the team less than a year after development began). Although some preliminary design and levels were completed, much of the work was abandoned or redeveloped.

Troika wanted to make a 3D game, but was uncertain whether to build a new game engine or license an existing one and whether to use first- or third-person. At that time, the Source game engine was being built by Valve Corporation. Valve employee Scott Lynch approached Troika about using the engine, and it was the first external team to use it. Troika chose Source for its facial animation and lip-synching system, since it wanted players to speak to the characters face-to-face. Since the engine was in development with "Bloodlines" and Valve's own "Half-Life 2", Troika was working with unfamiliar code and tools, forcing it to write its own code to compensate for the unfinished engine, and with only a single source for technical support. Troika developed a lighting system to create distinctive, moody illumination for the nighttime setting, a particle system for the special effects accompanying the vampire Disciplines, and a cloth system for clothing flow. Source lacked its later artificial intelligence (AI) coding, and Troika's code worked poorly with the Source engine.

Many of the central plot elements existed before designer Brian Mitsoda's involvement: the prince, the anarchs being upset, aspects of the Gehenna storyline, and Jack and the sarcophagus as a major subplot. The designers broadly tied the overarching story into each hub and level. Each designer controlled their assigned section of the game, and working with a small team enabled quick decision making and ease in keeping plot elements consistent. Mitsoda became the primary writer for many of the characters and their quests, dialog, and side content in the game, such as emails, which helped retain a consistent narrative. He was given freedom with respect to the script, with no restrictions on language or content, and could rewrite characters when he thought his initial draft weak. Although the story was developed by Troika, it is inspired by White Wolf's "Time of Judgment" novels about a vampire apocalypse. "Bloodlines" story was accepted as canonical by White Wolf, with the game serving as a prequel to "Time of Judgment" and including characters from the White Wolf game, such as Jack. Discussing character design, Mitsoda said he tried to disguise the need for characters who simply point a player in an appropriate direction:

You need a character to pose a problem or give out a quest or be a barrier of some kind. I don't like to make the [character] outright say "I need you to do X, then I'll give you Y" ... – it makes the character into an automated quest kiosk. I like the characters to come off like people actually do – they don't say "hi" when strangers come knocking, they say "who the hell are you?" or they're expecting you and know more than they let on, or they don't care. I don't like my [characters] to be standing around as if their lives begin when the character starts talking to them and end when the player leaves.

Single-purpose characters needed a distinctive personality trait to quickly establish them with the player, rather than serving as a disposable item, while major characters had to reflect the player's progression and actions through the game. Mitsoda wrote the characters by thinking about who each character was, assigning them motivations determining why they were where they were, what they thought about the player and what they wanted from them. In accordance with a suggestion by fellow writer Chad Moore, the Malkavian player character has a dialog script distinct from that of the other eight clans; Mitsoda said it was one of the simpler aspects of the development cycle. He wrote the Malkavian script last, with time running out on development, and the overwork and lack of sleep contributed to what Mitsoda considered an unhealthy state of mind, ideal for writing insane dialog. He wanted to highlight their madness, without making it comical. Since the story is set during the Camarilla's takeover of Los Angeles, the team simplified the plot by only allowing the player to belong to one of the LA-based clans.

Troika co-founder Jason Anderson's research on "Vampire: The Masquerade" source material and fansites found that character interaction and involvement in the vampire societies, not statistics and powers, was the game's main attraction. Troika tried to remain true to the pen-and-paper role-playing game, hoping not to alienate the game's fans, but rules designed for multiple players did not translate well to single player computer game design. The team attempted to discover which elements could work equally well in pen-and-paper and computer games. Although much of the character system and attributes translated, not all the attributes (such as "knowledge of law") made sense in the computer game. Of 30 pen-and-paper abilities, 15 reached the final design.

Another difficult area was feats. Although common feats worked well, with a random chance of success or failure, uncommon ones would appear to fail more often. To avoid this, randomization was replaced by a degree of difficulty in accomplishing the feat. Although pen-and-paper falling damage is random, the computer game bases damage on the distance of the fall. The team's biggest challenge was adapting disciplines. The pen-and-paper version may require a little blood that requires a long time to use, or have no blood cost and can be used at will; upgraded disciplines had additional requirements considered too confusing for a computer game. Troika attempted to equalize the disciplines, keeping the effect intact and normalizing the cost, so a first-level power requires one blood point, a second-level two points and so on. To balance the clans, the aristocratic Ventrue were only allowed to feed on noble blood, though this was changed to allow them to feed on lower-class humans, receiving less blood. During character creation, the game had an optional character biography with unique positive and negative characteristics (increasing one ability while limiting another). This was removed from the released game; Activision felt that there was insufficient test time, and removing it was a more stable option.

The team's previous experience was with turn-based combat games, and it struggled to develop a real-time combat system affected by customizable attributes and abilities that provided feedback to the player on how those statistics were affecting the battle. It initially found that by adhering too closely to the White Wolf source material rules for guns, where the effectiveness of a shot is determined in a contest between the player's skill and the opponent's defense, the firearms seemed broken; the player would not hit where they aimed. Troika found it difficult to mesh the available factors in a real-time setting. Melee combat had to deal with a variety of melee weapons and animations and adjust for melee-on-melee and melee-on-ranged combat.

Troika used first-person perspective to immerse the player in the setting, interacting face-to-face with the characters and seeing their facial reactions to the player. It chose to follow a single-character to aid the immersion, creating the isolation of a vampire unable to trust any other character. This aided the story and compensated for the technical issues of allowing multiple player characters.

Choice is a significant aspect of the game, requiring a non-linear design to accommodate the customized characters. Level design began with a list of factors such as Disciplines, stealth and feats. Each area had to be viable for a shooting character (sufficient ammunition), a discipline-focused character (sufficient blood sources to keep the powers fueled) and a melee specialist (to reach enemies without being killed), with stealth options and option combinations. Level design began with a focus on stealth, taking into consideration the positioning of guards and the character's potential stealth capability at that point in the game. Then direct, combat-heavy and dialog paths were added. The amusement arcade area was to feature playable versions of Activision arcade games such as "Pitfall!", though the idea was abandoned due to time constraints.

Director Leonard Boyarsky considered the animation system important in the team's choice of the Source engine. The integrated "faceposer" tool allowed Troika to customize facial animations, expressions, gestures and lip-synching, eliminating the need to explain what a character was doing. Every non-player character required a voiceover, which helped Troika define its characters more quickly. The engine had a physics system permitting new features, such as monsters hurling corpses at the player or dying characters realistically crumbling into pieces, instead of requiring pre-built animations. Although Troika had ignored first-person engines due to technical limitations, such as a low polygon count and limited texture memory, as the technology improved, it thought it could create a real-time action game without sacrificing the immersion and story of a role-playing game.

Describing the choice of developing a game based on the existing White Wolf property over creating their own, Boyarsky said that although an original property lacked the constraints of an existing one, the downside was that it had not been tested and could be rejected by its potential audience; an existing property was proven. Troika tried to stay as close as possible to the White Wolf rules, while reducing the number of abilities and disciplines to those relevant to "Bloodlines" gameplay.

Activision introduced the game in May 2003, but in October, Valve experienced a security breach in which hackers stole the source code for "Half-Life 2". The breach required new security implementations for the engine, delaying both games; the release of "Bloodlines" was postponed until early 2005. Until May 2004, Troika and Activision said that the game would feature a multiplayer component and modes including a team of vampires against a team of vampire hunters, with the ability to upgrade characters between each round. The team was left without a producer by Activision for over a year before David Mullich was assigned to the project. With no producer oversight, Mullich found the game's design incomplete, game levels created and abandoned, and several technical issues, including problems with code for the proposed multiplayer option. The Source multiplayer code was in its infancy, increasing its development time, and the idea was abandoned.

In addition to problems with the Source engine, the designers found that the game's scope exceeded their resources. "Bloodlines" has several styles of gameplay, requiring different interfaces, animations and artificial intelligence for stealth and melee combat, and first- or third-person capability. Compared to contemporary first-person shooters, with 10 to 20 animated character models, "Bloodlines" had over 150 characters with 3,000 unique animations, in addition to boss characters, with their own styles of movement. The designers underestimated the length of time required to develop and improve these systems. The game's scope suffered from content not being removed when necessary; other components would be endlessly refined without being finalized, preventing the developers from focusing on other parts of the game system. All content additionally required approval by White Wolf and Activision.

After three years in development, the game was progressing slowly, and it was unknown when it would be finished. Activision set a series of deadlines for the project's development to ensure Troika would have sufficient time to effectively test the game, though these milestones were repeatedly extended, and "Bloodlines" eventually ran over budget. In 2003 Activision intervened, ordering that the game be ready for release in the next few months, and even advancing more money to Troika to complete its work on "The Temple of Elemental Evil" for Atari, freeing the Troika team to work on "Bloodlines" exclusively. Activision eventually issued an ultimatum that the project be finished within months, on September 15, 2004. Troika delivered a version of "Bloodlines" on the required date; due to its scale, the game underwent three weeks of testing. Activision decided that the game was suitable for release, but was contractually bound to withhold "Bloodlines" until after the debut of "Half-Life 2" in November 2004. Troika convinced Activision to use the delay to fund further development; the additional budget was not enough to pay all of Troika's staff, and some employees worked unpaid to complete the project. This version underwent another three weeks of testing to become the final release code; the game was still unfinished when Activision forced its release. "Bloodlines" creative director Jason Anderson blamed Activision, saying that the publisher took the game from Troika without providing enough time to test and polish it. Conversely, Boyarsky defended Activision for supporting Troika as the project exceeded its budget and schedule. During the nearly four years of development, Anderson estimated that the team worked overtime for all but two months.

The game's original score was composed and produced by Rik Schaffer. Troika licensed many songs for the game, and posters for real bands are featured on the walls of the game's clubs. The soundtrack was released as a limited edition CD to customers who pre-ordered the game through Best Buy. It features nine tracks by artists including Daniel Ash, Chiasm, Tiamat, Darling Violetta, Genitorturers, and Lacuna Coil. "Bloodlines", performed by Al Jourgensen and Ministry, was composed and performed specifically for the game. The licensed tracks were chosen by Activision without input from Troika. The song "Angel" by Massive Attack was used as a placeholder on the game's menu screen. Troika was unable to obtain the rights to use the song in the finished game, and tasked Schaffer with creating something similar.

"Vampire: The Masquerade – Bloodlines" was released on November 16, 2004 in competition with "Half-Life 2", "", "Halo 2", and several other titles. Valve's contract for Troika's use of the Source engine guaranteed that "Bloodlines" could not be released before "Half-Life 2", and could not be introduced to the public until after the announcement of "Half-Life 2", over eighteen months after development began. In February 2004, the game was scheduled for release in spring 2005, partially to avoid competing with "Half-Life 2" and the competitive Christmas period, before Activision moved the date to November 2004. Activision obtained model Erin Layne to play Jeanette in promotional material for the game. Layne worked with "Bloodlines" artist Tim Bradstreet for a day to provide the poses chosen by Activision to represent Jeanette in the game's posters, clothing, and other items.

Despite generally favorable reviews, "Bloodlines" initial release sold 72,000 copies and earned approximately $3.4 million in sales, below Troika's other games, "" (234,000 units, $8.8 million) and " The Temple of Elemental Evil" (128,000 units, $5.2 million). In comparison, "Bloodlines" release competitor "Half-Life 2" had sold 6.5 million copies by 2008. "Bloodlines‍" relative failure contributed to the demise of Troika Games.

Shortly after its debut, most of the development staff were laid off; the remaining staff tried to patch "Bloodlines" and develop game concepts to secure funding to keep Troika in business. Troika, unable to obtain further funding from Activision or other publishers, released its employees in two waves: the first in November 2004, followed by the remaining staff in December, except for its three founders Anderson, Boyarsky, and Tim Cain. Some employees worked without pay to fix the game. When the company closed in February 2005, it had secured no other game development deals. That month, Boyarsky confirmed that Troika had not been working on a patch for the game since most of its staff were gone since December 2004.

In a 2006 interview, Anderson said that although Troika Games' library had been critically well received, consistent technical issues had marred the perception of the company's games, contributing to Troika's difficulty in obtaining new projects. In 2013, Mitsoda said that "Bloodlines" was released at "the worst possible time - most people didn't even know we were out ... fans and the Troika [developers] are always going to wonder what the game could have been like with another six months." In a 2017 interview, Boyarksy echoed Mitsoda's sentiments, saying that a further three to six months of development time could have allowed Troika to address many technical flaws, but he was unsure that they could have resolved larger issues. He said "I feel the second half of the game isn't as good as the first. I feel like we devolved into relying too much on combat at the end." Boyarsky noted that it was impossible to know if the fixes would have made "Bloodlines" more successful, or if it would have remained a niche product. He said "it might have been too early for people to appreciate it, but we'll never know." The game fared better following its release on Valve's Steam digital distribution service in March 2007, where, as of 2015, it has sold 492,000 copies.

Unofficial patches have been created by the game's fans to address "Bloodlines" technical problems, and restore missing and incomplete content. After experiencing problems with the first versions of an unofficial patch created by Dan Upright, analytical chemist Werner Spahl continued patching the game from version 1.2 with permission and instructions. The game community tested Spahl's patches, providing reports on bugs and spelling errors. Although the game's complexity meant that repairing one aspect often broke another, as work on the patches progressed Spahl began restoring removed and incomplete content in the game files, adding quests, items, weapons, and characters, with fan help to provide voice acting, models, and reinstating whole levels. Spahl contacted former Troika staff for insight into their intentions for cut content. A library area, for example, was restored after Mitsoda told Spahl only that "it was somehow connected to a main character and a Sabbat boss, and was meant to look like the real-world [Los Angeles] library." A fan traveled to the real library to gather notes on its layout, and co-developed the in-game area with Spahl. Schaffer also provided Spahl with unreleased scores from the game. The changes altered the original game so much that Spahl was criticized by some of the game's fans. This resulted in two patch versions: a basic version, fixing the game's technical issues, and a "plus" version with the additional content. As of 2016, the game has over 10 years of post-release support with the release of versions 9.x of the patch, which are also included in the version of the game sold on the GOG.com distribution service.

Boyarsky voiced his support for unofficial patches, saying "they've found the stuff that we hoped people would find about the game, in terms of the different paths you can take and how it played differently for every class." Boyarsky said that while he would have preferred that the game was more successful at launch, that people were still playing and modifying it made Troika's efforts feel more "worthwhile".

"Vampire: The Masquerade – Bloodlines" received a mixed response, with reviewers praising its writing and presentation and criticizing its technical problems. The aggregating review website Metacritic provides a score of 80 out of 100 (based on 61 reviews).

The game has been called a flawed masterpiece by critics. The scale and variety of choice and effect was highlighted by reviewers as "Bloodlines" greatest success, including the variety of clans, with specific dialog options, and the specific reactions from other characters, each with their own clan loyalty and bias. GameSpy called it a nearly flawless classic role-playing game; "The New York Times" described it as brilliant but unfinished. Eurogamer praised its "effortlessly intelligent" script, saying that "no other game has come close. Nothing's even tried". VideoGamer.com opined that at its best, "Bloodlines" stands among the greatest RPGs of the preceding five years, although its technical problems should be remembered. According to HonestGamers, the game "may not be polished and may end with a sigh instead of a shout, but for its ambition alone it deserves stream after stream of compliments." Reviewers compared it to other successful role-playing games, including "Fallout", "", "", "", "", and "Deus Ex"; Eurogamer described "Bloodlines" as "Deus Ex" with vampires.

IGN appreciated "Bloodlines" rewarding exploration outside the main story, and the "New York Times" and GameSpy praised its "wonderfully imaginative" missions. Reviewers noted that later parts of the game were disappointing, delivering repetitive combat-focused missions with regenerating enemies, abandoning dialog and stealth and punishing players who build characters with more social skills than combat abilities. GameSpy said that it had never seen a role-playing game so affected by player actions with everything, from clan choice and character build to actions in missions, influencing future options and dialog.

Its writing was consistently praised by reviewers. The narrative was considered deep, successfully using White Wolf's "Vampire: The Masquerade" content. Eurogamer said that it had the best script the website had ever seen in a video game, and others described it as a superbly crafted tale of conspiracies, underworld subterfuge, fun and intrigue. Reviewers appreciated the use of adult themes, such as sex and death, in the storyline of a contemporary video game, which no other games had tackled with similar effectiveness. The mature themes succeeded without being gratuitous or exploitative, and were explored honestly and intelligently by a knowledgeable writer. The game's characters were praised for their memorable, developed personalities, with most major characters possessing their own backstory and presented as living people instead of ciphers. Its ending had a mixed response, with some reviewers appreciating their ability to choose one of the game's four endings (adding an incentive to replay the game) and others considering the ending anti-climatic.

GameSpot and GameSpy called the dialog sharply written, with many memorable lines. Eurogamer noted that the characters' frequent use of vulgar language worked; written as real people, such language fit their character rather than giving the game an adult veneer. The website appreciated the breadth of dialog options, allowing the player greater control of how to play their character. "PC Zone" opined that the quantity of well-written dialog did not guarantee quality; many player choices seemed to have little effect on a conversation's outcome, and the best response was often the most obvious. The voice acting was repeatedly praised for the actors' quality and the amount of voice work, due to the many dialog options.

Much of "Bloodlines" criticism focused on technical problems when it was released, undermining the game experience or making it unplayable. Several reviewers noted errors which closed the game and typographical errors in on-screen text. Others cited frequent, sometimes-lengthy load times encountered while moving between hubs and entering or exiting buildings and areas. GameSpot called the game's artificial intelligence poor, often causing enemies to rush at an armed player, fire at them from too great a distance to be effective or become immobilized while waiting for the player's next attack. IGN noted that stealth broke the AI, allowing traps to be triggered and leaving the assailants standing still, unable to locate a hidden player. GameSpy said that the Source engine was "Bloodlines" greatest weakness; although the RPG aspects were the game's strong suit, features of the Source engine, such as first-person shooting, were where it stumbled.

Combat was also criticized. Reviewers called it poor, clumsy, and unsatisfactory, complaining that "Bloodlines" favors melee combat; firearms were weak, unwieldy and slow, even for characters specializing in guns. "PC Zone", however, called the first-person shooting entertaining and challenging. Although melee combat was criticized as sluggish and difficult due to enemy attacks interrupting the player's, reviewers considered it overpowered; according to GameSpot, a boss character was killed with melee weapons on a first attempt after the repeated failure to do so with a gun. The "New York Times" found the unavoidable combat in the last part of the game to be so difficult that they had to cheat to succeed. Stealth was criticized, with IGN noting that even with low stealth skill it was possible to sneak around many enemies and feed from a guard without alerting another guard next to them. GameSpot opined that some of the best missions were stealth-based, as combat was more straightforward.

In 2004, IGN named "Bloodlines" the Best PC RPG of that year and GameSpy called the "Ocean House Hotel" quest the Level of the Year. In 2005, "Computer Gaming World" called it the Role Playing Game of 2004, saying that it offered "a deep, balanced character creation system, a truckload of interesting quests, a good story and great NPCs to interact with." "Computer Games Magazine" nominated "Bloodlines" for its 2004 "Best Writing" award, which ultimately went to "Half-Life 2".

"Bloodlines" is considered a cult classic. Retrospective critiques continue to praise the game's narrative and degree of choice. In 2009, an article in Rock, Paper, Shotgun declared: "The sense of sorrow comes from the realisation that there's nothing like ["Bloodlines"] on the horizon ... why should there be so few games like this? Oh right, because it's so very hard to do ... the lack of games comparable to "Bloodlines" is one of the great tragedies of our time." "Eurogamer" called the game inspirational, with an unmatched level of narrative detail. In 2010, "The Escapist" called "Bloodlines" a flawed masterpiece which could have been a genuine masterpiece with more time, money and staff; although great games may inspire awe, it instead created a devoted fan base which continued to develop the game.

In 2006, "PC Zone" listed "Bloodlines" the seventh-best PC game which people were unlikely to have played, calling it the "best buggy game ever released". In 2007, the game was 80th on "Computer & Video Games" list of its top 100 games, and 86th on "PC Gamer"s 2014 list of the same; it also appeared in "PC Gamer"s 2015 edition (moving to 63rd), and the 2017 edition (moving to 42nd). In 2008, bit-tech listed Jeanette as the second-best non-player video game character. In 2011, Rock, Paper, Shotgun called "Bloodlines" one of the most important PC games of all time ("it signposts a direction to a future of games that we were denied"), listing it as one of the 122 Best PC Games Ever. Cinema Blend called it one of the most underappreciated games of the decade. In 2011, "Official Xbox Magazine" called it one of the ten PC franchises it wanted on the Xbox 360 console. In 2013, "PC Gamer" named it one of the 100 Best Horror Games on PC, and PCGamesN called it the seventh-best PC role-playing game. In 2014, "Bloodlines" was 90th in "Empire"s readers' poll of the 100 Greatest Video Games of All Time, and "Maximum PC" chose it as one of the games they wanted to be remastered for contemporary game systems. In 2015, Rock, Paper, Shotgun listed "Bloodlines" as the PC's 19th Best RPG and 15th Best Horror Game. In 2017, the game was listed 42nd on IGN's list of the Top 100 RPGs of all Time, "Den of Geek" named it one of the 20 Video Games that Deserve Remakes, and "PC Gamer" named it one of the best role playing games of all time.

In a November 2004 interview Boyarsky said that although the team would like to pursue a "Bloodlines" sequel, the decision was Activision's. Before their closure, Troika had begun development of a workable prototype based on White Wolf's other role-playing game, "", set in the same universe as "Vampire: The Masquerade". According to Boyarsky, the prototype was one small area built using assets taken from "Bloodlines", and allowed the player to play as a Werewolf, or a human capable of turning into one.

Paradox Interactive obtained the rights to "Bloodlines" in 2015, following their purchase of White Wolf. Paradox CEO Fredrik Wester confirmed that a sequel was possible, stating "when the time is right I guess a sequel will find its place in the market."



</doc>
<doc id="948631" url="https://en.wikipedia.org/wiki?curid=948631" title="Rainbow trout">
Rainbow trout

The rainbow trout ("Oncorhynchus mykiss") is a trout and species of salmonid native to cold-water tributaries of the Pacific Ocean in Asia and North America. The steelhead (sometimes called "steelhead trout") is an anadromous (sea-run) form of the coastal rainbow trout or Columbia River redband trout that usually returns to fresh water to spawn after living two to three years in the ocean. Freshwater forms that have been introduced into the Great Lakes and migrate into tributaries to spawn are also called steelhead.

Adult freshwater stream rainbow trout average between , while lake-dwelling and anadromous forms may reach . Coloration varies widely based on subspecies, forms and habitat. Adult fish are distinguished by a broad reddish stripe along the lateral line, from gills to the tail, which is most vivid in breeding males.

Wild-caught and hatchery-reared forms of this species have been transplanted and introduced for food or sport in at least 45 countries and every continent except Antarctica. Introductions to locations outside their native range in the United States (U.S.), Southern Europe, Australia, New Zealand and South America have damaged native fish species. Introduced populations may affect native species by preying on them, out-competing them, transmitting contagious diseases (such as whirling disease), or hybridizing with closely related species and subspecies, thus reducing genetic purity. The rainbow trout is included in the list of the top 100 globally invasive species. Nonetheless, other introductions into waters previously devoid of any fish species or with severely depleted stocks of native fish have created sport fisheries such as the Great Lakes and Wyoming's Firehole River.

Some local populations of specific subspecies, or in the case of steelhead, distinct population segments, are listed as either threatened or endangered under the Endangered Species Act. The steelhead is the official state fish of Washington.

The scientific name of the rainbow trout is . The species was originally named by German naturalist and taxonomist Johann Julius Walbaum in 1792 based on type specimens from the Kamchatka Peninsula in Siberia. Walbaum's original species name, "mykiss", was derived from the local Kamchatkan name used for the fish, "mykizha". The name of the genus is from the Greek "onkos" ("hook") and "rynchos" ("nose"), in reference to the hooked jaws of males in the mating season (the "kype").

Sir John Richardson, a Scottish naturalist, named a specimen of this species in 1836 to honor Meredith Gairdner, a Hudson's Bay Company surgeon at Fort Vancouver on the Columbia River who provided Richardson with specimens. In 1855, William P. Gibbons, the curator of Geology and Mineralogy at the California Academy of Sciences, found a population and named it (Latin: rainbow), later corrected to . These names faded once it was determined that Walbaum's description of type specimens was conspecific and therefore had precedence. In 1989, morphological and genetic studies indicated that trout of the Pacific basin were genetically closer to Pacific salmon ("Oncorhynchus" species) than to the "Salmos" – brown trout or Atlantic salmon of the Atlantic basin. Thus, in 1989, taxonomic authorities moved the rainbow, cutthroat and other Pacific basin trout into the genus "Oncorhynchus". Walbaum's name had precedence, so the species name became the scientific name of the rainbow trout. The previous species names "irideus" and "gairdneri" were adopted as subspecies names for the coastal rainbow and Columbia River redband trout, respectively. Anadromous forms of the coastal rainbow trout or redband trout are commonly known as steelhead.

Subspecies of are listed below as described by fisheries biologist Robert J. Behnke (2002).
Resident freshwater rainbow trout adults average between in riverine environments, while lake-dwelling and anadromous forms may reach . Coloration varies widely between regions and subspecies. Adult freshwater forms are generally blue-green or olive green with heavy black spotting over the length of the body. Adult fish have a broad reddish stripe along the lateral line, from gills to the tail, which is most pronounced in breeding males. The caudal fin is squarish and only mildly forked. Lake-dwelling and anadromous forms are usually more silvery in color with the reddish stripe almost completely gone. Juvenile rainbow trout display parr marks (dark vertical bars) typical of most salmonid juveniles. In some redband and golden trout forms parr marks are typically retained into adulthood. Some coastal rainbow trout and Columbia River redband trout populations and cutbow hybrids may also display reddish or pink throat markings similar to cutthroat trout. In many regions, hatchery-bred trout can be distinguished from native trout via fin clips. Fin clipping the adipose fin is a management tool used to identify hatchery-reared fish.

Rainbow trout, including steelhead forms, generally spawn in early to late spring (January to June in the Northern Hemisphere and September to November in the Southern Hemisphere) when water temperatures reach at least . The maximum recorded lifespan for a rainbow trout is 11 years.

Freshwater resident rainbow trout usually inhabit and spawn in small to moderately large, well oxygenated, shallow rivers with gravel bottoms. They are native to the alluvial or freestone streams that are typical tributaries of the Pacific basin, but introduced rainbow trout have established wild, self-sustaining populations in other river types such as bedrock and spring creeks. Lake resident rainbow trout are usually found in moderately deep, cool lakes with adequate shallows and vegetation to support production of sufficient food sources. Lake populations generally require access to gravelly bottomed streams to be self-sustaining.

Spawning sites are usually a bed of fine gravel in a riffle above a pool. A female trout clears a redd in the gravel by turning on her side and beating her tail up and down. Female rainbow trout usually produce 2000 to 3000 eggs per kilogram of weight. During spawning, the eggs fall into spaces between the gravel, and immediately the female begins digging at the upstream edge of the nest, covering the eggs with the displaced gravel. As eggs are released by the female, a male moves alongside and deposits milt (sperm) over the eggs to fertilize them. The eggs usually hatch in about four to seven weeks although the time of hatching varies greatly with region and habitat. Newly hatched trout are called sac fry or alevin. In approximately two weeks, the yolk sac is completely consumed and fry commence feeding mainly on zooplankton. The growth rate of rainbow trout is variable with area, habitat, life history and quality and quantity of food. As fry grow, they begin to develop "parr" marks or dark vertical bars on their sides. In this juvenile stage, immature trout are often called "parr" because of the marks. These small juvenile trout are sometimes called fingerlings because they are approximately the size of a human finger. In streams where rainbow trout are stocked for sport fishing but no natural reproduction occurs, some of the stocked trout may survive and grow or "carryover" for several seasons before they are caught or perish.

The oceangoing (anadromous) form, including those returning for spawning, are known as steelhead in Canada and the U.S. In Tasmania they are commercially propagated in sea cages and are known as ocean trout, although they are the same species.

Like salmon, steelhead return to their original hatching grounds to spawn. Similar to Atlantic salmon, but unlike their Pacific "Oncorhynchus" salmonid kin, steelhead are iteroparous (able to spawn several times, each time separated by months) and make several spawning trips between fresh and salt water, although fewer than 10 percent of native spawning adults survive from one spawning to another. The survival rate for introduced populations in the Great Lakes is as high as 70 percent. As young steelhead transition from freshwater to saltwater, a process called "smoltification" occurs where the trout undergoes physiological changes to allow it to survive in sea water. There are genetic differences between freshwater and steelhead populations that may account for the smoltification in steelheads.

Juvenile steelhead may remain in the river for one to three years before smolting and migrating to sea. Individual steelhead populations leave the ocean and migrate into their freshwater spawning tributaries at different times of the year. Two general forms exist—"summer-run steelhead" and "winter-run steelhead". Summer-run fish leave the ocean between May and October, before their reproductive organs are fully mature. They mature in fresh water while en route to spawning grounds where they spawn in the spring. Summer-run fish generally spawn in longer, more inland rivers such as the Columbia River. Winter-run fish are ready to spawn when they leave the ocean, typically between November and April, and spawn shortly after returning to fresh water. Winter-run fish generally spawn in shorter, coastal rivers typically found along the Olympic Peninsula and British Columbia coastline, and summer-run fish are found in some shorter, coastal streams. Once steelhead enter riverine systems and reach suitable spawning grounds, they spawn just like resident freshwater rainbow trout.
Rainbow trout are predators with a varied diet and will eat nearly anything they can capture. They are not as piscivorous or aggressive as brown trout or chars. Rainbow trout, including juvenile steelhead in fresh water, routinely feed on larval, pupal and adult forms of aquatic insects (typically caddisflies, stoneflies, mayflies and aquatic diptera). They also eat fish eggs and adult forms of terrestrial insects (typically ants, beetles, grasshoppers and crickets) that fall into the water. Other prey include small fish up to one-third of their length, crayfish, shrimp, and other crustaceans. As rainbow trout grow, the proportion of fish consumed increases in most populations. Some lake-dwelling forms may become planktonic feeders. In rivers and streams populated with other salmonid species, rainbow trout eat varied fish eggs, including those of salmon, brown and cutthroat trout, mountain whitefish and the eggs of other rainbow trout. Rainbows also consume decomposing flesh from carcasses of other fish. Adult steelhead in the ocean feed primarily on other fish, squid and amphipods.

The native range of is in the coastal waters and tributary streams of the Pacific basin, from the Kamchatka Peninsula in Russia, east along the Aleutian Islands, throughout southwest Alaska, the Pacific coast of British Columbia and southeast Alaska, and south along the west coast of the U.S. to northern Mexico. It is claimed that the Mexican forms of represent the southernmost native range of any trout or salmon ("Salmonidae"), though the Formosan landlocked salmon () in Asia inhabits a similar latitude. The range of coastal rainbow trout extends north from the Pacific basin into tributaries of the Bering Sea in northwest Alaska, while forms of the Columbia River redband trout extend east into the upper Mackenzie River and Peace River watersheds in British Columbia and Alberta, Canada, which eventually drain into the Beaufort Sea, part of the Arctic Ocean. Since 1875, the rainbow trout has been widely introduced into suitable lacustrine and riverine environments throughout the United States and around the world. Many of these introductions have established wild, self-sustaining populations.

Since 1870, rainbow trout have been artificially propagated in fish hatcheries to restock streams and to introduce them into non-native waters. The first rainbow trout hatchery was established on San Leandro Creek, a tributary of San Francisco Bay, in 1870, and trout production began in 1871. The hatchery was stocked with the locally native rainbow trout, and likely steelhead of the coastal rainbow trout subspecies . The fish raised in this hatchery were shipped to hatcheries out of state for the first time in 1875, to Caledonia, New York, and then in 1876 to Northville, Michigan. In 1877, another California rainbow trout hatchery, the first federal fish hatchery in the National Fish Hatchery System, was established on Campbell Creek, a McCloud River tributary. The McCloud River hatchery indiscriminately mixed coastal rainbow trout eggs with the eggs of local McCloud River redband trout . Eggs from the McCloud hatchery were also provided to the San Leandro hatchery, thus making the origin and genetic history of hatchery-bred rainbow trout somewhat diverse and complex. In the U.S., there are hundreds of hatcheries operated by the U.S. Fish and Wildlife Service and various state agencies and tribal governments propagating rainbow trout for conservation and recreational sport fishing. Six of ten Canadian provinces have rainbow trout farms, with Ontario leading production.

Rainbow trout are commercially farmed in many countries throughout the world. The practice began in the late 19th century, and since the 1950s commercial production has grown dramatically. Worldwide, in 2007, of farmed rainbow trout were harvested with a value of about US $2.6 billion. The largest producer is Chile. In Chile and Norway, sea cage production of steelhead has expanded to supply export markets. Inland production of rainbow trout to supply domestic markets has increased in countries such as Italy, France, Germany, Denmark and Spain. Other significant trout-producing countries include the U.S., Iran, the United Kingdom, and Lesotho. While the U.S. rainbow trout industry as a whole is viewed as ecologically responsible, trout raised elsewhere are not necessarily farmed with the same methods.

About three-quarters of U.S. production comes from Idaho, particularly the Snake River area, due in part to the quality and temperature of the water available there. California and Washington also produce significant numbers of farmed trout. In the east, Pennsylvania, North Carolina and West Virginia have farming operations. Rainbow trout farming is one of the largest finfish aquaculture industries in the U.S. They are raised inland in facilities where raceways or ponds have continuously flowing water with little pollution and a low risk of escape. The U.S. industry is noted for using best management practices. Imports constitute only about 15 percent of farmed rainbows sold in the U.S., and nearly all domestic production is consumed within the country; very little is exported. The U.S. produces about 7 percent of the world's farmed trout. Rainbow trout, especially those raised in farms and hatcheries, are susceptible to enteric redmouth disease. A considerable amount of research has been conducted on redmouth disease, given its serious implications for rainbow trout farming. The disease does not infect humans.

Populations of many rainbow trout subspecies, including anadromous forms (steelhead) of (coastal rainbow trout) and (Columbia River redband trout) have declined in their native ranges due to over-harvest, habitat loss, disease, invasive species, pollution and hybridization with other subspecies, and some introduced populations, once healthy, have declined for the same reasons. As a consequence, some rainbow populations, particularly anadromous forms within their native range, have been classified as endangered, threatened or species of special concern by federal or state agencies. Rainbow trout, and subspecies thereof, are currently a U.S. Environmental Protection Agency-approved indicator species for acute fresh water toxicity testing.

Many non-profit organizations have formed to protect, conserve and restore native rainbow trout and steelhead populations. Generally, in partnership with various universities, state, federal and tribal agencies and private interests, these organizations sponsor projects to restore habitat, prevent habitat loss and promote awareness of threats to native trout populations. 
Trout Unlimited (TU) is a non-profit organization dedicated to the conservation of North American freshwater streams, rivers, and associated upland habitats for trout, salmon, other aquatic species and people. A typical TU project is the Circle Creek Fish Passage Project, in which access to a spawning stream is being improved for steelhead and other salmonid species. The Wild Salmon Center, an international coalition of Russian, Canadian and U.S. scientists, sponsors the Kamchatka Steelhead Project, a 20-year (1994–2014) scientific program to study and conserve the present condition of Kamchatkan steelhead ("mikizha"), a species listed in the "Red Data Book of Russia". Other high-profile organizations involved in rainbow trout conservation include California Trout, which protects wild trout and other salmonids in the waters of California. The Steelhead Society of British Columbia promotes the wellbeing of wild salmonids in British Columbia. In 1997, a group of approximately 40 ichthyologists, biologists and naturalists from several U.S. and Mexican institutions formed a collaborative group—Truchas Mexicanas—to study the diversity of Mexican native trout, most of which are considered subspecies of .

Rainbow trout, primarily hatchery-raised fish of the coastal rainbow trout subspecies introduced into waters inhabited with cutthroat trout, will breed with cutthroats and produce fertile hybrids called cutbows. In the case of the westslope cutthroat trout ("O. clarki lewisi"), hybridization with introduced rainbow and Yellowstone cutthroat trout ("O. clarki bouvieri") is threatening the westslope cutthroat trout with genomic extinction. Such introductions into the ranges of redband trout have severely reduced the range of pure stocks of these subspecies, making them "species of concern" in their respective ranges.

Within the range of the Kern River golden trout of Southern California, hatchery-bred rainbows introduced into the Kern River have diluted the genetic purity of the Kern River rainbow trout and golden trout through intraspecific breeding. The Beardslee trout, , a genetically unique lake-dwelling variety of the coastal rainbow trout that is isolated in Lake Crescent (Washington), is threatened by the loss of its only spawning grounds in the Lyre River to siltation and other types of habitat degradation.

 is a myxosporean parasite of salmonids (salmon, trout, and their allies) that causes whirling disease in pen farmed salmon and trout and also in wild fish populations. It was first described in rainbow trout introduced to Germany a century ago, but its range has spread and it has appeared in most of Europe, northern Asia, the U.S., South Africa and other countries. In the 1980s, was found to require "Tubifex tubifex" (a kind of segmented worm) to complete its life cycle. The parasite infects its hosts with its cells after piercing them with polar filaments ejected from nematocyst-like capsules.

This parasite was originally a mild pathogen of brown trout in central Europe and other salmonids in northeast Asia, and the spread of the rainbow trout has greatly increased its impact. Having no innate immunity to , rainbow trout are particularly susceptible, and can release so many spores that even more resistant species in the same area, such as , can become overloaded with parasites and incur mortalities of 80 to 90 percent. Where has become well-established, it has caused decline or even elimination of whole cohorts of fish.

The parasite was first recorded in North America in 1956 in Pennsylvania, but until the 1990s whirling disease was considered a manageable problem only affecting rainbow trout in hatcheries. It eventually became established in natural waters of the Rocky Mountain states (Colorado, Wyoming, Utah, Montana, Idaho, New Mexico), where it is damaging several sport fishing rivers. Some streams in the western U.S. lost 90 percent of their trout. Whirling disease threatens recreational fishing, which is important for the tourism industry, a key component of the economies of some U.S. western states. For example, in 2005 anglers in Montana spent approximately $196,000,000 in activities directly related to trout fishing in the state. Some of the salmonids that infects (bull trout, cutthroat trout, and anadromous forms of rainbow trout—steelhead) are already threatened or endangered, and the parasite could worsen their population decline.

The New Zealand mud snail , once endemic to New Zealand, has spread widely and has become naturalised and an invasive species in many areas including Australia, Tasmania, Asia (Japan, in the Garmat Ali River in Iraq since 2008), Europe (since 1859 in England), and North America (U.S. and Canada: Thunder Bay in Ontario since 2001, British Columbia since July 2007), most likely inadvertently during human activity. It can reach concentrations greater than , endangering the food chain by outcompeting native snails and water insects for food, leading to sharp declines in native populations. There is evidence North American fishes are unable to digest the tiny but hard shells of the mud snail, and that their presence may result in poor growth outcomes for rainbow trout.

The mud snail was first detected in the U.S. in Idaho's Snake River in 1987. Since then, the snail has spread to the Madison River, Firehole River, and other watercourses around Yellowstone National Park, and has been discovered throughout the western U.S. The exact means of transmission is unknown, but it is likely that it was introduced in water transferred with live game fish and has been spread by ship ballast or contaminated recreational equipment such as wading gear.

, commonly known as didymo or rock snot, is a species of diatom that produces nuisance growths in freshwater rivers and streams with consistently cold water temperatures. In New Zealand, invasive didymo can form large mats on the bottom of rivers and streams in late winter. It is not considered a significant human health risk, but it can affect stream habitats and sources of food for fish, including rainbow trout, and make recreational activities unpleasant. Even though it is native in North America, it is considered a nuisance organism or invasive species.

Enteric redmouth disease is a bacterial infection of freshwater and marine fish caused by the pathogen . It is primarily found in rainbow trout and other cultured salmonids. The disease is characterized by subcutaneous hemorrhaging of the mouth, fins, and eyes. It is most commonly seen in fish farms with poor water quality. Redmouth disease was first discovered in Idaho rainbow trout in the 1950s.

Some fisheries are focused on removing rainbow trout in order to reestablish native trout populations. This can be done by poisoning rivers with chemicals such as antimycin or rotenone which have been declared safe in the USA by the Environmental Protection Agency. Once the chemicals have dissipated, native trout are released into the river. Another method is to use electrofishing which enable the fish to be caught alive and harvested or re-located. This technique has been used in the Great Smokey Mountains National Park to rid it of rainbow trout that were introduced in the 1930s and have thrived ever since. They are hoping to re-establish native brook trout in at least some of the 2100-mile river system. Neither method of control is 100% effective and are best regarded as methods to change the relative population sizes of fish species.

Steelhead populations in parts of its native range have declined due to a variety of human and natural causes. While populations in Alaska and along the British Columbia coast are considered healthy, populations in Kamchatka and some populations along the U.S. west coast are in decline.
The U.S. National Marine Fisheries Service has 15 identified distinct population segments (DPS)s, in Washington, Oregon, and California. Eleven of these DPSs are listed under the U.S. Endangered Species Act, ten as threatened and one as endangered. One DPS on the Oregon Coast is designated a U.S. Species of Concern.

The Southern California DPS, which was listed as endangered in 2011, has been affected by habitat loss due to dams, confinement of streams in concrete channels, water pollution, groundwater pumping, urban heat island effects, and other byproducts of urbanization. Steelhead in the Kamchatka Peninsula are threatened by over-harvest, particularly from poaching and potential development, and are listed in the "Red Data Book of Russia" that documents rare and endangered species.

Several studies have shown that almost all California coastal steelhead are of native origin, despite over a century of hatchery stocking. Genetic analysis shows that the South Central California Coast DPS and Southern California DPS from Malibu Creek north, and including the San Gabriel River, Santa Ana River and San Mateo Creek, are not hatchery strains. Steelhead from Topanga Creek and the Sweetwater River were partly, and those from San Juan Creek completely, of hatchery origin. Genetic analysis has also shown that the steelhead in the streams of the Santa Clara County and Monterey Bay basins are not of hatchery origin, including the Coyote Creek, Guadalupe River, Pajaro River, Permanente Creek, Stevens Creek, San Francisquito Creek, San Lorenzo River, and San Tomas Aquino Creek basins. Natural waterfalls and two major dams have isolated Russian River steelhead from freshwater rainbow trout forms above the impassable barriers; a 2007 genetic study of fin samples collected from steelhead at 20 different sites both above and below passage barriers in the watershed found that although 30 million hatchery trout were stocked in the river from 1911 to 1925, the steelhead remain of native and not hatchery origin.

Releases of conventionally reared hatchery steelhead pose ecological risks to wild steelhead populations. Hatchery steelhead are typically larger than the wild forms and can displace wild-form juveniles from optimal habitats. Dominance of hatchery steelhead for optimal microhabitats within streams may reduce wild steelhead survival as a result of reduced foraging opportunity and increased rates of predation.

Rainbow trout and steelhead are highly regarded game fish. Rainbow trout are a popular target for fly fishers, and several angling methods are used. The use of lures presented via spinning, casting or trolling techniques is common. Rainbow trout can also be caught on various live and dead natural baits. The International Game Fish Association recognizes the world record for rainbow trout as a fish caught on Saskatchewan's Lake Diefenbaker by Sean Konrad on September 5, 2009. The fish weighed and was a genetically modified hatchery escapee. Many anglers consider the rainbow trout the hardest-fighting trout species, as this fish is known for leaping when hooked and putting up a powerful struggle. It is considered one of the top five sport fish in North America and the most important game fish west of the Rocky Mountains.

There are tribal commercial fisheries for steelhead in Puget Sound, the Washington coast and in the Columbia River, but there has been controversy regarding over-harvesting of native stocks.

The highly desirable sporting qualities and adaptability of the rainbow trout to hatchery rearing and new habitats resulted in it being introduced to many countries around the world by or at the behest of sport fishermen. Many of these introductions have resulted in environmental and ecological problems, as the introduced rainbow trout disrupt local ecosystems and outcompete or eat indigenous fishes. Other introductions to support sport angling in waters either devoid of fish or with seriously depleted native stocks have created world-class fisheries such as in the Firehole River in Yellowstone National Park, and in the Great Lakes. 

Rainbow trout is popular in Western cuisine; both wild-caught and farmed fish are eaten. It has tender flesh and a mild, somewhat nutty flavor. Wild fish has a stronger, gamier taste than farmed fish. While the taste of wild-caught trout is often promoted as superior, rainbow trout and "steelhead" sold in American restaurants is farmed. Farmed rainbow are considered one of the safest fish to eat and are noted for high levels of vitamin B and a generally appealing flavor. Seafood Watch ranks farmed rainbow as a "Best Choice" fish for human consumption. In Montana, it is illegal to sell or market wild-caught rainbow trout, which are legally classified as game fish.

The color and flavor of the flesh depends on the diet and freshness of the trout. Farmed trout and some populations of wild trout, especially anadromous steelhead, have reddish or orange flesh as a result of high astaxanthin levels in their diets. Astaxanthin is a powerful antioxidant that may be from a natural source or a synthetic trout feed. Rainbow trout raised to have pinker flesh from a diet high in astaxanthin are sometimes sold in the U.S. with labeling calling them "steelhead". As wild steelhead are in decline in some parts of their range, farmed rainbow are viewed as a preferred alternative. In Chile and Norway, rainbow trout farmed in saltwater sea cages are sold labeled as steelhead.

Trout can be cooked as soon as they are cleaned, without scaling, skinning or filleting. If cooked with the skin on, the meat tends to hold together better. While trout sold commercially in Europe is often prepared and served this way, most trout sold commercially in the U.S. have had heads removed and have been fully or partially deboned and filleted. Medium to heavy bodied white wines, such as chardonnay, sauvignon blanc or pinot gris are typical wine pairings for trout.




</doc>
<doc id="949755" url="https://en.wikipedia.org/wiki?curid=949755" title="Canadian Indian residential school system">
Canadian Indian residential school system

In Canada, the Indian residential school system was a network of boarding schools for Indigenous peoples. The network was funded by the Canadian government's Department of Indian Affairs and administered by Christian churches. The school system was created for the purpose of removing Indigenous children from the influence of their own culture and assimilating them into the dominant Canadian culture. Over the course of the system's more than hundred-year existence, about 30 per cent of Indigenous children (around 150,000) were placed in residential schools nationally. The number of school-related deaths remains unknown due to an incomplete historical record, though estimates range from 3,200 upwards of 6,000.

The system had its origins in laws enacted before Confederation, but it was primarily active from the passage of the Indian Act in 1876. An amendment to the Indian Act in 1884 made attendance at day schools, industrial schools, or residential schools compulsory for First Nations children. Due to the remote nature of many communities, school locations meant that for some families residential schools were the only way to comply. The schools were intentionally located at substantial distances from Indigenous communities to minimize contact between families and their children. Indian Commissioner Hayter Reed argued for schools at greater distances to reduce family visits, which he thought counteracted efforts to civilize Indigenous children. Parental visits were further restricted by the use of a pass system designed to confine Indigenous peoples to reserves. The last federally operated residential school closed in 1996, called Gordon Indian Residential School and was located in Punnichy, Saskatchewan. Schools operated in every province and territory with the exception of New Brunswick and Prince Edward Island.

The residential school system harmed Indigenous children significantly by removing them from their families, depriving them of their ancestral languages, exposing many of them to physical and sexual abuse, and forcibly enfranchising them. Disconnected from their families and culture and forced to speak English or French, students who attended the residential school system often graduated unable to fit into either their communities and still subject to racist attitudes in mainstream Canadian society. The system ultimately proved successful in disrupting the transmission of Indigenous practices and beliefs across generations. The legacy of the system has been linked to an increased prevalence of post-traumatic stress, alcoholism, substance abuse, and suicide, which persist within Indigenous communities today. 

On June 11, 2008, Prime Minister Stephen Harper offered a public apology on behalf of the Government of Canada and the leaders of the other federal parties in the House of Commons. Nine days prior, the Truth and Reconciliation Commission (TRC) was established to uncover the truth about the schools. The commission gathered about 7,000 statements from residential school survivors through public and private meetings at various local, regional and national events across Canada. Seven national events held between 2008 and 2013 commemorated the experience of former students of residential schools. In 2015, the TRC concluded with the establishment of the National Centre for Truth and Reconciliation, and the publication of a multi-volume report detailing the testimonies of survivors and historical documents from the time. The TRC report found that the school system amounted to cultural genocide.

Attempts to assimilate Indigenous peoples were rooted in imperial colonialism, which centred around a European worldview of cultural practice and an understanding of land ownership based on the doctrine of Discovery. As explained in the executive summary of the Truth and Reconciliation Commission of Canada's (TRC) final report: "Underlying these arguments was the belief that the colonizers were bringing civilization to savage people who could never civilize themselves. The 'civilizing mission' rested on a belief of racial and cultural superiority."

Assimilation efforts began as early as the 17th century with the arrival of French colonists in New France. They were resisted by Indigenous communities who were unwilling to leave their children for extended periods and who came to associate missionaries with the diseases devastating Indigenous populations. The establishment of day and boarding schools by groups including the Récollets, Jesuits and Ursulines was largely abandoned by the 1690s. The political instability and realities of colonial life also played a role in the decision to halt the education programs. An increase in orphaned and foundling colonial children limited church resources, and colonists benefited from favourable relations with Indigenous peoples in both the fur trade and military pursuits.

After a failure to assimilate Indigenous children by early missionaries in the 17th century, educational programs were not widely attempted again by religious officials until the 1820s, prior to the introduction of state-sanctioned operations. Included among them was a school established by John West, an Anglican missionary, at the Red River Colony in what is today Manitoba. Protestant missionaries also opened residential schools in the current Ontario region, spreading Christianity and working to encourage Indigenous peoples to adopt subsistence agriculture as a way to ensure they would not return to their original, nomadic ways of life upon graduation.

Although many of these early schools were open for only a short time, efforts persisted. The Mohawk Institute Residential School, the oldest, continuously operated residential school in Canada, opened in 1834 on Six Nations of the Grand River near Brantford, Ontario. Administered by the Anglican Church, the facility opened as the Mechanics' Institute, a day school for boys, in 1828 and became a boarding school four years later when it accepted its first boarders and began admitting female students. It remained in operation until June 30, 1970.

The renewed interest in residential schools in the early 1800s has been linked to the decline in military hostility faced by British settlers, particularly after the War of 1812. With the threat of invasion by American forces minimized, Indigenous communities were no longer viewed as allies but as barriers to permanent settlement. This perspective was further underscored by the transfer of affairs with Indigenous communities from military officials, familiar with and sympathetic to their customs and way of life, to civilian representatives concerned only with permanent colonial settlement.

Beginning in the late 1800s, the Canadian government's Department of Indian Affairs (DIA) officially encouraged the growth of the residential school system as a valuable component in a wider policy of integrating Indigenous people into European-Canadian society. Responsible for separating Indigenous children from their families and communities, this process was found by the TRC to be cultural genocide, a conclusion that echoed the words of historian John S. Milloy, who argued that the system's aim was to "kill the Indian in the child". As the system was designed as an immersion program, Indigenous children were in many schools prohibited from, and sometimes punished for, speaking their own languages or practising their own faiths. The primary stated goal was to convert Indigenous children to Christianity and to civilize them.

Many of the government-operated residential schools were run by churches of various denominations, with the majority administered by Roman Catholics. Between 1867 and 1939, the number of schools operating at one time peaked at 80 in 1931. Of those schools, 44 were operated by Roman Catholics; 21 were operated by the Church of England / Anglican Church of Canada; 13 were operated by the United Church of Canada, and 2 were operated by Presbyterians. The approach of using established school facilities set up by missionaries was employed by the federal government for economic expedience: the government provided facilities and maintenance, while the churches provided teachers and their own lesson-planning. As a result, the number of schools per denomination was less a reflection of their presence in the general population, but rather their legacy of missionary work.

Although education in Canada was made the jurisdiction of the provincial governments by the British North America Act, Indigenous peoples and their treaties were under the jurisdiction of the federal government. Residential schools were funded under the Indian Act by what was then the federal Department of the Interior. Adopted in 1876 as "An Act to amend and consolidate the laws respecting Indians", it consolidated all previous laws placing Indigenous communities, land and finances under federal control. As explained by the TRC, the Act "made Indians wards of the state, unable to vote in provincial or federal elections or enter the professions if they did not surrender their status, and severely limited their freedom to participate in spiritual and cultural practices".

The by Governor General Charles Bagot, entitled "Report on the affairs of the Indians in Canada". Referred to as the Bagot Report, it is seen as the foundational document for the federal . It was supported by James Bruce, 8th Earl of Elgin, who had been impressed by industrial schools in the West Indies, and Egerton Ryerson, who was then the Chief Superintendent of Education in Upper Canada.

On May 26, 1847, Ryerson wrote a letter for George Vardon, Assistant Superintendent of Indian Affairs, asserting that "the North American Indian cannot be civilized or preserved in a state of civilization (including habits of industry and sobriety) except in connection with, if not by the influence of, not only religious instruction and sentiment but of religious feelings". He expressly recommended that Indigenous students be educated in a separate, denominational, English-only system with a focus on industrial training. This letter was published as an appendix to a larger report entitled "Statistics Respecting Indian Schools".

The Gradual Civilization Act of 1857 and the Gradual Enfranchisement Act of 1869 formed the foundations for this system prior to Confederation. These acts assumed the inherent superiority of French and British ways, and the need for Indigenous peoples to become French or English speakers, Christians, and farmers. At the time, many Indigenous leaders argued to have these acts overturned. The Gradual Civilization Act awarded of land to any Indigenous male deemed "sufficiently advanced in the elementary branches of education" and would automatically "enfranchise" him, removing any tribal affiliation or treaty rights. With this legislation, and through the creation of residential schools, the government believed Indigenous peoples could eventually become assimilated into the general population. For graduates to receive individual allotments of farmland would require changes in the communal reserve system, something fiercely opposed by First Nations governments.

In January 1879, Sir John A. Macdonald, Prime Minister of what was now post-Confederation Canada, commissioned politician Nicholas Flood Davin to write a report regarding the industrial boarding-school system in the United States. Now known as the Davin Report, the "Report on Industrial Schools for Indians and Half-Breeds" was submitted to Ottawa in March 14, 1879, and made the case for a cooperative approach between the Canadian government and the church to implement the "aggressive assimilation" pursued by President of the United States, Ulysses S. Grant. Davin's report relied heavily on findings he acquired through consultations with government officials and representatives of the Five Civilized Tribes in Washington, DC, and church officials in Winnipeg, Manitoba. He visited only one industrial day school, in Minnesota, before submitting his findings. In his report Davin concluded that the best way to civilize Indigenous peoples was to start with children in a residential setting, away from their families, so that they could be "kept constantly within the circle of civilized conditions".

Davin's findings were supported by Vital-Justin Grandin, who felt that while the likelihood of civilizing adults was low, there was hope when it came to Indigenous children. He explained in a letter to Public Works Minister Hector-Louis Langevin that the best course of action would be make children "lead a life different from their parents and cause them to forget the customs, habits & language of their ancestors". In 1883 Parliament approved $43,000 for three industrial schools and the first, Battleford Industrial School, opened on December 1 of that year. By 1900 there were 61 schools in operation.

The government began purchasing church run boarding schools in the 1920s. During this period capital costs associated with the schools were assumed by the government, leaving administrative and instructional duties to church officials. The hope was that minimizing facility expenditures would allow church administrators to provide higher quality instruction and support to the students in their care. Although the government was willing to, and did, purchase schools from the churches, many were acquired for free given that the rampant disrepair present in the buildings resulted in their having no economic value. Schools continued to be maintained by churches in instances where they failed to reach an agreement with government officials with the understanding that the government would provide support for capital costs. The understanding ultimately proved complicated due to the lack of written agreements outlining the extent and nature of that support or the approvals required to undertake expensive renovations and repairs.

By the 1930s it was recognized by government officials that the residential school system was financially unsustainable and failing to meet the intended goal of training and assimilating Indigenous children into European-Canadian society. Robert Hoey, superintendent of welfare and training at Indian Affairs, opposed the expansion of new schools, noting in 1936 that "to build educational institutions, particularly residential schools, while the money at our disposal is insufficient to keep the schools already erected in a proper state of repair, is, to me, very unsound and a practice difficult to justify". He proposed the expansion of day schools, an approach to educating Indigenous children that he would continue to pursue after being promoted to director of the welfare and training branch in 1945. The proposal was resisted by the United Church, the Anglican Church, and the Missionary Oblates of Mary Immaculate, who believed that the solution to the system's failure was not restructuring but intensification.

Between 1945 and 1955, the number of day schools run by Indian Affairs expanded from 9,532 to 17,947. The growth in day schools was accompanied by an amendment to the Indian Act in 1951 that allowed federal officials to establish agreements with provincial and territorial governments and school boards regarding the education of Indigenous students in the public school system. These changes were indicative of the government's shift in policy from assimilation-driven education at residential schools to the integration of Indigenous students into public schools. It was believed that Indigenous children would receive a better education as a result of their transition into the public school system.

Despite the shift in policy from educational assimilation to integration, the removal of Indigenous children from their families by state officials continued through much of the 1960s and 70s. The removals were the result of the 1951 addition of section 88 to the Indian Act, which allowed for the application of provincial laws to Indigenous peoples living on reserves in instances where federal laws were not in place. The change included the monitoring of child welfare. With no requirement for specialized training regarding the traditions or lifestyles of the communities they entered, provincial officials assessed the welfare of Indigenous children based on Euro-Canadian values that, for example, deemed traditional diets of game, fish and berries insufficient and grounds for taking children into custody. This period resulted in the widespread removal of Indigenous children from their traditional communities, first termed the Sixties Scoop by Patrick Johnston, the author of the 1983 report "Native Children and the Child Welfare System". Often taken without the consent of their parents or community elders, some children were placed in state-run child welfare facilities, increasingly operated in former residential schools, while others were fostered or placed up for adoption by predominantly non-Indigenous families throughout Canada and the United States. While the Indian and Northern Affairs estimates that 11,132 children were adopted between 1960 and 1990, the actual number may be as high as 20,000.

In 1969, after years of sharing power with churches, the DIA took sole control of the residential school system. The last residential school operated by the Canadian government, Gordon Indian Residential School in Saskatchewan, was closed in 1996. Residential schools operated in every Canadian province and territory with the exception of New Brunswick and Prince Edward Island. It is estimated that the number of residential schools reached its peak in the early 1930s with 80 schools and more than 17,000 enrolled students. About 150,000 children are believed to have attended a residential school over the course of the system's existence.

The parents and families of Indigenous children resisted the residential school system throughout its existence. Children were kept from schools and, in some cases, hidden from government officials tasked with rounding up children on reserves. Parents regularly advocated for increased funding for schools, including the increase of centrally located day schools to improve access to their children, and made repeated requests for improvements to the quality of education, food, and clothing being provided at the schools. Demands for answers in regards to claims of abuse were often dismissed as a ploy by parents seeking to keep their children at home, with government and school officials positioned as those who knew best.

In 1884, amendments to the Indian Act made school attendance compulsory for Indigenous children between 7 and 16 years of age. The changes included a series of exemptions regarding school location, the health of the children and their prior completion of school examinations. It was changed to children between 6 and 15 years of age in 1908. The introduction of mandatory attendance was the result of pressure from missionary representatives. Reliant on student enrollment quotas to secure funding, they were struggling to attract new students due to increasingly poor school conditions.

Compulsory attendance ended in 1948, following the 1947 report of a special joint committee and subsequent amendment of the Indian Act. Government officials were still able to influence student attendance. The introduction of the Family Allowance Act in 1945 stipulated that school-aged children had to be enrolled in school for families to qualify for the "baby bonus", further coercing Indigenous parents into having their children attend residential schools.

Students in the residential school system were faced with a multitude of abuses from teachers and administrators, including sexual and physical assault. They suffered from malnourishment and harsh discipline that would not have been tolerated in any other school system. Corporal punishment was often justified by a belief that it was the only way to save souls, civilize the savage, or punish and deter runaways – whose injuries or death sustained in their efforts to return home would become the legal responsibility of the school. Overcrowding, poor sanitation, inadequate heating, and a lack of medical care led to high rates of influenza and tuberculosis; in one school, the death rate reached 69 per cent. Federal policies that tied funding to enrollment numbers led to sick children being enrolled in order to boost numbers, thus introducing and spreading disease. The problem of unhealthy children was further exacerbated by the conditions of the schools themselves – overcrowding and poor ventilation, water quality and sewage systems.

Until the late 1950s, when the federal government shifted to a day school integration model, residential schools were severely underfunded and often relied on the forced labour of their students to maintain their facilities, although it was presented as training for artisan skills. The work was arduous, and severely compromised the academic and social development of the students. School books and textbooks were drawn mainly from the curricula of the provincially funded public schools for non-Indigenous students, and teachers at the residential schools were often poorly trained or prepared. During this same period, Canadian government scientists performed nutritional tests on students and knowingly kept some students undernourished to serve as the control sample.

Details of the mistreatment of students were published numerous times throughout the 20th century by both government officials, reporting on the condition of schools, and by the proceedings of civil cases brought forward by survivors seeking compensation for the abuse they endured. Attention to the conditions and impacts of residential schools were also brought to light in popular culture as early as 1967 with the publication of "The Lonely Death of Chanie Wenjack" by Ian Adams in "Maclean's" and the Indians of Canada Pavilion at Expo 67. In the 1990s, investigations and memoirs by former students revealed that many students at residential schools were subjected to severe physical, psychological, and sexual abuse by school staff members and by older students. Among the former students to come forward was Phil Fontaine, then Grand Chief of the Assembly of Manitoba Chiefs, who in October 1990 publicly discussed the abuse he and others suffered while attending Fort Alexander Indian Residential School.

Following the government's closure of most of the schools in the 1960s, the work of Indigenous activists and historians led to greater awareness by the public of the damage the schools had caused, as well as to official government and church apologies, and a legal settlement. These gains were achieved through the persistent organizing and advocacy by Indigenous communities to draw attention to the residential school system's legacy of abuse, including their participation in hearings of the Royal Commission on Aboriginal Peoples.

Parents and family members regularly travelled to the schools, often camping outside to be closer to their children. The number of parents who made the trip prompted Indian Commissioner Hayter Reed to argue that industrial schools, like residential schools, be moved greater distances from reserves to make visiting more difficult. He also objected to allowing children to return home during school breaks and holidays because he believed the trips interrupted the civilizing of school attendees. As Reed explained in 1894, the problem with day schools was that students returned home each night where they were influenced by life on the reserve, whereas "in the boarding or industrial schools the pupils are removed for a long period from the leadings of this uncivilized life and receive constant care and attention".

Visitation, for those able to make the journey, was strictly controlled by school officials in a manner similar to the procedures enforced in the prison system. In some cases visitors were altogether denied access to their children, while in others families were required to meet in the presence of school officials and forced to communicate in English. For parents unable to speak the language, verbal communication with their children was impossible. The obstacles families faced to visit their children were further exacerbated by the pass system. Introduced by Reed without legislative authority to do so, the system restricted and closely monitored the movement of Indigenous peoples off reserves. Launched in 1885 as a response to the North-West Rebellion, and later replaced by permits, the system was designed to prevent Indigenous people from leaving reserves without a pass issued by a local Indian agent.

 Instruction provided to students was rooted in an institutional and European approach to education. It differed dramatically from child rearing in traditional knowledge systems that are generally based on 'look, listen, and learn' models. Unlike the corporal punishment and loss of privileges that characterized the residential school system, traditional approaches to education favour positive guidance toward desired behaviour through the use of game-based play, story-telling, and formal ritualized ceremonies. While at school, many children had no contact with their families for up to 10 months at a time because of the distance between their home communities and schools, and in some cases had no contact for years. The impact of the disconnect from their families was furthered by students being discouraged or prohibited from speaking Indigenous languages, even among themselves and outside the classroom, so that English or French would be learned and their own languages forgotten. In some schools, they were subject to physical violence for speaking their own languages or for practicing non-Christian faiths.

Most schools operated with the goal of providing students with the vocational training and social skills required to obtain employment and integrate into Canadian society after graduation. In actuality, these goals were poorly and inconsistently achieved. Many graduates were unable to land a job due to poor educational training. Returning home was equally challenging due to an unfamiliarity with their culture and, in some cases, an inability to communicate with family members using their traditional language. Instead of intellectual achievement and advancement, it was often physical appearance and dress, like that of middle class, urban teenagers, or the promotion of a Christian ethic, that was used as a sign of successful assimilation. There was no indication that school attendees achieved greater financial success than those who did not go to school. As the father of a pupil who attended Battleford Industrial School, in Saskatchewan, for five years explained: "he cannot read, speak or write English, nearly all his time having been devoted to herding and caring for cattle instead of learning a trade or being otherwise educated. Such employment he can get at home."

Residential school deaths were common and have been linked to the persistence of poorly constructed and maintained facilities. The actual number of deaths remains unknown due to inconsistent reporting by school officials and the destruction of medical and administrative records in compliance with retention and disposition policies for government records. Research by the TRC revealed that at least 3,201 students had died, mostly from disease. TRC chair, Justice Murray Sinclair, has suggested that the number of deaths may be closer to more than 6,000.

The 1906 Annual Report of the Department of Indian Affairs, submitted by chief medical officer Peter Bryce, highlighted that the "Indian population of Canada has a mortality rate of more than double that of the whole population, and in some provinces more than three times". Among the list of causes he noted tuberculosis and the role residential schools played in spreading the disease by way of poor ventilation and medical screening.

In 1909, Bryce reported that, between 1894 and 1908, mortality rates at some residential schools in western Canada ranged from 30 to 60 per cent over five years (that is, five years after entry, 30 to 60 per cent of students had died, or 6 to 12 per cent per annum). These statistics did not become public until 1922, when Bryce, who was no longer working for the government, published "The Story of a National Crime: Being a Record of the Health Conditions of the Indians of Canada from 1904 to 1921." In particular, he alleged that the high mortality rates could have been avoided if healthy children had not been exposed to children with tuberculosis. At the time, no antibiotic had been identified to treat the disease, and this exacerbated the impact of the illness. Streptomycin, the first effective treatment, was not introduced until 1943.

In 1920 and 1922, Regina physician F.A. Corbett was commissioned to visit the schools in the west of the country, and found similar results to those reported by Bryce. At the Ermineskin school in Hobbema, Alberta, he found 50 per cent of the children had tuberculosis. At Sarcee Boarding School near Calgary, he noted that all 33 students were "much below even a passable standard of health" and but four were infected with tuberculosis". In one classroom, he found 16 ill children, many near death, who were being made to sit through lessons.

In 2011, reflecting on the TRC's research, Justice Murray Sinclair told the "Toronto Star": "Missing children – that is the big surprise for me ... That such large numbers of children died at the schools. That the information of their deaths was not communicated back to their families."

The TRC concluded that it may be impossible to ever identify the number of deaths or missing children, in part because of the habit of burying students in unmarked graves. The work is further complicated by a pattern of poor record keeping by school and government officials, who neglected to keep reliable numbers about the number of children who died or where they were buried. While most schools had cemeteries on site, their location and extent remain difficult to determine as cemeteries that were originally marked were found to have been later razed, intentionally hidden or built over.

The fourth volume of the TRC's final report, dedicated to missing children and unmarked burials, was developed after the original TRC members realized, in 2007, that the issue required its own working group. In 2009, the TRC requested $1.5million in extra funding from the federal government to complete this work, but was denied. The researchers concluded, after searching land near schools using satellite imagery and maps, that, "for the most part, the cemeteries that the Commission documented are abandoned, disused, and vulnerable to accidental disturbance".

When the government revised the Indian Act in the 1940s and 1950s, some bands, along with regional and national Indigenous organizations, wanted to maintain schools in their communities. Motivations for support of the schools included their role as a social service in communities that were suffering from extensive family breakdowns; the significance of the schools as employers; and the inadequacy of other opportunities for children to receive education. 

In the 1960s, a major confrontation took place at the Saddle Lake Reserve in Alberta. After several years of deteriorating conditions and administrative changes, parents protested against the lack of transparency at the Blue Quills Indian School in 1969. In response, the government decided to close the school, convert the building into a residence, and enroll students in a public school away in St. Paul, Alberta. The TRC report pertaining to this period states:Fearing their children would face racial discrimination in St. Paul, parents wished to see the school transferred to a private society that would operate it both as a school and a residence. The federal government had been open to such a transfer if the First Nations organization was structured as a provincial school division. The First Nations rejected this, saying that a transfer of First Nations education to the provincial authority was a violation of Treaty rights. In the summer of 1970, members of the Saddle Lake community occupied the building and demanded the right to run it themselves. More than 1,000 people are believed to have participated over the course of the 17-day sit-in, which lasted from July 14 to 31. Their efforts resulted in Blue Quills becoming the first Indigenous-administered school in the country. It continues to operate today as University nuhelot’įne thaiyots’į nistameyimâkanak Blue Quills, the first Indigenous-governed university in Canada. Following the success of the Blue Quills effort the National Indian Brotherhood (NIB) released the 1972 paper "Indian Control of Indian Education" that responded, in part, to the Canadian Government's 1969 White Paper calling for the abolishment of the land treaties and the Indian Act. The NIB paper underscored the right of Indigenous communities to locally direct how their children are educated and served as the integral reference for education policy moving forward.

Few other former residential schools have transitioned into independently-operated community schools for Indigenous children. White Calf Collegiate in Lebret, Saskatchewan, was run by the Star Blanket Cree Nation from 1973 until its closure in 1998, after being run by the Oblates from 1884 to 1969. Old Sun Community College is run by the Siksika Nation in Alberta in a building designed by architect Roland Guerney Orr. From 1929 to 1971 the building housed Old Sun residential school, first run by the Anglicans and taken over by the federal government in 1969. It was converted to adult learning and stood as a campus of Mount Royal College from 1971 to 1978, at which point the Siksika Nation took over operations. In 1988, the Old Sun College Act was passed in the Alberta Legislature recognizing Old Sun Community College as a First Nations College.

Survivors of residential schools and their families have been found to suffer from historic trauma that has had a lasting and adverse effect on the transmission of Indigenous culture between generations. Passed on intergenerationally, a 2010 study led by Gwen Reimer explains historic trauma as the process through which "cumulative stress and grief experienced by Aboriginal communities is translated into a collective experience of cultural disruption and a collective memory of powerlessness and loss". It has been used to explain the persistent negative social and cultural impacts of colonial rule and residential schools, including the prevalence of sexual abuse, alcoholism, drug addiction, lateral violence, mental illness and suicide among Indigenous peoples.

The 2012 national report of the First Nations Regional Health Study found that of respondents who attended residential schools were more likely than those who did not to have been diagnosed with at least one chronic medical condition. A sample of 127 survivors revealed that half have criminal records; 65 per cent have been diagnosed with posttraumatic stress disorder; 21 per cent have been diagnosed with major depression; 7 per cent have been diagnosed with anxiety disorder; and 7 per cent have been diagnosed with borderline personality disorder.

Although encouragement to keep Indigenous languages alive was present in some schools, a key tactic used to assimilate Indigenous children into Canadian society was to suppress Indigenous languages and culture. Many students spoke the language of their families fluently when they first entered residential schools. Teachers responded by strictly prohibiting the use of these languages despite many students having little or no understanding of English or French. The practice of traditional and spiritual activities including the Potlatch and Sun Dance were also banned. Some survivors reported being strapped or forced to eat soap when they were caught speaking their own language. The inability to communicate was further affected by their families' inabilities to speak English or French. Upon leaving residential school some survivors felt ashamed for being Indigenous as they were made to view their traditional identities as ugly and dirty.

The stigma created by the residential school system regarding transmission of Indigenous culture by elders to younger generations has been linked to the over-representation of Indigenous languages on the list of endangered languages in Canada. The TRC noted that the majority of 90 Indigenous languages still in existence are "under serious threat of extinction". With great-grandparents representing the only speakers of many Indigenous languages, it was concluded that a failure of governments and Indigenous communities to prioritize the teaching and preservation of traditional languages would ensure that, despite the closure of resident schools, the eradication of Indigenous culture desired by government officials and administrators would inevitably be fulfilled "through a process systemic neglect". In addition to the forceful eradication of elements of Indigenous culture, the schools trained students in patriarchal dichotomies useful to state institutions, such as the domesticization of female students through imbuing ‘stay-at-home’ values and the militarization of male students through soldierlike regimentation.  

Acknowledgment of the wrongs done by the residential school system began in the 1980s. In 1986, at its 31st General Council, the United Church of Canada responded to the request of Indigenous peoples that it apologize to them for its part in colonization and in 1998 apologized expressly for the role it played in the residential school system.

Archbishop Michael Peers apologized to residential school survivors, on behalf of the Anglican Church of Canada, on August 6, 1993, at the National Native Convocation in Minaki, Ontario. The following year the Presbyterian Church in Canada adopted a confession at its 120th General Assembly in Toronto on June 5, recognizing its role in residential schools and seeking forgiveness. The confession was presented on October 8 during a ceremony in Winnipeg.

In 2004, immediately before signing the first Public Safety Protocol with the Assembly of First Nations, Royal Canadian Mounted Police (RCMP) Commissioner Giuliano Zaccardelli issued an apology on behalf of the RCMP for its role in the Indian residential school system: "We, I, as Commissioner of the RCMP, am truly sorry for what role we played in the residential school system and the abuse that took place in the residential system."

On June 11, 2008, Prime Minister Stephen Harper issued a formal apology, on behalf of the sitting Cabinet, in front of an audience of Indigenous delegates, and in an address that was broadcast nationally on the CBC, for the past governments' policies of assimilation. The Prime Minister apologized not only for the known excesses of the residential school system, but for the creation of the system itself. Harper delivered the speech in the House of Commons; the procedural device of a Committee of the Whole was used, so that Indigenous leaders, who were not Members of Parliament, could be allowed to respond to the apology on the floor of the House.

Harper's apology excluded Newfoundland and Labrador as it was argued that the government should not be held accountable for pre-Confederation actions. Residential schools in Newfoundland and Labrador were located in St. Anthony, Cartwright, North West River, Nain and Makkovik. These schools were run by the International Grenfell Association and the German Monrovian Missionaries. The government argued that because these schools were not created under the auspices of the Indian Act, they were not true residential schools. More than 1,000 survivors disagreed and filed a class action lawsuit against the government for compensation in 2007. By the time the suit was settled in 2016, almost a decade later, dozens of plaintiffs had died. It was expected that up to 900 former students would be compensated.

On November 24, 2017, Prime Minister Justin Trudeau issued a formal apology to former Innu, Inuit and NunatuKavut school survivors and their families during a ceremony in Happy Valley-Goose Bay, Labrador. He acknowledged that students experienced multiple forms of abuse linking their treatment to the colonial thinking that shaped the school system. Trudeau's apology was received on behalf of residential school survivors by Toby Obed who framed the apology as a key part of the healing process that connected survivors from Newfoundland and Labrador with school attendees from across the country. Members of the Innu Nation were less receptive, rejecting the apology ahead of the ceremony. Grand Chief Gregory Rich noted in a released statement that he was "not satisfied that Canada understands yet what it has done to Innu and what it is still doing", indicating that members felt they deserved an apology for more than their experiences at residential schools.

On June 22, 2015, Rachel Notley, Premier of Alberta, issued a formal apology as a ministerial statement in a bid to begin to address the wrongs done by the government to the Indigenous peoples of Alberta and the rest of Canada. Notley's provincial government called on the federal government to hold an inquiry on the missing and murdered Indigenous women in Canada at the same time. They also stated their intent to build relationships with provincial leaders of Indigenous communities, and sought to amend the provincial curriculum to include the history of Indigenous culture.

On June 18, 2015, Manitoba Premier Greg Selinger became the first politician to issue a formal apology for the government's role in the Sixties Scoop. Class action lawsuits have been brought against the Saskatchewan, Manitoba and Ontario governments for the harm caused to victims of the large-scale adoption scheme that saw thousands of Indigenous children forcibly removed from their parents in the 1960s. Indigenous leaders responded by insisting that while apologies were welcomed, action – including a federal apology, reunification of families, compensation and counselling for victims – must accompany words for them to have real meaning.

Ontario Premier Kathleen Wynne apologized on behalf of the provincial government for the harm done at residential schools at Legislative Assembly of Ontario on May 30, 2016. Affirming Ontario's commitment to reconciliation with Indigenous peoples she acknowledged the school system as "one of the most shameful chapters in Canadian history". In a 105-minute ceremony, Wynne announced that the Ontario government would spend $250million on education initiatives and renamed the Ministry of Aboriginal Affairs the Ministry of Indigenous Relations and Reconciliation. It was further announced that the first week of November would be known as Treaties Recognition Week.

On October 27, 2011, University of Manitoba president David Barnard apologized to the TRC for the institution's role in educating people who operated the residential school system. This is believed to be the first time a Canadian university has apologized for playing a role in residential schools.

In 2009, Chief Fontaine had a private meeting with Pope Benedict XVI to obtain an apology for abuses that occurred in the residential school system. Fontaine was accompanied at the meeting by a delegation of Indigenous peoples from Canada funded by Indian and Northern Affairs Canada. Following the meeting, the Vatican released an official expression of sorrow on the church's role in residential schools:

His Holiness [i.e. the Pope] recalled that since the earliest days of her presence in Canada, the Church, particularly through her missionary personnel, has closely accompanied the Indigenous peoples.

Given the sufferings that some Indigenous children experienced in the Canadian Residential School system, the Holy Father expressed his sorrow at the anguish caused by the deplorable conduct of some members of the Church and he offered his sympathy and prayerful solidarity. His Holiness emphasized that acts of abuse cannot be tolerated in society. He prayed that all those affected would experience healing, and he encouraged First Nations Peoples to continue to move forward with renewed hope.
Fontaine later stated at a news conference that, at the meeting, he sensed the Pope's "pain and anguish" and that the acknowledgement was "important to [him] and that was what [he] was looking for".

On May 29, 2017, Prime Minister Justin Trudeau asked the current Pope Francis for a public apology to all survivors of the residential school system, rather than the expression of sorrow issued in 2009. The request aligned with the Truth and Reconciliation Commission's call for "a formal apology issued by the Pope to the survivors of the residential school system for the spiritual, cultural, emotional, physical and sexual abuse of Canada's First Nations, Inuit and Métis peoples". Trudeau invited the Pope to issue the apology in Canada. Although no commitment for such an apology followed the meeting, he noted that the Pope pointed to a lifelong commitment of supporting marginalized people and an interest in working collaboratively with Trudeau and Canadian bishops to establish a way forward.

In the summer of 1990, the Mohawks of Kanesatake confronted the government about its failure to honour Indigenous land claims and recognize traditional Mohawk territory in Oka, Quebec. Referred to by media outlets as the Oka Crisis, the land dispute sparked a critical discussion about the Canadian government's complacency regarding relations with Indigenous communities and responses to their concerns. The action prompted then Prime Minister Brian Mulroney to underscore four government responsibilities: "resolving land claims; improving the economic and social conditions on reserves; defining a new relationship between aboriginal peoples and governments; and addressing the concerns of Canada's aboriginal peoples in contemporary Canadian life." The actions of the Mohawk community members led to, in part, along with objections from Indigenous leaders regarding the Meech Lake Accord, the creation of the Royal Commission on Aboriginal Peoples to examine the status of Indigenous peoples in Canada. In 1996, the Royal Commission presented a final report which first included a vision for meaningful and action-based reconciliation.

In January 1998, the government made a "statement of reconciliation" – including an apology to those people who were sexually or physically abused while attending residential schools – and established the Aboriginal Healing Foundation (AHF). The foundation was provided with $350million to fund community-based healing projects addressing the legacy of physical and sexual abuse. In its 2005 budget, the Canadian government committed an additional $40million to support the work of the AHF. Federal funding for the foundation was cut in 2010 by the Stephen Harper government, leaving 134 national healing-related initiatives without an operating budget. The AHF closed in 2014. Former AHF executive director Mike DeGagne has said that the loss of AHF support has created a gap in dealing with mental health crises such as suicides in the Attawapiskat First Nation.

In June 2001, the government established Indian Residential Schools Resolution Canada as an independent government department to manage the residential school file. In 2003, the Alternative Dispute Resolution (ADR) process was launched as part of a larger National Resolution Framework which included health supports, a commemoration component and a strategy for litigation. As explained by the TRC, the ADR was designed as a "voluntary process for resolution of certain claims of sexual abuse, physical abuse, and forcible confinement, without having to go through the civil litigation process". It was created by the Canadian government without consultation with Indigenous communities or former residential school students. The ADR system also made it the responsibility of the former students to prove that the abuse occurred and was intentional, resulting in former students finding the system difficult to navigate, re-traumatizing, and discriminatory. Many survivor advocacy groups and Indigenous political organizations such as the Assembly of First Nations (AFN) worked to have the ADR system dissolved. In 2004 the Assembly of First Nations released a report critical of the ADR underscoring, among other issues, the failure of survivors to automatically receive the full amount of compensation without subsequent ligation against the church and failure to compensate for lost family, language and culture. The Canadian House of Commons Standing Committee on Aboriginal Affairs and Northern Development released its own report in April 2005 finding the ADR to be "an excessively costly and inappropriately applied failure, for which the Minister and her officials are unable to raise a convincing defence". Within a month of the report's release a Supreme Court of Canada decision granted school attendees the right to pursue class-action suits, which ultimately led to a government review of the compensation process.

On November 23, 2005, the Canadian government announced a $1.9-billion compensation package to benefit tens of thousands of former students. National Chief of the AFN, Phil Fontaine, said the package was meant to cover "decades in time, innumerable events and countless injuries to First Nations individuals and communities". Justice Minister Irwin Cotler applauded the compensation decision noting that the placement of children in the residential school system was "the single most harmful, disgraceful and racist act in our history". At an Ottawa news conference, Deputy Prime Minister Anne McLellan said: "We have made good on our shared resolve to deliver what I firmly believe will be a fair and lasting resolution of the Indian school legacy."

The compensation package led to the Indian Residential Schools Settlement Agreement (IRSSA), announced on May 8, 2006, and implemented in September 2007. At the time, there were about 86,000 living victims. The IRSSA included funding for the AHF, for commemoration, for health support, and for a Truth and Reconciliation program, as well as an individual Common Experience Payment (CEP). Any person who could be verified as having resided at a federally run Indian residential school in Canada was entitled to a CEP. The amount of compensation was based on the number of years a particular former student resided at the residential schools: $10,000 for the first year attended (from one night residing there to a full school year) plus $3,000 for every year thereafter.

The IRSSA also included the Independent Assessment Process (IAP), a case-by-case, out-of-court resolution process designed to provide compensation for sexual, physical and emotional abuse. The IAP process was built on the ADR program and all IAP claims from former students are examined by an adjudicator. The IAP became available to all former students of residential schools on September 19, 2007. Former students who experienced abuse and wished to pursue compensation had to apply by themselves or through a lawyer of their choice to receive consideration. The deadline to apply for the IAP was September 19, 2012. This gave former students of residential schools four years from the implementation date of the IRSSA to apply for the IAP. Claims involving physical and sexual abuse were compensated up to $275,000. By the end of January 2017, the IAP had resolved 36,538 claims and paid $3.1billion in compensation.

The IRSSA also proposed an advance payment for former students alive and who were 65 years old and over as of May 30, 2005. The deadline for reception of the advance payment form by IRSRC was December 31, 2006. Following a legal process, including an examination of the IRSSA by the courts of the provinces and territories of Canada, an "opt-out" period occurred. During this time, the former students of residential schools could reject the agreement if they did not agree with its dispositions. This opt-out period ended on August 20, 2007, with about 350 former students opting out. The IRSSA was the largest class action settlement in Canadian history. By December 2012, a total of $1.62billion was paid to 78,750 former students, 98 per cent of the 80,000 who were eligible. In 2014, the IRSSA funds left over from CEPs were offered for educational credits for survivors and their families.

In 2008, the Truth and Reconciliation Commission (TRC) was established to travel across Canada collecting the testimonies of people affected by the residential school system. About 7,000 Indigenous people told their stories. The TRC concluded in 2015 with the publication of a six volume, 4,000-plus-page report detailing the testimonies of survivors and historical documents from the time. It focused on the importance of moving "from apology to action" to achieve true reconciliation and resulted in the establishment of the National Centre for Truth and Reconciliation.

The executive summary of the TRC concluded that the assimilation amounted to cultural genocide. The ambiguity of the phrasing allowed for the interpretation that physical and biological genocide also occurred. The TRC was not authorized to conclude that physical and biological genocide occurred, as such a finding would imply a legal responsibility of the Canadian government that would be difficult to prove. As a result, the debate about whether the Canadian government also committed physical and biological genocide against Indigenous populations remains open.

Among the 94 Calls to Action that accompanied the conclusion of the TRC were recommendations to ensure that all Canadians are educated and made aware of the residential school system. Justice Murray Sinclair explained that the recommendations were not aimed solely at prompting government action, but instead a collective move toward reconciliation in which all Canadians have a role to play: "Many of our elements, many of our recommendations and many of the Calls to Action are actually aimed at Canadian society."

Preservation of documentation of the legacy of residential schools was also highlighted as part of the TRC's Calls to Action. Community groups and other stakeholders have variously argued for documenting or destroying evidence and testimony of residential school abuses. On April 4, 2016, the Ontario Court of Appeal ruled that documents pertaining to IAP settlements will be destroyed in 15 years if individual claimants do not request to have their documents archived. This decision was fought by the TRC as well as the federal government, but argued for by religious representatives.

In March 2017, Lynn Beyak, a Conservative member of the Senate Standing Committee of Aboriginal Peoples, voiced disapproval of the final TRC report, saying that it had omitted an "abundance of good" that was present in the schools. Although Beyak's right to free speech was defended by some Conservative senators, her comments were widely criticized by members of the opposition, among them Minister of Indigenous and Northern Affairs, Carolyn Bennett, and leader of the New Democratic Party, Tom Mulcair. The Anglican Church also raised concerns stating in a release co-signed by bishops Fred Hiltz and Mark MacDonald: "There was nothing good about children going missing and no report being filed. There was nothing good about burying children in unmarked graves far from their ancestral homes." In response, the Conservative Party leadership removed Beyak from the Senate committee underscoring that her comments did not align with the views of the party.

The four churches of the Indian Residential Schools Settlement Agreement – the United, Roman Catholic, Anglican and Presbyterian churches – agreed to participate in the reconciliation process between Indigenous and settler Canadians. They have been involved in funding various projects and services that assist former residential school students and their families in healing from the trauma caused by the schools. The Anglican Church of Canada set up the Anglican Healing Fund in the 1990s to respond to the ongoing need for healing related to residential schools. In the 2000s the United Church established the Justice and Reconciliation Fund to support healing initiatives and the Presbyterian Church has established a Healing & Reconciliation Program.

The churches have also engaged in reconciliation initiatives such as the Returning to Spirit: Residential School Healing and Reconciliation Program, a workshop that aims to unite Indigenous and non-Indigenous people through discussing the legacy of residential schools and fostering an environment for them to communicate and develop mutual understanding. In 2014, the federal government ceased to contribute funds to Indigenous health organizations such as the AHF and the National Aboriginal Health Organization. Since then, more pressure has been placed on churches to sustain their active participation in these healing efforts.

For many communities the existence of buildings that formerly housed residential schools is a traumatic reminder of the system's legacy, and there has been much discussion about demolition, heritage status and how the possibility of incorporating sites into the healing process.
In July 2016, it was announced that the building of the former Mohawk Institute Residential School would be converted into an educational centre with exhibits on the legacy of residential schools. Ontario's Minister of Indigenous Relations and Reconciliation, David Zimmer, noted: "Its presence will always be a reminder of colonization and the racism of the residential school system; one of the darkest chapters of Canadian history."

Reconciliation efforts have also been undertaken by several Canadian universities. In 2015 Lakehead University and the University of Winnipeg introduced a mandatory course requirement for all undergraduate students focused on Indigenous culture and history. The same year the University of Saskatchewan hosted a two-day national forum at which Canadian university administrators, scholars and members of Indigenous communities discussed how Canadian universities can and should respond to the TRC's Calls to Action. 

On April 1, 2017, a pole, titled "Reconciliation Pole", was raised on the grounds of the University of British Columbia (UBC) Vancouver campus, which sits on the unceded territory of the Musqueam people. Carved by Haida master carver and hereditary chief, 7idansuu (Edenshaw), James Hart, the pole tells the story of the residential school system prior to, during and after its operation. It features thousands of copper nails, used to represent the children who died in Canadian residential schools, and depictions of residential school survivors carved by artists from multiple Indigenous communities. Included among them are Canadian Inuk director Zacharias Kunuk, Maliseet artist Shane Perley-Dutcher, and Muqueam Coast Salish artist Susan Point.

In October 2016, Canadian singer-songwriter Gord Downie released "Secret Path", a concept album about Chanie Wenjack's escape and death. It was accompanied by a graphic novel and animated film, aired on CBC Television. All proceeds go to the University of Manitoba's Centre for Truth and Reconciliation. Following his death in October 2017, Downie's brother Mike said he was aware of 40,000 teachers who had used the material in their classrooms, and hoped to continue this. In December 2017, Downie was posthumously named Canadian Newsmaker of the Year by the Canadian Press, in part because of his work with reconciliation efforts for survivors of residential schools.



</doc>
<doc id="950311" url="https://en.wikipedia.org/wiki?curid=950311" title="The Catlins">
The Catlins

The Catlins (sometimes referred to as The Catlins Coast) comprises an area in the southeastern corner of the South Island of New Zealand. The area lies between Balclutha and Invercargill, straddling the boundary between the Otago and Southland regions. It includes the South Island's southernmost point, Slope Point.

A rugged, sparsely populated area, the Catlins features a scenic coastal landscape and dense temperate rainforest, both of which harbour many endangered species of birds, most notably the rare yellow-eyed penguin. The coast attracts numerous marine mammals, among them New Zealand fur seals and Hooker's sea lions. In general terms the area enjoys a maritime temperate climate. Its exposed location leads to its frequently wild weather and heavy ocean swells, which are an attraction to big-wave surfers, and have also caused numerous shipwrecks.

People have lived in the area since around 1350 AD. Prior to European settlement, the region was sparsely inhabited by nomadic groups of Māori, most of whom lived close to river mouths. In the early days of European settlement the area was frequented by whalers and sealers, and saw milling became a major local industry from the mid-19th century until the 1930s.

Tourism has become of growing importance in the Catlins economy, which otherwise relies heavily on dairy farming and fishing.

The region's population has fallen to less than half its peak in the early 20th century. Some 1,200 people now live in the Catlins, many of them in the settlement of Owaka. This is linked to population centres to the north and southwest via the area's only major road, part of the Southern Scenic Route. Owaka contains the area's main school,The Catlins Area School, catering for students from year 1 to year 13. There are three other small primary schools throughout the Catlins district. Owaka also has a medical centre, the nearest hospital being in Balclutha. The Catlins is governed at local level as part of the Clutha and Southland Districts and is represented at national level as part of the Clutha-Southland electorate.

The Catlins area covers some and forms a rough triangular shape, extending up to inland and along a stretch of coast in extent. The mouths of two large rivers, the Clutha River in the northeast and the Mataura River in the west, mark its coastal limits. To the north and northwest, the rough bush-clad hills give way to rolling pastoral countryside drained and softened by the actions of tributaries of these two rivers such as the Pomahaka River.

The rugged, scenic coastline of the Catlins features sandy beaches, blowholes, a petrified forest at Curio Bay, and the Cathedral Caves, which visitors can reach at low tide. Much of the coastline consists of high cliffs, up to in height, and the land rises sharply from the coast at most points. For this reason, many of the area's rivers cascade over waterfalls as they approach the ocean (notably the iconic Purakaunui Falls on the short Purakaunui River).

The South Island's southernmost point, Slope Point, projects near the southwestern corner of the Catlins. To the west of this lies Waipapa Point, often considered the boundary of the Catlins region, beyond which lies the swampy land around the mouth of the Mataura River at the eastern end of Toetoes Bay. But various people place the western boundary of the Catlins region in different places, and some more stringent definitions exclude even Slope Point. A proposed boundary circulated in 2009 by the New Zealand Geographic Board ran roughly north from Slope Point, then inland around the Catlins Ranges and east to Nugget Point. Tourist organisations objected, asking that the boundary be moved further west to include Fortrose.

Several parallel ranges of hills dominate the interior of the Catlins, separated by the valleys of the Owaka, Catlins and Tahakopa Rivers, which all drain southeastwards into the Pacific Ocean. The most notable of these ranges is the Maclennan Range. Between them, these hills are often simply referred to as the Catlins Ranges. Their northwestern slopes are drained by several tributaries of the Clutha and Mataura Rivers, most notably the Mokoreta River, which flows mainly westwards, reaching the Mataura close to the town of Wyndham.

The highest point in the Catlins, Mount Pye () stands north-northeast of Waikawa and close to the source of the Mokoreta River, and marks part of the Otago-Southland border. Other prominent peaks above include Mount Rosebery, Catlins Cone, Mount Tautuku, and Ajax Hill. The Catlins has several small lakes, notably scenic Lake Wilkie close to the Tautuku Peninsula. Catlins Lake, near Owaka, actually consists of the tidal estuary of the Catlins River.

Shipping has found the Catlins coast notoriously dangerous, and many shipwrecks have occurred on the headlands that jut into the Pacific Ocean here. Two lighthouses stand at opposite ends of the Catlins to help prevent further mishaps. The Nugget Point Lighthouse stands above the water at the end of Nugget Point, casting its light across a series of eroded stacks (the "nuggets" which give the point its name). It was built in 1869–70. The Waipapa Point light, which stands only above sea level, was the last wooden lighthouse to be built in New Zealand, and was constructed in 1884 in response to the tragic 1881 wreck of the "Tararua". Both of these lighthouses are now fully automated.
Due to its position at the southern tip of New Zealand, the Catlins coastline lies exposed to some of the country's largest ocean swells, often over . The region has enjoyed a growing reputation for big wave surfing, with regular competitions, award-winning rides, and coverage on the Discovery Channel gathering publicity for the sport. The Department of Conservation proposed protecting the Papatowai surf break in 2008, citing its national significance for surfing.

The landscape of the Catlins features in many poems by celebrated poet Hone Tuwhare. Born in Northland, Tuwhare lived in Kaka Point from 1992 until his death in 2008, and became one of the area's best-known inhabitants. His family plan to establish a writers' retreat at his crib there. The film "Two Little Boys", starring comedians Bret McKenzie and Hamish Blake, was filmed in the Catlins early in 2011.

The Catlins has a cool maritime temperate climate, somewhat cooler than other parts of the South Island, and strongly modified by the effect of the Pacific Ocean. Winds can reach considerable strength, especially on the exposed coast; most of the South Island's storms develop to the south or southwest of the island, and thus the Catlins catches the brunt of many of these weather patterns.

The Catlins—and especially its central and southern areas—experiences considerably higher precipitation than most of the South Island's east coast; heavy rain occurs infrequently, but drizzle is common and the region averages around 150 days of rain per year. Rain days are spread fairly evenly throughout the year; there is no particularly rainy season in the northern Catlins, and only a slight tendency towards more autumn rain in the southwest. The average annual rainfall recorded at the Tautuku Outdoor Education Centre is about , with little variation from year to year.

Fine days can be sunny and warm, and daily maxima may exceed in mid-summer (January/February). A more usual daily maximum in summer would be . Snow is rare except on the peaks even in the coldest part of winter, though frost is quite common during the months of June to September. Typical daily maximum temperatures in winter are .

The first people known to live in the Catlins, Māori of the Kāti Māmoe, Waitaha, and Kāi Tahu iwi (tribes), merged via marriage and conquest into the iwi now known as Kāi Tahu. Archaeological evidence of human presence dates back to approximately 1350 AD. The area's inhabitants were semi-nomadic, travelling from Stewart Island/Rakiura in the south and inland to Central Otago. They generally dwelt near river mouths for easy access to the best food resources. In legend, the Catlins forests further inland were inhabited by "Maeroero" (wild giants).

The Catlins may have offered one of the last places where the giant flightless bird, the moa, could be hunted, and the timber of the forest proved ideal for canoe construction (the name of the settlement "Owaka" means "Place of the canoe"). No formal Māori pa (villages) were located in the Catlins, but there were many hunting camps, notably at Papatowai, near the mouth of the Tahakopa River.

Europeans first sighted the area in 1770 when the crew of James Cook's "Endeavour" sailed along the coast. Cook named a bay in the Catlins area "Molineux's Harbour" after his ship's master Robert Molineux. Although this was almost certainly the mouth of the Waikawa River, later visitors applied the name to a bay to the northeast, close to the mouth of the Clutha River, which itself was for many years known as the Molyneux River. The town of Port Molyneux, located on this bay, was a busy harbour during the 19th century. Its location at the mouth of the Clutha made it a good site for trade both from the interior and for coastal and ocean-going shipping. A major flood in 1878 shifted the mouth of the Clutha to the north and silted up the port, after which the town gradually dwindled.

Sealers and whalers founded the first European settlements in the early years of the 19th century, at which time the hunting of marine mammals dominated European economic activity in New Zealand. A whaling station was established on the Tautuku Peninsula in 1839, with smaller stations at Waikawa and close to the mouth of the Clutha River.

The Catlins take their name from the Catlins River, itself named for whaling captain Edward Cattlin (sometimes spelt Catlin). He purchased an extensive block of land along Catlins River on 15 February 1840 from Kāi Tahu chief Hone Tūhawaiki (also known as "Bloody Jack") for muskets and £30 (roughly NZ$3000 in 2005 dollars). New Zealand's land commissioners declined to endorse the purchase, however, and the Māori received much of the land back after long negotiations ending more than a decade after Cattlin's death.

During the mid-19th century the area developed into a major saw-milling region, supplying the newly developing town of Dunedin with timber shipped from the ports of Waikawa and Fortrose. A -long jetty was built at Fortrose in 1875, although this has long since disappeared. Several shipwrecks occurred along the treacherous coastline during this period. Most notably, one of New Zealand's worst shipping disasters occurred here: the wreck of the passenger-steamer "Tararua", en route from Bluff to Port Chalmers, which foundered off Waipapa Point on 29 April 1881 with the loss of all but 20 of the 151 people aboard.

Another noted shipwreck, that of the "Surat", occurred on New Year's Day in 1874. This ship, holed on rocks near Chasland's Mistake eight kilometres southeast of Tautuku Peninsula, limped as far as the mouth of the Catlins River before its 271 immigrants abandoned ship. A beach at the mouth of the Catlins River is named Surat Bay in commemoration of this wreck. The schooner "Wallace" and steamer "Otago" were also both wrecked at or near Chasland's Mistake, in 1866 and 1876 respectively, and a 4534-ton steamer, the "Manuka", ran aground at Long Point north of Tautuku in 1929. In all there were eight shipwrecks of note between 1839 and 1892.

After a decline in the 1890s, the logging of native timber expanded into new areas made accessible by an extension of the railway, before petering out in the mid-20th century. One nail in the industry's coffin came with a series of bushfires which destroyed several mills in 1935. The cleared land was used primarily for pastoral sheep and dairy farming, which continues to be a mainstay of the Catlins' economy. Much of the remaining forest is now protected by the Department of Conservation as part of the Catlins Conservation Park.

Medical pioneer Dr Truby King established a farm at Tahakopa and a Catlins timber mill from the 1890s to the 1920s, and gave some of his mental patients vocational training there.

From the time of the Great Depression until the formation of the New Zealand Rabbit Board in 1954, rabbits became a major pest in the area, and rabbiters were employed to keep the creatures under control. The trapping of rabbits and auctioning of their skins in Dunedin became a minor but important part of the Catlins area's economy during this time.

The area's population has declined from a peak of around 2700 in 1926 to its current level of around 1200. This decline has halted in recent decades, with 2008 figures being very similar to those of 1986.

The Catlins coast often hosts New Zealand fur seals and Hooker's sea lions, and occasionally southern elephant seals can be seen. Several species of penguin also nest along the coast, notably the rare yellow-eyed penguin ("hoiho"), as do other seabirds including mollymawks and Australasian gannets, and the estuaries of the rivers are home to herons, stilts, godwits and oystercatchers. Bitterns and the threatened fernbird ("matata") can also occasionally be seen along the reedy riverbanks.

In the forests, endangered birds such as the yellowhead ("mohua") and kakariki (New Zealand parakeet) occur, as do other birds such as the tui, fantail ("piwakawaka"), and kereru (New Zealand pigeon). One of New Zealand's only two native species of non-marine mammal, the long-tailed bat, lives in small numbers within the forests, and several species of lizard are also found locally, including the southern forest gecko.

Many species of fish, shellfish, and crustaceans frequent both the local rivers and sea, notably crayfish and paua. Nugget Point in the northern Catlins hosts a particularly rich variety of marine wildlife. The establishment of a marine reserve off the coast here, discussed in 1992, 2004 and 2015, has been controversial. Hector's dolphins can often be seen close to the Catlins coast, especially at Porpoise Bay near Waikawa, which is protected as part of the Catlins Coast Marine Mammal Sanctuary, established in 2008. Migratory southern right whales and humpback whales can be spotted along the coastline during winter.

The Catlins features dense temperate rainforest, dominated by podocarps. This is the largest area of native forest remaining on the South Island's east coast, with over of forest and neighbouring subalpine areas being protected in Catlins Conservation Park. The forest is thick with trees such as rimu, totara, silver beech, matai and kahikatea. Of particular note are the virgin rimu and totara forest remaining in those areas which were too rugged or steep to have been milled by early settlers, and an extensive area of silver beech forest close to the Takahopa River. This is New Zealand's most southerly expanse of beech forest. Many native species of forest plant can be found in the undergrowth of the Catlins forest, including young lancewoods, orchids such as the spider orchid and perching Easter orchid, and many different native ferns.

Settlers cleared much of the Catlins' coastal vegetation for farmland, but in some areas the original coastal plant life survives, primarily around cliff edges and some of the bays close to the Tautuku Peninsula, these being furthest from the landward edges of the forest. Plant life here includes many native species adapted to the strong salt-laden winds found in this exposed region. The Catlins coastal daisy ("Celmisia lindsayii") is unique to the region, and is related to New Zealand's mountain daisies. Tussocks, hebes, and flaxes are common, as are native gentians, though sadly the endangered native sedge pingao can now rarely be found. In years when the southern rātā flowers well, the coastal forest canopy turns bright red. The rātā also thrives in some inland areas.

The geology of the Catlins dates back to over 150 million years ago, when the bedrock of the New Zealand continent was being assembled by thick sediments and volcanic arcs accreting onto the edge of the Gondwana supercontinent in a series of long thin terranes. The parallel hill ranges of the Catlins form part of the Murihiku terrane, which extends inland through the Hokonui Hills as far west as Mossburn. This itself forms part of a larger system known as the Southland Syncline, a fold system which links to similar formations in Tasman District (offset by the Alpine Fault), the North Island and even New Caledonia, away.

The north-eastern boundary of this geologic region is marked by the Murihiku escarpment, which runs along the southern edge of the dormant Hillfoot fault line. The Catlins ranges are strike ridges composed of Triassic and Jurassic sandstones, mudstones and other related sedimentary rocks, often with a high incidence of feldspar. Fossils of the late and middle Triassic Warepan and Kaihikuan stages are found in the area.

Curio Bay features the petrified remains of a forest 160 million years old. This represents a remnant of the subtropical woodland that once covered the region, only to become submerged by the sea. The fossilised remnants of trees closely related to modern kauri and Norfolk pine can be seen here.

The Catlins area has very few inhabitants; the region as a whole has a population of only some 1200 people. Almost all of the Catlins' population lies either close to the route of the former state highway running from Balclutha to Invercargill (which now forms part of the Southern Scenic Route), or in numerous tiny coastal settlements, most of which have only a few dozen inhabitants.

The largest town in the Catlins, Owaka, has a population of about 400. It is located southwest of Balclutha. The only other settlements of any great size are Kaka Point (population 200), Waikawa, Tokanui, and Fortrose, which lies at the western edge of the Catlins on the estuary of the Mataura River. Most of the area's other settlements are either little more than farming communities (such as Romahapa, Maclennan, and Glenomaru) or seasonally populated holiday communities with few permanent residents. An outdoor education centre, run by the Otago Youth Adventure Trust is located at Tautuku, almost exactly halfway between Owaka and Waikawa.

The area's population has predominantly European ancestry, with 94.2% of Owaka's population belonging to the European ethnic group according to the 2001 Census, compared to 93.7% for the Otago region and 80.1% for New Zealand as a whole. The median income in the same census ranked considerably lower than for most of the country, although the unemployment rate was very low (3.2%, compared with 7.5% nationwide).

The early European economy of the Catlins during the 1830s and 1840s centred on whaling and sealing. The exploitation of the forests for timber started in the 1860s with the rapid growth of the city of Dunedin as a result of the goldrush of 1861–62. In the early 1870s more timber cargo was loaded at Owaka than at any other New Zealand port. Forestry and sawmilling declined in the late 1880s once the easily accessible timber had been removed. The extension of the railway beyond Owaka breathed new life into these industries, however, with activity peaking during the 1920s.

The land cleared of trees largely became pasture. From the 1880s, clearing of land for dairy farming increased, especially in the areas around Tahakopa and the Owaka River valley. Considerable sheep and dairy farming continues on the cleared hills on the periphery of the region, and this accounts for much of the Catlins' income. A rural polytechnic specialising in agricultural science (Telford Rural Polytechnic) is located south of Balclutha close to the northeastern edge of the Catlins.

Fishing and tourism now account for much of the area's economy. The rugged natural scenery, sense of isolation, and natural attractions such as Cathedral Caves makes the Catlins a popular destination for weekend trips by people from Dunedin and Invercargill, the two nearest cities. A large number of cribs (holiday cottages) occur at places such as Jack's Bay and Pounawea. Ecotourism is becoming increasingly important to the area's economy, with many of the visitors coming from overseas. Tourism added an estimated $2.4 million to the region's economy in 2003.

The Southern Scenic Route links Fiordland and Dunedin via the Catlins. Here it runs northeast to southwest as an alternative road to State Highway 1, which skirts the Catlins to the northwest. This section of the Southern Scenic Route—formerly designated State Highway 92 but no longer listed as a state highway—winds through most of the small settlements in the area, and was only completely sealed during the late 1990s (a stretch of about southwest of Tautuku was surfaced with gravel prior to that time). The settlements of Owaka, Maclennan, Papatowai, Tokanui, and Fortrose all lie on this route. A coastal route also parallels the inland highway between Waikawa and Fortrose, but only about two thirds of this road is sealed.

The remaining small roads in the district, all of which link with the former State Highway, have gravel surfaces. These roads mainly link the main route with small coastal settlements, although gravel roads also extend along the valleys of the Owaka and Tahakopa Rivers, linking the main Catlins route with the small towns of Clinton and Wyndham respectively. The gravelled Waikawa Valley Road crosses the hills to join the Tahakopa-Wyndham route.

Several of the area's coastal settlements have facilities for small boats, but generally only fishing and holiday craft use them; no regular passenger or freight-boat service runs to the Catlins. A railway line, the Catlins River Branch, linked the area with the South Island Main Trunk Line from the late 19th century. Construction of this line began in 1879, but it did not reach Owaka until 1896. Construction progressed slowly due to the difficult terrain, and the final terminus of the line at Tahakopa was not completed until 1915.
The economic viability of the line declined with the sawmills that it was built to serve, and the line was eventually closed in 1971. Parts of the line's route are now accessible as walkways, among them a long tunnel ("Tunnel Hill") between Owaka and Glenomaru.

The Catlins forms part of the Clutha-Southland electorate in the New Zealand Parliament. Between 1996 and 2014, the electorate was represented by Bill English of the National Party, who was Prime Minister of New Zealand and a former Leader of the Opposition. The Catlins area is split between the Clutha and Southland Districts for local government purposes.

Most of the Catlins falls in the Clutha District, based in Balclutha, and one of the council's fourteen representatives is elected directly from a Catlins Ward which is roughly coterminous with this area. The Clutha District is itself part of the Otago Region, controlled administratively by the Otago Regional Council (ORC) in Dunedin, to the northeast of Balclutha. The Molyneux Constituency of the ORC, which covers roughly the same area as the Clutha District, elects two councillors to the 12-member Regional Council.

Approximately the westernmost one-third of the Catlins area lies in the Southland District, based in Invercargill, to the west of Fortrose. One of the council's 12 elected members represents the Toetoes Ward, which contains this part of the Catlins, along with an area around Wyndham and extending along Toetoes Bay towards the Awarua Plain. The Southland District is itself part of the Southland Region, controlled administratively by the Southland Regional Council (SRC; also known as "Environment Southland"), which is also based in Invercargill. The Southern Constituency of the SRC, which covers the entire Toetoes Ward and extends across the Awarua Plain almost as far as Bluff in the west and Mataura in the north, elects one councillor to the 12-member Regional Council.

The Catlins area hosts four co-educational schools: Tahakopa School, Tokanui School, and Romahapa School, all of which are primary schools; The Catlins Area School, Owaka is a combined primary and secondary school. It is the only one of the four with more than 100 pupils. The nearest dedicated secondary schools are South Otago High School in Balclutha and Menzies College in Wyndham.

The nearest tertiary institution is Telford Rural Polytechnic, located at the edge of the Catlins at Otanomomo, south of Balclutha. Other than this, the nearest tertiary establishments are in Invercargill and Dunedin, the nearest university being the University of Otago in Dunedin.

A hospital opened in Owaka in 1924, offering a decreasing range of services until its closure during the 1980s. The building and grounds now host a youth hostel and holiday park. Today, Owaka is served by a medical centre and a pharmacy. The Southern District Health Board is responsible for most publicly funded health services in Otago and Southland, including the Catlins.

The nearest hospital to most of the area is the community owned Clutha Health First, in Balclutha. There is another small hospital in Gore, a secondary level hospital in Invercargill, and a tertiary level hospital (Dunedin Public Hospital) in Dunedin. The last two are also university teaching hospitals.




</doc>
<doc id="952246" url="https://en.wikipedia.org/wiki?curid=952246" title="Canadian National Vimy Memorial">
Canadian National Vimy Memorial

The Canadian National Vimy Memorial is a war memorial site in France dedicated to the memory of Canadian Expeditionary Force members killed during the First World War. It also serves as the place of commemoration for Canadian soldiers of the First World War killed or presumed dead in France who have no known grave. The monument is the centrepiece of a preserved battlefield park that encompasses a portion of the ground over which the Canadian Corps made their assault during the initial Battle of Vimy Ridge offensive of the Battle of Arras.

The Battle of Vimy Ridge was the first time all four divisions of the Canadian Expeditionary Force participated in a battle as a cohesive formation, and it became a Canadian national symbol of achievement and sacrifice. France ceded to Canada perpetual use of a portion of land on Vimy Ridge on the understanding that Canada use the land to establish a battlefield park and memorial. Wartime tunnels, trenches, craters, and unexploded munitions still honeycomb the grounds of the site, which remains largely closed off for reasons of public safety. Along with preserved trench lines, several other memorials and cemeteries are contained within the park.

The project took designer Walter Seymour Allward eleven years to build. King Edward VIII unveiled it on 26 July 1936 in the presence of French President Albert Lebrun and a crowd of over 50,000 people, including 6,200 attendees from Canada. Following an extensive multi-year restoration, Queen Elizabeth II re-dedicated the monument on 9 April 2007 at a ceremony commemorating the 90th anniversary of the battle. The site is maintained by Veterans Affairs Canada. The Vimy Memorial is one of only two National Historic Sites of Canada located outside the country, the other being the Beaumont-Hamel Newfoundland Memorial.

Vimy Ridge is a gradually rising escarpment on the western edge of the Douai Plains, northeast of Arras. The ridge gradually rises on its western side, dropping more quickly on the eastern side. The ridge is approximately in length, wide at its narrowest point, and culminates at an elevation of above sea level, or above the Douai Plains, providing a natural unobstructed view for tens of kilometres in all directions.

The ridge fell under German control in October 1914, during the Race to the Sea, as the Franco-British and German forces continually attempted to outflank each other through northeastern France. The French Tenth Army attempted to dislodge the Germans from the region during the Second Battle of Artois in May 1915 by attacking their positions at Vimy Ridge and Notre Dame de Lorette. During the attack, the French 1st Moroccan Division briefly captured the height of the ridge, where the Vimy memorial is currently located, but was unable to hold it owing to a lack of reinforcements. The French made another attempt during the Third Battle of Artois in September 1915, but were once again unsuccessful in capturing the top of the ridge. The French suffered approximately 150,000 casualties in their attempts to gain control of Vimy Ridge and surrounding territory.

The British XVII Corps relieved the French Tenth Army from the sector in February 1916. On 21 May 1916, the German infantry attacked the British lines along a front in an effort to force them from positions along the base of the ridge. The Germans captured several British-controlled tunnels and mine craters before halting their advance and entrenching their positions. Temporary Lieutenant Richard Basil Brandram Jones was posthumously awarded the Victoria Cross for his ultimately unsuccessful defence of the Broadmarsh Crater during the attack. British counter-attacks on 22 May did not manage to change the situation. The Canadian Corps relieved the British IV Corps stationed along the western slopes of Vimy Ridge in October 1916.

The Battle of Vimy Ridge was the first instance in which all four Canadian divisions participated in a battle together, as a cohesive formation. The nature and size of the planned Canadian Corps assault necessitated support and resources beyond its normal operational capabilities. Consequently, the British 5th Infantry Division and supplementary artillery, engineer and labour units reinforced the four Canadian divisions already in place. The 24th British Division of I Corps supported the Canadian Corps along its northern flank while the XVII Corps did so to the south. The ad hoc formation, based under I Bavarian Reserve Corps commander Karl Ritter von Fasbender, was the principal defending formation with three divisions responsible for manning the frontline defences opposite the Canadian Corps.
The attack began at 5:30 am on Easter Monday, 9 April 1917. Light field guns laid down a barrage that advanced in predetermined increments, often every three minutes, while medium and heavy howitzers established a series of standing barrages against known defensive systems further ahead. The 1st, 2nd, and 3rd Canadian Divisions quickly captured their first objectives. The 4th Canadian Division encountered a great deal of trouble during its advance and was unable to complete its first objective until some hours later. The 1st, 2nd, and 3rd Canadian Divisions captured their second objective by approximately 7:30 am. The failure of the 4th Canadian Division to capture the top of the ridge delayed further advances and forced the 3rd Canadian Division to expend resources establishing a defensive line to its north. Reserve units from the 4th Canadian Division renewed the attack on the German positions on the top of the ridge and eventually forced the German troops holding the southwestern portion of Hill 145 to withdraw.

On the morning of 10 April, Canadian Corps commander Lieutenant-General Julian Byng moved up three fresh brigades to support the continued advance. The fresh units leapfrogged units already in place and captured the third objective line, including Hill 135 and the town of Thélus, by 11:00 am. By 2:00 pm both the 1st and 2nd Canadian Divisions reported capturing their final objectives. By this point the "Pimple", a heavily defended knoll west of the town of Givenchy-en-Gohelle, was the only German position remaining on Vimy Ridge. On 12 April, the 10th Canadian Brigade attacked and quickly overcame the hastily entrenched German troops, with the support of artillery and the 24th British Division. By nightfall on 12 April, the Canadian Corps was in firm control of the ridge. The Canadian Corps suffered 10,602 casualties: 3,598 killed and 7,004 wounded. The German Sixth Army suffered an unknown number of casualties, and around 4,000 men became prisoners of war.

Although the battle is not generally considered Canada's greatest military achievement, the image of national unity and achievement imbued the battle with considerable national significance for Canada. According to Pierce, "the historical reality of the battle has been reworked and reinterpreted in a conscious attempt to give purpose and meaning to an event that came to symbolize Canada's coming of age as a nation." The idea that Canada's identity and nationhood were born out of the battle is an opinion that is widely held in military and general histories of Canada.

In 1920, the Government of Canada announced that the Imperial War Graves Commission had awarded Canada eight sites—five in France and three in Belgium—on which to erect memorials. Each site represented a significant Canadian engagement, and the Canadian government initially decided that each battlefield be treated equally and commemorated with identical monuments. In September 1920, the Canadian government formed the Canadian Battlefields Memorials Commission to discuss the process and conditions for holding a memorial competition for the sites in Europe. The commission held its first meeting on 26 November 1920 and during this meeting decided that the architectural design competition would be open to all Canadian architects, designers, sculptors, and artists. The jury consisted of Charles Herbert Reilly representing the Royal Institute of British Architects, Paul Philippe Cret representing the Société centrale des architectes français and Frank Darling representing the Royal Architectural Institute of Canada. Each jury member was a leader in the architectural field; Reilly was training students in design and development of war memorials, and Cret had been selected by the United States to design national monuments in Europe. Interested parties submitted 160 design drawings, and the jury selected 17 submissions for consideration, commissioning each finalist to produce a plaster maquette of their respective design. The jury recommended in a 10 September 1921 report to the commission that two of the designs be executed. In October 1921, the commission formally selected the submission of Toronto sculptor and designer Walter Seymour Allward as the winner of the competition; the design submitted by Frederick Chapman Clemesha was selected as runner-up. The complexity of Allward's design precluded the possibility of duplicating the design at each site. The approach of selecting one primary memorial ran counter to the recommendation of Canadian Battlefields Memorials Commission architectural advisor Percy Erskine Nobbs, who had consistently expressed his preference for a series of smaller monuments. The consensus went in Allward's favour, his design receiving both public and critical approval. The commission revised its initial plans and decided to build two distinctive memorials—those of Allward and Clemesha—and six smaller identical memorials.
At the outset, members of the commission debated where to build Allward's winning design. The jury's assessment was that Allward's submission was best suited to a "low hill rather than to a continuous and lofty bluff or cliff like Vimy Ridge". The commission committee initially recommended placing the monument in Belgium on Hill 62, near the location of the Battle of Mont Sorrel, as the site provided an imposing view. This ran counter to the desires of Prime Minister William Lyon Mackenzie King who, while speaking in the House of Commons of Canada in May 1922, argued in favour of placing the memorial at Vimy Ridge. King's position received the unanimous support of the House and, in the end, the commission selected Vimy Ridge as the preferred site. The government announced its desire to acquire a more considerable tract of land along the ridge after the commission selected Vimy Ridge as the preferred location for Allward's design. In the interval between the 1st and 2nd session of the 14th Canadian Parliament, Speaker of the House of Commons of Canada Rodolphe Lemieux went to France to negotiate the acquisition of more land. On 5 December 1922, Lemieux concluded an agreement with France in which France granted Canada "freely and for all time" the use of of land on Vimy Ridge, inclusive of Hill 145, in recognition of Canada's war effort. The only condition placed on the donation was that Canada use the land to erect a monument commemorating Canadian soldiers killed during the First World War and assume the responsibility for the maintenance of the memorial and the surrounding battlefield park.

Following the competition, Allward spent the remainder of 1921 and the spring of 1922 preparing for his move to Europe. After selling his home and studio, Allward finally departed for Belgium on 6 June 1922 and spent several months seeking a suitable studio in Belgium and then Paris, though he eventually set up a studio in London.

Allward had initially hoped to use white marble for the memorial's facing stone, but Percy Nobbs suggested this would be a mistake because marble was unlikely to weather well in northern France and the memorial would have a "ghost like" appearance. Allward undertook a tour of almost two years to find stone of the right colour, texture, and luminosity. He found it in the ruins of Diocletian's Palace at Split, Croatia; he observed that the palace had not weathered over the years, which Allward took as evidence of the stone's durability. His choice—Seget limestone—came from an ancient Roman quarry located near Seget, Croatia. The difficulties with the quarrying process, coupled with complicated transportation logistics, delayed delivery of the limestone and thus construction of the memorial. The first shipment did not arrive at the site until 1927, and the larger blocks, intended for the human figures, did not begin to arrive until 1931.

On Allward's urging the Canadian Battlefields Memorials Commission hired Oscar Faber, a Danish structural engineer, in 1924 to prepare foundation plans and provide general supervision of the foundation work. Faber had recently designed the substructure for the Menin Gate at Ypres, and he selected a design that employed cast-in-place reinforced concrete to which the facing stone would be bonded. Major Unwin Simson served as the principal Canadian engineer during the construction of the memorial and oversaw much of the daily operations at the site. Allward moved to Paris in 1925 to supervise construction and the carving of the sculptures. Construction commenced in 1925 and took eleven years to complete. The Imperial War Graves Commission concurrently employed French and British veterans to carry out the necessary roadwork and site landscaping.

While awaiting the first delivery of stone, Simson noticed that the battlefield landscape features were beginning to deteriorate. Seeing an opportunity to not only preserve a portion of the battlefield but also keep his staff occupied, Simson decided to preserve a short section of trench line and make the Grange Subway more accessible. Labourers rebuilt and preserved sections of sandbagged trench wall, on both the Canadian and German sides of the Grange crater group, in concrete. The workforce also built a new concrete entrance for the Grange Subway and, after excavating a portion of the tunnel system, installed electric lighting.
Allward chose a relatively new construction method for the monument: limestone bonded to a cast concrete frame. A foundation bed of 11,000 tonnes of concrete, reinforced with hundreds of tonnes of steel, served as the support bed for the memorial. The memorial base and twin pylons contained almost 6,000 tonnes of Seget limestone. Sculptors carved the 20 approximately double life-sized human figures on site from large blocks of stone. The carvers used half-size plaster models produced by Allward in his studio, now on display at the Canadian War Museum, and an instrument called a pantograph to reproduce the figures at the proper scale. The carvers conducted their work year-round inside temporary studios built around each figure. The inclusion of the names of those killed in France with no known grave was not part of the original design, and Allward was unhappy when the government asked him to include them. Allward argued that the inclusion of names was not part of the original commissioning. Through a letter to Canadian Battlefields Memorials Commission in October 1927, Allward indicated his intention to relegate the names of the missing to pavement stones around the monument. The collective dismay and uproar of the commission forced Allward to relent and incorporate the names of the missing on the memorial walls. The task of inscribing the names did not begin until the early 1930s and employed a typeface that Allward designed for the monument.
In 1919, the year after the war ended, around 60,000 British tourists and mourners made pilgrimages to the Western Front. The transatlantic voyage was longer and more expensive from Canada; many attempts to organize large pilgrimages failed, and journeys overseas were largely made individually or in small, unofficial groups. The delegates of the 1928 national convention of the Canadian Legion passed a unanimous resolution asking that a pilgrimage be organized to the Western Front battlefields. A plan began to take form wherein the Legion aimed to coordinate the pilgrimage with the unveiling of the Vimy memorial, which at the time was expected to be completed in 1931 or 1932. Due to construction delays with the memorial, it was not until July 1934 that the Canadian Legion announced a pilgrimage to former battlefield sites in conjunction with the unveiling of the memorial. Although the exact date of the memorial unveiling was still not set, the Legion invited former service members to make tentative reservations with their headquarters in Ottawa. The response from veterans and their families was enthusiastic—1,200 inquiries by November 1934. The Legion presumptuously announced that the memorial would be unveiled on Dominion Day, 1 July 1936, even though the government still did not know when it would be completed.

For event planning purposes, the Legion and the government established areas for which each was responsible. The government was responsible for selection of the official delegation and the program for the official unveiling of the memorial. The Legion was responsible for the more challenging task of organizing the pilgrimage. For the Legion this included planning meals, accommodations and transportation for what was at the time the largest single peacetime movement of people from Canada to Europe. The Legion took the position that the pilgrimage would be funded by its members without subsidies or financial aid from Canadian taxpayers, and by early 1935 they had established that the price of the 3½-week trip, inclusive of all meals, accommodation, health insurance, and sea and land transportation would be per person ($ as of 2016). Indirect assistance came in a number of forms. The government waived passport fees and made a special Vimy passport available to pilgrims at no extra cost. The government and private sector also provided paid leave for their participating employees. It was not until April 1936 that the government was prepared to publicly commit to an unveiling date, 26 July 1936. On 16 July, the five transatlantic liners, escorted by and , departed the Port of Montreal with approximately 6,200 passengers and arrived in Le Havre on 24 and 25 July. The limited accommodation made it necessary for the Legion to lodge pilgrims in nine cities throughout northern France and Belgium and employ 235 buses to move the pilgrims between various locations.

On 26 July, the day of the ceremony, pilgrims spent the morning and early afternoon exploring the landscape of the memorial park before congregating at the monument. For the ceremony, sailors from HMCS "Saguenay" provided the guard of honour. Also present were The Royal Canadian Horse Artillery Band, French army engineers, and French-Moroccan cavalry who had fought on the site during the Second Battle of Artois. The ceremony itself was broadcast live by the Canadian Radio Broadcasting Commission over shortwave radio, with facilities of the British Broadcasting Corporation transmitting the ceremony to Canada. Senior Canadian, British, and European officials, including French President Albert Lebrun, and a crowd of over 50,000 attended the event. Absent, though, was Canadian Prime Minister William Lyon Mackenzie King, it being well understood that he was generally not comfortable around veterans and felt it more appropriate for a war veteran in Cabinet to act as minister in attendance.

Before the ceremony began, King Edward VIII, present in his capacity as king of Canada, inspected the guard of honour, was introduced to the honoured guests, and spent approximately half an hour speaking with veterans in the crowd. Two Royal Air Force and two French Air Force squadrons flew over the monument and dipped their wings in salute. The ceremony itself began with prayers from chaplains representing the Church of England, the United Church of Canada, and the Roman Catholic Church. Ernest Lapointe, Canadian Minister of Justice, spoke first, followed by Edward VIII who, in both French and English, thanked France for its generosity and assured those assembled that Canada would never forget its war missing and dead. The King then pulled the Royal Union Flag from the central figure of "Canada Bereft" and the military band played the Last Post. The ceremony was one of the King's few official duties before he abdicated the throne. The pilgrimage continued, and most participants toured Ypres before being taken to London to be hosted by the British Legion. One-third of the pilgrims left from London for Canada on 1 August, while the majority returned to France as guests of the government for another week of touring before going home.

In 1939, the increased threat of conflict with Nazi Germany amplified the Canadian government's level of concern for the general safety of the memorial. Canada could do little more than protect the sculptures and the bases of the pylons with sandbags and await developments. When war did break out in September 1939, the British Expeditionary Force (BEF) deployed to France and assumed responsibility for the Arras sector, which included Vimy. In late May 1940, following the British retreat to Dunkirk after the Battle of Arras, the status and condition of the memorial became unknown to Allied forces. The Germans took control of the site and held the site's caretaker, George Stubbs, in an Ilag internment camp for Allied civilians in St. Denis, France. The rumoured destruction of the Vimy Memorial, either during the fighting or at the hands of the Germans, was widely reported in Canada and the United Kingdom. The rumours led the German Ministry of Public Enlightenment and Propaganda to formally deny accusations that Germany had damaged or desecrated the memorial. To demonstrate the memorial had not been desecrated, Adolf Hitler, who reportedly admired the memorial for its peaceful nature, was photographed by the press while personally touring it and the preserved trenches on 2 June 1940. The undamaged state of the memorial was not confirmed until September 1944 when British troops of the 2nd Battalion, Welsh Guards of the Guards Armoured Division recaptured Vimy Ridge.

Immediately following the Second World War, very little attention was paid to the Battle of Vimy Ridge or the Vimy Memorial. The "Winnipeg Free Press" and "The Legionary", the magazine of the Royal Canadian Legion, were the only publications to note the 35th anniversary of the battle in 1952. The 40th anniversary in 1957 received even less notice, with only the "Halifax Herald" making any mention. Interest in commemoration remained low in the early 1960s but increased in 1967 with the 50th anniversary of the battle, paired with the Canadian Centennial. A heavily attended ceremony at the memorial in April 1967 was broadcast live on television. Commemoration of the battle decreased once again throughout the 1970s and only returned in force with the 125th anniversary of Canadian Confederation and the widely covered 75th anniversary of the battle in 1992. The 1992 ceremony at the memorial was attended by Canadian Prime Minister Brian Mulroney and at least 5,000 people. Subsequent smaller-scale ceremonies were held at the memorial in 1997 and 2002.

By the end of the century, the many repairs undertaken since the memorial's construction had left a patchwork of materials and colours, and a disconcerting pattern of damage from water intrusion at the joints. In May 2001, the Government of Canada announced the Canadian Battlefield Memorials Restoration Project, a major C$30 million restoration project to restore Canada's memorial sites in France and Belgium, in order to maintain and present them in a respectful and dignified manner. In 2005, the Vimy memorial closed for major restoration work. Veterans Affairs Canada directed the restoration of the memorial in cooperation with other Canadian departments, the Commonwealth War Graves Commission, consultants and specialists in military history.

Time, wear, and severe weather conditions led to many identified problems, the single most pervasive being water damage. In building a memorial made of cast concrete covered in stone, Allward had failed to take into account how these materials would shift over time. The builders and designer failed to incorporate sufficient space between the concrete and stones, which resulted in water infiltrating the structure through its walls and platforms, dissolving lime in the concrete foundation and masonry. As the water exited, it deposited the lime on exterior surfaces, obscuring many of the names inscribed thereon. Poor drainage and water flows off the monument also caused significant deterioration of the platform, terrace, and stairs. The restoration project intended to address the root causes of damage and included repairs to the stone, walkways, walls, terraces, stairs, and platforms. In order to respect Allward's initial vision of a seamless structure, the restoration team were required to remove all foreign materials employed in patchwork repairs, replace damaged stones with material from the original quarry in Croatia, and correct all minor displacement of stones caused by the freeze-thaw activity. Underlying structural flaws were also corrected.

Queen Elizabeth II, escorted by Prince Philip, Duke of Edinburgh, rededicated the restored memorial on 9 April 2007 in a ceremony commemorating the 90th anniversary of the battle. Other senior Canadian officials, including Prime Minister Stephen Harper, and senior French representatives, Prime Minister Dominique de Villepin among them, attended the event, along with thousands of Canadian students, veterans of the Second World War and of more recent conflicts, and descendants of those who fought at Vimy. The crowd attending the rededication ceremony was the largest crowd on the site since the 1936 dedication.

The centennial commemoration of the Battle of Vimy Ridge took place at the memorial on 9 April 2017, coincidentally during the Canadian sesquicentennial celebrations. Estimates before the event indicated that an audience of up to 30,000 would be present. The Mayor of Arras, Frédéric Leturque, thanked Canadians, along with Australians, Britons, New Zealanders and South Africans, for their role in the First World War battles in the area.

Attending dignitaries for Canada included Governor General David Johnston; Prince Charles; Prince William, Duke of Cambridge; Prince Harry; and Prime Minister Justin Trudeau. President François Hollande and Prime Minister Bernard Cazeneuve represented France. Elizabeth II issued a statement via the Governor General, remarking "[Canadians] fought courageously and with great ingenuity in winning the strategic high point of Vimy Ridge, though victory came at a heavy cost".

Two postage stamps are being released jointly by Canada Post and France's La Poste featuring the memorial, one designed by each country, to commemorate the centennial of the Battle of Vimy Ridge.

The Canadian National Vimy Memorial site is located approximately north of Arras, France, circled by the small towns and communes of Vimy to the east, Givenchy-en-Gohelle to the north, Souchez to the northwest, Neuville-Saint-Vaast to the south and Thélus to the southeast. The site is one of the few places on the former Western Front where a visitor can see the trench lines of a First World War battlefield and the related terrain in a preserved natural state. The total area of the site is , much of which is forested and off limits to visitors to ensure public safety. The site's rough terrain and buried unexploded munitions make the task of grass cutting too dangerous for human operators. Instead, sheep graze the open meadows of the site.

The site was established to honour the memory of the Canadian Corps, but it also contains other memorials. These are dedicated to the French Moroccan Division, Lions Club International, and Lieutenant-Colonel Mike Watkins. There are also two Commonwealth War Graves Commission cemeteries on site: Canadian Cemetery No. 2 and Givenchy Road Canadian Cemetery. Beyond being a popular location for battlefield tours, the site is also an important location in the burgeoning field of First World War battlefield archaeology, because of its preserved and largely undisturbed state. The site's interpretive centre helps visitors fully understand the Vimy Memorial, the preserved battlefield park, and the history of the Battle of Vimy within the context of Canada's participation in the First World War. The Canadian National Vimy Memorial and Beaumont-Hamel Newfoundland Memorial sites comprise close to 80 percent of conserved First World War battlefields in existence and between them receive over one million visitors each year.

Allward constructed the memorial on the vantage point of Hill 145, the highest point on the ridge. The memorial contains many stylized features, including 20 human figures, which help the viewer in contemplating the structure as a whole. The front wall, normally mistaken for the rear, is high and represents an impenetrable wall of defence. There is a group of figures at each end of the front wall, next to the base of the steps. The "Breaking of the Sword" is located at the southern corner of the front wall while "Sympathy of the Canadians for the Helpless" is located at the northern corner. Collectively, the two groups are "The Defenders" and represent the ideals for which Canadians gave their lives during the war. There is a cannon barrel draped in laurel and olive branches carved into the wall above each group, to symbolize victory and peace. In "Breaking of the Sword", three young men are present, one of whom is crouching and breaking his sword. This statue represents the defeat of militarism and the general desire for peace. This grouping of figures is the most overt image to pacifism in the monument, the breaking of a sword being extremely uncommon in war memorials. The original plan for the sculpture included one figure crushing a German helmet with his foot. It was later decided to dismiss this feature because of its overtly militaristic imagery. In "Sympathy of the Canadians for the Helpless", one man stands erect while three other figures, stricken by hunger or disease, are crouched and kneeling around him. The standing man represents Canada's sympathy for the weak and oppressed.

The figure of a cloaked young woman stands on top and at the centre of the front wall and overlooks the Douai Plains. She has her head bowed, her eyes cast down, and her chin resting in one hand. Below her at ground level is a sarcophagus, bearing a Brodie helmet and a sword, and draped in laurel branches. The saddened figure of "Canada Bereft", also known as "Mother Canada", is a national personification of the young nation of Canada, mourning her dead. The statue, a reference to traditional images of the and presented in a similar style to that of Michelangelo's Pietà, faces eastward looking out to the dawn of the new day. Unlike the other statues on the monument, stonemasons carved "Canada Bereft" from a single 30 tonne block of stone. The statue is the largest single piece in the monument and serves as a focal point. The area in front of the memorial was turned into a grassed space, which Allward referred to as the amphitheatre, that fanned out from the monument's front wall for a distance of while the battle-damaged landscape around the sides and back of the monument were left untouched.
The twin pylons rise to a height 30 metres above the memorial's stone platform; one bears the maple leaf for Canada and the other the fleur-de-lis for France, and both symbolize the unity and sacrifice of the two countries. At the top of the pylons is a grouping of figures known collectively as the "Chorus". The most senior figures represent "Justice" and "Peace"; "Peace" stands with a torch upraised, making it the highest point in the region. The pair is in a style similar to Allward's previously commissioned statues of "Truth" and "Justice", located outside the Supreme Court of Canada in Ottawa. The remainder of the "Chorus" is located directly below the senior figures: "Faith", "Hope" and "Truth" on the eastern pylon; and "Honour", "Charity" and "Knowledge" on the western pylon. Around these figures are shields of Canada, Britain, and France. Large crosses adorn the outside of each pylon. The First World War battle honours of the Canadian regiments, and a dedicatory message to Canada's war dead in both French and English are located at the base of the pylons. The "Spirit of Sacrifice" is located at the base between the two pylons. In the display, a young dying soldier is gazing upward in a crucifixion-like pose, having thrown his torch to a comrade who holds it aloft behind him. In a lightly veiled reference to the poem "In Flanders Fields" by John McCrae, the torch is passed from one comrade to another in an effort to keep alive the memory of the war dead.

The Mourning Parents, one male and one female figure, are reclining on either side of the western steps on the reverse side of the monument. They represent the mourning mothers and fathers of the nation and are likely patterned on the four statues by Michelangelo on the Medici Tomb in Florence. Inscribed on the outside wall of the monument are the names of the 11,285 Canadians killed in France whose final resting place is unknown. Most Commonwealth War Graves Commission memorials present names in a descending list format in a manner that permits the modification of panels as remains are found and identified. Allward instead sought to present the names as a seamless list and decided to do so by inscribing the names in continuous bands, across both vertical and horizontal seams, around the base of the monument. As a consequence, as remains were discovered it was not possible to remove commemorated names without interrupting the seamless list, and as a consequence there are individuals who have a known grave but are commemorated on the memorial. The memorial contains the names of four posthumous Victoria Cross recipients; Robert Grierson Combe, Frederick Hobson, William Johnstone Milne, and Robert Spall.

The Moroccan Division Memorial is dedicated to the memory of the French and Foreign members of the Moroccan Division, killed during the Second Battle of Artois in May 1915. The monument was raised by veterans of the division and inaugurated on 14 June 1925, having been built without planning permission. Excluding the various commemorative plaques at the bottom front facade of the memorial, campaign battles are inscribed on the left- and right-hand side corner view of the memorial. The veterans of the division later funded the April 1987 installation of a marble plaque that identified the Moroccan Division as the only division where all subordinate units had been awarded the Legion of Honour.

The Moroccan Division was initially raised as the Marching Division of Morocco. The division comprised units of varying origins and although the name would indicate otherwise, it did not in fact contain any units originating from Morocco. Moroccans were part of the Marching Regiment of the Foreign Legion which was formed from the merger of the 2nd Marching Regiment of the 1st Foreign Regiment with the 2nd Marching Regiment of the 2nd Foreign Regiment, both also part of the Moroccan Division Brigades. The division contained Tirailleurs and Zouaves, of principally Tunisian and Algerian origin, and most notably Legionnaires from the 2nd Marching Regiment of the 1st Foreign Regiment and the 7th Algerian Tirailleurs Regiment. The French Legionnaires came, as attested to by a plaque installed on the memorial, from 52 different countries and included amongst them American, Polish, Russian, Italian, Greek, German, Czechoslovakian, Swedish, Armenian, various nationals of the Jewish faith (http://monumentsmorts.univ-lille3.fr/monument/2892/givenchyengohelle-autre/), and Swiss volunteers such as writer Blaise Cendrars.

In the battle, General Victor d'Urbal, commander of the French Tenth Army, sought to dislodge the Germans from the region by attacking their positions at Vimy Ridge and Notre Dame de Lorette. When the attack began on 9 May 1915, the French XXXIII Army Corps made significant territorial gains. The Moroccan Division, which was part of the XXXIII Army Corps, quickly moved through the German defences and advanced into German lines in two hours. The division managed to capture the height of the ridge, with small parties even reaching the far side of the ridge, before retreating due to a lack of reinforcements. Even after German counter-attacks, the division managed to hold a territorial gain of . The division did however suffer heavy casualties. Those killed in the battle and commemorated on the memorial include both of the division's brigade commanders, Colonels Gaston Cros and Louis Augustus Theodore Pein.

The First World War's Western Front included an extensive system of underground tunnels, subways, and dugouts. The Grange Subway is a tunnel system that is approximately in length and once connected the reserve lines to the front line. This permitted soldiers to advance to the front quickly, securely, and unseen. A portion of this tunnel system is open to the public through regular guided tours provided by Canadian student guides.

The Arras-Vimy sector was conducive to tunnel excavation owing to the soft, porous yet extremely stable nature of the chalk underground. As a result, pronounced underground warfare had been a feature of the Vimy sector since 1915. In preparation for the Battle of Vimy Ridge, five British tunnelling companies excavated 12 subways along the Canadian Corps' front, the longest of which was in length. The tunnellers excavated the subways at a depth of 10 metres to ensure protection from large calibre howitzer shellfire. The subways were often dug at a pace of four metres a day and were often two metres tall and one metre wide. This underground network often incorporated or included concealed light rail lines, hospitals, command posts, water reservoirs, ammunition stores, mortar and machine gun posts, and communication centres.

Near the Canadian side of the restored trenches is a small memorial plaque dedicated to Lieutenant-Colonel Mike Watkins MBE. Watkins was head of Explosive Ordnance Disposal at the Directorate of Land Service Ammunition, Royal Logistic Corps, and a leading British explosive ordnance disposal expert. In August 1998, he died in a roof collapse near a tunnel entrance while undertaking a detailed investigative survey of the British tunnel system on the grounds of the Canadian National Vimy Memorial site. Watkins was no stranger to the tunnel system at Vimy Ridge. Earlier the same year, he participated in the successful disarming of 3 tonnes of deteriorated ammonal explosives located under a road intersection on the site.

The site has a visitors' centre, staffed by Canadian student guides, which is open seven days a week. During the memorial restoration, the original visitors' centre near the monument was closed and replaced with a temporary one, which remains in use today. The visitors' centre is now near the preserved forward trench lines, close to many of the craters created by underground mining during the war and near the entrance of the Grange Subway. Construction of a new educational visitors' centre is expected to be completed by April 2017, in advance of the 100th anniversary of the battle. The new million visitor centre is a public-private partnership between government and the Vimy Foundation. In order to raise funds the Vimy Foundation granted naming rights in various halls of the visitor centre to sponsors, an approach which has met some level of controversy due to the site being a memorial park.

The Canadian National Vimy Memorial site has considerable sociocultural significance for Canada. The idea that Canada's national identity and nationhood were born out of the Battle of Vimy Ridge is an opinion that is widely repeated in military and general histories of Canada. Historian Denise Thomson suggests that the construction of the Vimy memorial represents the culmination of an increasingly assertive nationalism that developed in Canada during the interwar period. Hucker suggests that the memorial transcends the Battle of Vimy Ridge and now serves as an enduring image of the whole First World War, while expressing the enormous impact of war in general, and also considers that the 2005 restoration project serves as evidence of a new generation's determination to remember Canada's contribution and sacrifice during the First World War.

The Historic Sites and Monuments Board of Canada recognized the importance of the site by recommending its designation as one of the National Historic Sites of Canada; it was so designated in 1996, and is one of only two outside of Canada. The other is the Beaumont-Hamel Newfoundland Memorial, also in France. Remembrance has also taken other forms: the Vimy Foundation, having been established to preserve and promote Canada's First World War legacy as symbolized by the victory at the Battle of Vimy Ridge, and Vimy Ridge Day, to commemorate the deaths and casualties during the battle. Local Vimy resident Georges Devloo spent 13 years until his death in 2009 offering car rides to Canadian tourists to and from the memorial at no charge, as a way of paying tribute to the Canadians who fought at Vimy.

The memorial is not without its critics. Alana Vincent has argued that constituent parts of the monument are in conflict, and as a result the message conveyed by the monument is not unified. Visually, Vincent argues there is a dichotomy between the triumphant pose of the figures at the top of the pylons and the mourning posture of those figures at the base. Textually, she argues the inscription text celebrating the victory at the Battle of Vimy Ridge strikes a very different tone to the list of names of the missing at the base of the monument.
The memorial is regularly the subject or inspiration of other artistic projects. In 1931, Will Longstaff painted "Ghosts of Vimy Ridge", depicting ghosts of men from the Canadian Corps on Vimy Ridge surrounding the memorial, though the memorial was still several years away from completion. The memorial has been the subject of stamps in both France and Canada, including a French series in 1936 and a Canadian series on the 50th anniversary of the Armistice of 11 November 1918. The Canadian "Unknown Soldier" was selected from a cemetery in the vicinity of the Canadian National Vimy Memorial, and the design of the Canadian Tomb of the Unknown Soldier is based upon the stone sarcophagus at the base of the Vimy memorial. The Never Forgotten National Memorial was intended to be a statue inspired by the "Canada Bereft" statue on the memorial, before the project was cancelled in February 2016. A 2001 Canadian historical novel "The Stone Carvers" by Jane Urquhart involves the characters in the design and creation of the memorial. In 2007, the memorial was a short-listed selection for the Seven Wonders of Canada. The Royal Canadian Mint released commemorative coins featuring the memorial on several occasions, including a 5 cent sterling silver coin in 2002 and a 30 dollar sterling silver coin in 2007. The Sacrifice Medal, a Canadian military decoration created in 2008, features the image of "Mother Canada" on the reverse side of the medal. A permanent bas relief sculpted image of the memorial is presented in the gallery of the grand hall of the Embassy of France in Canada to symbolize the close relations between the two countries. The memorial is featured on the reverse of the Frontier Series Canadian polymer $20 banknote, which was released by the Bank of Canada on 7 November 2012.




</doc>
<doc id="954222" url="https://en.wikipedia.org/wiki?curid=954222" title="Isabeau of Bavaria">
Isabeau of Bavaria

Isabeau of Bavaria (or Isabelle; also Elisabeth of Bavaria-Ingolstadt; c. 1370 – 24 September 1435) was born into the House of Wittelsbach as the eldest daughter of Duke Stephen III of Bavaria-Ingolstadt and Taddea Visconti of Milan. She became Queen of France when she married King Charles VI in 1385. At age 15 or 16, Isabeau was sent to France on approval to the young French king; the couple wed three days after their first meeting.

Isabeau was honored in 1389 with a lavish coronation ceremony and entry into Paris. In 1392 Charles suffered the first attack of what was to become a lifelong and progressive mental illness, resulting in periodic withdrawal from government. The episodes occurred with increasing frequency, leaving a court both divided by political factions and steeped in social extravagances. A 1393 masque for one of Isabeau's ladies-in-waiting—an event later known as "Bal des Ardents"—ended in disaster with the King almost burning to death. Although the King demanded Isabeau's removal from his presence during his illness, he consistently allowed her to act on his behalf. In this way she became regent to the Dauphin of France (heir apparent), and sat on the regency council, allowing far more power than was usual for a medieval queen.

Charles' illness created a power vacuum that eventually led to the Armagnac–Burgundian Civil War between supporters of his brother, Louis of Orléans and the royal dukes of Burgundy. Isabeau shifted allegiances as she chose the most favorable paths for the heir to the throne. When she followed the Armagnacs, the Burgundians accused her of adultery with Louis of Orléans; when she sided with the Burgundians the Armagnacs removed her from Paris and she was imprisoned. In 1407 John the Fearless assassinated Orléans, sparking hostilities between the factions. The war ended soon after Isabeau's eldest son, Charles, had John the Fearless assassinated in 1419—an act that saw him disinherited. Isabeau attended the 1420 signing of the Treaty of Troyes, which decided that the English king should inherit the French crown after the death of her husband, Charles VI. She lived in English-occupied Paris until her death in 1435.

Isabeau was popularly seen as a spendthrift and irresponsible philanderess. In the late 20th and early 21st centuries historians re-examined the extensive chronicles of her lifetime, concluding that many elements of her reputation were unearned and stemmed from factionalism and propaganda.

Isabeau's parents were Duke Stephen III of Bavaria-Ingolstadt and Taddea Visconti, whom he married for a 100,000 ducat dowry. She was most likely born in Munich where she was baptized as Elisabeth at the Church of Our Lady. She was great-granddaughter to the Wittelsbach Holy Roman Emperor Louis IV. At that period Bavaria counted amongst the most powerful German states and divided between members of the House of Wittelsbach.

Isabeau's uncle, Duke Frederick of Bavaria-Landshut, suggested in 1383 that she be considered as a bride to King Charles VI of France. The match was proposed again at the lavish Burgundian double wedding in Cambrai in April 1385—John the Fearless and his sister Margaret of Burgundy married Margaret and William of Bavaria-Straubing respectively. Charles, then 17, rode in the tourneys at the wedding. He was an attractive, physically fit young man, who enjoyed jousting and hunting and was excited to be married.
Charles VI's uncle, Philip the Bold, Duke of Burgundy, thought the proposed marriage ideal to build an alliance with the Holy Roman Empire and against the English. Isabeau's father agreed reluctantly and sent her to France with his brother, her uncle, on the pretext of taking a pilgrimage to Amiens. He was adamant that she was not to know she was being sent to France to be examined as a prospective bride for Charles, and refused permission for her to be examined in the nude, customary at the time. According to the contemporary chronicler Jean Froissart, Isabeau was 13 or 14 when the match was proposed and about 16 at the time of the marriage in 1385, suggesting a birth date of around 1370.

Before her presentation to Charles, Isabeau visited Hainaut for about a month, staying with her granduncle Duke Albert I, ruler of some of Bavaria-Straubing and Count of Holland. Albert's wife, Margaret of Brieg, replaced Isabeau's Bavarian style of dress, deemed unsuitable as French courtly attire, and taught her etiquette suitable to the French court. She learned quickly, suggestive of an intelligent and quick-witted character. On 13 July 1385 she traveled to Amiens to be presented to Charles.

Froissart writes of the meeting in his "Chronicles", saying that Isabeau stood motionless while being inspected, exhibiting perfect behavior by the standards of her time. Arrangements were made for the two to be married in Arras, but on the first meeting Charles felt "happiness and love enter his heart, for he saw that she was beautiful and young, and thus he greatly desired to gaze at her and possess her". She did not yet speak French and may not have reflected the idealized beauty of the period, perhaps inheriting her mother's dark Italian features, then unfashionable, but Charles most certainly approved of her because the couple were married three days later. Froissart documented the royal wedding, joking about the lascivious guests at the feast and the "hot young couple".

Charles seemingly loved his young wife, lavishing gifts on her. On the occasion of their first New Year in 1386, he gave her a red velvet palfrey saddle, trimmed with copper and decorated with an intertwined K and E (for "Karol and Elisabeth"), and he continued to give her gifts of rings, tableware and clothing. The uncles too, apparently, were pleased with the match, which contemporary chroniclers, notably Froissart and Michel Pintoin (the Monk of St. Denis), describe similarly as a match rooted in desire and based on her beauty. The day after the wedding, Charles went on a military campaign against the English, and Isabeau went to Creil to live with his step great-grandmother Queen Dowager Blanche, who taught her courtly traditions. In September she took up residence at the Château de Vincennes, where in the early years of their marriage Charles frequently joined her, and which became her favorite home.

Isabeau's coronation was celebrated on 23 August 1389 with a lavish ceremonial entry into Paris. Her second cousin and sister-in-law Valentina Visconti, who had married her own cousin Louis of Orléans (Charles' younger brother) two years earlier by proxy and papal dispensation, arrived in style, escorted across the Alps from Milan by 1,300 knights carrying personal luxuries such as books and a harp. The noblewomen in the coronation procession were dressed in lavish costumes with thread-of-gold embroidery, and rode in litters escorted by knights. Philip the Bold wore a doublet embroidered with 40 sheep and 40 swans, each decorated with a bell made of pearls.

The procession lasted from morning to night. The streets were lined with tableaux vivants displaying scenes from the Crusades, Deësis and the Gates of Paradise. More than a thousand burghers stood along the route; those on one side were dressed in green facing, those on the opposite in red. The procession began at the Porte de St. Denis and passed under a canopy of sky-blue cloth beneath which children dressed as angels sang, winding into the Rue Saint-Denis before arriving at the Notre Dame for the coronation ceremony. As Tuchman describes the event, "So many wonders were to be seen and admired that it was evening before the procession crossed the bridge leading to Notre Dame and the climactic display."

As Isabeau crossed the Grand Pont to Notre Dame, a person dressed as an angel descended from the church by mechanical means and "passed through an opening of the hangings of blue taffeta with golden fleurs-des-lis, which covered the bridge, and put a crown on her head." The angel was then pulled back up into the church. An acrobat carrying two candles walked along a rope suspended from the spires of the cathedral to the tallest house in the city.

After Isabeau's crowning, the procession made its way back from the cathedral along a route lit by 500 candles. They were greeted by a royal feast, and a progression of narrative pageants complete with a depiction of the Fall of Troy. Isabeau, seven months pregnant, nearly fainted from heat on the first of the five days of festivities. To pay for the extravagant event, taxes were raised in Paris two months later.

Charles suffered the first of what was to become a lifelong series of bouts of insanity in 1392 when, on a hot August day outside Le Mans, he attacked his household knights, including his brother Orléans, killing four men. After the attack he fell into a coma that lasted four days. Few believed he would recover; his uncles, the dukes of Burgundy and Berry, took advantage of his illness and quickly seized power, re-establishing themselves as regents and dissolving the Marmouset council.

The King's sudden onset of insanity was seen by some as a sign of divine anger and punishment, and by others as the result of magic. Modern historians speculate that he may have suffered from the onset of paranoid schizophrenia. The comatose king was returned to Le Mans, where Guillaume de Harsigny—a venerated and well-educated 92-year-old physician—was summoned to treat him. Charles regained consciousness and his fever subsided; he was gradually returned to Paris in September.

The physician recommended a program of amusements. A member of the court suggested that Charles surprise Isabeau and the other ladies by joining a group of courtiers who would disguise themselves as wild men and invade the masquerade celebrating the remarriage of Isabeau's lady-in-waiting, Catherine de Fastaverin. This came to be known as the "Bal des Ardents". Charles was almost killed and four of the dancers burned to death, when a spark from a torch brought by Orléans lit one of the dancer's costumes. The disaster undermined confidence in Charles' capacity to rule. Parisians considered it proof of courtly decadence and threatened to rebel against the more powerful members of the nobility. The public's outrage forced the King and Orléans, whom a contemporary chronicler accused of attempted regicide and sorcery, into offering penance for the event.

Charles suffered a second and more prolonged attack of insanity the following June; it removed him for about six months and set a pattern that would hold for the next three decades as his condition deteriorated. Froissart described the bouts of illness as so severe that the King was "far out of the way; no medicine could help him", although he had recovered from the first attack within months. For the first 20 years of his illness he sustained periods of lucidity, enough that he continued to rule. Suggestions were made to replace him with a regent, although there was uncertainty and debate as to whether a regency could assume the full role of a living monarch. When he was incapable of ruling, his brother Orléans, and their cousin John the Fearless, the new Duke of Burgundy, were chief among those who sought to take control of the government.

When Charles became ill in the 1390s, Isabeau was 22; she had three children and had already lost two infants. During the worst of his illness Charles was unable to recognize her, and caused her great distress by demanding her removal when she entered his chamber. The Monk of St Denis wrote in his chronicle, "What distressed her above all was to see how on all occasions ... the king repulsed her, whispering to his people, 'Who is this woman obstructing my view? Find out what she wants and stop her from annoying and bothering me. As his illness worsened at the turn of the century, she was accused of abandoning him, particularly when she moved her residence to the Hôtel Barbette. Historian Rachel Gibbons speculates that Isabeau wanted to distance herself from her husband and his illness, writing, "it would be unjust to blame her if she did not want to live with a madman."

Since the King often did not recognize her during his psychotic episodes and was upset by her presence, it was eventually deemed advisable to provide him with a mistress, Odette de Champdivers, the daughter of a horse-dealer; according to Tuchman, Odette is said to have resembled Isabeau and was called "the little Queen". She had probably assumed this role by 1405 with Isabeau's consent, but during his remissions the King still had sexual relations with his wife, whose last pregnancy occurred in 1407. Records show that Isabeau was in the King's chamber on 23 November 1407, the night of Orléans' assassination, and again in 1408.

Charles' bouts of illness continued unabated until his death. The two may have still felt mutual affection, and Isabeau exchanged gifts and letters with him during his periods of lucidity, but distanced herself during the prolonged attacks of insanity. Historian Tracy Adams writes that Isabeau's attachment and loyalty is evident in the great efforts she made to retain the crown for his heirs in the ensuing decades.

Isabeau's life is well documented, most likely because Charles' illness placed her in an unusual position of power. Nevertheless, not much is known about her personal characteristics, and historians even disagree about her appearance. She is variously described as "small and brunette" or "tall and blonde". The contemporaneous evidence is contradictory: chroniclers said of her either that she was "beautiful and hypnotic, or so obese through dropsy that she was crippled." Despite living in France after her marriage, she spoke with a heavy German accent that never diminished, which Tuchman describes as giving her an "alien" cast at the French court.

Adams describes Isabeau as a talented diplomat who navigated court politics with ease, grace and charisma. Charles had been crowned in 1387, aged 20, attaining sole control of the monarchy. His first acts included the dismissal of his uncles and the reinstatement of the so-called Marmousets—a group of councilors to his father, Charles V—and he gave Orléans more responsibility. Some years later, after Charles' first attack of illness, tensions mounted between Orléans and the royal uncles—Philip the Bold, Duke of Burgundy; John, Duke of Berry; and Louis II, Duke of Bourbon. Forced to assume a greater role in maintaining peace amidst the growing power struggle, which was to persist for many years, Isabeau succeeded in her role as peacekeeper among the various court factions.

As early as the late 1380s and early 1390s, Isabeau demonstrated that she possessed diplomatic influence when the Florentine delegation requested her political intervention in the Gian Galeazzo Visconti affair. Orléans and the Duke of Burgundy were in the pro-Visconti faction while the anti-Visconti faction included Isabeau, her brother, Louis VII, Duke of Bavaria, and John III, Count of Armagnac. At that time Isabeau lacked the political power to effect change. Some years later, however, at the 1396 wedding of her seven-year-old daughter, Isabella, to Richard II of England (an event at which Charles attacked a herald for wearing Galeazzo's livery), Isabeau successfully negotiated an alliance between France and Florence with Florentine ambassador Buonaccorso Pitti.

In the 1390s Jean Gerson of the University of Paris formed a council to eliminate the Western Schism, and in recognition of her negotiating skills he placed Isabeau on the council. The French wanted both the Avignon and Roman popes to abdicate in favor of a single papacy in Rome; Clement VII in Avignon welcomed Isabeau's presence given her record as an effective mediator. However, the effort faded when Clement VII died.

During his short-lived recovery in the 1390s, Charles made arrangements for Isabeau to be "principal guardian of the Dauphin", their son, until he reached 13 years of age, giving her additional political power on the regency council. Charles appointed Isabeau co-guardian of their children in 1393, a position shared with the royal dukes and her brother, Louis of Bavaria, while he gave Orléans full power of the regency. In appointing Isabeau, Charles acted under laws enacted by his father, Charles V, which gave the Queen full power to protect and educate the heir to the throne. These appointments separated power between Orléans and the royal uncles, increasing ill-will among the factions. The following year, as Charles' bouts of illness became more severe and prolonged, Isabeau became the leader of the regency council, giving her power over the royal dukes and the Constable of France, while at the same time making her vulnerable to attack from various court factions.

During Charles' illness, Orléans became financially powerful as the official tax collector, and in the following decade Isabeau and Orléans agreed to raise the level of taxation. In 1401, during one of the King's absences, Orléans installed his own men to collect royal revenues, angering Philip the Bold who in retaliation raised an army, threatening to enter Paris with 600 men-at-arms and 60 knights. At that time Isabeau intervened between Orléans and Burgundy, preventing bloodshed and the outbreak of civil war.

Charles trusted Isabeau enough by 1402 to allow her to arbitrate the growing dispute between the Orléanists and Burgundians, and he turned control of the treasury over to her. After Philip the Bold died in 1404 and his son John the Fearless became Duke of Burgundy, the new duke continued the political strife in an attempt to gain access to the royal treasury for Burgundian interests. Orléans and the royal dukes thought John was usurping power for his own interests and Isabeau, at that time, aligned herself with Orléans to protect the interests of the crown and her children. Furthermore, she distrusted John the Fearless who she thought overstepped himself in rank—he was cousin to the King whereas Orléans was Charles' brother.

Rumors that Isabeau and Orléans were lovers began to circulate, a relationship that was considered incestuous. Whether the two were intimate has been questioned by contemporary historians, including Gibbons who believes the rumor may have been planted as propaganda against Isabeau as retaliation against tax increases she and Orléans ordered in 1405. An Augustinian friar, Jacques Legrand, preached a long sermon to the court denouncing excess and depravity, in particular mentioning Isabeau and her fashions—with exposed necks, shoulders and décolletage. The monk presented his sermon as allegory so as not to offend Isabeau overtly, but he cast her and her ladies-in-waiting as "furious, vengeful characters". He said to Isabeau, "If you don't believe me, go out into the city disguised as a poor woman, and you will hear what everyone is saying." Thus he accused Isabeau as having lost touch with the commoners and the court with its subjects. At about the same time a satirical political pamphlet, "Songe Veritable", now considered by historians to be pro-Burgundian propaganda, was released and widely distributed in Paris. The pamphlet hinted at the Queen's relations with Orléans.

John the Fearless accused Isabeau and Orléans of fiscal mismanagement and again demanded money for himself, in recompense for the loss of royal revenues after his father's death; an estimated half of Philip the Bold's revenues had come from the French treasury. John raised a force of 1,000 knights, and entered Paris in 1405. Orléans hastily retreated with Isabeau to the fortified castle of Melun, with her household and children a day or so behind. John immediately left in pursuit, intercepting the party of chaperones and royal children. He took possession of the Dauphin, and returned him to Paris under control of Burgundian forces; however, the boy's uncle, the duke of Berry, quickly took control of the child at the orders of the Royal Council. At that time Charles was lucid for about a month and able to help with the crisis. The incident, that came to be known as the "enlèvement of the dauphin", almost caused full-scale war, but it was averted. Orléans quickly raised an army while John encouraged Parisians to revolt. They refused, claiming loyalty to the King and his son; Berry was made captain general of Paris and the city's gates were locked. In October Isabeau became active in mediating the dispute, in response to a letter from Christine de Pizan and an ordinance from the Royal Council.

In 1407 John the Fearless ordered Orléans' assassination. On 23 November hired killers attacked the duke as he returned to his Paris residence, cut off his hand holding the horse's reins, and "hacked [him] to death with swords, axes, and wooden clubs". His body was left in a gutter. John first denied involvement in the assassination, but quickly admitted that the act was done for the Queen's honor, claiming he acted to "avenge" the monarchy of the alleged adultery between Isabeau and Orléans. His royal uncles, shocked at his confession, forced him to leave Paris while the Royal Council attempted a reconciliation between the Houses of Burgundy and Orléans.

In March 1408 Jean Petit presented a lengthy and well-attended justification at the royal palace before a large courtly audience. Petit argued convincingly that in the King's absence Orléans became a tyrant, practiced sorcery and necromancy, was driven by greed, and had planned to commit fratricide at the "Bal des Ardents". John should be exonerated, Petit argued, because he had defended the King and monarchy by assassinating Orléans. Charles, "insane during the oration", was convinced by Petit's argument and pardoned John the Fearless, only to rescind the pardon in September.

Violence again broke out after the assassination; Isabeau had troops patrol Paris and, to protect the Dauphin Louis, Duke of Guyenne, she again left the city for Melun. In August she staged an entry to Paris for the Dauphin, and early in the new year Charles signed an ordinance giving the 13-year-old the power to rule in the Queen's absence. During these years Isabeau's greatest concern was the Dauphin's safety as she prepared him to take up the duties of the King; she formed alliances to further those aims. At this point the Queen and her influence were still crucial to the power struggle. Physical control of Isabeau and her children became important to both parties and she was frequently forced to change sides, for which she was criticized and called unstable. She joined the Burgundians from 1409 to 1413, and switched sides to form an alliance with the Orléanists from 1413 to 1415.

At the Peace of Chartres in March 1409, John the Fearless was reinstated to the Royal Council after a public reconciliation with Orléans' son, Charles, Duke of Orléans, at Chartres Cathedral, although the feuding continued. In December that year Isabeau bestowed the "tutelle" (guardianship of the Dauphin) upon John the Fearless, made him the master of Paris, and allowed him to mentor the Dauphin, after he had Jehan de Montagu, Grand Master of the King's household, executed. At that point the Duke essentially controlled the Dauphin and Paris, and was popular in the city because of his opposition to taxes levied by Isabeau and Orléans. Isabeau's actions with respect to John the Fearless angered the Armagnacs, who in the fall of 1410 marched to Paris to "rescue" the Dauphin from the Duke's influence. At that time members of the University of Paris, Jean Gerson in particular, proposed that all feuding members of the Royal Council step down and be immediately removed from power.

To defuse tension with the Burgundians a second double marriage was arranged in 1409. Isabeau's daughter Michelle married John the Fearless' son Philip the Good; Isabeau's son, Dauphin Louis, married John's daughter Margaret. Before the wedding, Isabeau negotiated a treaty with John the Fearless in which she clearly defined family hierarchy and her position in relation to the throne.

Despite Isabeau's efforts to keep the peace, the Armagnac–Burgundian Civil War broke out in 1411. John gained the upper hand during the first year, but the Dauphin began to build a power base; Christine de Pizan wrote of him that he was the savior of France. Still only 15, he lacked the power or backing to defeat John, who fomented revolt in Paris. In retaliation against John the Fearless' actions, Charles of Orléans denied funds from the royal treasury to all members of the royal family. In 1414, instead of allowing her son, then 17, to lead, Isabeau allied herself with Charles of Orléans. The Dauphin, in return, changed allegiance and joined John, which Isabeau considered unwise and dangerous. The result was continued civil war in Paris. Parisian commoners joined forces with John the Fearless in the Cabochien Revolt, and at the height of the revolt a group of butchers entered Isabeau's home in search of traitors, arresting and taking away up to 15 of her ladies-in-waiting. In his chronicles Pintoin wrote that Isabeau was firmly allied with the Orléanists and the 60,000 Armagnacs who invaded Paris and Picardy.

King Henry V of England took advantage of the internal strife in France, invading the northwest coast, and in 1415 he delivered a crushing defeat to the French at Agincourt. Nearly an entire generation of military leaders died or were taken prisoner in a single day. John, still feuding with the royal family and the Armagnacs, remained neutral as Henry V went on to conquer towns in northern France.

In December 1415 Dauphin Louis died suddenly at age 18 of illness, leaving Isabeau's political status unclear. Her 17-year-old fourth-born son, John of Touraine, now the Dauphin, had been raised since childhood in the household of Duke William II of Bavaria in Hainaut. Married to Countess Jacqueline of Hainaut, Dauphin John was a Burgundian sympathizer. William of Bavaria refused to send him to Paris during a period of upheaval as Burgundians plundered the city and Parisians revolted against another wave of tax increases initiated by Count Bernard VII of Armagnac; in a period of lucidity, Charles had raised the Count to be the Constable of France. Isabeau attempted to intervene by arranging a meeting with Jacqueline in 1416, but Armagnac refused to allow Isabeau to reconcile with the House of Burgundy, while William II continued to prevent the young Dauphin from entering Paris.

In 1417 Henry V invaded Normandy with 40,000 men. In April that year Dauphin John died and another shift in power occurred when Isabeau's sixth and last son, Charles, age 14, became Dauphin. He was married to Armagnac's daughter Marie of Anjou and favored the Armagnacs. At that time Armagnac imprisoned Isabeau in Tours, confiscating her personal property (clothing, jewels and money), dismantling her household, and separating her from the younger children as well as her ladies-in-waiting. She secured her freedom in November through the help of the Duke of Burgundy. Accounts of her release vary: Monstrelet writes that Burgundy "delivered" her to Troyes, and Pintoin that the Duke negotiated Isabeau's release to gain control of her authority. Isabeau maintained her alliance with Burgundy from that period until the Treaty of Troyes.

Isabeau at first assumed the role of sole regent but in January 1418 yielded her position to John the Fearless. Together Isabeau and John abolished parliament ("Chambre des comptes") and turned to securing control of Paris and the King. John took control of Paris by force on 28 May 1418, slaughtering Armagnacs. The Dauphin fled the city. According to Pintoin's chronicle, the Dauphin refused Isabeau's invitation to join her in an entry to Paris. She entered the city with John on 14 July.

Shortly after he assumed the title of Dauphin, Charles negotiated a truce with John in Pouilly. Charles then requested a private meeting with John, on 10 September 1419 at a bridge in Montereau, promising his personal guarantee of protection. The meeting, however, was a ploy to assassinate John, whom Charles "hacked to death" on the bridge. His father, King Charles, immediately disinherited his son. The civil war ended after John's death. The Dauphin's actions fueled more rumor about his legitimacy, and his disinheritance set the stage for the Treaty of Troyes.
By 1419 Henry V occupied much of Normandy and demanded an oath of allegiance from the residents. The new Duke of Burgundy, Philip the Good, allied with the English, putting enormous pressure on France and Isabeau, who remained loyal to the King. In 1420 Henry sent an emissary to confer with the Queen, after which according to Adams, Isabeau "ceded to what must have been a persuasively posed argument by Henry V's messenger". France had effectively been left without an heir to the throne, even before the Treaty of Troyes. Charles VI had disinherited the Dauphin, whom he considered responsible for "breaking the peace for his involvement in the assassination of the duke of Burgundy"; he wrote in 1420 of the Dauphin that he had "rendered himself unworthy to succeed to the throne or any other title". Charles of Orléans, next in line as heir under Salic law, had been taken prisoner at the Battle of Agincourt and was kept in captivity in London.

In the absence of an official heir to the throne, Isabeau accompanied King Charles to sign the Treaty of Troyes in May 1420; Gibbons writes that the treaty "only confirmed [the Dauphin's] outlaw status". The King's malady prevented him from appearing at the signing of the treaty, forcing Isabeau to stand in for him, which according to Gibbons gave her "perpetual responsibility in having sworn away France". For many centuries Isabeau stood accused of relinquishing the crown because of the Treaty. Under the terms of the Treaty, Charles remained as King of France but Henry V, who married Charles' and Isabeau's daughter, Catherine, kept control of the territories he conquered in Normandy, would govern France with the Duke of Burgundy, and was to be Charles' successor. Isabeau was to live in English-controlled Paris.

Charles VI died in October 1422. As Henry V had died earlier the same year, his infant son by Catherine, Henry VI, was proclaimed King of France, according to the terms of the Treaty of Troyes, with the Duke of Bedford acting as regent. Rumors circulated about Isabeau again; some chronicles describe her living in a "degraded state". According to Tuchman, Isabeau had a farmhouse built in St. Ouen where she looked after livestock, and in her later years, during a lucid episode, Charles arrested one of her lovers whom he tortured, then drowned in the Seine. Desmond Seward writes it was the disinherited Dauphin who had the man killed. Described as a former lover of Isabeau as well as a "poisoner and wife-murderer", Charles kept him as a favorite at his court until ordering his drowning.

Rumors about Isabeau's promiscuity flourished, which Adams attributes to English propaganda intended to secure England's grasp on the throne. An allegorical pamphlet, called "Pastorelet", was published in the mid-1420s painting Isabeau and Orleans as lovers. During the same period Isabeau was contrasted with Joan of Arc, considered virginally pure, in the allegedly popular saying "Even as France had been lost by a woman it would be saved by a woman". Adams writes that Joan of Arc has been attributed with the words "France, having been lost by a woman, would be restored by a virgin", but neither saying can be substantiated by contemporary documentation or chronicles.

In 1429, when Isabeau lived in English-occupied Paris, the accusation was again put forth that Charles VII was not the son of Charles VI. At that time, with two contenders for the French throne—the young Henry VI and disinherited Charles—this could have been propaganda to prop up the English claim. Furthermore, gossip spread that Joan of Arc was Isabeau and Orleans' illegitimate daughter—a rumor Gibbons finds improbable because Joan of Arc almost certainly was not born for some years after Orléans' assassination. Stories circulated that the dauphins were murdered, and attempts were made to poison the other children, all of which added to Isabeau's reputation of one of history's great villains.

Isabeau was removed from political influence and retired to live in the Hôtel Saint-Pol with her brother's second wife, Catherine of Alençon. She was accompanied by her ladies-in-waiting Amelie von Orthenburg and Madame de Moy, the latter of whom had traveled from Germany and had stayed with her as "dame d'honneur" since 1409. Isabeau died there in 1435. Her death and funeral were documented by Jean Chartier (member of St Denis Abbey) who may well have been an eyewitness.

Isabeau was dismissed by historians in the past as a wanton, weak and indecisive leader. Modern historians now see her as taking an unusually active leadership role for a queen of her period, forced to take responsibility as a direct result of Charles' illness. Her critics accepted skewed interpretations of her role in the negotiations with England, resulting in the Treaty of Troyes, and in the rumors of her marital infidelity with Orléans. Gibbons writes that a queen's duty was to secure the succession to the crown and look after her husband; historians described Isabeau as having failed in both respects, and she came to be seen as one of the great villains of history. Gibbons goes on to say that even her physical appearance is uncertain; depictions of her vary depending on whether she was to be portrayed as good or evil.

Rumored to be a bad mother, she was accused of "incest, moral corruption, treason, avarice and profligacy ... political aspirations and involvements". Adams writes that historians reassessed her reputation in the late 20th century, exonerating her of many of the accusations, seen particularly in Gibbons' scholarship. Furthermore, Adams admits she believed the allegations against Isabeau until she delved into contemporary chronicles: there she found little evidence against the Queen except that many of the rumors came from only a few passages, and in particular from Pintoin's pro-Burgundian writing.

After the onset of the King's illness, a common belief was that Charles' mental illness and inability to rule were due to Isabeau's witchcraft; as early as the 1380s rumors spread that the court was steeped in sorcery. In 1397 Orléans' wife, Valentina Visconti, was forced to leave Paris because she was accused of using magic. The court of the "mad king" attracted magicians with promises of cures who were often used as political tools by the various factions. Lists of people accused of bewitching Charles were compiled, with Isabeau and Orléans both listed.

The accusations of adultery were rampant. According to Pintoin's chronicle, "[Orléans] clung a bit too closely to his sister-in-law, the young and pretty Isabeau of Bavaria, the queen. This ardent brunette was twenty-two; her husband was insane and her seductive brother-in-law loved to dance, beyond that we can imagine all sorts of things". Pintoin said of the Queen and Orléans that they neglected Charles, behaved scandalously and "lived on the delights of the flesh", spending large amounts of money on court entertainment. The alleged affair, however, is based on a single paragraph from Pintoin's chronicles, according to Adams, and is no longer considered proof.

Isabeau was accused of indulging in extravagant and expensive fashions, jewel-laden dresses and elaborate braided hairstyles coiled into tall shells, covered with wide double hennins that, reportedly, required widened doorways to pass through. In 1406 a pro-Burgundian satirical pamphlet in verse allegory listed Isabeau's supposed lovers. She was accused of leading France into a civil war because of her inability to support a single faction; she was described as an "empty headed" German; of her children it was said that she "took pleasure in a new pregnancy only insofar as it offered her new gifts"; and her political mistakes were attributed to her being fat.

In the 18th and 19th centuries historians characterized Isabeau as "an adulterous, luxurious, meddlesome, scheming, and spendthrift queen", overlooking her political achievements and influence. A popular book written by Louise de Karalio (1758–1822) about the "bad" French queens prior to Marie Antoinette is, according to Adams, where "Isabeau's black legend attains its full expression in a violent attack on the French royalty in general and queens in particular." Karalio wrote: "Isabeau was raised by the furies to bring about the ruin of the state and to sell it to its enemies; Isabeau of Bavaria appeared, and her marriage, celebrated in Amiens on 17 July 1385, would be regarded as the most horrifying moment in our history". Isabeau was painted as Orléans' passionate lover, and the inspiration for the Marquis de Sade's unpublished 1813 novel "Histoire secrete d'Isabelle de Baviere, reine de France", about which Adams writes, "submitting the queen to his ideology of gallantry, [the Marquis de Sade] gives her rapaciousness a cold and calculating violence ... a woman who carefully manages her greed for maximum gratification." She goes on to say that de Sade admitted to "being perfectly aware that the charges against the queen are without ground."

Like many of the Valois, Isabeau was an appreciative art collector. She loved jewels and was responsible for the commissions of particularly lavish pieces of "ronde-bosse"—a newly developed technique of making enamel-covered gold pieces. Documentation suggests she commissioned several fine pieces of "tableaux d'or" from Parisian goldsmiths.
In 1404, Isabeau gave Charles a spectacular "ronde-bosse", known as the "Little Golden Horse Shrine", (or "Goldenes Rössl"), now held in a convent church in Altötting, Bavaria. Contemporary documents identify the statuette as a New Year's gift—an "étrennes"—a Roman custom Charles revived to establish rank and alliances during the period of factionalism and war. With the exception of manuscripts, the Little Golden Horse is the single surviving documented "étrennes" of the period. Weighing the gold piece is encrusted with rubies, sapphires and pearls. It depicts Charles kneeling on a platform above a double set of stairs, presenting himself to the Virgin Mary and child Jesus, who are attended by John the Evangelist and John the Baptist. A jewel encrusted trellis or bower is above; beneath stands a squire holding the golden horse. Isabeau also exchanged New Year's gifts with the Duke of Berry; one extant piece is the "ronde-bosse" statuette Saint Catherine.

Medieval author Christine de Pizan solicited the Queen's patronage at least three times. In 1402 she sent a compilation of her literary argument "Querelle du Roman de la Rose"—in which she questions the concept of courtly love—with a letter exclaiming "I am firmly convinced the feminine cause is worthy of defense. This I do here and have done with my other works." In 1410 and again in 1411, Pizan solicited the Queen, presenting her in 1414 an illuminated copy of her works. In "The Book of the City of Ladies", Pizan praised Isabeau lavishly, and again in the illuminated collection, "The Letter of Othea", which scholar Karen Green believes for de Pizan is "the culmination of fifteen years of service during which Christine formulated an ideology that supported Isabeau's right to rule as regent in this time of crisis."

Isabeau showed great piety, essential for a queen of her period. During her lifetime, and in her will, she bequeathed property and personal possessions to Notre Dame, St. Denis, and the convent in Poissy.
The birth of each of Isabeau's 12 children is well chronicled; even the decoration schemes of the rooms in which she gave birth are described. She had six sons and six daughters. The first son, born in 1386, died as an infant and the last, Philip, born in 1407, lived a single day. Three others died young with only her youngest son, Charles VII, living to adulthood. Five of the six daughters survived; four were married and one, Marie (1393–1438), was sent at age four to be raised in a convent, where she became prioress.

Her first son, Charles (b. 1386) died in infancy. A daughter, Joan, born two years later lived until 1390. The second daughter, Isabella (b. 1389), born in 1389, was married at age seven to Richard II of England and after his death to Charles, Duke of Orléans. The third daughter, Joan (1391–1433), who lived to age 42, married John VI, Duke of Brittany. The fourth daughter, Michelle (1395–1422), first wife to Philip the Good, died childless at age 27. Catherine of Valois, Queen of England, (1401–1438) married Henry V of England; on his death she took Sir Owen Tudor as her second husband. 

Of her sons, the first to survive infancy and become Dauphin, Charles, (1392–1401), died at age eight of a "wasting illness". Louis, Dauphin of France (1397–1415), and Duke of Guyenne, married to Margaret of Burgundy, died at age 19. John, Dauphin of France (1398–1417), and Duke of Touraine, first husband to Jacqueline, Countess of Hainaut, died without issue. Charles VII, (1403–1461) married Marie of Anjou.

According to modern historians Isabeau stayed in close proximity to the children during their childhood, had them travel with her, bought them gifts, wrote letters, bought devotional texts, and arranged for her daughters to be educated. She resisted separation and reacted against having her sons sent to other households to live (as was the custom at the time). Pintoin records she was dismayed at the marriage contract that stipulated her third surviving son, John, be sent to live in Hainaut. She maintained relationships with her daughters after their marriages, writing letters to them frequently. She sent them out of Paris during an outbreak of plague, staying behind herself with the youngest infant, Jean, too young to travel. The Celestines allowed "whenever and as often as she liked, she and her could enter the monastery and church ... their vineyards and gardens, both for devotion and for entertainment and pleasure of herself and her children."


|-


</doc>
<doc id="955656" url="https://en.wikipedia.org/wiki?curid=955656" title="France national rugby union team">
France national rugby union team

The France national rugby union team competes annually against England, Ireland, Italy, Scotland and Wales in the Six Nations Championship. They have won the championship outright seventeen times, shared it a further eight times, and have completed nine grand slams. Ten former French players have been inducted into the World Rugby Hall of Fame.

Rugby was introduced to France in 1872 by the British, and on New Years Day 1906 the national side played its first Test match – against New Zealand in Paris. France played sporadically against the Home Nations until they joined them to form a Five Nations tournament (now the Six Nations Championship) in 1910. France also competed in the rugby competitions at early Summer Olympics, winning the gold medal in 1900 and two silver medals in the 1920s. The national team came of age during the 1950s and 1960s, winning their first Five Nations title outright in 1959. They won their first Grand Slam in 1968. Since the inaugural World Cup in 1987, France have qualified for the knock-out stage of every tournament. They have reached the final three times, losing to the All Blacks in 1987 and 2011 and to Australia in 1999. France hosted the 2007 Rugby World Cup, where, as in 2003, they were beaten in the semi-finals by England and will once again host the tournament in 2023.

France traditionally play in blue shirts with white shorts and red socks, and are commonly referred to as "les tricolores" or "les bleus". The French emblem is a golden rooster imposed upon a red shield. Their alternative strip is composed of a white shirt and navy blue shorts and socks. French international matches are played at several venues across the country; the Stade de France in the Paris suburb of Saint-Denis is used for their games during the Six Nations, and they have a formidable home record at the Stade Vélodrome in Marseille where they have only lost twice, to Argentina in 2004 and to New Zealand in 2009.

Rugby was introduced to France in 1872 by English merchants and students. On 26 February 1890, a French rugby team recruited from the Janson Desailly Lyceum defeated an international team at the Bois de Boulogne.

Although France were represented at the 1900 Summer Olympics, their first official test match did not take place till New Year's Day, 1906 against the New Zealand All Blacks in Paris. France then played intermittently against the Home Nations until they joined them to form the Five Nations tournament in 1910. In 1913 France faced South Africa's Springboks for the first time; losing 38–5. France also competed at the 1920 and 1924 Summer Olympics, and on both occasions lost to the United States in the gold medal match.

France were ejected from the Five Nations in 1932 after being accused of professionalism in the French leagues at a time when rugby union was strictly amateur. Forced to play against weaker opposition, France went on a winning streak; winning ten games in a row during the years from 1931 to 1936. France was invited to rejoin the Five Nations in 1939 but did not compete until 1947 as international rugby was suspended during World War II.

French rugby came of age during the 1950s and 1960s: they won their first Five Nations championship and completed a successful tour of South Africa. Their first championship was won in 1954 when they shared the title with England and Wales. France won their first outright Five Nations championship in 1959; they won with two wins, a draw (against England) and a defeat (against Ireland).

France first toured South Africa winning the test series in 1958. The Springboks also visited Paris in 1961, the test was not completed due to onfield fighting amongst the players. France also toured New Zealand and Australia in 1961 losing both tests against the All Blacks but defeating Australia's Wallabies. They won their first Five Nations Grand Slam in 1968 by beating all four other competing teams, and won numerous titles in the following years.
In 1977, France won their second Grand Slam, fielding an unchanged side throughout the tournament and conceding no tries. They also defeated the All Blacks in Toulouse that year, but lost the return match in Paris. On Bastille Day, 1979 they defeated the All Blacks in New Zealand for the first time, at Eden Park in Auckland.

In 1981 the French clinched their third Grand Slam; at Twickenham against England. They again completed a Grand Slam in 1987 on the eve of the first Rugby World Cup hosted by Australia and New Zealand. In that tournament they came from behind numerous times to defeat the Wallabies in their semi-final, and faced the All Blacks in final at Eden Park, Auckland; France lost 29–9. They shared the Five Nations with Wales the next year, and also won it in 1989.

France hosted some of the tests during the 1991 World Cup, but made their exit from the after being knocked out by England at the Parc des Princes (Paris) in their quarter-final. One Five Nations championship was won in the early 1990s, in 1993. The following year France won a test series 2–0 in New Zealand. They were knocked out of the 1995 World Cup semi-finals by eventual champions the Springboks, but did win their third place play-off match against England. France played the All blacks in two tests, winning the first 22–15 at Toulouse and lost the second 37–12 at Paris. France won back-to-back Grand Slams in 1997 and 1998. At the 1999 World Cup they defeated tournament favourites the All Blacks in the semi-finals, but lost to the Wallabies in the final.

The Five Nations Championship was expanded in 2000 to include Italy. In the now Six Nations Championship France won a Grand Slam in 2002. At the 2003 World Cup in Australia they qualified for the semi-finals where they were defeated by eventual champions England. In 2004, they won a second Six Nations Grand Slam, which was followed by a Championship win in 2006 and a successful defence in 2007.

During the opener of the World Cup 2007, Argentina defeated France 17–12. However, after defeating Ireland 25–3, France qualified for the quarter-finals. After defeating the New Zealand All Blacks 20–18, they lost to England 14–9 in the semi-final. France then lost for a second time to Argentina 34–10 in the third-place match. In 2010, France won its ninth Grand Slam.

During the 2011 Rugby World Cup, France defeated Wales 9–8 in the semi-final at Eden Park in Auckland, New Zealand, on 15 October 2011 and in the following week they lost 8–7 to the All Blacks at the final to make it three final defeats.

During the 2015 Rugby World Cup France lost 62–13 to New Zealand in the Quarter Finals

Until 1912, the strip (uniform) of the French team was white with two rings, one red and one blue. After the first game won by France against Scotland in 1911, France's captain Marcel Communeau asked that the team adopt the "coq gaulois" (Gallic rooster), historical emblem of France, as its symbol. The Gallic rooster was probably chosen partly because it is considered as a proud and combative animal that can be sometimes aggressive, although it had been used previously as a symbol by French teams – a former association football player, Jean Rigal, wore a uniform with this emblem as early as May 1910. The badge was initially white and red, but was altered to a multicoloured, embroidered image after 1945, and has been golden since 1970.

The symbol used by the French rugby team was a great success, and was later adopted by the French delegation at the Olympic Games of 1920 where the rooster was perched on five Olympic rings. The rooster has since become a well-known symbol of French teams. French players are sometimes called "les coqs" and some French supporters have been known to release roosters on the playing field before games.

The French team traditionally played in blue shirts, white shorts, and red socks, the colors of the national flag, and as such were nicknamed "les tricolores". Due to the mostly blue strip the French team currently wears, the team is now often referred to as "les Bleus" (the Blues), like many other French sporting teams. When this strip clashes with that of their opponents, such as in games against Scotland and Italy, French players wear white. New strips were developed for the 2007 World Cup, one of which is a darker blue. In June 2011 they relaunched another kit which they wear blue shirt, blue shorts and blue socks for their home kit and they wear white shirt, white shorts and white socks for their away kit.

In 2011 the French Rugby Federation (FFR) announced that Adidas would be their new partner for a period of six years, with them taking over production of the French national rugby shirt from 1 July 2012 to 30 June 2018.

Led by newly elected president Bernard Laporte, the federation intended on selling the jersey to a sponsor. The FFR announced on 24 January 2017 that they had started the commercialisation of the jersey. In February, it was decided that the jersey would first be used to support France's bid for the 2023 Rugby World Cup by showing "#France2023" on the front of the kit. In March 2017, the Groupe Altrad showed its support for France's bid for the World Cup and the company's logo accompanied "#France2023" on the jersey. The group became the first private company in history that appeared on the French national team kits. As of 2017 and France's successful bid to host the World Cup, Groupe Altrad signed a contract with the FFR, appearing solely on the jerseys.

In 2017 the FFR announced that Le Coq Sportif would once again be their partner for a period of six years, with them taking over production of the French national rugby shirt from 1 July 2018 to 30 June 2024.

Historically, France played internationals at venues such as Parc des Princes and the Stade Olympique de Colombes, both in Paris. The Stade Olympique de Colombes was the main venue for the 1924 Summer Olympics, where rugby was a sport.

Ever since moving out of Parc des Princes at the end of 1997, France's main home venue has been the Stade de France in Saint-Denis, where their home Six Nations matches are played. It has a capacity of 80,000. Since 2005, France has also played home internationals at the following venues around the country: Stade Chaban-Delmas, Grand Stade Lille Métropole (now known as Stade Pierre-Mauroy), Stade Gerland, Stade Vélodrome, Stade de la Mosson, Stade de la Beaujoire, Stade Bonal, Stadium Municipal (Toulouse) and U Arena.

In June 2012, the FFR announced that plans were under way for a new rugby-dedicated stadium to be constructed in Évry, south of Paris. The stadium was projected to cost €600M and have a seating capacity of 82,000. It was originally scheduled for completion by 2017, but later delayed to 2021 or 2022. In December 2016, FFR officially abandoned the stadium project.

During the 1991 World Cup, Pool D (which included France) matches were played throughout France including Béziers, Bayonne, Grenoble, Toulouse, Brive and Agen. Parc des Princes and Stadium Lille-Metropole also hosted a quarter-final each. Pool C fixtures at the 1999 World Cup were played throughout France in Béziers, Bordeaux and Toulouse. A second round match was held at Stade Félix Bollaert, and one quarter final was held at the Stade de France, both 2007 venues.

For the 2007 World Cup, France was the primary host, and there were ten venues used for matches throughout the country (Cardiff in Wales and Edinburgh in Scotland also hosted some games). The French cities that hosted matches were Bordeaux (Stade Chaban-Delmas), Lens (Stade Félix Bollaert), Lyon (Stade Gerland), Marseille (Stade Vélodrome), Montpellier (Stade de la Mosson), Nantes (Stade de la Beaujoire), Paris (Stade de France, Saint-Denis and Parc des Princes), Saint-Étienne (Stade Geoffroy-Guichard), and Toulouse (Stadium de Toulouse). The final was played at Stade de France. They will host it again in 2023.

France competes annually in the Six Nations Championship, which is played against five other European nations: England, Ireland, Italy, Scotland and Wales. France first contested the tournament in 1910 when the Home Nations became the Five Nations. France were expelled from the tournament due to rumours of professionalism in the then-amateur sport in 1932, but rejoined in 1947. They first won the competition in 1954, sharing the championship with both England and Wales. France shared with Wales again the following season, and won it outright for the first time in 1959. France's longest wait for a championship spanned 37 tournaments (1910–1954). The Giuseppe Garibaldi Trophy is also contested between France and Italy during the Six Nations. Over the whole history of the Tournament, they are the third most-winning nation, ten wins behind England. However, it should be taken into account that France have been present in 33 fewer tournaments than the Home Nations. France has won almost exactly the same proportion of Six Nations Tournaments in which it has competed as England, and is the most successful nation in the post-World War II era (1945–present).

The French have competed at every World Cup since the inaugural tournament in 1987. Although they have yet to win a World Cup, they have participated in the play-off stage of every tournament, and have reached the final three times.

In 1987 France took on pre-tournament favourites Australia at Concord Oval for a place in the final. In one of the greatest World Cup matches, the Australians appeared to be in control, leading 9–0, 15–12 and 24–21 at various stages of the match, only for the French to keep coming back. With the scores locked at 24–24 and the prospect of extra time looming, the French scored one of the most memorable tries in rugby history. Starting an attack from inside their own half, the French passed the ball through 11 pairs of hands before fullback Serge Blanco beat Wallabies hooker Tom Lawton to score a try in the corner. France won 30–24, and would face co-hosts New Zealand in the final at Eden Park. The French had not fully recovered from their magnificent effort in the semi-final, and New Zealand won the anti-climactic decider 29–9.

In 1991 France met eternal arch-rivals England in the quarterfinal at Parc des Princes. Earlier in the year at Twickenham the two sides had played off for the Five Nations Grand Slam. The French scored three magnificent tries but were denied by the fearsome English forward pack. In a very tense and brutally physical match, the scores were tied at 10-all when the French were awarded a scrum five metres out from the tryline. French number eight Marc Cecillon looked set to score the try that would have won the game for the French. Suddenly he was hit and driven back in a tackle from opponent Mick Skinner, a tackle which changed the momentum of the match. England went on to win 19–10 and eventually reached the Final. At the end of the match, France coach Daniel Dubroca angrily assaulted New Zealand referee David Bishop in the players tunnel. He resigned soon afterwards.

In 1995 France finished third overall, defeating England 19–9 in the third/fourth place play-off after their defeat to South Africa in the semi-finals. After coming from behind to defeat the All Blacks in their 1999 semi-final, France lost to Australia 35–12 in the final. In 2003 they finished fourth, losing the third/fourth place game to the All Blacks. At the World Cup 2007, after defeating New Zealand 20–18 in the quarter-final, France lost out to England in the semi-finals losing 14–9 after finishing the break 5–6 ahead. France lost to Argentina in the bronze final to finish the tournament fourth.

France's 2011 campaign was marked by turmoil within the camp; reports before the tournament indicated as many as 25 of the 30-member squad had turned against head coach Marc Lièvremont. In pool play, France had unimpressive wins over Japan and Canada, an expected loss to New Zealand, and a shock loss to Tonga. During this stage, Lièvremont heavily criticized the team in the media, further angering many of his players, with veteran back-rower Imanol Harinordoquy publicly critical of Lièvremont. Despite the losses, they qualified for the knockout stage. At this time, the players effectively rebelled against Lièvremont; after the tournament, Harinordoquy would tell the French rugby publication "Midi Olympique", "We had to free ourselves from his supervision." The team responded by defeating England 19–12 in the quarter final and controversially beating Wales 9–8 in the semi-final after Welsh captain Sam Warburton was sent off. The French proved admirable opponents in the final, however, losing out to New Zealand 8–7 to finish second for the third time in a Rugby World Cup

France are the third-highest World Cup points scorers of all time, with 1195 points. They are also the third-highest try scorers, and the second-highest penalty scorers. France's Thierry Lacroix was the top points scorer at the 1995 tournament with 112 points, and Jean-Baptiste Lafond was the joint top try scorer in 1991 with six tries (equal with David Campese).

France were named World Rugby Team of the Year in 2002. When the World Rankings were introduced by World Rugby (then the International Rugby Board) in 2003, France were ranked fifth. During November 2003 France briefly occupied third place before falling to fourth by December that year. After falling to fifth during November 2004, France rose again to fourth by April 2005. During early 2006, France rose again, peaking at second in July that year. France were ranked number two in the world until falling to third in June 2007 after two successive defeats to the All Blacks. They then fell to fifth after losing to Argentina in the opening match of the 2007 World Cup.

France have won 404 of their 752 test matches, a win record of 54.00% 

Below is a table of the representative rugby matches played by a France national XV at test level up until 24 November 2018.

On 9 January 2019, Brunel named a 31-man squad ahead of the 2019 Six Nations.

On 22 January, Bernard Le Roux pulled out of the squad due to injury, and was replaced by Fabien Sanconnie.

On 5 February, Julien Marchand pulled out of the squad due to injury, and was replaced by Camille Chat.

On 16 February, Dany Priso was ruled out of the squad due to injury, and was replaced by Etienne Falgoux.

On 11 March, Dany Priso and Kélian Galletier were called up to replace the injured Jefferson Poirot and Wenceslas Lauret.

Head coach: Jacques Brunel


In December 2016, when World Rugby was considering a change in the eligibility rules for international selection, FFR president Bernard Laporte announced that the body would require that all France national team members hold French passports. This requirement is in addition to then-current WR rules mandating three years' residency for international selection, a period which WR increased to five years effective from 31 December 2020. Players who represented France prior to Laporte's announcement remain eligible for selection even if they do not hold French passports. Thus, since 2016 France have had the lowest number of foreign-born players in their Six Nations's squads.

Ten former French national team players have been inducted into the World Rugby Hall of Fame. Its direct predecessor is the IRB Hall of Fame, founded in 2006 by the sport's international governing body, World Rugby, when it was known as the International Rugby Board. In late 2014, the IRB Hall merged with the separate International Rugby Hall of Fame, with all International Hall inductees becoming members of the World Rugby Hall of Fame.

Marcel Communeau (1885–1971), a back-rower for Stade Français at club level, played in France's first official international match against New Zealand's Original All Blacks in 1906. He went on to earn 21 caps for France, serving as captain for the country's first Five Nations appearance in 1910 and leading France to its first-ever win in that competition in 1911 against Scotland. Communeau is also credited with suggesting that France adopt the rooster as its team emblem. He entered the World Rugby Hall in 2015.

Jean Prat (1923–2005) earned 51 caps playing for France from 1945 to 1955, and captained France to their first wins over Wales and the All Blacks. He was also France's captain in 1954 when they won their first ever Five Nations (shared with Wales and England). Prat was inducted to the International Hall of Fame in 2001 and the IRB Hall of Fame in 2011.

Lucien Mias (born 1930), nicknamed "Docteur Pack", was credited with inventing the concept of the advantage line in forward play. When inducted into the IRB Hall of Fame in 2011, he was called "one of the most influential captains of his country". He was most noted for captaining France to a Test series win over South Africa in 1958, the first such feat in the 20th century for a touring team.

André Boniface (born 1934) also played in France's win over the All Blacks in 1954; it was only his second test for France. Boniface went on to play 48 tests for France before retiring in 1966. He was inducted to the International Hall in 2005 and the IRB Hall in 2011.

Guy Boniface (1937–1968) emerged on the international scene shortly after his older brother André, although the two did not play together in the same France side until 1961. According to the IRB, the Boniface brothers "redefined the concept of back play through their unique blend of skill and creativity." Guy won 35 caps for France before his death in an auto accident in 1968. He was inducted into the IRB Hall of Fame alongside his brother in 2011.

Jo Maso (born 1944) first played for France between 1966 and 1973; mainly at centre. He played in France's first ever Five Nations Grand Slam in 1968, and that year toured New Zealand and Australia. He represented France in 25 tests and also played for the Barbarians and the World XV that beat England in 1971. Maso entered the International Hall in 2003 and became a member of the World Rugby Hall with the merger of the two halls of fame. He is now the manager of the French national team.

Jean-Pierre Rives (born 1952), a 1997 inductee of the International Hall who entered the World Rugby Hall with the merger, played 59 tests for France between 1975 and 1984; including 34 as captain. He played in Five Nations Grand Slams in 1977 and 1981, and captained France to their first ever win over the All Blacks in New Zealand. Rives is now a sculptor, and designed the Giuseppe Garibaldi Trophy (Italian: Trofeo Garibaldi; French: Trophée Garibaldi), which is competed for every year by France and Italy in the 6 Nations championship.

Serge Blanco (born 1958) played in 93 tests for France between 1980 and 1991. Playing at fullback Blanco won Five Nations Grand Slams with France in 1981 and 1987, and scored the match-winning try in France's semi-final against Australia in the 1987 World Cup. He is past president both of his longtime club, Biarritz Olympique, and France's national professional league, Ligue Nationale de Rugby. Blanco was inducted to the International Hall in 1997 and the IRB Hall in 2011.

Centre Philippe Sella (born 1962), who was also in the 1987 team, played 111 times for France between 1982 and 1995, setting an appearances record that stood until Fabien Pelous, who himself would be indicted into the World Rugby Hall in 2017, broke it during the 2007 Rugby World Cup. In 1986, he achieved the rare feat of scoring a try in each of France's Five Nations matches. Sella entered the International Hall in 1999 and the IRB Hall in 2005.

Lock Fabien Pelous (born 1973) was inducted into the World Rugby Hall in 2017 at a ceremony at the Hall's physical location in Rugby. He appeared 118 times for France from 1995 to 2007, surpassing Sella as France's most-capped player. According to World Rugby, "Pelous’ spirit and robustness in the heat of battle made him perfect captaincy material", and he would captain "Les Bleus" 42 times, with only Thierry Dusautoir serving as captain on more occasions. In his 18-season club career, 12 of which were with his hometown club Toulouse, he helped Toulouse to two European and three French titles.

The record for points scored for France is 422, held by Frédéric Michalak, who surpassed previous record holder Christophe Lamaison on 22 August 2015. Lamaison continues to hold the record for conversions with 59. The record for penalties scored is 89 by Thierry Lacroix, and the drop goal record of 15 is held by Jean-Patrick Lescarboura. The record for French appearances is held by Fabien Pelous with 118. The record for tries scored for France is with 38 held by Serge Blanco.

Historically the role of French rugby coach (or "trainer") has varied considerably. Due to the status of rugby union as an amateur sport for most of its history, the job of deciding tactics and running team trainings has often been that of the captain or senior players. Therefore, a comprehensive list of national coaches is impossible.

Although coached by Jean Desclaux between 1973 and 1980, the French team's main influence during the late 1970 was captain Jacques Fouroux. Fouroux played scrum-half and captained France to their 1977 Five Nations Grand Slam, during which France played a very forward-oriented style of rugby. Although the style of "Fouroux's Gang" was successful, it was criticised because it contrasted with the traditional open attacking style of French rugby. Fouroux was given the nickname "the little Corporal" – the same as Napoleon Bonaparte. Fouroux was named as Desclaux's successor in 1981 at the age of just 33. He continued to promote a forward-oriented style of play, and France won six Five Nations titles – including two Grand Slams – while he was coach. After nearly ten years in the role he resigned in 1990 after a defeat to Romania.

Fouroux was succeeded by Daniel Dubroca, who coached the team to the 1991 Rugby World Cup. Dubroca's tenure as coach did not last long, however, as he resigned after violently confronting referee David Bishop following France's World Cup quarter-final against England. Dubroca was replaced by Pierre Berbizier, who coached the team until after the 1995 Rugby World Cup. Berbizier's replacement, Jean-Claude Skrela, coached France to Five Nations Grand Slams in 1997 and 1998 before they came last in the tournament in 1999. He officially resigned following France's loss to Australia in the 1999 Rugby World Cup final. Bernard Laporte was appointed as Skrela's successor in November. Laporte guided France through the 2003 and 2007 Rugby World Cups before stepping down to become Secretary of State for Sport. After Philippe Saint-André turned down the offer to replace Laporte, French Rugby Federation president Bernard Lapasset appointed Marc Lièvremont to guide France to the 2011 World Cup. Lièvremont's tenure as coach was marked by inconsistent and puzzling squad selection choices, and player discontent. There were some bright moments, notably wins against New Zealand in Dunedin and South Africa in Toulouse, and the 2010 Six Nations Grand Slam. But there was also a 59–16 loss to Australia in Paris, a 22–21 loss to Italy in the 2011 Six Nations, and a 19–14 loss to Tonga during the 2011 World Cup. In August 2011, before the World Cup, it was announced that Philippe Saint-André would replace Lièvremont and guide France to the 2015 World Cup. This came as no surprise to Lièvremont, as he had announced as early as May 2010 that he would not continue as the coach of France after the World Cup.

France did not impress under Saint-André, finishing no higher than fourth in the Six Nations during his tenure and even claiming the wooden spoon in 2013. Following the 2015 Six Nations, he announced his resignation effective after that year's World Cup and was replaced by Guy Novès. France was even less impressive under Novès, with "Les Bleus" winning fewer than one-third of their matches during his tenure, capped off by a run of seven winless matches. Novès was dismissed in December 2017, becoming the first France head coach ever to be fired before the end of his contract, and was replaced by former Italy head coach Jacques Brunel, who arrived from the same position with Bordeaux Bègles. Novès' assistants were dismissed as well.

France's autumn internationals and Six Nations Championship are currently televised by the public national broadcaster France Télévisions (especially by the main channel France 2) which lasts until 2015. The summer tour matches are televised by the encrypted channel Canal plus and the World Cup matches by TF1.

French sport specialist newspapers are L'Équipe (specializing in sport) Midi Olympique (specializing in rugby).




</doc>
<doc id="959422" url="https://en.wikipedia.org/wiki?curid=959422" title="AirTrain JFK">
AirTrain JFK

AirTrain JFK is an elevated people mover system and airport rail link serving John F. Kennedy International Airport (JFK Airport) in New York City. The driverless system operates 24/7 and consists of three lines and ten stations. It connects the airport's six terminals with the New York City Subway in Howard Beach, Queens, and with the Long Island Rail Road and subway in Jamaica, Queens. Bombardier Transportation operates AirTrain JFK under contract to the airport's owner, the Port Authority of New York and New Jersey.

A railroad link to JFK Airport was first recommended in 1968. Various plans surfaced to build a JFK Airport rail connection until the 1990s, though these were not carried out because of a lack of funding. The JFK Express subway service and shuttle buses provided an unpopular transport system to and around JFK. In-depth planning for a dedicated transport system at JFK began in 1990, but was ultimately cut back from a direct rail link to an intra-borough people mover. Construction of the current people-mover system began in 1998. During construction, AirTrain JFK was the subject of several lawsuits, and an operator died during one of the system's test runs. The system opened on December 17, 2003, after many delays. Since then, several improvements have been proposed for AirTrain JFK, including an extension to Manhattan.

All passengers entering or exiting at either Jamaica or Howard Beach pay a $5 fare, while people traveling within the airport can ride for free. The system was originally projected to carry 4 million annual paying passengers and 8.4 million annual inter-terminal passengers every year. The AirTrain has consistently exceeded these projections since opening. In 2017 the system had nearly 7.7 million paying passengers and 12.6 million inter-terminal passengers.

The first proposal for a direct rail link to JFK Airport was made in 1968, when the Metropolitan Transportation Authority (MTA) suggested extending the Long Island Rail Road (LIRR) to the airport as part of the Program for Action, an ambitious transportation expansion program for the New York City area. Ultimately, the rail link was canceled altogether due to the New York City fiscal crisis of 1975. Another proposal, made by the Port Authority of New York and New Jersey in 1987, called for a rail line to connect all of JFK Airport's terminals with a new $500 million transportation center. The Port Authority withdrew its plans in 1990 after airlines objected that they could not fund the proposal.

The MTA operated the JFK Express, a premium-fare New York City Subway service that connected Midtown Manhattan to the Howard Beach–JFK Airport subway station, from 1978 to 1990. The route carried subway passengers to the Howard Beach station, where passengers would ride shuttle buses to the airport. The shuttle buses transported passengers between the different airport terminals within JFK's Central Terminal Area, as well as between Howard Beach and the terminals. The JFK Express service was unpopular with passengers because of its high cost, and because the buses often got stuck in traffic.

By the 1990s, there was demand for a direct link between Midtown Manhattan and JFK Airport, which are apart by road. During rush hour, the travel time from JFK to Manhattan could average up to 80 minutes by bus; during off-peak hours, a New York City taxi could make that journey in 45 minutes, while a bus could cover the same distance in an hour. The Port Authority, foreseeing economic growth for the New York City area and increased air traffic at JFK, began planning for a direct rail link from the airport to Manhattan. In 1991, the Port Authority introduced a Passenger Facility Charge (PFC), a $3 tax on every passenger departing from JFK, which would provide $120 million annually.

In 1990, the MTA proposed a $1.6 billion rail link to LaGuardia and JFK airports, which would be funded jointly by federal, state, and city government agencies. The rail line was to begin in Midtown Manhattan, crossing the East River into Queens via the Queensboro Bridge. It would travel to LaGuardia Airport, then make two additional stops at Shea Stadium and Jamaica before proceeding to JFK. After the Port Authority found that the ridership demand might not justify the cost of the rail link, the MTA downgraded the project's priority. The proposal was supported by Governor Mario Cuomo and Queens Borough President Claire Shulman. The transport advocacy group Regional Plan Association (RPA) called the plan "misguided", and the East Side Coalition on Airport Access's executive director said, "We are going to end up with another [...] uncompleted project in this city."

The Port Authority started reviewing blueprints for the JFK rail link in 1992. At the time, it was thought that the link could be partially open within six years. In 1994, the Port Authority set aside $40 million for engineering and marketing of the new line, and created an environmental impact statement (EIS). The project's budget had grown to $2.6 billion by that year. The EIS, conducted by the New York State Department of Transportation and the Federal Aviation Administration (FAA), found the plan to be feasible, though the project attracted opposition from area residents and advocacy groups.
The project was to start in 1996, but there were disputes over where the Manhattan terminal should be located. The Port Authority had suggested the heavily-trafficked corner of Lexington Avenue and 59th Street, though many nearby residents opposed the Manhattan terminal outright. The Port Authority did not consider a connection to the more-highly used Grand Central Terminal or Penn Station because such a connection would be too expensive and complicated. To pay for the project, the Port Authority would charge a one-way ticket price of between $9 and $12. By February 1995, the cost of the planned link had increased to over $3 billion in the previous year alone. As a result, the Port Authority considered abridging the rail link plan, seeking federal and state funding, partnering with private investors, or terminating the line at a Queens subway station.

The direct rail connection between Manhattan, LaGuardia Airport, and JFK Airport was canceled outright in May 1995. The plan had failed to become popular politically, as it would have involved increasing road tolls and PATH train fares to pay for the new link. In addition, the 1990s economic recession meant that there was little chance that the Port Authority could fund the project's rising price. Following the cancellation, the planned connection to JFK Airport was downsized to a monorail or people mover, which would travel between Howard Beach and the JFK terminals. The Port Authority initially proposed building a $827 million monorail (similar to AirTrain Newark at Newark Airport that would open the following year). In August 1995, the FAA approved the Port Authority's request to use the PFC funds for the monorail plan (the agency had already collected $114 million, and was planning to collect another $325 million). After the monorail was approved, the Port Authority hoped to begin construction in 1997 and open the line by 2002.

The Port Authority voted to proceed with the scaled-down system in 1996. Its final environmental impact statement (FEIS) for the JFK people mover, released in 1997, examined eight possibilities. Ultimately, the Port Authority opted for a light rail system with the qualities of a people mover, tentatively called the "JFK Light Rail System". It would replace the shuttle buses, running from the airport terminals to either Jamaica or Howard Beach. The FEIS determined that an automated system with frequent headways was the best design. According to "The New York Times", in the 30 years between the first proposal and the approval of the light rail system, 21 recommendations for direct rail links to New York-area airports had been canceled.

While Governor Pataki supported the revised people-mover plan, Mayor Rudy Giuliani voiced his opposition on the grounds that the city would have to contribute $300 million, and that it was not a direct rail link from Manhattan, and thus would not be profitable because of the need to transfer from Jamaica. The Port Authority was originally planning to pay for only $1.2 billion of the project, and use the other $300 million to pay the rent at the airport instead. In order to give his agreement, Giuliani wanted the Port Authority to study extending the Astoria elevated to LaGuardia Airport, as well as making the light-rail system compatible with the subway or LIRR to allow possible future interoperability. He agreed to the plan in 1997 when the state agreed to reimburse the city for its share of the system's cost. As part of the agreement, the state would also conduct a study on a similar train link to LaGuardia Airport. By that time, the Port Authority had collected $441 million in PFC funds.

In 1999, the RPA published a report in which it recommended the construction of new lines and stations for the New York City Subway. The plan included one service that would travel from Grand Central Terminal to JFK Airport via the JFK Light Rail. Ultimately, the MTA rejected the RPA's proposal.

The Port Authority could only use the funds from the Passenger Facility Charge to make improvements that exclusively benefited airport passengers. As a result, only the sections linking Jamaica and Howard Beach to JFK Airport were approved and built, since it was expected that airport travelers would be the sole users of the system. The federal government approved the use of PFC funds for the new light rail system in February 1998. Some $200 million of the project's cost was not eligible to be funded from the PFC tax because, according to the FAA, the tax funds could not be used to pay for "any costs resulting from an over-designed system", such as fare collection systems.

Construction of the system began in May 1998. Most of the system was built one span at a time, using cranes mounted on temporary structures that erected new spans as they progressed linearly along the structures. Several sections were built using a balanced cantilever design, where two separate spans were connected to each other using the span-by-span method. The Jamaica branch's location above the median of the busy Van Wyck Expressway, combined with the varying length and curves of the track spans, caused complications during construction. One lane of the Van Wyck had to be closed in each direction during off-peak hours, causing congestion.

The route ran mostly along existing rights-of-way, but three commercial properties were expropriated and demolished to make way for new infrastructure. Members of the New York City Planning Commission approved the condemnation of several buildings along the route in May 1999 but voiced concerns about the logistics of the project. These concerns included the projected high price of the tickets, ridership demand, and unwieldy transfers at Jamaica.

Though community leaders supported the project because of its connections to the Jamaica and Howard Beach station, almost all the civic groups along the Jamaica branch's route opposed it due to concerns about nuisance, noise, and traffic. There were multiple protests against the AirTrain project; during one such protest in 2000, a crane caught fire in a suspected arson. Homeowners in the vicinity believed the concrete supports would lower the value of their houses. Residents were also concerned about the noise that an elevated structure would create, and according to a 2012 study, the majority of residents' complaints were due to "nuisance violations". The Port Authority responded to residents' concerns by imposing strict rules regarding disruptive or loud construction activity, as well as implementing a streamlined damage claim process to compensate homeowners. Through 2002, there were 550 nuisance complaints over the AirTrain's construction, of which 98% had been resolved by April of that year. Not all community boards saw a high level of complaints; Queens Community Board 12, which includes the neighborhood of South Jamaica along the AirTrain's route, recorded few complaints about the construction process.

The Air Transportation Association of America (ATA) filed a federal lawsuit in January 1999 alleging misuse of PFC funds. In March, a federal judge vacated the project's approval because the FAA had incorrectly continued to collect and make use of comments posted after the deadline for public comment, but found that the PFC funds had not been misused. The FAA opened a second request for public comment and received a second approval. In 2000, two local advocacy groups filed a second federal lawsuit, claiming that the FEIS had published misleading statements about the effects of the elevated structure on southern Queens neighborhoods. The ATA and the two advocacy groups appealed the funding decision. The ATA later withdrew from the lawsuit, but one of the advocacy groups proceeded with the appeal and lost.

By the time the appeal was decided in October 2000, two-thirds of the system's viaduct structures had been erected. Construction progressed quickly, and the system was ready for its first test trains by that December. In May 2001, a $75 million renovation of the Howard Beach station was completed; the rebuilt station contained an ADA-compliant transfer to and from the AirTrain. The same month, work started on a $387 million renovation of the Jamaica LIRR station, which entailed building a transfer passageway to the AirTrain. Though the Jamaica station's rehabilitation was originally supposed to be finished by 2005, it was not actually completed until September 2006. Two AirTrain cars were delivered and tested after the system's guideway rails were complete by March 2001. The guideways themselves, located between the rails, were completed in August 2001.

The Port Authority predicted that the AirTrain's opening would create 118 jobs at JFK Airport. Service was originally planned to begin on the Howard Beach branch in October 2002, followed by the Jamaica branch in 2003, but was delayed because of several incidents during testing. In July 2002, three workers were injured during an AirTrain derailment, and in September 2002, a train operator died in another derailment. The National Transportation Safety Board's investigation of the second crash found that the train had sped excessively on a curve. As a result, the opening was postponed until June 2003, and then to December 17, 2003, its eventual opening date.

Southeast Queens residents feared the project could become a boondoggle, as the construction cost of the system had increased to $1.9 billion. Like other Port Authority properties, the AirTrain did not receive subsidies from the state or city for its operating costs. This was one of the reasons cited for the system's relatively high $5 fare, which was more than twice the subway's fare at the time of the AirTrain's opening.

Several projects were developed in anticipation of the AirTrain. By June 2003, a , 16-story building was being planned for Sutphin Boulevard across from the Jamaica station. Other nearby projects built in the preceding five years included the Jamaica Center Mall, Joseph P. Addabbo Federal Building, the Civil Court, and the Food and Drug Administration Laboratory and Offices. After AirTrain JFK began operations, Jamaica saw a boom in commerce. A 15-screen movie theater opened in the area in early 2004, and developers were also planning a 13-floor building in the area. A proposed hotel above the AirTrain terminal was canceled after the September 11, 2001, terrorist attacks.

In 2004, the city proposed rezoning 40 blocks of Jamaica, centered around the AirTrain station, as a commercial area. The mixed-use "airport village" was to consist of of space. According to the RPA, the rezoning was part of a proposal to re-envision Jamaica as a "regional center" because of the area's high usage as a transit hub. During the average weekday, 100,000 LIRR riders and 53,000 subway riders traveled to or from Jamaica. In addition, the Port Authority had estimated that the AirTrain JFK would carry 12.4 million passengers a year.

Plans to extend the AirTrain to Manhattan were examined even before the system's opening. Between September 2003 and April 2004, several agencies, including the MTA and the Port Authority, conducted a feasibility study of the Lower Manhattan–Jamaica/JFK Transportation Project, which would allow subway or LIRR trains to travel directly from JFK Airport to Manhattan. The study examined forty alternatives, but the project was halted in 2008 before an environmental impact statement could be created.

On January 4, 2017, the office of New York Governor Andrew Cuomo announced a $7–10 billion plan to renovate JFK Airport. As part of the project, the AirTrain JFK would either see lengthened trainsets or a direct track connection to the rest of New York City's transportation system, and a direct connection between the AirTrain, LIRR, and subway would be built at Jamaica station. Shortly after Cuomo's announcement, the Regional Plan Association published an unrelated study for a possible direct rail link between Manhattan and JFK Airport.

In July 2017, Cuomo's office began accepting submissions for master plans to renovate the airport. A year later, in October 2018, Cuomo released details of the project, whose cost had grown to $13 billion. The improvements included lengthening AirTrains as well as adding lanes to the Van Wyck Expressway. Work would begin in 2020 if the plan were approved.

AirTrain JFK connects the airport's terminals and parking areas with the Howard Beach and Jamaica stations. It is located entirely within the New York City borough of Queens. The system consists of three routes: two connecting the terminals with either the Howard Beach or Jamaica stations, and one route looping continuously around the central terminal area. It is operated by Bombardier under contract to the Port Authority.

The Howard Beach Train route (colored green on the official map) begins and ends at the Howard Beach–JFK Airport station, where there is a direct transfer to the New York City Subway's . It makes an additional stop at Lefferts Boulevard, where passengers can transfer to parking lot shuttle buses; the B15 bus to Brooklyn; and the limited-stop Q10 bus. The segment from Howard Beach to Federal Circle, which is about long, passes over the long-term and employee parking lots.

The Jamaica Station Train route (colored red on the official map) begins and ends at the Jamaica station, adjacent to the Long Island Rail Road platforms there. The Jamaica station contains a connection to the Sutphin Boulevard–Archer Avenue–JFK Airport station on the New York City Subway's . The AirTrain and LIRR stations contain transfers to the subway, as well as to ground-level bus routes. West of Jamaica, the line travels above the north side of 94th Avenue before curving southward onto the Van Wyck Expressway. The segment from Jamaica to Federal Circle is about long.

The Howard Beach Train and Jamaica Station Train routes merge at Federal Circle for car rental companies and shuttle buses to hotels and the airport's cargo areas. South of Federal Circle, the routes share track for and enter a tunnel before the tracks separate in two directions for the terminal loop. Both routes continue counterclockwise around the loop, stopping at Terminals 1, 2, 4, 5, 7, and 8 in that order. Connections to the Q3, Q10, and B15 local buses are available at Terminal 5. The travel time from either Jamaica or Howard Beach to the JFK terminals is about eight minutes.

The Airline Terminals Train (colored gold on the official map), an airport terminal circulator, serves the six terminals. It makes a continuous clockwise loop around the terminals, operating in the opposite direction to the Howard Beach Train and Jamaica Station Train routes. The terminal-area loop is long.

Trains to and from Jamaica and Howard Beach were originally planned to run every two minutes during peak hours, with alternate trains traveling to each branch. The final environmental impact statement projected that trains in the central terminal area would run every ninety seconds. By 2014 actual frequencies were much lower: each branch was served by one train every seven to 12 minutes during peak hours. Trains arrived every 10 to 15 minutes on each branch during weekdays; every 15 to 20 minutes during late nights; and every 16 minutes during weekends.

All AirTrain JFK stations contain elevators and are compliant with the Americans with Disabilities Act of 1990 (ADA). Each platform is long and can fit up to four cars. The stations include air conditioning, as well as platform screen doors to increase passenger safety and ensure safe operation of the unmanned trains. Each station also contains safety systems such as CCTV cameras, alarms, and emergency contact points, and is staffed by attendants.

All the stations have island platforms except for Federal Circle, which has a bi-level split platform layout. The Jamaica and Howard Beach stations are designed as "gateway stations" to give passengers the impression of entering the airport. There are also stations at Lefferts Boulevard, as well as Terminals 1, 2, 4, 5, 7, and 8. Three former terminals, numbered 3, 6, and 9, were respectively served by the stations that are now named Terminals 2, 5, and 8. The four stations outside the Central Terminal Area were originally designated with letters A–D alongside their names; the lettering was later dropped.

Except for Terminal 4, all stations in the airport are freestanding structures, and most are connected to their respective terminal buildings by an aerial walkway. Access to Terminal 2 requires passengers to use crosswalks at street level, while the Terminal 4 station is located inside the terminal building itself.

The AirTrain has a total route length of . The system consists of of single-track guideway viaducts and of double-track guideway viaducts. AirTrain JFK is mostly elevated, though there are short segments that run underground or at ground level. The elevated sections were built with precast single and dual guideway spans, while the underground sections used cut-and-cover, and the ground-level sections used concrete ties and ballast trackbeds. The single guideway viaducts carry one track each and are wide, while the double guideway viaducts carry two tracks each and are wide. Columns support the precast concrete elevated sections at intervals of up to . The elevated structures use seismic isolation bearings and soundproof barriers to protect from small earthquakes as well as prevent noise pollution.

The AirTrain runs on steel tracks that are continuously welded across all joints except at the terminals; the guideway viaducts are also continuously joined. Trains use double crossovers at the Jamaica and Howard Beach terminals in order to switch to the track going in the opposite direction. There are also crossover switches north and south of Federal Circle, counterclockwise from Terminal 8, and clockwise from Terminal 1.

The tracks are set at a gauge of . This enables possible future conversion to LIRR or subway use, or a possible connection to LIRR or subway tracks for a one-trip ride into Manhattan, since these systems use the same track gauge. AirTrain's current rolling stock, or train cars, are not able to use either LIRR or subway tracks due to the cars' inadequate structural strength and the different methods of propulsion used on each system. In particular, the linear induction motor system that propels the AirTrain vehicles is incompatible with the traction motor manual-propulsion system used by LIRR and subway rolling stock. If a one-seat ride is ever implemented, a hybrid-use vehicle would be needed to operate on both subway/LIRR and AirTrain tracks.

There are seven electrical substations. The redundancy allows trains to operate even if there are power outages at one substation. Since there are no emergency exits between stations, a control tower can automatically guide the train to its next stop in case of an emergency.

AirTrain JFK is free to use for travel within the terminal area, as well as at the stations for Lefferts Boulevard, next to the long-term parking, and Federal Circle, where there are car-rental shuttle buses and transfers to and from the airport hotels. Passengers entering or leaving the system only via the Jamaica or Howard Beach stations must pay using MetroCard.

As it has done since its opening, AirTrain accepts pay-per-ride MetroCards for $5. This is for transiting through either the Jamaica or Howard Beach gates. The MetroCards are preloaded with monetary value and $5 is deducted for each use. Cash and other forms of payment are not accepted. A $1 fee is charged for any new MetroCards.

In addition, two types of AirTrain JFK MetroCards can be purchased from vending machines at Jamaica and Howard Beach. The 30-Day AirTrain JFK MetroCard costs $40 and can be used for unlimited rides on the AirTrain for 30 days after first use. The AirTrain JFK 10-Trip MetroCard costs $25 and can be used for ten trips on the AirTrain for six months after first use. Both cards are only accepted on the AirTrain, and one trip is deducted for each use of the 10-Trip MetroCard. Other types of unlimited MetroCards are not accepted on the AirTrain.

Transferring to the Q3, Q10, or B15 buses from Terminal 5, or to the subway at Howard Beach and Jamaica, requires an additional $2.75 fare, since the MTA does not offer free transfers from the AirTrain. Passengers pay a total of $7.75 if they transfer between the AirTrain and MTA subways or buses at either Howard Beach or Jamaica. Patrons transferring from the AirTrain to a Penn Station-bound LIRR train at Jamaica pay $15.25 during peak hours, or $9.25 during off-peak periods, using the CityTicket.

The fare to enter or exit at Howard Beach and Jamaica was originally planned to be $5, with a discount to $2 for airport and airline employees. The original proposal also called for fare-free travel between airport terminals, a recommendation that was ultimately implemented.

AirTrain JFK uses Bombardier Transportation's Innovia Metro rolling stock and technology. Similar systems are used on the SkyTrain in Vancouver, British Columbia, Canada, and on the Kelana Jaya Line in Kuala Lumpur, Malaysia. The computerized trains are fully automated and use a communications-based train control system with moving block signals to dynamically determine the locations of the trains. AirTrain JFK is a wholly driverless system, and it uses SelTrac train-signaling technology manufactured by Thales Group. Trains are operated from and maintained at a train yard between Lefferts Boulevard and Federal Circle, atop a former employee parking lot. The system uses pre-recorded announcements by New York City traffic reporter Bernie Wagenblast, a longtime employee of the Port Authority.

The 32 individual, non-articulated Mark II vehicles operating on the line draw power from a 750 V DC top-running third rail. A linear induction motor pushes magnetically against an aluminum strip in the center of the track. The vehicles also have steerable trucks that can navigate sharp curves and steep grades, as well as align precisely with the platform doors at the stations. The cars can run at up to , and they can operate on trackage with a minimum railway curve radius of .

Each car is long and wide, which is similar to the dimensions of rolling stock used on the New York City Subway's B Division. Trains can run in either direction and can consist of between one and four cars. The cars contain two pairs of doors on each side. An individual car has 26 seats and can carry up to 97 passengers with luggage, or 205 without luggage. But because most passengers carry luggage, the actual operating capacity is between 75 and 78 passengers per car.

When AirTrain JFK was being planned, it was expected that 11,000 passengers per day would pay to ride the system between the airport and either Howard Beach or Jamaica, and that 23,000 more daily passengers would use the AirTrain to travel between terminals. This would amount to about 4 million paying passengers and 8.4 million in-airport passengers per year. According to the FEIS, the system could accommodate over 3,000 daily riders from Manhattan, and its opening would result in approximately 75,000 fewer vehicle miles ( kilometers) being driven each day.

During the first month of service, an average of 15,000 passengers rode the system each day. Though this figure was less than the expected daily ridership of 34,000, the AirTrain JFK had become the second-busiest airport transportation system in the United States. Within its first six months, AirTrain JFK had transported 1 million riders.

The AirTrain's ridership has risen each year since then. In 2017, there were 7,655,901 passengers who paid to travel between JFK Airport and either Howard Beach or Jamaica. This represents a 292% increase over 2004, the first full year of operation, when 2,623,791 riders paid. An additional 12.6 million people are estimated to have ridden the AirTrain for free in 2017. One possible factor in the AirTrain's increasing ridership is the $7.75 fare for AirTrain and subway, which is cheaper than the $45 taxi ride between Manhattan and JFK.




</doc>
<doc id="965178" url="https://en.wikipedia.org/wiki?curid=965178" title="HMAS Australia (1911)">
HMAS Australia (1911)

HMAS "Australia" was one of three s built for the defence of the British Empire. Ordered by the Australian government in 1909, she was launched in 1911, and commissioned as flagship of the fledgling Royal Australian Navy (RAN) in 1913. "Australia" was the only capital ship ever to serve in the RAN.

At the start of World War I, "Australia" was tasked with finding and destroying the German East Asia Squadron, which was prompted to withdraw from the Pacific by the battlecruiser's presence. Repeated diversions to support the capture of German colonies in New Guinea and Samoa, as well as an overcautious Admiralty, prevented the battlecruiser from engaging the German squadron before the latter's destruction. "Australia" was then assigned to North Sea operations, which consisted primarily of patrols and exercises, until the end of the war. During this time, "Australia" was involved in early attempts at naval aviation, and 11 of her personnel participated in the Zeebrugge Raid. The battlecruiser was not at the Battle of Jutland, as she was undergoing repairs following a collision with sister ship . "Australia" only ever fired in anger twice: at a German merchant vessel in January 1915, and at a suspected submarine contact in December 1917.

On her return to Australian waters, several sailors aboard the warship mutinied after a request for an extra day's leave in Fremantle was denied, although other issues played a part in the mutiny, including minimal leave during the war, problems with pay, and the perception that Royal Navy personnel were more likely to receive promotions than Australian sailors. Post-war budget cuts saw "Australia"s role downgraded to a training ship before she was placed in reserve in 1921. The disarmament provisions of the Washington Naval Treaty required the destruction of "Australia" as part of the British Empire's commitment, and she was scuttled off Sydney Heads in 1924.

The "Indefatigable" class of battlecruisers were based heavily on the preceding . The main difference was that the "Indefatigable"s design was enlarged to give the ships' two wing turrets a wider arc of fire. As a result, the "Indefatigable" class was not a significant improvement on the "Invincible" design; the ships were smaller and not as well protected as the contemporary German battlecruiser and subsequent German designs. While "Von der Tann"s characteristics were not known when the lead ship of the class, , was laid down in February 1909, the Royal Navy obtained accurate information on the German ship before work began on "Australia" and her sister ship .

"Australia" had an overall length of , a beam of , and a maximum draught of . The ship displaced at load and at deep load. She had a crew of 818 officers and ratings in 1913.

The ship was powered by two sets of Parsons direct-drive steam turbines, each driving two propeller shafts, using steam provided by 31 coal-burning Babcock & Wilcox boilers. The turbines were rated at and were intended to give the ship a maximum speed of . However, during trials in 1913, "Australia" turbines provided , allowing her to reach . "Australia" carried enough coal and fuel oil to give her a range of at a cruising speed of .

"Australia" carried eight BL 12-inch Mark X guns in four BVIII* twin turrets; the largest guns fitted to any Australian warship. Two turrets were mounted fore and aft on the centreline, identified as 'A' and 'X' respectively. The other two were wing turrets mounted amidships and staggered diagonally: 'P' was forward and to port of the centre funnel, while 'Q' was situated starboard and aft. Each wing turret had some limited ability to fire to the opposite side. Her secondary armament consisted of sixteen BL 4-inch Mark VII guns positioned in the superstructure. She mounted two submerged tubes for 18-inch torpedoes, one on each side aft of 'X' barbette, and 12 torpedoes were carried.

The "Indefatigable"s were protected by a waterline armoured belt that extended between and covered the end barbettes. Their armoured deck ranged in thickness between with the thickest portions protecting the steering gear in the stern. The main battery turret faces were thick, and the turrets were supported by barbettes of the same thickness.

"Australia"s 'A' turret was fitted with a rangefinder at the rear of the turret roof. It was also equipped to control the entire main armament, in case normal fire control positions were knocked out or rendered inoperable.

"Australia" received a single QF 3-inch 20 cwt (76 mm) anti-aircraft (AA) gun on a high-angle Mark II mount that was added in March 1915. This had a maximum depression of 10° and a maximum elevation of 90°. It fired a shell at a muzzle velocity of at a rate of fire of 12–14 rounds per minute. It had a maximum effective ceiling of . It was provided with 500 rounds. The 4-inch guns were enclosed in casemates and given blast shields during a refit in November 1915 to better protect the gun crews from weather and enemy action, and two aft guns were removed at the same time. An additional 4-inch gun was fitted in during 1917 as an AA gun. It was mounted on a Mark II high-angle mounting with a maximum elevation of 60°. It had a reduced propellant charge with a muzzle velocity of only ; 100 rounds were carried for it.
"Australia" received a fire-control director sometime between mid-1915 and May 1916; this centralised fire control under the director officer, who now fired the guns. The turret crewmen merely had to follow pointers transmitted from the director to align their guns on the target. This greatly increased accuracy, as it was easier to spot the fall of shells and eliminated the problem of the ship's roll dispersing the shells when each turret fired independently. "Australia" was also fitted with an additional inch of armour around the midships turrets following the Battle of Jutland.

By 1918, "Australia" carried a Sopwith Pup and a Sopwith 1½ Strutter on platforms fitted to the top of 'P' and 'Q' turrets. The first flying off by a 1½ Strutter was from "Australia"s 'Q' turret on 4 April 1918. Each platform had a canvas hangar to protect the aircraft during inclement weather. At the end of World War I, "Australia" was described as "the least obsolescent of her class".

After the war, both anti-aircraft guns were replaced by a pair of QF 4-inch Mark V guns on manually operated high-angle mounts in January 1920. Their elevation limits were −5° to 80°. The guns fired a shell at a muzzle velocity of at a rate of fire of 10–15 rounds per minute. They had a maximum effective ceiling of .

At the start of the 20th century, the British Admiralty maintained that naval defence of the British Empire, including the Dominions, should be unified under the Royal Navy. Attitudes on this matter softened during the first decade, and at the 1909 Imperial Conference, the Admiralty proposed the creation of 'Fleet Units': forces consisting of a battlecruiser, three light cruisers, six destroyers, and three submarines. Although some were to be operated by the Royal Navy at distant bases, particularly in the Far East, the Dominions were encouraged to purchase fleet units to serve as the core of new national navies: Australia and Canada were both encouraged to do so at earliest opportunity, New Zealand was asked to partially subsidise a fleet unit for the China Station, and there were plans for South Africa to fund one at a future point. Each fleet unit was designed as a "navy in miniature", and would operate under the control of the purchasing Dominion during peacetime. In the event of widespread conflict, the fleet units would come under Admiralty control, and would be merged to form larger fleets for regional defence. Australia was the only Dominion to purchase a full fleet unit, and while the New Zealand-funded battlecruiser was donated to the Royal Navy outright, no other nation purchased ships under the fleet unit plan.

On 9 December 1909, a cable was sent by Governor-General Lord Dudley to the Secretary of State for the Colonies, The Earl of Crewe, requesting that construction of three cruisers and an "Indefatigable"-class battlecruiser start at earliest opportunity. It is unclear why this design was selected, given that it was known to be inferior to the battlecruisers entering service with the German Imperial Navy ("Kaiserliche Marine"). Historian John Roberts has suggested that the request may have been attributable to the Royal Navy's practice of using small battleships and large cruisers as flagships of stations far from Britain, or it might have reflected the preferences of the First Sea Lord and Admiral of the Fleet John Fisher, preferences not widely shared.

The Australian Government decided on the name "Australia", as this would avoid claims of favouritism or association with a particular state. The ship's badge depicted the Federation Star overlaid by a naval crown, and her motto was "Endeavour", reflecting both an idealisation of Australians' national spirit and attitude, and a connection to James Cook and HM Bark "Endeavour". On 6 May 1910, George Reid, Australia's high commissioner to the United Kingdom, sent a telegram cable to the Australian Government suggesting that the ship be named after the newly crowned King George V, but this was rebuffed.

Bids for construction were forwarded to the Australian Government by Reid on 7 March 1910, and Prime Minister Alfred Deakin approved the submission by John Brown & Company to construct the hull and machinery, with separate contracts awarded to Armstrong and Vickers for the battlecruiser's armament. The total cost of construction was set at £2 million. Contracts were signed between the Admiralty and the builders to avoid the problems of distant supervision by the Australian Government, and a close watch on proceedings was maintained by Reid and Captain Francis Haworth-Booth, the Australian Naval Representative in London.

"Australia"s keel was laid at John Brown & Company's Clydebank yard on 23 June 1910, and was assigned the yard number 402. The ship was launched by Lady Reid on 25 October 1911, in a ceremony which received extensive media coverage. "Australia"s design was altered during construction to incorporate improvements in technology, including the newly developed nickel-steel armour plate. While it was intended that the entire ship be fitted with the new armour, manufacturing problems meant that older armour had to be used in some sections: the delay in sourcing the older armour plates set construction back half a year. Despite this, John Brown & Company delivered the ship £295,000 under budget.

During construction, First Lord of the Admiralty Winston Churchill attempted to arrange for "Australia" to remain in British waters on completion. Although the claim was made on strategic grounds, the reasoning behind it was so the Australian-funded ship could replace one to be purchased with British defence funds. This plan was successfully resisted by Admiral George King-Hall, then Commander-in-Chief of the Royal Navy's Australia Squadron.
"Australia" sailed for Devonport, Devon in mid-February 1913 to begin her acceptance trials. Testing of the guns, torpedoes, and machinery was successful, but it was discovered that two hull plates had been damaged during the launch, requiring the battlecruiser to dock for repairs. "Australia" was commissioned into the RAN at Portsmouth on 21 June 1913. Two days later, Rear Admiral George Patey, the first Rear Admiral Commanding Australian Fleet, raised his flag aboard "Australia".

At launch, the standard ship's company was 820, over half of which were Royal Navy personnel; the other half was made up of Australian-born RAN personnel, or Britons transferring from the Royal Navy to the RAN. Accommodation areas were crowded, with each man having only of space to sling his hammock when "Australia" was fully manned. Moreover, the ventilation system was designed for conditions in Europe, and was inadequate for the climate in and around Australia. On delivery, "Australia" was the largest warship in the Southern Hemisphere.

Following her commissioning, "Australia" hosted several official events. On 30 June, King George V and Edward, Prince of Wales, visited "Australia" to farewell the ship. During this visit, King George knighted Patey on the ship's quarterdeck—the first time a naval officer was knighted aboard a warship since Francis Drake. On 1 July, Patey hosted a luncheon which was attended by imperial dignitaries, including Reid, the Agents-General of the Australian states, First Lord of the Admiralty Winston Churchill, Secretary of State for the Colonies Lewis Harcourt, and the High Commissioners of other British Dominions. That afternoon, 600 Australian expatriates were invited to a ceremonial farewelling, and were entertained by shows and fireworks. Journalists and cinematographers were allowed aboard to report on "Australia" prior to her departure, and an official reporter was embarked for the voyage to Australia: his role was to promote the ship as a symbol of the bond between Australia and the United Kingdom.
"Australia" was escorted by the light cruiser during the voyage to Australia. On 25 July, the two ships left England for South Africa: the visit was part of an agreement between the Prime Ministers of Australia and South Africa to promote the link between the two nations, along with the nations' links to the rest of the British Empire. The two ships were anchored in Table Bay from 18 to 26 August, during which the ships' companies participated in parades and receptions, while tens of thousands of people came to observe the ships. The two ships also visited Simon's Town, while "Australia" additionally called into Durban. No other major ports were visited on the voyage, and the warships were instructed to avoid all major Australian ports.

"Australia" and "Sydney" reached Jervis Bay on 2 October, where they rendezvoused with the rest of the RAN fleet (the cruisers and , and the destroyers , , and ). The seven warships prepared for a formal fleet entry into Sydney Harbour. On 4 October, "Australia" led the fleet into Sydney Harbour, where responsibility for Australian naval defence was passed from the Royal Navy's Australia Squadron, commanded by King-Hall aboard , to the RAN, commanded by Patey aboard "Australia".

In her first year of service, "Australia" visited as many major Australian ports as possible, to expose the new navy to the widest possible audience and induce feelings of nationhood: naval historian David Stevens claims that these visits did more to break down state rivalries and promote the unity of Australia as a federated commonwealth than any other event. During late 1913, footage for the film "Sea Dogs of Australia" was filmed aboard the battlecruiser; the film was withdrawn almost immediately after first screening in August 1914 because of security concerns.
During July 1914, "Australia" and other units of the RAN fleet were on a training cruise in Queensland waters. On 27 July, the Australian Commonwealth Naval Board learned through press telegrams that the British Admiralty thought that there would be imminent and widespread war in Europe following the July Crisis, and had begun to position its fleets as a precaution. Three days later, the Board learned that the official warning telegram had been sent: at 22:30, "Australia" was recalled to Sydney to take on coal and stores.

On 3 August, the RAN was placed under Admiralty control. Orders for RAN warships were prepared over the next few days: "Australia" was assigned to the concentration of British naval power on the China Station, but was allowed to seek out and destroy any armoured warships (particularly those of the German East Asia Squadron) in the Australian Station before doing so. Vice Admiral Maximilian von Spee, commander of the German squadron, was aware of "Australia"s presence in the region and her superiority to his entire force; the German admiral's plan was to harass British shipping and colonies in the Pacific until the presence of "Australia" and the China Squadron forced his fleet to relocate to other seas.

The British Empire declared war on Germany on 5 August, and the RAN swung into action. "Australia" had departed Sydney the night before, and was heading north to rendezvous with other RAN vessels south of German New Guinea. The German colonial capital of Rabaul was considered a likely base of operations for von Spee, and Patey put together a plan to clear the harbour. "Australia"s role was to hang back: if the armoured cruisers and were present, the other RAN vessels would lure them into range of the battlecruiser. The night-time operation was executed on 11 August, and no German ships were found in the harbour. Over the next two days, "Australia" and the other ships unsuccessfully searched the nearby bays and coastline for the German ships and any wireless stations, before returning to Port Moresby to refuel.

In late August, "Australia" and escorted a New Zealand occupation force to German Samoa. Patey believed that the German fleet was likely to be in the eastern Pacific, and Samoa would be a logical move. Providing protection for the New Zealand troopships was a beneficial coincidence, although the timing could have been better, as an Australian expedition to occupy German New Guinea departed from Sydney a few days after the New Zealand force left home waters—"Australia" was expected to support both, but Patey only learned of the expeditions after they had commenced their journeys. The battlecruiser left Port Moresby on 17 August and was met by "Melbourne" en route on 20 August. The next day, they reached Nouméa and the New Zealand occupation force, consisting of the troopships "Moeraki" and "Monowai", the French cruiser , and three s. The grounding of "Monowai" delayed the expedition's departure until 23 August; the ships reached Suva, Fiji on 26 August, and arrived off Apia early in the morning of 30 August. The city surrendered without a fight, freeing "Australia" and "Melbourne" to depart at noon on 31 August to meet the Australian force bound for Rabaul.
The Australian invasion force had mustered off the Louisiade Archipelago by 9 September; the assembled ships included "Australia", the cruisers , and , the destroyers , , and , the submarines and , the auxiliary cruiser , the storeship , three colliers and an oiler. The force sailed north, and at 06:00 on 11 September, "Australia" deployed two picket boats to secure Karavia Bay for the expeditionary force's transports and supply ships. Later that day, "Australia" captured the German steamer "Sumatra" off Cape Tawui. After this, the battlecruiser stood off, in case she was required to shell one of the two wireless stations the occupation force was attempting to capture. The German colony was captured, and on 15 September, "Australia" departed for Sydney.

The presence of "Australia" around the former German colonies, combined with the likelihood of Japan declaring war on Germany, prompted von Spee to withdraw his ships from the region. On 13 August, the East Asia Squadron—with the exception of , which was sent to prey on British shipping in the Indian Ocean—had begun to move eastwards. After appearing off Samoa on 14 September, then attacking Tahiti eight days later, von Spee led his force to South America, and from there planned to sail for the Atlantic. Patey was ordered on 17 September to head back north with "Australia" and "Sydney" to protect the Australian expeditionary force. On 1 October, "Australia", "Sydney", "Montcalm", and "Encounter" headed north from Rabaul to find the German ships, but turned around to return at midnight, after receiving an Admiralty message about the Tahiti attack. Although Patey suspected that the Germans were heading for South America and wanted to follow with "Australia", the Admiralty was unsure that the intelligence was accurate, and tasked the battlecruiser with patrolling around Fiji in case they returned. "Australia" reached Suva on 12 October, and spent the next four weeks patrolling the waters around Fiji, Samoa, and New Caledonia: despite Patey's desires to range out further, Admiralty orders kept him chained to Suva until early November.

As Patey predicted, von Spee had continued east, and it was not until his force inflicted the first defeat on the Royal Navy in 100 years at the Battle of Coronel that "Australia" was allowed to pursue. Departing on 8 November, the battlecruiser replenished coal from a pre-positioned collier on 14 November, and reached Chamela Bay (near Manzanillo, Mexico) 12 days later. Patey was made commander of a multinational squadron tasked with preventing the German squadron from sailing north to Canadian waters, or following them if they attempted to enter the Atlantic via the Panama Canal or around Cape Horn. Patey's ships included "Australia", the British light cruiser and the Japanese cruisers , , and the ex-Russian battleship "Hizen". The ships made for the Galapagos Islands, which were searched from 4 to 6 December. After finding no trace of von Spee's force, the Admiralty ordered Patey to investigate the South American coast from Perlas Island down to the Gulf of Guayaquil. The German squadron had sailed for the Atlantic via Cape Horn, and was defeated by a British fleet after attempting to raid the Falkland Islands on 8 December. Patey's squadron learned of this 10 December, while off the Gulf of Panama; "Australia"s personnel were disappointed that they did not have the chance to take on "Scharnhorst" and "Gneisenau". Nevertheless, the battlecruiser's presence in the Pacific during 1914 had provided an important counter to the German armoured cruisers, and enabled the RAN to participate in the Admiralty's global strategy. Moreover, it is unlikely that the attack on Rabaul would have gone ahead had "Australia" not been available to protect the landing force.

As the threat of a German naval attack had been removed by the destruction of the East Asia Squadron, "Australia" was free for deployment elsewhere. Initially, the battlecruiser was to serve as flagship of the West Indies Squadron, with the task of pursuing and destroying any German vessels that evaded North Sea blockades. "Australia" was ordered to sail to Jamaica via the Panama Canal, but as it was closed to heavy shipping, she was forced to sail down the coast of South America and pass through the Strait of Magellan during 31 December 1914 and 1 January 1915—"Australia" is the only ship of the RAN to cross from the Pacific to the Atlantic by sailing under South America. During the crossing, one of the warship's propellers was damaged, and she had to limp to the Falkland Islands at half speed. Temporary repairs were made, and "Australia" departed on 5 January. A vessel well clear of the usual shipping routes was spotted on the afternoon of the next day, and the battlecruiser attempted to pursue, but was hampered by the damaged propeller. Unable to close the gap before sunset, a warning shot was fired from 'A' turret, which caused the ship—the former German passenger liner, now naval auxiliary "Eleonora Woermann"—to stop and be captured. As "Australia" could not spare enough personnel to secure and operate the merchant ship, and "Eleonora Woermann" was too slow to keep pace with the battlecruiser, the German crew were taken aboard and the ship was sunk.
Following the Battle of Dogger Bank, the Admiralty saw the need for dedicated battlecruiser squadrons in British waters, and earmarked "Australia" to lead one of them. On 11 January, while en route to Jamaica, "Australia" was diverted to Gibraltar. Reaching there on 20 January, the battlecruiser was ordered to proceed to Plymouth, where she arrived on 28 January and paid off for a short refit. The docking was completed on 12 February, and "Australia" reached Rosyth on 17 February after sailing through a gale. She was made flagship of the 2nd Battlecruiser Squadron (2nd BCS) of the Battlecruiser Fleet, part of the British Grand Fleet, on 22 February. Vice Admiral Patey was appointed to command this squadron. In early March, to avoid a conflict of seniority between Patey and the leader of the Battlecruiser Fleet, Vice Admiral David Beatty, Patey was reassigned to the West Indies, and Rear Admiral William Pakenham raised his flag aboard "Australia". British and Allied ships deployed to the North Sea were tasked with protecting the British Isles from German naval attack, and keeping the German High Seas Fleet penned in European waters through a distant blockade while trying to lure them into a decisive battle. During her time with the 2nd BCS, "Australia"s operations primarily consisted of training exercises (either in isolation or with other ships), patrols of the North Sea area in response to actual or perceived German movements, and some escort work. These duties were so monotonous, one sailor was driven insane.

"Australia" joined the Grand Fleet in a sortie on 29 March, in response to intelligence that the German fleet was leaving port as the precursor to a major operation. By the next night, the German ships had withdrawn, and "Australia" returned to Rosyth. On 11 April, the British fleet was again deployed on the intelligence that a German force was planning an operation. The Germans intended to lay mines at the Swarte Bank, but after a scouting Zeppelin located a British light cruiser squadron, they began to prepare for what they thought was a British attack. Heavy fog and the need to refuel caused "Australia" and the British vessels to return to port on 17 August, and although they were redeployed that night, they were unable to stop two German light cruisers from laying the minefield. From 26 to 28 January 1916, the 2nd BCS was positioned off the Skagerrak while the 1st Light Cruiser Squadron swept the strait in an unsuccessful search of a possible minelayer.
On the morning of 21 April, "Australia" and her sister ships sailed again for the Skagerrak, this time to support efforts to disrupt the transport of Swedish ore to Germany. The planned destroyer sweep of the Kattegat was cancelled when word came that the High Seas Fleet was mobilising for an operation of their own (later learned to be timed to coincide with the Irish Easter Rising), and the British ships were ordered to a rendezvous point in the middle of the North Sea, while the rest of the Grand Fleet made for the south-eastern end of the Long Forties. On the afternoon of 22 April, the Battlecruiser Fleet was patrolling to the north-west of Horn Reefs when heavy fog came down. The ships were zigzagging to avoid submarine attack, which, combined with the weather conditions, caused "Australia" to collide with sister ship twice in three minutes. Procedural errors were found to be the cause of the collisions, which saw "Australia" (the more heavily damaged of the two ships) docked for six weeks of repairs between April and June 1916. Initial inspections of the damage were made in a floating dock on the River Tyne, but the nature of the damage required a diversion to Devonport, Devon for the actual repair work. The repairs were completed more quickly than expected, and "Australia" rejoined the 2nd BCS Squadron at Rosyth on 9 June, having missed the Battle of Jutland.

On the evening of 18 August, the Grand Fleet put to sea in response to a message deciphered by Room 40, which indicated that the High Seas Fleet, minus II Squadron, would be leaving harbour that night. The German objective was to bombard Sunderland on 19 August, with extensive reconnaissance provided by airships and submarines. The Grand Fleet sailed with 29 dreadnought battleships and 6 battlecruisers. Throughout the next day, Jellicoe and Scheer received conflicting intelligence, with the result that having reached its rendezvous in the North Sea, the Grand Fleet steered north in the erroneous belief that it had entered a minefield before turning south again. Scheer steered south-eastward to pursue a lone British battle squadron sighted by an airship, which was in fact the Harwich Force under Commodore Tyrwhitt. Having realised their mistake, the Germans changed course for home. The only contact came in the evening when Tyrwhitt sighted the High Seas Fleet but was unable to achieve an advantageous attack position before dark, and broke off. Both the British and German fleets returned home, with two British cruisers sunk by submarines and a German dreadnought battleship damaged by a torpedo.

The year 1917 saw a continuation of the battlecruiser's routine of exercises and patrols into the North Sea, with few incidents. During this year "Australia"s activities were limited to training voyages between Rosyth and Scapa Flow and occasional patrols to the north-east of Britain in search of German raiders. In May, while preparing the warship for action stations, a 12-inch shell became jammed in the shell hoist when its fuze became hooked onto a projection. After the magazines were evacuated, Lieutenant-Commander F. C. Darley climbed down the hoist and successfully removed the fuze. On 26 June, King George V visited the ship. On 12 December, "Australia" was involved in a second collision, this time with the battlecruiser . Following this accident, she underwent three weeks of repairs from December 1917 until January 1918. During the repair period, "Australia" became the first RAN ship to launch an aircraft, when a Sopwith Pup took off from her quarterdeck on 18 December. On 30 December, "Australia" shelled a suspected submarine contact, the only time during her deployment with the 2nd BCS that she fired on the enemy.
In February 1918, the call went out for volunteers to participate in a special mission to close the port of Zeebrugge using blockships. Although many aboard "Australia" volunteered their services in an attempt to escape the drudgery of North Sea patrols, only 11 personnel—10 sailors and an engineering lieutenant—were selected for the raid, which occurred on 23 April. The lieutenant was posted to the engine room of the requisitioned ferry , and was awarded the Distinguished Service Medal (DSM) for his efforts. The other Australians were assigned to the boiler rooms of the blockship , or as part of a storming party along the mole. All ten sailors survived—"Australia" was the only ship to have no casualties from the raid—and three were awarded the DSM, while another three were mentioned in dispatches. One of the sailors was listed in the ballot to receive a Victoria Cross, but he did not receive the award.

During 1918, "Australia" and the Grand Fleet's other capital ships on occasion escorted convoys travelling between Britain and Norway. The 2nd BCS spent the period from 8 to 21 February covering these convoys in company with battleships and destroyers, and put to sea on 6 March in company with the 1st Battlecruiser Squadron to support minelayers. From 8 March on, the battlecruiser tested the capabilities of aircraft launched from platforms mounted over 'P' and 'Q' turrets. "Australia", along with the rest of the Grand Fleet, sortied on the afternoon of 23 March 1918 after radio transmissions had revealed that the High Seas Fleet was at sea after a failed attempt to intercept the regular British convoy to Norway. However, the Germans were too far ahead of the British and escaped without firing a shot. The 2nd BCS sailed again on 25 April to support minelayers, then cover one of the Scandinavian convoys the next day. Following the successful launch of a fully laden Sopwith 1½ Strutter scout plane on 14 May, "Australia" started carrying two aircraft—a Strutter for reconnaissance, and a Sopwith Camel fighter—and operated them until the end of the war. The 2nd BCS again supported minelayers in the North Sea between 25–26 June and 29–30 July. During September and October, "Australia" and the 2nd BCS supervised and protected minelaying operations north of Orkney.

When the armistice with Germany was signed on 11 November 1918 to end World War I, one of the conditions was that the German High Seas Fleet was to be interred at Scapa Flow. The German fleet crossed the North Sea, and on 21 November, the British Grand Fleet sailed out to meet it; "Australia" led the port division of the fleet. "Australia" then escorted the battlecruiser to Scapa Flow, and was assigned as the German vessel's guardship. "Australia" subsequently formed part of the force which guarded the High Seas Fleet during late 1918 and early 1919, and spent much of her time either at anchor at Scapa Flow, or conducting patrols in the North Sea. This monotonous duty contributed to low morale among some sections of the ship's crew.
After being formally farewelled by the Prince of Wales and First Sea Lord Rosslyn Wemyss on 22 April 1919, "Australia" departed from Portsmouth for home the next day. She sailed in company with for the first part of the voyage, but the light cruiser later had to detach to tow the submarine . "Australia" arrived in Fremantle on 28 May 1919, the first time the ship had seen home waters in four and a half years. Despite returning home, the battlecruiser remained under Admiralty control until 1 August 1919.

"Australia" was not awarded any official battle honours, although personnel aboard the battlecruiser and her successor claimed the operations in the Pacific, the North Sea patrol duties, and the battlecruiser's presence at the surrender of the German High Seas Fleet as unofficial honours. Following a reorganisation of RAN battle honours in 2010, the honours "Rabaul 1914" and "North Sea 1915–18" were retroactively awarded on 1 March 2010.

"Australia"s ship's company had consistently suffered from low morale since the battlecruiser entered service, and the proportion of "Australia"s sailors who were placed on disciplinary charges during World War I was among the highest in the RAN. Many of the Australian sailors were chafing under the severity of naval discipline and what they saw as excessive punishment for minor breaches; one example was of a sailor who was charged with desertion, imprisoned for three months, and lost all pay for staying out too late on Armistice Day. Factors which contributed to low morale and poor discipline included frustration at not participating in the Battle of Jutland, high rates of illness, limited opportunities for leave, delays or complete lack of deferred pay, and poor-quality food. The continuation of strict wartime routines and discipline after the armistice frustrated the ship's crew. There was also the perception that "Australia"s British personnel were being promoted faster than their Australian counterparts and were dominating leadership positions. The battlecruiser's arrival in Fremantle on 28 May was met with extensive hospitality, which was reciprocated where possible by the sailors with invitations and tours of their vessel. There were opportunities for shore leave, but these were limited as "Australia" was only in port for three days, and had to sail early on 1 June for Melbourne.
Representatives of the ship's company approached Captain Claude Cumberlege to ask for a one-day delay on departure; this would allow the sailors to have a full weekend of leave, give Perth-born personnel the chance to visit their families, and give personnel another chance to invite people aboard. Cumberlege replied that as "Australia" had a tight schedule of "welcome home" port visits, such delays could not even be considered. The next morning, at around 10:30, between 80 and 100 sailors gathered in front of 'P' turret, some in working uniform, others who had just returned from shore leave still in libertyman rig. Cumberlege sent the executive officer to find out why the men had assembled, and on learning that they were repeating the previous day's request for a delay in departure, went down to address them. In a strict, legalistic tone, he informed the sailors that delaying "Australia"s departure was impossible, and ordered them to disperse. The group obeyed this order, although some were vocal in their displeasure. Shortly after, "Australia" was ready to depart, but when the order to release the mooring lines and get underway was given, Cumberlege was informed that the stokers had abandoned the boiler rooms. After the assembly on deck, some sailors had masked themselves with black handkerchiefs, and encouraged or intimidated the stokers on duty into leaving their posts, leaving the navy's flagship stranded at the buoy, in full view of dignitaries and crowds lining the nearby wharf. The senior non-commissioned officers, along with sailors drafted from other departments, were sent to the boiler room to get "Australia" moving, and departure from Fremantle was only delayed by an hour.

Australian naval historians David Stevens and Tom Frame disagree on what happened next. Stevens states that Cumberledge assembled the ship's company in the early afternoon, read the "Articles of War", lectured them on the seriousness of refusing duty, then ordered the stokers to go to their stations, which they did meekly. Frame claims the stokers returned to duty freely once the battlecruiser was underway, before Cumberledge cleared lower deck and spoke to the sailors. After addressing the sailors, Cumberledge gathered the ship's senior officers for an inquiry. Five men, including the Victoria Cross nominee from the Zeebrugge raid, were charged with inciting a mutiny and arrested pending a court-martial, which was held aboard on 20 June, after "Australia" arrived in Sydney. The ruling was that the five men had "joined a mutiny, not accompanied by violence", and they were sentenced to imprisonment in Goulburn Gaol: two for a year, one for eighteen months, and two for two years with hard labour. A number of other sailors were charged with participating in a mutiny, but again, Stevens and Frame disagree on details: the former claims 7 men were successfully charged, while the latter says 32 sailors were subsequently acquitted of mutiny, but then successfully charged with refusing duty. Both authors agree that these men were tried by the captain while "Australia" was still at sea, and punished with 90 days each in cells.

Following the court-martial of the five ringleaders, there was debate among the public, in the media, and within government over the sentences; while most agreed that a mutiny had occurred, there were differences in opinion on the leniency or severity of the punishments imposed. Public sympathy was with the sailors, and several politicians pressured the government and the Admiralty to pardon the men. The Admiralty thought the sentences were fair, but on 10 September announced that they would be halved on consideration of the sailors' youth. Despite this, controversy continued until 21 November: after the Australian government appealed directly to the Admiralty, it was agreed that the sailors would be released on 20 December. However, the government had angered the Naval Board in appealing to the Admiralty without consulting the Board first. The First Naval Member, Rear Admiral Percy Grant and Commander of the Fleet, Commodore John Dumaresq, submitted their resignations in protest, as they felt the show of clemency would lead to a breakdown in discipline, and that if the government continued to communicate with the Admiralty without consulting the Board, it would undermine the Board's authority. The two officers were later convinced to withdraw their resignations after receiving assurances that Board would be consulted before all future government communications to Britain regarding the RAN, and that notices would be posted in all ships explaining that the sentences were correct, but the onset of peace had led to clemency in this particular case.

In May 1920, "Australia" participated in celebrations and naval activities associated with the visit of the Prince of Wales. From July to November 1920, an Avro 504 floatplane of the Australian Air Corps was embarked aboard "Australia" as part of a series of trials intended to cumulate in the creation of a naval aviation branch. The aircraft was stored on the quarterdeck next to 'Q' turret, and was deployed and recovered by derrick. Inter-service rivalry and the ship's reduction to non-seagoing status in September prevented further operations.

Following the demise of German naval power in the Pacific the fleet unit concept was no longer seen as being relevant, and "Australia" did not have a clear role. As a result, post-war budget cuts prompted the RAN to take the battlecruiser out of active service, as the large share of resources and manpower consumed by "Australia" could be better used elsewhere in the RAN. In August 1920 the battlecruiser was rated by the Naval Board as 11th out of the RAN's 12 priorities. Accordingly, the ship's company was reduced later that year and she was assigned to Flinders Naval Depot as a gunnery and torpedo training ship. In the event of a major conflict, "Australia" was to serve in a role akin to coastal artillery. She was not considered to have been placed in reserve at this time, however, as it was not possible for the RAN to provide a trained complement at short notice.

"Australia" returned to Sydney in November 1921, and was paid off into reserve in December. By this time battlecruisers built before the Battle of Jutland were considered obsolete, and there is no record of the Admiralty suggesting that Australia purchase a replacement. Moreover, it is unlikely that the Australian Government would have agreed to such a suggestion given the prevailing political and financial conditions. As the Admiralty had decided to phase out 12-inch guns and had stopped the manufacture of shells for these weapons shortly after the war, it would have been necessary to replace "Australia"s main armament once the Navy's stock of shells reached their expiry date given that it was not possible to produce replacement shells in Australia. This was also not financially feasible for the government, particularly given the RAN's lack of interest in retaining the ship.

The 1922 Washington Naval Treaty was a mutual naval arms limitation and disarmament treaty between the five major naval powers of the time: the United Kingdom, the United States of America, Japan, Italy, and France. One of the main aspects of the treaty was the limitation on the number and size of capital ships each nation possessed; as the RAN was counted as part of the Royal Navy for the purposes of the treaty, "Australia" was one of the battlecruisers nominated for disposal to meet the British limit. The battlecruiser had to be made unusable for warlike activities within six months of the treaty's ratification, then disposed of by scuttling, as Australia did not have the facilities to break her up for scrap, and the British share of target ships was taken up by Royal Navy vessels. This was the only time the Australian military has been affected by a disarmament treaty until the 1997 Ottawa Treaty banning the use of anti-personnel mines.
When "Australia" was decommissioned in 1921, some of her equipment was removed for use in other ships, but after the November 1923 Cabinet decision confirming the scuttling, RAN personnel and private contractors began to remove piping and other small fittings. Between November 1923 and January 1924, £68,000 of equipment was reclaimed; over half was donated to tertiary education centres (some of which was still in use in the 1970s), while the rest was either marked for use in future warships, or sold as souvenirs. Some consideration was given to reusing "Australia"s 12-inch guns in coastal fortifications, but this did not occur as ammunition for these weapons was no longer being manufactured by the British, and the cost of building suitable structures was excessive. It was instead decided to sink the gun turrets and spare barrels with the rest of the ship. There was also a proposal to remove "Australia"s conning tower and install it on the Sydney Harbour foreshore; although this did not go ahead, the idea was later used when the foremast of was erected as a monument at Bradleys Head. The ship's outer port propeller is on display at the Australian War Memorial, while other artefacts are in the collections of the War Memorial, the Australian National Maritime Museum, and the Royal Australian Navy Heritage Centre.
The scuttling was originally scheduled for Anzac Day (25 April) 1924, but was brought forward to 12 April, so the visiting British Special Service Squadron could participate. On the day of the sinking, "Australia" was towed out to a point north east of Sydney Heads. Under the terms of the Washington Treaty, the battlecruiser needed to be sunk in water that was deep enough to make it infeasible to refloat her at a future date. The former flagship was escorted by the Australian warships "Melbourne", "Brisbane", "Adelaide", "Anzac", and "Stalwart", the ships of the Special Service Squadron, and several civilian ferries carrying passengers. Many personnel volunteered to be part of the scuttling party, but only those who had served aboard her were selected. At 14:30, the scuttling party set the charges, opened all seacocks, and cleared the ship. Explosive charges blew a hole in the hull a few minutes later, but it took 20 minutes for the intake of water to bring holes cut in the battlecruiser's upper flanks to the waterline. The angle of list increased significantly, causing the three spare 12-inch barrels lashed to the deck to break free and roll overboard, before "Australia" inverted completely and began to sink stern-first. "Australia" submerged completely at 14:51; a Royal Australian Air Force aircraft dropped a wreath where the warship had sunk, while "Brisbane" fired a rolling 21-gun salute. The wreck was gazetted as being at , below. However, there were discrepancies with other sources, and the exact location of "Australia" was unknown.
There are two schools of thought surrounding the decision to scuttle the battlecruiser. The first is that sinking "Australia" was a major blow to the nation's ability to defend herself. Following the battlecruiser's scuttling, the most powerful warships in the RAN were four old light cruisers. The battlecruiser had served as a deterrent to German naval action against Australia during the war, and with growing tensions between Japan and the United States of America, that deterrence might have been required if the nations had become openly hostile towards each other or towards Australia. The opposing argument is that, while an emotive and symbolic loss, the ship was obsolete, and would have been a drain on resources. Operating and maintaining the warship was beyond the capabilities of the RAN's post-war budgets, necessitating the ship's reduction in status in 1920 and assignment to reserve in 1921. Ammunition and replacement barrels for the main guns were no longer manufactured. To remain effective, "Australia" required major modernisation (including new propulsion machinery, increased armour and armament, and new fire control systems) at a cost equivalent to a new .

In 1990, a large, unknown shipwreck was encountered by the Fugro Seafloor Surveys vessel MV "Moana Wave 1" while surveying the path of the PacRimWest communications cable. One of the survey ship's crew theorised that the wreck, located at in of water, was "Australia", but Fugro kept the information to themselves until 2002, when the company's Australian branch mentioned the discovery during a conference. This piqued the interest of a member of the New South Wales Heritage Office, who requested copies of the company's data. The size and location of the ship pointed towards it being "Australia", but the depth meant verification through inspection could only be achieved with a remote operated vehicle (ROV). The RAN was approached in 2007 for assistance, but although they supported the project, the RAN did not have the equipment to assist. In March 2007, the United States Navy loaned the deep-sea ROV "CURV-21" to the Australian Government, to locate and recover a Black Hawk helicopter which crashed during the Australian response to the 2006 Fijian coup d'état. While en route back to Australia, the ROV, carried aboard Defence Maritime Services vessel , was directed to Fugro's coordinates at the request of the NSW Heritage Office to verify and inspect the wreck. Video footage captured by the ROV allowed the NSW Heritage Office to confirm that the wreck was "Australia" by matching features like the superstructure and masts to historical photographs. Although initially sinking stern-first, the battlecruiser levelled out as she sank, with the aft mast the first to strike the bottom. After hitting the seabed, "Australia" slid about to her final resting place. The wreck site is protected under the federal "Historic Shipwrecks Act 1976".





</doc>
<doc id="969562" url="https://en.wikipedia.org/wiki?curid=969562" title="Superliner (railcar)">
Superliner (railcar)

The Superliner is a type of bilevel intercity railroad passenger car used by Amtrak, the national rail passenger carrier in the United States. Amtrak ordered the cars to replace older single-level cars on its long-distance trains in the Western United States. The design was based on the Budd Hi-Level vehicles, employed by the Santa Fe Railway on its "El Capitan" trains. Pullman-Standard built 284 cars, known as Superliner I, in 1975–1981; Bombardier Transportation built 195, known as Superliner II, in 1991–1996. The Superliner I cars were the last passenger cars built by Pullman.

Car types include coaches, dining cars, lounges, and sleeping cars. Most passenger spaces are on the upper level, which feature a row of windows on both sides. The Sightseer Lounge observation cars have distinctive floor-to-ceiling windows on the upper level. Boarding is on the lower level; passengers climb up a center stairwell to access the upper level.

The first Superliner I cars entered service in February 1979, with deliveries continuing through 1981. Amtrak assigned the cars to both long-distance and short-distance trains in the Western United States. The first permanent assignment, in October 1979, was to the Chicago–Seattle "Empire Builder". Superliner II deliveries began in 1993; the additional cars enabled the retirement of the aging Hi-Level cars and the assignment of Superliners to trains in the Eastern United States. Tunnel clearances prevent their use on the Northeast Corridor.

On May 1, 1971, Amtrak assumed control of almost all private sector intercity passenger rail service in the United States, with a mandate to reverse decades of decline. It retained about 184 of the 440 trains which had run the day before. To operate these trains, Amtrak inherited a fleet of 300 locomotives and 1,190 passenger cars, most of which dated from the 1940s and 1950s. No new sleeping cars had been built for service in the United States since 1955.

Conventional single-level cars made up most of Amtrak's inherited fleet, but it also included 73 Hi-Level cars from the Santa Fe. The Budd Company built these between 1954 and 1964; the bilevel design, with its superior views and smooth riding characteristics, was well-suited to the long distances in the west. Michael R. Weinman, who worked at the design firm Louis T. Klauder & Associates, recalled that when Amtrak issued a request for proposal (RFP) in 1973 for a "totally new" passenger car, it "was assumed" that the design would be bilevel. Thirteen companies responded to the RFP; Amtrak selected the Klauder proposal. The design was finished by mid-1974 and Amtrak invited four companies to bid on its construction: Boeing, Budd, Pullman-Standard, and Rohr. Pullman-Standard won the contract.

Amtrak ordered 235 Superliner I cars from Pullman-Standard on April 2, 1975, with deliveries scheduled for between January 1977 and June 1978. The order then consisted of 120 coaches, 55 sleepers, 34 diners, and 26 lounges. Amtrak soon increased the order to 284 cars: it added 30 coaches, 15 sleepers, 5 diners, and deleted 1 lounge. The initial order cost $143.6 million; with the additional cars and other payments the cost rose to $250 million.

The railroad asked its employees to name the new cars, and announced the winning entry in its internal newsletter of June 1, 1977: "Vistaliner," harkening back to the Vista-Domes of the Chicago, Burlington and Quincy Railroad. But the newsletter went on to note that the name was already under copyright by another company, and so the cars would be dubbed "Superliners," a name created by Needham, Harper & Steers, then Amtrak's advertising agency.

As the cars arrived in 1978 and 1979, Amtrak put them into use on short-haul routes radiating from Chicago. The first coaches entered regular service on February 26, 1979, running from Chicago to Milwaukee. The coaches, led by an EMD F40PH locomotive, displaced the regular Turboliner equipment. The equipment continued to operate on the run for several weeks. The "Illini" and "Shawnee" trains received Superliner coaches soon after; the first Superliner dining car ran on the "Shawnee" as a lounge.

A public unveiling took place at Union Station in Chicago on October 11, 1979, followed by a short trip over the Burlington Northern Railroad to Lisle. The following day, the "Shawnee" had the dubious distinction of the first Superliner accident, a collision with an Illinois Central Gulf Railroad freight train at Harvey, IL, which claimed the lives of 2 crew members of the freight train.

Amtrak's first choice for Superliner assignments had been the financially-troubled "Floridian", a Chicago–Florida long-distance train, but the two years' delay in delivery scuppered these plans. Amtrak turned next to the "Empire Builder". This long-distance train ran between Chicago and Seattle through the plains of Montana and North Dakota. Winters in that part of the United States are harsh, featuring both blizzards and cold temperatures. Traditional steam-heated equipment often broke down, causing Amtrak to cancel service. The Superliners, with their electrical head-end power, were far better suited for the conditions. The "Empire Builder" became the first long-distance train to use Superliners, and the first train permanently assigned them, on October 28, 1979. Amtrak's new national timetable depicted a Superliner coach on the front cover, and the listing for the "Empire Builder" carried a heading which read "Amtrak's Superliner is Special." At the same time, Superliners entered service on the short-haul "Pacific International" and "Mount Rainier" in the Pacific Northwest.

With the "Empire Builder" in operation, Amtrak began re-equipping the remaining long-distance trains in the west. The second permanent Superliner train was the "Desert Wind", then a day train between Los Angeles and Ogden, Utah, which gained coaches on June 30, 1980. The "San Francisco Zephyr", a long-distance train on the traditional Overland Route between Chicago and San Francisco, followed on July 7, 1980; it received the first of the Sightseer lounges on January 6, 1981. Amtrak assigned Superliners to another long-distance train, the Los Angeles–Chicago "Southwest Limited", in October 1980. The "Southwest Limited", formerly the "Super Chief", traveled the same route as the "El Capitan", whose Hi-Level cars had inspired the design. The management of the Santa Fe, impressed by the design, permitted Amtrak to restore the name "Chief" to the train, and Amtrak renamed it the "Southwest Chief" on October 28, 1984. The "Chief" was the first train to receive Superliner II sleeping cars in September 1993.

The "Coast Starlight" began operating with Superliners in January 1981. The "Sunset Limited", a long-distance train running along the southern border of the United States between Los Angeles and New Orleans, gained them in February, resulting in a commendation from the Texas State Legislature. The "Pioneer" gained Superliner coaches on April 26. The "Eagle", an overnight train between San Antonio and Chicago, began carrying Superliners in October on those days it connected with the "Sunset Limited" in San Antonio. Superliner assignments became permanent in the 1990s. Amtrak estimated that reequipping a train with Superliners boosted ridership on it by 25%. The last car of the order, a sleeper delivered in July 1981, was also the last car ever built by Pullman, and was named in honor of the company's founder, George Mortimer Pullman.

In the mid-1980s Canada's Via Rail contemplated replacing its aging Budd-built steam-heated cars with Superliners. The order would have consisted of 130 cars, valued at , to be built by a consortium of Bombardier Transportation and the Urban Transportation Development Corporation. Via tested several Amtrak Superliners in revenue service between Edmonton and Winnipeg in 1984–85. Ultimately Via chose to rebuild its Budd cars to use HEP instead of ordering new equipment.

Amtrak ordered 140 Superliner II cars from Bombardier Transportation in 1991; Bombardier had acquired the Superliner patents after Pullman-Standard's closure. The order consisted of 55 sleeping cars, 38 coaches, 20 dining cars, 15 lounges, and 12 transition-dormitory cars. The initial order cost $340 million, and included an option for 39 additional cars. In late 1993 Amtrak exercised the option for 55 cars at a cost of $110 million, bringing the total order of Superliner II cars to 195. The option included ten dining cars, ten lounges, and 35 transdorms. Bombardier built the order in Barre, Vermont.

The new order allowed the displacement of the remaining Hi-Level cars as well as the employment of Superliners on trains running with single-level cars. Amtrak converted three eastern long-distance trains to Superliners: the Chicago–New Orleans "City of New Orleans" (March 1994); the Chicago–Washington, D.C. "Capitol Limited" (October); and the Virginia–Florida "Auto Train" (March 1, 1995). A project to enlarge the First Street Tunnel in Washington, D.C., enabled the Chicago–Washington "Cardinal" to begin using Superliners in September 1995; these were withdrawn in 2002 because of equipment shortages. Superliners were used on the Chicago–Toronto "International" from November 1995 until early 2000. In 2017, Amtrak identified a need to replace the Superliners, noting that each car traveled the equivalent of "seven trips around the world" every year.

The Superliners generally resembled the Hi-Level design, though at , they were taller. The Superliners also used Amtrak's new 480-volt head-end power for heating and electricity. This was more reliable than the steam heat used by the Hi-Levels, whose own heaters and diesel generators would eventually be replaced by HEP equipment. 

Initially, the cars could not be worked east of Chicago because of limited overhead clearances, but by the 1980s many eastern railroads had raised clearances on their tracks to permit tri-level auto carriers and double-stack container trains, which also permitted the operation of the Superliners. To this day, tunnel clearances around New York City and elsewhere prevent their use on the Northeast Corridor.

The Superliner I cars ride on Waggon Union MD-76 trucks, which require more frequent overhauls than comparable domestic designs and are "notorious for their rough riding characteristics." The Superliner IIs ride on GSI-G70 outboard bearing trucks, also found on the Horizon single-level cars. Both models have a maximum speed of .

The Superliner I cars originally stored waste in tanks, then macerated and dumped it along the tracks once the train had attained a preset speed. This was an improvement on the Hi-Levels, which dumped directly to the tracks. Growing public concern about such dumping led Amtrak to order its Superliner IIs with a full-retention system. The Superliner I cars were retrofitted with a full-retention system in the early 1990s.

The "New York Times" described the Superliner I interior color scheme as "soft hues of beige, rust, brown and green." For the Superliner IIs, Amtrak introduced a new scheme incorporating gray, aquamarine, and salmon.

Pullman-Standard built 102 Superliner I coaches and 48 coach-baggage combine cars. Bombardier built 38 Superliner II coaches. As built, Superliner coaches could carry 62 passengers in the upper level and 15 passengers on the lower level. The lower level's capacity would later be reduced to 12. The coach-baggage cars had a baggage compartment in lieu of the lower level seating area, and squeezed 78 seats into the upper level. The total capacity of 75 to 78 represented a small increase over the 68 to 72 seats on the Hi-Level coaches, which lacked seating on the lower level. The Superliner I coach weighs ; the Superliner II coach weighs .

Seating on the upper and lower levels is 2×2 with reclining seats. The seats are wide with a pitch of . Included are adjustable footrests and retractable legrests, but no center armrest. There are overhead luggage racks on the upper level and a luggage storage area on the lower level across from the stairs. There are four unisex toilets per coach, all on the lower level. A shower was included in the original design, to be locked when the coaches were used in short-haul service, but deleted from the final design. After a grade crossing accident in 1999, the Transportation Safety Board of Canada faulted the layout on the lower level; the exterior door, when opened and locked in position, prevented egress from the wheelchair-accessible bathroom.

Two-piece windows are located at each seat row. Each window is . Integral blinds were rejected in favor of curtains on maintenance grounds, while an upper level of "skylight" windows, similar to those on the Sun Lounge cars, was rejected as too expensive. Full-height windows were incorporated into the lounge cars.

Eleven Superliner I coaches were rebuilt as "snack coaches". These retained the 62 seats on the upper level but removed the lower level seating in favor of a snack bar and lounge seats.

Amtrak rebuilt 34 of the coach-baggage cars as "smoking coaches" in 1996 and 1997. The baggage room was converted to a self-contained specially ventilated smoking lounge. After Amtrak banned smoking on long-distance trains in 2004, the cars were reconverted.

Five Superliner II coaches were rebuilt in 1996 and 1997 as "family coaches" or "Kiddie Cars". These cars featured a children's play area on the lower level instead of seating and were assigned to the "Coast Starlight", a long-distance train between Los Angeles and Seattle along the West Coast of the United States. Amtrak rebuilt these five cars again in 2008 and 2009 as "arcade cars" with video game machines in the lower level. The cars were converted once more in 2015 to provide business class service on the "Coast Starlight". The service began in June 2015.

The California Department of Transportation (Caltrans) paid to rebuild six Superliner I coaches and one baggage-coach, which had been wrecked in various accidents, for use in Amtrak California service. The seating capacity was increased to 76 on the upper level and 20 on the lower level.

Pullman-Standard built 70 Superliner I sleeping cars; Bombardier built 49 "standard" Superliner II sleepers and six "deluxe" sleepers. The standard Superliner sleeping car contains 14 roomettes, five bedrooms, a family bedroom, and an accessible bedroom. The deluxe sleeping car contains ten bedrooms, four roomettes, a family bedroom, and an accessible bedroom. As built, the standard sleeping car could hold a maximum of 44 passengers. The Superliner I sleeping car weighs ; the Superliner II sleeping car weighs . The Superliner II deluxe sleeper is slightly heavier at .

Roomettes measure × . In daytime configuration each features two facing seats; these are combined to form a bed. A second bed is folded down from the ceiling. Bedrooms measure × . Like the roomette, there are two berths; during the day the lower berth acts as a sofa. The room also contains a chair which faces the beds. Unlike the roomette, a bedroom includes a private toilet, shower, and sink.

The family bedroom is located at one end of the car's lower level and measures × . It can hold up to two adults and two children in four berths. During the day the berths form a sofa and two seats. At the opposite end of the car from the family bedroom is the accessible bedroom, which measures × . It sleeps two people in two berths and includes a wheelchair-accessible toilet, but no shower.

The standard sleeping car has five bedrooms and ten roomettes on the upper level. The bedrooms are set against one side of the car with a hallway along the edge, while the roomettes are located to each side with the hallway running down the centerline. At the center of the car are the stairs to the lower level and a bathroom. A hallway runs through the centerline of the lower level with the accessible bedroom at one end and the family bedroom at the other. To one side of the stairs are three bathrooms and one shower, and to the other are four more roomettes. Luggage racks are located opposite the stairs. The layout of the deluxe sleeping car is similar. There are ten bedrooms on the upper level with a continuous hallway along one edge. The lower level contains opposed family and accessible bedrooms, four toilets, four roomettes, and a luggage rack. Two bedrooms may be combined to form a "bedroom suite".

As delivered, the Superliner I sleeping cars had five bathrooms, all on the lower level, and no public shower. Roomettes were termed "economy bedrooms" and bedrooms "deluxe bedrooms". During the 1980s Amtrak retrofitted the cars to add a bathroom on the upper level and a public shower on the lower level, at the expense of one bathroom. The Superliner II cars incorporated these improvements into their design.

Pullman-Standard and Bombardier each built 25 dedicated lounge cars, dubbed "Sightseer" lounges. Windows wrap upward into the ceiling, providing lateral views of scenery along the train's route. This design element was drawn from the Hi-Level lounges and the Seaboard Air Line's Sun Lounges. The Superliner I lounge weighs ; the Superliner II lounge weighs .

The upper level contains a mix of seating options. At one end are eight tables, four to each side, each seating four passengers. In the center is a lounge area with a wet bar and several groups of seats. The stairs to the lower level are located here as well. At the other end are swivel chairs. The lower level contains a bathroom, additional tables, and a snack bar. As built, the lounges had seating for 73. The cars were built with an electric piano in the lower level, which has since been removed.

In addition to the Sightseer lounges, Amtrak converted five Superliner I dining cars to lounge cars in 1998 for use on the "Auto Train", an automobile-carrying overnight train between Virginia and Florida. These cars may be distinguished from the Sightseer lounges by their conventional windows.

Pullman-Standard built 30 dining cars; Bombardier built another 39. The dining cars can seat a maximum of 72 people on the upper level in tables of four. The galley occupies the entire lower level. At the center of the car are stairs down to the kitchen. A dumbwaiter is used to bring food and drink to the dining level, as well as to return dishes, glasses, and cutlery for washing. A late 2010s overhaul added a refrigerator on the upper level for easy access and replaced incandescent lights with LED lighting. As built, the Superliner I dining car weighs ; the Superliner II dining car weighs .

Amtrak rebuilt 17 Superliner I dining cars as diner-lounges in the late 2000s. Dubbed the "Cross-Country Cafe", they were intended to reduce food service losses by replacing both a traditional dining car and the Sightseer lounge on long-distance trains. One end of the car was converted into a café area, with tables and a small serving area near the stairs to the kitchen. The other side remained dedicated to traditional diner seating, but the standard two-by-two tables were replaced by booths.

Bombardier built 47 "transition sleeper" or dormitory cars. The car had two purposes: to provide sleeping accommodations for train personnel; and to provide access to single level equipment from bi-level Superliner and Hi-Level cars. Hi-Level "step-down" coaches previously performed the latter role. Most transition dormitory ("transdorm") cars have 16 roomettes on the upper level for crew accommodations, with an accessible bedroom and small crew lounge on the lower level. Bathrooms and showers are located on both levels. At one end of the car is a top level end-door; at the other end is a staircase and end door on the lower level. On some trains, Amtrak makes the roomettes closest to the upper level end door available for sale to passengers. The transition sleepers weigh .

Between them Pullman-Standard and Bombardier manufactured 479 cars:

The Superliners established a standard basic design for bilevel railcars, including the upper-floor height of above the top of rail. Built primarily for long-distance services, the Superliners were not ideal for use on corridor routes. They were not equipped for the volumes of passenger loading and unloading found on corridor routes, nor did they have amenities designed for these shorter trips. The 1990 passage of California propositions 108, 111 and 116 authorized the sale of nearly $3 billion in bonds for the creation of rail services across the state. Proposition 116 required the California Department of Transportation (Caltrans) to create specifications for standardized railcars and locomotives that would be suitable for rail operations across the state. 

The resulting California Car design, of which 66 were built by Morrison Knudsen from 1994 to 1997, offered a number of improvements on the Superliner design. The single vestibule and bent staircase of the Superliner design were replaced with two vestibules and two straight staircases to facilitate faster loading and unloading. The trainline-controlled power doors do not require a crew member at every door, thus reducing crew size requirements. The California Cars comply with the Americans with Disabilities Act of 1990, with wheelchair lifts and accessible seating on the lower levels. Fourteen of the cars were built as cab cars, allowing push-pull operations rather than turning the whole train at terminals. 

The success of the California Cars resulted in the procurement of the Surfliner cars by Amtrak and Caltrans in 1998. Alstom built 62 Surfliners from 2000 to 2002. The Surfliner is a modification of the California Car, with design changes including an accessible bathroom and passenger amenities such as outlets. Both the Surfliners and California Cars are mechanically and electrically compatible with the Superliners, and they often are combined in trainsets on Amtrak California services. 

Caltrans and Amtrak began drafting the specification for a third generation of the design in 2006. This specification, dubbed "Corridor Car for the 21st Century" or C21, became the basis for the design work undertaken by the Next Generation Corridor Equipment Pool Committee (NGCE) under the provisions of the Passenger Rail Investment and Improvement Act of 2008 beginning in 2009. Caltrans and the Illinois Department of Transportation ordered 130 of these Next Generation Bi-Level Passenger Rail Cars from Sumitomo (with Nippon Sharyo as the builder) in 2012. In August 2015, a new car shell failed a buff strength compression test, which forced a complete redesign of the car. That delay would have placed delivery beyond the expiration of a $220 million American Recovery and Reinvestment Act of 2009 (ARRA) grant that funded the order. In November 2017, Sumitomo instead contracted with Siemens Mobility to build 137 single-level CALIDOT cars instead of the bilevel cars.





</doc>
<doc id="969943" url="https://en.wikipedia.org/wiki?curid=969943" title="Common toad">
Common toad

The common toad, European toad, or in Anglophone parts of Europe, simply the toad ("Bufo bufo", from Latin "bufo" "toad"), is an amphibian found throughout most of Europe (with the exception of Ireland, Iceland, and some Mediterranean islands), in the western part of North Asia, and in a small portion of Northwest Africa. It is one of a group of closely related animals that are descended from a common ancestral line of toads and which form a species complex. The toad is an inconspicuous animal as it usually lies hidden during the day. It becomes active at dusk and spends the night hunting for the invertebrates on which it feeds. It moves with a slow, ungainly walk or short jumps, and has greyish-brown skin covered with wart-like lumps.

Although toads are usually solitary animals, in the breeding season, large numbers of toads converge on certain breeding ponds, where the males compete to mate with the females. Eggs are laid in gelatinous strings in the water and later hatch out into tadpoles. After several months of growth and development, these sprout limbs and undergo metamorphosis into tiny toads. The juveniles emerge from the water and remain largely terrestrial for the rest of their lives.

The common toad seems to be in decline in part of its range, but overall is listed as being of "least concern" in the IUCN Red List of Threatened Species. It is threatened by habitat loss, especially by drainage of its breeding sites, and some toads get killed on the roads as they make their annual migrations. It has long been associated in popular culture and literature with witchcraft.

The common toad was first given the name "Rana bufo" by the Swedish biologist Carl Linnaeus in the "10th edition of Systema Naturae" in 1758. In this work, he placed all the frogs and toads in the single genus "Rana". It later became apparent that this genus should be divided, and in 1768, the Austrian naturalist Josephus Nicolaus Laurenti placed the common toad in the genus "Bufo", naming it "Bufo bufo". The toads in this genus are included in the family Bufonidae, the true toads.

Various subspecies of "B. bufo" have been recognized over the years. The Caucasian toad is found in the mountainous regions of the Caucasus and was at one time classified as "B. b. verrucosissima". It has a larger genome and differs from "B. bufo" morphologically and is now accepted as "Bufo verrucosissimus". The spiny toad was classified as "B. b. spinosus". It is found in France, the Iberean Peninsula and the Maghreb and grows to a larger size and has a spinier skin than its more northern counterparts with which it intergrades. It is now accepted as "Bufo spinosus". The Gredos toad, "B. b. gredosicola", is restricted to the Sierra de Gredos, a mountain range in central Spain. It has exceptionally large paratoid glands and its colour tends to be blotched rather than uniform. It is now considered to be a synonym of "Bufo spinosus".

"B. bufo" is part of a species complex, a group of closely related species which cannot be clearly demarcated. Several modern species are believed to form an ancient group of related taxa from preglacial times. These are the spiny toad ("B. spinosus"), the Caucasian toad ("B. verrucosissimus") and the Japanese common toad ("B. japonicus"). The European common toad ("Bufo bufo") seems to have arisen more recently. It is believed that the range of the ancestral form extended into Asia but that isolation between the eastern and western species complexes occurred as a result of the development of the Central Asian Deserts during the Middle Miocene. The exact taxonomic relationships between these species remains unclear. A serological investigation into toad populations in Turkey undertaken in 2001 examined the blood serum proteins of "Bufo verrucosissimus" and "Bufo spinosus". It found that the differences between the two were not significant and that therefore the former should be synonymized with the latter.

A study published in 2012 examined the phylogenetic relationships between the Eurasian and North African species in the "Bufo bufo" group and indicated a long evolutionary history for the group. Nine to thirteen million years ago, "Bufo eichwaldi", a recently described species from south Azerbaijan and Iran, split from the main lineage. Further divisions occurred with "Bufo spinosus" splitting off about five million years ago when the Pyrenees were being uplifted, an event which isolated the populations in the Iberian Peninsula from those in the rest of Europe. The remaining European lineage split into "Bufo bufo" and "Bufo verrucosissimus" less than three million years ago during the Pleistocene. Very occasionally the common toad hybridizes with the natterjack toad ("Bufo calamita") or the European green toad ("Bufo viridis").

The common toad can reach about in length. Females are normally stouter than males and southern specimens tend to be larger than northern ones. The head is broad with a wide mouth below the terminal snout which has two small nostrils. There are no teeth. The bulbous, protruding eyes have yellow or copper coloured irises and horizontal slit-shaped pupils. Just behind the eyes are two bulging regions, the paratoid glands, which are positioned obliquely. They contain a noxious substance, bufotoxin, which is used to deter potential predators. The head joins the body without a noticeable neck and there is no external vocal sac. The body is broad and squat and positioned close to the ground. The fore limbs are short with the toes of the fore feet turning inwards. At breeding time, the male develops nuptial pads on the first three fingers. He uses these to grasp the female when mating. The hind legs are short relative to other frogs' legs and the hind feet have long, unwebbed toes. There is no tail. The skin is dry and covered with small wart-like lumps. The colour is a fairly uniform shade of brown, olive-brown or greyish-brown, sometimes partly blotched or banded with a darker shade. The common toad tends to be sexually dimorphic with the females being browner and the males greyer. The underside is a dirty white speckled with grey and black patches.

Other species with which the common toad could be confused include the natterjack toad ("Bufo calamita") and the European green toad ("Bufo viridis"). The former is usually smaller and has a yellow band running down its back while the latter has a distinctive mottled pattern. The paratoid glands of both are parallel rather than slanting as in the common toad. The common frog ("Rana temporaria") is also similar in appearance but it has a less rounded snout, damp smooth skin, and usually moves by leaping.

Common toads can live for many years and have survived for fifty years in captivity. In the wild, common toads are thought to live for about ten to twelve years. Their age can be determined by counting the number of annual growth rings in the bones of their phalanges.

After the common frog ("Rana temporaria"), the edible frog ("Pelophylax esculentus") and the smooth newt ("Lissotriton vulgaris"), the common toad is the fourth most common amphibian in Europe. It is found throughout the continent with the exception of Iceland, the cold northern parts of Scandinavia, Ireland and a number of Mediterranean islands. These include Malta, Crete, Corsica, Sardinia and the Balearic Islands. Its easterly range extends to Irkutsk in Siberia and its southerly range includes parts of northwestern Africa in the northern mountain ranges of Morocco, Algeria and Tunisia. A closely related variant lives in eastern Asia including Japan. The common toad is found at altitudes of up to in the southern part of its range. It is largely found in forested areas with coniferous, deciduous and mixed woodland, especially in wet locations. It also inhabits open countryside, fields, copses, parks and gardens, and often occurs in dry areas well away from standing water.

The common toad usually moves by walking rather slowly or in short shuffling jumps involving all four legs. It spends the day concealed in a lair that it has hollowed out under foliage or beneath a root or a stone where its colouring makes it inconspicuous. It emerges at dusk and may travel some distance in the dark while hunting. It is most active in wet weather. By morning it has returned to its base and may occupy the same place for several months. It is voracious and eats woodlice, slugs, beetles, caterpillars, flies, earthworms and even small mice. Small, fast moving prey may be caught by a flick of the tongue while larger items are grabbed with the jaws. Having no teeth, it swallows food whole in a series of gulps. It does not recognise its prey as such but will try to consume any small, dark coloured, moving object it encounters at night. A research study showed that it would snap at a moving piece of black paper as if it were prey but would disregard a larger moving piece. Toads seem to use visual cues for feeding and can see their prey at very low light intensities where humans are unable to discern anything. Periodically, the common toad sheds its skin. This comes away in tattered pieces and is then consumed.

When attacked, the common toad adopts a characteristic stance, inflating its body and standing with its hindquarters raised and its head lowered. Its chief means of defence lies in the foul tasting secretion that is produced by its paratoid glands and other glands on its skin. This contains a toxin called bufagin and is enough to deter many predators although grass snakes seem to be unaffected by it. Other predators of adult toads include hedgehogs, rats and mink, and even domestic cats. Birds that feed on toads include herons, crows and birds of prey. Crows have been observed to puncture the skin with their beak and then peck out the animal's liver, thus avoiding the toxin. The tadpoles also exude noxious substances which deter fishes from eating them but not the great crested newt. Aquatic invertebrates that feed on toad tadpoles include dragonfly larvae, diving beetles and water boatmen. These usually avoid the noxious secretion by puncturing the tadpole's skin and sucking out its juices.
A parasitic fly, "Lucilia bufonivora", attacks adult common toads. It lays its eggs on the toad's skin and when these hatch, the larvae crawl into the toad's nostrils and eat its flesh internally with lethal consequences. The European fingernail clam ("Sphaerium corneum") is unusual in that it can climb up water plants and move around on its muscular foot. It sometimes clings to the toe of a common toad and this is believed to be one of the means by which it disperses to new locations.

In 2007, researchers using a remotely operated underwater vehicle to survey Loch Ness, Scotland, observed a common toad moving along the bottom of the lake at a depth of . They were surprised to find that an air-breathing animal could survive in such a location.

The annual life cycle of the common toad is divided into 3 periods: the winter sleep, the time of mating and feeding period.

The common toad emerges from hibernation in spring and there is a mass migration towards the breeding sites. The toads converge on certain ponds that they favour while avoiding other stretches of water that seem eminently suitable. Adults use the same location year after year and over 80% of males marked as juveniles have been found to return to the pond at which they were spawned. They find their way to these by using a suite of orientation cues, including olfactory and magnetic cues, but also visual cues help guide their journeys. Toads experimentally moved elsewhere and fitted with tracking devices have been found to be able to locate their chosen breeding pond when the displacement exceeded three kilometres (two miles).
The males arrive first and remain in the location for several weeks while the females only stay long enough to mate and spawn. Rather than fighting for the right to mate with a female, male toads may settle disputes by means of the pitch of their voice. Croaking provides a reliable sign of body size and hence of prowess. Nevertheless, fights occur in some instances. In a study at one pond where males outnumbered females by four or five to one, it was found that 38% of the males won the right to mate by defeating rivals in combat or by displacing other males already mounted on females. Male toads generally outnumber female toads at breeding ponds. A Swedish study found that female mortality was higher than that of males and that 41% of females did not come to the breeding pond in the spring and missed a year before reproducing again.

The males mount the females' backs, grasping them with their fore limbs under the armpits in a grip that is known as amplexus. The males are very enthusiastic, will try to grasp fish or inanimate objects and often mount the backs of other males. Sometimes several toads form a heap, each male trying to grasp the female at the base. It is a stressful period and mortality is high among breeding toads. A successful male stays in amplexus for several days and, as the female lays a long, double string of small black eggs, he fertilises them with his sperm. As the pair wander piggyback around the shallow edges of the pond, the gelatinous egg strings, which may contain 3000 to 6000 eggs and be in length, get tangled in plant stalks.

The strings of eggs absorb water and swell in size, and small tadpoles hatch out after two to three weeks. At first they cling to the remains of the strings and feed on the jelly. They later attach themselves to the underside of the leaves of water weed before becoming free swimming. The tadpoles at first look similar to those of the common frog ("Rana temporaria") but they are a darker colour, being blackish above and dark grey below. They can be distinguished from the tadpoles of other species by the fact that the mouth is the same width as the space between the eyes, and this is twice as large as the distance between the nostrils. Over the course of a few weeks their legs develop and their tail gradually gets reabsorbed. By twelve weeks of age they are miniature toads measuring about long and ready to leave the pond.

The common toad reaches maturity at three to seven years old but there is great variability between populations. Juveniles are often parasitised by the lung nematode "Rhabdias bufonis". This slows growth rates and reduces stamina and fitness. Larger juveniles at metamorphosis always outgrow smaller ones that have been reared in more crowded ponds. Even when they have heavy worm burdens, large juveniles grow faster than smaller individuals with light worm burdens. After several months of heavy worm infection, some juveniles in a study were only half as heavy as control juveniles. Their parasite-induced anorexia caused a decrease in food intake and some died. Another study investigated whether the use of nitrogenous fertilisers affects the development of common toad tadpoles. The toadlets were kept in very dilute solutions of ammonium nitrate of various strengths. It was found that at certain concentrations, which were well above any normally found in the field, growth was increased and metamorphosis accelerated, but at others, there was no significant difference between the experimental tadpoles and controls. Nevertheless, certain unusual swimming patterns and a few deformities were found among the experimental animals.

A comparison was made between the growth rate of newly metamorphosed juveniles from different altitudes and latitudes, the specimens studied being from Norway, Germany, Switzerland, the Netherlands and France. At first the growth rates for males and females was identical. By the time they became mature their growth rate had slowed down to about 21% of the initial rate and they had reached 95% of their expected adult size. Some females that were on a biennial breeding cycle carried on growing rapidly for a longer time. Adjusting for differences in temperature and the length of the growing season, the toads grew and matured at much the same rate from the four colder localities. These juveniles reached maturity after 1.09 years for males and 1.55 years for females. However, the young toads from lowland France grew faster and longer to a much greater size taking an average 1.77 years for males and 2.49 years for females before reaching maturity.

Common toads winter in various holes in the ground, sometimes in basements, often in droves with other amphibians. Rarely they spend the winter in flowing waters with the common frogs and green frogs.

The IUCN Red List of Threatened Species considers the common toad as being of "least concern". This is because it has a wide distribution and is, over most of its range, a common species. It is not particularly threatened by habitat loss because it is adaptable and is found in deciduous and coniferous forests, scrubland, meadows, parks and gardens. It prefers damp areas with dense foliage. The major threats it faces include loss of habitat locally, the drainage of wetlands where it breeds, agricultural activities, pollution and mortality on roads. Chytridiomycosis, an infectious disease of amphibians, has been reported in common toads in Spain and the United Kingdom and may affect some populations.

There are parts of its range where the common toad seems to be in decline. In Spain, increased aridity and habitat loss have led to a diminution in numbers and it is regarded as "near threatened". A population in the Sierra de Gredos mountain range is facing predation by otters and increased competition from the frog "Pelophylax perezi". Both otter and frog seem to be extending their ranges to higher altitudes. The common toad cannot be legally sold or traded in the United Kingdom but there is a slow decline in toad numbers and it has therefore been declared a Biodiversity Action Plan priority species. In Russia, it is considered to be a "Rare Species" in the Bashkortostan Republic, the Tatarstan Republic, the Yamalo-Nenets Autonomous Okrug, and the Irkutsk Oblast, but during the 1990s, it became more abundant in Moscow Oblast.

It has been found that urban populations of common toad occupying small areas and isolated by development show a lower level of genetic diversity and reduced fitness as compared to nearby rural populations. The researchers demonstrated this by genetic analysis and by noting the greater number of physical abnormalities among urban as against rural tadpoles when raised in a controlled environment. It was considered that long term depletion in numbers and habitat fragmentation can reduce population persistence in such urban environments.

Many toads are killed by traffic while migrating to their breeding grounds. In Europe they have the highest rate of mortality from roadkill among amphibians. Many of the deaths take place on stretches of road where streams flow underneath showing that migration routes often follow water courses. In some places in Germany, Belgium, Great Britain, Northern Italy and Poland, special tunnels have been constructed so that toads can cross under roads in safety. In other places, local wildlife groups run "toad patrols", carrying the amphibians across roads at busy crossing points in buckets. The toads start moving at dusk and for them to travel far, the temperature needs to remain above . On a warm wet night they may continue moving all night but if it cools down, they may stop earlier. An estimate was made of the significance of roadkill in toad populations in the Netherlands. The number of females killed in the spring migration on a quiet country road (ten vehicles per hour) was compared with the number of strings of eggs laid in nearby fens. A 30% mortality rate was found, with the rate for deaths among males likely to be of a similar order.

The main toxic substance found in the parotoid gland and skin of the common toad is called bufotoxin. It was first isolated by Heinrich Wieland and his colleagues in 1922 and they succeeded in identifying its structure about 20 years later. Meanwhile, other workers succeeded in isolating the same compound and its parent steroid bufotalin from the Japanese toad ("Bufo japonicus"). By 1986, researchers at the Arizona State University had succeeded in synthesizing the toad venom constituents bufotalin, bufalitoxin and bufotoxin. The chemical formula of bufotoxin is CHNO. Its physical effects resemble those of digitalis which in small doses increases the strength with which the heart muscle contracts and which is used in the treatment of congestive heart failure. The skin of one toad contains enough toxin to cause serious symptoms or even death in animals and man. Clinical effects include severe irritation and pain to eyes, mouth, nose and throat, cardiovascular and respiratory symptoms, paralysis and seizures, increased salivation, vomiting, hyperkalemia, cyanosis and hallucinations. There is no known anti-venom. Treatment consists of supporting respiratory and cardiovascular functions, prevention of absorption and electrocardiography to monitor the condition. Atropine, phenytoin, cholestyramine and lidocaine may prove useful in its management.

The toad has long been considered to be an animal of ill omen or a connection to a spirit world. This may have its origins in the fact that it is at home both on land and in the water. It may cause repugnance because of its blackish, wart-like skin, its slow movements and the way it emerges from some dark hole. In Europe in the Middle Ages, the toad was associated with the Devil, for whom a coat-of-arms was invented emblazoned with three toads. It was known that the toad could poison people and, as the witch's familiar, it was thought to possess magical powers. Even ordinary people made use of dried toads, their bile, faeces and blood. In some areas, the finding of a toad in a house was considered evidence that a witch was present. In the Basque Country, the familiars were believed to be toads wearing elegant robes. These were herded by children who were being trained as witches. Between 1610 and 1612, the Spanish inquisitor Alonso de Salazar Frías investigated witchcraft in the region and searched the houses of suspected witches for dressed toads. He found none. These witches were reputed to use undomesticated toads as ingredients in their liniments and brews.

An English folk tale tells how an old woman, a supposed witch, cursed her landlord and all his possessions when he demanded the unpaid rent for her cottage. Soon afterwards, a large toad fell on his wife and caused her to collapse. The toad was thrown into the fire but escaped with severe burns. Meanwhile, the old witch's cottage had caught fire and she was badly burnt. By next day, both toad and witch had died, and it was found that the woman's burns exactly mirrored those of the toad.

The saliva of the toad was considered poisonous and was known as "sweltered venom" and it was believed that it could spit or vomit poisonous fire. Toads were associated with devils and demons and in "Paradise Lost", John Milton depicted Satan as a toad when he poured poison into Eve's ear. The First Witch in Shakespeare's Macbeth gave instructions on using a toad in the concoction of spells:

It was also believed that there was a jewel inside a toad's head, a "toadstone", that when worn as a necklace or ring would warn the wearer of attempts to poison them. Shakespeare mentioned this in "As You Like It":

Mr. Toad Esq. is one of the main characters in the children's novel "The Wind in the Willows", by Kenneth Grahame. This has been dramatized by several authors including A. A. Milne who called his play "Toad of Toad Hall". Mr. Toad is a very conceited, anthropomorphic toad and in the book he composes a ditty in his own praise which starts like this:

George Orwell in his essay "Some Thoughts on the Common Toad" described the emergence of the common toad from hibernation as one of the most moving signs of spring.



</doc>
<doc id="972359" url="https://en.wikipedia.org/wiki?curid=972359" title="Norodom Ranariddh">
Norodom Ranariddh

Norodom Ranariddh (; born 2 January 1944) is a Cambodian royal politician and law academic. He is the second son of Norodom Sihanouk of Cambodia and a half-brother of the current king, Norodom Sihamoni. Ranariddh is the president of FUNCINPEC, a Cambodian royalist party. He was also the First Prime Minister of Cambodia following the restoration of the monarchy, serving between 1993 and 1997, and subsequently as the President of the National Assembly between 1998 and 2006.

Ranariddh was a graduate of the University of Provence and started his career as a law researcher and lecturer in France. In 1983, he joined FUNCINPEC and in 1986 became the chief of staff and commander-in-chief of Armée nationale sihanoukiste. Ranariddh became Secretary-General of FUNCINPEC in 1989, and its president in 1992. When FUNCINPEC won the 1993 Cambodian general election, it formed a coalition government with the Cambodian People's Party (CPP), which was jointly headed by two concurrently serving prime ministers. Ranariddh became the First Prime Minister of Cambodia while Hun Sen, who was from the CPP, became the Second Prime Minister. As the First Prime Minister, Ranariddh promoted business interests in Cambodia to leaders from regional countries and established the Cambodian Development Council (CDC).

From early 1996, relations between Ranariddh and Hun Sen deteriorated as Ranariddh complained of unequal distribution of government authority between FUNCINPEC and the CPP. Subsequently, both leaders publicly argued over issues such as the implementation of construction projects, signing of property development contracts, and their rival alliances with the Khmer Rouge. In July 1997, a major clash between troops separately aligned to FUNCINPEC and the CPP took place, forcing Ranariddh into exile. The following month, Ranariddh was ousted from his position as First Prime Minister. He returned to Cambodia in March 1998, and led his party in the 1998 Cambodian general election. When FUNCINPEC lost the elections to the CPP, Ranariddh, after initially challenging the results, became President of the National Assembly in November 1998. He was seen as a potential successor to Sihanouk as the King of Cambodia, until in 2001 he renounced his interest in the succession. As the President of the National Assembly, Ranariddh was one of the nine members of the throne council which in 2004 selected Sihamoni as Sihanouk's successor.

In March 2006, Ranariddh resigned as the President of the National Assembly and in October 2006 was ousted as President of FUNCINPEC. The following month, he founded the Norodom Ranariddh Party (NRP). After accusations of embezzlement and adultery he went into exile again, and in March 2007 was convicted "in absentia" of embezzlement and sentenced to 18 months' imprisonment. After being pardoned in September 2008 and returning to Cambodia, Ranariddh announced his retirement from politics, but resumed the NRP leadership in December 2010. He failed to merge the NRP and FUNCINPEC, and retired again, but in March 2014 re-emerged to launch the Community of Royalist People's Party (CRPP). In January 2015, Ranariddh dissolved the CRPP and returned to FUNCINPEC. He was subsequently re-elected to the FUNCINPEC presidency.

Ranariddh was born in Phnom Penh to Sihanouk and his first wife, Phat Kanhol, who was a ballet dancer attached to the royal court. Ranariddh was separated from his mother at three years of age when she remarried, and subsequently grew up mostly under the care of his aunt, Norodom Ketkanya and grandaunt, Norodom Sobhana. Ranariddh attended primary education at Norodom School and completed part of his high school studies at Lycee Descartes in Phnom Penh. During his childhood, he developed a close relationship with his grandparents, Norodom Suramarit and Sisowath Kossamak, but was distanced from his father. In 1958, Ranariddh was sent to a boarding school in Marseille together with his half-brother Norodom Chakrapong. Ranariddh initially planned to pursue medical studies as he did well in science subjects, but was persuaded by Kossamak to study law. After finishing high school in 1961, he enrolled in the undergraduate programme of law at the University of Paris. He struggled to focus on his studies in Paris, which he attributed to the social distractions that he encountered in the city.

In 1962, Ranariddh enrolled in the law faculty at the University of Provence (now part of Aix-Marseille University). He obtained his bachelor's and master's degrees in 1968 and 1969 respectively, specialising in public law. After completing his master's, Ranariddh took the PhD qualifying examinations in 1969. He returned to Cambodia in January 1970, and worked briefly as a secretary at the Interior Ministry. When Lon Nol staged a successful coup against Sihanouk in March 1970, Ranariddh was dismissed from his job and fled into the jungle where he was a close associate of resistance leaders. In 1971, Ranariddh was captured, along with several members of the royal family, and was held in prison for six months before being released. He was rearrested the following year, and spent a further three months in detention. In 1973, Ranariddh returned to the University of Provence, where he completed his PhD in 1975. Between 1976 and 1979, he worked as a research fellow at the CNRS, and was awarded a diploma of higher studies in air transport. In 1979 Ranariddh went back to the University of Provence as an associate professor, teaching courses in constitutional law and political sociology.

When Sihanouk formed FUNCINPEC in 1981, Ranariddh declined his father's invitation to join the party as he disagreed with its association with the Khmer Rouge. In June 1983, Sihanouk urged Ranariddh to leave his teaching career in France and join FUNCINPEC, and this time he agreed. Ranariddh was appointed as a personal representative to Sihanouk, and relocated to Bangkok, Thailand, where he took charge of the party's diplomatic and political activities in Asia. In March 1985, Ranariddh was appointed inspector-general of the Armee Nationale Sihanoukiste (ANS), the armed force of FUNCINPEC, and in January 1986 became ANS commander-in-chief and chief-of-staff.

Ranariddh became secretary-general of FUNCINPEC in August 1989, when Sihanouk stepped down as its president. On 10 September 1990, Ranariddh joined the Supreme National Council of Cambodia (SNC), an interim United Nations administrative body tasked with overseeing sovereign affairs of Cambodia. When the 1991 Paris Peace Accords were signed in October of that year, officially ending the Cambodian–Vietnamese War, Ranariddh was one of the SNC signatories. In February 1992, he was elected to the presidency of FUNCINPEC.

When the United Nations Transitional Authority in Cambodia (UNTAC) – a parallel administrative body with the SNC – was formed in February 1992, Ranariddh was appointed as one of its council members. He spent time travelling between Bangkok and Phnom Penh, and while in Phnom Penh led efforts in opening FUNCINPEC party offices across Cambodia. At the same time, FUNCINPEC began to criticise the ruling CPP, which retaliated with violent attacks by police against low-level FUNCINPEC officials. The attacks prompted Ranariddh's close aides, Norodom Sirivudh and Sam Rainsy, to advise him against registering the party for the 1993 general elections. However, the chef-de-mission for UNTAC, Yasushi Akashi, encouraged Ranariddh to run in the elections. Persuaded by Akashi, he registered the party and the election campaign began in April 1993. Ranariddh, as well as other FUNCINPEC officials, wore T-shirts depicting Sihanouk on the campaign trail. This nominally complied with an election rule by the UNTAC administration not to use Sihanouk's name during the campaign, who now served as the politically neutral head of the SNC. Voting took place in May 1993; FUNCINPEC secured about 45 percent of the valid votes, winning 58 out of a total of 120 parliamentary seats. The CPP refused to recognise the election results and complained of electoral fraud.

On 3 June 1993, CPP leaders Chea Sim and Hun Sen met with Sihanouk and persuaded him to head an interim government with the CPP and FUNCINPEC as joint coalition partners. That evening, Sihanouk announced the formation of the interim government over national radio. Ranariddh, who had not been consulted, expressed surprise. At the same time, the United States and China declared their opposition to the plan, prompting Sihanouk to rescind his announcement the following day. On 10 June 1993, CPP leaders led by General Sin Song and Chakrapong threatened to secede eight eastern provinces from Cambodia. Ranariddh feared a civil war with the CPP, which had a much larger army than the ANS. Accordingly, he accepted the idea of FUNCINPEC working with the CPP, and both parties agreed to a dual prime minister arrangement in the new government. On 14 June, Ranariddh presided over a parliamentary meeting which made Sihanouk the Head of State, with Hun Sen and Ranariddh serving as co-Prime Ministers in an interim government. A new constitution was drafted over the next three months, and was adopted in early September. On 24 September 1993, Sihanouk resigned as the head of state and was reinstated as King of Cambodia. In the new government, Ranariddh and Hun Sen were appointed as the First Prime Minister and Second Prime Minister, respectively.

Benny Widyono, the UN secretary-general's representative in Cambodia from 1994 to 1997, has observed that although Ranariddh was nominally senior to Hun Sen, he held less executive power. Ranariddh initially viewed Hun Sen with suspicion, but the pair soon developed a close working relationship, agreeing on most policy decisions made until early 1996. In August 1993, while Cambodia was still under the administration of an interim government, Ranariddh and Hun Sen jointly applied to make the country a member in the International Organization of the Francophonie. The decision to enter the Francophonie sparked a debate among students in higher educational institutes, particularly those from the Institute of Technology of Cambodia who called for French to be replaced with English as the language of instruction. In response, Ranariddh encouraged students to simultaneously learn both English and French.

In August 1995, Ranariddh expressed admiration for the political and economic systems of Singapore, Malaysia and Indonesia. As he saw it, these countries, characterised by hybrid regimes, active economic interventionism and limited press freedom, served as good models to propel Cambodia's socio-economic growth. Ranariddh espoused the view that economic development should take precedence over democratic and human rights. In the initial months of the administration, he actively courted political leaders from various regional countries, including Indonesia, Singapore and Malaysia, with a view to encouraging investment in Cambodia. In early 1994, Ranariddh established the Cambodian Development Council (CDC) to encourage foreign investment, and served as its chairperson. The Malaysian Prime Minister, Mahathir Mohamad, supported Ranariddh's plans, and encouraged Malaysian businessmen to invest and assist in developing the tourism, infrastructural development and telecommunications industries.

As the chairman of the CDC, Ranariddh gave his approval to at least 17 business contracts submitted by Malaysian businessmen between August 1994 and January 1995. The projects mostly covered infrastructural development, and included construction of a racing track, power plants and petrol stations. In November 1994, the CDC opened a tender to build a casino near Sihanoukville and proposals submitted by three companies were shortlisted; Ariston Berhad from Malaysia, Unicentral Corporation from Singapore and Hyatt International from the US. Ariston's proposal was valued at USD 1.3 billion, and included bringing a luxury cruise ship with casino to Cambodia, to be used to accommodate tourists until the Sihanoukville resort was built. Before the tender was even concluded, Ariston's ship was brought to Phnom Penh in early December. The Tourism Minister, Veng Sereyvuth suspected that there was backroom dealing activities between CDC and Ariston, who were nevertheless awarded the contract, which Ranariddh signed in January 1995.

In 1992, the UNTAC administration had banned forest logging and timber exports, a major industry and source of foreign earnings. In October 1993, Ranariddh issued an order to lift the ban on a temporary basis so as to allow trees that were already felled to be exported for timber. The Khmer Rouge still controlled large tracts of forests in the regions of western and northern Cambodia bordering Thailand, and helped finance its operations by selling timber to Thai forestry companies. The Cambodian government was unable to impose its will in Khmer Rouge territory, and was eager to regain the logging revenues. In January 1994, Ranariddh and Hun Sen signed a bilateral agreement with Thai Prime Minister Chuan Leekpai. The agreement provided for felled trees to be legally exported to Thailand on a temporary basis until 31 March 1994. The agreement also arranged for specially-designated customs zones to be created within Thai territory, which allowed Cambodian custom officials to inspect the logs and collect export duties.

The logging ban went into force on 31 March 1994, but trees continued to be felled and a new stockpile of timber was created. Ranariddh and Hun Sen gave special authorisation for the lumber to be exported to North Korea. They would continue the practice of periodically lifting export bans and granting special approvals to clear stocks of fallen timber on an on-and off-basis until Ranariddh's ouster in 1997. According to Canadian geographer Philippe Le Billon, Ranariddh and Hun Sen tacitly supported continued Khmer Rouge logging activities as it provided a lucrative backdoor source of cash revenue to finance their own political activities. Under Ranariddh's co-administration, Malaysia's Samling Berhad and Indonesia's Macro-Panin were among the largest beneficiaries of government contracts, as these two logging companies, in 1994–1995, secured rights to log 805,000 hectares and 1.4 million hectares of forests, respectively.

In October 1994, Ranariddh and Hun Sen dropped Sam Rainsy as Finance Minister during a cabinet reshuffle. Rainsy had been appointed by Ranariddh in 1993, but both prime ministers became uncomfortable working with Rainsy, because of his pursuit of allegations of government corruption. Rainsy's dismissal upset Norodom Sirivudh, who resigned as Foreign Minister the following month. In March 1995, during an academic forum on corruption in Cambodia, Rainsy publicly questioned Ranariddh's acceptance of a Fokker 28 airplane and a US$108 million commission from Ariston Berhad. This angered Ranariddh, who expelled him from FUNCINPEC in May 1995. The following month, Ranariddh introduced a parliamentary motion to remove Rainsy as a member of parliament (MP).

In 1995, Ranariddh made calls for Capital punishment by calling for murderers and drug traffickers to be killed by the State. 

From January 1996 onwards, Ranariddh's relations with Hun Sen began to show signs of tension. Hun Sen submitted a government circular to reinstate 7 January as a national holiday, the anniversary of Phnom Penh's liberation from the Khmer Rouge by Vietnamese forces. Ranariddh added his signature to the circular, which incurred the ire of Sihanouk and several FUNCINPEC leaders. A few days later, apparently to tone down dissatisfaction from party members, Ranariddh publicly accused the Army of Vietnam of encroaching into the territories of four Cambodian provinces bordering it. As Widyono saw it, Ranariddh intended to test Hun Sen's response to his accusations, of which the latter chose to remain quiet. During a closed-door FUNCINPEC meeting in the later part of January 1996, party members criticised Hun Sen and the CPP for monopolizing government power, and also chided Ranariddh for being too subservient to Hun Sen.

In February 1996, Ranariddh expressed concern over repeated delays in the construction of the resort-cum-casino complex at Sihanoukville, for which he had signed an agreement with Ariston in January 1995. Ariston blamed the lack of a governmental authority in Sihanoukville for the delay. At the end of April 1996, the government formed the Sihanoukville Developmental Authority (SDA) to oversee regulatory affairs and facilitate development. At a conference in May 1996, Ranariddh charged that CPP-controlled ministries were deliberately delaying the paperwork needed to complete the approval of Ariston's project. According to Tioulong Saumura, the former deputy governor of Cambodia's Central Bank (and Sam Rainsy's wife), the delays were part of Hun Sen's strategy to undermine projects associated with Ranariddh. In an apparent act of retaliation, Ranariddh directed FUNCINPEC's co-minister of the interior, You Hockry to close down all casinos in the country, citing the absence of authorising legislation. Ranariddh also proposed the cancellation of Ariston's contracts due to the delays. Hun Sen responded by meeting with Mahathir, and assured him that agreements which Ranariddh had previously approved would be honoured.

At a FUNCINPEC congress in March 1996, Ranariddh expressed unhappiness over his relationship with Hun Sen and the CPP. He likened his position as prime minister, and those of the FUNCINPEC ministers, to "puppets". He also questioned the CPP over their delays in appointing FUNCINPEC local officials as district chiefs. Ranariddh threatened to dissolve the National Assembly before the end of 1996, should FUNCINPEC's concerns remain unresolved. Several FUNCINPEC MPs, including Loy Sim Chheang and Ahmad Yahya, called on Ranariddh to reconcile with Sam Rainsy and work with the newly formed Khmer Nation Party (KNP) in the forthcoming general election. On 27 April Ranariddh, while vacationing in Paris, attended a meeting with Sihanouk, Rainsy, Chakrapong and Sirivudh. A few days later, Sihanouk issued a declaration praising Hun Sen and the CPP, while also stating that FUNCINPEC had no intention of leaving the coalition government. According to Widyono, Sihanouk's statement was an attempt to defuse the tension between Ranariddh and Hun Sen. Hun Sen rejected the king's conciliatory overtures, and responded by publishing several public letters attacking Sihanouk, Ranariddh and FUNCINPEC. At a CPP party meeting on 29 June 1996, Hun Sen chided Ranariddh for not following through on his March threat to leave the coalition government and called him a "real dog". At the same time, Hun Sen urged provincial governors from the CPP not attend Ranariddh's rallies.

In August 1996, Khmer Rouge leaders Pol Pot and Ieng Sary publicly split, with the former denouncing the latter in a radio broadcast. Ieng Sary responded by disassociating himself from the Khmer Rouge and went on to form his own political party, the Democratic National Union Movement. Pol Pot's announcement prompted Ranariddh and Hun Sen to briefly set their political differences aside to jointly seek a royal pardon for Ieng Sary, who had been sentenced to death by the People's Republic of Kampuchea (PRK) government in 1979. Subsequently, in October and December 1996, both Ranariddh and Hun Sen competed to win Ieng Sary's favour by separately visiting the leader at his fiefdom in Pailin. Hun Sen gained the upper hand, when he announced at the end of his visit that he had managed to convince Khmer Rouge soldiers under Ieng Sary's charge to join the CPP. When Ranariddh announced plans for a follow-up to visit Samlout, another town located within Ieng Sary's fiefdom, his soldiers threatened to shoot down Ranariddh's helicopter if he went there, prompting Ranariddh to cancel his visit.

In September 1996 Ariston Berhad signed three agreements with CPP's minister Sok An, without Ranariddh's knowledge or that of other FUNCINPEC ministers. The agreements provided for the leasing of land to Ariston to develop a golf course, holiday resort and an airport in Sihanoukville. These actions angered Ranariddh, who in a February 1997 letter to Ariston's president Chen Lip Keong, declared the agreements null and void. Subsequently, Ariston claimed that they had tried unsuccessfully to contact FUNCINPEC officials, with a view to getting them to jointly sign the agreements. Hun Sen was offended by Ranariddh's actions, and in April 1997 wrote to Mahathir assuring him of the validity of the agreements.

Ranariddh forged a political coalition by bringing FUNCINPEC to work together with the KNP, the Buddhist Liberal Democratic Party and the Khmer Neutral Party. On 27 January 1997, the four political parties formalised their alliance, which became known as the "National United Front" (NUF). Ranariddh was nominated as the president of the NUF, and stated his intent to lead the alliance against the CPP, in the general elections scheduled to be held in 1998. The CPP issued a statement condemning NUF's formation, and formed a rival coalition consisting of political parties ideologically aligned to the former Khmer Republic.

Meanwhile, Ranariddh stepped up his attacks against Hun Sen, accusing him of harbouring plans to restore a Communist regime should the CPP win the next general election. At the same time Ranariddh attempted to persuade moderate leaders of the Khmer Rouge, including Khieu Samphan and Tep Kunnal, to join the NUF. Khieu Samphan accepted Ranariddh's overtures, and on 21 May 1997, he announced that his party, the Khmer National Solidarity Party (KNSP) would support the NUF. Ranariddh welcomed Samphan's announcement, and on 4 June 1997, both leaders signed a communiqué pledging mutual support. Five days later, customs officials at Sihanoukville discovered a three-ton shipment of rocket launchers, assault rifles and handguns, labelled "spare parts" and consigned to Ranariddh. The rocket launchers were seized by Cambodian Air Force officers aligned to the CPP, while Royal Cambodian Armed Forces (RCAF) officials aligned to FUNCINPEC were allowed to keep the light weapons. In mid-June, Khmer Rouge radio, controlled by Khieu Samphan, broadcast a speech praising the KNSP-NUF alliance and calling for an armed struggle against Hun Sen. Fighting subsequently broke out between Ranariddh's and Hun Sen's bodyguards.

In response Hun Sen issued an ultimatum, calling for Ranariddh to make a choice between siding with the Khmer Rouge or with the coalition government. Eleven days later, he followed up by announcing that he would stop working with Ranariddh altogether. On 3 July 1997, while travelling to Phnom Penh, Ranariddh encountered troops aligned to the CPP. These troops persuaded his bodyguards to surrender their weapons, which prompted him to flee Cambodia the following day. On 5 July, fighting broke out between RCAF troops separately aligned to CPP and FUNCINPEC, after CPP-aligned generals unsuccessfully attempted to coax FUNCINPEC-aligned troops into surrendering their weapons. The FUNCINPEC-aligned units suffered major casualties the following day, and subsequently fled from Phnom Penh to the border town of O Smach in Oddar Meanchey Province.

The defeat of FUNCINPEC-aligned troops in the military clashes on 6 July 1997 amounted to the effective ouster of Ranariddh. On 9 July 1997, the Cambodian Foreign Ministry issued a white paper labelling Ranariddh a "criminal" and a "traitor", as well as accusing him of conspiring with the Khmer Rouge to destabilise the government. Ranariddh travelled to the Philippines, Singapore and Indonesia, where he met with Fidel Ramos, Goh Chok Tong and Suharto to seek their help in his restoration. During his absence, at a party meeting on 16 July 1997, Ung Huot was nominated by FUNCINPEC MPs loyal to Hun Sen to replace Ranariddh as First Prime Minister. Huot was subsequently endorsed as First Prime Minister during a National Assembly sitting on 6 August 1997. A few days later, Sihanouk expressed his unhappiness over the clashes, and threatened to abdicate the throne and take over the premiership. Sihanouk also claimed that Ranariddh's ouster was unconstitutional, and initially refused to endorse Ung Huot's appointment, but later relented when Association of Southeast Asian Nations (ASEAN) member states supported Ung Huot's appointment. In September 1997, the UN secretary general, Kofi Annan met separately with Ranariddh and Hun Sen, to mediate the return of FUNCINPEC politicians and prepare for the 1998 Cambodian general elections. The UN proposed that its representatives monitor the elections, to which both Ranariddh and Hun Sen agreed, but Hun Sen insisted that Ranariddh be prepared to face court charges, to which Ranariddh responded with a threat to boycott the election.

At O Smach, FUNCINPEC-aligned troops fought along with the Khmer Rouge forces against CPP-aligned troops until February 1998, when a ceasefire brokered by the Japanese government came into effect. In March 1998, Ranariddh was convicted in absentia by a military court of illegally smuggling ammunitions in May 1997, and of colluding with the Khmer Rouge to cause instability in the country. He was sentenced to a total of 35 years' imprisonment, but this was nullified by a pardon from Sihanouk. Ranariddh returned to Cambodia at the end of March 1998 to lead FUNCINPEC's election campaign, which focused on pro-monarchical sentiments and anti-Vietnamese rhetoric. FUNCINPEC faced numerous obstacles, including lack of access to television and radio channels which had come under CPP's exclusive control following the 1997 clashes, and the difficulties of its supporters in getting to party rallies. In the vote on 26 July 1998, FUNCINPEC polled 31.7 percent and secured 43 out of a total of 122 parliamentary seats. The CPP won the elections by polling 41.4 percent of all votes and securing 64 parliamentary seats. The Sam Rainsy Party (SRP), Rainsy's renamed KNP, was in third place with 14.3 percent of the vote and 15 parliamentary seats.

Both Ranariddh and Rainsy protested against the election results, claiming that the CPP-led government had intimidated voters and tampered with ballot boxes. They filed petitions with the National Election Commission (NEC) and Constitutional Court; when these were rejected in August 1998, Ranariddh and Rainsy organised street protests to demand that Hun Sen relinquish power. The government responded on 7 September 1998, by banning street protests and cracking down on participants. At this point Sihanouk intervened, and arranged a summit meeting on 24 September 1998 in Siem Reap. He summoned Hun Sen, Ranariddh and Rainsy for discussions aimed at ending the political impasse. On the day of the summit meeting, a B40 rocket was fired from an RPG-2 rocket launcher at the direction of Hun Sen's motorcade, who was travelling en route to Siem Reap. The rocket missed the motorcade, and Hun Sen escaped unhurt. The police accused FUNCINPEC and SRP leaders of plotting the attack, with Rainsy as its ringleader. Both Ranariddh and Rainsy denied any involvement, but fled to Bangkok the following day, fearing government crackdowns on their parties.

Following Ranariddh's departure, Sihanouk urged him to return with a view to joining the CPP in a coalition government, reckoning that FUNCINPEC faced the prospect of breaking up if Ranariddh refused. Ranariddh returned to Cambodia on 12 November 1998 to attend a summit meeting hosted by Sihanouk, at which Ranariddh negotiated with Hun Sen and Chea Sim over the structure of a new government. An agreement was reached whereby FUNCINPEC would be given the National Assembly presidency together with several low and mid-level cabinet posts, in exchange for its support for the creation of the Cambodian Senate. On 25 November 1998, Ranariddh was nominated as the President of the National Assembly. According to Mehta, the creation of the Senate was to provide an alternative platform to pass legislation in the event that Ranariddh exerted his influence as the President of the National Assembly to block legislation.

After his appointment, Ranariddh worked with Hun Sen to re-integrate the FUNCINPEC-aligned troops into the RCAF. He also participated in efforts to foster better relations with Vietnam, and liaised with the Vietnamese National Assembly president Nông Đức Mạnh to develop friendship and cooperation initiatives. This led to several mutual visits between Cambodian and Vietnamese political leaders, between 1999 and 2000, but relations between Cambodia and Vietnam deteriorated from September 2000 onwards amid renewed border clashes. Ranariddh steered FUNCINPEC towards political rapprochement with the CPP, and actively discouraged FUNCINPEC ministers and MPs from criticising their CPP counterparts. During the party's congress in March 2001, Ranariddh declared the CPP an "eternal partner".

As early as 1999, a sizeable minority of FUNCINPEC's politicians were unhappy with Ranariddh's leadership, as rumours began to circulate that he had accepted bribes from the CPP. In February 2002, FUNCINPEC performed poorly in the commune elections, winning 10 out of 1,600 commune seats. As a result of FUNCINPEC's poor performance in the commune elections, rifts within the party boiled into the open. In March 2002, the Deputy Commander-in-chief of the RCAF – Khan Savoeun, accused You Hockry, the co-Minister of the Interior, of corruption and nepotism, acts which Savoeun claimed had alienated voters. When Ranariddh expressed support for Savoeun in May 2002, Hockry resigned. Around the same time, two new political parties, splintered from FUNCINPEC, were formed: the Khmer Soul Party, led by Norodom Chakrapong, and the Hang Dara Democratic Party, led by Hang Dara. Both new parties attracted sizeable numbers of FUNCINPEC defectors, who were apparently unhappy with Ranariddh's leadership. The defections caused Ranariddh to fear that FUNCINPEC would fare poorly in the 2003 general elections.

When general elections were held in July 2003, the CPP won, while FUNCINPEC polled 20.8 percent of the popular vote and secured 26 out of a total of 120 parliamentary seats. This marked an 11 percentage point drop in FUNCINPEC's share of the popular vote compared with 1998. Both Ranariddh and Sam Rainsy, whose SRP had also participated in the elections, expressed unhappiness with the outcome of the election, and once again accused the CPP of winning through fraud and voter intimidation. They also refused to support a CPP-led government, which needed the joint support of more MPs from FUNCINPEC or SRP to attain the two-thirds majority in forming a new government. Subsequently, in August 2003, Ranariddh and Rainsy formed a new political alliance, the "Alliance of Democrats" (AD), and together they lobbied upon the CPP to form a three-party government consisting of the CPP, FUNCINPEC and the SRP. At the same time, they also called for Hun Sen to step down and a reform of the NEC, which they claimed was stacked with pro-CPP appointees. Hun Sen rejected their demands, bringing several months of political stalemate.

In March 2004, Ranariddh privately proposed to Hun Sen that FUNCINPEC should join CPP in the new government as a junior coalition partner. Discussions between CPP and FUNCINPEC began on the composition of the coalition government and legislative procedures. An agreement was reached in June 2004, when Ranariddh walked out of his alliance with Rainsy, dropped his demands to reform the NEC and once again pledged to support Hun Sen as Prime Minister. Hun Sen also pressured Ranariddh into supporting a constitutional amendment known as a "package vote", which required MPs to support legislation and ministerial appointments by an open show of hands. While Ranariddh acquiesced to Hun Sen's demand, the "package vote" amendment was opposed by Sihanouk, Chea Sim, the SRP as well as several senior leaders within FUNCINPEC. After the "package vote" amendment was passed in July 2004, several FUNCINPEC leaders resigned in protest. Ranariddh, who remained as President of the National Assembly as part of the agreement, attempted to lure SRP leaders into defecting to FUNCINPEC with the promise of jobs within the government. At least one senior SRP leader, Ou Bun Long, caved into Ranariddh's enticements.

On 2 March 2006, the National Assembly passed a constitutional amendment which required only a simple majority of parliamentarians to support a government, instead of the two-thirds majority that was previously stipulated. Rainsy had first proposed the amendment in February 2006, who had hoped that a simple majority would make it easier for his party to form a government should they win in future elections. The following day after the constitutional amendment was passed, Hun Sen relieved Norodom Sirivudh and Nhek Bun Chhay of their posts as FUNCINPEC's co-minister of interior and co-minister of defense respectively. Ranariddh protested against the dismissals, and resigned as the President of the National Assembly on 14 March. He then left Cambodia, to reside in France. Shortly after his departure, local tabloids published stories that Ranariddh had had an affair with Ouk Phalla, an Apsara dancer.

In early September 2006, a new law was passed to outlaw adultery, and Ranariddh responded by accusing the government of attempting to undermine FUNCINPEC. On 18 September 2006, Hun Sen and Nhek Bun Chhay called for Ranariddh to be replaced as FUNCINPEC's president, after party reports suggested that Phalla had lobbied Ranariddh to appoint her relatives to government posts. On 18 October 2006, Nhek Bun Chhay convened a party congress which dismissed Ranariddh from his position as FUNCINPEC's president. In turn, he was given the titular position of "Historic President". At the congress, Nhek Bun Chhay justified Ranariddh's ouster on the grounds of his deteriorating relations with Hun Sen as well as his practice of spending prolonged periods of time overseas.

Following Ranariddh's exit from FUNCINPEC, Nhek Bun Chhay filed a lawsuit in November 2006, accusing Ranariddh of pocketing $3.6 million from the sale of its headquarters to the French embassy in 2005. In mid-November, Ranariddh returned to Cambodia, announced the formation of the Norodom Ranariddh Party (NRP) and became its president. The following month, the National Assembly expelled Ranariddh as an MP. Within days his wife, Eng Marie, sued him for adultery. Ranariddh's half-brother Chakrapong was also expelled from the party, and joined the NRP as the party's deputy president. In March 2007, Ranariddh was convicted by the Phnom Penh Municipal Court for embezzlement of the sale proceeds of FUNCINPEC headquarters, and sentenced to 18 months imprisonment. To avoid imprisonment, Ranariddh sought asylum in Malaysia shortly before the sentencing.

While living in exile in Malaysia, Ranariddh communicated to NRP party members and supporters through telephone and video conferencing. In November 2007, he proposed a merger between the NRP, SRP and the Human Rights Party, to better their prospects against the CPP in the 2008 general elections. Rainsy, the leader of the SRP, rejected his proposal. When the election campaign began in June 2008, Ranariddh, though not able to enter the country, raised issues such as border disputes with Cambodia's neighbours, illegal logging, and promised to lower petrol prices. When voting took place in July, the NRP won two parliamentary seats. Immediately after the election, the NRP joined the SRP and the HRP in charging the Election Commission with irregularities. The NRP subsequently dropped their accusations, after Hun Sen brokered a secret deal with Ranariddh which allowed the latter to return from exile, in exchange for the NRP's recognition of the election results.

In September 2008, Ranariddh received a royal pardon from Sihamoni (who had succeeded to the throne in October 2004) for his embezzlement conviction, allowing him to return to Cambodia without risking imprisonment. Following his return, Ranariddh announced his retirement from politics and pledged to support the CPP-led government. After his retirement, Ranariddh dedicated most of his time to philanthropic work and supporting royal activities. In late 2010, NRP and FUNCINPEC leaders including Nhek Bun Chhay publicly called for Ranariddh to return to politics. Ranariddh initially resisted the calls, but changed his mind and announced his return in December 2010. For the next one-and-a-half years, Ranariddh and Nhek Bun Chhay negotiated for a merger between NRP and FUNCINPEC. An agreement was formalised in May 2012, whereby Ranariddh would be made the president of FUNCINPEC, while Nhek Bun Chhay would become its vice-president. The merger agreement was rescinded a month later, when Nhek Bun Chhay accused Ranariddh of supporting other opposition parties. Two months later, Ranariddh declared his retirement from politics for a second time, and tendered his resignation as the president of NRP.

In March 2014, Ranariddh renounced his retirement and launched a new political party, the Community of Royalist People's Party (CRPP). Sam Rainsy, now president of the Cambodian National Rescue Party (CNRP), accused Ranariddh of intending to split the opposition vote to favour the ruling CPP in future elections. Ranariddh responded by accusing the CNRP of harbouring republican sentiments, while also stating that his motivation in launching CRPP was to reunite royalist supporters within the Cambodian electorate. The CRPP attracted support from some senior FUNCINPEC party members; in December 2014 an ex-secretary of state, a senator and a deputy police chief declared their support for the CRPP. Hun Sen then proposed to Ranariddh that he return to FUNCINPEC.

In early January 2015, Ranariddh announced his intention to dissolve the CRPP and return to FUNCINPEC. At a party congress on 19 January 2015, he was reappointed as FUNCINPEC president; his half-sister and previous FUNCINPEC president, Norodom Arunrasmy became the first vice-president, while Nhek Bun Chhay was appointed as second vice-president. In March 2015, Ranariddh held another party congress where he appointed four more vice-presidents to the FUNCINPEC executive committee. He also convinced the congress to adopt a new party logo, which had a design almost identical that of the now-defunct CRPP. Ranariddh supported the formation of the Cambodian Royalist Youth Movement in July 2015, a youth organisation aimed at garnering electoral support for FUNCINPEC from younger voters, which he was appointed as its honorary president. In November 2017, he returned to the National Assembly as a member of parliament, following the dissolution of the Cambodia National Rescue Party, after which the FUNCINPEC received 41 of the 55 vacated seats. The party performed poorly in the 2018 general election, failing to win a single seat in the National Assembly. Though they were runners-up behind the Cambodian People's Party, their tally of popular vote was fewer than the 594,659 invalid ballots cast by disenfranchised supporters of the former opposition.

In June 1993 Ranariddh was granted the Cambodian royal title of "Sdech Krom Luong" (Khmer: ស្ដេចក្រុមលួង), which translates as "Senior Prince" in English. Five months later, in November 1993, he was elevated to the rank of "Samdech Krom Preah" (Khmer: សម្ដេចក្រុមព្រះ), or "Leading Senior Prince" in English, in recognition of his efforts to re-instate Sihanouk as the King of Cambodia. Ranariddh has been a recipient of several awards from the palace; in December 1992 he was decorated as the Grand Officer of the Royal Order of Cambodia. In May 2001 he received the Grand Order of National Merit and in October 2001 was awarded the Order of Sovatara, with the class of Mohasereivadh. He was also awarded the Grand Officer de l'Ordre de la Pleaide by the La Francophonie in March 2000.

In December 2008, Sihamoni appointed Ranariddh as President of the Supreme Privy Council of Cambodia, equivalent in rank to that of prime minister, and, during an interview in December 2010 Ranariddh revealed that this royal appointment entitles him to a monthly salary of three million riels (about US$750).

Debates on the succession to the throne began in November 1993, shortly after Sihanouk was diagnosed with cancer. In a 1995 poll of 700 people conducted by the Khmer Journalists' Associations, 24 percent of respondents preferred Ranariddh to take the throne, although a larger proportion indicated no preference over any members of the royal family. In a March 1996 interview with the "Cambodia Daily", Sihanouk encouraged Ranariddh to succeed him as king, but also expressed concern that a leadership vacuum within FUNCINPEC would occur, should Ranariddh accede. Sihanouk repeated these concerns in an interview with the "Phnom Penh Post" in February 1997. Sihanouk mentioned Sihamoni as another potential candidate, despite the latter's view that the responsibilities attached to the throne were "frightening". Sihamoni's candidacy found favour with Hun Sen and Chea Sim, because of his non-involvement in politics.

In two reports from 1993 and 1996, Ranariddh rejected the notion of becoming the next king. In November 1997, Ranariddh suggested that his outspoken and passionate personality made him an unsuitable candidate for the throne. However, by March 1999 Ranariddh became more receptive to the idea of succeeding his father. In early 2001, in an interview to Harish Mehta, Ranariddh discussed his conflicting desires between taking the throne and staying in politics. In November 2001, Ranariddh told the "Cambodia Daily" that he had decided to prioritize his political career over the throne. In the same interview, he added that Sihamoni had in the past supported him to become the next king. In September 2004, Ranariddh revealed that although he had been offered the throne by both Sihanouk and Monineath, who was Sihamoni's mother, he would prefer to see Sihamoni take the throne. When the throne council convened in October 2004 to select Sihanouk's successor, Ranariddh was part of the council which unanimously chose Norodom Sihamoni to be the next king.

Ranariddh is known for his physical resemblance to his father Sihanouk, inheriting his facial features, high-pitched voice and mannerisms. Contemporaries including Harish Mehta, Lee Kuan Yew and Benny Widyono have so stated after meeting with him. An opinion poll conducted in July 1997 by the Cambodian Information Centre also supports similar observations of Ranariddh's physical resemblance to Sihanouk. Journalists such as those from the "Phnom Penh Post" have observed that Ranariddh had used his resemblance to canvass support for FUNCINPEC during the 1993 and 1998 general elections. Ranariddh acknowledged these observations during an interview with Mehta in 2001, saying:

"People adore the king and I look like him. It is not my achievement they are remembering, but the deeds of my father. On the contrary, if I fail the people would say 'Oh, you are the son, but you are not like your father'. It's rather a burden."

Ranariddh speaks Khmer, French and English fluently. He also holds dual Cambodian and French citizenship, having obtained the latter in 1979. He enjoys listening to music and watching films, though in a 2001 interview he described himself as lacking the artistic talent which Sihanouk possessed. In 2002, Ranariddh produced and directed a 90-minute film, titled "Raja Bori", which was shot at Angkor Wat.

Ranariddh has 12 half-siblings from his father by different wives; Norodom Buppha Devi is his only full-sibling. Buppha Devi became a ballet dancer, like her mother Phat Kanhol had been during her younger days. Kanhol remarried in 1947 to a military officer, Chap Huot, and had five children with him. Phat Kanhol died from cancer in February 1969 at the age of 49, while Chap Huot was killed in an explosion a year later. Four of Ranariddh's half-siblings by his mother and Chap Huot were killed during the Khmer Rouge years, while one of them, Chap Nhalyvoud, survived. Chap Nhalyvoud served as the governor of Siem Reap Province between 1998 and 2004.

Ranariddh met his first wife, Eng Marie, in early 1968. Marie was the eldest child of Eng Meas, an Interior Ministry official of Sino-Khmer descent, and Sarah Hay, a Muslim of Cham ethnicity. Marie had nine younger siblings, and among them was Roland Eng, the former ambassador to Thailand and the United States. The couple married in September 1968 at the royal palace, and had three children: Chakravuth (born 1970), Sihariddh (born 1972) and Rattana Devi (born 1974). The couple separated, and Marie filed for divorce in March 2006 when Ranariddh's relationship with Ouk Phalla became known. The divorce was not finalised until June 2010. Ranariddh had two sons with Ouk Phalla: Sothearidh (born 2003) and Ranavong (born 2011). Phalla was a descendant of King Sisowath and was a classical dancer. She met Ranariddh when the latter was producing and directing the film "Raja Bori".

On 17 June 2018, Ranariddh and Ouk Phalla were both seriously injured in a car accident en route to Sihanoukville Province. Ouk Phalla died hours later as a result of her injuries. 

 


</doc>
<doc id="974726" url="https://en.wikipedia.org/wiki?curid=974726" title="Hurricane Iris">
Hurricane Iris

Hurricane Iris was a small, but powerful tropical cyclone that caused widespread destruction in Belize. Iris was the second-strongest storm of the 2001 Atlantic hurricane season, behind Hurricane Michelle. It was the ninth named storm, fifth hurricane, and third major hurricane of the year, forming from a tropical wave on October 4 just southeast of Barbados. It moved westward through the Caribbean, intensifying into a tropical storm on October 5 south of Puerto Rico, and into a hurricane on the following day. While passing south of the Dominican Republic, Iris dropped heavy rainfall that caused landslides, killing eight people. Later, the hurricane passed south of Jamaica, where it destroyed two houses. On reaching the western Caribbean Sea, Iris rapidly intensified into a Category 4 on the Saffir–Simpson scale. A small hurricane with an eye of only 7 mi (11 km) in diameter, Iris reached peak winds of 145 mph (230 km/h) before making landfall in southern Belize near Monkey River Town on October 9. The hurricane quickly dissipated over Central America, although its remnants contributed to the formation of Tropical Storm Manuel in the eastern Pacific Ocean. The hurricane caused severe damage—destroying homes, flooding streets, and leveling trees—in coastal towns south of Belize City.

Destruction was heaviest in Belize and totaled $250 million (2001 USD). Because Iris was compact, the damage was largely confined to 72% of the houses in the Toledo district and 50% of the houses in the Stann Creek district. The hurricane damaged or destroyed 3,718 homes nationwide, and wrecked more than 95% of the homes in 35 villages in the poorest parts of the country. Iris left about 15,000 people homeless, many receiving assistance from the government and the local Red Cross chapter. High winds also damaged large swaths of forest and crops, mostly affecting the banana industry. Iris killed 24 people in Belize, including 20 who died when a scuba diving boat capsized near Big Creek. The storm also killed eight people and damaged about 2,500 homes in neighboring Guatemala, and later dropped heavy rainfall in southern Mexico, where two people died.

Toward the end of September 2001, a poorly-defined tropical wave moved westward across the tropical Atlantic Ocean, through an area of hostile wind shear, which was caused by a large upper-level low within a trough, to the northeast of the Lesser Antilles. A few days later, the upper-level low detached from the trough and moved southwestward over the Caribbean Sea, allowing for an upper-level ridge, or high-pressure area, to form over the tropical wave. The change provided a favorable environment for tropical development, and an area of convection soon blossomed along the wave's axis. As the tropical wave approached the Lesser Antilles, a mid-level wind circulation formed within the deepest part of the convection, and a low-level circulation became gradually more pronounced on satellite imagery. Although its low-level circulation was small and poorly defined, the system increased in organization enough to be classified as Tropical Depression Eleven at 12:00 UTC on October 4, located about 100 mi (160 km) southeast of Barbados. Operationally, however, Hurricane Hunters did not confirm the depression's formation until nine hours later.

In its early stages, the depression moved west-northwestward between the islands of St. Vincent and St. Lucia under the influence of a strong ridge to its north. Compared to its appearance 24 hours before forming, the depression exhibited improved outflow and more distinct convection, although its lower circulation remained very poorly organized. This was confirmed by a Hurricane Hunters flight into the system, which failed to report a closed circulation despite the depression's well-organized appearance on satellite imagery. At 21:00 UTC on October 5, they reported a strengthening circulation with flight-level winds of 74 mph (119 km/h), corresponding to a surface wind intensity of 60 mph (95 km/h). Based on these data, the depression was upgraded to Tropical Storm Iris, situated about 155 mi (250 km) south of the southern coast of Puerto Rico. In post-season analysis, the National Hurricane Center (NHC) estimated that Iris had attained tropical storm status about nine hours earlier.
Despite the storm's intensification and well-organized satellite appearance, the circulation failed to become better defined. In their first discussion on Iris, the NHC mentioned the potential for the system to degenerate into a tropical wave if it maintained its fast forward speed. One forecaster noted that the center was fragile and that the cyclone could dissipate quickly if it encountered stronger wind shear to its south. Although its overall appearance did not change significantly, the Hurricane Hunters reported a closed eye with a diameter 23 mi (37 km) and a stadium effect (eyewall curvature) on October 6. Later that day, Iris reached hurricane strength just southwest of the southern tip of the Dominican Republic, and the NHC remarked that land interaction with the Greater Antilles was the only factor impeding further development. After Iris reached winds of 85 mph (140 km/h) early on October 7, its intensity remained steady for about 24 hours. During that time, the satellite appearance became slightly ragged as its outflow became restricted, possibly due to an upper-level low. By late on October 7, the area of hurricane force winds associated with Iris extended only 25 mi (35 km) from its 16 mi (22 km) wide eye.

Early on October 8, after turning west-southwestward away from the Greater Antilles, Iris began strengthening again, with warm waters and an absence of significant wind shear. The NHC predicted peak winds of 105 mph (165 km/h) before the storm would hit Belize. It rapidly intensified with the favorable conditions, intensifying from 95 mph (150 km/h) to 140 mph (225 km/h) in a 12-hour period on October 8, making Iris a Category 4 hurricane on the Saffir-Simpson scale; in the same duration, the minimum central pressure dropped 38 mbar (1.12 inHg). While intensifying, the hurricane developed concentric eyewalls, with an innermost eye having a diameter of 7 mi (11 km). For comparison, the smallest known eye diameter on record for an Atlantic hurricane was about 3 mi (5 km), during Hurricane Wilma in 2005. With such a small eye, a Hurricane Hunters flight could not deploy a dropsonde into the center of Iris, and shortly after the flight, the innermost eye collapsed as the core paralleled the Honduras coastline just offshore. This resulted in a temporary and slight weakening during an eyewall replacement cycle, but within a few hours Iris re-intensified to attain peak winds of 145 mph (230 km/h) just off Belize. At 02:00 UTC on October 9, it made landfall at peak intensity in Monkey River Town in the southern portion of Belize. Operationally, it was assessed as having made landfall with winds of 150 mph (240 km/h), though for an unknown reason this was lowered in post-analysis. 

Initially, Hurricane Iris was forecast to remain a tropical cyclone while crossing Central America and to re-intensify in the eastern Pacific Ocean; had it done so, it would have retained the name Iris. Instead, the hurricane rapidly weakened after moving into the mountainous terrain of Guatemala, and within six hours of landfall, the hurricane weakened to a tropical storm. Late on October 9, within sixteen hours of landfall, the storm's circulation dissipated over extreme southeastern Mexico. As the remnants approached the Pacific Ocean, a new area of convection developed south of the original circulation of Iris. It gradually organized while continuing westward, developing into Tropical Storm Manuel; the new storm ultimately lasted until October 18, before succumbing to cooler waters and wind shear.

Over a stretch of four days, sixteen tropical cyclone watches and warnings were issued in association with Iris, affecting the Dominican Republic, the Cuban provinces of Granma and Santiago de Cuba, Jamaica, Cayman Islands, the Yucatán Peninsula, Guatemala, Honduras and Belize. The threat from Iris prompted the Jamaica National Emergency Operations Center to be activated. Shelters were opened in the country but were ultimately unused.

In Belize, a hurricane warning was issued about 23 hours before Iris moved ashore. A state of national emergency was declared on October 8 as Hurricane Iris neared landfall. All emergency response committees were activated to quickly begin recovery efforts. A mandatory evacuation was issued for Stann Creek and Toledo coastal villages and all offshore islands. The main hospital in Belize City was evacuated as a precaution and the city itself was placed under a voluntary evacuation order. Overall, 11,380 people evacuated their homes in Belize, including many in Belize City. These evacuations were later credited for limiting the death toll. Hurricane Keith had struck the nation a year prior, preparing some citizens for what to expect. Disaster response teams arrived the day after Iris was projected to make landfall. Pan American Health Organization staff were on standby in Belize, Guatemala and Honduras and were ready to respond to any post-storm disease outbreaks.

On October 8, the Government of Honduras declared a red alert for all northern regions, advising residents to expect "extreme weather conditions". About 5,000 people in the country evacuated from their homes. To the north of Belize, officials in Mexico evacuated people from fishing villages and closed ports.

While Iris was in its development stages, residents as far north as Saint Thomas reported rain and thunderstorms. In the Dominican Republic, Iris dropped around of rainfall along the coast, forcing 35 families to evacuate their homes after rivers exceeded their banks. The rains triggered a landslide outside of Santo Domingo that destroyed a home, killing a family of three. There was another landslide in the region that injured two people. Iris's passage near Jamaica destroyed two houses and damaged the roofs of two others, causing one injury. Otherwise, damage in the country was minimal.

A scuba diving boat overturned during the hurricane near Big Creek, Belize, possibly hit by a tornado. The boat, named the "Wave Dancer", had 28 people on board, including 20 from the Richmond Dive Club out of Richmond, Virginia; most of them were upstairs in the boat, and none were diving. The captain had delayed returning to shore, and the passengers waited for the storm to pass along a dock, not anticipating the ferocity. Iris cut the ropes connecting the boat to the dock, causing it to overturn in waters. Eight people survived, and 11 bodies were recovered; it was presumed that 20 people died during the wreck, including 15 from the Richmond area and three crew members.

Another boat, the "Vendera", also reportedly capsized with people on board.

Hurricane Iris moved ashore in Belize with winds of , although the highest measured winds were at a station in Big Creek. Because of its small diameter, Iris produced heavy damage only in a area of southern Belize. In that region, the hurricane produced a storm surge of up to , with waves of over in height, causing street flooding and some damage to the offshore cayes.

As it moved ashore, Iris damaged houses and schools in dozens of villages. In 35 villages, the storm destroyed more than 95% of the buildings. Its small size confined the worst damage largely to Toledo and Stann Creek districts, which are the two southernmost and poorest districts of the country. The percentage of damaged houses was 72% in Toledo district and about 50% in Stann Creek, leaving about 15,000 people homeless. In both districts, the storm caused power outages and contaminated water supplies. In the worst-affected areas, poor Mayan people living on farms lost much of what they owned. At Placencia near the coast, about 80% of the homes were destroyed and many of the remaining buildings had roof damage, with downed power poles in the streets. About 90% of the houses in nearby Seine Bight were destroyed, and where Iris made landfall, over 90% of the homes were destroyed throughout Monkey River Town. The storm damaged several roads and fishing piers in southern Belize. Iris also damaged tourism facilities, including minor impact to the Maya ruins of Belize, and damaged 20% of the hotel rooms in the country, accounting for $37 million in losses. The remainder of the country remained generally unaffected during the storm.

In southern Belize, the storm's strong winds left crop damage, in some cases where the harvest had just begun. About of bananas were destroyed, along with over of rice, of corn, and other crops to a lesser degree. The storm also flooded fields and killed several livestock. The shrimp industry lost 25% of its catch, partly due to contaminated waters. Crop damage in Belize was estimated at $103 million, mostly from banana losses. Iris's strong winds also damaged large swaths of forest, with upwards of 40% of trees affected in some areas. This disrupted the habitats of several animals, and it is likely that many of the howler monkeys near Monkey River were killed. The storm's strong waves eroded the beach, although marine effects were much less than those of Hurricane Keith in the previous year. Nevertheless, there were reports of fish die-offs after the storm, possibly from low oxygen due to too much decaying matter.

Nationwide, Iris damaged or destroyed 3,718 homes, directly affecting a total of 21,568 people, or 8.5% of the total population. The storm damaged or destroyed 31 schools and 17 health facilities, along with 21 government buildings. There was about $25 million in damage to the transportation sector, including highways and bridges. Iris killed 24 people in and around the country, including the victims of the "Wave Dancer" shipwreck. Overall damage was estimated at $250 million, making it the most damaging storm in the country since Hurricane Hattie in 1961.

High tides and heavy rainfall caused power outages across both Guatemala and Honduras. In the former, the hurricane's rainfall generally amounted to , triggering flash flooding and landslides that injured nearly 100 people. The damage was heaviest in Petén Department in the northern portion of the country. The storm damaged 26 schools and 2,500 homes in the country's interior. An estimated 27,500 people were affected by the storm throughout Guatemala. There were eight deaths in the country, two of them the result of falling trees.

The remnants of Iris dropped heavy rainfall over southern Mexico, accumulating 4.80 in (122 mm) in the southern state of Chiapas. In Oaxaca, the storm produced heavy rains and damaged a total of 120 houses. A mudslide in one village demolished 20 homes and killed a child, while elsewhere in the state a man drowned after being swept away in a flooded river.

On October 9, the government of Belize issued the "all clear" signal, indicating that the storm had fully passed, and began reconstruction efforts and damage assessment. The government declared Stann Creek and Toledo districts as disaster areas, and officials declared a nighttime curfew. By the day after the storm struck, the airport in Belize City had been reopened, and transportation in all but the southern portion of the country returned to normal. Residents in the southern part of the country lost access to fresh water, forcing them to drink unclean water. Officials sent medical teams to southern Belize in the most affected areas. The Belmopan Red Cross issued an appeal for residents to donate money, clothing, and food for storm victims. The Red Cross also set up shelters and gave food to more than 7,000 people. By October 19, most roads in southern Belize were reopened. The Belize government printed a new postage stamp to help pay for reconstruction costs, and officials authorized spending $1.2 million to rebuild damaged homes. To assist the farmers who lost crops, the Belize government provided of maize seeds, as well as fertilizer. After the storm, the World Food Programme and the Belize Red Cross collectively provided food for the 9,000 families in need of subsidence. By October 31, the Red Cross had provided blankets, tarps, and hygienic supplies to 4,800 people severely affected by the storm. Homes were gradually repaired, and crop production returned to normal by early 2002. Around Christmas of 2001, the Belize Red Cross provided presents to school children in 14 villages affected by the storm. The lost banana crop caused sales to decrease by 22% in 2002, although sales gradually recovered.

The government of Belize issued an appeal to the international community for assistance in the days following Iris's landfall, and various countries provided aid. The United Kingdom sent a helicopter to assist in damage assessment and a crew to clean the water. The United States also sent a crew for damage assessment and donated plastic sheeting. Although sustaining significant damage, the Government of Guatemala deployed a working team with members from throughout the country to assist in recovery in Belize. Mexico sent blankets, mattresses, food, and water, as well as a medical team. The Japanese government sent tents and blankets, and the Chinese government donated of rice and dried fruits. Various United Nations departments donated about $225,000.

The American victims of the "Wave Dancer" boat wreck were flown back to the Richmond, Virginia area following the storm. The insurance company covering the boat reached a $4 million settlement, which was disbursed among the survivors and the victims' families. The boat operator remained in business following the accident.

Following the major damage in Belize, the name "Iris" was retired in the spring of 2002 by the World Meteorological Organization and will never again be used for an Atlantic hurricane. The name was subsequently replaced by the name "Ingrid" and was first used during the 2007 season.




</doc>
<doc id="976833" url="https://en.wikipedia.org/wiki?curid=976833" title="Japanese battleship Ise">
Japanese battleship Ise

Despite the expensive reconstruction, the ship was considered obsolete by the eve of the Pacific War, and did not see significant action in the early years of the war. Following the loss of most of the IJN's large aircraft carriers during the Battle of Midway in mid-1942, she was rebuilt with a flight deck replacing the rear pair of gun turrets to give her the ability to operate an air group of floatplanes; lack of aircraft and qualified pilots meant that "Ise" never actually operated her aircraft in combat. She participated in the Battle off Cape Engaño in late 1944, where she was one of the ships that decoyed the American carrier fleet supporting the invasion of Leyte away from the landing beaches. Afterwards the ship was transferred to Southeast Asia; in early 1945 "Ise" participated in Operation Kita, where she transported petrol and other strategic materials to Japan. The ship was then reduced to reserve until she was sunk by American airstrikes in July. After the war "Ise" was scrapped in 1946–1947.

The "Ise" class was designed as an improved version of the preceding . The ships had a length of overall, a beam of and a draught of at deep load. They displaced at standard load and at deep load, roughly more than the earlier ships. Their crew consisted of 1,360 officers and ratings.

During the ships' modernisation in the 1930s, their forward superstructure was enlarged with multiple platforms added to their tripod masts to create a pagoda mast. Both ships were also given torpedo bulges to improve their underwater protection and to compensate for the weight of the extra armour. These changes increased their overall length to , their beam to and their draught to . Their displacement increased by over to at deep load. The crew now numbered 1,376 officers and enlisted men.

The "Ise"-class ships had two sets of direct-drive steam turbines, each of which drove two propeller shafts, using steam provided by 24 Kampon Ro Gō water-tube boilers. The turbines were designed to produce a total of and give the ships a speed of . "Ise" reached from during her sea trials. Each of the boilers consumed a mixture of coal and oil and the ships carried enough of both to give them a range of at a speed of .

During their 1930s modernisation, the boilers on each ship were replaced by eight new Kampon oil-fired boilers. The turbines were replaced by four geared Kampon turbines with a designed output of intended to increase their speed to . On her trials, "Ise" reached a top speed of from . The fuel storage of the ships was increased, which gave them a range of at a speed of , despite the additional weight.

The twelve Type 41 guns of the "Ise" class were mounted in three pairs of twin-gun, superfiring turrets that were numbered one through six from front to rear. The first pair was forward of the main superstructure, the second pair was amidships, and the last ones were aft of the rear superstructure. The ships' secondary armament consisted of twenty Type 3 guns in single mounts. Eighteen of these were mounted in casemates in the forecastle and superstructure and the remaining pair were mounted on the deck above them and protected by gun shields. Anti-aircraft defence was provided by four 3rd Year Type 8-centimetre (3 in) anti-aircraft (AA) guns in single mounts. The ships were also fitted with six submerged torpedo tubes, three on each broadside.

In 1931–1933 the AA guns were replaced with eight Type 89 dual-purpose guns, placed beside the forward superstructure in four twin-gun mounts. Two twin-gun mounts for licence-built Vickers two-pounder () light AA guns were also added, while the pair of 14 cm guns on the upper deck were removed.

During the mid-1930s reconstruction, the torpedo tubes were removed and the Vickers two-pounders were replaced by twenty licence-built Hotchkiss Type 96 light AA guns in 10 twin-gun mounts. This was the standard Japanese light AA gun during World War II, but it suffered from severe design shortcomings that rendered it a largely ineffective weapon. According to historian Mark Stille, the twin and triple mounts "lacked sufficient speed in train or elevation; the gun sights were unable to handle fast targets; the gun exhibited excessive vibration; the magazine was too small, and, finally, the gun produced excessive muzzle blast". During the reconstruction the forward pair of 14-centimetre guns in the forecastle were removed and the maximum elevation of the remaining guns was increased to +30 degrees.

The "Ise"-class ships' waterline protective belt had a maximum thickness of of Vickers cemented armour amidships; below it was a strake of armour. The upper armoured deck consisted of two layers of high-tensile steel totaling thick and the lower armoured deck also consisted of two layers of high-tensile steel, but only thick in total. The turrets were protected with an armour thickness of on the face and 76 mm on the roof. The casemate armour was thick and that of the barbettes was 299 mm thick rather than the originally planned 305 mm.

While the details of the ship's fire-control instruments are not fully available, it is known that "Ise" was fitted with a gunnery director after completion. In the late 1920s the fire-control systems were upgraded and additional platforms were added to the foremast to accommodate them. A pair of directors for the 12.7 cm AA guns were added in the early 1930s, one on each side of the forward superstructure. The fire-control systems were again upgraded in the mid-1930s and directors were added for the 2.5 cm AA guns. The ship had a rangefinder installed at the top of the pagoda mast at that time. Type 21 air-search radars were installed aboard the ship in mid-1942.

"Ise" was briefly fitted with an aircraft flying-off platform for a Mitsubishi 1MF3 fighter on Turret No. 2 in 1927. It was replaced by a platform on Turret No. 5 for a Yokosuka E1Y reconnaissance floatplane in 1928–1929. A catapult and a collapsible crane were fitted on the stern during the mid-1930s modernisation, and the ship was equipped to operate three floatplanes, although no hangar was provided. The initial Nakajima E4N2 biplanes were replaced by Nakajima E8N2 biplanes in 1938.

"Ise", named after Ise Province, one of the traditional provinces of Japan, was laid down at the Kawasaki Heavy Industries shipyard in Kobe on 5 May 1915 and launched on 12 November 1916. Captain Akizawa Yoshima assumed command on 1 December and the ship was completed on 15 December 1917, too late for service in World War I. "Ise" was assigned to the 1st Division of the 1st Fleet in 1917–1918. Captain Kuwashima Shozo relieved Akizawa on 1 December 1918 and he was relieved in his turn by Captain Furukawa Hiroshi on 20 November 1919. On 29 August 1920, the ship began the first of numerous patrols off the Siberian coast and in northern waters in support of Japan's Siberian Intervention against the Bolshevik Red Army. Captain Yokoo Hisashi replaced Furukawa on 20 November and he was replaced by Captain Nagasawa Naotaro in his turn on 1 December 1921.

On 12 April 1922, while at Yokohama, "Ise" hosted a delegation which included the Prince of Wales (the future King Edward VIII), who was accompanied by his second cousin, the future Lord Mountbatten of Burma. Captain Kanna Norikazu relieved Nagasawa on 1 December. The ship aided survivors of the Great Kantō earthquake in September 1923. From the early 1920s through the late 1930s, "Ise" mostly cruised off the coast of China. Little detailed information is available about her activities during the 1920s, although she helped sink the obsolete destroyer during gunnery training on 10 August 1926. The ship was overhauled in 1928–1929, during which her forward superstructure was enlarged and her aviation facilities improved.

Between 20 November 1931 and 10 February 1932, "Ise" had her anti-aircraft armament entirely replaced, her forward superstructure was further enlarged so that it became a pagoda mast, and her stern was modified in preparation for a catapult and crane at Kure Naval Arsenal. These were installed between 14 May and 6 June 1933. On 15 November, she became a training ship. "Ise"s crew participated in the state funeral of Marshal-Admiral The Marquis Tōgō Heihachirō, victor of the 1905 Battle of Tsushima, on 15 June 1934.
Beginning on 1 August 1935, "Ise" was drydocked at Kure Naval Arsenal and underwent an extensive reconstruction and modernisation that lasted until 23 March 1937. On 9 April 1938, the ship began the first of her patrols off the southern Chinese coast during the Second Sino-Japanese War that lasted until early 1941. She was transferred to the 2nd Division of the 1st Fleet on 15 November 1940 and became its flagship on 15 November 1941. Captain Takeda Isamu assumed command of "Ise" on 25 September 1941.

To provide distant support for the 1st Air Fleet attacking Pearl Harbor on 8 December, the division, reinforced by the battleships and and the light carrier , sortied from Hashirajima to the Bonin Islands and returned six days later. "Ise" had a minor refit at the Kure Naval Arsenal in 19–25 February 1942. Together with the rest of the division, she pursued, but did not catch, the American carrier force that had launched the Doolittle Raid on 18 April. On 11 May "Ise" had an accident which flooded her No. 2 engine room. While under repair, the ship was fitted with one of the first experimental Type 21 early-warning radar sets in the IJN, but it was removed shortly afterwards.

"Ise" and the rest of the 2nd Battleship Division set sail on 28 May with the Aleutian Support Group at the same time that most of the Imperial Fleet began an attack on Midway Island (Operation MI). Commanded by Vice-Admiral Shirō Takasu, the division was composed of Japan's four oldest battleships, including "Ise", accompanied by two light cruisers, 12 destroyers, and two oilers. Official records do not show the division as part of the larger Midway operation, known as Operation AL; they were to accompany the fleet under Admiral Isoroku Yamamoto, but were only to provide support to the Aleutian task force if needed.

The loss of four Japanese aircraft carriers during the Battle of Midway in June severely limited the ability of the IJN to conduct operations and alternatives were sought. Plans for full conversions of battleships into aircraft carriers were rejected on the grounds of expense and, most critically, time, so the IJN settled on removing the rear pair of turrets from the "Ise"-class ships and replacing them with a flight deck equipped with two rotating catapults. "Ise" began her conversion on 23 February 1943 and Takeda was relieved by Captain Hase Shinzaburo on 25 April. The ship's No. 5 and No. 6 turrets were replaced by a hangar surmounted by a flight deck. This was not long enough to permit the launch of aircraft or their recovery. Two catapults were installed and the existing crane was moved to the flight deck. The deck was fitted with an extensive system of rails to link each catapult, the storage positions on the deck and the "T"-shaped aircraft lift that moved aircraft between the flight deck and the hangar. It had a capacity of nine aircraft, the remainder being stowed on deck and one on each catapult for a total of 22–24. The ship's air group was intended to consist of a dozen each Yokosuka D4Y "Suisei" dive bombers (Allied reporting name "Judy"), modified for catapult launching, and Aichi E16A reconnaissance aircraft (Allied reporting name "Paul"). The former had to land either on a conventional carrier or on land bases, whereas the E16A could be hoisted back aboard using a crane, after landing on the water near the ship.

During the conversion, all of the 14 cm guns were removed and the ship's anti-aircraft suite was heavily reinforced. The eight 12.7 cm Type 89 guns were supplemented with four additional twin mounts and the existing 2.5 cm Type 96 AA twin-gun mounts were replaced by 19 triple-gun mounts for a total of 57 weapons.

These changes increased the ship's overall length to and the removal of the heavy gun turrets and their barbettes reduced her displacement to at deep load, despite the addition of more fuel oil storage. The extra fuel increased "Ise"s range to . The weight reductions decreased her draught to . The crew now numbered 1,463 officers and enlisted men.
The rebuild was officially completed on 8 October 1943 and "Ise" made a sortie to Truk later that month, conveying a detachment of the 52nd Division and supplies. Hase was promoted to rear admiral on 1 November and the ship began formally working up 10 days later. Captain Nakase Noboru relieved Hase on 25 December.

On 25 February 1944, Battleship Division 2 was assigned to the direct control of the Combined Fleet. "Ise" and her sister ship were transferred to the Third Fleet and assigned to the newly reformed Fourth Carrier Division on 1 May, commanded by Rear Admiral Chiaki Matsuda. That same day the 634th Naval Air Group was formed and assigned to the Fourth Carrier Division. On 24 May, a pair of Type 22 surface-search radars were installed aboard the ship. From 31 May to 7 June, "Ise"s light anti-aircraft armament was reinforced with 47 additional Type 96 AA guns in 12 triple and 11 single mounts, which brought her total to 104 guns. Two Type 2 IFF units were also installed.

On 23 June, the sisters conducted their first catapult training, each with four D4Ys and six E16As aboard; subsequent sessions were conducted on 21 July and 31 August. A pair of Type 13 early-warning radars and an E27 radar detector were installed from 22 to 26 July. From 28 September to 10 October, six racks of 30-tube 12.7 cm anti-aircraft rocket launchers were added. Training of the D4Y and E16A aircrew was slowed by technical problems and was generally conducted from land bases. By 1 October the 634th had on strength 17 D4Ys, of which 6 were serviceable, and 18 E16As, of which 16 were operable.

After the Americans began attacking Japanese installations in the Bonin Islands on 10 October 1944, the aircraft of the Fourth Carrier Division were ordered to prepare for combat by the commander of the Combined Fleet, Admiral Soemu Toyoda. Two days later, the 634th Naval Air Group was reassigned to the Second Air Fleet and began flying to bases in southern Kyushu, among these were nine D4Ys and a dozen E16As assigned to "Ise" and "Hyūga". On 14 October they attacked the aircraft carriers of Task Force 38 near Formosa with little effect and heavy losses. The following day Nakase was promoted to rear admiral.

The ships of the Fourth Carrier Division were assigned to the Main Body of the 1st Mobile Fleet, commanded by Vice-Admiral Jisaburō Ozawa. The Main Body's role was to act as a decoy to attract attention away from the two other forces approaching from the south and west. All forces were to converge on Leyte Gulf on 25 October and the Main Body left Japan on 20 October. By the morning of 24 October, the Main Body was within range of the northernmost American carriers of Task Force 38 and Ozawa ordered an air strike launched by the Third Carrier Division ("Ise" and "Hyūga" had no aircraft aboard) to attract the attention of the Americans. This accomplished little else as the Japanese aircraft failed to penetrate past the defending fighters; the survivors landed at airfields on the Philippine island of Luzon. The Americans were preoccupied dealing with the other Japanese naval forces and defending themselves from air attacks launched from Luzon and Leyte and could not spare any aircraft to search for the Japanese carriers until the afternoon. They finally found them, but Admiral William Halsey, Jr., commander of Task Force 38, decided that it was too late in the day to mount an effective strike. He did, however, turn all of his ships north to position himself for a dawn attack on the Japanese carriers the next day.
On the morning of 25 October, "Ise" was positioned astern of the carriers and to protect them with her anti-aircraft guns. Her radar picked up American aircraft at a range of at 07:39, but the first attack did not begin until 08:20. The battleship engaged them with San Shiki anti-aircraft shells from her main guns with unknown effect. She was not heavily attacked at that time and was near missed by two bombs. The second wave of aircraft attacked at 10:05 and the ship's gunners claimed to have shot down five out of ten attacking dive bombers. "Ise" was near missed eight times, although one small bomb struck No. 2 turret. The third wave was detected by her radar at 12:28, but it did not attack the battleship, sinking the damaged "Zuikaku" and "Zuihō" instead. "Ise" rescued 98 survivors from "Zuihō" before the next attack began around 17:26. She was the primary focus of this wave and was attacked by about 85 dive bombers and at least 11 torpedo bombers. Saved by heavy anti-aircraft fire and expert manoeuvring, the battleship dodged all of the torpedoes, and was only struck once, near the port catapult. Roughly 34 near misses damaged her hull plating near the waterline and started a small leak that contaminated a small oil tank and caused minor damage to the port boiler rooms. Splinters from the near misses and the single hit killed 5 crewmen and wounded 71.

The American submarine spotted the Fourth Carrier Division at 17:42 and manoeuvred to attack, missing with six torpedoes at 18:43. At 19:00 Ozawa ordered Matsuda to take his ships south to defend the light cruiser and her escorting destroyers that were attempting to rescue survivors of the crippled light carrier despite gunfire from a group of four American cruisers. Unable to locate either group of ships, Ozawa ordered Matsuda to reverse course at 23:30 and head for Amami Ōshima to refuel. Despite being spotted by American submarines en route, the division arrived safely on 27 October. After leaving the island the following day, they were unsuccessfully attacked by the submarine before their arrival at Kure on the 29th.

Between 29 October and 8 November, the catapults were removed to improve the firing arcs of No. 3 and No. 4 turrets. "Ise" and "Hyūga" departed on 11 November, loaded with troops and munitions for Manila, capital of the Philippines, but news was received of heavy American air attacks on Manila and they were diverted to the Spratly Islands. They arrived on 14 November and their cargo was unloaded so it could be transshipped to the Philippines. The 4th Carrier Division was transferred to the 2nd Fleet the following day. Reinforced by the battleship and three cruisers, the sisters proceeded on to Lingga Island, near Singapore, on 20 November. They arrived two days later and remained there until 12 December when they departed for Cam Ranh Bay, French Indochina, where they were on standby for an attack on an American supply convoy bound for the island of Mindanao in the Philippines. The attack was cancelled on the 30th and the ships sailed for Singapore where they arrived on 1 January 1945 before continuing on to Lingga. That same day the Fourth Carrier Division was transferred to the Southwest Area Fleet.

On 6 February, the division sailed for Singapore to participate in Operation Kita. While approaching Singapore, "Ise" was slightly damaged by a mine. Given temporary repairs at the former British naval base there, "Ise", "Hyūga", and the light cruiser were loaded with critically needed strategic war supplies (oil, rubber, tin, zinc, and mercury) and 1,150 surplus oil workers to be ferried back to Japan.

The division sailed from Singapore on 10 February and was spotted by the British submarine the following day. It was forced to submerge by a maritime patrol aircraft and was unable to attack. On 13 February the submarine unsuccessfully attacked the ships as did the submarine . One of "Ise"s AA guns caused one of "Blower"s torpedoes to detonate prematurely. Later that afternoon, "Oyodo" launched one of her floatplanes which spotted the submarine on the surface about ahead of the convoy. "Hyūga" opened fire with her main guns and forced "Bashaw" to submerge when one of her shells landed within of the submarine. The convoy reached the Matsu Islands, off the Chinese coast, on the 15th and was unsuccessfully attacked by the submarine before they reached Zhoushan Island, near Shanghai that night. The convoy reached Kure on 20 February, having evaded or escaped pursuit by twenty-three Allied submarines along the way. Nakase was relieved by Captain Mutaguchi Kakuro five days later.
The 4th Carrier Division was disbanded on 1 March and "Ise" was reduced to first-class reserve. From this time until the surrender of Japan, "Ise" remained docked at Kure, without fuel or aircraft, and repainted in an olive green camouflage with vari-coloured splotches. The camouflage was not effective against American carrier-based aircraft from Task Force 58 (TF 58) on 19 March, when more than 240 aircraft attacked Kure and "Ise" was hit by two bombs. Re-designated as a fourth-class reserve ship on 20 April, "Ise" was towed to the island of Ondo Seto (between Kure and Kurahashijima) to serve as a floating anti-aircraft battery. She was attacked again on 24 July by 60 carrier-based aircraft, whose bombs hit the starboard bow, flight deck, main deck, No. 3 turret and bridge, killing Mutaguchi, other bridge personnel, and around 50 crewmen; many other crewmen were wounded. The ship settled by the bow and it took three days to pump her dry and the IJN planned to drydock her for repairs. On 28 July she was struck by five bombs dropped by F4U Corsair fighters from , and eleven more bombs dropped by other aircraft from TF 58. Later that day an attack by 18 USAAF Consolidated B-24 Liberator heavy bombers was unsuccessful. "Ise" took on a 15° list to starboard and sank in shallow water. Salvage efforts were abandoned that same day, although some AA guns were stripped from her wreck. The ship was struck from the Navy list on 20 November. The underwater portion of "Ise"s wreck was ignored until the following year and she was scrapped in place by the Kure Dockyard of the Harima Zōsen Corporation from 9 October 1946 to 4 July 1947.





</doc>
<doc id="976909" url="https://en.wikipedia.org/wiki?curid=976909" title="Japanese battleship Yamashiro">
Japanese battleship Yamashiro

"Yamashiro" was modernized between 1930 and 1935, with improvements to her armor and machinery and a rebuilt superstructure in the pagoda mast style. Nevertheless, with only 14-inch guns, she was outclassed by other Japanese battleships at the beginning of World War II, and played auxiliary roles for most of the war.

By 1944, though, she was forced into front-line duty, serving as the flagship of Vice-Admiral Shōji Nishimura's Southern Force at the Battle of Surigao Strait, the southernmost action of the Battle of Leyte Gulf. During fierce night fighting in the early hours of 25 October against a superior American force, "Yamashiro" was sunk by torpedoes and naval gunfire. Nishimura went down with his ship, and only 10 crewmembers survived.

The ship had a length of between perpendiculars and overall. She had a beam of and a draft of . "Yamashiro" displaced at standard load and at full load. Her crew consisted of 1,198 officers and enlisted men in 1915 and about 1,400 in 1935.

During the ship's modernization during 1930–35, her forward superstructure was enlarged with multiple platforms added to her tripod foremast. Her rear superstructure was rebuilt to accommodate mounts for anti-aircraft (AA) guns and additional fire-control directors. "Yamashiro" was also given torpedo bulges to improve her underwater protection and to compensate for the weight of the additional armor. In addition, her stern was lengthened by . These changes increased her overall length to , her beam to and her draft to . Her displacement increased nearly to at deep load.

The ship had two sets of Brown-Curtis direct-drive steam turbines, each of which drove two propeller shafts. The turbines were designed to produce a total of , using steam provided by 24 Miyahara-type water-tube boilers, each of which consumed a mixture of coal and oil. "Yamashiro" had a stowage capacity of of coal and of fuel oil, giving her a range of at a speed of . The ship exceeded her designed speed of during her sea trials, reaching at .

During her modernization, the Miyahara boilers were replaced by six new Kanpon oil-fired boilers fitted in the former aft boiler room, and the forward funnel was removed. The Brown-Curtis turbines were replaced by four geared Kanpon turbines with a designed output of . On her trials, "Yamashiro"s sister ship "Fusō" reached a top speed of from . The fuel storage of the ship was increased to a total of of fuel oil that gave her a range of at a speed of .

The twelve 45-calibre 14-inch guns of "Yamashiro" were mounted in six twin-gun turrets, numbered one through six from front to rear, each with an elevation range of −5 to +30 degrees. The turrets were arranged in an unorthodox 2-1-1-2 style with superfiring pairs of turrets fore and aft; the middle turrets were not superfiring, and had a funnel between them. The main guns and their turrets were modernized during the ship's 1930 reconstruction; the maximum elevation of the main guns was increased to +43 degrees, increasing their maximum range from . Initially, the guns could fire at a rate of 1.5 rounds per minute, and this was also improved during her first modernization.

Originally, "Yamashiro" was fitted with a secondary armament of sixteen 50-caliber 6-inch guns mounted in casemates on the upper sides of the hull. Each gun could fire a high-explosive projectile to a maximum range of at up to six shots per minute. She was later fitted with six high-angle 40-caliber three-inch AA guns, in single mounts on both sides of the forward superstructure and both sides of the second funnel, as well as on both sides of the aft superstructure. These guns had a maximum elevation of +75 degrees, and could fire a shell at a rate of 13 to 20 rounds per minute to a maximum height of . The ship was also fitted with six submerged torpedo tubes, three on each broadside.
During "Yamashiro"s modernization in the early 1930s, all six three-inch guns were removed and replaced with eight 40-caliber 127-millimeter dual-purpose guns, fitted on both sides of the fore and aft superstructures in four twin-gun mounts. When firing at surface targets, the guns had a range of ; they had a maximum ceiling of at their maximum elevation of +90 degrees. Their maximum rate of fire was 14 rounds a minute, but their sustained rate of fire was around eight rounds per minute.

The improvements made during the reconstruction increased "Yamashiro"s draft by ; the two foremost six-inch guns were removed, as the same guns on her sister ship had gotten soaked in high seas after that ship's reconstruction. The ship's light-AA armament was augmented by eight 25 mm Type 96 light AA guns in twin-gun mounts. Four of these mounts were fitted on the forward superstructure, one on each side of the funnel and two on the rear superstructure. This was the standard Japanese light-AA gun during World War II, but it suffered from severe design shortcomings that rendered it a largely ineffective weapon. According to historian Mark Stille, the twin and triple mounts "lacked sufficient speed in train or elevation; the gun sights were unable to handle fast targets; the gun exhibited excessive vibration; the magazine was too small, and, finally, the gun produced excessive muzzle blast". The configuration of the AA guns varied significantly over time; in 1943, 17 single and two twin-mounts were added for a total of 37. In July 1944, the ship was fitted with another 17 single, 15 twin and eight triple-mounts, for a total of 92 anti-aircraft guns in her final configuration. The gun had an effective range of , and an effective ceiling of at an elevation of 85 degrees. The maximum effective rate of fire was only between 110 and 120 rounds per minute because of the frequent need to change the fifteen-round magazines.

Also in July 1944, the ship was provided with three twin-gun and 10 single mounts for the license-built 13.2 mm Hotchkiss machine gun. The maximum range of these guns was , but the effective range against aircraft was only . The cyclic rate was adjustable between 425 and 475 rounds per minute, but the need to change 30-round magazines reduced the effective rate to 250 rounds per minute.

The ship's waterline armor belt was thick; below it was a strake of armor. The deck armor ranged in thickness from . The turrets were protected with an armor thickness of on the face, on the sides, and on the roof. The barbettes of the turrets were protected by armor 305 mm thick, while the casemates of the 152 mm guns were protected by 152 mm armor plates. The sides of the conning tower were thick. Additionally, the vessel contained 737 watertight compartments (574 underneath the armor deck, 163 above) to preserve buoyancy in the event of battle damage.

During her first reconstruction "Yamashiro"s armor was substantially upgraded. The deck armor was increased to a maximum thickness of . A longitudinal bulkhead of of high-tensile steel was added to improve the underwater protection.

"Yamashiro" was briefly fitted with an aircraft flying-off platform on Turret No. 2 in 1922. She successfully launched Gloster Sparrowhawk and Sopwith Camel fighters from it, the first Japanese ship to do so. During her modernization in the 1930s, a catapult and a collapsible crane were fitted on the stern, and the ship was equipped to operate three floatplanes, although no hangar was provided. The initial Nakajima E4N2 biplanes were replaced by Nakajima E8N2 biplanes in 1938 and then by Mitsubishi F1M biplanes, from 1942 on.

The ship was originally fitted with two and two rangefinders in her forward superstructure, a rangefinder on the roof of Turret No. 2, and 4.5-meter rangefinders in Turrets 3, 4, and 5.

While in drydock in July 1943, a Type 21 air search radar was installed on the roof of the 10-meter rangefinder at the top of the pagoda mast. In August 1944, two Type 22 surface search radar units were installed on the pagoda mast and two Type 13 early warning radar units were fitted on her mainmast.

"Yamashiro", named for Yamashiro Province, the former province of Kyoto, was laid down at the Yokosuka Naval Arsenal on 20 November 1913 and launched on 3 November 1915. She was completed on 31 March 1917 with Captain Suketomo Nakajima in command, and was assigned to the 1st Division of the 1st Fleet in 1917–1918. She did not take part in any combat during World War I, as there were no longer any forces of the Central Powers in East Asia by the time she was completed, but she did patrol off the coast of China briefly during the war. On 29 March 1922, a Gloster Sparrowhawk fighter successfully took off from the ship. She aided survivors of the 1923 Great Kantō earthquake in September 1923. Little detailed information is available about "Yamashiro"s activities during the 1920s, although she did make a port visit to Ryojun Guard District, in Manchuria, on 5 April 1925 and also conducted training off the coast of China.

The ship's reconstruction began on 18 December 1930 at the Yokosuka Naval Arsenal where her machinery was replaced, her armor was reinforced, and torpedo bulges were fitted. "Yamashiro"s armament was also upgraded and her torpedo tubes were removed. Captain Chuichi Nagumo assumed command of the ship on 15 November 1934, her modernization was completed on 30 March 1935, and she became flagship of the Combined Fleet. Captain Masakichi Okuma relieved Nagumo on 15 November and he, in turn, was replaced by Captain Masami Kobayashi on 1 December 1936. "Yamashiro" began a lengthy refit on 27 June 1937 and Captain Kasuke Abe assumed command on 20 October. Her refit was completed on 31 March 1938 and Captain Kakuji Kakuta relieved Abe on 15 November. In early 1941, the ship experimentally launched radio-controlled Kawanishi E7K2 floatplanes. Captain Chozaemon Obata assumed command on 24 May 1941 and "Yamashiro" was assigned to the 1st Fleet's 2nd Division, consisting of the two "Fusō"-class and the two s.

"Yamashiro" and her sister ship "Fusō" spent most of the war around Japan, mostly at the anchorage at Hashirajima in Hiroshima Bay. When the war started for Japan on 8 December, the division, reinforced by the battleships and and the light carrier , sortied from Hashirajima to the Bonin Islands as distant support for the 1st Air Fleet attacking Pearl Harbor, and returned six days later. On 18 April 1942, "Yamashiro" chased the Doolittle Raider force that had just launched an air raid on Tokyo, but returned four days later without having made contact. On 28 May, she set sail, commanded by Captain Gunji Kogure, with the rest of the 2nd Battleship Division and the Aleutian Support Group at the same time that most of the Imperial Fleet began an attack on Midway Island (Operation MI). Commanded by Vice-Admiral Shirō Takasu, the division was composed of Japan's four oldest battleships, including "Yamashiro", accompanied by two light cruisers, 12 destroyers, and two oilers. Official records do not show the squadron as part of the larger Midway operation, known as Operation AL; they were to accompany the fleet under Admiral Isoroku Yamamoto, but were only to provide support to the Aleutian task force if needed. They were not needed, and "Yamashiro" returned to home waters where she was employed mostly for training duties, in the Inland Sea till 1 February 1943 and at Yokosuka until September, when she became a training ship for midshipmen.

In an effort to replace the aircraft carriers lost at the Battle of Midway, the Navy made plans to convert the two "Fusō"-class ships to hybrid battleship/carriers, but the two "Ise"-class battleships were chosen instead. In July 1943, "Yamashiro" was at the Yokosuka drydock for fitting of a radar and additional 25 mm AA guns. The ship was briefly assigned as a training ship on 15 September before loading troops on 13 October bound for Truk Naval Base, arriving with the battleship on the 20th. The two battleships sailed for Japan, accompanied by the carriers and , on 31 October. On 8 November, the submarine fired torpedoes at "Jun'yo" that missed, but hit "Yamashiro" with a torpedo that failed to detonate. "Yamashiro" resumed her training duties in Japan, and Captain Yoshioki Tawara assumed command. He was promoted to Rear Admiral on 1 May, but died of natural causes four days later, and Captain Katsukiyo Shinoda was appointed to replace him.

During the US invasion of Saipan in June 1944, Japanese troop ships attempting to reinforce the defenses were sunk by submarines. Shigenori Kami, chief of operations of the Navy Staff, volunteered to command "Yamashiro" to carry troops and equipment to Saipan. If the ship actually reached the island, he intended to deliberately beach the ship before it could be sunk and to use its artillery to defend the island. After Ryūnosuke Kusaka, Chief of Staff of the Combined Fleet, also volunteered to go, Prime Minister Hideki Tōjō approved the plan, known as Operation "Y-GO", but the operation was cancelled after the decisive defeat in the Battle of the Philippine Sea on 19 and 20 June.

The ship was refitted in July at Yokosuka, where additional radar systems and light AA guns were fitted. "Yamashiro" and her sister ship were transferred to Battleship Division 2 of the 2nd Fleet on 10 September. The ship briefly became the division's flagship under Vice Admiral Shōji Nishimura until 23 September when he transferred his flag to "Fusō". They departed Kure on 23 September for Lingga Island, carrying the Army's 25th Independent Mixed Regiment, and escaped an attack by the submarine the next day. They arrived on 4 October, where Nishimura transferred his flag back to "Yamashiro". The ships then transferred to Brunei to offload their toops and refuel in preparation for Operation "Shō-Gō", the attempt to destroy the American fleet conducting the invasion of Luzon.

As flagship of Nishimura's Southern Force, "Yamashiro" left Brunei at 15:30 on 22 October 1944, heading east into the Sulu Sea and then to the northeast into the Mindanao Sea. Intending to join Vice-Admiral Takeo Kurita's force in Leyte Gulf, they passed west of Mindanao Island into Surigao Strait, where they met a large force of battleships and cruisers lying in wait. The Battle of Surigao Strait would become the southernmost action in the Battle of Leyte Gulf.

At 09:08 on 24 October, "Yamashiro", "Fusō" and the heavy cruiser "Mogami" were spotted by a group of 27 planes, including Grumman TBF Avenger torpedo bombers and Curtiss SB2C Helldiver dive bombers escorted by Grumman F6F Hellcat fighters, coming from the carrier . Around 20 sailors on "Yamashiro" were killed by strafing and rocket attacks, and the ship listed by almost 15 degrees after a bomb's near miss damaged the hull and flooded the starboard bilge, until counter-flooding in the port bilge righted the ship.

Nishimura issued a telegram to Admiral Soemu Toyoda at 20:13: "It is my plan to charge into Leyte Gulf to [reach] a point off Dulag at 04:00 hours on the 25th." At 22:52, his force opened fire, damaging and and forcing them to retreat before they could launch their torpedoes. Three American destroyers launched torpedoes at 03:00 that morning, hitting "Fusō" at 03:08 and forcing her to fall out of formation. "Yamashiro" opened fire with her secondary battery seven minutes later. Around 03:11, the destroyers "Monssen" and "Killen" fired their torpedoes, one or two of which hit "Yamashiro" amidships. The resulting damage temporarily slowed the ship down, gave her a list to port and forced the flooding of the magazines for the two aft turrets. "Yamashiro" may have been hit a third time near the bow at 03:40.

At 03:52, the battleship was attacked by a large formation to the north commanded by Rear Admiral Jesse Oldendorf. First came 6- and shells from three heavy cruisers, , , and , and four light cruisers, , , and . Six battleships formed a battle line; the Pearl Harbor veteran was the first to open fire a minute later, scoring at least one hit with shells in the first salvo, followed by and . Hampered by older radar equipment, joined the fight late, never fired, and managed to fire exactly one salvo—the last of the engagement. The Australian heavy cruiser HMAS "Shropshire" also had radar problems and did not begin firing until 03:56.

The main bombardment lasted 18 minutes, and "Yamashiro" was the only target for seven of them. The first rounds hit the forecastle and pagoda mast, and soon the entire battleship appeared to be ablaze. "Yamashiro" two forward turrets targeted her assailants, and the secondary armament targeted the American destroyers plaguing "Mogami" and the destroyer "Asagumo". The ship continued firing in all directions, but was not able to target the battleships with the other four operable 14-inch guns of her amidships turrets until almost 04:00, after turning west. There was a big explosion at 04:04, possibly from one of the middle turrets. "Yamashiro" increased her firing rate between 04:03 and 04:09, despite the widespread fires and damage, and was hit during this time near the starboard engine room by a torpedo. By 04:09, her speed was back up to 12 knots, and Nishimura wired to Kurita: "We proceed till totally annihilated. I have definitely accomplished my mission as pre-arranged. Please rest assured." At the same time, Oldendorf issued a brief cease-fire order to the entire formation after hearing that the destroyer "Albert W. Grant" was taking friendly fire, and the Japanese ships also ceased fire.

"Yamashiro" increased speed to 15 knots in an attempt to escape the trap, but she had already been hit by two to four torpedoes, and after two more torpedo hits near the starboard engine room, likely fired by the USS Bennion, she was listing 45 degrees to port. Shinoda gave the command to abandon ship, but neither he nor Nishimura made any attempt to leave the conning tower as the ship capsized within five minutes and quickly sank, stern first, vanishing from radar between 04:19 and 04:21. Only 10 crewmembers of the estimated 1,636 officers and crew on board survived.

John Bennett claimed to have discovered "Yamashiro"s wreck in April 2001, but confirmation of the wreck's identity could not be made. On 26 November 2017, Paul Allen and his crew aboard the research ship R/V "Petrel", discovered the wreck of "Yamashiro" and confirmed her identity. The ship was found upside down and mostly intact, with the forward bow folded over the hull and the area around the engine rooms partially collapsed.



</doc>
<doc id="977013" url="https://en.wikipedia.org/wiki?curid=977013" title="Japanese battleship Nagato">
Japanese battleship Nagato

, named for Nagato Province, was a super-dreadnought battleship built for the Imperial Japanese Navy (IJN). Completed in 1920 as the lead ship of her class, she carried supplies for the survivors of the Great Kantō earthquake in 1923. The ship was modernized in 1934–1936 with improvements to her armor and machinery and a rebuilt superstructure in the pagoda mast style. "Nagato" briefly participated in the Second Sino-Japanese War in 1937 and was the flagship of Admiral Isoroku Yamamoto during the attack on Pearl Harbor. She covered the withdrawal of the attacking ships and did not participate in the attack itself.

Other than participating in the Battle of Midway in June 1942, where she did not see combat, the ship spent most of the first two years of the Pacific War training in home waters. She was transferred to Truk in mid-1943, but did not see any combat until the Battle of the Philippine Sea in mid-1944 when she was attacked by American aircraft. "Nagato" did not fire her main armament against enemy vessels until the Battle of Leyte Gulf in October. She was lightly damaged during the battle and returned to Japan the following month. The IJN was running out of fuel by this time and decided not to fully repair her. "Nagato" was converted into a floating anti-aircraft platform and assigned to coastal defense duties. She was attacked in July 1945 as part of the American campaign to destroy the IJN's last remaining capital ships, but was only slightly damaged and went on to be the only Japanese battleship to have survived World War II. In mid-1946, the ship was a target for nuclear weapon tests during Operation Crossroads. She survived the first test with little damage, but was sunk by the second.

"Nagato" had a length of between perpendiculars and overall. She had a beam of and a draft of . The ship displaced at standard load and at full load. Her crew consisted of 1,333 officers and enlisted men as built and 1,368 in 1935. The crew totaled around 1,734 men in 1944.

In 1930, "Nagato"s bow was remodeled to reduce the amount of spray produced when steaming into a head sea. This increased her overall length by to . During her 1934–1936 reconstruction, the ship's stern was lengthened by to improve her speed and her forward superstructure was rebuilt into a pagoda mast. She was given torpedo bulges to improve her underwater protection and to compensate for the weight of the additional armor and equipment. These changes increased her overall length to , her beam to and her draft to . Her displacement increased over to at deep load. The ship's metacentric height at deep load was . In November 1944, the tops of "Nagato"s mainmast and funnel were removed to improve the effective arcs of fire for her anti-aircraft guns.

"Nagato" was equipped with four Gihon geared steam turbines, each of which drove one propeller shaft. The turbines were designed to produce a total of , using steam provided by 21 Kampon water-tube boilers; 15 of these were oil-fired while the remaining half-dozen consumed a mixture of coal and oil. The ship could carry of coal and of fuel oil, giving her a range of at a speed of . The ship exceeded her designed speed of during her sea trials, reaching at .

Funnel smoke would often choke and blind crewmen on the bridge and in the fire-control systems so a "fingernail"-shaped deflector was installed on the fore funnel in 1922 to direct the exhaust away from them. It was less than effective and the fore funnel was rebuilt in a serpentine shape in an unsuccessful effort during a refit in 1924. That funnel was eliminated during the ship's 1930s reconstruction when all of her boilers were replaced by ten oil-fired Kampon boilers, which had a working pressure of and temperature of . In addition her turbines were replaced by lighter, more modern, units. When "Nagato" conducted her post-reconstruction trials, she reached a speed of with . Additional fuel oil was stored in the bottoms of the newly added torpedo bulges, which increased her capacity to and thus her range to at 16 knots.

"Nagato"s eight 45-caliber 41-centimeter (16 inch) guns were mounted in two pairs of twin-gun, superfiring turrets fore and aft. Numbered one through four from front to rear, the hydraulically powered turrets gave the guns an elevation range of −2 to +35 degrees. The rate of fire for the guns was around two rounds per minute. The turrets aboard the "Nagato"-class ships were replaced in the mid-1930s with the turrets stored from the unfinished s. While in storage the turrets had been modified to increase their range of elevation to –3 to +43 degrees, which increased the gun's maximum range from .

The ship's secondary armament of twenty 50-caliber 14-centimeter guns was mounted in casemates on the upper sides of the hull and in the superstructure. The manually operated guns had a maximum range of and fired at a rate of six to 10 rounds per minute. Anti-aircraft defense was provided by four 40-caliber 3rd Year Type three-inch AA guns in single mounts. The high-angle guns had a maximum elevation of +75 degrees, and had a rate of fire of 13 to 20 rounds per minute. The ship was also fitted with eight torpedo tubes, four on each broadside, two above water and two submerged.
Around 1926, the four above-water torpedo tubes were removed and the ship received three additional 76 mm AA guns that were situated around the base of the foremast. They were replaced by eight 40-caliber 12.7-centimeter Type 89 dual-purpose (DP) guns in 1932, fitted on both sides of the fore and aft superstructures in four twin-gun mounts. When firing at surface targets, the guns had a range of ; they had a maximum ceiling of at their maximum elevation of +90 degrees. Their maximum rate of fire was 14 rounds a minute, but their sustained rate of fire was around eight rounds per minute. Two twin-gun mounts for license-built Vickers two-pounder light AA guns were also added to the ship that same year. These guns had a maximum elevation of +80 degrees which gave them a ceiling of . They had a maximum rate of fire of 200 rounds per minute.

When the ship was reconstructed in 1934–1936, the remaining torpedo tubes and the two forward 14 cm (5-1/2 inch) guns were removed from the hull. The remaining 14 cm guns had their elevation increased to +35 degrees which increased their range to . An unknown number of license-building Hotchkiss M1929 machine gun in twin mounts were added. The maximum range of these guns was , but the effective range against aircraft was . The cyclic rate was adjustable between 425 and 475 rounds per minute, but the need to change 30-round magazines reduced the effective rate to 250 rounds per minute.

The unsatisfactory two-pounders were replaced in 1939 by twenty license-built Type 96 Hotchkiss Type 96 light AA guns in a mixture of twin-gun and single mounts. This was the standard Japanese light AA gun during World War II, but it suffered from severe design shortcomings that rendered it a largely ineffective weapon. According to historian Mark Stille, the twin and triple mounts "lacked sufficient speed in train or elevation; the gun sights were unable to handle fast targets; the gun exhibited excessive vibration; the magazine was too small, and, finally, the gun produced excessive muzzle blast". These 25 mm guns had an effective range of , and an effective ceiling of at an elevation of 85 degrees. The maximum effective rate of fire was only between 110 and 120 rounds per minute because of the frequent need to change the fifteen-round magazines. Additional Type 96 guns were installed during the war; on 10 July 1944, the ship was reported to have 98 guns on board. An additional 30 guns were added during a refit in Yokosuka in November. Two more twin 12.7 cm (5 inch) gun mounts were added at the same time abreast the funnel and her 14 cm guns were removed as she was by then a floating anti-aircraft battery.

The ship's waterline armor belt was thick and tapered to a thickness of at its bottom edge; above it was a strake of armor. The main deck armor was while the lower deck was thick. The turrets were protected with an armor thickness of 305 mm on the face, on the sides, and on the roof. The barbettes of the turrets were protected by armor 305 mm thick, while the casemates of the 1 guns were protected by Type 96 armor plates. The sides of the conning tower were thick.

The new 41 cm turrets installed during "Nagato"s reconstruction were more heavily armored than the original ones. Face armor was increased to , the sides to , and the roof to . The armor over the machinery and magazines was increased by 38 mm on the upper deck and Type 96 on the upper armored deck. These additions increased the weight of the ship's armor to , 32.6 percent of her displacement. In early 1941, as a preparation for war, "Nagato"s barbette armor was reinforced with armor plates above the main deck and plates below it.

When completed in 1920, the ship was fitted with a rangefinder in the forward superstructure; and anti-aircraft rangefinders were added in May 1921 and 1923, respectively. The rangefinders in the second and third turrets were replaced by 10-meter units in 1932–1933.

"Nagato" was initially fitted with a Type 13 fire-control system derived from Vickers equipment received during World War I, but this was replaced by an improved Type 14 system around 1925. It controlled the main and secondary guns; no provision was made for anti-aircraft fire until the Type 31 fire-control director was introduced in 1932. A modified Type 14 fire-control system was tested aboard the ship in 1935 and later approved for service as the Type 34. A new anti-aircraft director called the Type 94 that was used to control the 127 mm AA guns was introduced in 1937, although when "Nagato" received hers is unknown. The Type 96 AA guns were controlled by a Type 95 director that was also introduced in 1937.

While in drydock in May 1943, a Type 21 air search radar was installed on the roof of the 10-meter rangefinder at the top of the pagoda mast. On 27 June 1944, two Type 22 surface search radars were installed on the pagoda mast and two Type 13 early warning radars were fitted on her mainmast.

"Nagato" was fitted with an aircraft flying-off platform on Turret No. 2 in August 1925. Yokosuka Ro-go Ko-gata and Heinkel HD 25 floatplanes were tested from it before it was removed early the following year. An additional boom was added to the mainmast in 1926 to handle the Yokosuka E1Y now assigned to the ship. A Hansa-Brandenburg W.33 floatplane was tested aboard "Nagato" that same year. A catapult was fitted between the mainmast and Turret No. 3 in mid-1933, a collapsible crane was installed in a portside sponson, and the ship was equipped to operate two or three floatplanes, although no hangar was provided. The ship now operated Nakajima E4N2 biplanes until they were replaced by Nakajima E8N2 biplanes in 1938. A more powerful catapult was installed in November 1938 to handle heavier aircraft, such as the one Kawanishi E7K that was added in 1939–1940. Mitsubishi F1M biplanes replaced the E8Ns on 11 February 1943.

"Nagato", named for Nagato Province, was ordered on 12 May 1916 and laid down at the Kure Naval Arsenal on 28 August 1917 as the lead ship of her class. She was launched on 9 November 1919 by Admiral Katō Tomosaburō, completed on 15 November 1920 and commissioned 10 days later with Captain Nobutaro Iida in command. "Nagato" was assigned to the 1st Battleship Division and became the flagship of Rear Admiral Sōjirō Tochinai. On 13 February 1921, the ship was inspected by the Crown Prince, Hirohito. Captain Kanari Kabayama relieved Iida on 1 December 1921. The ship hosted Marshal Joseph Joffre on 18 February 1922 and Edward, Prince of Wales, and his aide-de-camp Lieutenant Louis Mountbatten on 12 April during the prince's visit to Japan.

After the 1923 Great Kantō earthquake, "Nagato" loaded supplies from Kyushu for the victims on 4 September. Together with her sister ship , she sank the hulk of the obsolete battleship on 7 September 1924 during gunnery practice in Tokyo Bay in accordance with the Washington Naval Treaty. The ship was transferred to the reserve of the 1st Division on 1 December and became a gunnery training ship. In August 1925, aircraft handling and take-off tests were conducted aboard "Nagato". She was reassigned as the flagship of the Combined Fleet on 1 December, flying the flag of Admiral Keisuke Okada. Captain Kiyoshi Hasegawa assumed command of the ship on 1 December 1926.

"Nagato" was again placed in reserve on 1 December 1931 and her anti-aircraft armament was upgraded the following year. In August 1933 the ship participated in fleet maneuvers north of the Marshall Islands and she began her first modernization on 1 April 1934. This was completed on 31 January 1936 and "Nagato" was assigned to the 1st Battleship Division of the 1st Fleet. During the attempted coup d'état on 26 February by disgruntled Army officers, the ship was deployed in Tokyo Bay and some of her sailors were landed in support of the government. In August, she transported 1,749 men of the 43rd Infantry Regiment of the 11th Infantry Division from Shikoku to Shanghai during the Second Sino-Japanese War. Her floatplanes bombed targets in Shanghai on 24 August before she returned to Sasebo the following day. "Nagato" became a training ship on 1 December until she again became the flagship of the Combined Fleet on 15 December 1938. The ship participated in an Imperial Fleet Review on 11 October 1940. She was refitted in early 1941 in preparation for war.

Admiral Isoroku Yamamoto issued the code phrase ""Niitaka yama nobore"" (Climb Mount Niitaka) on 2 December 1941 from "Nagato" at anchor at Hashirajima to signal the 1st Air Fleet ("Kido Butai") in the North Pacific to proceed with its attack on Pearl Harbor. When the war started for Japan on 8 December, she sortied for the Bonin Islands, along with "Mutsu", the battleships , , , of Battleship Division 2, and the light carrier as distant cover for the withdrawal of the fleet attacking Pearl Harbor, and returned six days later. Yamamoto transferred his flag to the new battleship on 12 February 1942. "Nagato" was briefly refitted 15 March – 9 April at Kure Naval Arsenal.

In June 1942 "Nagato", commanded by Captain Hideo Yano, was assigned to the Main Body of the 1st Fleet during the Battle of Midway, together with "Yamato", "Mutsu", "Hosho", the light cruiser , nine destroyers and four auxiliary ships. Following the loss of all four carriers of the 1st Air Fleet on 4 June, Yamamoto attempted to lure the American forces west to within range of the Japanese air groups at Wake Island, and into a night engagement with his surface forces, but the American forces withdrew and "Nagato" saw no action. After rendezvousing with the remnants of the 1st Air Fleet on 6 June, survivors from the aircraft carrier were transferred to "Nagato". On 14 July, the ship was transferred to Battleship Division 2 and she became the flagship of the 1st Fleet. Yano was promoted to Rear Admiral on 1 November and he was replaced by Captain Yonejiro Hisamune nine days later. Nagato remained in Japanese waters training until August 1943. On 2 August Captain Mikio Hayakawa assumed command of the ship.

That month, "Nagato", "Yamato", "Fusō" and the escort carrier , escorted by two heavy cruisers and five destroyers transferred to Truk in the Caroline Islands. In response to the carrier raid on Tarawa on 18 September, "Nagato" and much of the fleet sortied for Eniwetok to search for the American forces before they returned to Truk on 23 September, having failed to locate them. The Japanese had intercepted some American radio traffic that suggested an attack on Wake Island, and on 17 October, "Nagato" and the bulk of the 1st Fleet sailed for Eniwetok to be in a position to intercept any such attack. The fleet arrived on 19 October, departed four days later, and arrived back at Truk on 26 October. Hayakawa was promoted to Rear Admiral on 1 November and he was relieved on 25 December by Captain Yuji Kobe.
On 1 February 1944, "Nagato" departed Truk with "Fusō" to avoid an American air raid, and arrived at Palau on 4 February. They left on 16 February to escape another air raid. The ships arrived on 21 February at Lingga Island, near Singapore, and the ship became the flagship of Vice Admiral Matome Ugaki, commander of Battleship Division 1, on 25 February until he transferred his flag to "Yamato" on 5 May. Aside from a brief refit at Singapore, the ship remained at Lingga training until 11 May when she was transferred to Tawitawi on 12 May. The division was now assigned to the 1st Mobile Fleet, under the command of Vice Admiral Jisaburō Ozawa.

On 10 June, Battleship Division 1 departed Tawitawi for Batjan in preparation for Operation Kon, a planned counterattack against the American invasion of Biak. Three days later, when Admiral Soemu Toyoda, commander-in-chief of the Combined Fleet, was notified of American attacks on Saipan, Operation Kon was canceled and Ugaki's force was diverted to the Mariana Islands. The battleships rendezvoused with Ozawa's main force on 16 June. During the Battle of the Philippine Sea, "Nagato" escorted the aircraft carriers , and the light carrier . She fired 41 cm Type 3 "Sankaidan" incendiary anti-aircraft shrapnel shells at aircraft from the light carrier that were attacking "Jun'yō" and claimed to have shot down two Grumman TBF Avenger torpedo bombers. The ship was strafed by American aircraft during the battle, but was not damaged and suffered no casualties. During the battle "Nagato" rescued survivors from "Hiyō" that were transferred to the carrier once the ship reached Okinawa on 22 June. She continued on to Kure where she was refitted with additional radars and light AA guns. Undocked on 8 July, "Nagato" loaded a regiment of the 28th Infantry Division the following day and delivered them to Okinawa on 11 July. She arrived at Lingga via Manila on 20 July.

Kobe was promoted to Rear Admiral on 15 October. Three days later, "Nagato" sailed for Brunei Bay, Borneo, to join the main Japanese fleet in preparation for "Operation "Sho"-1", the counterattack planned against the American landings at Leyte. The Japanese plan called for Ozawa's carrier forces to lure the American carrier fleets north of Leyte so that Vice Admiral Takeo Kurita's 1st Diversion Force (also known as the Center Force) could enter Leyte Gulf and destroy American forces landing on the island. "Nagato", together with the rest of Kurita's force, departed Brunei for the Philippines on 22 October.

In the Battle of the Sibuyan Sea on 24 October, "Nagato" was attacked by multiple waves of American dive bombers and fighters. At 14:16 she was hit by two bombs dropped by planes from the fleet carrier and the light carrier . The first bomb disabled five of her casemate guns, jammed one of her Type 89 gun mounts, and damaged the air intake to No. 1 boiler room, immobilizing one propeller shaft for 24 minutes until the boiler was put back on line. Damage from the second bomb is unknown. The two bombs killed 52 men between them; the number of wounded is not known.
On the morning of 25 October, the 1st Diversion Force passed through the San Bernardino Strait and headed for Leyte Gulf to attack the American forces supporting the invasion. In the Battle off Samar, "Nagato" engaged the escort carriers and destroyers of Task Group 77.4.3, codenamed "Taffy 3". At 06:01 she opened fire on three escort carriers, the first time she had ever fired her guns at an enemy ship, but missed. At 06:54 the destroyer fired a spread of torpedoes at the fast battleship ; the torpedoes missed "Haruna" and headed for "Yamato" and "Nagato" which were on a parallel course. The two battleships were forced 10 miles (16 km) away from the engagement before the torpedoes ran out of fuel. Turning back, "Nagato" engaged the American escort carriers and their screening ships, claiming to have damaged one cruiser with forty-five 410 mm and ninety-two 14 cm shells. The ineffectiveness of her shooting was the result of the poor visibility caused by numerous rain squalls and by smoke screens laid by the defending escorts. At 09:10 Kurita ordered his ships to break off the engagement and head north. At 10:20 he ordered the fleet south once more, but as they came under increasingly severe air attack he ordered a retreat again at 12:36. At 12:43 "Nagato" was hit in the bow by two bombs, but the damage was not severe. Four gunners were washed overboard at 16:56 as the ship made a sharp turn to avoid dive-bomber attacks; a destroyer was detached to rescue them, but they could not be found. As it retreated back to Brunei on 26 October, the Japanese fleet came under repeated air attacks. "Nagato" and "Yamato" used "Sankaidan" shells against them and claimed to have shot down several bombers. Over the course of the last two days she fired ninety-nine 410 mm and six hundred fifty-three 14 cm shells, suffering 38 crewmen killed and 105 wounded during the same time.

On 15 November the ship was assigned to Battleship Division 3 of the 2nd Fleet. After an aerial attack at Brunei on 16 November, "Nagato", "Yamato", and the fast battleship left the following day, bound for Kure. En route, "Kongō" and one of the escorting destroyers was sunk by on 21 November. On 25 November, she arrived at Yokosuka, Japan, for repairs. Lack of fuel and materials meant that she could not be brought back into service and she was turned into a floating anti-aircraft battery. Her funnel and mainmast were removed to improve the arcs of fire of her AA guns, which were increased by two Type 89 mounts and nine triple Type 96 gun mounts. Her forward secondary guns were removed in compensation. Captain Kiyomi Shibuya relieved Kobe in command of "Nagato" on 25 November. Battleship Division 3 was disbanded on 1 January 1945 and the ship was reassigned to Battleship Division 1. That formation was disbanded on 10 February and she was assigned to the Yokosuka Naval District as a coastal defense ship. Moored alongside a pier, a coal-burning donkey boiler was installed on the pier for heating and cooking purposes and a converted submarine chaser was positioned alongside to provide steam and electricity; her anti-aircraft guns lacked full power and were only partially operational. On 20 April, "Nagato" was reduced to reserve and retired Rear Admiral Miki Otsuka assumed command a week later.

In June 1945, all of her secondary guns and about half of her anti-aircraft armament was moved ashore, together with her rangefinders and searchlights. Her crew was accordingly reduced to less than 1,000 officers and enlisted men. On 18 July 1945, the heavily camouflaged ship was attacked by fighter bombers and torpedo bombers from five American carriers as part of Admiral William Halsey, Jr.'s campaign to destroy the IJN's last surviving capital ships. "Nagato" was hit by two bombs, the first bomb struck the bridge and killed Otsuka, the executive officer, and twelve sailors when it detonated upon hitting the roof of the conning tower. The second 500-pound bomb struck the deck aft of the mainmast and detonated when it hit No. 3 barbette. It failed to damage the barbette or the turret above it, but blew a hole nearly in diameter in the deck above the officer's lounge, killing 21 men and damaging four Type 96 guns on the deck above. A dud rocket of uncertain size hit the ship's fantail, but failed to do any significant damage. To convince the Americans that "Nagato" had been badly damaged by the attack, her damage was left unrepaired and some of her ballast tanks were pumped full of seawater to make her sit deeper in the water as if she had sunk to the harbor bottom.
Captain Shuichi Sugino was appointed as "Nagato"s new captain on 24 July, but he was unable to take up his appointment until 20 August. Retired Rear Admiral Masamichi Ikeguchi was assigned as the ship's interim captain until Sugino arrived. The Yokosuka Naval District received an alarm on the night of 1/2 August that a large convoy was approaching Sagami Bay and "Nagato" was ordered to attack immediately. The ship was totally unprepared for any attack, but Ikeguchi began the necessary preparations. The water in the ballast compartments was pumped out and her crew began reloading the propellant charges for her 16-inch guns. The ship received more fuel from a barge later that morning, but no order to attack ever came as it had been a false alarm. Sailors from the battleship , Underwater Demolition Team 18, and the high-speed transport secured the battleship on 30 August after the occupation began and Captain Cornelius Flynn, executive officer of the "Iowa", assumed command. By the time the war ended, "Nagato" was the only Japanese battleship still afloat. She was stricken from the Navy List on 15 September.

The ship was selected to participate as a target ship in Operation Crossroads, a series of nuclear weapon tests held at Bikini Atoll in mid-1946. In mid-March, "Nagato" departed Yokosuka for Eniwetok under the command of Captain W. J. Whipple with an American crew of about 180 men supplementing her Japanese crew. The ship was only capable of a speed of from her two operating propeller shafts. Her hull had not been repaired from the underwater damage sustained during the attack on 18 July and she leaked enough that her pumps could not keep up. Her consort, the light cruiser , broke down on 28 March and "Nagato" attempted to take her in tow, but one of her boilers malfunctioned and the ship ran out of fuel in bad weather. The ship had a list of seven degrees to port by the time tugboats from Eniwetok arrived on 30 March. Towed at a speed of , the ship reached Eniwetok on 4 April where she received temporary repairs. On her trip to Bikini in May, "Nagato" reached .
Operation Crossroads began with the first blast (Test Able), an air burst on 1 July; she was from ground zero and was only lightly damaged. A skeleton crew boarded "Nagato" to assess the damage and prepare her for the next test on 25 July. As a test, they operated one of her boilers for 36 hours without any problems. For Test Baker, an underwater explosion, the ship was positioned from ground zero. "Nagato" rode out the tsunami from the explosion with little apparent damage; she had a slight starboard list of two degrees after the tsunami dissipated. A more thorough assessment could not be made because she was dangerously radioactive. Her list gradually increased over the next five days and she capsized and sank during the night of 29/30 July.

The wreck is upside down and her most prominent features are her four propellers, at a depth of below the surface. She has become a scuba diving destination in recent years and "The Times" named "Nagato" as one of the top ten wreck diving sites in the world in 2007.




</doc>
<doc id="977032" url="https://en.wikipedia.org/wiki?curid=977032" title="Japanese battleship Mutsu">
Japanese battleship Mutsu

Mutsu was the second and last dreadnought battleship built for the Imperial Japanese Navy (IJN) at the end of World War I. It was named after the province, In 1923 she carried supplies for the survivors of the Great Kantō earthquake. The ship was modernized in 1934–1936 with improvements to her armour and machinery, and a rebuilt superstructure in the pagoda mast style.

Other than participating in the Battle of Midway and the Battle of the Eastern Solomons in 1942, where she did not see any significant combat, "Mutsu" spent most of the first year of the Pacific War in training. She returned to Japan in early 1943. That June, one of her aft magazines detonated while she was at anchor, sinking the ship with the loss of 1,121 crew and visitors. The IJN investigation into the cause of her loss concluded that it was the work of a disgruntled crew member. The navy dispersed the survivors in an attempt to conceal the sinking in the interest of morale in Japan. Much of the wreck was scrapped after the war, but some artefacts and relics are on display in Japan, and a small portion of the ship remains where it was sunk. 

"Mutsu" had a length of between perpendiculars and overall. She had a beam of and a draught of . The ship displaced at standard load and at full load. Her crew consisted of 1,333 officers and enlisted men as built and 1,368 in 1935. The crew totalled around 1,475 men in 1942.

In 1927, "Mutsu"s bow was remodelled to reduce the amount of spray produced when steaming into a head sea. This increased her overall length by to . During her 1934–1936 reconstruction, the ship's stern was lengthened by to improve her speed, and her forward superstructure was rebuilt into a pagoda mast. She was given torpedo bulges to improve her underwater protection and to compensate for the weight of the additional armour and equipment. These changes increased her overall length to , her beam to and her draught to . Her displacement increased over to at deep load.

"Mutsu" was equipped with four Gihon geared steam turbines, each of which drove one propeller shaft. The turbines were designed to produce a total of , using steam provided by 21 Kampon water-tube boilers; 15 of these were oil-fired, and the remaining half-dozen consumed a mixture of coal and oil. The ship had a stowage capacity of of coal and of fuel oil, giving her a range of at a speed of . The ship exceeded her designed speed of during her sea trials, reaching at .

During a refit in 1924 the fore funnel was rebuilt in a serpentine shape in an unsuccessful effort to prevent smoke interference with the bridge and fire-control systems. That funnel was eliminated during the ship's 1930s reconstruction when all of her existing boilers were replaced by ten lighter and more powerful oil-fired Kampon boilers, which had working pressures of and temperatures of . In addition her turbines were replaced by lighter, more modern, units. When "Mutsu" conducted her post-reconstruction trials, she reached a speed of with . Additional fuel oil was stored in the bottoms of the newly added torpedo bulges, which increased her capacity to and thus her range to at 16 knots.

"Mutsu"s eight 45-calibre 41-centimetre guns were mounted in two pairs of twin-gun, superfiring turrets fore and aft. Numbered one to four from front to rear, the hydraulically powered turrets gave the guns an elevation range of −2 to +35 degrees. The rate of fire for the guns was around two rounds per minute. A special Type 3 "Sankaidan" incendiary shrapnel shell was developed in the 1930s for anti-aircraft use. The turrets aboard the "Nagato"-class ships were replaced in the mid-1930s using those stored from the unfinished s. While in storage the turrets were modified to increase their range of elevation to −3 degrees to +43 degrees, which increased the guns' maximum range from .

The ship's secondary armament of twenty 50-calibre 14-centimetre guns was mounted in casemates on the upper sides of the hull and in the superstructure. The manually operated guns had a maximum range of and fired at a rate of six to ten rounds per minute. Anti-aircraft defence was provided by four 40-calibre 8-centimetre 3rd Year Type AA guns in single mounts. These guns had a maximum elevation of +75 degrees, and a rate of fire of 13 to 20 rounds per minute. The ship was also fitted with eight torpedo tubes, four on each broadside, two above water and two submerged.
Around 1926, the four above-water torpedo tubes were removed and the ship received three additional 76 mm AA guns that were situated around the base of the foremast. The 76 mm AA guns were replaced by eight 40-calibre 127-millimeter dual-purpose guns in 1932, fitted on both sides of the fore and aft superstructures in four twin-gun mounts. When firing at surface targets, the guns had a range of ; they had a maximum ceiling of at their maximum elevation of +90 degrees. Their maximum rate of fire was 14 rounds a minute, but their sustained rate of fire was around eight rounds per minute. Two twin-gun mounts for licence-built Vickers two-pounder light AA guns were also added to the ship in 1932. These guns had a maximum elevation of +80 degrees, which gave them a ceiling of . They had a maximum rate of fire of 200 rounds per minute.

The two-pounders were replaced by 1941 by 20 licence-built Hotchkiss 25 mm Type 96 light AA guns in five twin-gun mounts. This was the standard Japanese light AA gun during World War II, but it suffered from severe design shortcomings that rendered it a largely ineffective weapon. According to historian Mark Stille, the twin and triple mounts "lacked sufficient speed in train or elevation; the gun sights were unable to handle fast targets; the gun exhibited excessive vibration; the magazine was too small, and, finally, the gun produced excessive muzzle blast". These guns had an effective range of , and an effective ceiling of at an elevation of 85 degrees. The maximum effective rate of fire was only between 110 and 120 rounds per minute because of the frequent need to change the 15-round magazines.

The ship's waterline armour belt was thick and tapered to a thickness of at its bottom edge; above it was a strake of armour. The main deck armour was while the lower deck was thick. The turrets were protected with an armour thickness of 305 mm on the face, on the sides, and on the roof. The barbettes of the turrets were protected by armour 305 mm thick, and the casemates of the 140 mm guns were protected by 25 mm armour plates. The sides of the conning tower were thick.

The new 41 cm turrets installed during "Mutsu"s reconstruction were more heavily armoured than the original ones. Face armour was increased to , the sides to , and the roof to . The armour over the machinery and magazines was increased by 38 mm on the upper deck and 25 mm on the upper armoured deck. These additions increased the weight of the ship's armour to , 32.6 percent of her displacement. In early 1941, in preparation for war, "Mutsu"s barbette armour was reinforced with armour plates above the main deck and plates below it.

"Mutsu" had an additional boom added to the mainmast in 1926 to handle the Yokosuka E1Y floatplane recently assigned to the ship. In 1933 a catapult was fitted between the mainmast and Turret No. 3, and a collapsible crane was installed in a port-side sponson the following year; the ship was equipped to operate two or three seaplanes, although no hangar was provided. The ship was operating Nakajima E4N2 biplanes until they were replaced by Nakajima E8N2 biplanes in 1938. A more powerful catapult was installed in November 1938 to handle heavier aircraft like the single Kawanishi E7K, added in 1939–40. Mitsubishi F1M biplanes replaced the E8Ns on 11 February 1943.

The ship was fitted with a rangefinder in the forward superstructure. Additional and anti-aircraft rangefinders were also fitted, although the date is unknown. The rangefinders in No. 2 and 3 turrets were replaced by 10-metre units in 1932–33.

"Mutsu" was initially fitted with a Type 13 fire-control system derived from Vickers equipment received during World War I, but this was replaced by an improved Type 14 system around 1925. It controlled the main and secondary guns; no provision was made for anti-aircraft fire until the Type 31 fire-control director was introduced in 1932. A modified Type 14 fire-control system was tested aboard her sister ship in 1935 and later approved for service as the Type 94. A new anti-aircraft director, also called the Type 94, used to control the 127 mm AA guns, was introduced in 1937, although when "Mutsu" received hers is unknown. The 25 mm AA guns were controlled by a Type 95 director that was also introduced in 1937.

"Mutsu", named for Mutsu Province, was laid down at the Yokosuka Naval Arsenal on 1 June 1918 and launched on 31 May 1920. Funding for the ship had partly come from donations from schoolchildren. While "Mutsu" was still fitting out, the American government called a conference in Washington, D.C. late in 1921 to forestall the expensive naval arms race that was developing between the United States, the United Kingdom and the Empire of Japan. The Washington Naval Conference convened on 12 November and the Americans proposed to scrap virtually every capital ship under construction or being fitted out by the participating nations. "Mutsu" was specifically listed among those to be scrapped even though she had been commissioned a few weeks earlier. This was unacceptable to the Japanese delegates; they agreed to a compromise that allowed them to keep "Mutsu" in exchange for scrapping the obsolete dreadnought , with a similar arrangement for several American dreadnoughts that were fitting out. "Mutsu" was commissioned on 24 October 1921 with Captain Shizen Komaki in command. Captain Seiichi Kurose assumed command on 18 November and the ship was assigned to the 1st Battleship Division on 1 December. "Mutsu" hosted Edward, Prince of Wales, and his aide-de-camp and second cousin, Lieutenant Louis Mountbatten, on 12 April 1922 during the prince's visit to Japan.

On 4 September 1923, "Mutsu" loaded supplies at Uchinoura Bay, Kyushu, for the victims of the Great Kantō earthquake. With her sister "Nagato", she sank the hulk of the obsolete battleship on 7 September 1924 during gunnery practice in Tokyo Bay, in accordance with the Washington Naval Treaty. Captain Mitsumasa Yonai, later Prime Minister of Japan, assumed command on 10 November. The ship was transferred to the reserve on 1 December 1925. "Mutsu" served as flagship of Emperor Hirohito during the 1927 naval manoeuvres and fleet review. Captain Zengo Yoshida relieved Captain Teikichi Hori on 10 December 1928. On 29 March 1929, the ship was assigned to Battleship Division 3, together with three light cruisers.

"Mutsu"s anti-aircraft armament was upgraded during 1932. Upon completion, she was assigned to Battleship Division 1 of the 1st Fleet, and again served as the Emperor's flagship during the annual maneuvers and fleet review in 1933. The ship was placed in reserve on 15 November and began her lengthy reconstruction. This was completed on 30 September 1936 and "Mutsu" rejoined the 1st Battleship Division on 1 December 1936. In August 1937, she transported 2,000 men of the 11th Infantry Division to Shanghai during the Second Sino-Japanese War. Her seaplanes bombed targets in Shanghai on 24 August before she returned to Sasebo the following day. On 15 November 1938, Captain Aritomo Gotō assumed command of the ship. "Mutsu" was placed in reserve from 15 December 1938 to 15 November 1939. She was refitted in early 1941 in preparation for war; as part of this work, she was fitted with external degaussing coils and additional armour for her barbettes.

During the war "Mutsu" saw limited action, spending much of her time in home waters. On 8 December 1941, she sortied for the Bonin Islands, along with "Nagato", the battleships , , , of Battleship Division 2, and the light carrier as distant support for the fleet attacking Pearl Harbor, and returned six days later. On 18 January 1942, "Mutsu" towed the obsolete armoured cruiser as a target for the new battleship , which promptly sank "Nisshin".

In June 1942 "Mutsu", commanded by Rear Admiral Gunji Kogure, was assigned to the Main Body of the 1st Fleet during the Battle of Midway, together with "Yamato", "Nagato", "Hōshō", the light cruiser "Sendai", nine destroyers and four auxiliary ships. Following the loss of all four carriers on 4 June, Yamamoto attempted to lure the American forces west to within range of the Japanese air groups at Wake Island, and into a night engagement with his surface forces, but the American forces withdrew and "Mutsu" saw no action. After rendezvousing with the remnants of the striking force on 6 June, about half of the survivors from the sunken aircraft carriers of the 1st Air Fleet were transferred to "Mutsu". She arrived at Hashirajima on 14 June.

On 14 July, "Mutsu" was transferred to Battleship Division 2 and then to the advance force of the 2nd Fleet on 9 August. Two days later, the ship departed Yokosuka accompanied by the cruisers , , , , , , the seaplane tender and escorting destroyers to support operations during the Guadalcanal Campaign. They arrived at Truk on 17 August. On 20 August, while sailing from Truk to rendezvous with the main body of Vice Admiral Chūichi Nagumo's 3rd Fleet, "Mutsu", the heavy cruiser "Atago", and escorting destroyers unsuccessfully attempted to locate the escort carrier in response to a flying boat detecting the American ship.

During the Battle of the Eastern Solomons on 27 August, "Mutsu", assigned to the support force, fired four shells at enemy reconnaissance aircraft during what was her first and only time her guns were fired in anger during the war. Following her return to Truk on 2 September, a group of skilled AA gunnery officers and men were detached to serve as instructors to ground-based naval anti-aircraft gunners stationed in Rabaul. During October "Mutsu" off-loaded surplus fuel oil to the fleet oil tanker "Kenyo Maru", allowing the tanker to refuel other ships involved in Guadalcanal operations. On 7 January 1943, "Mutsu" steamed from Truk via Saipan to return to Japan together with the carrier , the heavy cruiser and four destroyers. "Mutsu" left Hashirajima for Kure on 13 April, where she prepared to sortie to reinforce the Japanese garrisons in the Aleutian Islands in response to the Battle of the Komandorski Islands. The operation was cancelled the next day and the ship resumed training.

On 8 June 1943, "Mutsu" was moored in the Hashirajima fleet anchorage, with 113 flying cadets and 40 instructors from the Tsuchiura Naval Air Group aboard for familiarisation. At 12:13 the magazine of her No. 3 turret exploded, destroying the adjacent structure of the ship and cutting her in half. A massive influx of water into the machinery spaces caused the forward section of the ship to capsize to starboard and sink almost immediately. The stern section upended and remained floating until about 02:00 hours on 9 June before sinking, coming to rest a few hundred feet south of the main wreck at coordinates .

The nearby "Fusō" immediately launched two boats which, together with the destroyers and and the cruisers and , rescued 353 survivors from the 1,474 crew members and visitors aboard "Mutsu"; 1,121 men were killed in the explosion. Only 13 of the visiting aviators were among the survivors.

After the explosion, as the rescue operations commenced, the fleet was alerted and the area was searched for Allied submarines, but no traces were found. To avert the potential damage to morale from the loss of a battleship so soon after the string of recent setbacks in the war effort, "Mutsu"s destruction was declared a state secret. Mass cremations of recovered bodies began almost immediately after the sinking. Captain Teruhiko Miyoshi's body was recovered by divers on 17 June, but his wife was not officially notified until 6 January 1944. Both he and his second in command, Captain Ono Koro, were posthumously promoted to rear admiral, as was normal practice. To further prevent rumours from spreading, healthy and recovered survivors were reassigned to various garrisons in the Pacific Ocean. Some of the survivors were sent to Truk in the Caroline Islands and assigned to the 41st Guard Force. Another 150 were sent to Saipan in the Mariana Islands, where most were killed in 1944 during the battle for the island.

At the time of the explosion, "Mutsu"s magazine contained some 16-inch Type 3 "Sanshikidan" incendiary shrapnel shells, which had caused a fire at the Sagami arsenal several years earlier due to improper storage. Because they might have been the cause of the explosion, the minister of the navy, Admiral Shimada Shigetaro, immediately ordered the removal of Type 3 shells from all IJN ships carrying them, until the conclusion of the investigation into the loss.

A commission led by Admiral Kōichi Shiozawa was convened three days after the sinking to investigate the loss. The commission considered several possible causes:


The commission issued its preliminary conclusions on 25 June, well before the divers had completed their investigation of the wreck, and concluded that the explosion was the result of a disgruntled seaman. Historian Mike Williams put forward an alternative theory of fire:

A number of observers noted smoke coming from the vicinity of No. 3 turret and the aircraft area just forward of it, just before the explosion. Compared with other nations' warships in wartime service, Japanese battleships contained a large amount of flammable materials including wooden decking, furniture, and insulation, as well as cotton and wool bedding. Although she had been modernized in the 1930s, some of the "Mutsu"s original electrical wiring may have remained in use. While fire in the secure magazines was a very remote possibility, a fire in an area adjacent to the No. 3 magazine could have raised the temperature to a level sufficient to ignite the highly sensitive black-powder primers stored in the magazine and thus cause the explosion.

Divers were brought into the area to retrieve bodies and to assess the damage to the ship. Prior to diving on the wreck they were allowed to familiarize themselves on board "Mutsu"s sister ship, "Nagato". The Navy leadership initially gave serious consideration to raising the wreck and rebuilding her, although these plans were dropped after the divers completed their survey of the ship on 22 July. Thus "Mutsu" was struck from the Navy List on 1 September. As part of the investigation, Dive-boat No. 3746, a small "Nishimura"-class search and rescue submarine, explored the wreck on 17 June with a crew of seven officers. While crawling on the harbour bottom, it became snagged on the wreckage and its crew nearly suffocated before they could free themselves and surface. In July 1944, the oil-starved IJN recovered of fuel from the wreck.

The diameter chrysanthemum crest, symbol of the Imperial Throne, was raised in 1953 but lost or scrapped shortly thereafter. One of the 140 mm casemate guns was raised in 1963 and donated to the Yasukuni Shrine. In 1970, the Fukada Salvage Company began salvage operations that lasted until 1978 and scrapped about 75% of the ship. The two aft turrets were raised in 1970 and 1971. Despite the fact that the salvaged components were remarkably preserved, in particular the two gun turrets, bow (including chrysanthemum mount) and stern (with every propeller, and intact rudders and steering gear), the entirety of the ship was broken up to farm low-radiation steel and sold to an anonymous "research institute." The salvagers retrieved 849 bodies of crewmen lost during the explosion. In 1995, the Mutsu Memorial Museum declared that no further salvage operations were planned.

The only significant portion of the ship that remains is a long section running from the bridge structure forward to the vicinity of No. 1 turret. The highest portion of the ship is below the surface.

In addition to the 140 mm gun donated to the Yasukuni Shrine, now on display at the Yasukuni Museum, the following items recovered over the years can be viewed at various museums and memorials in Japan:





</doc>
<doc id="977878" url="https://en.wikipedia.org/wiki?curid=977878" title="Sandringham House">
Sandringham House

Sandringham House is a country house in the parish of Sandringham, Norfolk, England. It is the private home of Elizabeth II, whose father, George VI, and grandfather, George V, both died there. The house stands in a estate in the Norfolk Coast Area of Outstanding Natural Beauty. The house is listed as Grade II* along with its landscaped gardens, park, and woodlands.

The site has been occupied since Elizabethan times, when a large manor was constructed. This was replaced in 1771 by a Georgian mansion for the owners, the Hoste Henleys. In 1836, Sandringham was bought by John Motteux, a London merchant, who already owned property in Norfolk and Surrey. Motteux had no direct heir, and on his death in 1843, his entire estate was left to Charles Spencer Cowper, the son of Motteux's close friend Emily Temple, Viscountess Palmerston. Cowper sold the Norfolk and the Surrey estates and embarked on rebuilding at Sandringham. He led an extravagant life, and by the early 1860s, the estate was mortgaged and he and his wife spent most of their time on the Continent.

In 1862, Sandringham and just under 8,000 acres of land were purchased for Albert Edward, Prince of Wales, later Edward VII, as a country home for him and his fiancée, Princess Alexandra of Denmark. Between 1870 and 1900, the house was almost completely rebuilt in a style described by Pevsner as "frenetic Jacobean". Edward also developed the estate, creating one of the finest shoots in England. Following his death in 1910, the estate passed to Edward's son and heir, George V, who described the house as "dear old Sandringham, the place I love better than anywhere else in the world". It was the setting for the first Christmas broadcast in 1932. George died at the house on 20 January 1936. The estate passed to his son Edward VIII; and at the abdication, as the private property of the monarch, it was purchased by Edward's brother, George VI. George was as devoted to the house as his father, writing to his mother Queen Mary, "I have always been so happy here and I love the place". He died at Sandringham on 6 February 1952.

On the King's death, Sandringham passed to his daughter Elizabeth II. The Queen spends most of the winter at the house, including the anniversary of her father's death and of her own accession. In 1957 she broadcast her first televised Christmas message from Sandringham. In the 1960s, plans were drawn up to demolish the house and replace it with a modern building, but these were not carried out. In 1977, for her Silver Jubilee, the Queen opened the house and grounds to the public for the first time. Unlike the royal palaces, such as Buckingham Palace and Windsor Castle, Sandringham and Balmoral Castle are the Queen's private homes.

Sandringham is recorded in the Domesday Book as "sant-Dersingham" and the land was awarded to a Norman knight, Robert Fitz-Corbun after the Conquest. The local antiquarian Claude Messent, in his study "The Architecture on the Royal Estate of Sandringham", records the discovery of evidence of the pavements of a Roman villa. In the Elizabethan era a manor was built on the site of the present house, which, by the 18th century, came into the possession of the Hoste Henley family, descendants of Dutch refugees. In 1771 Cornish Henley cleared the site to build a Georgian mansion, Sandringham Hall. In 1834, Henry Hoste Henley died without issue, and the estate was bought at auction by John Motteux, a London merchant. Motteux was also without heirs and bequeathed Sandringham, together with another Norfolk estate and a property in Surrey, to the third son of his close friend, Emily Lamb, the wife of Lord Palmerston. At the time of his inheritance in 1843, Charles Spencer Cowper was a bachelor diplomat, resident in Paris. On succeeding to Motteux's estates, he sold the other properties and based himself at Sandringham. He undertook extensions to the hall, employing Samuel Sanders Teulon to add an elaborate porch and conservatory. Cowper's style of living was extravagant—he and his wife spent much of their time on the Continent—and within 10 years the estate was mortgaged for £89,000. The death of their only child, Mary Harriette, from cholera in 1854 led the couple to spend even more time abroad, mainly in Paris, and by the early 1860s Cowper was keen to sell the estate.

In 1861 Queen Victoria's eldest son and heir, Albert Edward, was approaching his twenty-first birthday. Edward's dissipated lifestyle had been disappointing to his parents, and his father, Prince Albert, thought that marriage and the purchase of a suitable establishment were necessary to ground the Prince in country life and pursuits and lessen the influence of the "Marlborough House set" with which he was involved. Albert had his staff investigate eighteen possible country estates that might be suitable, including Newstead Abbey in Nottinghamshire and Houghton Hall in Norfolk. The need to act quickly was reinforced by the Nellie Clifden affair, when Edward's fellow officers smuggled the actress into his quarters. The possibility of a scandal was deeply concerning to his parents. Sandringham Hall was on the list of the estates considered, and a personal recommendation to the Prince Consort from the Prime Minister Lord Palmerston, stepfather to the owner, swayed Prince Albert. Negotiations were only slightly delayed by Albert's death in December 1861—his widow declared, "His wishes – his plans – about everything are to be my law". The Prince visited in February 1862, and a sale was agreed for the house and just under 8,000 acres of land, which was finalised that October. Queen Victoria only twice visited the house she had paid for. Over the course of the next forty years, and with considerable expenditure, Edward was to create a house and country estate that his friend Charles Carington called "the most comfortable in England".

The price paid for Sandringham, £220,000, has been described as "exorbitant". This is questioned by Helen Walch, author of the estate's recent (2012) history, who shows the detailed analysis undertaken by the Prince Consort's advisers and suggests that the cost was reasonable. The house was soon found to be too small to accommodate the Prince of Wales's establishment following his marriage in March 1863 and the many guests he was required, and desired, to entertain. In 1865, two years after moving in, the Prince commissioned A. J. Humbert to raze the original hall and create a much larger building. Humbert was an architect favoured by the royal family—"for no good reason", according to the architectural historian Mark Girouard—and had previously undertaken work for Queen Victoria at Osborne House and at Frogmore House. The new red-brick house was complete by late 1870; the only element of the original house of the Henley Hostes and the Cowpers that was retained was the elaborate conservatory designed by Teulon in the 1830s. Edward had this room converted into a billiard room. A plaque in the entrance hall records that "This house was built by Albert Edward Prince of Wales and Alexandra his wife in the year of our Lord 1870". The building was entered through a large porte-cochère straight into the main living room (the saloon), an arrangement that was subsequently found to be inconvenient. The house provided living and sleeping accommodation over three storeys, with attics and a basement. The Norfolk countryside surrounding the house appealed to Alexandra, as it reminded her of her native Denmark.
Within a decade, the house was again found to be too small, and in 1883 a new extension, the Bachelors' Wing, was constructed to the designs of a Norfolk architect, Colonel R. W. Edis. Edis also built a new billiard room and converted the old conservatory into a bowling alley. The Prince of Wales had been impressed by one he had seen at Trentham Hall, and the alley at Sandringham was modelled on an example from Rumpelheim, Germany. In 1891, during preparations for the Prince of Wales's fiftieth birthday, a serious fire broke out when maids lit all the fires in the second-floor bedrooms to warm them in advance of the Prince's arrival. Edis was recalled to undertake rebuilding and further construction. As he had with the Bachelors' Wing, Edis tried to harmonise these additions with Humbert's house by following the original Jacobethan style, and by using matching brickwork and Ketton stone.

The house was up to date in its facilities, the modern kitchens and lighting running on gas from the estate's own plant and water being supplied from the Appleton Water Tower, constructed at the highest point on the estate. The tower was designed in an Italianate style by Robert Rawlinson, and Alexandra laid the foundation stone in 1877. The Prince's efforts as a country gentleman were approved by the press of the day; a contemporary newspaper expressed a wish to ""Sandringhamize" Marlborough House – as a landlord, agriculturist and country gentleman, the Prince sets an example which might be followed with advantage".

The royal couple's developments at Sandringham were not confined to the house; over the course of their occupation, the wider estate was also transformed. Ornamental and kitchen gardens were established, employing over 100 gardeners at their peak. Many estate buildings were constructed, including cottages for staff, kennels, a school, a rectory and a staff clubhouse, the Babingley. Edward also made Sandringham one of the best sporting estates in England to provide a setting for the elaborate weekend shooting parties that became Sandringham's defining rationale. To increase the amount of daylight available during the shooting season, which ran from October to February, the Prince introduced the tradition of Sandringham Time, whereby all the clocks on the estate were set half an hour ahead of GMT. This tradition was maintained until 1936. Edward's entertaining was legendary, and the scale of the slaughter of game birds, predominantly pheasants and partridges, was colossal. The meticulously maintained game books recorded annual bags of between 6,000 and 8,000 birds in the 1870s, rising to bags of over 20,000 a year by 1900. The game larder, constructed for the storage of the carcasses, was inspired by that at Holkham Hall and was the largest in Europe.

Guests for Sandringham house parties generally arrived at Wolferton railway station, 2.5 miles from the house, travelling in royal trains that ran from St Pancras Station to King's Lynn and then on to Wolferton. The station served the house from 1862 until its closure in 1969. Thereafter, the Queen travelled by car from King's Lynn. Edward VII established the Sandringham stud in 1897, achieving considerable success with the racehorses Persimmon and Diamond Jubilee. Neither his son nor his grandsons evinced as much interest in horses, although the stud was maintained; but his great-granddaughter, Elizabeth II, has sought to match Edward's equestrian achievements and has bred several winners at the Sandringham Stud.

On 14 January 1892, Edward's eldest son and heir, Prince Albert Victor, Duke of Clarence and Avondale, died of pneumonia at the house. He is commemorated in the clock tower, which bears an inscription in Latin that translates as "the hours perish and will be charged to our account". Edward fell ill at Sandringham in early 1910 and died at Buckingham Palace on 6 May.

In his will Edward VII left his widow £200,000 and a lifetime interest in the Sandringham estate. Queen Alexandra's continued occupancy of the "big house" compelled George V, his wife, Queen Mary, and their expanding family to remain at York Cottage in the grounds, in rather "cramped" conditions. Suggestions from courtiers that Queen Alexandra might move out were firmly rebuffed by the King; "It is my mother's house, my father built it for her". The King also lacked the sociability of his father, and the shortage of space at York Cottage enabled him to limit the entertaining he undertook, with the small rooms reportedly reminding him of the onboard cabins of his naval career.
The new King's primary interests, aside from his constitutional duties, were shooting and stamp collecting. He was considered one of the best shots in England, and his collections of shotguns and stamps were among the finest in the world. Deeply conservative by nature, George sought to maintain the traditions of Sandringham estate life established by his father, and life at York Cottage provided respite from the constitutional and political struggles that overshadowed the early years of George's reign. Even greater upheaval was occasioned by the outbreak of the First World War, a dynastic struggle that involved many of his relatives, including the German Kaiser and the Russian Emperor, both of whom had previously been guests at Sandringham. The estate and village of Sandringham suffered a major loss when all but two members of the King's Own Sandringham Company, a territorial unit of the Fifth Battalion of the Royal Norfolk Regiment, were killed at Sulva Bay during the Gallipoli Campaign. The story of the battalion was the subject of a BBC drama, "All the King's Men". A memorial to the dead was raised on the estate; the names of those killed in the Second World War were added subsequently.

Following Queen Alexandra's death at Sandringham on 20 November 1925, the King and his family moved to the main house. In 1932, George V gave the first of the royal Christmas messages from a studio erected at Sandringham. The speech, written by Rudyard Kipling, began, "I speak now from my home and from my heart to you all". George V died in his bedroom at Sandringham at 11.55 p.m. on 20 January 1936, his death hastened by injections of morphine and cocaine, to maintain the King's dignity and to enable the announcement of his death to be made in the following day's "Times". The King's body was moved to St Mary Magdalene's Church, a scene described by the late King's assistant private secretary, "Tommy" Lascelles. "Next evening we took him over to the little church at the end of the garden. We saw the lych-gate brilliantly lit (and) the guardsmen slung the coffin on their shoulders and laid it before the altar. After a brief service, we left it, to be watched over by the men of the Sandringham Estate." Two days later, George's body was transported by train from Wolferton to London, and to its lying in state at Westminster Hall.

On the night of his father's death, Edward VIII summarily ordered that the clocks at Sandringham be returned to Greenwich Mean Time, ending the tradition of Sandringham Time begun by his grandfather over 50 years earlier. Edward had rarely enjoyed his visits to Sandringham, either in his father's time or that of his grandfather. He described a typical dinner at the house in a letter to his then mistress Freda Dudley Ward, dated 26 December 1919; "it's too dull and boring for words. Christ how any human beings can ever have got themselves into this pompous secluded and monotonous groove I just can't imagine". In another letter, evenings at the "big house" – Edward stayed at York Cottage with his father – were recorded as "sordidly dull and boring". His antipathy to the house was unlikely to have been lessened by his late father's will, which was read to the family in the saloon at the house. His brothers were each left £750,000 while Edward was bequeathed no monetary assets beyond the revenues from the Duchy of Cornwall. A codicil also prevented him from selling the late King's personal possessions; Lascelles described the inheritance as "the Kingship without the cash".

Edward's concerns regarding his income led him immediately to focus on the expense associated with running his late father's private homes. Sandringham he described as a "voracious white elephant", and he asked his brother George to undertake a review of the management of the estate, which had been costing his father £50,000 annually in subsidies at the time of his death. The review recommended significant retrenchments, and its partial implementation caused considerable resentment among the dismissed staff. Edward spent a single night of his reign at the house, bringing Wallis Simpson for a shooting party in October 1936. The party was interrupted by a request to meet with prime minister Stanley Baldwin, and having arrived on a Sunday, the King returned to Fort Belvedere the next day. He never returned to Sandringham; and, his attention diverted by the impending crisis arising from his attachment to Simpson, within two months of his only visit to the house as King, he had abdicated. On his abdication, as Sandringham and Balmoral Castle were the private property of the monarch, it was necessary for King George VI to purchase both properties. The price paid, £300,000, was a cause of friction between the new King and his brother.

George VI had been born at Sandringham on 14 December 1895. A keen follower of country pursuits, he was as devoted to the estate as his father, writing to his mother, Queen Mary, "I have always been so happy here". The deep retrenchment planned by his brother was not enacted, but economies were still made. His mother was at church at Sandringham on Sunday 3 September 1939, when the outbreak of the Second World War was declared. The house was shut up during the war, but occasional visits were made to the estate, with the family staying at outlying cottages. After the war the King made improvements to the gardens surrounding the house; but, as traditionalist as his father, he made few other changes. December 1945 saw the first celebration of Christmas at the house since 1938. Lady Airlie recorded her impressions at dinner: "I sat next to the King. His face was tired and strained and he ate practically nothing. Looking at him I felt the cold fear of the probability of another short reign".

George was a heavy smoker throughout his life and had an operation to remove part of his lung in September 1951. He was never fully well again and died at Sandringham during the early morning of 6 February 1952. He had gone out after hares on 5 February, "shooting conspicuously well", and had planned the next day's shoot before retiring at 10.30 p.m. He was discovered at 7.30 a.m. in his bedroom by his valet, having died of a coronary thrombosis at the age of 56. His body was placed in the Church of St Mary Magdalene, before being taken to Wolferton Station and transported by train to London, to lie in state at Westminster Hall.

Since King George VI's death, Queen Elizabeth II's custom has been to spend the anniversary of that and of her own accession privately with her family at Sandringham House, and, more recently, to use it as her official base from Christmas until February. In celebrating Christmas at Sandringham, the Queen follows the tradition of her last three predecessors, whereas her great-great-grandmother, Queen Victoria, held her celebrations at Windsor Castle. The taxation arrangements of the monarch meant that no inheritance tax was paid on the Sandringham or Balmoral estates when they passed to the Queen, at a time when it was having a deleterious effect on other country estates. On her accession, the Queen asked her husband, the Duke of Edinburgh, to take on the responsibility for the management of the estate. The Duke has worked to move towards self-sufficiency, generating additional income streams, taking more of the land in hand, and amalgamating many of the smaller tenant farms.

In January 1957 the Queen received the resignation of the Prime Minister Anthony Eden at the house. Eden's wife, Clarissa, recorded the event in her diary, "8 January – Anthony has to go through a Cabinet and listening to Harold prosing for half an hour. Then by train to Sandringham. Many photographers. We arrive into the hall where everyone is looking at the television." At the end of that year, the Queen made her first televised Christmas broadcast from Sandringham. In the 1960s, plans were initiated to demolish the house and replace it with a modern residence by David Roberts, an architect who worked mainly at the University of Cambridge. The plans were not taken forward, but modernisation of the interior of the house and the removal of a range of ancillary buildings were carried out by Hugh Casson, who also decorated the Royal Yacht, "Britannia". In 1977, for her silver jubilee, the Queen opened the house to the public.

Sandringham continues to operate as a sporting estate. The pheasants and partridge are no longer reared for this purpose, and Sandringham is now one of the few wild shoots in England. Along with her equestrian interest in the Sandringham Stud, where she has bred several winning horses, the Queen has developed a successful gun dog breeding programme at Sandringham. Following the tradition of a kennels at Sandringham established by her great grandfather, when Queen Alexandra kept over 100 dogs on the estate, the Queen prefers black labrador retrievers, over the yellow type favoured by her father, and the terriers bred by her earlier predecessors. Since his retirement from official duties in August 2017, the Duke of Edinburgh has spent increasing amounts of time at Wood Farm, a cottage on the Sandringham Estate used by the Duke and the Queen when not hosting guests at the main house. Sandringham is one of the two homes owned by the Queen in her private capacity, rather than as head of state, the other being Balmoral Castle.

The house is mainly constructed of red brick with limestone dressings; Norfolk Carrstone is also prevalent, particularly in Eddis's additions. The tiled roof contains nine separate clusters of chimneystacks. The style is Jacobethan, with inspiration drawn principally from nearby Blickling Hall. Construction was undertaken by Goggs Brothers of Swaffham. The principal rooms of the house are the saloon, the drawing room, the dining room and the ballroom, together with rooms devoted to sports, such as the gun room, or leisure, such as the bowling alley, now a library, and the billiard room. The walls of the corridors connecting the principal rooms display a collection of Oriental and Indian arms and armour, gathered by Edward VII on his tour of the East in 1875–1876. Decoration of the house and the provision of furniture and fittings was undertaken by Holland and Sons in the 1870 rebuilding.

The largest room in the house, the saloon is used as the main reception room. The arrangement of entry under the porte-cochère direct into the saloon proved problematic, with no ante-room in which guests could remove their hats and coats. Jenkins describes the decorative style, here and elsewhere in the house, as "Osbert Lancaster's Curzon Street Baroque". The room contains portraits of Queen Victoria and Prince Albert by their favourite artist Franz Xaver Winterhalter. The saloon functioned as a venue for dances, until the construction of the new ballroom by Edis, and has a minstrels' gallery to accommodate musicians. The room contains a weighing machine; Edward VII was in the habit of requiring his guests to be weighed on their arrival, and again on their departure, to establish that his lavish hospitality had caused them to put on weight.

The drawing room is described by Jenkins as "the nearest Sandringham gets to pomp". On one of her two visits to the house, Victoria recorded in her journal that, after dinner, the party adjourned to, "the very long and handsome drawing room with painted ceiling and two fireplaces". The room contains portraits of Queen Alexandra and her daughters, Princess Louise, Princess Victoria, and Princess Maud of Wales, by Edward Hughes. White marble statues complete what has been described as a "tour de force of fashionable late-Victorian decoration".

The ballroom was added by Edis in 1884, to overcome the inconvenience of having only the saloon as the major room for entertaining. As this was also the main family living room, it had previously been necessary to remove the furniture when the saloon was required for dances and large entertainments. Alexandra recorded her delight at the result, "Our new ballroom is beautiful I think & a great success & avoids pulling the hall to pieces each time there is a ball or anything". At the time of Queen Victoria's visit in 1889, the room was used for a theatrical performance given by Sir Henry Irving and Ellen Terry. The present Queen uses the room for entertainments and as a cinema.

The walls of the dining room are decorated with Spanish tapestries including some by Goya which were a gift from Alfonso XII of Spain. The walls are panelled in oak, painted light green for Queen Mary who had been inspired by a visit to a Scottish castle. Jill Franklin's study of the planning of Victorian country houses includes a photograph of the dining room at Sandringham with the table laid for dinner for twenty-four, a "very usual" number to seat for dinner in a major country house of the time.

Sandringham House has not been admired by critics. Its chief fault is the lack of harmony between Humbert's original building and Edis's extensions, "a contrast between the northern and southern halves of the house (that) has been much criticised ever since". The architectural historian John Martin Robinson wrote in 1982, "Sandringham, the latest in date of the houses of the British monarchy, is the least distinguished architecturally". In his biography of Queen Mary, James Pope-Hennessy compared the house unfavourably to "a golf-hotel at St Andrews or a station-hotel at Strathpeffer". Simon Jenkins considered Sandringham "unattractive", with a "grim, institutional appearance". Pevsner described the architectural style as "frenetic"; Girouard expressed himself perplexed as to the preference shown by the royal family for A. J. Humbert, a patronage the writer Adrian Tinniswood described as "the Victorian Royal Family's knack for choosing second-rate architects". An article on the house in the June 1902 edition of "Country Life" opined, "of mere splendour there is not much, but of substantial comfort a good deal". The writer Clive Aslet suggests that the sporting opportunities offered by the estate were the main attraction for its royal owners, rather than "the house itself, which even after rebuilding was never beguiling".

The fittings and furnishings were also criticised; the biographer of George V, Kenneth Rose, wrote that, "except for some tapestries given by Alfonso XII, Sandringham had not a single good picture, piece of furniture or other work of art". Neither Edward VII nor his heir, were noted for their artistic appreciation; writing of the redevelopments at Buckingham Palace undertaken by George V, and previously by Edward VII, the architectural historian John Martin Robinson wrote that, "the King had no more aesthetic sensibility than his father and expressed impatience with his wife's keen interest in furniture and decoration". In the series of articles on the house and estate published in 1902 by "Country Life" to celebrate Edward VII's accession, the author noted the royal family's "set policy of preferring those pictures that have "associations" to those which have merely artistic merit". Exceptions came to include works from the collection of mainly 20th-century English art assembled by the Queen Mother, including pieces by Edward Seago and John Piper, who produced a view of Sandringham.

Although not highly regarded as architecture, Sandringham is a rare extant example of a full-scale Victorian country house, described in the magazine "Country Life" as "lived in and beautifully maintained, complete with its original contents, gardens and dependent estate buildings". The house, the landscaped gardens, park and woodlands are listed Grade II* on the Register of Historic Parks and Gardens, Grade II* being the second-highest listing, reserved for "particularly important buildings of more than special interest".

The gardens and country park comprise of the estate with the gardens extending to . They were predominantly laid out from the 1860s, with later alterations and simplifications. Edward VII sought advice from William Broderick Thomas and Ferdinand de Rothschild, a friend and adviser to the King throughout his life. The original lake was filled and replaced with the elaborate parterres fashionable at the time. These have since been removed. Two new lakes were dug further from the house, and bordered by rockeries constructed of Pulhamite stone. A summerhouse, called "The Nest", stands above the Upper Lake, a gift in 1913 to Queen Alexandra from the comptroller of her household, General Sir Dighton Probyn. The gardens to the north of the house, which are overlooked by the suite of rooms used by George VI, were remodelled and simplified by Geoffrey Jellicoe for the King and his wife after the Second World War. A statue of Father Time, dating from the 18th century, was purchased by the Queen Mother and installed in 1951. Further areas of the gardens were remodelled by Sir Eric Savill in the 1960s for Queen Elizabeth and Prince Philip. The extensive kitchen gardens, which in Edward VII's time included carriage drives to allow guests to view the "highly ornamental" arrangements, were also laid to lawn during the present Queen's reign, having proved uneconomic to maintain.

The 20,000 acre Sandringham estate has some of the finest shoots in England, and is used for royal shooting parties. Covering seven villages, the estate's other main activities, aside from tourism, are arable crops and forestry. The grounds provided room for Queen Alexandra's menagerie of horses, dogs, cats, and other animals. In 1886 a racing pigeon loft was constructed for birds given to the Duke of York by King Leopold II of Belgium and one or more lofts for pigeons have been maintained ever since. The Norwich Gates, designed by Thomas Jeckell and made by the local firm of Barnard, Bishop and Barnard, were a wedding present for Edward and Alexandra from "the gentry of Norfolk".

In 2007 Sandringham House and its grounds were designated a protected site under Section 128 of the Serious Organised Crime and Police Act 2005. This makes it a criminal offence to trespass in the house or its grounds. The Sandringham estate has a museum in the former coach house with displays of royal life and estate history. The museum also houses an extensive collection of royal motor vehicles including a 1900 Daimler owned by Edward VII and a 1939 Merryweather & Sons fire engine, made for the Sandringham fire brigade which was founded in 1865 and operated independently on the estate until 1968. The coach house stables and garaging were designed by A. J .Humbert at the same time as his construction of the main house. The estate contains several houses with close links to the royal family.

Anmer Hall is a Georgian house on the grounds, purchased by the Prince of Wales in 1896. Formerly occupied by the Duke of Kent, it is now the country home of the Duke and Duchess of Cambridge.

When Prince Carl of Denmark (later King Haakon VII of Norway) and Princess Maud were married in July 1896, Appleton House was a wedding gift to them from the bride's parents, the Prince and Princess of Wales. Queen Maud became fond of Appleton, "our little house is a perfect paradise", and their son, the future King Olav V of Norway, was born at the house in 1903. The last inhabitants were King George VI and Queen Elizabeth who stayed there during a visit to Norfolk during World War II, when Sandringham was closed. Lascelles considered it "an ugly villa, but not uncomfortable". The house was demolished in 1984.

Constructed by Edward VII, Park House has been owned by the royal family for many years. The birthplace of Diana, Princess of Wales when the house was let to her father, it is now a hotel managed by the Leonard Cheshire charity.

Wood Farm has been part of the Sandringham Estate since the time of Edward VII. In the early 20th century, it was home to Prince John, the youngest of George V and Queen Mary's six children. Born in 1905, the Prince was epileptic, and spent much of his life in relative seclusion at Sandringham. He died at Wood Farm, his home for the last two years of his life, on 18 January 1919.

York Cottage, originally known as Bachelors' Cottage, was built by Edward, Prince of Wales, soon after he acquired Sandringham to provide further accommodation for guests. It was home to George V from 1893 until his mother's death enabled him to move into the main house in 1925. When discussing his father with Harold Nicolson, at the time Nicolson had been appointed to write the late King's biography, Edward VIII, by then Duke of Windsor, remarked "Until you have seen York Cottage you will never understand my father". The cottage was no more highly regarded architecturally than the main house; James Pope-Hennessy, the official biographer of Queen Mary, called it, "tremendously vulgar and emphatically, almost defiantly hideous". Nicolson described it as a "glum little villa (with) rooms indistinguishable from those of any Surbiton or Upper Norwood home". He was particularly dismissive of the royal bathing arrangements: "Oh my God! what a place. The King's and Queen's baths had lids that shut down so that when not in use they could be used as tables". "It is almost incredible that the heir to so vast a heritage lived in this horrible little house." Nicolson's strictures did not appear in his official biography of the King. York Cottage is currently the estate office for the Sandringham Estate.

The country park and the visitors' centre are open throughout the year. The house, gardens and museum open annually from the end of March until the end of October, except for 23–25 July.




</doc>
<doc id="979165" url="https://en.wikipedia.org/wiki?curid=979165" title="Guy Fawkes Night">
Guy Fawkes Night

Guy Fawkes Night, also known as Guy Fawkes Day, Bonfire Night and Firework Night, is an annual commemoration observed on 5 November, primarily in the United Kingdom. Its history begins with the events of 5 November 1605 O.S., when Guy Fawkes, a member of the Gunpowder Plot, was arrested while guarding explosives the plotters had placed beneath the House of Lords. Celebrating the fact that King James I had survived the attempt on his life, people lit bonfires around London; and months later, the introduction of the Observance of 5th November Act enforced an annual public day of thanksgiving for the plot's failure.

Within a few decades Gunpowder Treason Day, as it was known, became the predominant English state commemoration, but as it carried strong Protestant religious overtones it also became a focus for anti-Catholic sentiment. Puritans delivered sermons regarding the perceived dangers of popery, while during increasingly raucous celebrations common folk burnt effigies of popular hate-figures, such as the pope. Towards the end of the 18th century reports appear of children begging for money with effigies of Guy Fawkes and 5 November gradually became known as Guy Fawkes Day. Towns such as Lewes and Guildford were in the 19th century scenes of increasingly violent class-based confrontations, fostering traditions those towns celebrate still, albeit peaceably. In the 1850s changing attitudes resulted in the toning down of much of the day's anti-Catholic rhetoric, and the Observance of 5th November Act was repealed in 1859. Eventually the violence was dealt with, and by the 20th century Guy Fawkes Day had become an enjoyable social commemoration, although lacking much of its original focus. The present-day Guy Fawkes Night is usually celebrated at large organised events, centred on a bonfire and extravagant firework displays.

Settlers exported Guy Fawkes Night to overseas colonies, including some in North America, where it was known as Pope Day. Those festivities died out with the onset of the American Revolution. Claims that Guy Fawkes Night was a Protestant replacement for older customs like Samhain are disputed, although another old celebration, Halloween, has lately increased in popularity in England, and according to some writers, may threaten the continued observance of 5 November.

Guy Fawkes Night originates from the Gunpowder Plot of 1605, a failed conspiracy by a group of provincial English Catholics to assassinate the Protestant King James I of England and replace him with a Catholic head of state. In the immediate aftermath of the 5 November arrest of Guy Fawkes, caught guarding a cache of explosives placed beneath the House of Lords, James's Council allowed the public to celebrate the king's survival with bonfires, so long as they were "without any danger or disorder". This made 1605 the first year the plot's failure was celebrated. The following January, days before the surviving conspirators were executed, Parliament passed the Observance of 5th November Act, commonly known as the "Thanksgiving Act". It was proposed by a Puritan Member of Parliament, Edward Montagu, who suggested that the king's apparent deliverance by divine intervention deserved some measure of official recognition, and kept 5 November free as a day of thanksgiving while in theory making attendance at Church mandatory. A new form of service was also added to the Church of England's "Book of Common Prayer", for use on that date.

Little is known about the earliest celebrations. In settlements such as Carlisle, Norwich, and Nottingham, corporations (town governments) provided music and artillery salutes. Canterbury celebrated 5 November 1607 with of gunpowder and of match, and three years later food and drink was provided for local dignitaries, as well as music, explosions, and a parade by the local militia. Even less is known of how the occasion was first commemorated by the general public, although records indicate that in the Protestant stronghold of Dorchester a sermon was read, the church bells rung, and bonfires and fireworks lit.

According to historian and author Antonia Fraser, a study of the earliest sermons preached demonstrates an anti-Catholic concentration "mystical in its fervour". Delivering one of five 5 November sermons printed in "A Mappe of Rome" in 1612, Thomas Taylor spoke of the "generality of his [a papist's] cruelty", which had been "almost without bounds". Such messages were also spread in printed works like Francis Herring's "Pietas Pontifica" (republished in 1610 as "Popish Piety"), and John Rhode's "A Brief Summe of the Treason intended against the King & State", which in 1606 sought to educate "the simple and ignorant ... that they be not seduced any longer by papists". By the 1620s the Fifth was honoured in market towns and villages across the country, though it was some years before it was commemorated throughout England. Gunpowder Treason Day, as it was then known, became the predominant English state commemoration. Some parishes made the day a festive occasion, with public drinking and solemn processions. Concerned though about James's pro-Spanish foreign policy, the decline of international Protestantism, and Catholicism in general, Protestant clergymen who recognised the day's significance called for more dignified and profound thanksgivings each 5 November.

What unity English Protestants had shared in the plot's immediate aftermath began to fade when in 1625 James's son, the future Charles I, married the Catholic Henrietta Maria of France. Puritans reacted to the marriage by issuing a new prayer to warn against rebellion and Catholicism, and on 5 November that year, effigies of the pope and the devil were burnt, the earliest such report of this practice and the beginning of centuries of tradition. During Charles's reign Gunpowder Treason Day became increasingly partisan. Between 1629 and 1640 he ruled without Parliament, and he seemed to support Arminianism, regarded by Puritans like Henry Burton as a step toward Catholicism. By 1636, under the leadership of the Arminian Archbishop of Canterbury William Laud, the English church was trying to use 5 November to denounce all seditious practices, and not just popery. Puritans went on the defensive, some pressing for further reformation of the Church.
Bonfire Night, as it was occasionally known, assumed a new fervour during the events leading up to the English Interregnum. Although Royalists disputed their interpretations, Parliamentarians began to uncover or fear new Catholic plots. Preaching before the House of Commons on 5 November 1644, Charles Herle claimed that Papists were tunnelling "from Oxford, Rome, Hell, to Westminster, and there to blow up, if possible, the better foundations of your houses, their liberties and privileges". A display in 1647 at Lincoln's Inn Fields commemorated "God's great mercy in delivering this kingdom from the hellish plots of papists", and included fireballs burning in the water (symbolising a Catholic association with "infernal spirits") and fireboxes, their many rockets suggestive of "popish spirits coming from below" to enact plots against the king. Effigies of Fawkes and the pope were present, the latter represented by Pluto, Roman god of the underworld.

Following Charles I's execution in 1649, the country's new republican regime remained undecided on how to treat 5 November. Unlike the old system of religious feasts and State anniversaries, it survived, but as a celebration of parliamentary government and Protestantism, and not of monarchy. Commonly the day was still marked by bonfires and miniature explosives, but formal celebrations resumed only with the Restoration, when Charles II became king. Courtiers, High Anglicans and Tories followed the official line, that the event marked God's preservation of the English throne, but generally the celebrations became more diverse. By 1670 London apprentices had turned 5 November into a fire festival, attacking not only popery but also "sobriety and good order", demanding money from coach occupants for alcohol and bonfires. The burning of effigies, largely unknown to the Jacobeans, continued in 1673 when Charles's brother, the Duke of York, converted to Catholicism. In response, accompanied by a procession of about 1,000 people, the apprentices fired an effigy of the Whore of Babylon, bedecked with a range of papal symbols. Similar scenes occurred over the following few years. On 17 November 1677, anti-Catholic fervour saw the Accession Day marked by the burning of a large effigy of the pope—his belly filled with live cats "who squalled most hideously as soon as they felt the fire"—and two effigies of devils "whispering in his ear". Two years later, as the exclusion crisis reached its zenith, an observer noted that "the 5th at night, being gunpowder treason, there were many bonfires and burning of popes as has ever been seen". Violent scenes in 1682 forced London's militia into action, and to prevent any repetition the following year a proclamation was issued, banning bonfires and fireworks.

Fireworks were also banned under James II, who became king in 1685. Attempts by the government to tone down Gunpowder Treason Day celebrations were, however, largely unsuccessful, and some reacted to a ban on bonfires in London (born from a fear of more burnings of the pope's effigy) by placing candles in their windows, "as a witness against Catholicism". When James was deposed in 1688 by William of Orange—who, importantly, landed in England on 5 November—the day's events turned also to the celebration of freedom and religion, with elements of anti-Jacobitism. While the earlier ban on bonfires was politically motivated, a ban on fireworks was maintained for safety reasons, "much mischief having been done by squibs".

William III's birthday fell on 4 November, and for orthodox Whigs the two days therefore became an important double anniversary. William ordered that the thanksgiving service for 5 November be amended to include thanks for his "happy arrival" and "the Deliverance of our Church and Nation". In the 1690s he re-established Protestant rule in Ireland, and the Fifth, occasionally marked by the ringing of church bells and civic dinners, was consequently eclipsed by his birthday commemorations. From the 19th century, 5 November celebrations there became sectarian in nature. Its celebration in Northern Ireland remains controversial, unlike in Scotland where bonfires continue to be lit in various cities. In England though, as one of 49 official holidays, for the ruling class 5 November became overshadowed by events such as the birthdays of Admiral Edward Vernon, or John Wilkes, and under George II and George III, with the exception of the Jacobite Rising of 1745, it was largely "a polite entertainment rather than an occasion for vitriolic thanksgiving". For the lower classes, however, the anniversary was a chance to pit disorder against order, a pretext for violence and uncontrolled revelry. At some point, for reasons that are unclear, it became customary to burn Guy Fawkes in effigy, rather than the pope. Gradually, Gunpowder Treason Day became Guy Fawkes Day. In 1790 "The Times" reported instances of children "... begging for money for Guy Faux", and a report of 4 November 1802 described how "a set of idle fellows ... with some horrid figure dressed up as a "Guy Faux"" were convicted of begging and receiving money, and committed to prison as "idle and disorderly persons". The Fifth became "a polysemous occasion, replete with polyvalent cross-referencing, meaning all things to all men". Lower class rioting continued, with reports in Lewes of annual rioting, intimidation of "respectable householders" and the rolling through the streets of lit tar barrels. In Guildford, gangs of revellers who called themselves "guys" terrorised the local population; proceedings were concerned more with the settling of old arguments and general mayhem, than any historical reminiscences. Similar problems arose in Exeter, originally the scene of more traditional celebrations. In 1831 an effigy was burnt of the new Bishop of Exeter Henry Phillpotts, a High Church Anglican and High Tory who opposed Parliamentary reform, and who was also suspected of being involved in "creeping popery". A local ban on fireworks in 1843 was largely ignored, and attempts by the authorities to suppress the celebrations resulted in violent protests and several injured constables.
On several occasions during the 19th century "The Times" reported that the tradition was in decline, being "of late years almost forgotten", but in the opinion of historian David Cressy, such reports reflected "other Victorian trends", including a lessening of Protestant religious zeal—not general observance of the Fifth. Civil unrest brought about by the union of the Kingdoms of Great Britain and Ireland in 1800 resulted in Parliament passing the Roman Catholic Relief Act 1829, which afforded Catholics greater civil rights, continuing the process of Catholic Emancipation in the two kingdoms. The traditional denunciations of Catholicism had been in decline since the early 18th century, and were thought by many, including Queen Victoria, to be outdated, but the pope's restoration in 1850 of the English Catholic hierarchy gave renewed significance to 5 November, as demonstrated by the burnings of effigies of the new Catholic Archbishop of Westminster Nicholas Wiseman, and the pope. At Farringdon Market 14 effigies were processed from the Strand and over Westminster Bridge to Southwark, while extensive demonstrations were held throughout the suburbs of London. Effigies of the 12 new English Catholic bishops were paraded through Exeter, already the scene of severe public disorder on each anniversary of the Fifth. Gradually, however, such scenes became less popular. With little resistance in Parliament, the thanksgiving prayer of 5 November contained in the Anglican "Book of Common Prayer" was abolished, and in March 1859 the Anniversary Days Observance Act repealed the Observance of 5th November Act. As the authorities dealt with the worst excesses, public decorum was gradually restored. The sale of fireworks was restricted, and the Guildford "guys" were neutralized in 1865, although this was too late for one constable, who died of his wounds. Violence continued in Exeter for some years, peaking in 1867 when, incensed by rising food prices and banned from firing their customary bonfire, a mob was twice in one night driven from Cathedral Close by armed infantry. Further riots occurred in 1879, but there were no more bonfires in Cathedral Close after 1894. Elsewhere, sporadic instances of public disorder persisted late into the 20th century, accompanied by large numbers of firework-related accidents, but a national Firework Code and improved public safety has in most cases brought an end to such things.

One notable aspect of the Victorians' commemoration of Guy Fawkes Night was its move away from the centres of communities, to their margins. Gathering wood for the bonfire increasingly became the province of working-class children, who solicited combustible materials, money, food and drink from wealthier neighbours, often with the aid of songs. Most opened with the familiar "Remember, remember, the fifth of November, Gunpowder Treason and Plot". The earliest recorded rhyme, from 1742, is reproduced below alongside one bearing similarities to most Guy Fawkes Night ditties, recorded in 1903 at Charlton on Otmoor:

Organised entertainments also became popular in the late 19th century, and 20th-century pyrotechnic manufacturers renamed Guy Fawkes Day as Firework Night. Sales of fireworks dwindled somewhat during the First World War, but resumed in the following peace. At the start of the Second World War celebrations were again suspended, resuming in November 1945. For many families, Guy Fawkes Night became a domestic celebration, and children often congregated on street corners, accompanied by their own effigy of Guy Fawkes. This was sometimes ornately dressed and sometimes a barely recognisable bundle of rags stuffed with whatever filling was suitable. A survey found that in 1981 about 23 percent of Sheffield schoolchildren made Guys, sometimes weeks before the event. Collecting money was a popular reason for their creation, the children taking their effigy from door to door, or displaying it on street corners. But mainly, they were built to go on the bonfire, itself sometimes comprising wood stolen from other pyres; "an acceptable convention" that helped bolster another November tradition, Mischief Night. Rival gangs competed to see who could build the largest, sometimes even burning the wood collected by their opponents; in 1954 the "Yorkshire Post" reported on fires late in September, a situation that forced the authorities to remove latent piles of wood for safety reasons. Lately, however, the custom of begging for a "penny for the Guy" has almost completely disappeared. In contrast, some older customs still survive; in Ottery St Mary men chase each other through the streets with lit tar barrels, and since 1679 Lewes has been the setting of some of England's most extravagant 5 November celebrations, the Lewes Bonfire.

Generally, modern 5 November celebrations are run by local charities and other organisations, with paid admission and controlled access. In 1998 an editorial in the "Catholic Herald" called for the end of "Bonfire Night", labelling it "an offensive act". Author Martin Kettle, writing in "The Guardian" in 2003, bemoaned an "occasionally nannyish" attitude to fireworks that discourages people from holding firework displays in their back gardens, and an "unduly sensitive attitude" toward the anti-Catholic sentiment once so prominent on Guy Fawkes Night. David Cressy summarised the modern celebration with these words: "The rockets go higher and burn with more colour, but they have less and less to do with memories of the Fifth of November ... it might be observed that Guy Fawkes' Day is finally declining, having lost its connection with politics and religion. But we have heard that many times before."

Historians have often suggested that Guy Fawkes Day served as a Protestant replacement for the ancient Celtic festival of Samhain or Calan Gaeaf, pagan events that the church absorbed and transformed into All Hallow's Eve and All Souls' Day. In "The Golden Bough", the Scottish anthropologist James George Frazer suggested that Guy Fawkes Day exemplifies "the recrudescence of old customs in modern shapes". David Underdown, writing in his 1987 work "Revel, Riot, and Rebellion", viewed Gunpowder Treason Day as a replacement for Hallowe'en: "just as the early church had taken over many of the pagan feasts, so did Protestants acquire their own rituals, adapting older forms or providing substitutes for them". While the use of bonfires to mark the occasion was most likely taken from the ancient practice of lighting celebratory bonfires, the idea that the commemoration of 5 November 1605 ever originated from anything other than the safety of James I is, according to David Cressy, "speculative nonsense". Citing Cressy's work, Ronald Hutton agrees with his conclusion, writing, "There is, in brief, nothing to link the Hallowe'en fires of North Wales, Man, and central Scotland with those which appeared in England upon 5 November." Further confusion arises in Northern Ireland, where some communities celebrate Guy Fawkes Night; the distinction there between the Fifth, and Halloween, is not always clear. Despite such disagreements, in 2005 David Cannadine commented on the encroachment into British culture of late 20th-century American Hallowe'en celebrations, and their effect on Guy Fawkes Night:

Reporting on the same topic, in 2012 the BBC's Tom de Castella concluded:

Another celebration involving fireworks, the five-day Hindu festival of Diwali (normally observed between mid-October and November), in 2010 began on 5 November. This led "The Independent" to comment on the similarities between the two, its reporter Kevin Rawlinson wondering "which fireworks will burn brightest".

Gunpowder Treason Day was exported by settlers to colonies around the world, including members of the Commonwealth of Nations such as Australia, New Zealand, Canada and various Caribbean nations. The day is still marked in Saint Vincent and the Grenadines, and in Saint Kitts and Nevis, but a fireworks ban by Antigua and Barbuda during the 1990s reduced its popularity in that country. In Australia, Sydney (founded as a penal colony in 1788) saw at least one instance of the parading and burning of a Guy Fawkes effigy in 1805, while in 1833, four years after its founding, Perth listed Gunpowder Treason Day as a public holiday. By the 1970s, Guy Fawkes Night had become less common in Australia. Some measure of celebration remains in New Zealand, Canada and South Africa.

In North America the commemoration was at first paid scant attention, but the arrest of two boys caught lighting bonfires on 5 November 1662 in Boston suggests, in historian James Sharpe's view, that "an underground tradition of commemorating the Fifth existed". In parts of North America it was known as Pope Day, celebrated mainly in colonial New England, but also as far south as Charleston. In Boston, founded in 1630 by Puritan settlers led by John Winthrop, an early celebration was held in 1685, the same year that James II assumed the throne. Fifty years later, again in Boston, a local minister wrote "a Great number of people went over to Dorchester neck where at night they made a Great Bonfire and plaid off many fireworks", although the day ended in tragedy when "4 young men coming home in a Canoe were all Drowned". Ten years later the raucous celebrations were the cause of considerable annoyance to the upper classes and a special Riot Act was passed, to prevent "riotous tumultuous and disorderly assemblies of more than three persons, all or any of them armed with Sticks, Clubs or any kind of weapons, or disguised with vizards, or painted or discolored faces, on in any manner disguised, having any kind of imagery or pageantry, in any street, lane, or place in Boston". With inadequate resources, however, Boston's authorities were powerless to enforce the Act. In the 1740s gang violence became common, with groups of Boston residents battling for the honour of burning the pope's effigy. But by the mid-1760s these riots had subsided, and as colonial America moved towards revolution, the class rivalries featured during Pope Day gave way to anti-British sentiment. In author Alfred Young's view, Pope Day provided the "scaffolding, symbolism, and leadership" for resistance to the Stamp Act in 1764–65, forgoing previous gang rivalries in favour of unified resistance to Britain.

The passage in 1774 of the Quebec Act, which guaranteed French Canadians free practice of Catholicism in the Province of Quebec, provoked complaints from some Americans that the British were introducing "Popish principles and French law". Such fears were bolstered by opposition from the Church in Europe to American independence, threatening a revival of Pope Day. Commenting in 1775, George Washington was less than impressed by the thought of any such resurrections, forbidding any under his command from participating:

Generally, following Washington's complaint, American colonists stopped observing Pope Day, although according to The Bostonian Society some citizens of Boston celebrated it on one final occasion, in 1776. The tradition continued in Salem as late as 1817, and was still observed in Portsmouth, New Hampshire, in 1892. In the late 18th century, effigies of prominent figures such as two Prime Ministers of Great Britain, the Earl of Bute and Lord North, and the American traitor General Benedict Arnold, were also burnt. In the 1880s bonfires were still being lit in some New England coastal towns, although no longer to commemorate the failure of the Gunpowder Plot. In the area around New York City, stacks of barrels were burnt on Election Day eve, which after 1845 was a Tuesday early in November.


Notes
Footnotes
Bibliography



</doc>
<doc id="979227" url="https://en.wikipedia.org/wiki?curid=979227" title="Rings of Jupiter">
Rings of Jupiter

The planet Jupiter has a system of rings known as the rings of Jupiter or the Jovian ring system. It was the third ring system to be discovered in the Solar System, after those of Saturn and Uranus. It was first observed in 1979 by the "Voyager 1" space probe and thoroughly investigated in the 1990s by the "Galileo" orbiter. It has also been observed by the Hubble Space Telescope and from Earth for several years. Ground-based observation of the rings requires the largest available telescopes.

The Jovian ring system is faint and consists mainly of dust. It has four main components: a thick inner torus of particles known as the "halo ring"; a relatively bright, exceptionally thin "main ring"; and two wide, thick and faint outer "gossamer rings", named for the moons of whose material they are composed: Amalthea and Thebe.

The main and halo rings consist of dust ejected from the moons Metis, Adrastea, and other unobserved parent bodies as the result of high-velocity impacts. High-resolution images obtained in February and March 2007 by the "New Horizons" spacecraft revealed a rich fine structure in the main ring.

In visible and near-infrared light, the rings have a reddish color, except the halo ring, which is neutral or blue in color. The size of the dust in the rings varies, but the cross-sectional area is greatest for nonspherical particles of radius about 15 μm in all rings except the halo. The halo ring is probably dominated by submicrometre dust. The total mass of the ring system (including unresolved parent bodies) is poorly known, but is probably in the range of 10 to 10 kg. The age of the ring system is not known, but it may have existed since the formation of Jupiter.

A ring could possibly exist in Himalia's orbit. One possible explanation is that a small moon had crashed into Himalia and the force of the impact caused material to blast off Himalia.

Jupiter's ring system was the third to be discovered in the Solar System, after those of Saturn and Uranus. It was first observed in 1979 by the "Voyager 1" space probe. It is composed of four main components: a thick inner torus of particles known as the "halo ring"; a relatively bright, exceptionally thin "main ring"; and two wide, thick and faint outer "gossamer rings", named after the moons of whose material they are composed: Amalthea and Thebe. The principal attributes of the known Jovian Rings are listed in the table.

The narrow and relatively thin main ring is the brightest part of Jupiter's ring system. Its outer edge is located at a radius of about (; = equatorial radius of Jupiter or ) and coincides with the orbit of Jupiter's smallest inner satellite, Adrastea. Its inner edge is not marked by any satellite and is located at about ().

Thus the width of the main ring is around . The appearance of the main ring depends on the viewing geometry. In forward-scattered light the brightness of the main ring begins to decrease steeply at (just inward of the Adrastean orbit) and reaches the background level at —just outward of the Adrastean orbit. Therefore, Adrastea at clearly shepherds the ring. The brightness continues to increase in the direction of Jupiter and has a maximum near the ring’s center at , although there is a pronounced gap (notch) near the Metidian orbit at . The inner boundary of the main ring, in contrast, appears to fade off slowly from to , merging into the halo ring. In forward-scattered light all Jovian rings are especially bright.
In back-scattered light the situation is different. The outer boundary of the main ring, located at , or slightly beyond the orbit of Adrastea, is very steep. The orbit of the moon is marked by a gap in the ring so there is a thin ringlet just outside its orbit. There is another ringlet just inside Adrastean orbit followed by a gap of unknown origin located at about . The third ringlet is found inward of the central gap, outside the orbit of Metis. The ring’s brightness drops sharply just outward of the Metidian orbit, forming the Metis notch. Inward of the orbit of Metis, the brightness of the ring rises much less than in forward-scattered light. So in the back-scattered geometry the main ring appears to consist of two different parts: a narrow outer part extending from to , which itself includes three narrow ringlets separated by notches, and a fainter inner part from to , which lacks any visible structure like in the forward-scattering geometry. The Metis notch serves as their boundary. The fine structure of the main ring was discovered in data from the "Galileo" orbiter and is clearly visible in back-scattered images obtained from "New Horizons" in February–March 2007. The early observations by Hubble Space Telescope (HST), Keck and the "Cassini" spacecraft failed to detect it, probably due to insufficient spatial resolution. However the fine structure was observed by the Keck telescope using adaptive optics in 2002–2003.

Observed in back-scattered light the main ring appears to be razor thin, extending in the vertical direction no more than 30 km. In the side scatter geometry the ring thickness is 80–160 km, increasing somewhat in the direction of Jupiter. The ring appears to be much thicker in the forward-scattered light—about 300 km. One of the discoveries of the "Galileo" orbiter was the bloom of the main ring—a faint, relatively thick (about 600 km) cloud of material which surrounds its inner part. The bloom grows in thickness towards the inner boundary of the main ring, where it transitions into the halo.

Detailed analysis of the "Galileo" images revealed longitudinal variations of the main ring’s brightness unconnected with the viewing geometry. The Galileo images also showed some patchiness in the ring on the scales 500–1000 km.

In February–March 2007 "New Horizons" spacecraft conducted a deep search for new small moons inside the main ring. While no satellites larger than 0.5 km were found, the cameras of the spacecraft detected seven small clumps of ring particles. They orbit just inside the orbit of Adrastea inside a dense ringlet. The conclusion, that they are clumps and not small moons, is based on their azimuthally extended appearance. They subtend 0.1–0.3° along the ring, which correspond to 1000–3000 km. The clumps are divided into two groups of five and two members, respectively. The nature of the clumps is not clear, but their orbits are close to 115:116 and 114:115 resonances with Metis. They may be wavelike structures excited by this interaction.

Spectra of the main ring obtained by the HST, Keck, Galileo and "Cassini" have shown that particles forming it are red, i.e. their albedo is higher at longer wavelengths. The existing spectra span the range 0.5–2.5 μm. No spectral features have been found so far which can be attributed to particular chemical compounds, although the Cassini observations yielded evidence for absorption bands near 0.8 μm and 2.2 μm. The spectra of the main ring are very similar to Adrastea and Amalthea.

The properties of the main ring can be explained by the hypothesis that it contains significant amounts of dust with 0.1–10 μm particle sizes. This explains the stronger forward-scattering of light as compared to back-scattering. However, larger bodies are required to explain the strong back-scattering and fine structure in the bright outer part of the main ring.

Analysis of available phase and spectral data leads to a conclusion that the size distribution of small particles in the main ring obeys a power law

where "n"("r") "dr" is a number of particles with radii between "r" and "r" + "dr" and formula_2 is a normalizing parameter chosen to match the known total light flux from the ring. The parameter "q" is 2.0 ± 0.2 for particles with "r" < 15 ± 0.3 μm and "q" = 5 ± 1 for those with "r" > 15 ± 0.3 μm. The distribution of large bodies in the mm–km size range is undetermined presently. The light scattering in this model is dominated by particles with "r" around 15 μm.

The power law mentioned above allows estimation of the optical depth formula_3 of the main ring: formula_4 for the large bodies and formula_5 for the dust. This optical depth means that the total cross section of all particles inside the ring is about 5000 km². The particles in the main ring are expected to have aspherical shapes. The total mass of the dust is estimated to be 10−10 kg. The mass of large bodies, excluding Metis and Adrastea, is 10−10 kg. It depends on their maximum size— the upper value corresponds to about 1 km maximum diameter. These masses can be compared with masses of Adrastea, which is about 2 kg, Amalthea, about 2 kg, and Earth's Moon, 7.4 kg.

The presence of two populations of particles in the main ring explains why its appearance depends on the viewing geometry. The dust scatters light preferably in the forward direction and forms a relatively thick homogenous ring bounded by the orbit of Adrastea. In contrast, large particles, which scatter in the back direction, are confined in a number of ringlets between the Metidian and Adrastean orbits.

The dust is constantly being removed from the main ring by a combination of Poynting–Robertson drag and electromagnetic forces from the Jovian magnetosphere. Volatile materials, for example ices, evaporate quickly. The lifetime of dust particles in the ring is from 100 to 1000 years, so the dust must be continuously replenished in the collisions between large bodies with sizes from 1 cm to 0.5 km and between the same large bodies and high velocity particles coming from outside the Jovian system. This parent body population is confined to the narrow—about 1000 km—and bright outer part of the main ring, and includes Metis and Adrastea. The largest parent bodies must be less than 0.5 km in size. The upper limit on their size was obtained by "New Horizons" spacecraft. The previous upper limit, obtained from HST and "Cassini" observations, was near 4 km. The dust produced in collisions retains approximately the same orbital elements as the parent bodies and slowly spirals in the direction of Jupiter forming the faint (in back-scattered light) innermost part of the main ring and halo ring. The age of the main ring is currently unknown, but it may be the last remnant of a past population of small bodies near Jupiter.

Images from the "Galileo" and "New Horizons" space probes show the presence of two sets of spiraling vertical corrugations in the main ring. These waves became more tightly wound over time at the rate expected for differential nodal regression in Jupiter's gravity field. Extrapolating backwards, the more prominent of the two sets of waves appears to have been excited in 1995, around the time of the impact of Comet Shoemaker-Levy 9 with Jupiter, while the smaller set appears to date to the first half of 1990. "Galileo"'s November 1996 observations are consistent with wavelengths of and , and vertical amplitudes of and , for the larger and smaller sets of waves, respectively. The formation of the larger set of waves can be explained if the ring was impacted by a cloud of particles released by the comet with a total mass on the order of 2–5 × 10 kg, which would have tilted the ring out of the equatorial plane by 2 km. A similar spiraling wave pattern that tightens over time has been observed by "Cassini" in Saturns's C and D rings.

The halo ring is the innermost and the vertically thickest Jovian ring. Its outer edge coincides with the inner boundary of the main ring approximately at the radius (). From this radius the ring becomes rapidly thicker towards Jupiter. The true vertical extent of the halo is not known but the presence of its material was detected as high as over the ring plane. The inner boundary of the halo is relatively sharp and located at the radius (), but some material is present further inward to approximately . Thus the width of the halo ring is about . Its shape resembles a thick torus without clear internal structure. In contrast to the main ring, the halo's appearance depends only slightly on the viewing geometry.

The halo ring appears brightest in forward-scattered light, in which it was extensively imaged by "Galileo". While its surface brightness is much less than that of the main ring, its vertically (perpendicular to the ring plane) integrated photon flux is comparable due to its much larger thickness. Despite a claimed vertical extent of more than , the halo’s brightness is strongly concentrated towards the ring plane and follows a power law of the form "z" to "z", where "z" is altitude over the ring plane. The halo’s appearance in the back-scattered light, as observed by Keck and HST, is the same. However its total photon flux is several times lower than that of the main ring and is more strongly concentrated near the ring plane than in the forward-scattered light.

The spectral properties of the halo ring are different from the main ring. The flux distribution in the range 0.5–2.5 μm is flatter than in the main ring; the halo is not red and may even be blue.

The optical properties of the halo ring can be explained by the hypothesis that it comprises only dust with particle sizes less than 15 μm. Parts of the halo located far from the ring plane may consist of submicrometre dust. This dusty composition explains the much stronger forward-scattering, bluer colors and lack of visible structure in the halo. The dust probably originates in the main ring, a claim supported by the fact that the halo’s optical depth formula_6 is comparable with that of the dust in the main ring. The large thickness of the halo can be attributed to the excitation of orbital inclinations and eccentricities of dust particles by the electromagnetic forces in the Jovian magnetosphere. The outer boundary of the halo ring coincides with location of a strong 3:2 Lorentz resonance. As Poynting–Robertson drag causes particles to slowly drift towards Jupiter, their orbital inclinations are excited while passing through it. The bloom of the main ring may be a beginning of the halo. The halo ring’s inner boundary is not far from the strongest 2:1 Lorentz resonance. In this resonance the excitation is probably very significant, forcing particles to plunge into the Jovian atmosphere thus defining a sharp inner boundary. Being derived from the main ring, the halo has the same age.

The Amalthea gossamer ring is a very faint structure with a rectangular cross section, stretching from the orbit of Amalthea at (2.54 "R") to about (). Its inner boundary is not clearly defined because of the presence of the much brighter main ring and halo. The thickness of the ring is approximately 2300 km near the orbit of Amalthea and slightly decreases in the direction of Jupiter. The Amalthea gossamer ring is actually the brightest near its top and bottom edges and becomes gradually brighter towards Jupiter; one of the edges is often brighter than another. The outer boundary of the ring is relatively steep; the ring's brightness drops abruptly just inward of the orbit of Amalthea, although it may have a small extension beyond the orbit of the satellite ending near 4:3 resonance with Thebe. In forward-scattered light the ring appears to be about 30 times fainter than the main ring. In back-scattered light it has been detected only by the Keck telescope and the ACS (Advanced Camera for Surveys) on HST. Back-scattering images show additional structure in the ring: a peak in the brightness just inside the Amalthean orbit and confined to the top or bottom edge of the ring.

In 2002–2003 Galileo spacecraft had two passes through the gossamer rings. During them its dust counter detected dust particles in the size range 0.2–5 μm. In addition, the Galileo spacecraft's star scanner detected small, discrete bodies (< 1 km) near Amalthea. These may represent collisional debris generated from impacts with this satellite.

The detection of the Amalthea gossamer ring from the ground, in "Galileo" images and the direct dust measurements have allowed the determination of the particle size distribution, which appears to follow the same power law as the dust in the main ring with "q"=2 ± 0.5. The optical depth of this ring is about 10, which is an order of magnitude lower than that of the main ring, but the total mass of the dust (10–10 kg) is comparable.

The Thebe gossamer ring is the faintest Jovian ring. It appears as a very faint structure with a rectangular cross section, stretching from the Thebean orbit at () to about (;). Its inner boundary is not clearly defined because of the presence of the much brighter main ring and halo. The thickness of the ring is approximately 8400 km near the orbit of Thebe and slightly decreases in the direction of the planet. The Thebe gossamer ring is brightest near its top and bottom edges and gradually becomes brighter towards Jupiter—much like the Amalthea ring. The outer boundary of the ring is not especially steep, stretching over . There is a barely visible continuation of the ring beyond the orbit of Thebe, extending up to () and called the Thebe Extension. In forward-scattered light the ring appears to be about 3 times fainter than the Amalthea gossamer ring. In back-scattered light it has been detected only by the Keck telescope. Back-scattering images show a peak of brightness just inside the orbit of Thebe. In 2002–2003 the dust counter of the Galileo spacecraft detected dust particles in the size range 0.2–5 μm—similar to those in the Amalthea ring—and confirmed the results obtained from imaging.

The optical depth of the Thebe gossamer ring is about 3, which is three times lower than the Amalthea gossamer ring, but the total mass of the dust is the same—about 10–10 kg. However the particle size distribution of the dust is somewhat shallower than in the Amalthea ring. It follows a power law with q < 2. In the Thebe extension the parameter q may be even smaller.

The dust in the gossamer rings originates in essentially the same way as that in the main ring and halo. Its sources are the inner Jovian moons Amalthea and Thebe respectively. High velocity impacts by projectiles coming from outside the Jovian system eject dust particles from their surfaces. These particles initially retain the same orbits as their moons but then gradually spiral inward by Poynting–Robertson drag. The thickness of the gossamer rings is determined by vertical excursions of the moons due to their nonzero orbital inclinations. This hypothesis naturally explains almost all observable properties of the rings: rectangular cross-section, decrease of thickness in the direction of Jupiter and brightening of the top and bottom edges of the rings.

However some properties have so far gone unexplained, like the Thebe Extension, which may be due to unseen bodies outside Thebe's orbit, and structures visible in the back-scattered light. One possible explanation of the Thebe Extension is influence of the electromagnetic forces from the Jovian magnetosphere. When the dust enters the shadow behind Jupiter, it loses its electrical charge fairly quickly. Since the small dust particles partially corotate with the planet, they will move outward during the shadow pass creating an outward extension of the Thebe gossamer ring. The same forces can explain a dip in the particle distribution and ring's brightness, which occurs between the orbits of Amalthea and Thebe.

The peak in the brightness just inside of the Amalthea's orbit and, therefore, the vertical asymmetry the Amalthea gossamer ring may be due to the dust particles trapped at the leading (L) and trailing (L) Lagrange points of this moon. The particles may also follow horseshoe orbits between the Lagrangian points. The dust may be present at the leading and trailing Lagrange points of Thebe as well. This discovery implies that there are two particle populations in the gossamer rings: one slowly drifts in the direction of Jupiter as described above, while another remains near a source moon trapped in 1:1 resonance with it.

The small moon Dia, 4 kilometres in diameter, had gone missing since its discovery in 2000. One theory was that it had crashed into the much larger moon Himalia, 170 kilometres in diameter, creating a faint ring. This possible ring appears as a faint streak near Himalia in images from NASA's "New Horizons "mission to Pluto. This suggests that Jupiter sometimes gains and loses small moons through collisions. However, the rediscovery of Dia in 2010 and 2011 disproves the link between Dia and the Himalia ring, although it is still possible that a different moon may have been involved.

The existence of the Jovian rings was inferred from observations of the planetary radiation belts by Pioneer 11 spacecraft in 1975. In 1979 the "Voyager 1" spacecraft obtained a single overexposed image of the ring system. More extensive imaging was conducted by "Voyager 2" in the same year, which allowed rough determination of the ring’s structure. The superior quality of the images obtained by the "Galileo" orbiter between 1995 and 2003 greatly extended the existing knowledge about the Jovian rings. Ground-based observation of the rings by the Keck telescope in 1997 and 2002 and the HST in 1999 revealed the rich structure visible in back-scattered light. Images transmitted by the "New Horizons" spacecraft in February–March 2007 allowed observation of the fine structure in the main ring for the first time. In 2000, the "Cassini" spacecraft en route to Saturn conducted extensive observations of the Jovian ring system. Future missions to the Jovian system will provide additional information about the rings.




</doc>
<doc id="981069" url="https://en.wikipedia.org/wiki?curid=981069" title="Grand Duchess Olga Alexandrovna of Russia">
Grand Duchess Olga Alexandrovna of Russia

Grand Duchess Olga Alexandrovna of Russia (; – 24 November 1960) was the youngest child of Emperor Alexander III of Russia and younger sister of Emperor Nicholas II.

She was raised at the Gatchina Palace outside Saint Petersburg. Olga's relationship with her mother, Empress Marie, the daughter of King Christian IX of Denmark, was strained and distant from childhood. In contrast, she and her father were close. He died when she was 12, and her brother Nicholas became emperor.

In 1901, at 19, she married Duke Peter Alexandrovich of Oldenburg, who was privately believed by family and friends to be homosexual. Their marriage of 15 years remained unconsummated, and Peter at first refused Olga's request for a divorce. The couple led separate lives and their marriage was eventually annulled by the Emperor in October 1916. The following month Olga married cavalry officer Nikolai Kulikovsky, with whom she had fallen in love several years before. During the First World War, the Grand Duchess served as an army nurse and was awarded a medal for personal gallantry. At the downfall of the Romanovs in the Russian Revolution of 1917, she fled with her husband and children to Crimea, where they lived under the threat of assassination. Her brother Nicholas and his family were shot by revolutionaries.

Olga escaped revolutionary Russia with her second husband and their two sons in February 1920. They joined her mother, the Dowager Empress, in Denmark. In exile, Olga acted as companion and secretary to her mother, and was often sought out by Romanov impostors who claimed to be her dead relatives. She met Anna Anderson, the best-known impostor, in Berlin in 1925. After the Dowager Empress's death in 1928, Olga and her husband purchased a dairy farm in Ballerup, near Copenhagen. She led a simple life: raising her two sons, working on the farm and painting. During her lifetime, she painted over 2,000 works of art, which provided extra income for both her family and the charitable causes she supported.

In 1948, feeling threatened by Joseph Stalin's regime, Olga and her immediate family relocated to a farm in Ontario, Canada. With advancing age, Olga and her husband moved to a bungalow near Cooksville, Ontario. Colonel Kulikovsky died there in 1958. Two years later, as her health deteriorated, Olga moved with friends to a small apartment in East Toronto. She died aged 78, seven months after her older sister, Xenia. At the end of her life and afterwards, Olga was widely labelled the last Grand Duchess of Imperial Russia.

Olga was the youngest daughter of Emperor Alexander III and his consort, Empress Marie, formerly Princess Dagmar of Denmark. She was born in the purple (i.e., during her father's reign) on 13 June 1882 in the Peterhof Palace, west of central Saint Petersburg. Her birth was announced by a traditional 101-gun salute from the ramparts of the Peter and Paul Fortress, and similar salutes throughout the Russian Empire. Her mother, advised by her sister, Alexandra, Princess of Wales, placed Olga in the care of an English nanny, Elizabeth Franklin.

The Russian imperial family was a frequent target for assassins, so for safety reasons the Grand Duchess was raised at the country palace of Gatchina, about 50 miles (80 km) west of Saint Petersburg. Although Olga and her siblings lived in a palace, conditions in the nursery were modest, even Spartan. They slept on hard camp beds, rose at dawn, washed in cold water, and ate a simple porridge for breakfast.

Olga left Gatchina for the first time in 1888 when the imperial family visited the Caucasus. On 29 October, their return train approached the small town of Borki at speed. Olga's parents and their four older children were eating lunch in the dining-car when the train lurched violently and came off the rails. The carriage was torn open; the heavy iron roof caved in, and the wheels and floor of the car were sliced off. Survivors claimed the Tsar crawled out from beneath the crushed roof, and held it up with "a Herculean effort" so that the others could escape; a story subsequently considered unbelievable. There were 21 fatalities. Empress Marie helped tend the wounded, and made makeshift bandages from her own clothes. An official investigation found that the crash was an accident, but it was widely and falsely believed that two bombs had been planted on the line.

The Grand Duchess and her siblings were taught at home by private tutors. Subjects included history, geography, Russian, English, and French, as well as drawing and dancing. Physical activities such as equestrianism were taught at an early age, and the children became expert riders.

The family was deeply religious. While Christmas and Easter were times of celebration and extravagance, Lent was strictly observed—meat, dairy products and any form of entertainment were avoided. 

Empress Marie was reserved and formal with Olga as a child, and their relationship remained a difficult one. But Olga, her father, and the youngest of her brothers, Michael, had a close relationship. Together, the three frequently went on hikes in the Gatchina forests, where the Tsar taught Olga and Michael woodsmanship. Olga said of her father:
Family holidays were taken in the summer at Peterhof, and with Olga's grandparents in Denmark. However, in 1894, Olga's father became increasingly ill, and the annual trip to Denmark was cancelled. On 13 November 1894, he died at the age of 49. The emotional impact on Olga, aged 12, was traumatic, and her eldest brother, the new Tsar Nicholas II, was propelled into a role for which, in Olga's later opinion, he was ill-prepared.

Olga was due to enter society in mid-1899, but after the death of her brother George at the age of 28, her first official public appearance was delayed by a year until 1900. She hated the experience, and later told her official biographer Ian Vorres, "I felt as though I were an animal in a cage—exhibited to the public for the first time." From 1901, Olga was appointed honorary Commander-in-Chief of the 12th Akhtyrsky Hussar Regiment of the Imperial Russian Army. The Akhtyrsky Hussars were famous for their victory over Napoleon Bonaparte at the Battle of Kulm in 1813, and wore a distinctive brown dolman.

By 1900, Olga, age 18, was being escorted to the theatre and opera by a distant cousin, Duke Peter Alexandrovich of Oldenburg, a member of the Russian branch of the House of Oldenburg. He was 14 years her senior and known for his passion for literature and gambling. Peter asked for Olga's hand in marriage the following year, a proposal that took the Grand Duchess completely by surprise: "I was so taken aback that all I could say was 'thank you'," she later explained.
Their engagement, announced in May 1901, was unexpected by family and friends, as Peter had shown no prior interest in women, and members of society assumed he was homosexual. At the age of 19, on 9 August 1901, Olga married 33-year-old Peter. After the celebration the newlyweds left for the Oldenburg palace on the Field of Mars. Olga spent her wedding night alone in tears, while her husband left for a gambling club returning the next morning. Their marriage remained unconsummated, and Olga suspected that Peter was pushed into proposing by his ambitious mother. Biographer Patricia Phenix thought Olga may have accepted his proposal to gain independence from her own mother, the Dowager Empress, or avoid marriage into a foreign court. The couple initially lived with her in-laws Alexander Petrovich and Eugénie Maximilianovna of Oldenburg. The arrangement was not harmonious as Peter's parents, both well known for their philanthropic work, berated their only son for his laziness. Olga took a dislike towards her mother-in-law; although Eugénie, a close friend of the Dowager Empress, gave her daughter-in-law many gifts, including a ruby tiara that had been a present to Joséphine de Beauharnais from Napoleon. A few weeks after the wedding, Olga and her husband travelled to Biarritz, France, from where they sailed to Sorrento, Italy, on a yacht loaned to them by King Edward VII of Great Britain.

On their return to Russia, they settled into a 200-room palace (the former Baryatinsky mansion) at 46 Sergievskaya Street (today Tchaikovsky Street), Saint Petersburg. The palace, a gift from Tsar Nicholas II to his sister, now houses the Saint Petersburg Chamber of Commerce and Industry. Olga and Peter had separate bedrooms at opposite ends of the building, and the Grand Duchess had her own art studio. Unhappy in her marriage, she fell into bouts of depression that caused her to lose her hair, forcing her to wear a wig. It took two years for her hair to regrow.

Near the Oldenburg's estate, Ramon in Voronezh province, Olga had her own villa, called "Olgino" after the local town. She subsidized the village school out of her own pocket, and established a hospital. Her daughter-in-law later wrote, "She tried to help every needy person as far as her strengths and means would permit." At the hospital, she learned basic medical treatment and proper care from the local doctor. She exemplified her strong Orthodox faith by creating religious icons, which she distributed to the charitable endeavours she supported. At Ramon, Olga and Peter enjoyed walking through the nearby woods and hunted wolves together. He was kind and considerate towards her, but she longed for love, a normal marriage, and children.

In April 1903, she was introduced to a Blue Cuirassier Guards officer Nikolai Kulikovsky by her brother Michael during a royal military review at Pavlovsk Palace. Olga and Kulikovsky began to see each other, and exchanged letters regularly. The same year, at the age of 22, she confronted her husband and asked for a divorce, which he refused with the qualification that he might reconsider after seven years. Nevertheless, Oldenburg appointed Kulikovsky as an aide-de-camp, and allowed him to live in the same residence as Oldenburg and the Grand Duchess on Sergievskaya Street. The relationship between Kulikovsky and the Grand Duchess was not public, but gossip about their romance spread through society.

From 1904 to 1906, Duke Peter was appointed to a military post in Tsarskoye Selo, a complex of palaces just south of Saint Petersburg. In Tsarskoye Selo, the Grand Duchess grew close to her brother Nicholas and his family, who lived at the Alexander Palace near her own residence. Olga prized her connection to the Tsar's four daughters. From 1906 to 1914, Olga took her nieces to parties and engagements in Saint Petersburg, without their parents, every weekend throughout the winter. She especially took a liking to the youngest of Nicholas's daughters, her god-daughter Anastasia, whom she called "Shvipsik" ("little one"). Through her brother and sister-in-law, Olga met Rasputin, a self-styled holy man who purported to have healing powers. Although she made no public criticisms of Rasputin's association with the imperial family, she was unconvinced of his supposed powers and privately disliked him. As Olga grew close to her brother's family, her relationship with her other surviving brother, Michael, deteriorated. To her and Nicholas's horror, Michael eloped with his mistress, a twice-divorced commoner, and communication between Michael and the rest of the family was essentially cut off.

Public unrest over the Russo-Japanese War and demands for political reform increased in the early years of the twentieth century. At Epiphany 1905, a band of revolutionaries fired live rounds at the Winter Palace from the Peter and Paul Fortress. Olga and the Dowager Empress were showered with glass splinters from a smashed window, but were unharmed. Three weeks later, on "Bloody Sunday", at least 92 people were killed by Cossack troops during a demonstration, and a month later Olga's uncle, Grand Duke Sergei Alexandrovich of Russia, was assassinated. Uprisings occurred throughout the country, and parts of the navy mutinied. Olga supported the appointment of the liberal Pyotr Stolypin as prime minister, and he embarked on a programme of gradual reform, but in 1911 he was assassinated. The public unrest, Michael's elopement, and Olga's sham marriage placed her under strain, and in 1912, while visiting England with her mother, she suffered a nervous breakdown. Tsarina Alexandra was also unwell with fatigue, concerned by the poor health of her hemophiliac son, Alexei. Olga stood in for the Tsarina at public events, and accompanied her brother on a tour of the interior, while the Tsarina remained at home.

On 1 August 1914, with World War I looming, Olga's regiment, the Akhtyrsky Hussars, appeared at an Imperial Review before her and the Tsar at Krasnoe Selo. Kulikovsky volunteered for service with the Hussars, who were stationed on the frontlines in Southwestern Russia. With the Grand Duchess's prior medical knowledge from the village of Olgino, she started work as a nurse at an under-staffed Red Cross hospital in Rovno, near to where her own regiment was stationed. During the war, she came under heavy Austrian fire while attending the regiment at the front. Nurses rarely worked so close to the frontline and consequently she was awarded the Order of St. George by General Mannerheim, who later became President of Finland. As the Russians lost ground to the Central Powers, Olga's hospital was moved eastwards to Kiev, and Michael returned to Russia from exile abroad.

In 1916, Tsar Nicholas II annulled the marriage between Duke Peter Alexandrovich and the Grand Duchess, allowing her to marry Colonel Kulikovsky. The service was performed on 16 November 1916 in the Kievo-Vasilievskaya Church on Triokhsviatitelskaya (Three Saints Street) in Kiev. The only guests were the Dowager Empress, Olga's brother-in-law Grand Duke Alexander, four officers of the Akhtyrsky Regiment, and two of Olga's fellow nurses from the hospital in Kiev.

During the war, internal tensions and economic deprivation in Russia continued to mount and revolutionary sympathies grew. After Tsar Nicholas II abdicated in early 1917, many members of the Romanov dynasty, including Nicholas and his immediate family, were detained under house arrest. In search of safety, the Dowager Empress, Grand Duke Alexander, and Grand Duchess Olga travelled to Crimea by special train, where they were joined by Olga's sister (Alexander's wife) Grand Duchess Xenia. They lived at Alexander's estate, Ay-Todor, about 12 miles (19 km) from Yalta, where they were placed under house arrest by the local forces. On 12 August 1917, her first child and son, Tikhon Nikolaevich was born during their virtual imprisonment. He was named after Tikhon of Zadonsk, the Saint venerated near the Grand Duchess's estate at Olgino.

The Romanovs isolated in Crimea knew little of the fate of the Tsar and his family. Nicholas, Alexandra, and their children, were originally held at their official residence, the Alexander Palace, but the Provisional government under Alexander Kerensky relocated them to Tobolsk, Siberia. In February 1918, most of the imperial family at Ay-Todor was moved to another estate at Djulber, where Grand Dukes Nicholas and Peter were already under house arrest. Olga and her husband were left at Ay-Todor. The entire Romanov family in Crimea was condemned to death by the Yalta revolutionary council, but the executions were delayed by political rivalry between the Yalta and Sevastopol Soviets. By March 1918, the Central Power of Germany had advanced on Crimea, and the revolutionary guards were replaced by German ones. In November 1918, the German forces were informed that their nation had lost the war, and they evacuated homewards. Allied forces took over the Crimean ports, in support of the loyalist White Army, which allowed the surviving members of the Romanov family time to escape abroad. The Dowager Empress and, at her insistence, most of her family and friends were evacuated by the British warship HMS "Marlborough". Nicholas II had already been shot dead and the family assumed, correctly, that his wife and children had also been killed.

Olga and her husband refused to leave Russia, and decided to move to the Caucasus, which the White Army had cleared of revolutionary Bolsheviks. An imperial bodyguard, Timofei Yatchik, guided them to his hometown, the large Cossack village of Novominskaya. In a rented five-room farmhouse there, Olga gave birth to her second son, Guri Nikolaevich, on 23 April 1919. He was named after a friend of hers, Guri Panayev, who was killed while serving in the Akhtyrsky Regiment during World War I. In November 1919, the family set out on what would be their last journey through Russia. Just ahead of revolutionary troops, they escaped to Novorossiysk, and took refuge in the residence of the Danish consul, Thomas Schytte, who informed them of the Dowager Empress's safe arrival in Denmark. After a brief stay with the consul, the family was shipped to a refugee camp on the island of Büyükada in the Dardanelles Strait near Istanbul, Turkey, where Olga, her husband and children shared three rooms with eleven other adults. After two weeks, they were evacuated to Belgrade in the Kingdom of Serbs, Croats and Slovenes where she was visited by Prince Regent Alexander. Alexander offered the Grand Duchess and her family a permanent home, but Olga was summoned to Denmark by her mother. On Good Friday 1920, Olga and her family arrived in Copenhagen. They lived with the Dowager Empress, at first at the Amalienborg Palace and then at the royal estate of Hvidøre, where Olga acted as her mother's secretary and companion. It was a difficult arrangement at times. The Dowager Empress insisted on having Olga at her beck and call and found Olga's young sons too boisterous. Having never reconciled with the idea of her daughter's marriage to a commoner, she was cold towards Kulikovsky, rarely allowing him in her presence. At formal functions, Olga was expected to accompany her mother alone.

In 1925, Olga and Colonel Kulikovsky travelled to Berlin to meet Anna Anderson, who claimed to be Olga's niece, Grand Duchess Anastasia Nikolaevna of Russia. Anderson had attempted suicide in Berlin in 1920, which Olga later called "probably the only indisputable fact in the whole story". Anderson claimed that with the help of a man named Tchaikovsky she had escaped from revolutionary Russia via Bucharest, where she had given birth to his child. Olga thought the story "palpably false", since Anderson made no attempt to approach Queen Marie of Romania, during her entire alleged time in Bucharest. Olga said:
Anderson stated she was in Berlin to inform Princess Irene of Prussia (sister of Tsarina Alexandra and cousin of Tsar Nicholas II) of her survival. Olga commented, "[Princess Irene] was one of the most straightlaced women in her generation. My niece would have known that her condition would have indeed have shocked [her]."

Olga met Anderson, who was being treated for tuberculosis, at a nursing home. Of the visit Olga later said:
Olga also said she was dismayed that Anderson spoke only German and showed no sign of knowing either English or Russian, while Anastasia spoke both those languages fluently and was ignorant of German. Nevertheless, Olga remained sympathetic towards Anderson, perhaps because she thought that she was ill rather than deliberately deceitful. Olga later explained:

Conceivably, Olga was initially either open to the possibility that Anderson was Anastasia or unable to make up her mind. Anderson's biographer and supporter Peter Kurth claimed that Olga wrote to the Danish ambassador, Herluf Zahle, at the end of October 1925: "My feeling is that she is not the one she believes—but one can't say she is not as a fact". Within a month she had made up her mind. She wrote to a friend, "There is no resemblance, and she is undoubtedly not A." Olga sent Anderson a scarf and five letters, which were used by Anderson's supporters to claim that Olga recognized Anderson as Anastasia. Olga later said she sent the gift and letters "out of pity", and called the claims "a complete fabrication". When Olga refused to recognize Anderson as Anastasia publicly and published a statement denying any resemblance in a Danish newspaper, Anderson's supporters, Harriet von Rathlef and Gleb Botkin, claimed that Olga was acting on instructions received from her sister Xenia by telegram, which Olga denied in private letters and sworn testimony. She told her official biographer, "I never received any such telegram." The telegram was never produced by Anderson's supporters, and it has never been found among any of the papers relating to the case. Xenia said,
The Dowager Empress died on 13 October 1928 at Hvidøre. Her estate was sold and Olga purchased "Knudsminde", a farm in Ballerup about 15 miles (24 km) from Copenhagen, with her portion of the proceeds. She and her husband kept horses, in which Colonel Kulikovsky was especially interested, along with Jersey cows, pigs, chickens, geese, dogs and cats. For transport they had a small car and a sledge. Tihon and Guri (age thirteen and eleven, respectively when they moved to Knudsminde) grew up on the farm. Olga ran the household with the help of her elderly, faithful lady's maid Emilia Tenso ("Mimka"), who had come along with her from Russia. The Grand Duchess lived with simplicity, working in the fields, doing household chores, and painting.

The farm became a center for the Russian monarchist community in Denmark, and many Russian emigrants visited. Olga maintained a high level of correspondence with the Russian émigré community and former members of the imperial army. On 2 February 1935 in the Russian Orthodox Church in Copenhagen, she and her husband were godparents, with her cousin Prince Gustav of Denmark, to Aleksander Schalburg, son of Russian-born Danish army officer Christian Frederik von Schalburg. In the 1930s, the family took annual holidays at Sofiero Castle, Sweden, with Crown Prince Gustaf of Sweden and his wife, Louise. Olga began to sell her own paintings, of Russian and Danish scenes, with exhibition auctions in Copenhagen, London, Paris, and Berlin. Some of the proceeds were donated to the charities she supported.

Neutral Denmark was invaded by Nazi Germany on 9 April 1940, and was occupied for the remainder of World War II. Food shortages, communication restrictions, and transport closures followed. As Olga's sons, Tikhon and Guri, served as officers in the Danish Army, they were interned as prisoners of war, but their imprisonment in a Copenhagen hotel lasted less than two months. Tikhon was imprisoned for a further month in 1943 after being arrested on charges of espionage. Other Russian émigrés, keen to fight against the Soviets, enlisted in the German forces. Despite her sons' internment and her mother's Danish origins, Olga was implicated in her compatriots' collusion with German forces, as she continued to meet and extend help to Russian émigrés fighting against communism. On 4 May 1945, German forces in Denmark surrendered to the British. When economic and social conditions for Russian exiles failed to improve, General Pyotr Krasnov wrote to the Grand Duchess, detailing the wretched conditions affecting Russian immigrants in Denmark. She in turn asked Prince Axel of Denmark to help them, but her request was refused.

With the end of World War II, Soviet troops occupied the Danish island of Bornholm, and the Soviet Union wrote to the Danish government accusing Olga and a Danish Catholic bishop of conspiracy against the Soviet government. The surviving Romanovs in Denmark grew fearful of an assassination or kidnap attempt, and Olga decided to move her family across the Atlantic to the relative safety of rural Canada.

In May 1948, the Kulikovskys travelled to London by Danish troopship. They were housed in a grace and favour apartment at Hampton Court Palace while arrangements were made for their journey to Canada as agricultural immigrants. On 2 June 1948, Olga, Kulikovsky, Tikhon and his Danish-born wife Agnete, Guri and his Danish-born wife Ruth, Guri and Ruth's two children, Xenia and Leonid, and Olga's devoted companion and former maid Emilia Tenso ("Mimka") departed Liverpool on board the "Empress of Canada". After a rough crossing, the ship docked at Halifax, Nova Scotia. The family lived in Toronto, until they purchased a farm in Halton County, Ontario, near Campbellville.

By 1952, the farm had become a burden to Olga and her husband. They were both elderly; their sons had moved away; labour was hard to come by; the Colonel suffered increasing ill-health, and some of Olga's remaining jewelry was stolen. The farm was sold, and Olga, her husband and her former maid, Mimka, moved to a smaller five-room house at 2130 Camilla Road, Cooksville, Ontario, a suburb of Toronto now amalgamated into Mississauga. Mimka suffered a stroke that left her an invalid, and Olga nursed her until Mimka's death on 24 January 1954.

Neighbours and visitors to the region, including foreign and royal dignitaries, took interest in Olga, and visited her home; these included Princess Marina, Duchess of Kent, in 1954, and Louis Mountbatten and his wife Edwina, in August 1959. In June 1959, Queen Elizabeth II and Prince Philip visited Toronto and invited the Grand Duchess for lunch on board the royal yacht "Britannia". Her home was also a magnet for Romanov impostors, whom Olga and her family considered a menace.

By 1958, Olga's husband was virtually paralyzed, and she sold some of her remaining jewelry to raise funds. Following her husband's death in 1958, she became increasingly infirm until hospitalized in April 1960 at Toronto General Hospital. She was not informed or was not aware that her elder sister, Xenia, died in London that month. Unable to care for herself, Olga went to stay with Russian émigré friends, Konstantin and Sinaida Martemianoff, in an apartment above a beauty salon at 716 Gerrard Street East, Toronto. She slipped into a coma on 21 November 1960, and died on 24 November at the age of 78.

She was interred next to her husband in York Cemetery, Toronto, on 30 November 1960, after a funeral service at Christ the Saviour Cathedral, Toronto. Officers of the Akhtyrsky Hussars and the Blue Cuirassiers stood guard in the small Russian church, which overflowed with mourners. Although she lived simply, bought cheap clothes, and did her own shopping and gardening, her estate was valued at more than 200,000 Canadian dollars (about $1.5 million as of 2013) and was mostly held as stock and bonds. Her material possessions were appraised at $350 in total, which biographer Patricia Phenix considered an underestimate.

Olga began drawing and painting at a young age. She told her official biographer Ian Vorres:

She painted throughout her life, on paper, canvas and ceramic, and her output is estimated at over 2,000 pieces. Her usual subject was scenery and landscape, but she also painted portraits and still lifes. Vorres wrote,

Her daughter-in-law wrote,
Her paintings were a profitable source of income. According to her daughter-in-law, Olga preferred to exhibit in Denmark to avoid the commercialism of the North American market. The Russian Relief Programme, which was founded by Tikhon and his third wife Olga in honour of the Grand Duchess, exhibited a selection of her work at the residence of the Russian ambassador in Washington in 2001, in Moscow in 2002, in Ekaterinburg in 2004, in Saint Petersburg and Moscow in 2005, in Tyumen and Surgut in 2006, at the Tretyakov Gallery in Moscow and Saint Michael's Castle in Saint Petersburg in 2007, and at the Vladimir Arsenyev Museum in Vladivostok in 2013. Pieces by Olga are included in the collections of the British queen Elizabeth II and her husband Philip, the Norwegian king Harald V, and private collections in North America and Europe. Ballerup Museum in Pederstrup, Denmark, has around 100 of her works.




</doc>
<doc id="982118" url="https://en.wikipedia.org/wiki?curid=982118" title="Ho Ho Ho">
Ho Ho Ho

Ho Ho Ho, also known as VH-1 Presents RuPaul: Ho Ho Ho, is a 1997 Christmas album and the third studio album by American singer and drag queen RuPaul. Released on October 28, 1997 by the record label Rhino, it is RuPaul's first album featuring Christmas music and serves as a follow-up to his 1996 album "Foxy Lady". RuPaul co-produced the album with Fenton Bailey and Randy Barbato from the production company World of Wonder. "Ho Ho Ho" consists of thirteen tracks, including ten covers of Christmas standards and carols, and three original songs written by Joe Carrano and RuPaul. Music critics frequently described the album as an example of camp though RuPaul clarified that it included several more serious covers, specifically "All Alone on Christmas" and "Hard Candy Christmas".

"Ho Ho Ho" was praised by critics following its release and during retrospective reviews; its cheerful and humorous compositions were frequently cited as the album's highlights, though some commentators responded negatively to the record's use of humor and the lack of clarity in its overall message. It was included in a 2016 parody list discussing the alt-right, the "War on Christmas", and the bathroom bill. The album peaked at number 27 on the Heatseekers Albums "Billboard" chart, selling a little more than 4,000 copies in one week. To support the record, RuPaul filmed a television special as part of his VH1 talk show "The RuPaul Show" (1996).

"Ho Ho Ho" was recorded in RuPauls' living room in New York City; it was completed over the span of three days in July 1997. RuPaul attributed the album's success to his chemistry with American singer Michelle Visage, saying: "You can hear us having a good time. So whether it was a Hanukkah album or a Kwanzaa album, it didn't make a difference, because the chemistry is there." RuPaul and Visage interpreted Christmas songs as examples of camp while describing them as still holding clear messages; RuPaul explained: "Even the camp stuff still holds the true meaning of Christmas, the sweetness and the love about another year gone by." The album's record label Rhino executive promoted the album through the tagline: "Celebrate Christmas with classic holiday songs and camp, RuPaul style!"

"Ho Ho Ho" was made available on October 28, 1997 by Rhino on cassette and CD. It was rereleased as a digital download in 2009 through Rhino and Tommy Boy Records. The album was also known as "VH-1 Presents RuPaul: Ho Ho Ho". RuPaul promoted the record by headlining a 1997 Christmas special, entitled "A RuPaul Christmas Special", as a part of his VH1 talk show "The RuPaul Show". The special featured a guest appearance from American band Nirvana. RuPaul later released a second Christmas album ("Slay Belles") in 2015, after he spent years hoping to record one with producer Lucian Piane.

The opening track for "Ho Ho Ho" is "With Bells On", a "disco-influenced country" interpretation of the Dolly Parton and Kenny Rogers song of the same name. Visage is featured on the track, and sings about batteries as her only memorable Christmas present. The second track is RuPaul's re-imagining of "Rudolph, the Red-Nosed Reindeer" as "RuPaul, the Red-Nosed Drag Queen". In "All I Want For Christmas", the singer makes a list of requests for various plastic surgery procedures that he would like to receive for the holiday, including cheek implants, chin implants, and a buttock augmentation. He also recorded a cover of "All Alone on Christmas", calling it his favorite Christmas song; he clarified that he wanted to do a serious interpretation of the track.

RuPaul's covers of "I Saw Daddy Kissing Santa Claus" and "Hard Candy Christmas" were noted for their use of camp. He identified "Hard Candy Christmas" as one of the "serious ones" on the album, and said it was only considered camp due to "the fact that [he was] doing it". When recording the song, Visage was unfamiliar with its source "The Best Little Whorehouse in Texas", and sang it according to RuPaul's direction. Carol Hall, who had written the song, had described RuPaul's cover as her favorite version, and ranked it above Dolly Parton's interpretation. The album also includes a cover of "You're a Mean One, Mr. Grinch", incorporating elements from funk, and "Christmas Train (Medley)", serving as a club remix of various Christmas songs. The final track is a remix of the song "Celebrate"; the original version had previously appeared on RuPaul's second album "Foxy Lady" (1996).

Upon its release, "Ho Ho Ho" received primarily positive reviews from music critics. "Vibe"'s Shawnee Smith described the album as a "collection of reinterpretations guaranteed to lift your spirits", and commended it for its up-tempo instrumentals and ability to reverse "holiday depression". While highlighting the changes made to the songs' titles, Ken Veeder of "The Advocate" positively responded to RuPaul's interpretations of the Christmas classic in "the gay way". Veeder pointed to "I Saw Daddy Kissing Santa Claus" as his favorite track. "E! News"' Joal Ryan noted that the album was one of the most boundary-pushing Christmas releases of the year. "Billboard"'s Melinda Newman considered the album a novelty record, praising it as a more humorous example of the genre.

"Ho Ho Ho" has also been the subject of praise from several retrospective reviews. During a 2015 interview with the "Gay Times", RuPaul and Visage stated that "Ho Ho Ho" had become a "classic Christmas traditional album" alongside releases by American singers Johnny Mathis and Barbra Streisand. In a 2015 article, Idolator's Robbie Daw described it as a "yuletide classic". The same year, Darren Scott of the "Gay Times" praised it as one of his favorite Christmas albums of all time, and a writer from OutTV referred to it as a "collection of cheeky and cheerful tunes". On the other hand, in a 2017 article, Junkee's Bel Ryan felt that the album had "for the most part, fallen into the mighty chasm of obscurity".

In a 2016 retrospective review, Serene Dominic of "Tucson Weekly" jokingly included RuPaul as part of its list of artists who should not have released a Christmas album for "Ho Ho Ho". The article was written as a parody of the alt-right and the "War on Christmas", Dominic joking that the album led to the creation of the bathroom bills.

Some critics have negatively responded to RuPaul's use of humor in "Ho Ho Ho". "AllMusic"'s Thomas Erlewine criticized RuPaul's reliance on camp in the album, writing that it was "tired, predictable, and simply not funny" and that it was a "sad display from an entertainer who used to be hip, clever, and very funny". Newman questioned the effectiveness of the record's overall message, noting that RuPaul's message in the liner notes about "creating one's own family for the holidays" did not fit with the image of "Ru's Christmas panties around his ankles". While she responded positively to a majority of the songs, Newman viewed "You're A Mean One, Mr. Grinch" as an unsuccessful cover. In an interview with "Queerty", American drag queen Hedda Lettuce revealed that RuPaul's cover of "Hard Candy Christmas" was her least favorite Christmas song of all time; Lettuce said that the song "makes [him] want to shove a candy cane in [his] eye".

In the United States, "Ho Ho Ho" reached a peak position of number 27 on the Heatseekers Albums "Billboard" chart, and remained on the chart for two weeks. It sold a little more than 4,000 copies in one week. The remix of "Celebrate" peaked at number 31 on "Billboard" Dance Club Songs chart on October 11, 1997 and remained on the chart for a total of seven weeks.

Credits adapted from the liner notes of "Ho Ho Ho". All songs produced by Joe Carrano and Welcome.

Notes

Credits adapted from "AllMusic".



</doc>
<doc id="983374" url="https://en.wikipedia.org/wiki?curid=983374" title="Ankylosaurus">
Ankylosaurus

Ankylosaurus is a genus of armored dinosaur. Its fossils have been found in geological formations dating to the very end of the Cretaceous Period, about 68–66 million years ago, in western North America, making it among the last of the non-avian dinosaurs. It was named by Barnum Brown in 1908; the only species in the genus is A. magniventris. The genus name means "fused lizard", and the specific name means "great belly". A handful of specimens have been excavated to date, but a complete skeleton has not been discovered. Though other members of Ankylosauria are represented by more extensive fossil material, "Ankylosaurus" is often considered the archetypal member of its group, despite having some unusual features.

Possibly the largest-known ankylosaurid, "Ankylosaurus" is estimated to have been between long and to have weighed between . It was quadrupedal, with a broad, robust body. It had a wide, low skull, with two horns pointing backward from the back of the head, and two horns below these that pointed backward and down. Unlike other ankylosaurs, its nostrils faced sideways rather than towards the front. The front part of the jaws was covered in a beak, with rows of small, leaf-shaped teeth farther behind it. It was covered in armor plates, or osteoderms, with bony half-rings covering the neck, and had a large club on the end of its tail. Bones in the skull and other parts of the body were fused, increasing their strength, and this feature is the source of the genus name.

"Ankylosaurus" is a member of the family Ankylosauridae, and its closest relatives appear to be "Anodontosaurus" and "Euoplocephalus". "Ankylosaurus" is thought to have been a slow-moving animal, able to make quick movements when necessary. Its broad muzzle indicates it was a non-selective browser. Sinuses and nasal chambers in the snout may have been for heat and water balance or may have played a role in vocalization. The tail club is thought to have been used in defense against predators or in intraspecific combat. "Ankylosaurus" has been found in the Hell Creek, Lance, Scollard, Frenchman, and Ferris formations, but appears to have been rare in its environment. Although it lived alongside a nodosaurid ankylosaur, their ranges and ecological niches do not appear to have overlapped, and "Ankylosaurus" may have inhabited upland areas. "Ankylosaurus" also lived alongside dinosaurs such as "Tyrannosaurus", "Triceratops", and "Edmontosaurus".

"Ankylosaurus" was the largest-known ankylosaurine dinosaur and possibly the largest ankylosaurid. In 2004 the American paleontologist Kenneth Carpenter estimated that the individual with the largest-known skull (specimen CMN 8880), which is long and wide, was about long and had a hip height of about . The smallest-known skull (specimen AMNH 5214) is long and wide, and Carpenter estimated that it measured about long and about tall at the hips. In 2017, based on comparisons with more complete ankylosaurines, the Canadian paleontologists Victoria Arbour and Jordan Mallon estimated a length of for CMN 8880 and for AMNH 5214. Though the latter is the smallest specimen of "Ankylosaurus", its skull is still larger than those of any other ankylosaurins. A few other ankylosaurs reached about in length. Because the vertebrae of AMNH 5214 are not significantly larger than those of other ankylosaurines, Arbour and Mallon considered their upper range estimate of nearly for large "Ankylosaurus" too long, and suggested a length of instead. Arbour and Mallon estimated a weight of for AMNH 5214 and tentatively estimated the weight of CMN 8880 at . Benson and colleagues also estimated the weight for the animal of AMNH 5214 at in 2014. 

The structure of much of the skeleton of "Ankylosaurus", including most of the pelvis, tail, and feet, is still unknown. It was quadrupedal, and its hind limbs were longer than its forelimbs. In specimen AMNH 5895, the scapula (shoulder blade) measures long and was fused with the coracoid (a rectangular bone connected to the lower end of the scapula). It also had entheses (connective tissue) for various muscle attachments. The humerus (upper arm bone) of AMNH 5214 was short, very broad and about long. The femur (thigh bone), also from AMNH 5214, was long and very robust. While the feet of "Ankylosaurus" are incompletely known, the hindfeet probably had three toes, as is the case in advanced ankylosaurids.

The cervical vertebrae of the neck had broad neural spines that increased in height towards the body. The front part of the neural spines had well-developed entheses, which was common among adult dinosaurs, and indicates the presence of large ligaments, which helped support the massive head. The dorsal vertebrae of the back had centra (or bodies) that were short relative to their width, and their neural spines were short and narrow. The dorsal vertebrae were tightly spaced, which limited the downwards movement of the back. The neural spines had ossified (turned to bone) tendons, which also overlapped some of the vertebrae. The ribs of the last four back vertebrae were fused to them, and the ribcage was very broad in this part of the body. The ribs had scars that show where muscles attached to them. The caudal vertebrae of the tail had centra that were slightly amphicoelous, meaning they were concave on both sides.

The three known "Ankylosaurus" skulls differ in various details; this is thought to be the result of taphonomy (changes happening during decay and fossilization of the remains) and individual variation. The skull was low and triangular in shape, and wider than it was long; the back of the skull was broad and low. The skull had a broad beak on the premaxillae. The orbits (eye sockets) were almost round to slightly oval and did not face directly sideways because the skull tapered towards the front. The braincase was short and robust, as in other ankylosaurines. Crests above the orbits merged into the upper squamosal horns (their shape has been described as "pyramidal"), which pointed backwards to the sides from the back of the skull. The crest and horn were probably separate elements originally, as seen in the related "Pinacosaurus" and "Euoplocephalus". Below the upper horns, jugal horns were present, which pointed backward and down. The horns may have originally been osteoderms (armor plates) that fused to the skull. The scale-like pattern on the skull surface (called "caputegulae" in ankylosaurs) was the result of remodeling of the skull itself. This obliterated the sutures between skull elements, which is common for adult ankylosaurs. The scale pattern of the skull was variable between specimens, though some details are shared. "Ankylosaurus" had a diamond-shaped (or hexagonal) internarial scale at the front of the snout between the nostrils, two squamosal osteoderms above the orbit, and a ridge of scales at the back of the skull.

The snout region of "Ankylosaurus" was unique among ankylosaurs, and had undergone an "extreme" transformation compared to its relatives. The snout was arched and truncated at the front, and the nostrils were elliptical and were directed downward and outward, unlike in all other known ankylosaurids where they faced obliquely forward or upward. Additionally, the nostrils were not visible from the front because the sinuses were expanded to the sides of the premaxilla bone, to a larger extent than seen in other ankylosaurs. Large loreal caputegulae—strap-like, side osteoderms of the snout—completely roofed the enlarged opening of the nostrils, giving a bulbous appearance. The nostrils also had an intranarial septum, which separated the nasal passage from the sinus. Each side of the snout had five sinuses, four of which expanded into the maxilla bone. The nasal cavities (or chambers) of "Ankylosaurus" were elongated and separated by a septum at the midline, which divided the inside of the snout into two mirrored halves. The septum had two openings, including the choanae (internal nostrils).

The maxillae expanded to the sides, giving the impression of a bulge, which may have been due to the sinuses inside. The maxillae had a ridge that may have been the attachment site for fleshy cheeks; the presence of cheeks in ornithischians is controversial, but some nodosaurid ankylosaurs had armor plates that covered the cheek region, which may have been embedded in the flesh. Specimen AMNH 5214 has 34–35 dental alveoli (tooth sockets) in the maxilla and has more teeth than any other known ankylosaurid. The tooth rows in the maxillae of this specimen are about long. Each alveolus had a foramen (opening) near its side where a replacement tooth could be seen.

Compared to other ankylosaurs, the mandible of "Ankylosaurus" was low in proportion to its length, and, when seen from the side, the tooth row was almost straight instead of arched. The mandibles are completely preserved only in the smallest specimen (AMNH 5214) and are about long. The incomplete mandible of the largest specimen (CMN 8880) is the same length. AMNH 5214 has 35 dental alveoli in the left dentary and 36 in the right, for a total of 71, the highest number known for any ankylosaurid. The predentary bone of the tip of the mandibles has not yet been found. The tooth row was relatively short. Like other ankylosaurs, "Ankylosaurus" had small, phylliform (leaf-shaped) teeth, which were compressed sideways. The teeth were mostly taller than they were wide, and were very small; their size in proportion to the skull meant that the jaws could accommodate more teeth than other ankylosaurines. The teeth of the largest "Ankylosaurus" skull are smaller than those of the smallest skull in the absolute sense. Some teeth from behind in the tooth row curved backwards, and tooth crowns were usually flatter on one side than the other. "Ankylosaurus" teeth are diagnostic and can be distinguished from the teeth of other ankylosaurids based on their smooth sides. The denticles were large, their number ranging from six to eight on the front part of the tooth, and five to seven behind.

A prominent feature of "Ankylosaurus" was its armor, consisting of knobs and plates of bone known as osteoderms, or scutes, embedded in the skin. These have not been found in articulation, so their exact placement on the body is unknown, though inferences can be made based on related animals, and various configurations have been proposed. The osteoderms ranged from in diameter to in length, and varied in shape. The osteoderms of "Ankylosaurus" were generally thin walled and hollowed on the underside. Compared to "Euoplocephalus", the osteoderms of "Ankylosaurus" were smoother. Small osteoderms and ossicles probably occupied the space between the larger ones. The osteoderms covering the body were very flat, though with a low keel at one margin. In contrast, the nodosaurid "Edmontonia" had high keels stretching from one margin to the other on the midline of its osteoderms. "Ankylosaurus" had some smaller osteoderms with a keel across the midline. 

Like other ankylosaurids, "Ankylosaurus" had cervical half-rings (armor plates on the neck), but these are known only from fragments, making their exact arrangement uncertain. Carpenter suggested that when seen from above, the plates would have been paired, creating an inverted V-shape across the neck, with the midline gap probably being filled with small ossicles (round bony scutes) to allow for movement. He believed the width of this armor belt was too wide to have fitted solely on the neck, and that it covered the base of the neck and continued onto the shoulder region. Arbour and Philip J. Currie disagreed with Carpenter's interpretation in 2015 and pointed out that the cervical half-ring fragments of specimen AMNH 5895 did not fit together in the way proposed by Carpenter (though this could be due to breakage). They instead suggested that the fragments represented the remains of two cervical half-rings, which formed two semi-circular plates of armor around the upper part of the neck, as in the closely related "Anodontosaurus" and "Euoplocephalus". Arbour and Mallon elaborated on this idea, describing the shape of these half-rings as "continuous U-shaped yokes" over the upper part of the neck, and suggested that "Ankylosaurus" had six keeled osteoderms with oval bases on each half-ring. Other ankylosaurids often have many smaller osteoderms surrounding these larger ones.

The first osteoderms behind the second cervical half-ring would have been similar in shape to those in the half-ring, and the osteoderms on the back probably decreased in diameter hindwards. The largest osteoderms were probably arranged in transverse and longitudinal rows across most of the body, with four or five transverse rows separated by creases in the skin. The osteoderms on the flanks would probably have had a more square outline than those on the back. There may have been four longitudinal rows of osteoderms on the flanks. Unlike some basal ankylosaurs and many nodosaurs, ankylosaurids do not appear to have had co-ossified pelvic shields above their hips. Some osteoderms without keels may have been placed above the hip region of "Ankylosaurus", as in "Euoplocephalus". "Ankylosaurus" may have had three or four transverse rows of circular osteoderms over the pelvic region, which were smaller than those on the rest of the body, as in "Scolosaurus". Smaller, triangular osteoderms may have been present on the sides of the pelvis. Flattened, pointed plates resemble those on the sides of the tail of "Saichania". Osteoderms with oval keels could have been placed on the upper side of the tail or the side of the limbs. Compressed, triangular osteoderms found with "Ankylosaurus" specimens may have been placed on the sides of the pelvis or the tail. Ovoid, keeled, and teardrop-shaped osteoderms are known from "Ankylosaurus", and may have been placed on the forelimbs, like those known from "Pinacosaurus", but it is unknown whether the hindlimbs bore osteoderms. 

The tail club (or tail knob) of "Ankylosaurus" was composed of two large osteoderms, with a row of small osteoderms at the midline, and two small osteoderms at the tip; these osteoderms obscured the last tail vertebra. As only the tail club of specimen AMNH 5214 is known, the range of variation between individuals is unknown. The tail club of AMNH 5214 is long, wide, and tall. The club of the largest specimen may have been wide. The tail club of "Ankylosaurus" was semicircular when seen from above, similar to those of "Euoplocephalus" and "Scolosaurus" but unlike the pointed club osteoderms of "Anodontosaurus" or the narrow, elongated club of "Dyoplosaurus". The last seven tail vertebrae formed the "handle" of the tail club. These vertebrae were in contact, with no cartilage between them, and were sometimes co-ossified, which made them immobile. Ossified tendons attached to the vertebrae in front of the tail club, and these features together helped strengthen it. The interlocked zygapophyses (articular processes) and neural spines of the handle vertebrae were U-shaped when seen from above, whereas those of most other ankylosaurids are V-shaped, which may be due to the handle of "Ankylosaurus" being wider. The larger width may indicate that the tail of "Ankylosaurus" was shorter in relation to its body length than those of other ankylosaurids, or that it had the same proportions but with a smaller club.

In 1906, an American Museum of Natural History expedition led by paleontologist Barnum Brown discovered the type specimen of "Ankylosaurus magniventris" (AMNH 5895) in the Hell Creek Formation, near Gilbert Creek, Montana. The specimen (found by collector Peter Kaisen) consisted of the upper part of a skull, two teeth, part of the shoulder girdle, cervical, dorsal, and caudal vertebrae, ribs, and more than thirty osteoderms. Brown scientifically described the animal in 1908; the genus name is derived from the Greek words /"ankulos" ('bent' or 'crooked'), referring to the medical term ankylosis, the stiffness produced by the fusion of bones in the skull and body, and /"sauros" ('lizard'). The name can be translated as "fused lizard", "stiff lizard", or "curved lizard". The type species name "magniventris" is derived from the ('great') and ('belly'), referring to the great width of the animal's body.

The skeletal reconstruction accompanying the 1908 description restored the missing parts in a fashion similar to "Stegosaurus", and Brown likened the result to the extinct armored mammal "Glyptodon". In contrast to modern depictions, Brown's stegosaur-like reconstruction showed robust forelimbs, a strongly arched back, a pelvis with prongs projecting forwards from the ilium and pubis, as well as a short, drooping tail without a tail club, which was unknown at the time. Brown also reconstructed the armor plates in parallel rows running down the back; this arrangement was purely hypothetical. Brown's reconstruction became highly influential, and restorations of the animal based on his diagram were published as late as the 1980s. In a 1908 review of Brown's "Ankylosaurus" description, American paleontologist Samuel Wendell Williston criticised the skeletal reconstruction as being based on too few remains, and claimed that "Ankylosaurus" was merely a synonym of the genus "Stegopelta", which Williston had named in 1905. Williston also stated that a skeletal reconstruction of the related "Polacanthus" by Hungarian paleontologist Franz Nopcsa was a better example of how ankylosaurs would have appeared in life. The claim of synonymy was not accepted by other researchers, and the two genera are now considered distinct.

Brown had collected 77 osteoderms while excavating a "Tyrannosaurus" specimen in the Lance Formation of Wyoming in 1900. He mentioned these osteoderms (specimen AMNH 5866) in his description of "Ankylosaurus" but thought they belonged to the "Tyrannosaurus" instead. Paleontologist Henry Fairfield Osborn also expressed this view when he described the "Tyrannosaurus" specimen as the now invalid genus "Dynamosaurus" in 1905. More recent examination has shown them to be similar to those of "Ankylosaurus"; it seems that Brown had compared them with some "Euoplocephalus" osteoderms, which had been erroneously cataloged as belonging to "Ankylosaurus" at the AMNH.

In 1910 another AMNH expedition led by Brown discovered an "Ankylosaurus" specimen (AMNH 5214) in the Scollard Formation by the Red Deer River in Alberta, Canada. This specimen included a complete skull, mandibles, the first and only tail club known of this genus, as well as ribs, vertebrae, limb bones, and armor. In 1947 fossil collectors Charles M. Sternberg and T. Potter Chamney collected a skull and mandible (specimen CMN 8880, formerly NMC 8880), a kilometer (0.6 mile) north of where the 1910 specimen was found. This is the largest-known "Ankylosaurus" skull, but it is damaged in places. A section of caudal vertebrae (specimen CCM V03) was discovered in the 1960s in the Powder River drainage, Montana, part of the Hell Creek Formation. In addition to these five incomplete specimens, many other isolated osteoderms and teeth have been found.

In 1990 American paleontologist Walter P. Coombs pointed out that the teeth of two skulls assigned to "A. magniventris" differed from those of the holotype specimen in some details, and though he expressed a "considerate temptation" to name a new species of "Ankylosaurus" for these, he refrained from doing so, as the range of variation in the species was not completely documented. He also raised the possibility that the two teeth associated with the holotype specimen perhaps did not belong to it, as they were found in matrix within the nasal chambers. Carpenter accepted the teeth as belonging to "A. magniventris", and that all the specimens belonged to the same species, noting that the teeth of other ankylosaurs are highly variable.

Most of the known "Ankylosaurus" specimens were not scientifically described at length, though several paleontologists planned to do so until Carpenter redescribed the genus in 2004. Carpenter noted that "Ankylosaurus" has become the archetypal member of its group, and the best-known ankylosaur in popular culture, perhaps due to a life-sized reconstruction of the animal being featured at the 1964 World's Fair in New York City. That sculpture, as well as the American artist Rudolph Zallinger's 1947 mural "The Age of Reptiles" and other later popular depictions, showed "Ankylosaurus" with a tail club, following the first discovery of this feature in 1910. In spite of its familiarity, it is known from far fewer remains than its closest relatives. In 2017 Arbour and Mallon redescribed the genus in light of newer ankylosaur discoveries, including elements of the holotype that had not been previously mentioned in the literature (such as parts of the skull and the cervical half-rings). They concluded that though "Ankylosaurus" is iconic and the best-known member of its group, it was bizarre in comparison to related ankylosaurs, and therefore not representative of the group.

Many traditional popular depictions show "Ankylosaurus" in a squatting posture and with a huge tail club being dragged over the ground. Modern reconstructions show the animal with a more upright limb posture and with the tail held off the ground. Likewise, large spines projecting sideways from the body (similar to those of nodosaurs) are present in many traditional depictions, but are not known from "Ankylosaurus" itself. The armor of "Ankylosaurus" has often been conflated with that of "Edmontonia" (earlier referred to as "Palaeoscincus"); in addition to "Ankylosaurus" being depicted with spikes, "Edmontonia" has also been depicted with an "Ankylosaurus"-like tail club (a feature nodosaurids did not have), including in a mural by the American artist Charles R. Knight from 1930.

Brown considered "Ankylosaurus" so distinct that he made it the type genus of a new family, Ankylosauridae, typified by massive, triangular skulls, short necks, stiff backs, broad bodies, and osteoderms. He also classified "Palaeoscincus" (only known from teeth), and "Euoplocephalus" (then only known from a partial skull and osteoderms) as part of the family. Due to the fragmentary condition of the remains, Brown was unable to fully distinguish between "Euoplocephalus" and "Ankylosaurus". Having for comparison only a few, incomplete members of the family, he believed the group was part of the suborder Stegosauria. In 1923 Osborn coined the name Ankylosauria, thereby placing the ankylosaurids in their own suborder.

Ankylosauria and Stegosauria are now grouped together within the clade Thyreophora. This group first appeared in the Sinemurian age, and survived for 135 million years until disappearing in the Maastrichtian. They were widespread and inhabited a broad range of environments. As more complete specimens and new genera have been discovered, theories about ankylosaurian interrelatedness have become more complex, and hypotheses have often changed between studies. In addition to Ankylosauridae, Ankylosauria has been divided into the families Nodosauridae, and sometimes Polacanthidae (these families lacked tail clubs). "Ankylosaurus" is considered part of the subfamily Ankylosaurinae (members of which are called ankylosaurines) within Ankylosauridae. "Ankylosaurus" appears to be most closely related to "Anodontosaurus" and "Euoplocephalus". The following cladogram is based on a 2015 phylogenetic analysis of the Ankylosaurinae conducted by Arbour and Currie:

Since "Ankylosaurus" and other Late Cretaceous North American ankylosaurids grouped with Asian genera (in a tribe the authors named Ankylosaurini), Arbour and Currie suggested that earlier North American ankylosaurids had gone extinct by the late Albian or Cenomanian ages of the Middle Cretaceous. Ankylosaurids thereafter recolonized North America from Asia during the Campanian or Turonian ages of the Late Cretaceous, and there diversified again, leading to genera such as "Ankylosaurus", "Anodontosaurus", and "Euoplocephalus". This explains a 30-million-year gap in the fossil record of North American ankylosaurids between these ages.

Like other ornithischians, "Ankylosaurus" was herbivorous. Its wide muzzle was adapted for non-selective low-browse cropping, although not to the extent seen in some related genera, especially "Euoplocephalus". Though ankylosaurs may not have fed on fibrous and woody plants, they may have had a varied diet, including tough leaves and pulpy fruits. "Ankylosaurus" probably fed on abundant ferns and low-growing shrubs. Assuming it was endothermic, "Ankylosaurus" would have eaten of ferns per day, similar to the amount of dry vegetation a large elephant would consume. The requirements for nutrition could have been more effectively met if "Ankylosaurus" ate fruit, which its small, cusp-like teeth and the shape of its beak seem well adapted for, compared to for example "Euoplocephalus". Certain invertebrates, which the small teeth may have been adapted for handling, could also have provided supplemental nutrition.

Fossils of "Ankylosaurus" teeth exhibit wear on the face of the crown rather than on the tip of the crown, as in nodosaurid ankylosaurs. In 1982 Carpenter ascribed to baby "Ankylosaurus" two very small teeth that originate from the Lance and Hell Creek Formations and measure in length, respectively. The smaller tooth is heavily worn, leading Carpenter to suggest that ankylosaurids in general or at least the young did not swallow their food whole but employed some sort of chewing. Since adult "Ankylosaurus" did little chewing of its food, it would have spent less time in the day foraging than an elephant. Based on the broadness of the ribcage, the digestion of unchewed food may have been facilitated by hindgut fermentation like in modern herbivorous lizards, which have several chambers in their enlarged colon.
In 1969 Austrian paleontologist Georg Haas concluded that despite the large size of ankylosaur skulls, the associated musculature was relatively weak. He also thought jaw movement was limited to up and down movements. Extrapolating from this, Haas suggested that ankylosaurs ate relatively soft non-abrasive vegetation. Later research on "Euoplocephalus" indicates that forward and sideways jaw movement was possible in these animals, the skull being able to withstand considerable forces. A 2016 study of the dental occlusion (contact between the teeth) of ankylosaur specimens found that the ability for backwards (palinal) jaw movement evolved independently in different ankylosaur lineages, including Late Cretaceous North American ankylosaurids like "Ankylosaurus" and "Euoplocephalus".

A specimen of the ankylosaur "Pinacosaurus" preserves large paraglossalia (triangular bones or cartilages located in the tongue) that show signs of muscular stress, and it is thought this was a common feature of ankylosaurs. The researchers who examined the specimen suggested that ankylosaurs relied heavily on muscular tongues and hyobranchia (tongue bones) when feeding since their teeth were fairly small and were replaced at a relatively slow rate. Some modern salamanders have similar tongue bones, and use prehensile tongues to pick up food. The retracted position of the nostrils of "Ankylosaurus" have been compared to those of fossorial (digging) worm lizards and blind snakes, and though it was probably not a burrowing animal, the snout of "Ankylosaurus" may indicate earth-moving behavior. These factors, as well as the low rate of tooth formation in ankylosaurs compared to other ornithischians, indicate that "Ankylosaurus" may have been omnivorous (eating both plant and animal matter). It may also (or alternatively) have dug in the ground for roots and tubers.

In 1977 Polish paleontologist Teresa Maryańska proposed that the complex sinuses and nasal cavities of ankylosaurs may have lightened the weight of the skull, housed a nasal gland, or acted as a chamber for vocal resonance. Carpenter rejected these hypotheses, arguing that tetrapod animals make sounds through the larynx, not the nostrils, and that reduction in weight was minimal, as the spaces only accounted for a small percent of the skull volume. He also considered a gland unlikely and noted that the sinuses may not have had any specific function. It has also been suggested that the respiratory passages were used to perform a mammal-like treatment of inhaled air, based on the presence and arrangement of specialized bones.

A 2011 study of the nasal passages of "Euoplocephalus" supported their function as a heat and water balancing system, noting the extensive blood vessel system and an increased surface area for the mucosa membrane (used for heat and water exchange in modern animals). The researchers also supported the idea of the loops acting as a resonance chamber, comparable to the elongated nasal passages of saiga antelope and the looping trachea of cranes and swans. Reconstructions of the inner ear suggest adaptation to hearing at low frequencies, such as the low-toned resonant sounds possibly produced by the nasal passages. They disputed the possibility that the looping is related to olfaction (sense of smell) as the olfactory region is pushed to the sides of the main airway.

The shape of the nasal chambers of "Ankylosaurus" indicate that airflow was unidirectional (looping through the lungs during inhalation and exhalation), although it may also have been bidirectional in the posterior nasal chamber, with air directed past the olfactory lobes. The enlarged olfactory region of ankylosaurids indicates a well-developed sense of smell, and the position of the orbits of "Ankylosaurus" suggest some stereoscopic vision. Though hindwards retraction of the nostrils is seen in aquatic animals and animals with a proboscis, it is unlikely either possibility applies to "Ankylosaurus", as the nostrils tend to be reduced or the premaxilla extended. In addition, though the widely separated nostrils may have allowed for stereo-olfaction (where each nostril senses smells from different directions), as has been proposed for the moose, little is known about this feature.

Reconstructions of ankylosaur forelimb musculature made by Coombs in 1978 suggest that the forelimbs bore the majority of the animal's weight, and were adapted for high force delivery on the front feet, possibly for food gathering. In addition, Coombs suggested that ankylosaurs may have been capable diggers, though the hoof-like structure of the manus would have limited fossorial activity. Ankylosaurs were likely to have been slow-moving and sluggish animals, though they may have been capable of quick movements when necessary.

The squamosal horns of the largest "Ankylosaurus" specimen are blunter than those of the smallest specimen, which is also the case in "Euoplocephalus", and this may represent ontogenetic variation (related to growth development). Studies of specimens of "Pinacosaurus" of different ages found that during ontogenetic development, the ribs of juvenile ankylosaurs fused with their vertebrae. The forelimbs strongly increased in robustness while the hindlimbs did not become larger relative to the rest of the skeleton, further evidence that the arms bore most of the weight. In the cervical half-rings, the underlying bone band developed outgrowths connecting it with the underlying osteoderms, which simultaneously fused to each other. On the skull, the middle bone plates first ossified at the snout and the rear rim, with ossification gradually extending towards the middle regions. On the rest of the body, ossification progressed from the neck backward in the direction of the tail.

The osteoderms of ankylosaurids were thin in comparison to those of other ankylosaurs, and appear to have been strengthened by randomly distributed cushions of collagen fibers. Structurally similar to Sharpey's fibres, they were embedded directly into the bone tissue, a feature unique to ankylosaurids. This would have provided the ankylosaurids with an armor covering that was both lightweight and highly durable, being resistant to breakage and penetration by the teeth of predators. The palpebral bones over the eyes may have provided additional protection for them. Carpenter suggested in 1982 that the heavily vascularized armor may also have had a role in thermoregulation as in modern crocodilians.

The tail club of "Ankylosaurus" seems to have been an active defensive weapon, capable of producing enough of an impact to break the bones of an assailant. The tendons of the tail were partially ossified and were not very elastic, allowing great force to be transmitted to the club when it was used as a weapon. Coombs suggested in 1979 that several hindlimb muscles would have controlled the swinging of the tail, and that violent thrusts of the club would have been able to break the metatarsal bones of large theropods. A 2009 study estimated that ankylosaurids could swing their tails at 100 degrees laterally, and the mainly cancellous clubs would have had a lowered moment of inertia and been effective weapons. The study also found that while adult ankylosaurid tail clubs were capable of breaking bones, those of juveniles were not. Despite the feasibility of tail-swinging, the researchers could not determine whether ankylosaurids used their clubs for defense against potential predators, in intraspecific combat, or both.

In 1993 Tony Thulborn proposed that the tail club of ankylosaurids primarily acted as a decoy for the head, as he thought the tail too short and inflexible to have an effective reach; the "dummy head" would lure a predator close to the tail, where it could be struck. Carpenter has rejected this idea, as tail club shape is highly variable among ankylosaurids, even in the same genus.

"Ankylosaurus" existed between 68 and 66 million years ago, in the final, or Maastrichtian, stage of the Late Cretaceous Period. It was among the last dinosaur genera that appeared before the Cretaceous–Paleogene extinction event. The type specimen is from the Hell Creek Formation of Montana, while other specimens have been found in the Lance and Ferris Formations in Wyoming, the Scollard Formation in Alberta, and the Frenchman Formation in Saskatchewan, all of which date to the end of the Cretaceous.

Fossils of "Ankylosaurus" are rare in these sediments, and the distribution of its remains suggests that it was ecologically rare, or restricted to the uplands of the formations rather than the coastal lowlands, where it would have been more likely to fossilize. Another ankylosaur, a nodosaur referred to as "Edmontonia" sp., is also found in the same formations, but according to Carpenter, the range of the two genera does not seem to have overlapped. Their remains have so far not been found in the same localities, and the nodosaur appears to have inhabited the lowlands. The narrower muzzle of the nodosaur suggests it had a more selective diet than "Ankylosaurus", further indicating ecological separation, whether their range overlapped or not.

With its low center of gravity, "Ankylosaurus" would have been unable to knock down trees like modern elephants do. It was also incapable of chewing bark and thus unlikely to have practiced bark stripping. As an adult, "Ankylosaurus" does not appear to have congregated in groups (though some ankylosaurs appear to have congregated when young). So, although it was a large herbivore with similar energetic requirements, it is therefore improbable that "Ankylosaurus" was able to modify the landscape of its ecosystem in the way elephants do; hadrosaurids may instead have had such an "ecosystem engineer" role.

The formations where "Ankylosaurus" fossils have been found represent different sections of the western shore of the Western Interior Seaway dividing western and eastern North America during the Cretaceous, a broad coastal plain extending westward from the seaway to the newly formed Rocky Mountains. These formations are composed largely of sandstone and mudstone, which have been attributed to floodplain environments. The regions where "Ankylosaurus" and other Late Cretaceous ankylosaurs have been found had a warm subtropical/temperate climate, which was monsoonal, had occasional rainfall, tropical storms, and forest fires. In the Hell Creek Formation, many types of plants were supported, primarily angiosperms, with less common conifers, ferns and cycads. An abundance of fossil leaves found at dozens of different sites indicates that the area was largely forested by small trees. "Ankylosaurus" shared its environment with other dinosaurs that included the ceratopsids "Triceratops" and "Torosaurus", the hypsilophodont "Thescelosaurus", the hadrosaurid "Edmontosaurus", an indeterminate nodosaur, the pachycephalosaurian "Pachycephalosaurus", and the theropods "Struthiomimus", "Ornithomimus", "Pectinodon", and "Tyrannosaurus".


Notes

Citations


</doc>
<doc id="986788" url="https://en.wikipedia.org/wiki?curid=986788" title="Hurricane Diane">
Hurricane Diane

Hurricane Diane was the costliest Atlantic hurricane of its time. One of three hurricanes to hit North Carolina during the 1955 Atlantic hurricane season, it formed on August 7 from a tropical wave between the Lesser Antilles and Cape Verde. Diane initially moved west-northwestward with little change in its intensity, but began to strengthen rapidly after turning to the north-northeast. On August 12, the hurricane reached peak sustained winds of 105 mph (165 km/h), making it a Category 2 hurricane. Gradually weakening after veering back west, Diane made landfall near Wilmington, North Carolina, as a strong tropical storm on August 17, just five days after Hurricane Connie struck near the same area. Diane weakened further after moving inland, at which point the United States Weather Bureau noted a decreased threat of further destruction. The storm turned to the northeast, and warm waters from the Atlantic Ocean helped produce record rainfall across the northeastern United States. On August 19, Diane emerged into the Atlantic Ocean southeast of New York City, becoming extratropical two days later and completely dissipating by August 23.

The first area affected by Diane was North Carolina, which suffered coastal flooding but little wind and rain damage. After the storm weakened in Virginia, it maintained an area of moisture that resulted in heavy rainfall after interacting with the Blue Ridge Mountains, a process known as orographic lift. Flooding affected roads and low-lying areas along the Potomac River. The northernmost portion of Delaware also saw freshwater flooding, although to a much lesser extent than adjacent states. Diane produced heavy rainfall in eastern Pennsylvania, causing the worst floods on record there, largely in the Poconos and along the Delaware River. Rushing waters demolished about 150 road and rail bridges and breached or destroyed 30 dams. The swollen Brodhead Creek virtually submerged a summer camp, killing 37 people. Throughout Pennsylvania, the disaster killed 101 people and caused an estimated $70 million in damage (1955 USD). Additional flooding spread through the northwest portion of neighboring New Jersey, forcing hundreds of people to evacuate and destroying several bridges, including one built in 1831. Storm damage was evident but less significant in southeastern New York.

Damage from Diane was heaviest in Connecticut, where rainfall peaked at 16.86 in (428 mm) near Torrington. The storm produced the state's largest flood on record, which effectively split the state into two by destroying bridges and cutting communications. All major streams and valleys were flooded, and 30 stream gauges reported their highest levels on record. The Connecticut River at Hartford reached a water level of 30.6 ft (9.3 m), the third highest on record there. The flooding destroyed a large section of downtown Winsted, much of which was never rebuilt. Record-high tides and flooded rivers heavily damaged Woonsocket, Rhode Island. In Massachusetts, flood water levels surpassed those during the 1938 Long Island hurricane, breaching multiple dams and inundating adjacent towns and roads. Throughout New England, 206 dams were damaged or destroyed, and about 7,000 people were injured. Nationwide, Diane killed at least 184 people and destroyed 813 houses, with another 14,000 homes heavily damaged. Monetary losses totaled $754.7 million, although the inclusion of loss of business and personal revenue increased the total to over $1 billion. In the hurricane's wake, eight states were declared federal disaster areas, and the name Diane was retired.

Hurricane Diane originated in a tropical wave first observed as a tropical depression on August 7 between the Lesser Antilles and Cape Verde. The system moved generally to the west-northwest, intensifying into a tropical storm on August 9. By the time the Weather Bureau first classified the storm on August 10, Diane was south of the Bermuda high, a semi-permanent ridge in the jet stream just east of Nova Scotia. Ships in the region of the storm reported winds of . During the next day, the Hurricane Hunters reported no increase in strength, and Diane initially remained disorganized. The storm interacted with Hurricane Connie to its northwest in a process known as the Fujiwhara effect, in which Diane turned toward the north. Quick intensification ensued, potentially due to interaction with a cold-core low that increased atmospheric instability. On August 12, the storm rapidly intensified into a hurricane. The intensification was so quick that a ship southeast of the center believed Diane was undergoing a loop due to a steady drop in barometric pressure, despite moving away from the hurricane.

At its peak, Diane developed a well-defined eye about in diameter, described by reconnaissance aircraft as taking the shape of an "inverted teacup". The strongest winds were located in the northeast quadrant, where there was a secondary pressure minimum located northeast of the eye. After moving to the north for about a day, Diane resumed its westward motion on August 13, after Hurricane Connie to the northwest had weakened. That day, Diane reached its lowest pressure of , and peak winds of 105 mph (170 km/h); originally the hurricane was analyzed to reach peak winds of 120 mph (195 km/h), although the large size and slow forward speed suggested the lower winds. It maintained its peak winds for about 12 hours, after which it weakened due to cooler air in the region. By August 15, the eye had become poorly defined, and winds steadily weakened. As it approached land, its center deteriorated, with minimal precipitation near the center; the eye was observed on a radar installed in July 1955. On August 17, Diane made landfall on the coast of North Carolina near Wilmington. Pressure at landfall was estimated at , accompanied by winds just under hurricane intensity. Diane struck the state only five days after Hurricane Connie struck the same general area.

Diane quickly weakened as a tropical storm over the mountainous terrain of central North Carolina. The associated area of precipitation expanded and spread away from the center to the north and northeast. The weakening system turned to the north and recurved toward the northeast through Virginia after a ridge built in from the west. It did not interact much with the non-tropical westerlies, and as a result it remained a distinct tropical cyclone over land. Convection redeveloped as the storm approached the Atlantic coast once again. Diane passed through the Mid-Atlantic states, exiting New Jersey on August 19 into the Atlantic Ocean southeast of New York City. Paralleling the southern coast of New England, the storm later accelerated east-northeastward, becoming extratropical on August 21. Passing south and east of Newfoundland, the remnants of Diane accelerated and restrengthened slightly while moving to the northeast. Late on August 23, the storm dissipated between Greenland and Iceland.

Late on August 14, more than two days before Diane made landfall, the United States Weather Bureau issued a hurricane alert from Georgia through North Carolina. On August 15, the agency issued a hurricane warning from Brunswick, Georgia to Wilmington, North Carolina, although the warning was later extended to the south and north to Fernandina, Florida and Cape Hatteras, North Carolina, respectively. The agency also issued storm warnings southward to Saint Augustine, Florida and northward to Atlantic City, New Jersey, including the Chesapeake and Delaware bays. Throughout the warned region, small ships were advised to remain at port. Before Diane made landfall, the North Carolina National Guard assisted in evacuating people near the Pamlico River, and 700 residents left their homes near New Bern; thousands of tourists also evacuated. The threat of the hurricane forced the planned retirement ceremony for Admiral Robert Carney to be transferred from an aircraft carrier in Norfolk, Virginia to an academy dormitory. All aircraft at Marine Corps Air Station Cherry Point were flown to safer locations further inland.

All hurricane warnings were dropped after Diane moved inland. Forecasters downplayed the threat of Diane after it weakened over Virginia; the Weather Bureau agreed they did not foresee the extent of the rain that would occur, instead calling for just "some local flooding". The agency later admitted they "goofed" in downplaying the storm's destructive potential after weakening, noting their lack of experience with extreme rainfall events. Once the storm moved ashore, the Weather Bureau transferred official forecasting duties to regional offices, and local newspapers also issued their own forecasts. The Springfield Daily News in Massachusetts noted that "moderate rains [were] possible" in its daily weather forecast ahead of the storm. Still, flood warnings were issued, with stream flooding forecasts of over 12 hours in advance. Along smaller rivers, including the Lehigh, Schuylkill, and Farmington, forecasts were issued every few hours.

In the summer of 1955, the eastern United States experienced generally hot and dry weather, leading to drought conditions and decreased water levels. When Hurricane Connie struck, its rainfall moistened the soil and heightened creeks throughout the Mid-Atlantic and New England. Hurricane Diane struck North Carolina just five days later and affected the same general area. After floods in 1936, the United States federal government enacted plans to prevent future devastating floods, although they made no progress by the time Connie and Diane struck in 1955. Along the Delaware River in the 1930s, state legislatures in New Jersey and Pennsylvania had established a commission that worked to clean up polluted water, but the legislators and commission blocked federal help, comparing it to European socialism; this was in contrast to the federally funded Tennessee Valley Authority, which mitigated flooding along the Tennessee River.

Hurricane Diane's path over the eastern United States brought heavy rainfall, fueled by unusually moist air resulting from abnormally high sea surface temperatures. The worst flooding was in eastern Pennsylvania, northern New Jersey, southeastern New York, and southern New England. Of the 287 stream gauges in the region, 129 reported record levels during the course of the event. Many streams reported discharge rates of more than double the previous records. Most of the flooding occurred along small rivers that rose to flood stage within hours, largely impacting populated areas; there were around 30 million people in the region affected by the floods. Overall, 813 houses were destroyed, with 14,000 heavily damaged. The floods severed infrastructure and affected several summer camps. Damage to public utilities was estimated at $79 million. Flooding in rural areas resulted in landslides in the mountains, while destroyed crops cost an estimated $7 million. Hundreds of miles of roads and bridges were also destroyed, accounting for $82 million in damage. Damage from Diane's winds were generally minor. The hurricane caused $754,706,000 in damage (1955 USD), of which $600 million was in New England, making it the costliest hurricane in American history at the time. Taking into account indirect losses, such as loss of wages and business earnings, Diane was described as "the first billion dollar hurricane." This contributed to 1955 being the costliest Atlantic hurricane season on record at the time. Overall, there were at least 184 deaths, potentially as many as 200.

The strongest sustained winds associated with Diane's landfall in North Carolina reached in Hatteras, with gusts to in Wilmington. Any hurricane-force gusts were likely very sporadic and isolated in nature. Tides ran above normal near Wilmington, and waves in height struck the coast. The resultant storm surge damaged beach houses, flooded coastal roads, and destroyed seawalls damaged by Hurricane Connie a few days prior. The center of the hurricane passed over Wilmington without much of a decrease in winds, suggesting the eye was disorganized or even nonexistent. Little precipitation fell in and around the city, though precipitation was more substantial elsewhere in the state, peaking at in New Bern. At Oakway in neighboring South Carolina, rainfall amounted to .

After Diane crossed into Virginia, it dropped heavy rainfall of over in 24 hours in the Blue Ridge Mountains, peaking at in Big Meadows. There, the rains were enhanced by moist air rising over the mountain peaks and condensing, a process known as orographic lift. Rainfall of over occurred throughout Virginia, as well as into the Eastern Panhandle of West Virginia, where was reported at Stony River Reservoir. Similar precipitation amounts fell through Delaware, including at the National Arboretum in Washington, D.C. Rivers across the region rose above flood stage, including the James River which crested at in Columbia, Virginia, which was above flood stage. High amounts of rainfall accrued in eastern Pennsylvania, peaking at in Pecks Pond in the northeast portion of the state. As with Virginia, the heaviest rainfall occurred due to orographic lift near a mountain. In neighboring New Jersey, the highest precipitation was near Sussex. Rainfall in New York peaked at in Lake Mohonk.

In Virginia, severe flooding occurred near Richmond and along the Blue Ridge Mountains. Near the coast, Diane damaged large areas of farmlands due to slow-moving floods. In the state, 21 gauges reported their highest levels on record. High levels along the Potomac River flooded low-lying portions of Virginia and Washington, D.C. Wind gusts reached in Roanoke. In the state, flooding covered several roads, prompting closures. Due to the flat terrain, flooding in Delaware was described by the United States Geological Survey as "comparably mild". Flooding along the Brandywine Creek was at least the fifth highest in 45 years. Flooding was worst in the northernmost portion of the state.

Flooding began in many streams in eastern Pennsylvania on August 18. The Delaware River crested at over in Easton, which was above the previous record set in 1903. In Allentown, the Lehigh River crested at , surpassing the previous record of set in 1942. The floods were the worst in record across eastern portions of the state, notably in the Poconos and along all tributaries of the Delaware River from Honesdale to Philadelphia. Lake Wallenpaupack and other reservoirs mitigated flooding. Floods destroyed 17 bridges and of track along the Delaware, Lackawanna and Western Railroad, which is the primary rail line in northeastern Pennsylvania. Damage to the line totaled several million dollars, and overall railroad damage in the state totaled $16 million. Hundreds of cars were damaged in the region. Damage extended into Philadelphia due to flooding along the Schuylkill River, but the damage was minor. In the small village of Upper Black Eddy, hundreds of people became homeless, and the post office was washed away. Statewide, the floods destroyed or breached 30 dams, and destroyed about 150 road of rail bridges. Flooding left home and factory damage in the Allentown area. In the Poconos in Pennsylvania, the Brodhead Creek nearly destroyed a camp, killing 37 people, mostly children. Many people at the camp fled to a lodge that was ultimately destroyed. The Brodhead Creek also washed out a bridge along U.S. Route 209 between Stroudsburg and East Stroudsburg, flooding both cities. There were about 75 deaths in the area, and another 10 deaths occurred in Greentown due to flooding along the Lackawaxen River. Overall, there were 101 deaths in the state, and damage totaled at least $70 million.

In New Jersey, flooding largely occurred north of Trenton and west of Perth Amboy; rainfall in the southern two–thirds of the state was less than . The three major rivers in the area - the Delaware, Passaic, and Raritan - had severe flooding, and damage was widespread. When the Millstone River flooded, two teenagers drowned while canoeing, and a police officer drowned while attempting to rescue them. About 200 families were evacuated in Oakland along the Ramapo River. Damage in the state was heaviest along the Delaware from Port Jervis, New York to Trenton, where flooding inundated adjacent towns. Between the two towns, all but two bridges were damaged, including four that were destroyed. About 500 children had to be rescued from camps on three islands in the Delaware River; they were airlifted to a high school in Frenchtown. In that city, about 200 people were forced to evacuate their houses along the water. In Trenton, workers used sandbags to prevent flooding from affecting government buildings. Flooding destroyed the Portland–Columbia Pedestrian Bridge, first constructed in 1831, after most of it was submerged. The center of the Northampton Street Bridge between Easton, Pennsylvania and Phillipsburg, New Jersey collapsed. A dam near Branchville collapsed, flooding the town and causing heavy damage. About 200 homes were damaged or destroyed in Lambertville. Statewide, 93 homes were destroyed. Damage was estimated at $27.5 million.

Flash floods occurred in mountainous regions of southeastern New York, including Port Jervis along the Delaware River. Wappinger Creek flooded to cause heavy damage. Most streams in the Rondout Creek basin left damage due to fast-moving waters, including heavy damage near Ellenville. Damage in New York was largely limited to an area between Port Jervis and Poughkeepsie. Several bridges were destroyed along the Bash Bish Brook, and portions of U.S. Route 209 were flooded. Damage totaled $16.2 million, and there was one death in the state.

Diane produced heavy rainfall after recurving inland, setting rainfall records in several areas. Windsor Locks, Connecticut reported in a 23‑hour period; the station's total, located near Hartford, was higher than the 24‑hour rainfall record in Hartford. Some locations along the Housatonic River experienced per hour over 24 hours. The highest total in the state was at a station near Torrington. This is the highest rainfall on record in the state. The highest rainfall in the United States related to the storm was in Westfield, Massachusetts, which was also the wettest known storm in the state's history as well as throughout New England. Other statewide rainfall maxima in New England included in Greenville, Rhode Island, in Essex Junction, Vermont, in Fitzwilliam, New Hampshire, and at Long Falls Dam in Maine. Throughout New England, 206 dams were damaged or destroyed, mostly in the region south of Worcester, Massachusetts. About 7,000 people were injured throughout New England, most of whom in Connecticut.

Damage was greatest in Connecticut, where floods affected about two-thirds of the state. It was the largest flood on record in the state's history. All major streams and valleys were flooded during the storm, including hundreds of tributaries, and 30 gauges in the state reported the highest level on record. The Connecticut River at Hartford reached the third-highest level on record at the time, cresting at , or above flood stage. Although there was rural damage, the city of Hartford was spared from flooding due to previously constructed dykes. The Naugatuck River had significant flooding that damaged or destroyed every bridge across it and did extensive damage in Ansonia. In Waterbury, the river washed buildings and railroad girders into a bridge. In the city, 30 people were killed, including 26 in 13 houses that were washed away in one block. The Quinebaug River flooded the city of Putnam at the same time that a major fire originated at a magnesium plant. Much of the commercial district of Winsted was destroyed by the Mad River, which reached deep; the floods destroyed most buildings on the south side of the town's Main Street, and carried away several cars from a car dealership. The local newspaper reported that 95% of businesses were destroyed or severely damaged in Winsted. High rivers destroyed historical sites and buildings, and statewide Diane destroyed 563 houses. There were 77 deaths in the state and $350 million in damage. Most of the damage in the state was industrial or commercial damage.

In Rhode Island, flooding was worst in the northern portion of the state, mostly along the Blackstone River, which expanded to a width of about . The Horseshoe Dam was washed out, causing heavy damage in Woonsocket. There, about 6,000 of its 50,000 residents were left unemployed. Record high tides were also reported. In Rhode Island, damage was estimated at $21 million, mostly in Woonsocket, and there were three deaths.

Much of southern Massachusetts, from its border with New York toward Worcester and to the ocean, experienced flooding. Most streams in western Massachusetts overflowed their banks, and in southeastern Massachusetts, which is largely flat terrain, streams flooded large areas along their channels; these streams moved slowly, while other areas in New England sustained damage due to the fast-moving nature of the floods. Record flooding was reported along 24 stream gauges in the state, including ones that surpassed the peak set by the 1938 New England hurricane. Both the Charles and Neponset rivers were among those that flooded. About 40% of the city of Worcester was flooded during Diane, and in Russell, the state police forced many residents to evacuate. In Weymouth, the floods were considered at least a 1 in 50 year event. The Little River in Buffumville, Massachusetts had a peak discharge of 8,340 ft³/s (236 m³/s), which was 6.2 times greater than the previous peak and 28.5 times the average annual flooding. Flooded rivers breached run-of-the-river dams and covered nearby roadways, although dams with reservoirs resulted in less flooding. Nearly all dams along the French River were severely damaged or destroyed. One failed dam in West Auburn washed out a portion of U.S. Route 20, and the same route was washed out near Charlton. An overflown brook also damaged the Massachusetts Turnpike. A train on the Boston and Albany Railroad line plunged into a washed out portion along the Westfield River. Along the same river, floods destroyed roads and tobacco farms. In the state, 97 houses were destroyed. Damage in Massachusetts was second worst of the affected states, totaling $110 million; the damage was largely due to flooded basements. There were 12 deaths in the state.

In Diane's immediate aftermath, one of the first priorities in response was to distribute adequate inoculations for typhoid amongst the widespread areas left without clean drinking water. The United States Army assisted in search and rescue operations using helicopters. After the floods of Hurricane Diane, more than 100,000 people fled to shelter or away from their houses. The American Red Cross quickly provided aid to the affected residents, using churches and public buildings to house homeless people. In the two weeks after the storm, Americans donated about $10 million to the Red Cross. The countries of Great Britain, Netherlands, Australia, Canada, France, Austria, and Venezuela offered aid to help the flood victims, sending emergency supplies. Additional flooding affected New England in September and October 1955, although neither was as major as those caused by Hurricane Diane. Following Diane, hundreds of companies affected by the flooding installed waterproof doors and windows to preempt similar disasters in the future.

President Dwight Eisenhower declared eight states as disaster areas, making them eligible for federal aid. The Small Business Administration opened 18 temporary offices in the eastern United States for people to take out disaster loan applications. In the months after the storm, both the United States federal government and the American Red Cross had difficulty raising enough funds for the storm victims; collectively, the Red Cross, the Small Business Administration, and Farmers Home Administration raised $37 million, which was less than 8% of Diane's damage total. Throughout 1955, the Red Cross assisted about 10,000 families in New England and the Mid-Atlantic states; some of the families received aid to move to a new house not in a flood zone. The Small Business Administration provided about 1,600 loans, totaling $25 million, for small businesses. Senator Herbert H. Lehman proposed a $12 billion federal flood insurance program. In 1956, the United States Congress passed the Federal Flood Insurance Act, but the program was not enacted due to lack of funding. A nationwide flood program was not enacted until the passage of the National Flood Insurance Act of 1968. After the floods from Diane, the American federal government provided funding for the Army Corps of Engineers to construct dams and reservoirs throughout New England to mitigate future flooding. In about 14 years, the Corps built 29 dams in Connecticut alone at the cost of $70 million, including three along the Connecticut River. The federal government restored plans from the 1930s to build dams along the Delaware River, one of which along Tocks Island. A controversy arose there due to the long reservoir the dam would have created, causing 600 families to be displaced. The project was canceled in 1975, and the acquired lands became the Delaware Water Gap National Recreation Area.

In Pennsylvania, washed-out rail lines prevented operation along the Delaware, Lackawanna and Western Railroad for several weeks, and lines reopened after about two months. The expense of reopening, and the loss of being closed, led to the railroad merging with the Erie Railroad to become the Erie Lackawanna Railway in 1960. One stranded train along the line prompted a helicopter to rescue 235 people. Flooding along the Lehigh River destroyed 15 industrial plants, which left more than 15,000 people near Allentown, Pennsylvania without work temporarily. The mayor of Scranton declared a state of emergency due to the floods, ordering all businesses to close. United States Army soldiers provided water to residents after the town lost its water supply. Elsewhere, the Pennsylvania National Guard was on duty on streets in damaged towns, including 50 to prevent looting in Upper Black Eddy, which was one of the hardest hit towns. Helicopters assisted in discovering bodies at Camp Davis, where many deaths occurred during the storm. Statewide, thousands of people were left homeless. In Stroudsburg, there was a food shortage, and officials enacted a curfew, after reports of looting. In the same city, water was shipped in milk cartons to the flood victims, which later inspired a Federal Civil Defense Administration proposal to use water packaged in milk containers in the event of a nuclear attack. The state government implemented a tax on cigarettes to help pay for storm damage, which lasted for about two years; this was partially due to a lack of significant funding from the federal government. Pennsylvania also enacted an increase in the gasoline tax that was later made permanent to pay for the Interstate Highway System. The two taxes, each an increase of 1 penny, totaled $71 million, a part of which was set aside for future disasters. The experience of the storm's aftermath provided the basis for the aftermath for Hurricane Agnes in 1972. In New Jersey, Governor Robert B. Meyner declared the floods as at the time the state's worst natural disaster.

After the Naugatuck River flood in Connecticut cut off communications and bridges, the state was effectively cut in two. The state's National Guard used helicopters to rescue people. Governor Abraham A. Ribicoff visited areas affected by the flooding, due to the damage, Connecticut was declared a federal disaster area on August 20. The declaration allocated $25 million in assistance to the state. Governor Ribicoff requested $34 million in funds to rebuild and produce future flood mitigation projects; the state's funding was paid by a combination of bonds and tax increases. Including subsequent storms, the 1955 floods cumulatively killed 91 people and left 1,100 families homeless. Flooding occurred in 67 towns, resulting in damage to 20,000 families. About 86,000 people were left unemployed after the floods. In Winsted, the buildings that were washed away along the south side of Main Street were never rebuilt.

Massachusetts Governor Christian Herter also issued a state of emergency, due to the widespread flooding damage. As a result, the state's National Guard and the Army Corps assisted in cleanup, and most roads took three weeks to clear. Residents in areas affected by Diane's flooding were advised to boil water and not to use gas cooking equipment. Diane's historic rainfall resulted in the wettest month on record in Boston with a total of , a record that stands as of 2010; Boston's 24‑hour total of remained the highest daily total as of 1996. Following Diane's floods, cities in Massachusetts enlarged culverts and improved draining systems, as well as constructing weirs; these systems helped mitigate against future flooding.

The name Diane was retired from the Atlantic hurricane naming list. Due to the damage from hurricanes in 1954 and 1955, including Diane, public outcry over storm damage led to the creation of the National Hurricane Center in 1956. Using a monetary deflator in 2010 United States dollars, the damage from Diane would be about $7.4 billion, which would have been the 17th highest in the United States. Accounting for inflation, changes in personal wealth, and population changes, it is estimated Diane would have caused $18 billion in damage in 2010, or the 15th highest for a United States hurricane.




</doc>
<doc id="986986" url="https://en.wikipedia.org/wiki?curid=986986" title="Hurricane Hattie">
Hurricane Hattie

Hurricane Hattie was the strongest and deadliest tropical cyclone of the 1961 Atlantic hurricane season, reaching a peak intensity equivalent to that of a Category 5 hurricane. The ninth tropical storm and seventh hurricane and major hurricane of the season, Hattie originated from an area of low pressure that strengthened into a tropical storm over the southwestern Caribbean Sea on October 27. Moving generally northward, the storm quickly became a hurricane and later major hurricane the following day. Hattie then turned westward west of Jamaica and strengthened into a Category 5 hurricane, with maximum sustained winds of . It weakened to Category 4 before making landfall south of Belize City on October 31. The storm turned southwestward and weakened rapidly over the mountainous terrain of Central America, dissipating on November 1.

Hattie first affected the southwestern Caribbean, where it produced hurricane-force winds and caused one death on San Andres Island. It was initially forecast to continue north and strike Cuba, prompting evacuations on the island. While turning west, Hattie dropped heavy rainfall of up to on Grand Cayman. The country of Belize, at the time known as British Honduras, sustained the worst damage from the hurricane. The former capital, Belize City, was buffeted by strong winds and flooded by a powerful storm surge. The territory governor estimated that 70% of the buildings in the city had been damaged, leaving more than 10,000 people homeless. The destruction was so severe that it prompted the government to relocate inland to a new city, Belmopan. Overall, Hattie caused about $60 million in losses and 307 deaths in the territory. Although damage was heavier in Hattie than a hurricane in 1931 that killed 2,000 people, the death toll from Hattie was less due to advance warnings. Elsewhere in Central America, Hattie killed 11 people in Guatemala and one in Honduras.

For several days toward the end of October 1961, a low-pressure area persisted in the western Caribbean Sea, north of the Panama Canal Zone. On October 25, an upper-level anticyclone moved over the low; the next day, a trough over the western Gulf of Mexico provided favorable outflow for the disturbance. At 0000 UTC on October 27, a ship nearby reported southerly winds of 46 mph (74 km/h). Later that day, the airport on San Andres Island reported easterly winds of 60 mph (95 km/h). The two observations confirmed the presence of a closed wind circulation, centered about 70 miles (110 km) southeast of San Andres, or 155 mi (250 km) east of the Nicaraguan coast; as a result, the Miami Weather Bureau began issuing advisories on the newly formed Tropical Storm Hattie.

After being classified, Hattie moved steadily northward, passing very near or over San Andres Island. A station on the island recorded a pressure of and sustained winds of 80 mph (130 km/h), which indicated that Hattie had reached hurricane status. Late on October 28, a Hurricane Hunters flight encountered a much stronger hurricane, with winds of 125 mph (200 km/h) in a small area near the center. At the time, gale-force winds extended outward 140 mi (225 km) to the northeast and 70 miles (115 km) to the southwest. Early on October 29, a trough extending from Nicaragua to Florida was expected to allow Hattie to continue northward, based on climatology for similar hurricanes. Later that day, Hattie was forecast to be an imminent threat to the Cayman Islands and western Cuba. Around that time, a strengthening ridge to the north turned the hurricane northwestward, which spared the Greater Antilles but increased the threat to Central America.

With the strengthening ridge to its north, Hattie began restrengthening after retaining the same intensity for about 24 hours. Initially, forecasters at the Miami Weather Bureau predicted the storm to turn northward again. Late on October 29, the center of the hurricane passed about 90 miles (145 km) southwest of Grand Cayman, at which time the interaction between Hattie and the ridge to its north produced squally winds of around 30 mph (50 km/h) across Florida. Early on October 30, the Hurricane Hunters confirmed the increase in intensity, reporting winds of 140 mph (225 km/h). The storm's minimum central pressure continued to drop throughout the day, reaching by 1300 UTC; a lower pressure of was computed at 1700 UTC that day, based on a flight-level reading from the Hurricane Hunters. Hattie later curved toward the west-southwest, passing between the Cayman Islands and the Swan Islands. Late on October 30, Hattie attained peak winds of 160 mph (260 km/h) about 190 mi (310 km) east of the border of Mexico and British Honduras. This made Hattie the equivalence of a Category 5 hurricane on the Saffir-Simpson Hurricane Scale, making it the latest hurricane on record to reach the status until a reanalysis of the 1932 season revealed that Hurricane Fourteen had a similar intensity on November 5, six days after Hattie. Additionally, Hattie was the strongest October hurricane in the northwest Caribbean until Hurricane Mitch in 1998.

Hattie maintained much of its intensity as it continued toward the coast of British Honduras. After moving through several small islands offshore, the hurricane made landfall a short distance south of Belize City on October 31, with an eyewall of about 25 miles (40 km) in diameter. Based on a post-season analysis, it was determined that Hattie had weakened to winds of 140 mph (225 km/h) before moving ashore. The hurricane deteriorated rapidly over land, dissipating on November 1 as it moved into the mountains of Guatemala. During its dissipation, Tropical Storm Simone was developing off the Pacific coast of Guatemala. There was speculation that Hattie contributed to the development of Simone, and later Tropical Storm Inga after the remnants of Simone merged with nearby disturbed weather.

Upon initiating advisories on Hattie, the Miami Weather Bureau noted the potential for heavy rainfall and flash flooding in the southwestern Caribbean. The advisories recommended for small ships to remain at harbor across the region. Initially, the hurricane was predicted to move near or through the Cayman Islands, Jamaica, and Cuba. As a result, Cuban officials advised residents in low-lying areas to evacuate.

Hurricane Hattie first posed a threat to the Yucatán Peninsula and British Honduras on October 30 when it turned toward the area. Officials at the Miami Weather Bureau warned of the potential for high tides, strong winds, and torrential rainfall. The warnings allowed for extensive evacuations in high-risk areas. Most people in the capital, Belize City, were evacuated or moved to shelters, and a school was operated as a refuge. A hospital in the city was evacuated, and over 75% of the population of Stann Creek fled to safer locations. After Hattie made landfall, officials in Mexico ordered the closure of ports along the Isthmus of Tehuantepec.

Despite predictions for heavy rainfall in the southwestern Caribbean, the hurricane's movement was more northerly than expected, resulting in less precipitation along the Central American coast than anticipated. In its early developmental stages, Hattie struck San Andrés Island, located offshore eastern Nicaragua, with maximum sustained winds of 80 mph (130 km/h) and gusts of 104 mph (167 km/h). As the hurricane neared the island, the airport was closed due to tropical-storm-force winds. Rough seas and winds damaged private property and two hotels. Many palm tree plantations were devastated. The schooner "Admirar", anchored in one of the island's bays, capsized during the storm. Overall, Hattie resulted in one death, fifteen injuries, and $300,000 in damage (1961 USD) in San Andrés. The hurricane was the fourth on record to strike the island, and of the four was the only to approach from the south.

In the northwestern Caribbean, Hattie passed close to Grand Cayman with heavy rainfall. At least 11.5 inches (292 mm) of rain were reported on the island, including 7.8 inches (198 mm) in six hours. Winds on Grand Cayman were below hurricane force, and only minor damage occurred due to the rain.

The interaction between Hattie and the ridge of high pressure to its north produced sustained winds of 20 mph (35 km/h) across most of Florida, with a gust of 72 mph (116 km/h) reported at Hillsboro Inlet Light; the winds caused some beach erosion in the state. The U.S. Weather Bureau issued a small craft warning for the west and east Florida coastlines, as well as northward to Brunswick, Georgia.

Later, Hattie impacted various countries in Central America with flash floods, causing 11 deaths in Guatemala and one fatality in Honduras. The Swan Islands reported wind gusts just below hurricane force, resulting in minor damage and one injury.

Hurricane Hattie moved ashore in British Honduras with a storm tide of up to 14 feet (4.3 m) near Belize City, a city of 31,000 people located at sea-level; its only defenses against the storm tide were a small seawall and a strip of swamp lands. The capital experienced high waves and a 10 ft (3 m) storm tide along its waterfront that reached the third story of some buildings. A trained observer estimated winds of over 150 mph (240 km/h), and winds in the territory were unofficially estimated as strong as 200 mph (325 km/h). When Hattie affected the area, most buildings in Belize City were wooden, and most of this type were destroyed. Offshore, the hurricane heavily damaged 80% of the Belize Barrier Reef, although the reef recovered after the storm.
High winds caused a power outage, downed trees across the region, and destroyed the roofs of many buildings. Governor Colin Thornley estimated that over 70% of the buildings in the territory were damaged, and more than 10,000 people were left homeless. Some shelters set up before the storm were destroyed in the hurricane. The hurricane destroyed the wall at an insane asylum, which allowed the residents to escape. High waves damaged a prison, prompting officials to institute a "daily parole" program for the inmates. Hattie also flooded the Government House, washing away all records. All of Belize City was coated in a layer of mud and debris, and majority of the city was destroyed or severely damaged, as was nearby Stann Creek. The hurricane left significant crop damage across the region, including $2 million in citrus fruits and similar losses to timber, cocoa, and bananas. The year's production of sugar cane was also heavily damaged. About 70% of the territory's mahogany trees were downed, as were most citrus and grapefruit trees. The hurricane damaged several factories and oil rigs in the region. Damage throughout the territory totaled $60 million (1961 USD), and a total of 307 deaths were reported; more than 100 of the fatalities were in Belize City, including 36 who evacuated to a British administration building that was later destroyed in the storm. The government of British Honduras considered Hurricane Hattie more damaging than a hurricane in 1931 that killed 2,000 people; the lower death toll of Hattie was due to advance warning.

After Hattie struck, officials in Belize City declared martial law. A manager of United Press International described Belize City as "nothing but a huge pile of matchsticks," and many roads were either flooded for days or covered with mud. Doctors provided typhoid vaccinations to 12,000 residents in two days to prevent the spread of the disease. Due to the high death toll, officials ordered mass cremations to stop additional disease from spreading. At the city's police station, workers provided fresh water and rice to storm victims. Many residents throughout British Honduras donated supplies to the storm victims, such that an airlines manager described it as "taxing... manpower and facilities." One airline allowed donations to be flown to Belize City at no cost. The city's three newspapers were unable to operate due to lack of power after the storm. By November 5, Belize City's post office reopened on a limited basis, and all business initially remained closed. About 4,000 homeless residents from Stann Creek were moved by boat to the northern portion of the territory. Many homeless people from the Belize City area set up a tent city on bushland about inland, which was initially intended to be temporary. In December 1961, barracks were erected near a Red Cross Hospital to house the homeless in the camp. The site was named Hattieville and became a proper city, with utilities installed in the subsequent decade.

About 200 British soldiers arrived from Jamaica to quell looting and maintain order. At least 20 people were arrested in the day after Hattie struck. The British government sent flights of aid to the territory containing food, clothing, and medical supplies. The House of Commons quickly passed a bill to provide £10,000 in aid. The Save the Children fund sent £1,000 to British Honduras, and the Mexican government sent three flights with food and medicine to the territory. Two American destroyers arrived in the country by November 2, reporting the need for assistance. The USS Antietam remained at port for weeks after the storm with six medical officers and six Marine helicopters. Four other ships sailed to the territory to provide 458,000 lb (208,000 kg) of food. The United States government allocated about $300,000 in assistance through the International Development Association. The Canadian government provided C$75,000 worth of aid, including food, blankets, and medical supplies.

By Hattie's one year anniversary, private and public workers repaired and rebuilt buildings affected by the storm. New hotels were constructed, and many stores were reopened. Prime Minister George Cadle Price successfully appealed for assistance from the British government, which ultimately provided £20 million in loans. In the days after the storm, the government announced plans to relocate the capital of British Honduras farther inland on higher ground. Work on the new capital, Belmopan, was completed in 1970. On the 44th anniversary of the hurricane in 2005, the government of Belize unveiled a monument in Belize City to recognize the victims of the hurricane.

Due to the destruction and loss of life attributed to the hurricane, the name Hattie was retired by the World Meteorological Organization and will never again be used for an Atlantic hurricane.



</doc>
<doc id="987113" url="https://en.wikipedia.org/wiki?curid=987113" title="Hurricane Eloise">
Hurricane Eloise

Hurricane Eloise was the most destructive tropical cyclone of the 1975 Atlantic hurricane season. The fifth tropical storm, fourth hurricane, and second major hurricane of the season, Eloise formed as a tropical depression on September 13 to the east of the Virgin Islands. The depression tracked westward and intensified into a tropical storm while passing to the north of Puerto Rico. Eloise briefly attained hurricane intensity soon thereafter, but weakened back to a tropical storm upon making landfall over Hispaniola. A weak and disorganized cyclone, Eloise emerged into open waters of the northern Caribbean Sea; upon striking the northern Yucatan Peninsula, it turned north and began to re-intensify. In the Gulf of Mexico, the cyclone quickly matured and became a Category 3 hurricane on September 23. Eloise made landfall along the Florida Panhandle west of Panama City before moving inland across Alabama and dissipating on September 24.

The storm produced torrential rainfall throughout the islands of Puerto Rico and Hispaniola, causing extensive flooding that led to severe damage and more than 40 deaths. Thousands of people in these areas became homeless as flood waters submerged numerous communities. As Eloise progressed westward, it affected Cuba to a lesser extent. In advance of the storm, about 100,000 residents evacuated from the Gulf Coast region. Upon making landfall in Florida, Eloise generated wind gusts of 155 miles per hour (249 km/h), which demolished hundreds of buildings in the area. The storm's severe winds, waves, and storm surge left numerous beaches, piers, and other coastal structures heavily impaired.

Wind-related damage extended into inland Alabama and Georgia. Further north, torrential rains along the entire East Coast of the United States created an unprecedented and far-reaching flooding event, especially into the Mid-Atlantic States. In that region, an additional 17 people died as a result of freshwater flooding from the post-tropical storm; infrastructural and geological effects were comparable to those from Hurricane Agnes several years prior. Across the United States, damage amounted to approximately $560 million. The storm killed 80 people along its entire track; due to the severe damage, the name "Eloise" was retired from the Atlantic tropical cyclone naming lists.

The origins of Hurricane Eloise trace back to a tropical wave that emerged from the western coast of Africa on September 6, 1975. Satellite imagery indicated that the system was initially disjointed and poorly developed, although there was evidence of a low-level circulation. The disturbance tracked westward for several days as it slowly matured. On September 13, a ship called the "Gulf Hansa" recorded winds of around and seas in association with the system. Shortly thereafter, a reconnaissance aircraft found a center of circulation east of the Virgin Islands, and it is estimated that the storm became a tropical depression at 0600 UTC.

The depression continued moving towards the west as it gradually strengthened. On September 16, the system attained tropical storm status and was designated Eloise; accordingly, the first advisory on the system was issued by the San Juan Weather Bureau office. While in the vicinity of a strengthening anticyclone aloft, Eloise became better organized, and the storm rapidly intensified and reached Category 1 hurricane status 18 hours after being named. The cyclone soon made landfall on the Dominican Republic, inhibiting further development. Although initially predicted to remain north of land, the storm moved across northern Hispaniola and then tracked across southeastern Cuba. After 36 hours with much of its circulation over mountainous terrain, Eloise deteriorated to a tropical storm on September 17.

The cyclone emerged over the open waters of the northern Caribbean on September 19, passing Jamaica to the north as it moved away from Cuba. Despite favorable upper-level conditions, its interaction with land—combined with the weakening of a ridge to the north—left the storm's center distorted. Eloise remained a fairly disorganized tropical storm until September 20, when it approached the Yucatan Peninsula and began to re-intensify. The storm crossed over the northern tip of the peninsula as it began to turn northward in response to an approaching trough. Between September 17 and September 21, however, reports on the storm were scarce, leading to uncertainty in its exact location and strength. Upon entering the Gulf of Mexico, Eloise quickly organized. The trough enhanced the wind divergence over the storm's center, allowing it to strengthen once again to reach hurricane force about south of New Orleans, Louisiana.
On September 22, the cyclone intensified to attain Category 2 strength, and became a major hurricane of Category 3 status shortly thereafter as it turned towards the northeast. Several ships penetrated the storm's center during its passage through the gulf. The hurricane also moved over two experimental buoys which recorded data on the storm, aiding meteorologists in their forecasts. Hurricane Eloise continued to strengthen until it reached its peak winds of 125 mph (205 km/h) and a minimum barometric pressure of about 955 mbar (hPa; 28.2 inHg). It moved ashore along the Florida Panhandle near Panama City on September 23. Shortly after making landfall, the hurricane rapidly degenerated. Just six hours later, it had weakened into a tropical storm, while situated over eastern Alabama. It further weakened into a tropical depression at 0000 UTC on September 24. The depression transitioned into an extratropical storm over Virginia, and became indistinguishable by later that same day. The remnant moisture, however, merged with a weather front to produce widespread and heavy precipitation.

In advance of Hurricane Eloise, warnings for heavy rainfall and potential flooding were issued for Puerto Rico and the Virgin Islands. A hurricane warning was declared for parts of the Dominican Republic about 12 hours before landfall. A "hurricane emergency" was put into effect for the Oriente Province of Cuba, while a "state of alert" was issued for the Camagüey Province. Cubana de Aviación suspended all flights to Oriente.

On and before September 15, there was still uncertainty as to whether Eloise would impact the United States. However, officials in Florida began taking precautionary measures. When the storm entered the Gulf of Mexico, forecasters suggested that the storm would continue northward and strike the area near Mobile Bay. Contrary to predictions, by late on September 22, the storm had turned northeast, and some residents of Florida were still unaware of the storm's threat despite the issuance of hurricane warnings 24 hours in advance. As a result, evacuations were delayed to an extent. During the morning hours of September 23, civil preparedness workers drove through coastal towns with loudspeakers advising people to seek shelter. Due of the intensity of the approaching hurricane, evacuations along the coast were ultimately thorough, despite the initial delay. It was reported that 99% of Pensacola residents along the beach had left their homes, and overall, 100,000 people evacuated from areas in Louisiana through Florida.

A statement issued by the National Weather Service advised people in nine Florida counties to complete hurricane preparations, which included securing loose objects and moving watercraft to safety. Homes along the coast were boarded up by their owners, while offshore, workers were removed from oil platforms. A spokesman for Royal Dutch Shell reported that 800 workers were to be evacuated. In New Orleans, emergency equipment was readied and inspected. The New Orleans Levee Board went into a second-stage alert on September 21, and cleared debris from floodwall openings.

As a weak tropical depression, the storm brought of rainfall to portions of the Leeward Islands, including St. Kitts and St. Martin. More minor amounts of precipitation fell over the northernmost islands, and winds were light in these areas.

Despite being only a tropical storm while passing by Puerto Rico, Eloise produced extreme amounts of rainfall on the island, peaking at in Dos Bocas. Other totals of were common. The heavy rains resulted in severe flash flooding which killed 34 people, mostly from drownings, and left $60 million in damages. Several hundred people were injured, and the storm forced over 6,000 residents from their homes. Dozens of towns and villages were flooded, though Utuado, with a population of 35,000 at the time, was hit the hardest. The situation in that town was described as a "total disaster"; four housing developments were under water, and dozens of vehicles were washed away. The flood waters submerged thousands of miles of roads and put several bridges out-of-service.

As the storm proceeded westward, it dropped heavy rainfall throughout eastern and southern Hispaniola. Widespread flooding impacted Haiti and the Dominican Republic, leaving a total of 25 people dead. Although the most intense winds remained offshore, a gust of was recorded at Cape Engaño. Puerto Plata on the northern coast of the Dominican Republic was also battered by high winds and heavy rain. Following the storm, electricity was turned off due to the danger of electrocutions. Despite the storm's effects across Hispaniola and Puerto Rico, no monetary damage totals are available.

Rain and wind from the storm affected the southern Bahamas, Cuba, Jamaica, the Cayman Islands, and the northern Yucatan Peninsula. Since the storm was primarily weak while passing by these areas, no significant damage was reported. Eloise brought torrential rainfall and winds of to the Guantanamo Bay Naval Base in southeastern Cuba, inflicting $65,000 in damage. Personnel on the base were moved to designated hurricane shelters in advance of the storm.

Eloise came ashore along the coast of northern Florida as a Category 3 storm producing winds of with gusts that reached 155 mph (249 km/h). Sustained winds were likely higher, but due to the sparsity of recording stations, few official records exist. The winds in the area were reportedly the strongest of the century. Hurricane-force winds occurred from Fort Walton Beach through Panama City. Along the coast, tides ran above normal, peaking at . Hurricane Eloise spawned several tornadoes as it pressed inland. In general, rainfall ranged from ; at the Eglin Air Force Base near Valparaiso, however, the hurricane dropped of precipitation. The heaviest rainfall was usually confined to northwest of the storm's track, and a number of locations to the east of Eloise's center picked up less than of rain.

Damage from the hurricane was widespread. Fort Walton Beach, where hundreds of structures were damaged or destroyed, was hit particularly hard. In some areas, the storm surge washed away buildings demolished by the strong winds. The winds cleared certain locations of trees and buried properties and roads under sand. Throughout northwest Florida, an estimated 8,000 people suffered storm-related losses, and 500 businesses were completely destroyed. An article in the "Tallahassee Democrat" reported that "Cottages, motels, restaurants, convenience stores and other beach businesses were strewn across the highway in a tangle of down power poles, lines and busted mains." A shrimp farm at Panama City, the first of its kind, was effectively lost. The storm destroyed the farm's prospective initial harvest, of shrimp enclosed in a system of nets and enclosures. The president of the company described the subsequent events as six months of extreme turmoil in an effort to recover, followed by a quick and steady rebound. By the spring of 1976, the company became confident in financial success and full recovery.
The storm caused severe beach erosion in Bay County; approximately of sand was removed. Storm-related changes in the coastal topography resulted in extensive structural damage in the Panama City Beach area. The most severe damage was concentrated in a area of the shore east of the hurricane's eye, and storm surge peaked in intensity for no more than a half hour according to preliminary estimates. Much of the resultant damage came as a result of foundation undermining, which was compared to that of the New England hurricane of 1938. Although Eloise was not abnormally strong, the geographicy setting and building standards in the area were blamed for the destruction of many homes and businesses. Monetary losses from property damage in Panama City Beach alone totaled about $50 million.

The first major storm to strike the region in 40 years, Hurricane Eloise did not directly kill anyone in the state of Florida. However, four deaths of an indirect nature were attributed to the hurricane; two of them were related to heart attacks. Numerous people sustained injuries, largely from broken glass or cleanup efforts. Overall property damage from the storm in Florida amounted to $150 million. In the storm's aftermath, a study of the hurricane's effect on aquatic animals living in the "swash zone" (the immediate area where land and the ocean meet) of Panama City Beach was conducted. The study concluded that compared to 11 consecutive months of data prior to the storm, the swash zone experienced a brief influx of animal species normally found offshore. However, the number decreased to near normal shortly thereafter. Also along the shore, the hurricane dismantled or severely impaired several piers, including the total destruction of a extension of the Okaloosa Island Pier built just three years earlier and part of its original span. A fishing pier at St. Andrews State Park also suffered vast damage, along with another wooden pier at Mexico Beach and the M.B. Miller Pier at Panama City Beach, which lost its end section to the storm.

As the hurricane progressed inland, it passed over eastern Alabama, generating strong winds. A gust of was recorded northeast of Ozark. Winds elsewhere in the state ranged from around to . Precipitation in Alabama peaked at . The high winds resulted in severe damage to property and crops, amounting to $100 million. Eloise cut power and telephone service in the area, and in Geneva County, several people sustained storm-related injuries. As in Florida, the weakening hurricane spawned a number of tornadoes in Alabama and Georgia. Preliminary reports indicated that every county in southeastern Alabama received some damage from the storm. The strong winds uprooted trees and knocked down powerlines. Heavy rain associated with the storm caused a leak in the Alabama State Capitol building roof. Gusty winds, moderate to heavy rainfall, and low pressures extended into Georgia, Louisiana, and to a lesser extent, Mississippi.
The remnants of Eloise interacted with another weather system, producing widespread precipitation across the Eastern United States, including portions of the Ohio Valley, the Mid-Atlantic states, and New England. The deluge was "almost continuous" during the period between September 22 and 26 according to a statement by the National Weather Service. One of the highest rainfall totals in association with the storm occurred in Westminster, Maryland, where of rain were recorded. Elsewhere, or more of precipitation fell throughout parts of Pennsylvania, New Jersey, New York and Connecticut. At least 22 states received rainfall from Hurricane Eloise and its remnant moisture. Nearby Hurricane Faye may have also contributed to the heavy rainfall, although this connection was never confirmed. In Washington, D.C., of rain contributed to the wettest September on record since 1934. The excessive rainfall led to extensive flooding throughout the region, in some areas exceeding 50- to 100-year levels.

Pennsylvania and New York bore the brunt of the flooding, which culminated in loss of life and severe property damage. Along the central Southern Tier region of New York, the storm damaged or destroyed over 700 structures. Flooding throughout the Northeastern United States disabled over a dozen water plants and at least 16 sewage treatment plants, prompting a boil-water advisory in Pennsylvania's capital city of Harrisburg. Infrastructure further south also suffered; in Maryland, the Monocacy River—a tributary of the Potomac—swelled to above flood stage, inundating the city of Frederick and compromising the city's supply of fresh drinking water. A final downpour of rain on the night of September 25–26 led to an additional of rain in central Maryland triggered severe flash flooding. In some cases, this onslaught affected the same areas that were still recovering from Hurricane Agnes several years earlier, including Ellicott City, Elkridge, and Laurel, where two major rivers breached their banks and engulfed nearby areas. Many homes and businesses were lost, along with numerous vehicles; in the aftermath, looters entered on boats to access the devastated cities. The floodgates at the Rocky Gorge Dam in Laurel were opened, forcing 500 residents downstream to leave their homes.

The consequences of the flooding rains were the worst seen in areas of the interior Mid-Atlantic states since Agnes, and comparisons were often drawn between the two hurricanes. In Pennsylvania alone, flooding from the remnants of Eloise forced 20,000 residents out of their homes; thousands further south in the Washington, D.C. area, where severe flooding impacted the city's southern suburbs, also fled to seek refuge. Further, many motorists throughout the region became stranded on highways inundated by floodwaters. Four Mile Run and nearby streams overflowed and "tumbled through residential neighborhoods". Hundreds of families in the Alexandria and Arlington, Virginia area suffered flood-related losses. Across the Northeastern U.S., the storm system killed 17 people and inflicted $300 million in damage. An instance of a storm-induced fatality is the death of a man in White Plains, New York, who was killed by waters raging across the Hutchinson River Parkway. Agriculturally, the extended period of wet weather threatened a range of crops, including the Rhode Island apple crop, of which 35% was feared to have been destroyed, and corn and sweet potato fields in North Carolina. With ground too moist for farm machinery to operate on, harvests were postponed.

After touring the disaster area, Florida Governor Reubin Askew noted, "I think we're going to have to take a long, close look at some of the construction [...] Some of the structures simply won't be able to be built back in the exact location where they were." Governor Askew recruited 400 National Guard troops to prevent looting following the storm. He also requested the initial declaration of five counties along the Florida panhandle as national disaster areas, and stated that he would consider adding two more counties. The declaration would make residents in the counties recognized as disaster areas eligible to receive federal aid. Immediately following the storm, the mayor of Panama City criticized the state of Florida for failing to provide sufficient post-storm aid. Despite the destruction, the storm reportedly had some economic benefits; in the midst of rebuilding and recovery, business grew, especially in and around Panama City, and people began to move into the area. In at least one instance, the hurricane and its associated storm surge had a lasting effect on local geography, breaching Crooked Island in Bay County to create an inlet wide referred to as Eloise Inlet. Eloise provided a comprehensive base of information on beach and dune erosion along the Florida panhandle, which aided in the programming of certain erosion prediction numerical models. In 1995, reports from the aftermath of Hurricane Opal created a more extensive collection of data.

On September 26, President Gerald Ford approved the declaration for Florida, and later issued a separate declaration for 30 counties in Pennsylvania as the storm's flooding rains progressed northward. Pennsylvania Lieutenant Governor Ernest Kline assigned 600 National Guardsmen to assist in the evacuation of flood victims and maintain security in storm-ravaged areas. Over $430 million in federal disaster relief was spent overall in 1975 and distributed to 92,000 families; the bulk of the funds went to recovery for areas affected by Hurricane Eloise along its entire course. In Maryland, Governor Marvin Mandel placed 10 of the state's 23 counties under a state of emergency. Following the severe damage caused by Hurricane Eloise, its name was retired at the end of the 1975 season and will never again be used for a Atlantic hurricane. However, Eloise was not replaced by any particular name due to the addition of male names into the lists in 1979.





</doc>
<doc id="990790" url="https://en.wikipedia.org/wiki?curid=990790" title="H. C. McNeile">
H. C. McNeile

Herman Cyril McNeile, MC (28 September 1888 – 14 August 1937), commonly known as Cyril McNeile and publishing under the name H. C. McNeile or the pseudonym Sapper, was a British soldier and author. Drawing on his experiences in the trenches during the First World War, he started writing short stories and getting them published in the "Daily Mail". As serving officers in the British Army were not permitted to publish under their own names, he was given the pen name "Sapper" by Lord Northcliffe, the owner of the "Daily Mail"; the nickname was based on that of his corps, the Royal Engineers.

After the war McNeile left the army and continued writing, although he changed from war stories to thrillers. In 1920 he published "Bulldog Drummond", whose eponymous hero became his best-known creation. The character was based on McNeile himself, on his friend Gerard Fairlie and on English gentlemen generally. McNeile wrote ten Bulldog Drummond novels, as well as three plays and a screenplay.

McNeile interspersed his Drummond work with other novels and story collections that included two characters who appeared as protagonists in their own works, Jim Maitland and Ronald Standish. He was one of the most successful British popular authors of the inter-war period before his death in 1937 from throat cancer, which has been attributed to damage sustained from a gas attack in the war.

McNeile's stories are either directly about the war, or contain people whose lives have been shaped by it. His thrillers are a continuation of his war stories, with upper class Englishmen defending England from foreigners plotting against it. Although he was seen at the time as "simply an upstanding Tory who spoke for many of his countrymen", after the Second World War his work was criticised as having fascist overtones, while also displaying the xenophobia and anti-semitism apparent in some other writers of the period. 

McNeile was born in Bodmin, Cornwall. He was the son of Malcolm McNeile, a captain in the Royal Navy who at the time was governor of the naval prison at Bodmin, and Christiana Mary (née Sloggett). The McNeile family had ancestral roots from both Belfast and Scotland, and counted a general in the British Indian Army among their members.

McNeile did not like either of his given names but preferred to be called Cyril, although he was always known by his friends as Mac. After attending a prep school in Eastbourne, he was further educated at Cheltenham College. On leaving the college, he joined the Royal Military Academy, Woolwich, from which he was commissioned into the Royal Engineers as a second lieutenant in July 1907. He underwent further training at the Royal School of Military Engineering before a short posting to Aldershot Garrison. He received promotion to lieutenant in June 1910 and was posted to Canterbury, serving three years with the 3rd Field Troop, until January 1914, when he was posted to Malta.

In 1914 McNeile was promoted to the rank of captain. He was still in Malta when the war broke out and was ordered to France in October 1914; he travelled via England and married Violet Evelyn Baird on 31 October 1914. Baird was the daughter of Lieutenant-Colonel Arthur Baird Douglas of the Cameron Highlanders.

On 2 November 1914 McNeile travelled to France as part of the British Expeditionary Force. Few details are known about McNeile's wartime service, as his records were destroyed by incendiary bombs during the Second World War. He spent time with a number of Royal Engineer units on the Western Front, including 1st Field Squadron RE, 15th Field Company RE and RE elements of the 33rd Division.
McNeile's first known published story, "Reminiscences of Sergeant Michael Cassidy", was serialised on page four of the "Daily Mail" from 13 January 1915. As serving officers in the British Army were not permitted to publish under their own names except during their half-pay sabbaticals, many would write under a pseudonym; Lord Northcliffe, the owner of the "Daily Mail", gave McNeile the pen name "Sapper", as the Royal Engineers were commonly known as the Sappers. McNeile later confided that he had started writing through "sheer boredom". Some of his stories appeared on page four of the "Daily Mail" over the following months. Northcliffe was impressed by his writing and attempted, but failed, to have him released from the army to work as a war correspondent. By the end of 1915, he had written two collections of short stories, "The Lieutenant and Others" and "Sergeant Michael Cassidy, R.E.", both of which were published by Hodder & Stoughton. Although many of the stories had already appeared in the "Daily Mail", between 1916 and 1918 "Sergeant Michael Cassidy, R.E." sold 135,000 copies and "The Lieutenant and Others" sold 139,000 copies. By the end of the war he had published three more collections, "Men, Women, and Guns" (1916), "No Man's Land" (1917) and "The Human Touch" (1918). In 1916 he wrote a series of articles titled "The Making of an Officer", which appeared under the initials C. N., in five issues of "The Times" between 8 and 14 June 1916. The articles were aimed at young and new officers to explain their duties to them; these were collected together and published by Hodder & Stoughton later in 1916.

During his time with the Royal Engineers, McNeile saw action at the First and Second Battles of Ypres—he was gassed at the second battle—and the Battle of the Somme. In 1916 he was awarded the Military Cross and was mentioned in dispatches; in November that year he was gazetted to acting major. From 1 April to 5 October 1918, he commanded a battalion of the Middlesex Regiment and was promoted to acting lieutenant-colonel; the scholar Lawrence Treadwell observes that "for an engineer to command an infantry regiment was ... a rarity". 18th Battalion, Middlesex Regiment under McNeile saw action for the remainder of his command, and were involved in fighting during the Hundred Days Offensive in the St. Quentin-Cambrai sector in September 1918; during the year, he was again mentioned in dispatches. On 2 October 1918 he broke his ankle and was briefly hospitalised, which forced him to relinquish his command of the regiment on 4 October. He was on convalescent leave when the war ended in November 1918. During the course of the war, he had spent a total of 32 months in France, and had probably been gassed more than once. His literary output from 1915 to 1918 accounted for more than 80 collected and uncollected stories. His brother—also in the Royal Engineers—had been killed earlier in the war.

McNeile had a quiet life after the war; his biographer Jonathon Green notes that "as in the novels of fellow best-selling writers such as P. G. Wodehouse or Agatha Christie, it is the hero who lives the exciting life". Although he was an "unremittingly hearty man", he suffered from delicate health following the war. He had a loud voice and a louder laugh, and "liked to enliven clubs and restaurants with the sight and sound of military good fellowship"; his friend and collaborator Gerard Fairlie described him as "not everybody's cup of tea", and commented that "he was loud in every possible way—in his voice, in his laugh, in his clothes, in the unconscious swagger with which he always motivated himself, in his whole approach to life". McNeile and his wife had two sons.

On 13 June 1919 McNeile retired onto the reserve officer list and was confirmed in the rank of major. The same year he also published a short-story collection, "Mufti", in which he introduced a type of character as "the Breed", a class of Englishman who was patriotic, loyal and "physically and morally intrepid". Although well received by the critics, the book failed commercially and, by the end of 1922, had only sold 16,700 copies from its first print run of 20,000; the unsold copies were pulped and the novel went out of print later that year.

In 1920 McNeile published "Bull-Dog Drummond", whose eponymous hero—a member of "the Breed"—became his most famous creation. He had first written Drummond as a detective for a short story in "The Strand Magazine", but the character was not successful and was changed for the novel, which was a thriller. Captain Hugh "Bulldog" Drummond DSO, MC was described in the novel's sub-title as "a demobilised officer who found peace dull" after service during the First World War with the fictional Loamshire Regiment. Drummond went on to appear in ten full-length novels by McNeile and a further seven by his friend Gerard Fairlie. The character was an amalgam of Fairlie, himself, and his idea of an English gentleman. Drummond also had roots in the literary characters Sherlock Holmes, Sexton Blake, Richard Hannay and The Scarlet Pimpernel. Drummond was characterised as large, very strong, physically unattractive and an "apparently brainless hunk of a man", who was also a gentleman with a private income; he could also be construed as "a brutalized ex-officer whose thirst for excitement is also an attempt to reenact the war". The character was later described by Cecil Day-Lewis, author of rival gentleman detective Nigel Strangeways, as an "unspeakable public school bully". Drummond's main adversary across four novels is Carl Peterson, a master criminal with no national allegiance, who is often accompanied by his wife, Irma. Irma is described by Jonathon Green as "the slinky epitome of a twenties 'vamp, and by Lawrence Treadwell as dark, sexy and from an oriental background, "a true "femme fatale"". After Carl Peterson's death in "The Final Count", Irma swears revenge on Drummond and kidnaps his wife—whom he had met in "Bull-Dog Drummond"—with the intent of killing him in the ensuing chase. Irma Peterson appears in six of McNeile's books, and in a further five by Fairlie.

McNeile adapted "Bulldog Drummond" for the stage. It was produced at Wyndham's Theatre during the 1921–22 season, with Gerald du Maurier playing the title role; it ran for 428 performances. The play also ran in New York during the same season, with A. E. Matthews as Drummond. Later in 1922 McNeile resigned his reserve commission with the rank of lieutenant-colonel, and moved as a tax exile to Territet, Montreux, Switzerland, with his wife; the Swiss countryside was later described in a number of his stories.

The following year McNeile introduced the character of Jim Maitland, a "footloose sahib of the period". Maitland was the protagonist of the 1923 novel "Jim Maitland"; he later appeared in a second novel in 1931, "The Island of Terror". Around the time McNeile killed off the Carl Peterson character in "The Final Count" (1926), he also introduced the character Ronald Standish, who first appeared in "The Saving Clause" (1927) and "Tiny Carteret" (1930) before becoming the protagonist in two collections of short stories, "Ronald Standish" (1933) and "Ask for Ronald Standish" (1936). The character also appeared in the final three Drummond novels, "Knock-Out" (1933), "Bull-Dog Drummond at Bay" (1935) and "Challenge" (1937). Standish was a sportsman who played cricket for England and was a part-time consultant with the War Office.

In 1929 McNeile edited a volume of short stories from O. Henry, "The Best of O. Henry"; the stories had served as models for him when he had started as a writer. The same year, the film "Bulldog Drummond" was released, starring Ronald Colman in the title role. Colman was nominated for an Academy Award for Best Actor at the 3rd Academy Awards ceremony. The film earned $750,000 at the box office, and McNeile received an estimated £5,000 for the rights to his novel. The same year he wrote his second play—"The Way Out"—which was staged at the Comedy Theatre in January 1930. About a year later he and his wife returned to England, and settled near Pulborough, West Sussex.

In 1935 McNeile, Fairlie, Sidney Gilliat and J.O.C. Orton collaborated on the screenplay "Bulldog Jack", a "comedy thriller" with Jack Hulbert and Fay Wray, which was produced by Gaumont British.

In 1937 McNeile was working with Fairlie on the play "Bulldog Drummond Hits Out" when he was diagnosed with terminal throat cancer. He came to an agreement with Fairlie for the play to continue after his death and for Fairlie to continue writing the Drummond stories. McNeile died on 14 August 1937 at his home in West Chiltington, West Sussex. Although most sources identify throat cancer as the cause of death, Treadwell also suggests that it may have been lung cancer. It was "traceable to his war service", and attributed to a gas attack. His funeral, with full military honours, was conducted at Woking crematorium. At his death his estate was valued at over £26,000.

"Bulldog Drummond Hits Out" was finished by Fairlie and had a short tour of Brighton, Birmingham, Manchester and Edinburgh, before opening in London at the Savoy Theatre on 21 December 1937. The story was later turned into a novel by Fairlie, with the title "Bulldog Drummond on Dartmoor". Fairlie continued to write Drummond novels, seven in total.

Drummond, McNeile's chief literary legacy, became a model for other literary heroes created in the 1940s and '50s. W. E. Johns used McNeile's work as a model for his character Biggles, while Ian Fleming admitted that James Bond was "Sapper from the waist up and Mickey Spillane below". Sydney Horler's popular character "Tiger" Standish was also modelled on Drummond.

McNeile's works fall into two distinct phases. Those works published between 1915 and 1918 are his war stories, and relate directly to his experiences during the First World War, while the later works are largely thrillers. His war stories were marketed by the "Daily Mail" and Hodder & Stoughton as a soldier's eyewitness accounts. When he started writing thrillers, Hodder & Stoughton advertised McNeile as a "light and entertaining" writer, and began publishing his works in the "Yellow Jacket" series. Magazine editors competed vigorously for Sapper's stories and paid extravagant prices for them. Gerald Fairlie, his close friend and collaborator, has put it on record that Sapper was the highest-paid short story writer of his time.

McNeile's early works, the war stories published before 1919, are either "plot-driven adventure narrative[s]", such as the short stories "The Song of the Bayonet" and "Private Meyrick, Company Idiot", or "atmospheric vignette[s]", such as "The Land of Topsy Turvy" and "The Human Touch". McNeile would write about 1,000 words every morning in a routine that was rarely disturbed; he took no breaks while writing and would do no re-writes until he completed his work. The academic Jessica Meyer has criticised his style as having "little aesthetic merit, being stylised, clichéd and often repetitive"; Richard Usborne agreed, adding that the female characters were "cardboard" and that McNeile was "wonderfully forgetful" about characters dead in one book and alive in the next. In the Bulldog Drummond stories, Watson identifies the central character as "a melodramatic creation, workable only within a setting of melodrama". The academic Joan DelFattore points out that while the characters and plots cannot be considered to be unique, credible or well-rounded, his books "make no claim to literary excellence", and are instead, "good, solid thrillers". Usborne agrees, and believes that McNeile wrote good stories that were flawed but well told. Meyer classifies the non-war stories as middlebrow, with "sentimental plotlines and presenting a social message about the condition of England". His early novels, particularly "Bull-Dog Drummond" and "The Black Gang", were structured loosely and in some ways as short stories. The academic Hans Bertens blamed this on McNeile's lack of experience and self-confidence, noting that in his later novels, McNeile "mastered the tricks of his trade".

DelFattore outlines the use of double adjectives to reinforce feelings towards enemies in both his war stories and thrillers, such as "filthy, murdering Boche", and "stinking, cowardly Bolshevik". She and the scholar Lise Jaillant also comment on the dehumanisation of the enemy, comparing them to animals and vermin. Watson noted the frequency of the use of the word "devil"—and variations—when discussing antagonists.

The major theme running throughout McNeile's works is the First World War. Between 1915 and 1918 he had five collections of short stories published about the war, while his post-war fiction can be seen as an extension of those stories, as "both treat the war as a trial with manhood at stake". His war stories were considered by contemporary audiences as anti-sentimental, realistic depictions of the trenches, and as a "celebration of the qualities of the Old Contemptibles". McNeile's view, as expressed through his writing, was that war was a purposeful activity for the nation and for individuals, even if that purpose was later wasted: a "valuable chance at national renewal that had been squandered". The positive effects of war on the individual were outlined by McNeile in "The Making of an Officer", his series of articles in "The Times", in which he wrote about "the qualities of leadership and selflessness essential to 'inspire' subalterns", a theme he returned to in his war stories—particularly "The Lieutenant and Others" and "Sergeant Michael Cassidy, R.E"—and then afterwards in his fictional stories, notably the Bulldog Drummond works.

McNeile's fictional work—particularly his Drummond series of books—shows characters who have served in the war and have been affected by it; Jaillant comments that Drummond's war-time experience "has shaped his social identity, his skills, and even his physical appearance". The Drummond character has been "brutalized by war", which accounts for his physical approach when dealing with Peterson and others.

McNeile provided Drummond with a "flamboyantly aggressive patriotism" towards England, which Drummond defends physically against those who challenge its stability or morality. Hans Bertens argued that the patriotism demonstrated by Drummond was closer to nationalistic pride and a paranoia about threats directed at the upper middle classes, of which Drummond was a member. Drummond's nickname—Bulldog—is symbolic of England, and he and his English gentlemen friends—"the Breed"—fight the conspiracy of foreigners threatening England's stability. McNeile's thriller stories do not often pit Englishman against Englishman as the main characters; most of the foreigners in his books are the villains.

Running throughout McNeile's books is the metaphor of warfare as sport. His war stories include descriptions of fights between individuals that carry a sporting motif: in "Sergeant Michael Cassidy, R.E.", he writes, "To bag a man with a gun is one thing; there is sport—there is an element of one against one, like when the quality goes big game shooting. But to bag twenty men by a mine has not the same feeling at all, even if they are Germans". The motif was continued into the Drummond novels. McNeile reinforces this theme through his use of the language of public school sports, or of boxing, poker or hunting. The titles of his books also use sporting imagery: "The Third Round", "The Final Count", "Knock-Out" and "Challenge".

McNeile's war story collections sold well; nearly 50,000 copies of his first book, "Sergeant Michael Cassidy, R.E.", were purchased in its first year, and nearly 58,000 copies the following year. His thrillers were also popular, with "Bulldog Drummond" selling 396,302 copies between 1920 and 1939, exceeding the 100,000-copies benchmark for "best-sellers". At his peak in the 1920s, he was the highest paid short story writer in the world, and it was estimated that in the last five years of his life he was earning around £10,000 a year; the "Daily Mirror" estimated that during his writing career he had earned £85,000.
McNeile's war stories were seen by reviewers as honest portrayals of the war, with British and American reviewers in the mainstream press praising his realism and avoidance of sentimentality in dealing with his subject matter. Reviewing "Men, Women, and Guns" for "The Times Literary Supplement", Francis Henry Gribble wrote that "Sapper has been successful in previous volumes of war stories ... When the time comes for picking out the writers whose war fiction has permanent value, his claim to be included in the list will call for serious examination." The reviewer of "Sergeant Michael Cassidy, R.E." for "The Atlanta Constitution" reminded its readers that McNeile "has been called the foremost literary genius of the British army." Jaillant observes that once McNeile moved from war stories to thrillers, with the concurrent re-positioning of advertising and marketing by Hodder & Stoughton, the reviewers also treated him differently, and presented him as "a writer of thrillers, without any pretension to literary seriousness". When reviewing "Bulldog Drummond Strikes Back" for "The New York Times", the critic observed that "if you like a good knock-down-and-drag-out yarn with excitement and violence on nearly every page, you can't go wrong on Bulldog Drummond"; for the novel "Bulldog Drummond at Bay", the reviewer considered that "as a piece of fictional melodrama, the book is first rate". In the British market, "The Times Literary Supplement" also characterised him as a mass-market thriller writer, which contrasted with its consideration of his earlier works.

From the 1950s on, McNeile's work came to be viewed in the light of events of the Second World War, and journalists such as Richard Usborne highlighted aspects of the stories which he considered were "carrying the Führer-principle". DelFattore agrees, and considers that the second Bulldog Drummond novel—"The Black Gang" (1922)—is when the fascist element was introduced. Jaillant notes that the accusations of fascism only came about after the Second World War, while the academic Ion Trewin considers that through the Drummond stories, McNeile was seen at the time as "simply an upstanding Tory who spoke for many of his countrymen".

Throughout the Drummond stories, much of the language used by McNeile's characters relating to ethnic minorities or Jews is considered by DelFattore to be "intensely conservative by modern standards"; Green observes that while the characters of other contemporary writers, such as Agatha Christie, "exhibit the inevitable xenophobia and anti-semitism of the period, McNeile's go far beyond the 'polite' norms". J. D. Bourn considers his language to be "rather distasteful", while the academic Michael Denning observed that "Drummond is a bundle of chauvinisms, hating Jews, Germans, and most other foreigners".

Notes
References



</doc>
<doc id="993445" url="https://en.wikipedia.org/wiki?curid=993445" title="Battle of Arras (1917)">
Battle of Arras (1917)

The Battle of Arras (also known as the Second Battle of Arras) was a British offensive on the Western Front during World War I. From 9 April to 16 May 1917, British troops attacked German defences near the French city of Arras on the Western Front. The British achieved the longest advance since trench warfare had begun, surpassing the record set by the French Sixth Army on 1 July 1916. The British advance slowed in the next few days and the German defence recovered. The battle became a costly stalemate for both sides and by the end of the battle, the British Third and First Armies had suffered about 160,000 and the German 6th Army about 125,000 casualties.

For much of the war, the opposing armies on the Western Front were at stalemate, with a continuous line of trenches from the Belgian coast to the Swiss border. The Allied objective from early 1915 was to break through the German defences into the open ground beyond and engage the numerically inferior German Army ("Westheer") in a war of movement. The British attack at Arras was part of the French Nivelle Offensive, the main part of which was to take place on the Aisne to the south. The aim of the French offensive was to break through the German defences in forty-eight hours. At Arras the Canadians were to re-capture Vimy Ridge, dominating the plain of Douai to the east, advance towards Cambrai and divert German reserves from the French front.

The British effort was an assault on a relatively broad front between Vimy in the north-west and Bullecourt to the south-east. After a long preparatory bombardment, the Canadian Corps of the First Army in the north fought the Battle of Vimy Ridge and took the ridge. The Third Army in the centre advanced astride the Scarpe River and in the south, the Fifth Army attacked the Hindenburg Line ("Siegfriedstellung") but was frustrated by the defence in depth and made few gains. The British armies then engaged in a series of small operations to consolidate the new positions. Although these battles were generally successful in achieving limited aims, they came at considerable cost.

When the battle officially ended on 16 May, British Empire troops had made significant advances but had been unable to achieve a breakthrough. New tactics and the equipment to exploit them had been used, showing that the British had absorbed the lessons of the Battle of the Somme and could mount set-piece attacks against fortified field defences. After the Second Battle of Bullecourt (3–17 May), the Arras sector returned to the stalemate that typified most of the war on the Western Front, except for attacks on the Hindenburg Line and around Lens, culminating in the Canadian Battle of Hill 70 (15–25 August).
At the beginning of 1917, the British and French were still searching for a way to achieve a strategic breakthrough on the Western Front. The previous year had been marked by the costly success of the Anglo-French offensive astride the River Somme, while the French had been unable to take the initiative because of intense German pressure at Verdun until after August 1916. The battles consumed enormous quantities of resources while achieving virtually no strategic gains on the battlefield. The cost to Germany of containing the Anglo-French attacks had been enormous and given that the material preponderance of the Entente and its allies could only be expected to increase in 1917, Hindenburg and Ludendorff decided on a defensive strategy on the Western Front for that year. This impasse reinforced the French and British commanders' belief that to end the stalemate they needed a breakthrough; while this desire may have been the main impetus behind the offensive, the timing and location were influenced by political and tactical considerations.

The mid-war years were momentous times. Governing politicians in Paris and London were under great pressure from the press, the people and their parliaments to win the war. Hundreds of thousands of casualties had been suffered at the battles of Gallipoli, the Somme and Verdun, with little prospect of victory in sight. The British Prime Minister, H. H. Asquith, resigned in early December 1916 and was succeeded by David Lloyd George. In France, Prime Minister Aristide Briand, along with Minister of Defence Hubert Lyautey were politically diminished and resigned in March 1917, following disagreements over the prospective Nivelle Offensive. The United States was close to declaring war on Germany; American public opinion was growing increasingly incensed by U-boat attacks upon civilian shipping, starting with the sinking of in 1915 and culminating in the torpedoing of seven American merchantmen in early 1917. The United States Congress finally declared war on Imperial Germany on 6 April 1917 but it would be more than a year before a suitable army could be raised, trained and transported to France.

Although the French and British had intended to launch a spring offensive in 1917, the strategy was threatened in February, when the Russians admitted that they could not meet the commitment to a joint offensive, which reduced the two-front offensive to a French assault along the Aisne River. In March, the German army in the west (), withdrew to the Hindenburg line in Operation Alberich, which negated the tactical assumptions underlying the plans for the French offensive. Until French troops advanced to compensate during the Battles of Arras, they encountered no German troops in the assault sector and it became uncertain whether the offensive would go forward. The French government desperately needed a victory to avoid civil unrest but the British were wary of proceeding, in view of the rapidly changing tactical situation. In a meeting with Lloyd George, French commander-in-chief General Robert Nivelle persuaded the British Prime Minister, that if the British launched a diversionary assault to draw German troops away from the Aisne sector, the French offensive could succeed. It was agreed in the London Convention of 16 January, that the French assault on the Aisne would begin in mid-April and that the British would make a diversionary attack in the Arras sector approximately one week prior.

Three armies of Field Marshal Sir Douglas Haig, the commander of the British Expeditionary Force (BEF) were in the Arras sector, the Fifth Army (General Hubert Gough) in the south, the Third Army (General Edmund Allenby) in the centre and the First Army (General Henry Horne) in the north and the plan was devised by Allenby. The British used the lessons of the Somme and Verdun the previous year and planned to attack attacking on an , from Vimy Ridge in the north to Neuville Vitasse, south of the Scarpe river. The preliminary bombardment was planned to last about a week at all points on the line, with a much longer and heavier barrage at Vimy Ridge.

In December 1916, the training manual replaced of 8 May 1916 and marked a significant step in the evolution of the British Expeditionary Force (BEF) into a homogeneous force, well adapted to its role on the Western Front. The duties of army, corps and divisions in planning attacks were standardised. Armies were to devise the plan and the principles of the artillery component. The corps were to allot tasks to divisions, which would then select objectives and devise infantry plans subject to corps approval. Artillery planning was controlled by corps with consultation of divisions by the corps General Officer Commanding, Royal Artillery (GOCRA) which became the title of the officer at each level of command who devised the bombardment plan, which was coordinated with neighbouring corps artillery commanders by the army GOCRA. Specific parts of the bombardment were nominated by divisions, using their local knowledge and the results of air reconnaissance. The corps artillery commander was to co-ordinate counter-battery fire and the howitzer bombardment for zero hour. Corps controlled the creeping barrage but divisions were given authority over extra batteries added to the barrage, which could be switched to other targets by the divisional commander and brigade commanders. provided the basis for the operational technique of the BEF for the rest of 1917.

The training manual of February 1917 marked the end of attacks made by lines of infantry with a few detached specialists. The platoon was divided into a small headquarters and four sections, one with two trained grenade-throwers and assistants, the second with a Lewis gunner and nine assistants carrying of ammunition, the third section comprised a sniper, scout and nine riflemen and the fourth section had nine men with four rifle-grenade launchers. The rifle and hand-grenade sections were to advance in front of the Lewis-gun and rifle-grenade sections, in two waves or in "artillery formation", which covered an area wide and deep, with the four sections in a diamond pattern, the rifle section ahead, rifle grenade and bombing sections to the sides and the Lewis gun section behind, until resistance was met. German defenders were to be suppressed by fire from the Lewis-gun and rifle-grenade sections, while the riflemen and hand-grenade sections moved forward, preferably by infiltrating around the flanks of the resistance, to overwhelm the defenders from the rear.

The changes in equipment, organisation and formation were elaborated in "The Normal Formation For the Attack" of February 1917, which recommended that the leading troops should push on to the final objective, when only one or two were involved but that for a greater number of objectives, when artillery covering fire was available for the depth of the intended advance, fresh platoons should "leap-frog" through the leading platoons to the next objective. The new organisations and equipment gave the infantry platoon the capacity for fire and manoeuvre, even in the absence of adequate artillery support. To bring uniformity in adoption of the methods laid down in the revised manuals and others produced over the winter, Haig established a BEF Training Directorate in January 1917, to issue manuals and oversee training. and its companion manuals like provided British infantry with "off-the-peg" tactics, devised from the experience of the Somme and from French Army operations, to go with the new equipment made available by increasing British and Allied war production and better understanding of the organisation necessary to exploit it in battle.

In a new manual of 1 December 1916, (Principles of Command for Defensive Battles in Positional Warfare), the policy of unyielding defence of ground regardless of its tactical value, was replaced by the defence of positions suitable for artillery observation and communication with the rear, where an attacking force would ""fight itself to a standstill and use up its resources while the defenders conserve[d] their strength"". Defending infantry would fight in areas, with the front divisions in an outpost zone up to deep behind listening posts, with the main line of resistance placed on a reverse slope, in front of artillery observation posts, which were kept far enough back to retain observation over the outpost zone. Behind the main line of resistance was a (battle zone), a second defensive area deep as far as possible on ground hidden from enemy observation, while in view of German artillery observers. A (rear battle zone) further back was to be occupied by the reserve battalion of each regiment.

Given the growing Allied superiority in munitions and manpower, attackers might still penetrate to the second (artillery protection) line, leaving in their wake German garrisons isolated in , (resistance nests, ) still inflicting losses and disorganisation on the attackers. As the attackers tried to capture the and dig in near the German second line, and of the counter-attack divisions would advance from the into the battle zone, in an immediate counter-attack (). If the immediate counter-attack failed, the counter-attack divisions would take their time to prepare a methodical attack, provided the lost ground was essential to the retention of the main position. Such methods required large numbers of reserve divisions ready to move to the battlefront. The reserve was obtained by creating by internal reorganisation of the army, bringing divisions from the eastern front and by shortening the Western Front, in Operation Alberich. By the spring of 1917, the German army in the west had a strategic reserve of 

"Experience of the German 1st Army in the Somme Battles", ("Erfahrungen der I Armee in der Sommeschlacht") was published on 30 January 1917 by Ludendorff but new defensive methods were controversial. During the Battle of the Somme in 1916 Colonel Fritz von Loßberg (Chief of Staff of the 1st Army) had been able to establish a line of "relief" divisions (), with the reinforcements from Verdun, which began to arrive in greater numbers in September. In his analysis of the battle, Loßberg opposed the granting of discretion to front trench garrisons to retire, as he believed that manoeuvre would not evade Allied artillery fire, which could blanket the forward area and invited French or British infantry to occupy vacant areas. Loßberg considered that spontaneous withdrawals would disrupt the counter-attack reserves as they deployed and further deprive battalion and division commanders of the meand to conduct an organised defence, which the dispersal of infantry over a wide area had already made difficult. Loßberg and others had severe doubts as to the ability of relief divisions to arrive on the battlefield in time to conduct an immediate counter-attack () from behind the battle zone. Sceptics wanted the tactic of fighting in the front line to continue, with authority devolved no further than battalion, to maintain organizational coherence in anticipation of a methodical counter-attack () by the relief divisions after Ludendorff was sufficiently impressed by Loßberg's memorandum to add it to the new "Manual of Infantry Training for War".

General Ludwig von Falkenhausen, commander of the 6th Army arranged the infantry at Arras for the rigid defence of the front-line, supported by methodical counter-attacks (), by the "relief" divisions () on the second or third day. Five were placed behind Douai, away from the front line. The new Hindenburg line ended at Telegraph Hill between Neuville-Vitasse and Tilloy lez Mofflaines, from whence the original system of four lines apart, ran north to the Neuville St. Vaast–Bailleul-aux-Cornailles road. About behind were the Wancourt–Feuchy and to the north the Point du Jour lines, running from the Scarpe river north along the east slope of Vimy ridge. The new "Wotan" line, which extended the Hindenburg position, was built around further back and not entirely mapped by the Allies until the battle had begun.

Just before the battle, Falkenhausen had written that parts of the front line might be lost but the five could be brought forward to relieve the front divisions on the evening of the second day. On 6 April, General Karl von Nagel, the 6th Army Chief of Staff, accepted that some of the front divisions might need to be relieved on the first evening of battle but that any penetrations would be repulsed with local immediate counter-attacks () by the front divisions. On 7 April, Nagel viewed the imminent British attack as a limited effort against Vimy ridge, preparatory to a bigger attack later, perhaps combined with the French attack expected in mid-April. Construction of positions to fulfil the new policy of area defence had been drastically curtailed by shortages of labour and the long winter, which affected the setting of concrete. The 6th Army commanders had also been reluctant to encourage the British to change their plans if the British detected a thinning of the front line. The Germans were inhibited by the extent of British air reconnaissance, which observed new field works and promptly directed artillery fire on them. The 6th Army failed to redeploy its artillery, which remained in lines easy to see and bombard. Work on defences was also divided between maintaining the front line, strengthening the third line and the new (Drocourt–Quéant switch line) further back.

After the Allied conference at Chantilly, Haig issued instructions for army commanders on 17 November 1916, with a general plan for offensive operations in the spring of 1917. The Chief engineer of the Third Army, Major-General E. R. Kenyon, composed a list of requirements by 19 November, for which he had 16 Army Troops companies, five with each corps in the front line and one with XVIII Corps, four tunnelling companies, three entrenching battalions, eight RE labour battalions and 37 labour companies. Inside the old walls of Arras were the Grand and Petit places, under which there were old cellars, which were emptied and refurbished for the accommodation of 13,000 men. Under the suburbs of St Sauveur and Ronville were many caves, some huge, which were rediscovered by accident in October 1916. When cleared out the caves had room for 11,500 men, one in the Ronville system housing 4,000 men. The Crinchon sewer followed the ditch of the old fortifications and tunnels were dug from the cellars to the sewer.

Two long tunnels were excavated from the Crinchon sewer, one through the St Sauveur and one through the Ronville system, allowing the 24,500 troops safely sheltered from German bombardment to move forward underground, avoiding the railway station, an obvious target for bombardment. The St Sauveur tunnel followed the line of the road to Cambrai and had five shafts in no man's land but the German retirement to the Hindenburg Line forestalled the use of the Ronville tunnels, when the German front line was withdrawn and there was no time to extend the diggings. The subterranean workings were lit by electricity and supplied by piped water, with gas-proof doors at the entrances; telephone cables, exchanges and testing-points used the tunnels, a hospital was installed and a tram ran from the sewer to the St Sauveur caves. The observation post for the VI Corps heavy artillery off the St Sauveur tunnel, had a telephone exchange with 750 circuits; much of the work in this area being done by the New Zealand Tunnelling Company.

On the First Army front German sappers also conducted underground operations, seeking out Allied tunnels to assault and counter-mine, in which 41 New Zealand tunnellers were killed and 151 wounded. The British tunnellers had gained an advantage over the German miners by the Autumn of 1916, which virtually ended the German underground threat. The British turned to digging 12 subways about down, to the front line, the longest tunnel being long of the dug. In one sector, four Tunnelling companies of 500 men each, worked around-the-clock in 18-hour shifts for two months to dig of subways for foot traffic, tramways with rails for hand-drawn trolleys and a light railway system. Most tunnels were lit by electricity, accommodated telephone cables and some had trams and water supplies. Caverns were dug into the sides for brigade and battalion HQs, first aid posts and store-rooms. The subways were found to be a most efficient way to relieve troops in the line, form up for the attack and then to evacuate wounded. Some of the tunnels were continued into Russian saps with exits in mine craters in no man's land and new mines were laid. Galleries were dug to be opened after the attack for communication or cable trenches, the work being done by the 172nd, 176th, 182nd and 185th Tunnelling companies (Lieutenant-Colonel G. C. Williams, Controller of Mines First Army).

Although the Royal Flying Corps (RFC) entered the battle with inferior aircraft to the "Luftstreitkräfte", this did not deter their commander, General Trenchard, from adopting an offensive posture. Dominance of the air over Arras was essential for reconnaissance and the British carried out many aerial patrols. RFC aircraft carried out artillery spotting, photography of trench systems and bombing. Aerial observation was hazardous work as, for best results, the aircraft had to fly at slow speeds and low altitude over the German defences. It became even more dangerous with the arrival of the Red Baron, Manfred von Richthofen in March 1917. The presence of "Jasta" 11 led to sharply increased losses of Allied pilots and April 1917, became known as Bloody April. A German infantry officer later wrote,

The average flying life of a RFC pilot in Arras in April was 18 hours and from 4–8 April, the RFC lost 75 aircraft and 105 aircrew. The casualties created a pilot shortage and replacements were sent to the front straight from flying school; during the same period, 56 aircraft were crashed by inexperienced RFC pilots.

To keep enemy action to a minimum during the assault, a creeping barrage was planned. This required gunners to create a curtain of high explosive and shrapnel shell explosions that crept across the battlefield in lines, about one hundred metres in advance of the assaulting troops. The Allies had previously used creeping barrages at the Battle of Neuve Chapelle and the Battle of the Somme but had encountered two technical problems. The first was accurately synchronising the movement of the troops to the fall of the barrage: for Arras, this was overcome by rehearsal and strict scheduling. The second was the barrage falling erratically as the barrels of heavy guns wore swiftly but at differing rates during fire: for Arras, the rate of wear of each gun barrel was calculated and calibrated accordingly. While there was a risk of friendly fire, the creeping barrage forced the Germans to remain in their shelters, allowing Allied soldiers to advance without fear of machine gun fire. The new instantaneous No. 106 Fuze had been adapted from a French design for high-explosive shells so that they detonated on the slightest impact, vaporising barbed wire. Poison gas shells were used for the final minutes of the barrage.

The principal danger to assaulting troops came from enemy artillery fire as they crossed no man's land, accounting for over half the casualties at the first day of the Somme. A further complication was the location of German artillery, hidden as it was behind the ridges. In response, specialist artillery units were created to attack German artillery. Their targets were provided by 1st Field Survey Company, Royal Engineers, who collated data obtained from flash spotting and sound ranging. (Flash spotting required Royal Flying Corps observers to record the location of telltale flashes made by guns whilst firing.) On Zero-Day, 9 April, over 80 percent of German heavy guns in the sector were neutralised (that is, "unable to bring effective fire to bear, the crews being disabled or driven off") by counter-battery fire. Gas shells were also used against the draught horses of the batteries and to disrupt ammunition supply columns.

Forty tanks of the 1st Brigade were to be used in the attack on the Third Army front, eight with XVIII Corps and sixteen each in VII Corps and VI Corps. When the blue line had been reached, four of the VII Corps tanks were to join VI Corps for its attack on the brown line. The black line (first objective) was not to be attacked by tanks, which were to begin the drive to the front line at zero hour and rendezvous with infantry at the black line two hours later. The tanks were reserved for the most difficult objectives beyond the black line in groups of up to ten vehicles. Four tanks were to attack Neuville Vitasse, four against Telegraph Hill, four against The Harp and another four against Tilloy lez Mofflaines and two were to drive down the slope from Roclincourt west of Bois de la Maison Blanche. Once the blue line had fallen, the tanks still running were to drive to rally points.

The preliminary bombardment of Vimy Ridge started on 20 March; and the bombardment of the rest of the sector on 4 April. Limited to a front of only , the bombardment used 2,689,000 shells, over a million more than had been used on the Somme. German casualties were not heavy but the men became exhausted by the endless task of keeping open dug-out entrances and demoralised by the absence of rations caused by the difficulties of preparing and moving hot food under bombardment. Some went without food altogether for two or three consecutive days. By the eve of battle, the front-line trenches had ceased to exist and their barbed wire defences were blown to pieces. The official history of the 2nd Bavarian Reserve Regiment describes the front line as "consisting no longer of trenches but of advanced nests of men scattered about". The 262nd Reserve Regiment history writes that its trench system was "lost in a crater field". To add to the misery, for the last ten hours of bombardment, gas shells were added.

Zero-Hour had originally been planned for the morning of 8 April (Easter Sunday) but it was postponed 24 hours at the request of the French, despite reasonably good weather in the assault sector. Zero-Day was rescheduled for 9 April with Zero-Hour at 05:30. The assault was preceded by a hurricane bombardment lasting five minutes, following a relatively quiet night. When the time came, it was snowing heavily; Allied troops advancing across no man's land were hindered by large drifts. It was still dark and visibility on the battlefield was very poor. A westerly wind was at the Allied soldiers' backs blowing "a squall of sleet and snow into the faces of the Germans". The combination of the unusual bombardment and poor visibility meant many German troops were caught unawares and taken prisoner, still half-dressed, clambering out of the deep dug-outs of the first two lines of trenches. Others were captured without their boots, trying to escape but stuck in the knee-deep mud of the communication trenches.

The major British assault of the first day was directly east of Arras, with the 12th Division attacking Observation Ridge, north of the Arras—Cambrai road. After reaching this objective, they were to push on towards Feuchy, as well as the second and third lines of German trenches. At the same time, elements of the 3rd Division began an assault south of the road, with the taking of Devil's Wood, Tilloy-lès-Mofflaines and the Bois des Boeufs as their initial objectives. The ultimate objective of these assaults was the "Monchyriegel", a trench running between Wancourt and Feuchy and an important component of the German defences. Most of these objectives, including Feuchy village, had been achieved by the evening of 10 April though the Germans were still in control of large sections of the trenches between Wancourt and Feuchy, particularly in the area of the heavily fortified village of Neuville-Vitasse. The following day, troops from the 56th Division were able to force the Germans out of the village, although the "Monchyriegel" was not fully in British hands until a few days later. The British were able to consolidate these gains and push forward towards Monchy-le-Preux, although they suffered heavy casualties in fighting near the village.
One reason for the success of the offensive in this sector was the failure of Falkenhausen to employ a defence in depth. In theory, the enemy would be allowed to make initial gains, thus stretching their lines of communication. Reserves held close to the battlefield would be committed once the initial advance had bogged down, before enemy reinforcements could be brought up. The defenders would thus be able to counter-attack and regain any lost territory. In this sector, Falkenhausen kept his reserve troops too far from the front and they were too late for a useful counter-attack on either 10 or 11 April.

At roughly the same time, in perhaps the most carefully crafted portion of the entire offensive, the Canadian Corps launched an assault on Vimy Ridge. Advancing behind a creeping barrage and making heavy use of machine guns – eighty to each brigade, including one Lewis gun in each platoon – the corps was able to advance through about of German defences and captured the crest of the ridge at about 13:00. Military historians have attributed the success of this attack to careful planning by Canadian Corps commander Julian Byng and his subordinate General Arthur Currie, constant training and the assignment of specific objectives to each platoon. By giving units specific goals, troops could continue the attack even if their officers were killed or communication broke down, thus bypassing two major problems of combat on the Western Front. The Canadian troops could see the Germans in retreat across the Douai Plain away from the ridge.There was nevertheless an inflexibility to the plan which prevented the leading troops from continuing the advance and on 10 April the Germans began to stop the gaps with reserves.

After the territorial gains of the first two days, a lull followed as the immense logistical support needed to keep armies in the field caught up with the new realities. Battalions of pioneers built temporary roads across the churned up battlefield; heavy artillery (and its ammunition) was manhandled into position in new gun pits; food for the men and feed for the draught horses was brought up and casualty clearing stations were established in readiness for the inevitable counter-attacks. Allied commanders also faced a dilemma: whether to keep their exhausted divisions on the attack and run the risk of having insufficient manpower or replace them with fresh divisions and lose momentum. In London, "The Times" printed,

The Berlin "Vossische Zeitung," wrote: "We have to count on reverses like that near Arras. Such events are a kind of tactical reverse. If this tactical reverse is not followed by strategical effects i.e., breaking through on the part of the aggressor, then the whole battle is nothing but a weakening of the attacked party in men and materiel." The same day, the "Frankfurter Zeitung" commented: "If the British succeed in breaking through it will render conditions worse for them as it will result in freedom of operations which is Germany's own special art of war". General Ludendorff was less sanguine. The news of the battle reached him during his 52nd birthday celebrations at his headquarters in Kreuznach. He wrote: "I had looked forward to the expected offensive with confidence and was now deeply depressed". He telephoned each of his commanders and "gained the impression that the principles laid down by "OHL" were sound but the whole art of leadership lies in applying them correctly". (A later court of inquiry would establish that Falkenhausen had indeed misunderstood the principles of defence in depth.) Ludendorff immediately ordered reinforcements. Then, on 11 April, he sacked Falkenhausen's chief of staff and replaced him with Loßberg. Loßberg went armed with "vollmacht" (a power of command enabling him to issue orders in the army ccommander's name), replacing Falkenhausen. Within hours of arriving, Loßberg began to restructure the German defences. The British aimed to consolidate the gains made in the first days of the offensive, to keep the initiative and to break through in concert with the French at Aisne. From 16 April, it was apparent that the French part of the Nivelle Offensive on the Aisne had not achieved a breakthrough. Haig continued to attack at Arras, to continue to divert troops from the French on the Aisne.

At 04:45 on 23 April, following two days of poor visibility and freezing weather, British troops of the Third Army (VI and VII corps), attacked to the east along an approximate front from Croisilles to Gavrelle on both sides of the Scarpe. The 51st Division attacked on the northern side in heavy fighting on the western outskirts of Roeux Wood and the chemical works. On their left, the 37th Division, attacked the buildings west of Roeux Station and gained the line of their objectives on the western slopes of Greenland Hill, north of the railway. On the left of the main British attack the 63rd Division, made rapid progress against Gavrelle and secured the village. To the south of the Scarpe and east of Monchy-le-Preux the 29th Division gained the western slopes of the rising ground known as Infantry Hill. The Cojeul river marked a divisional boundary within the VI Corps. Guémappe on the north side of the river was the objective of the 15th Division, attacking east from Wancourt towards Vis-en-Artois. The objective was commanded by the higher ground on the south bank and it was not until the 50th Division captured the rise on the south side of the Cojeul that the village was taken. Several determined German counter-attacks were made and by the morning of 24 April, the British held Guémappe, Gavrelle and the high ground overlooking Fontaine-lez-Croisilles and Cherisy; the fighting around Roeux was indecisive.

The principal objective of the attack was the need to sustain a supporting action tying down German reserves to assist the French offensive against the plateau north of the Aisne traversed by the Chemin des Dames. Haig reported,

At 04:25 on 28 April, British and Canadian troops launched the main attack on a front of about north of Monchy-le-Preux. The battle continued for most of 28 and 29 April, with the Germans delivering determined counter-attacks. The British positions at Gavrelle were attacked seven times with strong forces and on each occasion the German thrust was repulsed with great loss by the 63rd Division. The village of Arleux-en-Gohelle was captured by the 1st Canadian Division after hand-to-hand fighting and the 2nd Division (Major-General C. E. Pereira), made further progress in the neighbourhood of Oppy, Greenland Hill (37th Division) and between Monchy-le-Preux and the Scarpe (12th Division).

After securing the area around Arleux at the end of April, the British determined to launch another attack east from Monchy to try to break through the "Boiry Riegel" and reach the "Wotanstellung", a major German defensive fortification. This was scheduled to coincide with the Australian attack at Bullecourt to present the Germans with a two–pronged assault. British commanders hoped that success in this venture would force the Germans to retreat further to the east. With this objective in mind, the British launched another attack near the Scarpe on 3 May. However, neither prong was able to make any significant advances and the attack was called off the following day after incurring heavy casualties. Although this battle was a failure, the British learned important lessons about the need for close liaison between tanks, infantry and artillery, which they would use in the Battle of Cambrai, 1917.

South of Arras, the plan called for two divisions, the British 62nd Division and the Australian 4th Division to attack either side of the village of Bullecourt and push the Germans out of their fortified positions and into the reserve trenches. The attack was initially scheduled for the morning of 10 April but the tanks intended for the assault were delayed by bad weather and the attack was postponed for 24 hours. The order to delay did not reach all units in time and two battalions of the West Yorkshire Regiment attacked and were driven back with significant losses. Despite protests from the Australian commanders, the attack was resumed on the morning of 11 April; mechanical failures meant that only 11 tanks were able to advance in support and the limited artillery barrage left much of the barbed wire in front of the German trenches uncut. Additionally, the abortive attack of the previous day alerted German troops in the area to the impending assault and they were better prepared than they had been in the Canadian sector. Misleading reports about the extent of the gains made by the Australians deprived them of necessary artillery support and although elements of the 4th Division briefly occupied sections of German trenches, they were ultimately forced to retreat with heavy losses. In this sector, the German commanders correctly employed the elastic defence and were therefore able to counter-attack effectively. The Germans acquired two of the tanks which had been used and after seeing them perforated by armour-piercing bullets, believed the rifle A.P. bullet was an effective anti-tank weapon, which threw them off-guard.

Observing that the 1st Australian Division was holding a frontage of , the local German corps commander (General Otto von Moser, commanding the German XIV Reserve Corps) planned a spoiling attack to drive back the advanced posts, destroy supplies and guns and then retire to the Hindenburg defences. Passing his plans to higher command they assigned an extra division to his corps to further strengthen the attack. Attacking with 23 battalions (from four divisions), the German forces managed to penetrate the Australian front line at the junction on the 1st Australian Division and 2nd Australian Division and occupy the village of Lagnicourt (damaging some Australian artillery pieces). Counter-attacks from the Australian 9th and 20th Australian battalions, restored the front line and the action ended with the Australians suffering 1,010 casualties, against 2,313 German casualties.

After the initial assault around Bullecourt failed to penetrate the German lines, British commanders made preparations for a second attempt. British artillery began an intense bombardment of the village, which by 20 April had been virtually destroyed. Although the infantry assault was planned for 20 April, it was pushed back a number of times and finally set for the early morning of 3 May. At 03:45, elements of the 2nd Australian Division attacked east of Bullecourt village, intending to pierce the Hindenburg Line and capture Hendecourt-lès-Cagnicourt, while British troops from the 62nd (2nd West Riding) Division attacked Bullecourt, which was finally taken by the British 7th Division and despite determined effort by the Germans was held by the British 62nd Division. German resistance was fierce and when the offensive was called off on 17 May, few of the initial objectives had been met. The Australians were in possession of much of the German trench system between Bullecourt and Riencourt-lès-Cagnicourt but had been unable to capture Hendecourt. To the west, British troops managed to push the Germans out of Bullecourt but incurred considerable losses, failing also to advance north-east to Hendecourt.

By the standards of the Western Front, the gains of the first two days were nothing short of spectacular. A great deal of ground was gained for relatively few casualties and a number of tactically significant points were captured, notably Vimy Ridge. The offensive drew German troops away from the French offensive in the Aisne sector. In many respects, the battle might be deemed a victory for the British and their allies but these gains were offset by high casualties after the first two days and the failure of the French offensive at the Aisne. By the end of the offensive, the British had suffered more than 150,000 casualties and gained little ground since the first day. Despite significant early gains, they were unable to break through and the situation reverted to stalemate. Although historians generally consider the battle a British victory, in the wider context of the front, it had very little impact on the strategic or tactical situation. Ludendorff later commented "no doubt exceedingly important strategic objects lay behind the British attack but I have never been able to discover what they were". Ludendorff was also "very depressed; had our principles of defensive tactics proved false and if so, what was to be done?"

On the Allied side, twenty-five Victoria Crosses were awarded. On the German side, on 24 April 1917, Kaiser Wilhelm awarded Loßberg the Oakleaves (similar to a bar for a repeat award) for the Pour le Mérite he had received at the Battle of the Somme the previous September.

The most quoted Allied casualty figures are those in the returns made by Lt-Gen Sir George Fowke, Haig's adjutant-general. His figures collate the daily casualty tallies kept by each unit under Haig's command. Third Army casualties were 87,226; First Army 46,826 (including 11,004 Canadians at Vimy Ridge); and Fifth Army 24,608; totalling 158,660.
German losses are more difficult to determine. "Gruppe Vimy" and "Gruppe Souchez" suffered 79,418 casualties but the figures for "Gruppe Arras" are incomplete. The writers of the German Official History "Der Weltkrieg", recorded losses to the end of April and another by the end of May, a total of and casualties. German records excluded those "lightly wounded". Captain Cyril Falls (the writer of the Official History volume on the battle) estimated that 30 percent needed to be added to German returns for comparison with the British. Falls made "a general estimate" that German casualties were "probably fairly equal". Nicholls puts them at 120,000 and Keegan at 130,000.

Although Haig paid tribute to Allenby for the plan's "great initial success", Allenby's subordinates "objected to the way he handled the ... attritional stage". Allenby was sent to command the Egyptian Expeditionary Force in Palestine. He regarded the transfer as a "badge of failure", but he "more than redeemed his reputation by defeating" the Ottomans in battles that were fought in the Sinai and Palestine Campaign in 1917–18. Haig stayed in his post until the end of the war. When the failures of the 6th Army command became apparent, Ludendorff removed Falkenhausen (who never held a field command again, spending the rest of war as Governor-General of Belgium) and several staff officers. In early 1918, "The Times" carried an article, "Falkenhausen's Reign of Terror", describing 170 military executions of Belgian civilians since he had been appointed governor. Ludendorff and Loßberg discovered that although the Allies were capable of breaking through the first position, they could probably not capitalise on their success if they were confronted by a mobile, clever defence. Ludendorff immediately ordered more training in manoeuvre warfare for the "Eingreif" divisions. Loßberg was soon promoted to general and directed the defensive battle of the 4th Army against the Flanders Offensive of the summer and late autumn; he had become "legendary as the fireman of the Western Front; always sent by OHL to the area of crisis".

Siegfried Sassoon makes reference to the battle in the poem . The Anglo-Welsh lyric poet Edward Thomas was killed by a shell on 9 April 1917, during the first day of the Easter Offensive. Thomas's war diary gives a vivid and poignant picture of life on the Western front in the months leading up to the battle. The composer Ernest John Moeran was wounded during the attack on Bullecourt on 3 May 1917.

Books

Newspapers



</doc>
<doc id="996468" url="https://en.wikipedia.org/wiki?curid=996468" title="Operation Brevity">
Operation Brevity

Operation Brevity was a limited offensive conducted in mid-May 1941, during the Western Desert Campaign of the Second World War. Conceived by the commander-in-chief of the British Middle East Command, General Archibald Wavell, Brevity was intended to be a rapid blow against weak Axis front-line forces in the Sollum–Capuzzo–Bardia area of the border between Egypt and Libya. Although the operation got off to a promising start, throwing the Axis high command into confusion, most of its early gains were lost to local counter-attacks, and with German reinforcements being rushed to the front the operation was called off after one day.

Egypt had been invaded by Libyan-based Italian forces in September 1940, but by February of the following year a British counter-offensive had advanced well into Libya, destroying the Italian Tenth Army in the process. British attention then shifted to Greece, which was under the threat of Axis invasion. While Allied divisions were being diverted from North Africa, the Italians reinforced their positions and were supported by the arrival of the German "Afrika Korps" under "Generalleutnant" Erwin Rommel. Rapidly taking the offensive against his distracted and over-stretched opponent, by April 1941 Rommel had driven the British and Commonwealth forces in Cyrenaica back across the Egyptian border. Although the battlefront now lay in the border area, the port city of Tobruk— inside Libya—had resisted the Axis advance, and its substantial Australian and British garrison constituted a significant threat to Rommel's lengthy supply chain. He therefore committed his main strength to besieging the city, leaving the front line only thinly held.

Wavell defined Operation Brevity's main objectives as the acquisition of territory from which to launch a further planned offensive toward Tobruk, and the depletion of German and Italian forces in the region. With limited battle-ready units to draw on in the wake of Rommel's recent successes, on 15 May Brigadier William Gott attacked in three columns with a mixed infantry and armoured force. The strategically important Halfaya Pass was taken against stiff Italian opposition, and deeper inside Libya Fort Capuzzo was captured, but German counter-attacks under Colonel Maximilian von Herff regained the fort during the afternoon causing heavy casualties amongst its defenders. Gott—concerned that his forces were in danger of being caught by German armour in open ground—conducted a staged withdrawal to the Halfaya Pass on 16 May, and Brevity was closed down. The importance of the Halfaya Pass as a safe supply route was highlighted to Rommel, and 11 days later it was recaptured during Operation Skorpion, a German counter-attack.

In early September 1940, the Italian 10th Army based in Libya conducted the Italian invasion of Egypt and three months later, the British and Commonwealth troops of the Western Desert Force began a counter-offensive, codenamed Operation Compass. In two months, the British advanced , occupying the Italian province of Cyrenaica and destroying the 10th Army. The advance was halted in February 1941 because of supply shortages and to give priority to the Battle of Greece. Renamed XIII Corps and reorganised under HQ Cyrenaica Command (CYRCOM), the troops of the former Western Desert Force adopted a defensive posture. Over the next few months, HQ Cyrenaica lost its commander, Lieutenant-General Sir Henry Maitland Wilson, followed by the 2nd New Zealand Division and the 6th Australian Division when they were sent to Greece in Operation Lustre. The 7th Armoured Division, with virtually no serviceable tanks left, was also withdrawn and sent to the Nile Delta for rest and refitting. Wilson was replaced by Lieutenant-General Philip Neame; parts of the 2nd Armoured Division and 9th Australian Division were deployed to Cyrenaica but both formations were inexperienced, ill-equipped and in the case of the 2nd Armoured Division, well under strength, after detachments to Greece.
The Italians responded by despatching the 132nd Armoured Division "Ariete" and 102nd Motorised Division"Trento" to North Africa. From February 1941 until early May, Operation Sonnenblume saw the arrival of the German "Afrika Korps" in Tripoli to reinforce their Italian allies. Commanded by "Generalleutnant" Erwin Rommel and consisting of the 5th Light and 15th Panzer Division, the "Afrika Korps" was to block Allied attempts to drive the Italians out of the region. Rommel seized on the weakness of his opponents and without waiting for his forces fully to assemble, rapidly went on the offensive. During March and April, the remaining units of the 2nd Armoured Division were destroyed as the Axis forces advanced, which also forced the British and Commonwealth forces into retreat. Neame and the General Officer Commanding British Troops Egypt—Lieutenant-General Richard O'Connor—were captured and the British command structure had to be reorganised. HQ Cyrenaica was dissolved on 14 April and its command functions taken over by a new HQ Western Desert Force (Lieutenant-General Noel Beresford-Peirse). The 9th Australian Infantry Division fell back to the fortress port of Tobruk and the remaining British forces withdrew a further east to Sollum on the Libyan–Egyptian border. With the main Axis force conducting the Siege of Tobruk a small battlegroup ("Kampfgruppe") commanded by Colonel Maximilian von Herff continued to press eastward. Capturing Fort Capuzzo and Bardia in passing, it then advanced into Egypt; by the end of April had taken Sollum and the tactically important Halfaya Pass. Rommel garrisoned these positions, reinforced the "Kampfgruppe" and ordered it onto the defensive.

The Tobruk garrison received supplies from the Royal Navy and Rommel was unable to take the port. This failure was significant; his front line positions at Sollum were at the end of an extended supply chain that stretched back to Tripoli and was threatened by the Tobruk garrison. The substantial commitment required to invest Tobruk prevented him from building up his forces at Sollum, making further advances into Egypt impractical. By maintaining possession of Tobruk, the Allies had regained the initiative.

General Archibald Wavell—the commander-in-chief of the British Middle East Command—conceived Operation Brevity as a rapid blow in the Sollum area. Wavell intended to create advantageous conditions from which to launch Operation Battleaxe, the main offensive that he was planning for June. Operation Brevity's primary objectives were to recapture the Halfaya Pass, to drive the enemy from the Sollum and Capuzzo areas, and to deplete Rommel's forces. A secondary objective was to advance toward Tobruk, although only as far as supplies would allow, and without risking the force committed to the operation.

Operation Brevity would be carried out by the 22nd Guards Brigade and elements of the 7th Armoured Division. Its armoured component consisted of 29 cruiser tanks of the 2nd Royal Tank Regiment (2RTR) and 24 infantry tanks of the 4th Royal Tank Regiment (4RTR). The Royal Air Force (RAF) allocated all available fighters and a small force of bombers to the operation.

Brigadier William Gott—in command of all Allied front-line forces since the retreat—was to lead the operation in the field, and his plan was to advance in three parallel columns. On the desert flank to the south, the 7th Armoured Brigade group was to move from Bir el Khireigat to Sidi Azeiz destroying any opposition encountered en route. This group included three small mobile forces ("Jock columns") of the 7th Support Group, the cruiser tanks of 2RTR, and the armoured cars of the 11th Hussars, whose task was to patrol the open desert on the left flank and monitor the Sidi Azeiz–Bardia road. In the centre, the 22nd Guards Brigade group was to clear the top of the Halfaya Pass, secure Bir Wair, Musaid, and Fort Capuzzo, and conduct a company-sized probe toward Bardia. The group included two infantry formations (1st Battalion Durham Light Infantry and 2nd Battalion Scots Guards), and the infantry tanks of 4RTR. In the north, the "coast group" was to advance along the coast road, capturing the lower Halfaya Pass, Sollum barracks, and the town of Sollum. The group included elements of the 2nd Battalion The Rifle Brigade, and the 8th Field Regiment Royal Artillery.

The main Axis opposition was "Kampfgruppe" von Herff, positioned on the desert plateau. It included 30–50 tanks of the 2nd Battalion Panzer Regiment 5, an Italian motorised infantry battalion of the "Trento" Division, and supporting arms. The front line area around Halfaya Pass was defended by two companies of "Bersaglieri"—well trained Italian motorised infantry—with artillery support.

On 9 May, the Germans intercepted a British weather report over the radio. The "Afrika Korps" war diary noted that "In the past, such reports had always been issued prior to the important enemy offensives to capture Sidi Barrani, Bardi, Tobruk, and the Gebel." Rommel's response was to strengthen the eastern side of his cordon around Tobruk as a precaution against sorties from the garrison, and to order "Kampfgruppe" von Herff to adopt a more aggressive posture. On 13 May, Axis aircraft bombed British tank concentrations, and Herff expected an imminent British attack. However, the following day aircraft were unable to locate the British, and it was reported that the "enemy intentions to attack were not known".

On 13 May, Wavell's infantry battalions began to concentrate at their start lines, followed by the tank regiments during the early hours of 15 May. At 06:00, the three columns began their advance, supported overhead by a standing patrol of Hawker Hurricane fighters.

Reaching the top of the Halfaya Pass, the 22nd Guards Brigade group ran into heavy opposition from an Italian "Bersaglieri" infantry company, supported by anti-tank guns, under the command of Colonel Ugo Montemurro. This unit fought tenaciously, doing much to repair the poor impression Rommel had of his Italian allies. Opening fire upon the attacking British tanks, the "Bersaglieri" found their 47mm anti-tank guns to be unable to penetrate the armour of the Matilda infantry tanks. At , the gunners shifted targets. Now aiming at the tracks and undercarriages, when the tanks raised up crossing low stone walls and rocks, seven tanks were disabled. For his conduct during this action, Rommel recommended that Montemurro be awarded the Iron Cross First Class. At the cost of these seven tanks, the position was taken by C Squadron 4RTR and G Company 2nd Scots Guards, and the brigade group pushed on towards the Bir Wair-Musaid road. At around 08:00, it received the surrender of a large German-Italian camp, and by 10:15 Bir Wair and Musaid had been taken in the face of limited opposition.

A Squadron 4RTR and the 1st Durham Light Infantry (1DLI) continued the advance toward Fort Capuzzo. Concealed in hull down positions behind a ridge near the fort were 20–30 German tanks, supported by anti tank guns. These engaged A Squadron, disabling five tanks, but were forced to withdraw as the squadron pressed its attack. On the final approach to Fort Capuzzo, contact was lost between 4RTR's tanks and 1DLI's leading C Company, and the attack on the fort began without armoured support. The fort was vigorously defended, and it was not until just before midday that C Company, reunited with A Squadron 4RTR and reinforced by A and B Companies 1DLI, eventually took the position. D Company 1DLI—which had been in reserve during the attack—then made a wide left hook to capture a small landing ground to the north of the fort.

In the afternoon, one company of the 2nd Scots Guards probed toward Bardia, the infantry coming under heavy machine gun fire from three positions as they neared Sollum barracks. A group of Universal Carriers—commanded by Sergeant F. Riley—charged the gun positions and quickly neutralised them, but one carrier was disabled when the group was subsequently engaged by anti-tank guns. Riley executed a second charge, silencing these too and taking their crews prisoner. His carrier was hit three times; for his actions Riley was awarded the Military Medal, the battalion's first decoration of the war.

On the desert flank, 2RTR advanced with the 7th Armoured Brigade group. During the morning, reports were received of up to 30 German armoured vehicles operating nearby, and A Squadron 2RTR moved to investigate. Most of the German force had pulled back, but three tanks were located and brought under fire. One Panzer IV was disabled and the other two driven off, for the loss of one British tank due to mechanical failure. A second force of 15 German tanks was engaged by two tanks of No 2 Troop, destroying a Panzer III and forcing the remainder to withdraw. By midday, the brigade group had reached a position west of Fort Capuzzo, and in the afternoon the nine remaining cruisers of A Squadron 2RTR began a reconnaissance patrol towards Sidi Azeiz.

The advance along the coastal road—which lacked tank support—was held up all morning by determined Italian resistance at the bottom of Halfaya Pass. This objective was finally achieved toward evening when S Company 2nd Rifle Brigade—supported by Australian anti-tank gunners fighting as infantry—overran the Italian positions taking around 130 prisoners.

Although the German and Italian commands in North Africa knew that a British offensive was imminent, Operation Brevity nevertheless caught them unprepared, and Rommel recorded in his diary that the initial attacks had caused him considerable losses. By midday on 15 May, Axis command was showing signs of confusion. It was erroneously believed that the offensive involved more than 100 tanks, and repeated requests were made to both the "Luftwaffe" and the "Regia Aeronautica" for a concerted effort to defeat it. Forces around Tobruk were redeployed east of the besieged city, to block any attempt at relief and to prevent the garrison from breaking out to meet the British advance. Lieutenant-Colonel Hans Cramer was sent to reinforce "Kampfgruppe" von Herff with a tank battalion from Panzer Regiment 8 and a battery of anti-aircraft guns, and additional reinforcements under General Hans-Karl Freiherr von Esebeck were despatched the following day.

The Germans concentrated their riposte against the central column. Herff—who had been prepared to fall back—instead launched a local counter-attack toward Fort Capuzzo during the afternoon of 15 May with the 2nd Battalion Panzer Regiment 5. At around 13:30, D Company 1DLI at the landing ground was overrun, and with no anti-tank support more capable than the Boys anti-tank rifle, the remaining troops of 1DLI were forced to fall back toward Musaid. A fortuitous dust cloud aided their withdrawal, but by 14:45 Panzer Regiment 5 was reporting that it had recaptured Capuzzo, inflicting heavy casualties on the British and taking 70 prisoners.

On the desert flank, A Squadron 2RTR's patrol toward Sidi Azeiz was being monitored by Panzer Regiment 5, but the Germans misidentified the light cruiser tanks as heavily armoured Matilda infantry tanks, and reported that an attack was not possible. Herff—believing the British had two divisions operating in the area—had grown uneasy. A Squadron's patrol was interpreted as an attempt to concentrate south of Sidi Azeiz, in preparation for a thrust north the next day; such a move threatened to sweep aside Herff's force and completely unhinge the German front in the Sollum–Bardia area. In response, Herff broke contact with the British; his plan was to join up with Cramer's Panzer Regiment 8 to mount a concentrated counter-attack the following morning.

Realising that the 22nd Guards Brigade group would be vulnerable to German armoured counterattacks in the open ground around Bir Wair and Mussaid, Brigadier Gott withdrew it during the early hours of the morning of 16 May. By 10:00, the infantry had taken up new positions back at Halfaya Pass, although the 7th Armoured Brigade group was ordered to remain west of Fort Capuzzo for the time being.

Cramer's reinforcements arrived in the Sidi Azeiz area at 03:00 and reached Fort Capuzzo at 06:30. At around 08:00, he made contact with "Kampfgruppe" von Herff, but by mid-morning both groups had run out of fuel. The German advance resumed at 16:00 before being stopped by around 17 tanks of 2RTR. The British reported one German tank set alight and another disabled and that an advance of up to fifty tanks had been halted, while the Germans believed that they had repulsed a strong British tank attack. As nightfall approached, Herff broke off the action and went on to the defensive. He intended to repair his damaged machines, reorganise, and resume offensive operations on 18 May. 2RTR pulled back to Bir el Khireigat, initially followed by two German tanks, one of which withdrew after the other was destroyed. The regiment arrived at Bir el Khireigat, from where it had set out two days previously, at around 02:30 on 17 May.

Operation Brevity failed to achieve most of its objectives, succeeding only in retaking the Halfaya Pass. The British lost five tanks destroyed and a further 13 were damaged but the tank regiments suffered no losses in personnel. Total casualties amounted to at least 206 men. The 1st Durham Light Infantry suffered the most during the operation losing 196 men killed, wounded or captured. The 2nd Scots Guards lost one man killed and four wounded, the 3rd Coldstream Guards lost one man killed and the 11th Hussars suffered four men wounded. Losses among the 2nd Rifle Brigade are unknown. German casualties numbered three tanks (a Panzer II and two Panzer IIIs, although several more suffered minor damage) and 258 men killed, wounded or captured. Jack Greene and Alessandro Massignani place total Italian losses at 395. Allied accounts record the capture of 347 of these men.

On 5 August, Herff praised the "Bersaglieri", who had defended Halfaya Pass "...with lionlike courage until the last man against stronger enemy forces. The greatest part of them died faithful to the flag." Lieutenant Giacinto Cova, a platoon commander in the 8th "Bersaglieri" Regiment, received a posthumous Gold Medal of Military Valour, Italy's highest award for bravery. The medal citation reported that Cova had organised a counter-attack and was killed attempting to throw a hand-held bomb at a British tank. The British received plaudits from Winston Churchill, who sent a telegram to Wavell betraying his ignorance of events by stating: "Without using the Tiger cubs you have taken the offensive, advanced , captured Halfaya and Sollum, taken 500 German prisoners and inflicted heavy losses in men and tanks. For this twenty I tanks and 1,000 or 1,500 casualties do not seem too heavy a cost." Churchill ended the message by asking Wavell "What are your dates for bringing Tiger cubs into action?", in reference to the reinforcements that had arrived at Alexandria on 12 May as part of a convoy code-named Operation Tiger. The 11th Hussar's regimental history notes that "it was clear that no further offensive action would be possible before 7[th] Arm[oured Division] was fully prepared". The Tiger convoy brought 238 tanks and made it possible to refit the 7th Armoured Division, which had been out of action since February as a result of the losses it sustained during Operation Compass. Preparations could now be made for Operation Battleaxe and the relief of Tobruk. In the system of British and Commonwealth battle honours, units that served in the Halfaya Pass area between 15 and 27 May were awarded the honour "Halfaya 1941" in 1957.

Historian Thomas Jentz suggests that Brevity could have ended in victory for the British. While their tank forces were fighting ineffectively, the "gutsy" actions by 2RTR and their patrol toward Sidi Azeiz had convinced the Germans that the battle was lost by the evening of 15 May. Because of their failure to engage 2RTR late that day, several German commanders from Panzer Regiment 5, including its commanding officer, were removed from their posts after the battle. Jentz notes that a feint by the 1st and 7th RTR out of Tobruk might have caused a realignment of the Axis forces, weakening their overall position and perhaps even forcing them to give up the Sollum area.

Operation Brevity highlighted to Rommel the importance of the Halfaya Pass; whichever side held it would have a "comparatively safe route for his supplies" during offensives in the area. On 27 May, he launched Operation Skorpion, during which Herff recaptured the pass and reversed the last British territorial gain from Brevity.




</doc>
<doc id="999875" url="https://en.wikipedia.org/wiki?curid=999875" title="Roy of the Rovers">
Roy of the Rovers

Roy of the Rovers is a British comic strip about the life and times of a fictional footballer named Roy Race, who played for Melchester Rovers. The strip first appeared in the "Tiger" in 1954, before giving its name to a weekly (and later monthly) comic magazine, published by IPC and Fleetway from 1976 until 1995, in which it was the main feature.

The weekly strip ran until 1993, following Roy's playing career until its conclusion after he lost his left foot in a helicopter crash. When the monthly comic was launched later that year the focus switched to Roy's son Rocky, who also played for Melchester. This publication was short-lived, and folded after only 19 issues. The adventures of the Race family were subsequently featured in the monthly "Match of the Day" football magazine, in which father and son were reunited as manager and player respectively. These strips began in 1997 and continued until the magazine's closure in May 2001.

Football-themed stories were a staple of British comics for boys from the 1950s onwards, and Roy of the Rovers was the most popular. To keep the strip exciting, Melchester was almost every year either competing for major honours or struggling against relegation to a lower division; a normal, uneventful season of mid-table mediocrity was unknown at Melchester Rovers. The strip followed the structure of the actual English football season, thus there were several months each year in summer when there was no league football. By far the most common summer storyline saw Melchester touring a fictional country in an exotic part of the world, often South America, where they would invariably be kidnapped and held to ransom. The average reader probably stayed with the comic regularly for only three or four years, therefore storylines were sometimes recycled; during the first ten years of his playing career, Roy was kidnapped at least four times. Roy also made numerous appearances for England, depicted playing alongside actual players such as Malcolm Macdonald and Trevor Francis.

The stock media phrase "real 'Roy of the Rovers' stuff" is often used by football writers, commentators and fans when describing displays of great skill, or surprising results that go against the odds, in reference to the dramatic storylines that were the strip's trademark.

Roy of the Rovers first appeared on 11 September 1954, as a weekly feature in the comic magazine "Tiger", debuting on the front page of the first issue. After 22 years of continued popularity, the strip was judged successful enough to sustain its own weekly comic, the eponymous "Roy of the Rovers", launched on 25 September 1976. The comic ran for 851 issues, until 20 March 1993, and included other football strips and features. At the peak of the comic's success about 450,000 copies were sold each week. There were also hardback annuals and holiday specials featuring a mix of reprinted and original content, and for a brief period, starting in 1986, Roy of the Rovers was serialised in the now defunct "Today" newspaper. These were all-new strips, focusing largely on the relationship between Roy and his wife Penny, rather than the action on the pitch. Between 1988 and 1993, a "Best of Roy of the Rovers" monthly comic was published, reprinting older stories.

Following the closure of the weekly title in 1993, the strip appeared in a relaunched monthly publication in September that year, with grittier storylines intended to attract teen and young adult fans who had read the weekly comic in their youth. Between January 1994 and January 1995, the monthly strips were mirrored by a weekly edition in "Shoot" magazine, which had in the late 1980s published a parody called Ray of the Rangers.

The comic strip was resurrected in July 1997, printed as short (usually two-page) features in the BBC's monthly "Match of the Day" magazine. These strips ran until the magazine's demise in May 2001. By then the strip's wholesome tone, often espousing the virtues of fair play and strong moral character, was beginning to seem old-fashioned. The editor of "Roy of the Rovers" comic, Barrie Tomlinson, has commented that "everyone seemed to be growing up a bit more quickly, and they wanted stories that were more realistic". This series ran until 2001.

Then-rights holder Egmont published a 64-page "collectors edition" of the comic strip in April 2009, gathering together a number of 1980's era Roy of the Rovers stories in addition to other backup strips from the comic. Two "Best of Roy of the Rovers" books, featuring successive runs of strips from the 1980s and 1970s, were published in June 2008 and 2009 respectively.

In 2016, the rights to Roy of the Rovers and the rest of the Fleetway comics library were acquired by Rebellion Developments, who subsequently relaunched the character in a series of graphic novels, depicting Roy as a teenager.

The story followed Roy Race, a striker for the fictional football team Melchester Rovers, based in a town of the same name in an unspecified part of England, where Roy lived with his family. In the first episode, a teenaged Roy and his best friend, Blackie Gray, signed for the Rovers after being spotted playing for a youth club team. Eight months later, Roy and Blackie made their first-team debuts against Elbury Wanderers in a game that ended in a 3–3 draw, with Roy scoring twice. He soon became a star, leading the team to either the Football League title or a cup almost every season. In January 1975 he was made player-manager, a position he retained for most of the next 20 years. Although the strip followed the Rovers through nearly 40 seasons, Roy did not age at the same rate and appeared to be at most in his late thirties by the time the weekly comic ended. This unrealistic longevity was never remarked upon by the weekly comic, although the monthly comic attempted to address the anomaly by explaining that more than one Roy Race had played for Melchester over the years.

Roy won a number of trophies during his career with Rovers, including nine league titles, eight FA Cups, three League Cups, three European Cups, one UEFA Cup, and four Cup Winners' Cups, and he also made several appearances for England. He married club secretary Penny Laine at the end of the 1975–76 season, with whom he had three children: Roy Jr. (later known as Rocky), Melinda, and Diana. Penny left Roy in the early 1980s, in a high-profile storyline that was covered on national television news. The following year Roy was shot in his office by a mystery gunman, in an incident clearly mirroring the shooting of J. R. Ewing in the hit television series "Dallas" the previous year. Roy lay in a coma for several weeks. The culprit was eventually revealed to be Elton Blake, an actor who had been cast as Roy in a television series about the Rovers, but who blamed him for his dismissal. In early 1983 Roy swapped Melchester Rovers for ambitious London side Walford Rovers after a fallout with the Melchester directors, but his stint away was short-lived and he was back at his spiritual home by the end of the year. In July 1986 eight members of the Rovers team were killed during a club tour of the fictional Middle Eastern country of Basran, when terrorists accidentally crashed a bomb-laden car into the team bus. Roy escaped with a dislocated shoulder. Author Mick Collins has commented that "Even as youngsters, we knew that this certainly bordered on bad taste, and probably overstepped the mark."
The final incident of Roy's playing career came in the closing pages of the last weekly issue, in March 1993, when he lost control of his helicopter and crashed into a field. Thus the weekly strip ended its 39-year unbroken run on a downbeat and unresolved cliffhanger, as Roy was taken into hospital while fans, the media and his family awaited news on his condition. The mystery of whether or not Roy had survived his crash was unresolved until the first issue of the new "Roy of the Rovers Monthly" in September 1993, in which readers discovered that the accident had resulted in the amputation of his famous left foot, ending his playing career and resulting in his move to Italy as the manager of Serie A side AC Monza (a fictional top-level Italian club, rather than the real club of the same name).

Reconciling the continuity of the monthly strip with the stories that preceded and followed it presented difficulties, forcing the story's writers to alter its history in a number of ways, a technique known as retroactive continuity. Significantly, the strip rewrote various parts of Melchester's history, and shortened Roy Sr.'s recorded playing career to a more realistic level.

By the time the strip ended in March 1995 Melchester were in dire straits, on the verge of bankruptcy, and their long-term future far from certain. When the strip returned in "Match of the Day" magazine in May 1997, much of the monthly comic's new continuity was ignored, although the basic thread of the club having struggled against relegation and being severely in debt was continued. It was revealed in the first strip that in the intervening years, while Rovers had managed to survive the threat of bankruptcy, a bribery scandal had caused a mass exodus of players and eventual relegation to Division One. Rocky, meanwhile, was playing for fierce local rivals Melborough, after a bitter falling-out with his father over a car accident in Italy in which his mother, Penny, had been killed. Roy, who had quit football as a result, was blamed by some (including his son) for the accident, even though he had no memory of it, and the precise circumstances surrounding the event were never resolved.

Roy was persuaded to rejoin Melchester as manager and part-owner, backed by the unscrupulous Vinter brothers, and he arrived just in time to save the club from relegation. The following season, Roy and Rocky resolved their differences. Rocky rejoined Melchester, and the club was promoted back into the Premier League at the end of the year. When the magazine closed in 2001, Rovers were attempting to achieve a league placing that would secure them UEFA Champions League football, giving them financial security. Although this storyline was never resolved, there was nevertheless a certain sense of closure as, shortly beforehand, Roy Sr. had wrested full control of the club from the Vinters, thus completing his 44-year progression from player to owner.

Over the years, the strip became famous for its employment of certain types of storyline and stylistic storytelling devices. For example, despite the fast-paced nature of a football match, exposition would be provided by members of the crowd apparently commenting to one another. Fans made lengthy comments in the short time it took the ball to travel through the air; as the ball was struck towards the goal a member of the crowd might be seen saying "Racey's had a shot!", followed by another responding "The 'keeper won't make it!". Nonetheless, loyal readers would usually suspend disbelief, a characteristic later parodied by "Viz" magazine's Billy the Fish, a fish with a human head who plays in goal for Fulchester United.

In the interests of keeping the strip exciting, it seemed that no season for Melchester Rovers could ever consist of mid-table obscurity. Almost every year, the club was either competing for the major honours at the top of the domestic and European game, or struggling against relegation to lower divisions. Often, such spells of good and bad fortune and form would directly succeed one another—a Rovers team that won the European Cup one year could find itself struggling to stay in Division One the next.

Storylines often centred on new signings who were unable to settle easily in the Melchester team, either because they refused to change their style of play and expected the Rovers to play around them, such as the uncomprisingly tough defender Duncan McKay, or had personal characteristics that made it difficult for the other players to accept them, such as ex-circus ball juggler Sammy Spangler. As the average reader probably stayed with the comic for only three or four years, many storylines were recycled. For instance, during the first ten years of his playing career Roy was kidnapped at least five times.

When playing foreign teams, particularly in the European club competitions, the opposition would often cynically employ overt gamesmanship or downright dirty tactics. Continental sides were considered to be "sneaky":

The strip followed the structure of the football season, thus there were several months each year when the Rovers were not playing football, but the strip needed to depict something more exciting than the players going on holiday and then reporting for pre-season training. As a result, the players tended to spend their summers involved in activities such as competing in charity cricket tournaments, but by far the most common summer storyline saw the Rovers go on tour to a fictional country in an exotic part of the world, normally South America, where they would invariably be kidnapped and held to ransom. "Melchester played more pre-season games at gunpoint deep in the jungle than they ever did in more mundane settings." The summer would often also see Roy fending off lucrative offers to leave Melchester, as in 1978, when the Sheik of Basran, an oil-rich Middle-Eastern state, offered him £1 million to coach the national team.

Especially during the 1980s, real-life personalities often made appearances. Former Division One stars Bob Wilson and Emlyn Hughes were brought out of retirement to play for Melchester in 1985, along with longtime fans of the strip Martin Kemp and Steve Norman, of the pop group Spandau Ballet. Geoff Boycott served for several years as Melchester's chairman, and Sir Alf Ramsey had briefly taken over as manager of Melchester in 1982, while Roy lay in his coma. Players such as Malcolm Macdonald and Trevor Francis would sometimes line up alongside Roy in England matches, despite the fact that the clubs they played for in real life were never featured in the strip.

The concept of TV pundits and anchormen making appearances was a later development. When Roy announced his resignation as Rovers manager in 1992, he did so live on Sky Sports in front of shocked presenters Richard Keys and Andy Gray.

Roy was created by the author Frank S. Pepper, who had created the similar strip, Danny of the Dazzlers, but he only wrote four instalments of Roy of the Rovers, because of his commitments to another of his characters, Captain Condor. His role was taken by the strip's first artist Joe Colquhoun, who used the pen-name "Stewart Colwyn". He was replaced after four-and-a-half years by Derek Birnage, the editor of "Tiger", who had commissioned the strip. In 1960, in an attempt to whip up publicity, it was announced that the footballer Bobby Charlton had taken over as writer, although in reality it was still written by Birnage (who claimed that he did consult with Charlton occasionally for story ideas). The longest-serving writer of the strip was Tom Tully, who began in 1969 on an intermittent basis and then continuously from 1974 until the end of the weekly comic in 1993. Ian Rimmer became the main writer for the strip during the "Match of the Day" years, until the magazine's closure in May 2001.

After Joe Colquhoun departed, he was succeeded first by Paul Trevillion, then by Yvonne Hutton, who illustrated from 1967 to 1974, before David Sque took over in 1975. Despite reportedly not being a football fan, he was responsible for one of the strip's more definitive looks in its early '80s period. He was replaced in 1986 by former "2000 AD" artist Mike White, who gave Roy a more muscular look and the strip a more modern feel. Barrie Mitchell took over in 1992, with a style quite similar to White's. A number of artists worked on the monthly comic, such as David Jukes, Sean Longcroft and Garry Marshall, in contrast to the lengthy tenures of the weekly strip's creative team. Tony Harding often illustrated Roy for the Roy of the Rovers annuals and also drew the Roy's Action Replay strip that appeared in All Action Monthly in the late eighties (Fleetway). Mitchell returned in 1997 as the sole artist of the "Match of the Day" strips for all four years.

Filmmakers Luke Dormehl and Tom Atkinson, released a documentary called "Roy" in 2008, featuring interviews with some of the key members of the Roy of the Rovers creative team. The film was shown at The End of the Pier International Film Festival in 2009, where it won the prize for Best Documentary Short.

The phrase "Roy of the Rovers" has become a trope familiar to generations of British football fans and sports commentators, used to describe a memorable sporting achievement such as winning against the odds, or an unexpected comeback. "The Guardian" newspaper of 10 April 1995, for instance, described future England captain Alan Shearer as "the classic working class sporting hero ... everything legend demands an English centre-forward should be ... As a striker he comes closer to fitting the "Roy of the Rovers" fantasy than anyone else lately admired by English crowds". Shearer was at that time the leading goal-scorer for "unfashionable" Blackburn Rovers F.C., who were on the verge of winning the Premiership title.

Comparisons have been drawn between the fictional Roy Race and the captain of England's 1966 World Cup winning team, Bobby Moore, whose playing career spanned a similar time-scale to that of Roy's. Moore's death in 1993, just days after the last edition of the "Roy of the Rovers" comic was published, produced a "literature of tribute", framed around themes "remarkably similar to those at the center of the Roy Race fiction and ideology ... there was a clear sense of mourning for the loss of an age".
"Roy of the Rovers Annual"s were produced every year from 1958 until 1994, and again in 2000. A number of tie-in books were also published, including a handful of paperback prose storybooks in 1977 and 1993, and two football quiz books in 1978 and 1979. Roy of the Rovers never made the leap from page to screen, although he did make an appearance on the BBC comedy sports quiz "They Think It's All Over" in 1999, in the form of a cardboard cut-out.

A "Roy of the Rovers" computer game was released, on the Commodore 64, Amstrad CPC and ZX Spectrum in 1988. It was split into two parts: the first an adventure game, in which – taking the role of Roy Race – the player had to find and rescue the kidnapped Melchester team, before then playing the second part, which consisted of a charity match to raise funds for the club. The fewer players recovered before the match began, then the smaller the team who could take part. In the extreme, Roy would be the only player for Melchester. The game received mixed reactions; the Spectrum version received 7/10 from "Your Sinclair", but only 3/10 from "Sinclair User".

A number of official Melchester Rovers Subbuteo teams were produced in the 1980s and 1990s. There was also an officially licensed board game in the 1980s, which saw players take on the role of Roy Race and manage the club. The Old Fashioned Football Shirt Company now makes officially licensed replica shirts.

In 1990, "Roy Race" and footballer Gary Lineker released a single, "Europe United", described in the comic as "a hot rocking heavy metal rap", which failed to chart in the UK Top 40. The confectionery company McCowans produced a pineapple-flavoured "Roy of the Rovers" chew bar in the 1990s.

On 29 February 2008 it was announced that Titan Books had acquired worldwide book publishing rights to a range of Egmont's comic strips, including Roy of the Rovers. The first of their compilations of Roy's playing days, "The Best of Roy of the Rovers: The 1980s" was released in May 2008 and included the "Relegation" and "Who Shot Roy" story arcs. "The Bumper Book of Roy of the Rovers" was published in October 2008, and reprinted strips, articles, short stories and features taken from Roy annuals dated from 1957 to 1971. Two further titles were released in 2009, "The Best of the 1970s and The Second Bumper Book", and a third "Best of", focusing on the World Cup, was released in 2010. All five of the titles were edited and compiled by David Leach.

The trade paperbacks:
The hardcovers:




</doc>
