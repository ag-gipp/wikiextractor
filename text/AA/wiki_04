<doc id="16095" url="https://en.wikipedia.org/wiki?curid=16095" title="Jimi Hendrix">
Jimi Hendrix

James Marshall "Jimi" Hendrix (born Johnny Allen Hendrix; November 27, 1942 – September 18, 1970) was an American rock guitarist, singer, and songwriter. Although his mainstream career spanned only four years, he is widely regarded as one of the most influential electric guitarists in the history of popular music, and one of the most celebrated musicians of the 20th century. The Rock and Roll Hall of Fame describes him as "arguably the greatest instrumentalist in the history of rock music".

Born in Seattle, Washington, Hendrix began playing guitar at the age of 15. In 1961, he enlisted in the U.S. Army and trained as a paratrooper in the 101st Airborne Division; he was granted an honorable discharge the following year. Soon afterward, he moved to Clarksville, Tennessee, and began playing gigs on the Chitlin' Circuit, earning a place in the Isley Brothers' backing band and later with Little Richard, with whom he continued to work through mid-1965. He then played with Curtis Knight and the Squires before moving to England in late 1966 after being discovered by Linda Keith, who in turn interested bassist Chas Chandler of the Animals in becoming his first manager. Within months, Hendrix had earned three UK top ten hits with the Jimi Hendrix Experience: "Hey Joe", "Purple Haze", and "The Wind Cries Mary". He achieved fame in the U.S. after his performance at the Monterey Pop Festival in 1967, and in 1968 his third and final studio album, "Electric Ladyland", reached number one in the U.S.; it was Hendrix's most commercially successful release and his first and only number one album. The world's highest-paid performer, he headlined the Woodstock Festival in 1969 and the Isle of Wight Festival in 1970, before his accidental death from barbiturate-related asphyxia on September 18, 1970, at the age of 27.

Hendrix was inspired musically by American rock and roll and electric blues. He favored overdriven amplifiers with high volume and gain, and was instrumental in popularizing the previously undesirable sounds caused by guitar amplifier feedback. He was also one of the first guitarists to make extensive use of tone-altering effects units, such as fuzz tone, Octavia, wah-wah, and Uni-Vibe in mainstream rock. He was the first artist to use stereophonic phasing effects in music recordings. Holly George-Warren of "Rolling Stone" commented: "Hendrix pioneered the use of the instrument as an electronic sound source. Players before him had experimented with feedback and distortion, but Hendrix turned those effects and others into a controlled, fluid vocabulary every bit as personal as the blues with which he began."

Hendrix was the recipient of several music awards during his lifetime and posthumously. In 1967, readers of "Melody Maker" voted him the Pop Musician of the Year, and in 1968, "Rolling Stone" declared him the Performer of the Year. "Disc and Music Echo" honored him with the World Top Musician of 1969 and in 1970, "Guitar Player" named him the Rock Guitarist of the Year. The Jimi Hendrix Experience was inducted into the Rock and Roll Hall of Fame in 1992 and the UK Music Hall of Fame in 2005. "Rolling Stone" ranked the band's three studio albums, "Are You Experienced", "", and "Electric Ladyland", among the 100 greatest albums of all time, and they ranked Hendrix as the greatest guitarist and the sixth greatest artist of all time.

Jimi Hendrix had a diverse heritage. His paternal grandmother, Zenora "Nora" Rose Moore, was African American and one-quarter Cherokee. Hendrix's paternal grandfather, Bertran Philander Ross Hendrix (born 1866), was born out of an extramarital affair between a woman named Fanny, and a grain merchant from Urbana, Ohio, or Illinois, one of the wealthiest men in the area at that time. After Hendrix and Moore relocated to Vancouver, British Columbia, Canada, had a son they named James Allen Hendrix on June 10, 1919; the family called him "Al".

In 1941 after moving to Seattle, Al met Lucille Jeter (1925–1958) at a dance; they married on March 31, 1942. Lucille's father (Jimi's maternal grandfather) was Preston Jeter (born 1875), whose mother was born in similar circumstances as Bertran Philander Ross Hendrix. Lucille's mother, née Clarice Lawson, had African American and Cherokee ancestors. Al, who had been drafted by the U.S. Army to serve in World War II, left to begin his basic training three days after the wedding. Johnny Allen Hendrix was born on November 27, 1942, in Seattle; he was the first of Lucille's five children. In 1946, Johnny's parents changed his name to James Marshall Hendrix, in honor of Al and his late brother Leon Marshall.

Stationed in Alabama at the time of Hendrix's birth, Al was denied the standard military furlough afforded servicemen for childbirth; his commanding officer placed him in the stockade to prevent him from going AWOL to see his infant son in Seattle. He spent two months locked up without trial, and while in the stockade received a telegram announcing his son's birth. During Al's three-year absence, Lucille struggled to raise their son. When Al was away, Hendrix was mostly cared for by family members and friends, especially Lucille's sister Delores Hall and her friend Dorothy Harding. Al received an honorable discharge from the U.S. Army on September 1, 1945. Two months later, unable to find Lucille, Al went to the Berkeley, California, home of a family friend named Mrs. Champ, who had taken care of and had attempted to adopt Hendrix; this is where Al saw his son for the first time.

After returning from service, Al reunited with Lucille, but his inability to find steady work left the family impoverished. They both struggled with alcohol, and often fought when intoxicated. The violence sometimes drove Hendrix to withdraw and hide in a closet in their home. His relationship with his brother Leon (born 1948) was close but precarious; with Leon in and out of foster care, they lived with an almost constant threat of fraternal separation. In addition to Leon, Hendrix had three younger siblings: Joseph, born in 1949, Kathy in 1950, and Pamela, 1951, all of whom Al and Lucille gave up to foster care and adoption. The family frequently moved, staying in cheap hotels and apartments around Seattle. On occasion, family members would take Hendrix to Vancouver to stay at his grandmother's. A shy and sensitive boy, he was deeply affected by his life experiences. In later years, he confided to a girlfriend that he had been the victim of sexual abuse by a man in uniform. On December 17, 1951, when Hendrix was nine years old, his parents divorced; the court granted Al custody of him and Leon.

At Horace Mann Elementary School in Seattle during the mid-1950s, Hendrix's habit of carrying a broom with him to emulate a guitar gained the attention of the school's social worker. After more than a year of his clinging to a broom like a security blanket, she wrote a letter requesting school funding intended for underprivileged children, insisting that leaving him without a guitar might result in psychological damage. Her efforts failed, and Al refused to buy him a guitar.

In 1957, while helping his father with a side-job, Hendrix found a ukulele amongst the garbage they were removing from an older woman's home. She told him that he could keep the instrument, which had only one string. Learning by ear, he played single notes, following along to Elvis Presley songs, particularly "Hound Dog". By the age of 33, Hendrix's mother Lucille had developed cirrhosis of the liver, and on February 2, 1958, she died when her spleen ruptured. Al refused to take James and Leon to attend their mother's funeral; he instead gave them shots of whiskey and instructed them that was how men should deal with loss. In 1958, Hendrix completed his studies at Washington Junior High School and began attending, but did not graduate from, Garfield High School.

In mid-1958, at age 15, Hendrix acquired his first acoustic guitar, for $5 (equivalent to $43.40 in 2018). He played for hours daily, watching others and learning from more experienced guitarists, and listening to blues artists such as Muddy Waters, B.B. King, Howlin' Wolf, and Robert Johnson. The first tune Hendrix learned to play was the television theme "Peter Gunn". Around that time, Hendrix jammed with boyhood friend Sammy Drain and his keyboard-playing brother. In 1959, attending a concert by Hank Ballard & the Midnighters in Seattle, Hendrix met the group's guitarist Billy Davis. Davis showed him some guitar licks and later got him a short gig with the Midnighters. The two remained friends until Hendrix's death in 1970.

Soon after he acquired the acoustic guitar, Hendrix formed his first band, the Velvetones. Without an electric guitar, he could barely be heard over the sound of the group. After about three months, he realized that he needed an electric guitar. In mid-1959, his father relented and bought him a white Supro Ozark. Hendrix's first gig was with an unnamed band in the Jaffe Room of Seattle's Temple De Hirsch Sinai, but they fired him between sets for showing off. He joined the Rocking Kings, which played professionally at venues such as the Birdland club. When his guitar was stolen after he left it backstage overnight, Al bought him a red Silvertone Danelectro.

Before Hendrix was 19 years old, law authorities had twice caught him riding in stolen cars. Given a choice between prison or joining the Army, he chose the latter and enlisted on May 31, 1961. After completing eight weeks of basic training at Fort Ord, California, he was assigned to the 101st Airborne Division and stationed at Fort Campbell, Kentucky. He arrived on November 8, and soon afterward he wrote to his father: "There's nothing but physical training and harassment here for two weeks, then when you go to jump school ... you get hell. They work you to death, fussing and fighting." In his next letter home, Hendrix, who had left his guitar at his girlfriend Betty Jean Morgan's house in Seattle, asked his father to send it to him as soon as possible, stating: "I really need it now." His father obliged and sent the red Silvertone Danelectro on which Hendrix had hand-painted the words "Betty Jean" to Fort Campbell. His apparent obsession with the instrument contributed to his neglect of his duties, which led to taunting and physical abuse from his peers, who at least once hid the guitar from him until he had begged for its return.

In November 1961, fellow serviceman Billy Cox walked past an army club and heard Hendrix playing. Impressed by Hendrix's technique, which Cox described as a combination of "John Lee Hooker and Beethoven", Cox borrowed a bass guitar and the two jammed. Within weeks, they began performing at base clubs on the weekends with other musicians in a loosely organized band, the Casuals.

Hendrix completed his paratrooper training in just over eight months, and Major General C. W. G. Rich awarded him the prestigious Screaming Eagles patch on January 11, 1962. By February, his personal conduct had begun to draw criticism from his superiors. They labeled him an unqualified marksman and often caught him napping while on duty and failing to report for bed checks. On May 24, Hendrix's platoon sergeant, James C. Spears, filed a report in which he stated: "He has no interest whatsoever in the Army ... It is my opinion that Private Hendrix will never come up to the standards required of a soldier. I feel that the military service will benefit if he is discharged as soon as possible." On June 29, 1962, Captain Gilbert Batchman granted Hendrix an honorable discharge on the basis of unsuitability. Hendrix later spoke of his dislike of the army and lied that he had received a medical discharge after breaking his ankle during his 26th parachute jump.

In September 1963, after Cox was discharged from the Army, he and Hendrix moved to Clarksville, Tennessee, and formed a band called the King Kasuals. Hendrix had watched Butch Snipes play with his teeth in Seattle and by now Alphonso 'Baby Boo' Young, the other guitarist in the band, was performing this guitar gimmick. Not to be upstaged, Hendrix learned to play with his teeth. He later commented: "The idea of doing that came to me...in Tennessee. Down there you have to play with your teeth or else you get shot. There's a trail of broken teeth all over the stage." Although they began playing low-paying gigs at obscure venues, the band eventually moved to Nashville's Jefferson Street, which was the traditional heart of the city's black community and home to a thriving rhythm and blues music scene. They earned a brief residency playing at a popular venue in town, the Club del Morocco, and for the next two years Hendrix made a living performing at a circuit of venues throughout the South that were affiliated with the Theater Owners' Booking Association (TOBA), widely known as the Chitlin' Circuit. In addition to playing in his own band, Hendrix performed as a backing musician for various soul, R&B, and blues musicians, including Wilson Pickett, Slim Harpo, Sam Cooke, Ike & Tina Turner and Jackie Wilson.

In January 1964, feeling he had outgrown the circuit artistically, and frustrated by having to follow the rules of bandleaders, Hendrix decided to venture out on his own. He moved into the Hotel Theresa in Harlem, where he befriended Lithofayne Pridgon, known as "Faye", who became his girlfriend. A Harlem native with connections throughout the area's music scene, Pridgon provided him with shelter, support, and encouragement. Hendrix also met the Allen twins, Arthur and Albert. In February 1964, Hendrix won first prize in the Apollo Theater amateur contest. Hoping to secure a career opportunity, he played the Harlem club circuit and sat in with various bands. At the recommendation of a former associate of Joe Tex, Ronnie Isley granted Hendrix an audition that led to an offer to become the guitarist with the Isley Brothers' back-up band, the I.B. Specials, which he readily accepted.

In March 1964, Hendrix recorded the two-part single "Testify" with the Isley Brothers. Released in June, it failed to chart. In May, he provided guitar instrumentation for the Don Covay song, "Mercy Mercy". Issued in August by Rosemart Records and distributed by Atlantic, the track reached number 35 on the "Billboard" chart.

Hendrix toured with the Isleys during much of 1964, but near the end of October, after growing tired of playing the same set every night, he left the band. Soon afterward, Hendrix joined Little Richard's touring band, the Upsetters. During a stop in Los Angeles in February 1965, he recorded his first and only single with Richard, "I Don't Know What You Got (But It's Got Me)", written by Don Covay and released by Vee-Jay Records. Richard's popularity was waning at the time, and the single peaked at number 92, where it remained for one week before dropping off the chart. Hendrix met singer Rosa Lee Brooks while staying at the Wilcox Hotel in Hollywood, and she invited him to participate in a recording session for her single, which included the Arthur Lee penned "My Diary" as the A-side, and "Utee" as the B-side. Hendrix played guitar on both tracks, which also included background vocals by Lee. The single failed to chart, but Hendrix and Lee began a friendship that lasted several years; Hendrix later became an ardent supporter of Lee's band, Love.

In July 1965, on Nashville's Channel 5 "Night Train", Hendrix made his first television appearance. Performing in Little Richard's ensemble band, he backed up vocalists Buddy and Stacy on "Shotgun". The video recording of the show marks the earliest known footage of Hendrix performing. Richard and Hendrix often clashed over tardiness, wardrobe, and Hendrix's stage antics, and in late July, Richard's brother Robert fired him. He then briefly rejoined the Isley Brothers, and recorded a second single with them, "Move Over and Let Me Dance" backed with "Have You Ever Been Disappointed". Later that year, he joined a New York-based R&B band, Curtis Knight and the Squires, after meeting Knight in the lobby of a hotel where both men were staying. Hendrix performed with them for eight months. In October 1965, he and Knight recorded the single, "How Would You Feel" backed with "Welcome Home" and on October 15, Hendrix signed a three-year recording contract with entrepreneur Ed Chalpin. While the relationship with Chalpin was short-lived, his contract remained in force, which later caused legal and career problems for Hendrix. During his time with Knight, Hendrix briefly toured with Joey Dee and the Starliters, and worked with King Curtis on several recordings including Ray Sharpe's two-part single, "Help Me". Hendrix earned his first composer credits for two instrumentals, "Hornets Nest" and "Knock Yourself Out", released as a Curtis Knight and the Squires single in 1966.

Feeling restricted by his experiences as an R&B sideman, Hendrix moved in 1966 to New York City's Greenwich Village, which had a vibrant and diverse music scene. There, he was offered a residency at the Cafe Wha? on MacDougal Street and formed his own band that June, Jimmy James and the Blue Flames, which included future Spirit guitarist Randy California. The Blue Flames played at several clubs in New York and Hendrix began developing his guitar style and material that he would soon use with the Experience. In September, they gave some of their last concerts at the Cafe au Go Go, as John Hammond Jr.'s backing group.

By May 1966, Hendrix was struggling to earn a living wage playing the R&B circuit, so he briefly rejoined Curtis Knight and the Squires for an engagement at one of New York City's most popular nightspots, the Cheetah Club. During a performance, Linda Keith, the girlfriend of Rolling Stones guitarist Keith Richards, noticed Hendrix. She remembered: "[His] playing mesmerised me". She invited him to join her for a drink; he accepted and the two became friends.

While Hendrix was playing with Jimmy James and the Blue Flames, Keith recommended him to Stones manager Andrew Loog Oldham and producer Seymour Stein. They failed to see Hendrix's musical potential, and rejected him. She then referred him to Chas Chandler, who was leaving the Animals and interested in managing and producing artists. Chandler saw the then-unknown Jimi Hendrix play in Cafe Wha?, a Greenwich Village, New York City nightclub. Chandler liked the Billy Roberts song "Hey Joe", and was convinced he could create a hit single with the right artist. Impressed with Hendrix's version of the song, he brought him to London on September 24, 1966, and signed him to a management and production contract with himself and ex-Animals manager Michael Jeffery. On September 24, Hendrix gave an impromptu solo performance at The Scotch of St James, and later that night he began a relationship with Kathy Etchingham that lasted for two and a half years.
Following Hendrix's arrival in London, Chandler began recruiting members for a band designed to highlight the guitarist's talents, the Jimi Hendrix Experience. Hendrix met guitarist Noel Redding at an audition for the New Animals, where Redding's knowledge of blues progressions impressed Hendrix, who stated that he also liked Redding's hairstyle. Chandler asked Redding if he wanted to play bass guitar in Hendrix's band; Redding agreed. Chandler then began looking for a drummer and soon after, he contacted Mitch Mitchell through a mutual friend. Mitchell, who had recently been fired from Georgie Fame and the Blue Flames, participated in a rehearsal with Redding and Hendrix where they found common ground in their shared interest in rhythm and blues. When Chandler phoned Mitchell later that day to offer him the position, he readily accepted. Chandler also convinced Hendrix to change the spelling of his first name from "Jimmy" to the exotic looking "Jimi".

On October 1, 1966, Chandler brought Hendrix to the London Polytechnic at Regent Street, where Cream was scheduled to perform, and where Hendrix and Eric Clapton met. Clapton later commented: "He asked if he could play a couple of numbers. I said, 'Of course', but I had a funny feeling about him." Halfway through Cream's set, Hendrix took the stage and performed a frantic version of the Howlin' Wolf song "Killing Floor". In 1989, Clapton described the performance: "He played just about every style you could think of, and not in a flashy way. I mean he did a few of his tricks, like playing with his teeth and behind his back, but it wasn't in an upstaging sense at all, and that was it ... He walked off, and my life was never the same again".

In mid-October 1966, Chandler arranged an engagement for the Experience as Johnny Hallyday's supporting act during a brief tour of France. Thus, the Jimi Hendrix Experience performed their very first show on October 13, 1966, at the Novelty in Evreux. Their enthusiastically received 15-minute performance at the Olympia theatre in Paris on October 18 marks the earliest known recording of the band. In late October, Kit Lambert and Chris Stamp, managers of the Who, signed the Experience to their newly formed label, Track Records, and the group recorded their first song, "Hey Joe", on October 23. "Stone Free", which was Hendrix's first songwriting effort after arriving in England, was recorded on November 2.

In mid-November, they performed at the Bag O'Nails nightclub in London, with Clapton, John Lennon, Paul McCartney, Jeff Beck, Pete Townshend, Brian Jones, Mick Jagger, and Kevin Ayers in attendance. Ayers described the crowd's reaction as stunned disbelief: "All the stars were there, and I heard serious comments, you know 'shit', 'Jesus', 'damn' and other words worse than that." The successful performance earned Hendrix his first interview, published in "Record Mirror" with the headline: "Mr. Phenomenon". "Now hear this ... we predict that [Hendrix] is going to whirl around the business like a tornado", wrote Bill Harry, who asked the rhetorical question: "Is that full, big, swinging sound really being created by only three people?" Hendrix commented: "We don't want to be classed in any category ... If it must have a tag, I'd like it to be called, 'Free Feeling'. It's a mixture of rock, freak-out, rave and blues". Through a distribution deal with Polydor Records, the Experience's first single, "Hey Joe", backed with "Stone Free", was released on December 16, 1966. After appearances on the UK television shows "Ready Steady Go!" and the "Top of the Pops", "Hey Joe" entered the UK charts on December 29 and peaked at number six. Further success came in March 1967 with the UK number three hit "Purple Haze", and in May with "The Wind Cries Mary", which remained on the UK charts for eleven weeks, peaking at number six. On March 12, 1967, he performed at the Troutbeck Hotel, Ilkley, West Yorkshire, where, after about 900 people turned up (the hotel was licensed for 250) the local police stopped the gig due to safety concerns.

On March 31, 1967, while the Experience waited to perform at the London Astoria, Hendrix and Chandler discussed ways in which they could increase the band's media exposure. When Chandler asked journalist Keith Altham for advice, Altham suggested that they needed to do something more dramatic than the stage show of the Who, which involved the smashing of instruments. Hendrix joked: "Maybe I can smash up an elephant", to which Altham replied: "Well, it's a pity you can't set fire to your guitar". Chandler then asked road manager Gerry Stickells to procure some lighter fluid. During the show, Hendrix gave an especially dynamic performance before setting his guitar on fire at the end of a 45-minute set. In the wake of the stunt, members of London's press labeled Hendrix the "Black Elvis" and the "Wild Man of Borneo".

After the UK chart success of their first two singles, "Hey Joe" and "Purple Haze", the Experience began assembling material for a full-length LP. Recording began at De Lane Lea Studios and later moved to the prestigious Olympic Studios. The album, "Are You Experienced", features a diversity of musical styles, including blues tracks such as "Red House" and "Highway Chile", and the R&B song "Remember". It also included the experimental science fiction piece, "Third Stone from the Sun" and the post-modern soundscapes of the title track, with prominent backwards guitar and drums. "I Don't Live Today" served as a medium for Hendrix's guitar feedback improvisation and "Fire" was driven by Mitchell's drumming.

Released in the UK on May 12, 1967, "Are You Experienced" spent 33 weeks on the charts, peaking at number two. It was prevented from reaching the top spot by the Beatles' "Sgt. Pepper's Lonely Hearts Club Band". On June 4, 1967, Hendrix opened a show at the Saville Theatre in London with his rendition of "Sgt. Pepper" title track, which was released just three days previous. Beatles manager Brian Epstein owned the Saville at the time, and both George Harrison and Paul McCartney attended the performance. McCartney described the moment: "The curtains flew back and he came walking forward playing 'Sgt. Pepper'. It's a pretty major compliment in anyone's book. I put that down as one of the great honors of my career." Released in the U.S. on August 23 by Reprise Records, "Are You Experienced" reached number five on the "Billboard" 200.

In 1989, Noe Goldwasser, the founding editor of "Guitar World" magazine, described "Are You Experienced" as "the album that shook the world ... leaving it forever changed". In 2005, "Rolling Stone" called the double-platinum LP Hendrix's "epochal debut", and they ranked it the 15th greatest album of all time, noting his "exploitation of amp howl", and characterizing his guitar playing as "incendiary ... historic in itself".

Although popular in Europe at the time, the Experience's first U.S. single, "Hey Joe", failed to reach the "Billboard" Hot 100 chart upon its release on May 1, 1967. The group's fortunes improved when McCartney recommended them to the organizers of the Monterey Pop Festival. He insisted that the event would be incomplete without Hendrix, whom he called "an absolute ace on the guitar", and he agreed to join the board of organizers on the condition that the Experience perform at the festival in mid-June.

Introduced by Brian Jones as "the most exciting performer [he had] ever heard", Hendrix opened with a fast arrangement of Howlin' Wolf's song "Killing Floor", wearing what author Keith Shadwick described as "clothes as exotic as any on display elsewhere." Shadwick wrote: "[Hendrix] was not only something utterly new musically, but an entirely original vision of what a black American entertainer should and could look like." The Experience went on to perform renditions of "Hey Joe", B.B. King's "Rock Me Baby", Chip Taylor's "Wild Thing", and Bob Dylan's "Like a Rolling Stone", as well as four original compositions: "Foxy Lady", "Can You See Me", "The Wind Cries Mary", and "Purple Haze". The set ended with Hendrix destroying his guitar and tossing pieces of it out to the audience. "Rolling Stone" Alex Vadukul wrote:

Caraeff stood on a chair next to the edge of the stage while taking a series of four monochrome pictures of Hendrix burning his guitar. Caraeff was close enough to the fire that he had to use his camera as a shield to protect his face from the heat. "Rolling Stone" later colorized the image, matching it with other pictures taken at the festival before using the shot for a 1987 magazine cover. According to author Gail Buckland, the fourth and final frame of "Hendrix kneeling in front of his burning guitar, hands raised, is one of the most famous images in rock." Author and historian Matthew C. Whitaker wrote: "Hendrix's burning of his guitar became an iconic image in rock history and brought him national attention." The "Los Angeles Times" asserted that, upon leaving the stage, Hendrix "graduated from rumor to legend". Author John McDermott commented: "Hendrix left the Monterey audience stunned and in disbelief at what they'd just heard and seen." According to Hendrix: "I decided to destroy my guitar at the end of a song as a sacrifice. You sacrifice things you love. I love my guitar." The performance was filmed by D. A. Pennebaker, and later included in the concert documentary "Monterey Pop", which helped Hendrix gain popularity with the U.S. public.

Immediately after the festival, the Experience were booked for a series of five concerts at Bill Graham's Fillmore, with Big Brother and the Holding Company and Jefferson Airplane. The Experience outperformed Jefferson Airplane during the first two nights, and replaced them at the top of the bill on the fifth. Following their successful West Coast introduction, which included a free open-air concert at Golden Gate Park and a concert at the Whisky a Go Go, the Experience were booked as the opening act for the first American tour of the Monkees. They requested Hendrix as a supporting act because they were fans, but their young audience disliked the Experience, who left the tour after six shows. Chandler later admitted that he engineered the tour in an effort to gain publicity for Hendrix.

The second Experience album, "", opens with the track "EXP", which utilized microphonic and harmonic feedback in a new, creative fashion. It also showcased an experimental stereo panning effect in which sounds emanating from Hendrix's guitar move through the stereo image, revolving around the listener. The piece reflected his growing interest in science fiction and outer space. He composed the album's title track and finale around two verses and two choruses, during which he pairs emotions with personas, comparing them to colors. The song's coda features the first recording of stereo phasing. Shadwick described the composition as "possibly the most ambitious piece on "Axis", the extravagant metaphors of the lyrics suggesting a growing confidence" in Hendrix's songwriting. His guitar playing throughout the song is marked by chordal arpeggios and contrapuntal motion, with tremolo-picked partial chords providing the musical foundation for the chorus, which culminates in what musicologist Andy Aledort described as "simply one of the greatest electric guitar solos ever played". The track fades out on tremolo-picked 32nd note double stops.

The scheduled release date for "Axis" was almost delayed when Hendrix lost the master tape of side one of the LP, leaving it in the back seat of a London taxi. With the deadline looming, Hendrix, Chandler, and engineer Eddie Kramer remixed most of side one in a single overnight session, but they could not match the quality of the lost mix of "If 6 Was 9". Bassist Noel Redding had a tape recording of this mix, which had to be smoothed out with an iron as it had gotten wrinkled. During the verses, Hendrix doubled his singing with a guitar line which he played one octave lower than his vocals. Hendrix voiced his disappointment about having re-mixed the album so quickly, and he felt that it could have been better had they been given more time.

"Axis" featured psychedelic cover art that depicts Hendrix and the Experience as various avatars of Vishnu, incorporating a painting of them by Roger Law, from a photo-portrait by Karl Ferris. The painting was then superimposed on a copy of a mass-produced religious poster. Hendrix stated that the cover, which Track spent $5,000 producing, would have been more appropriate had it highlighted his American Indian heritage. He commented: "You got it wrong ... I'm not that kind of Indian." Track released the album in the UK on December 1, 1967, where it peaked at number five, spending 16 weeks on the charts. In February 1968, "Axis: Bold as Love" reached number three in the U.S.

While author and journalist Richie Unterberger described "Axis" as the least impressive Experience album, according to author Peter Doggett, the release "heralded a new subtlety in Hendrix's work". Mitchell commented: ""Axis" was the first time that it became apparent that Jimi was pretty good working behind the mixing board, as well as playing, and had some positive ideas of how he wanted things recorded. It could have been the start of any potential conflict between him and Chas in the studio."

Recording for the Experience's third and final studio album, "Electric Ladyland", began at the newly opened Record Plant Studios, with Chandler as producer and engineers Eddie Kramer and Gary Kellgren. As the sessions progressed, Chandler became increasingly frustrated with Hendrix's perfectionism and his demands for repeated takes. Hendrix also allowed numerous friends and guests to join them in the studio, which contributed to a chaotic and crowded environment in the control room and led Chandler to sever his professional relationship with Hendrix. Redding later recalled: "There were tons of people in the studio; you couldn't move. It was a party, not a session." Redding, who had formed his own band in mid-1968, Fat Mattress, found it increasingly difficult to fulfill his commitments with the Experience, so Hendrix played many of the bass parts on "Electric Ladyland". The album's cover stated that it was "produced and directed by Jimi Hendrix".

During the "Electric Ladyland" recording sessions, Hendrix began experimenting with other combinations of musicians, including Jefferson Airplane's Jack Casady and Traffic's Steve Winwood, who played bass and organ, respectively, on the 15-minute slow-blues jam, "Voodoo Chile". During the album's production, Hendrix appeared at an impromptu jam with B.B. King, Al Kooper, and Elvin Bishop. "Electric Ladyland" was released on October 25, and by mid-November it had reached number one in the U.S., spending two weeks at the top spot. The double LP was Hendrix's most commercially successful release and his only number one album. It peaked at number six in the UK, spending 12 weeks on the chart. "Electric Ladyland" included Hendrix's cover of Bob Dylan's song, "All Along the Watchtower", which became Hendrix's highest-selling single and his only U.S. top 40 hit, peaking at number 20; the single reached number five in the UK. "Burning of the Midnight Lamp", which was his first recorded song to feature the use of a wah-wah pedal, was added to the album. It was originally released as his fourth single in the UK in August 1967 and reached number 18 in the charts.

In 1989, Noe Goldwasser, the founding editor of "Guitar World" magazine, described "Electric Ladyland" as "Hendrix's masterpiece". According to author Michael Heatley, "most critics agree" that the album is "the fullest realization of Jimi's far-reaching ambitions." In 2004, author Peter Doggett commented: "For pure experimental genius, melodic flair, conceptual vision and instrumental brilliance, "Electric Ladyland" remains a prime contender for the status of rock's greatest album." Doggett described the LP as "a display of musical virtuosity never surpassed by any rock musician."

In January 1969, after an absence of more than six months, Hendrix briefly moved back into his girlfriend Kathy Etchingham's Brook Street apartment, which was next door to the Handel House Museum in the West End of London. During this time, the Experience toured Scandinavia, Germany, and gave their final two performances in France. On February 18 and 24, they played sold-out concerts at London's Royal Albert Hall, which were the last European appearances of this lineup.

By February 1969, Redding had grown weary of Hendrix's unpredictable work ethic and his creative control over the Experience's music. During the previous month's European tour, interpersonal relations within the group had deteriorated, particularly between Hendrix and Redding. In his diary, Redding documented the building frustration during early 1969 recording sessions: "On the first day, as I nearly expected, there was nothing doing ... On the second it was no show at all. I went to the pub for three hours, came back, and it was still ages before Jimi ambled in. Then we argued ... On the last day, I just watched it happen for a while, and then went back to my flat." The last Experience sessions that included Redding—a re-recording of "Stone Free" for use as a possible single release—took place on April 14 at Olmstead and the Record Plant in New York. Hendrix then flew bassist Billy Cox to New York; they started recording and rehearsing together on April 21.

The last performance of the original Experience lineup took place on June 29, 1969, at Barry Fey's Denver Pop Festival, a three-day event held at Denver's Mile High Stadium that was marked by police using tear gas to control the audience. The band narrowly escaped from the venue in the back of a rental truck, which was partly crushed by fans who had climbed on top of the vehicle. Before the show, a journalist angered Redding by asking why he was there; the reporter then informed him that two weeks earlier Hendrix announced that he had been replaced with Billy Cox. The next day, Redding quit the Experience and returned to London. He announced that he had left the band and intended to pursue a solo career, blaming Hendrix's plans to expand the group without allowing for his input as a primary reason for leaving. Redding later commented: "Mitch and I hung out a lot together, but we're English. If we'd go out, Jimi would stay in his room. But any bad feelings came from us being three guys who were traveling too hard, getting too tired, and taking too many drugs ... I liked Hendrix. I don't like Mitchell."

Soon after Redding's departure, Hendrix began lodging at the eight-bedroom Ashokan House, in the hamlet of Boiceville near Woodstock in upstate New York, where he had spent some time vacationing in mid-1969. Manager Michael Jeffery arranged the accommodations in the hope that the respite might encourage Hendrix to write material for a new album. During this time, Mitchell was unavailable for commitments made by Jeffery, which included Hendrix's first appearance on U.S. TV—on "The Dick Cavett Show"—where he was backed by the studio orchestra, and an appearance on "The Tonight Show" where he appeared with Cox and session drummer Ed Shaughnessy.

By 1969, Hendrix was the world's highest-paid rock musician. In August, he headlined the Woodstock Music and Art Fair that included many of the most popular bands of the time. For the concert, he added rhythm guitarist Larry Lee and conga players Juma Sultan and Jerry Velez. The band rehearsed for less than two weeks before the performance, and according to Mitchell, they never connected musically. Before arriving at the engagement, Hendrix heard reports that the size of the audience had grown to epic proportions, which gave him cause for concern as he did not enjoy performing for large crowds. He was an important draw for the event, and although he accepted substantially less money for the appearance than his usual fee, he was the festival's highest-paid performer. As his scheduled time slot of midnight on Sunday drew closer, he indicated that he preferred to wait and close the show in the morning; the band took the stage around 8:00 a.m. on Monday. By the time of their set, Hendrix had been awake for more than three days. The audience, which peaked at an estimated 400,000 people, was now reduced to 30–40,000, many of whom had waited to catch a glimpse of Hendrix before leaving during his performance. The festival MC, Chip Monck, introduced the group as "the Jimi Hendrix Experience", but Hendrix clarified: "We decided to change the whole thing around and call it "Gypsy Sun and Rainbows". For short, it's nothin' but a "Band of Gypsys"".

Hendrix's performance featured a rendition of the U.S. national anthem, "The Star-Spangled Banner", during which he used copious amounts of amplifier feedback, distortion, and sustain to replicate the sounds made by rockets and bombs. Although contemporary political pundits described his interpretation as a statement against the Vietnam War, three weeks later Hendrix explained its meaning: "We're all Americans ... it was like 'Go America!'... We play it the way the air is in America today. The air is slightly static, see". Immortalized in the 1970 documentary film, "Woodstock", his guitar-driven version would become part of the sixties Zeitgeist. Pop critic Al Aronowitz of the "New York Post" wrote: "It was the most electrifying moment of Woodstock, and it was probably the single greatest moment of the sixties." Images of the performance showing Hendrix wearing a blue-beaded white leather jacket with fringe, a red head-scarf, and blue jeans are widely regarded as iconic pictures that capture a defining moment of the era. He played "Hey Joe" during the encore, concluding the 3-day festival. Upon leaving the stage, he collapsed from exhaustion. In 2011, the editors of "Guitar World" placed his rendition of "The Star-Spangled Banner" at Woodstock at number one in their list of his 100 greatest performances.

A legal dispute arose in 1966 regarding a record contract that Hendrix had entered into the previous year with producer Ed Chalpin. After two years of litigation, the parties agreed to a resolution that granted Chalpin the distribution rights to an album of original Hendrix material. Hendrix decided that they would record the LP, "Band of Gypsys", during two live appearances. In preparation for the shows he formed an all-black power-trio with Cox and drummer Buddy Miles, formerly with Wilson Pickett, the Electric Flag, and the Buddy Miles Express. Critic John Rockwell described Hendrix and Miles as jazz-rock fusionists, and their collaboration as pioneering. Others identified a funk and soul influence in their music. Concert promoter Bill Graham called the shows "the most brilliant, emotional display of virtuoso electric guitar" that he had ever heard. Biographers have speculated that Hendrix formed the band in an effort to appease members of the Black Power movement and others in the black communities who called for him to use his fame to speak-up for civil rights.

Hendrix had been recording with Cox since April and jamming with Miles since September, and the trio wrote and rehearsed material which they performed at a series of four shows over two nights on December 31 and January 1, at the Fillmore East. They used recordings of these concerts to assemble the LP, which was produced by Hendrix. The album includes the track "Machine Gun", which musicologist Andy Aledort described as the pinnacle of Hendrix's career, and "the premiere example of [his] unparalleled genius as a rock guitarist ... In this performance, Jimi transcended the medium of rock music, and set an entirely new standard for the potential of electric guitar." During the song's extended instrumental breaks, Hendrix created sounds with his guitar that sonically represented warfare, including rockets, bombs, and diving planes.

The "Band of Gypsys" album was the only official live Hendrix LP made commercially available during his lifetime; several tracks from the Woodstock and Monterey shows were released later that year. The album was released in April 1970 by Capitol Records; it reached the top ten in both the U.S. and the UK. That same month a single was issued with "Stepping Stone" as the A-side and "Izabella" as the B-side, but Hendrix was dissatisfied with the quality of the mastering and he demanded that it be withdrawn and re-mixed, preventing the songs from charting and resulting in Hendrix's least successful single; it was also his last.

On January 28, 1970, a third and final Band of Gypsys appearance took place; they performed during a music festival at Madison Square Garden benefiting the anti-Vietnam War Moratorium Committee titled the "Winter Festival for Peace". American blues guitarist Johnny Winter was backstage before the concert; he recalled: "[Hendrix] came in with his head down, sat on the couch alone, and put his head in his hands ... He didn't move until it was time for the show." Minutes after taking the stage he snapped a vulgar response at a woman who had shouted a request for "Foxy Lady". He then began playing "Earth Blues" before telling the audience: "That's what happens when earth fucks with space". Moments later, he briefly sat down on the drum riser before leaving the stage. Both Miles and Redding later stated that Jeffery had given Hendrix LSD before the performance. Miles believed that Jeffery gave Hendrix the drugs in an effort to sabotage the current band and bring about the return of the original Experience lineup. Jeffery fired Miles after the show and Cox quit, ending the Band of Gypsys.

Soon after the abruptly ended Band of Gypsys performance and their subsequent dissolution, Jeffery made arrangements to reunite the original Experience lineup. Although Hendrix, Mitchell, and Redding were interviewed by "Rolling Stone" in February 1970 as a united group, Hendrix never intended to work with Redding. When Redding returned to New York in anticipation of rehearsals with a re-formed Experience, he was told that he had been replaced with Cox. During an interview with "Rolling Stone" Keith Altham, Hendrix defended the decision: "It's nothing personal against Noel, but we finished what we were doing with the Experience and Billy's style of playing suits the new group better." Although the lineup of Hendrix, Mitchell, and Cox became known as the Cry of Love band, after their accompanying tour, billing, advertisements, and tickets were printed with the New Jimi Hendrix Experience or occasionally just Jimi Hendrix.

During the first half of 1970, Hendrix sporadically worked on material for what would have been his next LP. Many of the tracks were posthumously released in 1971 as "The Cry of Love". He had started writing songs for the album in 1968, but in April 1970 he told Keith Altham that the project had been abandoned. Soon afterward, he and his band took a break from recording and began the Cry of Love tour at the L.A. Forum, performing for 20,000 people. Set-lists during the tour included numerous Experience tracks as well as a selection of newer material. Several shows were recorded, and they produced some of Hendrix's most memorable live performances. At one of them, the second Atlanta International Pop Festival, on July 4, he played to the largest American audience of his career. According to authors Scott Schinder and Andy Schwartz, as many as 500,000 people attended the concert. On July 17, they appeared at the New York Pop Festival; Hendrix had again consumed too many drugs before the show, and the set was considered a disaster. The American leg of the tour, which included 32 performances, ended at Honolulu, Hawaii, on August 1, 1970. This would be Hendrix's final concert appearance in the U.S.

In 1968, Hendrix and Jeffery jointly invested in the purchase of the Generation Club in Greenwich Village. They had initially planned to reopen the establishment, but after an audit revealed that Hendrix had incurred exorbitant fees by block-booking lengthy sessions at peak rates they decided that the building would better serve them as a recording studio. With a facility of his own, Hendrix could work as much as he wanted while also reducing his recording expenditures, which had reached a reported $300,000 annually. Architect and acoustician John Storyk designed Electric Lady Studios for Hendrix, who requested that they avoid right angles where possible. With round windows, an ambient lighting machine, and a psychedelic mural, Storyk wanted the studio to have a relaxing environment that would encourage Hendrix's creativity. The project took twice as long as planned and cost twice as much as Hendrix and Jeffery had budgeted, with their total investment estimated at $1 million.

Hendrix first used Electric Lady on June 15, 1970, when he jammed with Steve Winwood and Chris Wood of Traffic; the next day, he recorded his first track there, "Night Bird Flying". The studio officially opened for business on August 25, and a grand opening party was held the following day. Immediately afterwards, Hendrix left for England; he never returned to the States. He boarded an Air India flight for London with Cox, joining Mitchell for a performance as the headlining act of the Isle of Wight Festival.

When the European leg of the Cry of Love tour began, Hendrix was longing for his new studio and creative outlet, and was not eager to fulfill the commitment. On September 2, 1970, he abandoned a performance in Aarhus after three songs, stating: "I've been dead a long time". Four days later, he gave his final concert appearance, at the Isle of Fehmarn Festival in Germany. He was met with booing and jeering from fans in response to his cancellation of a show slated for the end of the previous night's bill due to torrential rain and risk of electrocution. Immediately following the festival, Hendrix, Mitchell, and Cox travelled to London.

Three days after the performance, Cox, who was suffering from severe paranoia after either taking LSD or being given it unknowingly, quit the tour and went to stay with his parents in Pennsylvania. Within days of Hendrix's arrival in England, he had spoken with Chas Chandler, Alan Douglas, and others about leaving his manager, Michael Jeffery. On September 16, Hendrix performed in public for the last time during an informal jam at Ronnie Scott's Jazz Club in Soho with Eric Burdon and his latest band, War. They began by playing a few of their recent hits, and after a brief intermission Hendrix joined them during "Mother Earth" and "Tobacco Road". His performance was uncharacteristically subdued; he quietly played backing guitar, and refrained from the histrionics that people had come to expect from him. He died less than 48 hours later.

In July 1962, after Hendrix was discharged from the U.S. Army, he entered a small club in Clarksville, Tennessee. Drawn in by live music, he stopped for a drink and ended up spending most of the $400 he had saved. He explained: "I went in this jazz joint and had a drink. I liked it and I stayed. People tell me I get foolish, good-natured sometimes. Anyway, I guess I felt real benevolent that day. I must have been handing out bills to anyone that asked me. I came out of that place with sixteen dollars left." According to the authors Steven Roby and Brad Schreiber: "Alcohol would later be the scourge of his existence, driving him to fits of pique, even rare bursts of atypical, physical violence."

While Roby and Schreiber assert that Hendrix first used LSD when he met Linda Keith in late 1966, according to the authors Harry Shapiro and Caesar Glebbeek, the earliest that Hendrix is known to have taken it was in June 1967, while attending the Monterey Pop Festival. According to Hendrix biographer Charles Cross, the subject of drugs came up one evening in 1966 at Keith's New York apartment; when one of Keith's friends offered Hendrix "acid", a street name for lysergic acid diethylamide, Hendrix asked for LSD instead, showing what Cross described as "his naivete and his complete inexperience with psychedelics". Before that, Hendrix had only sporadically used drugs, with his experimentation limited to cannabis, hashish, amphetamines and occasionally cocaine. After 1967, he regularly smoked cannabis and hashish, and used LSD and amphetamines, particularly while touring. According to Cross, by the time of his death in September 1970, "few stars were as closely associated with the drug culture as Jimi".

Hendrix would often become angry and violent when he drank too much alcohol or when he mixed alcohol with drugs. His friend Herbie Worthington explained: "You wouldn't expect somebody with that kind of love to be that violent ... He just couldn't drink ... he simply turned into a bastard". According to journalist and friend Sharon Lawrence, Hendrix "admitted he could not handle hard liquor, which set off a bottled-up anger, a destructive fury he almost never displayed otherwise".

In January 1968, the Experience travelled to Sweden for a one-week tour of Europe. During the early morning hours of the first day, Hendrix became engaged in a drunken brawl in the Hotel Opalen, in Gothenburg, smashing a plate-glass window and injuring his right hand, for which he received medical treatment. The incident culminated in his arrest and release, pending a court appearance that resulted in a large fine.

After the 1969 burglary of a house Hendrix was renting in Benedict Canyon, California, and while he was under the influence of drugs and alcohol, he punched his friend Paul Caruso and accused him of the theft. He then chased Caruso away from the residence while throwing stones at him. A few days later, one of Hendrix's girlfriends, Carmen Borrero, required stitches after he hit her above her eye with a vodka bottle during a drunken, jealous rage.

On May 3, 1969, while Hendrix was passing through customs at Toronto International Airport, authorities detained him after finding a small amount of what they suspected to be heroin and hashish in his luggage. Four hours later, he was formally charged with drug possession and released on $10,000 bail. He was required to return on May 5 for an arraignment hearing. The incident proved stressful for Hendrix, and it weighed heavily on his mind during the seven months that he awaited trial, which took place in December of that year. For the Crown to prove possession they had to show that Hendrix knew the drugs were there. During the jury trial he testified that a fan had given him a vial of what he thought was legal medication, which he put in his bag not knowing what was in it. He was acquitted of the charges. Mitchell and Redding later revealed that everyone had been warned about a planned drug bust the day before flying to Toronto; both men also stated they believed that the drugs had been planted in Hendrix's bag without his knowledge.

Although the details of Hendrix's last day and death are widely disputed, he spent much of September 17, 1970, in London with Monika Dannemann, the only witness to his final hours. Dannemann said that she prepared a meal for them at her apartment in the Samarkand Hotel, 22 Lansdowne Crescent, Notting Hill, sometime around 11 p.m., when they shared a bottle of wine. She drove Hendrix to the residence of an acquaintance at approximately 1:45 a.m., where he remained for about an hour before she picked him up and drove them back to her flat at 3 a.m. Dannemann said they talked until around 7 a.m., when they went to sleep. She awoke around 11 a.m., and found Hendrix breathing, but unconscious and unresponsive. She called for an ambulance at 11:18 a.m., which arrived on the scene at 11:27 a.m. Paramedics then transported Hendrix to St Mary Abbot's Hospital where Dr. John Bannister pronounced him dead at 12:45 p.m. on September 18, 1970.

To determine the cause of death, coroner Gavin Thurston ordered a post-mortem examination on Hendrix's body, which was performed on September 21 by Professor Robert Donald Teare, a forensic pathologist. Thurston completed the inquest on September 28, and concluded that Hendrix aspirated his own vomit and died of asphyxia while intoxicated with barbiturates. Citing "insufficient evidence of the circumstances", he declared an open verdict. Dannemann later revealed that Hendrix had taken nine of her prescribed Vesparax sleeping tablets, 18 times the recommended dosage.

After Hendrix's body had been embalmed by Desmond Henley, it was flown to Seattle, Washington, on September 29, 1970. After a service at Dunlap Baptist Church in Seattle's Rainier Valley on October 1, it was interred at Greenwood Cemetery in Renton, Washington, the location of his mother's grave. Hendrix's family and friends traveled in 24 limousines and more than 200 people attended the funeral, including several notable musicians such as original Experience members Mitch Mitchell and Noel Redding, as well as Miles Davis, John Hammond, and Johnny Winter.

By 1967, as Hendrix was gaining in popularity, many of his pre-Experience recordings were marketed to an unsuspecting public as Jimi Hendrix albums, sometimes with misleading later images of Hendrix. The recordings, which came under the control of producer Ed Chalpin of PPX, with whom Hendrix had signed a recording contract in 1965, were often re-mixed between their repeated reissues, and licensed to record companies such as Decca and Capitol. Hendrix publicly denounced the releases, describing them as "malicious" and "greatly inferior", stating: "At PPX, we spent on average about one hour recording a song. Today I spend at least twelve hours on each song." These unauthorized releases have long constituted a substantial part of his recording catalogue, amounting to hundreds of albums.

Some of Hendrix's unfinished material was released as the 1971 title "The Cry of Love". Although the album reached number three in the U.S. and number two in the UK, producers Mitchell and Kramer later complained that they were unable to make use of all the available songs because some tracks were used for 1971's "Rainbow Bridge"; still others were issued on 1972's "War Heroes". Material from "The Cry of Love" was re-released in 1997 as "First Rays of the New Rising Sun", along with the other tracks that Mitchell and Kramer had wanted to include.

In 1993, MCA Records delayed a multimillion-dollar sale of Hendrix's publishing copyrights because Al Hendrix was unhappy about the arrangement. He acknowledged that he had sold distribution rights to a foreign corporation in 1974, but stated that it did not include copyrights and argued that he had retained veto power of the sale of the catalogue. Under a settlement reached in July 1995, Al Hendrix prevailed in his legal battle and regained control of his son's song and image rights. He subsequently licensed the recordings to MCA through the family-run company Experience Hendrix LLC, formed in 1995. In August 2009, Experience Hendrix announced that it had entered a new licensing agreement with Sony Music Entertainment's Legacy Recordings division which would take effect in 2010. Legacy and Experience Hendrix launched the 2010, Jimi Hendrix Catalog Project, starting with the release of "Valleys of Neptune" in March of that year. In the months before his death, Hendrix recorded demos for a concept album tentatively titled "Black Gold", which are now in the possession of Experience Hendrix LLC; , no official release date has been announced.

Hendrix played a variety of guitars throughout his career, but the instrument that became most associated with him was the Fender Stratocaster. He acquired his first Stratocaster in 1966, when a girlfriend loaned him enough money to purchase a used one that had been built around 1964. He thereafter used the model prevalently during performances and recordings. In 1967, he described the instrument as "the best all-around guitar for the stuff we're doing"; he praised its "bright treble and deep bass sounds".

With few exceptions, Hendrix played right-handed guitars that were turned upside down and restrung for left-hand playing. This had an important effect on the sound of his guitar; because of the slant of the bridge pickup, his lowest string had a brighter sound while his highest string had a darker sound, which was the opposite of the Stratocaster's intended design. In addition to Stratocasters, Hendrix also used Fender Jazzmasters, Duosonics, two different Gibson Flying Vs, a Gibson Les Paul, three Gibson SGs, a Gretsch Corvette, and a Fender Jaguar. He used a white Gibson SG Custom for his performances on "The Dick Cavett Show" in September 1969, and a black Gibson Flying V during the Isle of Wight festival in 1970.

During 1965, and 1966, while Hendrix was playing back-up for soul and R&B acts in the U.S., he used an 85-watt Fender Twin Reverb amplifier. When Chandler brought Hendrix to England in October 1966, he supplied him with 30-watt Burns amps, which Hendrix thought were too small for his needs. After an early London gig when he was unable to use his preferred Fender Twin, he asked about the Marshall amps that he had noticed other groups using. Years earlier, Mitch Mitchell had taken drum lessons from the amp builder, Jim Marshall, and he introduced Hendrix to Marshall. At their initial meeting, Hendrix bought four speaker cabinets and three 100-watt Super Lead amplifiers; he would grow accustomed to using all three in unison. The equipment arrived on October 11, 1966, and the Experience used the new gear during their first tour. Marshall amps were well-suited for Hendrix's needs, and they were paramount in the evolution of his heavily overdriven sound, enabling him to master the use of feedback as a musical effect, creating what author Paul Trynka described as a "definitive vocabulary for rock guitar". Hendrix usually turned all of the amplifier's control knobs to the maximum level, which became known as the Hendrix setting. During the four years prior to his death, he purchased between 50 and 100 Marshall amplifiers. Jim Marshall said that he was "the greatest ambassador" his company ever had.

One of Hendrix's signature effects was the wah-wah pedal, which he first heard used with an electric guitar in Cream's "Tales of Brave Ulysses", released in May 1967. In July of that year, while playing gigs at the Scene club in New York City, Hendrix met Frank Zappa, whose band, the Mothers of Invention were performing at the adjacent Garrick Theater. Hendrix was fascinated by Zappa's application of the pedal, and he experimented with one later that evening. He used a wah pedal during the opening to "Voodoo Child (Slight Return)", creating one of the best-known wah-wah riffs of the classic rock era. He can also be heard using the effect on "Up from the Skies", "Little Miss Lover", and "Still Raining, Still Dreaming".

Hendrix consistently used a Dallas Arbiter Fuzz Face and a Vox wah pedal during recording sessions and live performances, but he also experimented with other guitar effects. He enjoyed a fruitful long-term collaboration with electronics enthusiast Roger Mayer, whom he once called "the secret" of his sound. Mayer introduced him to the Octavia, an octave doubling effect pedal, in December 1966, and he first recorded with the effect during the guitar solo to "Purple Haze".

Hendrix also utilized the Uni-Vibe, which was designed to simulate the modulation effects of a rotating Leslie speaker by providing a rich phasing sound that could be manipulated with a speed control pedal. He can be heard using the effect during his performance at Woodstock and on the Band of Gypsys track "Machine Gun", which prominently features the Uni-vibe along with an Octavia and a Fuzz Face. His signal flow for live performance involved first plugging his guitar into a wah-wah pedal, then connecting the wah-wah pedal to a Fuzz Face, which was then linked to a Uni-Vibe, before connecting to a Marshall amplifier.

As an adolescent during the 1950s, Hendrix became interested in rock and roll artists such as Elvis Presley, Little Richard, and Chuck Berry. In 1968, he told "Guitar Player" magazine that electric blues artists Muddy Waters, Elmore James, and B.B. King inspired him during the beginning of his career; he also cited Eddie Cochran as an early influence. Of Muddy Waters, the first electric guitarist of which Hendrix became aware, he said: "I heard one of his records when I was a little boy and "it scared me to death" because I heard all of these "sounds"." In 1970, he told "Rolling Stone" that he was a fan of western swing artist Bob Wills and while he lived in Nashville, the television show the Grand Ole Opry.

Cox stated that during their time serving in the U.S. military, he and Hendrix primarily listened to southern blues artists such as Jimmy Reed and Albert King. According to Cox, "King was a very, very powerful influence". Howlin' Wolf also inspired Hendrix, who performed Wolf's "Killing Floor" as the opening song of his U.S. debut at the Monterey Pop Festival. The influence of soul artist Curtis Mayfield can be heard in Hendrix's guitar playing, and the influence of Bob Dylan can be heard in Hendrix's songwriting; he was known to play Dylan's records repeatedly, particularly "Highway 61 Revisited" and "Blonde on Blonde".

The Experience's Rock and Roll Hall of Fame biography states: "Jimi Hendrix was arguably the greatest instrumentalist in the history of rock music. Hendrix expanded the range and vocabulary of the electric guitar into areas no musician had ever ventured before. His boundless drive, technical ability and creative application of such effects as wah-wah and distortion forever transformed the sound of rock and roll." Musicologist Andy Aledort described Hendrix as "one of the most creative" and "influential musicians that has ever lived". Music journalist Chuck Philips wrote: "In a field almost exclusively populated by white musicians, Hendrix has served as a role model for a cadre of young black rockers. His achievement was to reclaim title to a musical form pioneered by black innovators like Little Richard and Chuck Berry in the 1950s."

Hendrix favored overdriven amplifiers with high volume and gain. He was instrumental in developing the previously undesirable technique of guitar amplifier feedback, and helped to popularize use of the wah-wah pedal in mainstream rock. He rejected the standard barre chord fretting technique used by most guitarists in favor of fretting the low 6th string root notes with his thumb. He applied this technique during the beginning bars of "Little Wing", which allowed him to sustain the root note of chords while also playing melody. This method has been described as piano style, with the thumb playing what a pianist's left hand would play and the other fingers playing melody as a right hand. Having spent several years fronting a trio, he developed an ability to play rhythm chords and lead lines together, giving the audio impression that more than one guitarist was performing. He was the first artist to incorporate stereophonic phasing effects in rock music recordings. Holly George-Warren of "Rolling Stone" commented: "Hendrix pioneered the use of the instrument as an electronic sound source. Players before him had experimented with feedback and distortion, but Hendrix turned those effects and others into a controlled, fluid vocabulary every bit as personal as the blues with which he began." According to Robert Christgau, Hendrix's 1965 recordings with the Isley Brothers, such as "Move Over and Let Me Dance", "anticipate effects [Eric] Clapton introduced on 'Sunshine of Your Love,' but in a less inflated context". Aledort wrote: "In rock guitar, there are but two eras—before Hendrix and after Hendrix."

While creating his unique musical voice and guitar style, Hendrix synthesized diverse genres, including blues, R&B, soul, British rock, American folk music, 1950s rock and roll, and jazz. Musicologist David Moskowitz emphasized the importance of blues music in Hendrix's playing style, and according to authors Steven Roby and Brad Schreiber, "[He] explored the outer reaches of psychedelic rock". His influence is evident in a variety of popular music formats, and he has contributed significantly to the development of hard rock, heavy metal, funk, post-punk, grunge, and hip hop music. His lasting influence on modern guitar players is difficult to overstate; his techniques and delivery have been abundantly imitated by others. Despite his hectic touring schedule and notorious perfectionism, he was a prolific recording artist who left behind numerous unreleased recordings. More than 40 years after his death, Hendrix remains as popular as ever, with annual album sales exceeding that of any year during his lifetime.

Hendrix has influenced numerous funk and funk rock artists, including Prince, George Clinton, John Frusciante, formerly of the Red Hot Chili Peppers, Eddie Hazel of Funkadelic, and Ernie Isley of the Isley Brothers. Grunge guitarists such as Jerry Cantrell of Alice in Chains, and Mike McCready and Stone Gossard of Pearl Jam have cited Hendrix as an influence. Hendrix's influence also extends to many hip hop artists, including De La Soul, A Tribe Called Quest, Digital Underground, Beastie Boys, and Run–D.M.C. Miles Davis was deeply impressed by Hendrix, and he compared Hendrix's improvisational abilities with those of saxophonist John Coltrane. Guitar virtuoso Greg Koch has stated that Jimi Hendrix was his biggest influence. Hendrix also influenced industrial artist Marilyn Manson, blues legend Stevie Ray Vaughan, Metallica Kirk Hammett, Aerosmith's Brad Whitford, instrumental rock guitarist Joe Satriani, Frank Zappa/David Bowie/Talking Heads/King Crimson/Nine Inch Nails hired gun Adrian Belew, and heavy metal virtuoso Yngwie Malmsteen, who said: "[Hendrix] created modern electric playing, without question ... He was the first. He started it all. The rest is history."

Hendrix received several prestigious rock music awards during his lifetime and posthumously. In 1967, readers of "Melody Maker" voted him the Pop Musician of the Year. In 1968, "Rolling Stone" declared him the Performer of the Year. Also in 1968, the City of Seattle gave him the Keys to the City. "Disc & Music Echo" newspaper honored him with the World Top Musician of 1969 and in 1970 "Guitar Player" magazine named him the Rock Guitarist of the Year.

"Rolling Stone" ranked his three non-posthumous studio albums, "Are You Experienced" (1967), "Axis: Bold as Love" (1967), and "Electric Ladyland" (1968) among the "500 Greatest Albums of All Time". They ranked Hendrix number one on their list of the 100 greatest guitarists of all time, and number six on their list of the 100 greatest artists of all time. "Guitar World"'s readers voted six of Hendrix's solos among the top 100 Greatest Guitar Solos of All Time: "Purple Haze" (70), "The Star-Spangled Banner" (52; from "Live at Woodstock"), "Machine Gun" (32; from "Band of Gypsys"), "Little Wing" (18), "Voodoo Child (Slight Return)" (11), and "All Along the Watchtower" (5). "Rolling Stone" placed seven of his recordings in their list of the 500 Greatest Songs of All Time: "Purple Haze" (17), "All Along the Watchtower" (47) "Voodoo Child (Slight Return)" (102), "Foxy Lady" (153), "Hey Joe" (201), "Little Wing" (366), and "The Wind Cries Mary" (379). They also included three of Hendrix's songs in their list of the "100 Greatest Guitar Songs of All Time": "Purple Haze" (2), "Voodoo Child" (12), and "Machine Gun" (49).

A star on the Hollywood Walk of Fame was dedicated to Hendrix on November 14, 1991, at 6627 Hollywood Boulevard. November 27, 1992 was made Jimi Hendrix Day in Seattle. This was largely due to the efforts of his boyhood friend Sammy Drain. He approached the Seattle mayor Norm Rice and talked to him about it. Mayor Rice being aware of the contribution to music Hendrix had made, readily agreed and on November 27, 1992 which would have been the 50th birthday for the guitarist, the mayor issued a proclamation making it Jimi Hendrix Day. The Jimi Hendrix Experience was inducted into the Rock and Roll Hall of Fame in 1992, and the UK Music Hall of Fame in 2005. In 1999, readers of "Rolling Stone" and "Guitar World" ranked Hendrix among the most important musicians of the 20th century. In 2005, his debut album, "Are You Experienced", was one of 50 recordings added that year to the United States National Recording Registry in the Library of Congress, "[to] be preserved for all time ... [as] part of the nation's audio legacy".

The blue plaque identifying his former residence at 23 Brook Street, London, (next door to the former residence of George Frideric Handel) was the first one issued by English Heritage to commemorate a pop star. A memorial statue of Hendrix playing a Stratocaster stands near the corner of Broadway and Pine Streets in Seattle. In May 2006, the city renamed a park near its Central District Jimi Hendrix Park, in his honor. In 2012, an official historic marker was erected on the site of the July 1970 Second Atlanta International Pop Festival near Byron, Georgia. The marker text reads, in part: "Over thirty musical acts performed, including rock icon Jimi Hendrix playing to the largest American audience of his career."

Hendrix's music has received a number of Hall of Fame Grammy awards, starting with a Lifetime Achievement Award in 1992, followed by two Grammys in 1999 for his albums "Are You Experienced" and "Electric Ladyland"; "Axis: Bold as Love" received a Grammy in 2006. In 2000, he received a Hall of Fame Grammy award for his original composition, "Purple Haze", and in 2001, for his recording of Dylan's "All Along the Watchtower". Hendrix's rendition of "The Star-Spangled Banner" was honored with a Grammy in 2009.

The United States Postal Service issued a commemorative postage stamp honoring Hendrix in 2014.

On August 21, 2016, Jimi Hendrix was officially inducted into the R&B Hall of Fame in Dearborn, Michigan.

The James Marshall "Jimi" Hendrix United States Post Office in Renton Highlands near Seattle, about a mile from Hendrix's grave and memorial, was renamed for the musician in 2019.

The Jimi Hendrix Experience

Jimi Hendrix/Band of Gypsys

Posthumous albums






</doc>
<doc id="16134" url="https://en.wikipedia.org/wiki?curid=16134" title="Jefferson Davis">
Jefferson Davis

Jefferson Finis Davis (June 3, 1808 – December 6, 1889) was an American politician who served as the only President of the Confederate States from 1861 to 1865. As a member of the Democratic Party, he represented Mississippi in the United States Senate and the House of Representatives prior to switching allegiance to the Confederacy. He was appointed as the United States Secretary of War, serving from 1853 to 1857, under President Franklin Pierce.

Davis was born in Fairview, Kentucky, to a moderately prosperous farmer, the youngest of ten children. He grew up in Wilkinson County, Mississippi, and also lived in Louisiana. His eldest brother Joseph Emory Davis secured the younger Davis's appointment to the United States Military Academy. After graduating, Jefferson Davis served six years as a lieutenant in the United States Army. He fought in the Mexican–American War (1846–1848), as the colonel of a volunteer regiment. Before the American Civil War, he operated a large cotton plantation in Mississippi, which his brother Joseph gave him, and owned as many as 113 slaves. Although Davis argued against secession in 1858, he believed that states had an unquestionable right to leave the Union.

Davis married Sarah Knox Taylor in 1835, when he was 27 years old. They were both stricken with malaria soon thereafter, and Sarah died after three months of marriage. Davis recovered slowly and suffered from recurring bouts of the disease throughout his life. At the age of 36, Davis married again, to 18-year-old Varina Howell, a native of Natchez, Mississippi, who had been educated in Philadelphia and had some family ties in the North. They had six children. Only two survived him, and only one married and had children.

Many historians attribute some of the Confederacy's weaknesses to the poor leadership of Davis. His preoccupation with detail, reluctance to delegate responsibility, lack of popular appeal, feuds with powerful state governors and generals, favoritism toward old friends, inability to get along with people who disagreed with him, neglect of civil matters in favor of military ones, and resistance to public opinion all worked against him. Historians agree he was a much less effective war leader than his Union counterpart, President Abraham Lincoln. After Davis was captured in 1865, he was accused of treason and imprisoned at Fort Monroe in Hampton, Virginia. He was never tried and was released after two years. While not disgraced, Davis had been displaced in ex-Confederate affection after the war by his leading general, Robert E. Lee. Davis wrote a memoir entitled "The Rise and Fall of the Confederate Government", which he completed in 1881. By the late 1880s, he began to encourage reconciliation, telling Southerners to be loyal to the Union. Ex-Confederates came to appreciate his role in the war, seeing him as a Southern patriot. He became a hero of the Lost Cause of the Confederacy in the post-Reconstruction South.

Jefferson Finis Davis was born at the family homestead in Fairview, Kentucky, on June 3, 1808. He sometimes gave his year of birth as 1807. He dropped his middle name in later life, although he sometimes used a middle initial. Davis was the youngest of ten children born to Jane (née Cook) and Samuel Emory Davis; his oldest brother Joseph Emory Davis was 23 years his senior. He was named after then-incumbent President Thomas Jefferson, whom his father admired. In the early 20th century, the Jefferson Davis State Historic Site was established near the site of Davis's birth. Coincidentally, Abraham Lincoln was born in Hodgenville, Kentucky, only eight months later, less than to the northeast of Fairview.

Davis's paternal grandparents were born in the region of Snowdonia in North Wales, and immigrated separately to North America in the early 18th century. His maternal ancestors were English. After initially arriving in Philadelphia, Davis's paternal grandfather Evan settled in the colony of Georgia, which was developed chiefly along the coast. He married the widow Lydia Emory Williams, who had two sons from a previous marriage, and their son Samuel Emory Davis was born in 1756. He served in the Continental Army during the American Revolutionary War, along with his two older half-brothers. In 1783, after the war, he married Jane Cook. She was born in 1759 to William Cook and his wife Sarah Simpson in what is now Christian County, Kentucky. In 1793, the Davis family relocated to Kentucky, establishing a community named "Davisburg" on the border of Christian and Todd counties; it was eventually renamed Fairview.

During Davis's childhood, his family moved twice: in 1811 to St. Mary Parish, Louisiana, and less than a year later to Wilkinson County, Mississippi. Three of his older brothers served in the War of 1812. In 1813, Davis began his education at the Wilkinson Academy in the small town of Woodville, near the family cotton plantation. His brother Joseph acted as a surrogate father and encouraged Jefferson in his education. Two years later, Davis entered the Catholic school of Saint Thomas at St. Rose Priory, a school operated by the Dominican Order in Washington County, Kentucky. At the time, he was the only Protestant student at the school. Davis returned to Mississippi in 1818, studying at Jefferson College in Washington. He returned to Kentucky in 1821, studying at Transylvania University in Lexington. (At the time, these colleges were like academies, roughly equivalent to high schools.) His father Samuel died on July 4, 1824, when Jefferson was 16 years old.

Joseph arranged for Davis to get an appointment and attend the United States Military Academy (West Point) starting in late 1824. While there, he was placed under house arrest for his role in the Eggnog Riot during Christmas 1826. Cadets smuggled whiskey into the academy to make eggnog, and more than one-third of the cadets were involved in the incident. In June 1828, Davis graduated 23rd in a class of 33.

Following graduation, Second Lieutenant Davis was assigned to the 1st Infantry Regiment and was stationed at Fort Crawford, Prairie du Chien, Michigan Territory. Zachary Taylor, a future president of the United States, had assumed command shortly before Davis arrived in early 1829. In March 1832, Davis returned to Mississippi on furlough, having had no leave since he first arrived at Fort Crawford. He was still in Mississippi during the Black Hawk War but returned to the fort in August. At the conclusion of the war, Colonel Taylor assigned him to escort Black Hawk to prison. Davis made an effort to shield Black Hawk from curiosity seekers, and the chief noted in his autobiography that Davis treated him "with much kindness" and showed empathy for the leader's situation as a prisoner.

Davis fell in love with Sarah Knox Taylor, daughter of his commanding officer, Zachary Taylor. Both Sarah and Davis sought Taylor's permission to marry. Taylor refused, as he did not wish his daughter to have the difficult life of a military wife on frontier army posts. Davis's own experience led him to appreciate Taylor's objection. He consulted his older brother Joseph, and they both began to question the value of an Army career. Davis hesitated to leave, but his desire for Sarah overcame this, and he resigned his commission in a letter dated April 20, 1835. He had arranged for the letter to be sent to the War Department for him on May 12 when he did not return from leave, but he did not tell Taylor he intended to resign. Against his former commander's wishes, on June 17, he married Sarah in Louisville, Kentucky. His resignation became effective June 30.

Davis's older brother Joseph had been very successful and owned Hurricane Plantation and of adjoining land along the Mississippi River on a peninsula 20 miles south of Vicksburg, Mississippi. The adjoining land was known as Brierfield, since it was largely covered with brush and briers. Wanting to have his youngest brother and his wife nearby, Joseph gave use of Brierfield to Jefferson, who eventually developed Brierfield Plantation there. Joseph retained the title.

In August 1835, Jefferson and Sarah traveled south to his sister Anna's home in West Feliciana Parish, Louisiana; the plantation was known as Locust Grove. They intended to spend the hot summer months in the countryside away from the river floodplain, for their health, but both of them contracted either malaria or yellow fever. Sarah died at the age of 21 on September 15, 1835, after three months of marriage. Davis was also severely ill, and his family feared for his life. In the month following Sarah's death, he slowly improved, although he remained weak.

In late 1835, Davis sailed from New Orleans to Havana, Cuba, to help restore his health. He was accompanied by James Pemberton, his only slave at the time. Davis observed the Spanish military and sketched fortifications. Although no evidence points to his having any motive beyond general interest, the authorities knew that Davis was a former army officer and warned him to stop his observations. Bored and feeling somewhat better, Davis booked passage on a ship to New York, then continued to Washington, D.C., where he visited his old schoolmate George Wallace Jones. He soon returned with Pemberton to Mississippi.

For several years following Sarah's death, Davis was reclusive and honored her memory. He spent time clearing Brierfield and developing his plantation, studied government and history, and had private political discussions with his brother Joseph. By early 1836, Davis had purchased 16 slaves; he held 40 slaves by 1840, and 74 by 1845. Davis promoted Pemberton to be overseer of the field teams. In 1860, he owned 113 slaves.

In 1840, Davis first became involved in politics when he attended a Democratic Party meeting in Vicksburg and, to his surprise, was chosen as a delegate to the party's state convention in Jackson. In 1842, he attended the Democratic convention, and, in 1843, became a Democratic candidate for the state House of Representatives from the Warren County-Vicksburg district; he lost his first election. In 1844, Davis was sent to the party convention for a third time, and his interest in politics deepened. He was selected as one of six presidential electors for the 1844 presidential election and campaigned effectively throughout Mississippi for the Democratic candidate James K. Polk.

In 1844, Davis met Varina Banks Howell, then 18 years old, whom his brother Joseph had invited for the Christmas season at Hurricane Plantation. She was a granddaughter of New Jersey Governor Richard Howell; her mother's family was from the South and included successful Scots-Irish planters. Within a month of their meeting, the 35-year-old widower Davis had asked Varina to marry him, and they became engaged despite her parents' initial concerns about his age and politics. They were married on February 26, 1845.

During this time, Davis was persuaded to become a candidate for the United States House of Representatives and began canvassing for the election. In early October 1845 he traveled to Woodville to give a speech. He arrived a day early to visit his mother there, only to find that she had died the day before. After the funeral, he rode the back to Natchez to deliver the news, then returned to Woodville again to deliver his speech. He won the election and entered the 29th Congress.

Jefferson and Varina had six children; three died before reaching adulthood. Samuel Emory, born July 30, 1852, was named after his grandfather; he died June 30, 1854, of an undiagnosed disease. Margaret Howell was born February 25, 1855, and was the only child to marry and raise a family. She married Joel Addison Hayes, Jr. (1848–1919), and they had five children. They were married in St. Lazarus Church, nicknamed "The Confederate Officers' Church", in Memphis, Tennessee. In the late 19th century, they moved from Memphis to Colorado Springs, Colorado. She died on July 18, 1909, at the age of 54.

Jefferson Davis, Jr., was born January 16, 1857. He died at age 21 because of yellow fever on October 16, 1878, during an in the Mississippi River Valley that caused 20,000 deaths. Joseph Evan, born on April 18, 1859, died at the age of five due to an accidental fall on April 30, 1864. William Howell, born on December 6, 1861, was named for Varina's father; he died of diphtheria at age 10 on October 16, 1872. Varina Anne, known as "Winnie", was born on June 27, 1864, several months after her brother Joseph's death. She was known as the Daughter of the Confederacy as she was born during the war. After her parents refused to let her marry into a northern abolitionist family, she never married. She died nine years after her father, on September 18, 1898, at age 34. Jim Limber an octoroon (mixed race) orphan was briefly a ward of Jefferson Davis and Varina Howell Davis.

Davis had poor health for most of his life, including repeated bouts of malaria, battle wounds from fighting in the Mexican–American War and a chronic eye infection that made bright light painful. He also had trigeminal neuralgia, a nerve disorder that causes severe pain in the face; it has been called one of the most painful known ailments.

In 1846 the Mexican–American War began. Davis raised a volunteer regiment, the 1st Mississippi Rifles, becoming its colonel under the command of his former father-in-law, General Zachary Taylor. On July 21 the regiment sailed from New Orleans for Texas. Colonel Davis sought to arm his regiment with the M1841 Mississippi rifle. At this time, smoothbore muskets were still the primary infantry weapon, and any unit with rifles was considered special and designated as such. President James K. Polk had promised Davis the weapons if he would remain in Congress long enough for an important vote on the Walker tariff. General Winfield Scott objected on the basis that the weapons were insufficiently tested. Davis insisted and called in his promise from Polk, and his regiment was armed with the rifles, making it particularly effective in combat. The regiment became known as the Mississippi Rifles because it was the first to be fully armed with these new weapons. The incident was the start of a lifelong feud between Davis and Scott.

In September 1846, Davis participated in the Battle of Monterrey, during which he led a successful charge on the La Teneria fort. On October 28, Davis resigned his seat in the House of Representatives. On February 22, 1847, Davis fought bravely at the Battle of Buena Vista and was shot in the foot, being carried to safety by Robert H. Chilton. In recognition of Davis's bravery and initiative, Taylor is reputed to have said, "My daughter, sir, was a better judge of men than I was." On May 17, President Polk offered Davis a federal commission as a brigadier general and command of a brigade of militia. Davis declined the appointment, arguing that the Constitution gives the power of appointing militia officers to the states, not the federal government.

Honoring Davis's war service, Governor Albert G. Brown of Mississippi appointed him to the vacant position of United States Senator Jesse Speight, a Democrat, who had died on May 1, 1847. Davis, also a Democrat, took his temporary seat on December 5, and in January 1848 he was elected by the state legislature to serve the remaining two years of the term. In December, during the 30th United States Congress, Davis was made a regent of the Smithsonian Institution and began serving on the Committee on Military Affairs and the Library Committee.

In 1848, Senator Davis proposed and introduced an amendment (the first of several) to the Treaty of Guadalupe Hidalgo that would have annexed most of northeastern Mexico, but it failed on a vote of 11 to 44. Southerners wanted to increase territory held in Mexico as an area for the expansion of slavery. Regarding Cuba, Davis declared that it "must be ours" to "increase the number of slaveholding constituencies." He also was concerned about the security implications of a Spanish holding lying relatively close to the coast of Florida.

A group of Cuban revolutionaries led by Venezuelan adventurer Narciso López intended to liberate Cuba from Spanish rule by the sword. Searching for a military leader for a filibuster expedition, they first offered command of the Cuban forces to General William J. Worth, but he died before making his decision. In the summer of 1849, López visited Davis and asked him to lead the expedition. He offered an immediate payment of $100,000 (worth more than $2,000,000 in 2013), plus the same amount when Cuba was liberated. Davis turned down the offer, stating that it was inconsistent with his duty as a senator. When asked to recommend someone else, Davis suggested Robert E. Lee, then an army major in Baltimore; López approached Lee, who also declined on the grounds of his duty.

The Senate made Davis chairman of the Committee on Military Affairs on December 3, 1849, during the first session of the 31st United States Congress. On December 29 he was elected to a full six-year term (by the Mississippi legislature, as the constitution mandated at the time). Davis had not served a year when he resigned (in September 1851) to run for the governorship of Mississippi on the issue of the Compromise of 1850, which he opposed. He was defeated by fellow Senator Henry Stuart Foote by 999 votes. Left without political office, Davis continued his political activity. He took part in a convention on states' rights, held at Jackson, Mississippi, in January 1852. In the weeks leading up to the presidential election of 1852, he campaigned in numerous Southern states for Democratic candidates Franklin Pierce and William R. King.

Franklin Pierce, after winning the presidential election, made Davis his Secretary of War in 1853. In this capacity, Davis began the Pacific Railroad Surveys in order to determine various possible routes for the proposed Transcontinental Railroad. He promoted the Gadsden Purchase of today's southern Arizona from Mexico, partly because it would provide an easier southern route for the new railroad; the Pierce administration agreed and the land was purchased in December 1853. He saw the size of the regular army as insufficient to fulfill its mission, maintaining that salaries would have to be increased, something which had not occurred for 25 years. Congress agreed and increased the pay scale. It also added four regiments, which increased the army's size from about 11,000 to about 15,000. Davis also introduced general usage of the rifles that he had used successfully during the Mexican–American War. As a result, both the morale and capability of the army was improved. He became involved in public works when Pierce gave him responsibility for construction of the Washington Aqueduct and an expansion of the U.S. Capitol, both of which he managed closely. The Pierce administration ended in 1857 after Pierce's loss of the Democratic nomination to James Buchanan. Davis's term was to end with Pierce's, so he ran for the Senate, was elected, and re-entered it on March 4, 1857.

In the 1840s, tensions were growing between the North and South over various issues including slavery. The Wilmot Proviso, introduced in 1846, contributed to these tensions; if passed, it would have banned slavery in any land acquired from Mexico. The Compromise of 1850 brought a temporary respite, but the Dred Scott case, decided by the United States Supreme Court in 1857, spurred public debate. Chief Justice Roger Taney ruled that the Missouri Compromise was unconstitutional and that African Americans had no standing as citizens under the constitution. Northerners were outraged and there was increasing talk in the South of secession from the Union.

Davis's renewed service in the Senate was interrupted in early 1858 by an illness that began as a severe cold and which threatened him with the loss of his left eye. He was forced to remain in a darkened room for four weeks. He spent the summer of 1858 in Portland, Maine. On the Fourth of July, Davis delivered an anti-secessionist speech on board a ship near Boston. He again urged the preservation of the Union on October 11 in Faneuil Hall, Boston, and returned to the Senate soon after.

As he explained in his memoir "The Rise and Fall of the Confederate Government", Davis believed that each state was sovereign and had an unquestionable right to secede from the Union. At the same time, he counseled delay among his fellow Southerners, because he did not think that the North would permit the peaceable exercise of the right to secession. Having served as secretary of war under President Pierce, he also knew that the South lacked the military and naval resources necessary for defense in a war. Following the election of Abraham Lincoln in 1860, however, events accelerated. South Carolina adopted an ordinance of secession on December 20, 1860, and Mississippi did so on January 9, 1861. Davis had expected this but waited until he received official notification. On January 21, the day Davis called "the saddest day of my life", he delivered a farewell address to the United States Senate, resigned and returned to Mississippi.

In 1861, the Episcopal Church split and Davis became a member of the newly founded Protestant Episcopal Church in the Confederate States of America. He attended St. Paul's Episcopal Church in Richmond while he was President of the Confederacy. The two denominations were reunited in 1865.

Anticipating a call for his services since Mississippi had seceded, Davis had sent a telegraph message to Governor John J. Pettus saying, "Judge what Mississippi requires of me and place me accordingly." On January 23, 1861, Pettus made Davis a major general of the Army of Mississippi. On February 9, a constitutional convention met at Montgomery, Alabama, and considered Davis and Robert Toombs of Georgia as a possible president. Davis, who had widespread support from six of the seven states, easily won. He was seen as the "champion of a slave society and embodied the values of the planter class", and was elected provisional Confederate President by acclamation. He was inaugurated on February 18, 1861. Alexander H. Stephens was chosen as Vice President, but he and Davis feuded constantly.

Davis was the first choice because of his strong political and military credentials. He wanted to serve as commander-in-chief of the Confederate armies but said he would serve wherever directed. His wife Varina Davis later wrote that when he received word that he had been chosen as president, "Reading that telegram he looked so grieved that I feared some evil had befallen our family."

Several forts in Confederate territory remained in Union hands. Davis sent a commission to Washington with an offer to pay for any federal property on Southern soil, as well as the Southern portion of the national debt, but Lincoln refused to meet with the commissioners. Brief informal discussions did take place with Secretary of State William Seward through Supreme Court Justice John A. Campbell, the latter of whom later resigned from the federal government, as he was from Alabama. Seward hinted that Fort Sumter would be evacuated, but gave no assurance.

On March 1, 1861, Davis appointed General P. G. T. Beauregard to command all Confederate troops in the vicinity of Charleston, South Carolina, where state officials prepared to take possession of Fort Sumter. Beauregard was to prepare his forces but await orders to attack the fort. Within the fort the issue was not of the niceties of geopolitical posturing but of survival. They would be out of food on the 15th. The small Union garrison had but half a dozen officers and 127 soldiers under Major Robert Anderson. Famously, this included the baseball folk hero Captain (later major general) Abner Doubleday. More improbable yet was a Union officer who had the name of Jefferson C. Davis. He would spend the war being taunted for his name but not his loyalty to the Northern cause. The newly installed President Lincoln, not wishing to initiate hostilities, informed South Carolina Governor Pickens that he was dispatching a small fleet of ships from the navy yard in New York to resupply but not re-enforce Fort Pickens in Florida and Fort Sumter. The U.S. President did not inform CSA President Davis of this intended resupply of food and fuel. For Lincoln, Davis, as the leader of an insurrection, was without legal standing in U.S. affairs. To deal with him would be to give legitimacy to the rebellion. The fact that Sumter was the property of the sovereign United States was the reason for maintaining the garrison on the island fort. He informed Pickens that the resupply mission would not land troops or munitions unless they were fired upon. As it turned out, just as the supply ships approached Charleston harbor, the bombardment would begin and the flotilla watched the spectacle from 10 miles at sea.

Davis faced the most important decision of his career: to prevent reinforcement at Fort Sumter or to let it take place. He and his cabinet decided to demand that the Federal garrison surrender and, if this was refused, to use military force to prevent reinforcement before the fleet arrived. Anderson did not surrender. With Davis's endorsement, Beauregard began the bombarding of the fort in the early dawn of April 12. The Confederates continued their artillery attack on Fort Sumter until it surrendered on April 14. No one was killed in the artillery duel, but the attack on the U.S. fort meant the fighting had started. President Lincoln called up 75,000 state militiamen to march south to recapture Federal property. In the North and South, massive rallies were held to demand immediate war. The Civil War had begun.

When Virginia joined the Confederacy, Davis moved his government to Richmond in May 1861. He and his family took up his residence there at the White House of the Confederacy later that month. Having served since February as the provisional president, Davis was elected to a full six-year term on November 6, 1861, and was inaugurated on February 22, 1862.

At the start of the war, nearly 21 million people lived in the North compared to 9 million in the South. While the North's population was almost entirely white, the South had an enormous number of black slaves and people of color. While the latter were free, becoming a soldier was seen as the prerogative of white men only. Many Southerners were terrified at the idea of a black man with a gun. Excluding old men and boys, the white males available for Confederate service were less than two million. There was also the additional burden that the near four million black slaves had to be heavily policed as there was no trust between the owner and "owned". The North had vastly greater industrial capacity; built nearly all the locomotives, steamships, and industrial machinery; and had a much larger and more integrated railroad system. Nearly all the munitions facilities were in the North, while critical ingredients for gunpowder were in very short supply in the South.

Much of the railroad track that existed in the Confederacy was of simple railway design just meant to carry the large bales of cotton to local river ports in the harvest season. These often did not connect to other rail-lines, making internal shipments of goods difficult at best. While the Union had a large navy, the new Confederate Navy had only a few captured warships or newly built vessels. These did surprisingly well but ultimately were sunk or abandoned as the Union Navy controlled more rivers and ports. Rebel 'raiders' loosed on the Northern ships on the Atlantic did tremendous damage and sent Yankee ships into safe harbors as insurance rates soared. The Union blockade of the South, however, made imports via blockade runners difficult and expensive. Somewhat awkwardly, these runners didn't bring significant amounts of the war materials, so greatly needed, but rather the European luxuries sought as a relief from the privations of the wartime's stark conditions.

In June 1862, Davis was forced to assign General Robert E. Lee to replace the wounded Joseph E. Johnston to command of the Army of Northern Virginia, the main Confederate army in the Eastern Theater. That December Davis made a tour of Confederate armies in the west of the country. He had a very small circle of military advisers. He largely made the main strategic decisions on his own, though he had special respect for Lee's views. Given the Confederacy's limited resources compared with the Union, Davis decided that the Confederacy would have to fight mostly on the strategic defensive. He maintained this outlook throughout the war, paying special attention to the defense of his national capital at Richmond. He approved Lee's strategic offensives when he felt that military success would both shake Northern self-confidence and strengthen the peace movements there. However, the several campaigns invading the North were met with defeat. A bloody battle at Antietam in Maryland as well as the ride into Kentucky, the Confederate Heartland Offensive (both in 1862) drained irreplaceable men and talented officers. A final offense led to the three-day bloodletting at Gettysburg in Pennsylvania (1863), crippling the South still further. The status of techniques and munitions made the defensive side much more likely to endure: an expensive lesson vindicating Davis's initial belief.

As provisional president in 1861, Davis formed his first cabinet. Robert Toombs of Georgia was the first Secretary of State and Christopher Memminger of South Carolina became Secretary of the Treasury. LeRoy Pope Walker of Alabama was made Secretary of War, after being recommended for this post by Clement Clay and William Yancey (both of whom declined to accept cabinet positions themselves). John Reagan of Texas became Postmaster General. Judah P. Benjamin of Louisiana became Attorney General. Although Stephen Mallory was not put forward by the delegation from his state of Florida, Davis insisted that he was the best man for the job of Secretary of the Navy, and he was eventually confirmed.

Since the Confederacy was founded, among other things, on states' rights, one important factor in Davis's choice of cabinet members was representation from the various states. He depended partly upon recommendations from congressmen and other prominent people. This helped maintain good relations between the executive and legislative branches. This also led to complaints as more states joined the Confederacy, however, because there were more states than cabinet positions.

As the war progressed, this dissatisfaction increased and there were frequent changes to the cabinet. Toombs, who had wished to be president himself, was frustrated as an advisor and resigned within a few months of his appointment to join the army. Robert Hunter of Virginia replaced him as Secretary of State on July 25, 1861. On September 17, Walker resigned as Secretary of War due to a conflict with Davis, who had questioned his management of the War Department and had suggested he consider a different position. Walker requested, and was given, command of the troops in Alabama. Benjamin left the Attorney General position to replace him, and Thomas Bragg of North Carolina (brother of General Braxton Bragg) took Benjamin's place as Attorney General.

Following the November 1861 election, Davis announced the permanent cabinet in March 1862. Benjamin moved again, to Secretary of State. George W. Randolph of Virginia had been made the Secretary of War. Mallory continued as Secretary of the Navy and Reagan as Postmaster General. Both kept their positions throughout the war. Memminger remained Secretary of the Treasury, while Thomas Hill Watts of Alabama was made Attorney General.

In 1862 Randolph resigned from the War Department, and James Seddon of Virginia was appointed to replace him. In late 1863, Watts resigned as Attorney General to take office as the Governor of Alabama, and George Davis of North Carolina took his place. In 1864, Memminger withdrew from the Treasury post due to congressional opposition, and was replaced by George Trenholm of South Carolina. In 1865 congressional opposition likewise caused Seddon to withdraw, and he was replaced by John C. Breckinridge of Kentucky.

Cotton was the South's primary export and the basis of its economy and the system of production the South used was dependent upon slave labor. At the outset of the Civil War, Davis realized that intervention from European powers would be vital if the Confederacy was to stand against the Union. The administration sent repeated delegations to European nations, but several factors prevented Southern success in terms of foreign diplomacy. The Union blockade of the Confederacy led European powers to remain neutral, contrary to the Southern belief that a blockade would cut off the supply of cotton to Britain and other European nations and prompt them to intervene on behalf of the South. Many European countries objected to slavery. Britain had abolished it in the 1830s, and Lincoln's Emancipation Proclamation of 1863 made support for the South even less appealing in Europe. Finally, as the war progressed and the South's military prospects dwindled, foreign powers were not convinced that the Confederacy had the strength to become independent. In the end, not a single foreign nation recognized the Confederate States of America.

Most historians sharply criticize Davis for his flawed military strategy, his selection of friends for military commands, and his neglect of homefront crises. Until late in the war, he resisted efforts to appoint a general-in-chief, essentially handling those duties himself. "Davis was loathed by much of his military, Congress and the public — even before the Confederacy died on his watch," and General Beauregard wrote in a letter: "If he were to die today, the whole country would rejoice at it."

On January 31, 1865, Lee assumed this role, but it was far too late. Davis insisted on a strategy of trying to defend all Southern territory with ostensibly equal effort. This diluted the limited resources of the South and made it vulnerable to coordinated strategic thrusts by the Union into the vital Western Theater (e.g., the capture of New Orleans in early 1862). He made other controversial strategic choices, such as allowing Lee to invade the North in 1862 and 1863 while the Western armies were under very heavy pressure. When Lee lost at Gettysburg, Vicksburg simultaneously fell, and the Union took control of the Mississippi River, splitting the Confederacy. At Vicksburg, the failure to coordinate multiple forces on both sides of the Mississippi River rested primarily on Davis's inability to create a harmonious departmental arrangement or to force such generals as Edmund Kirby Smith, Earl Van Dorn, and Theophilus H. Holmes to work together. In fact, during the late stages of the Franklin–Nashville Campaign, Davis warned Beauregard that Kirby Smith would prove uncooperative to whatever proposal the Creole general had in mind for him.

Davis has been faulted for poor coordination and management of his generals. This includes his reluctance to resolve a dispute between Leonidas Polk, a personal friend, and Braxton Bragg, who was defeated in important battles and distrusted by his subordinates. He was similarly reluctant to relieve the capable but overcautious Joseph E. Johnston until, after numerous frustrations which he detailed in a March 1, 1865 letter to Col. James Phelan of Mississippi, he replaced him with John Bell Hood, a fellow Kentuckian who had shared the Confederate President's views on aggressive military policies.

Davis gave speeches to soldiers and politicians but largely ignored the common people, who came to resent the favoritism shown to the rich and powerful; Davis thus failed to harness Confederate nationalism. One historian speaks of "the heavy-handed intervention of the Confederate government." Economic intervention, regulation, and state control of manpower, production and transport were much greater in the Confederacy than in the Union. Davis did not use his presidential pulpit to rally the people with stirring rhetoric; he called instead for people to be fatalistic and to die for their new country. Apart from two month-long trips across the country where he met a few hundred people, Davis stayed in Richmond where few people saw him; newspapers had limited circulation, and most Confederates had little favorable information about him.

To finance the war, the Confederate government initially issued bonds, but investment from the public never met the demands. Taxes were lower than in the Union and collected with less efficiency; European investment was also insufficient. As the war proceeded, both the Confederate government and the individual states printed more and more paper money. Inflation increased from 60% in 1861 to 300% in 1863 and 600% in 1864. Davis did not seem to grasp the enormity of the problem.

In April 1863, food shortages led to rioting in Richmond, as poor people robbed and looted numerous stores for food until Davis cracked down and restored order. Davis feuded bitterly with his vice president. Perhaps even more seriously, he clashed with powerful state governors who used states' rights arguments to withhold their militia units from national service and otherwise blocked mobilization plans.

Davis is widely evaluated as a less effective war leader than Lincoln, even though Davis had extensive military experience and Lincoln had little. Davis would have preferred to be an army general and tended to manage military matters himself. Lincoln and Davis led in very different ways. According to one historian,

There were many factors that led to Union victory over the Confederacy, and Davis recognized from the start that the South was at a distinct disadvantage; but in the end, Lincoln helped to achieve victory, whereas Davis contributed to defeat.

In March 1865, General Order 14 provided for enlisting slaves into the army, with a promise of freedom for service. The idea had been suggested years earlier, but Davis did not act upon it until late in the war, and very few slaves were enlisted.

On April 3, with Union troops under Ulysses S. Grant poised to capture Richmond, Davis escaped to Danville, Virginia, together with the Confederate Cabinet, leaving on the Richmond and Danville Railroad. Lincoln was in Davis's Richmond office just 40 hours later. William T. Sutherlin turned over his mansion, which served as Davis's temporary residence from April 3 to April 10, 1865. On about April 12, Davis received Robert E. Lee's letter announcing surrender. He issued his last official proclamation as president of the Confederacy, and then went south to Greensboro, North Carolina.

After Lee's surrender, a public meeting was held in Shreveport, Louisiana, at which many speakers supported continuation of the war. Plans were developed for the Davis government to flee to Havana, Cuba. There, the leaders would regroup and head to the Confederate-controlled Trans-Mississippi area by way of the Rio Grande. None of these plans were put into practice.

On April 14, Lincoln was shot, dying the next day. Davis expressed regret at his death. He later said that he believed Lincoln would have been less harsh with the South than his successor, Andrew Johnson. In the aftermath, Johnson issued a $100,000 reward for the capture of Davis and accused him of helping to plan the assassination. As the Confederate military structure fell into disarray, the search for Davis by Union forces intensified.

President Davis met with his Confederate Cabinet for the last time on May 5, 1865, in Washington, Georgia, and officially dissolved the Confederate government. The meeting took place at the Heard house, the Georgia Branch Bank Building, with 14 officials present. Along with their hand-picked escort led by Given Campbell, Davis and his wife Varina Davis were captured by Union forces on May 10 at Irwinville in Irwin County, Georgia.
Mrs. Davis recounted the circumstances of her husband's capture as described below: "Just before day the enemy charged our camp yelling like demons ... I pleaded with him to let me throw over him a large waterproof wrap which had often served him in sickness during the summer season for a dressing gown and which I hoped might so cover his person that in the grey of the morning he would not be recognized. As he strode off I threw over his head a little black shawl which was around my own shoulders, saying that he could not find his hat and after he started sent my colored woman after him with a bucket for water hoping that he would pass unobserved."

It was reported in the media that Davis put his wife's overcoat over his shoulders while fleeing. This led to the persistent rumor that he attempted to flee in women's clothes, inspiring caricatures that portrayed him as such. Over 40 years later, an article in the "Washington Herald" claimed that Mrs. Davis's heavy shawl had been placed on Davis who was "always extremely sensitive to cold air", to protect him from the "chilly atmosphere of the early hour of the morning" by the slave James Henry Jones, Davis's valet who served Davis and his family during and after the Civil War. Meanwhile, Davis's belongings continued on the train bound for Cedar Key, Florida. They were first hidden at Senator David Levy Yulee's plantation in Florida, then placed in the care of a railroad agent in Waldo. On June 15, 1865, Union soldiers seized Davis's personal baggage from the agent, together with some of the Confederate government's records. A historical marker was erected at this site. In 1939, Jefferson Davis Memorial Historic Site was opened to mark the place where Confederate President Jefferson Davis was captured.

On May 19, 1865, Davis was imprisoned in a casemate at Fortress Monroe on the coast of Virginia. Irons were riveted to his ankles at the order of General Nelson Miles who was in charge of the fort. Davis was allowed no visitors, and no books except the Bible. He became sicker, and the attending physician warned that his life was in danger, but this treatment continued for some months until late autumn when he was finally given better quarters. General Miles was transferred in mid-1866, and Davis's treatment continued to improve.

Pope Pius IX (see Pope Pius IX and the United States), after learning that Davis was a prisoner, sent him a portrait inscribed with the Latin words ""Venite ad me omnes qui laboratis, et ego reficiam vos, dicit Dominus"", which correspond to , "Come to me, all you that labor, and are burdened, and I will refresh you, sayeth the Lord". A hand-woven crown of thorns associated with the portrait is often said to have been made by the Pope but may have been woven by Davis's wife Varina.

Varina and their young daughter Winnie were allowed to join Davis, and the family was eventually given an apartment in the officers' quarters. Davis was indicted for treason while imprisoned; one of his attorneys was ex-Governor Thomas Pratt of Maryland. There was a great deal of discussion in 1865 about bringing treason trials, especially against Jefferson Davis. While there was no consensus in President Johnson's cabinet to do so, on June 11, 1866 the House of Representatives voted, 105-19, to support such a trial against Davis. Although Davis wanted such a trial for himself, there were no treason trials against anyone, as it was felt they would probably not succeed and would impede reconciliation. There was also a concern at the time that such action could result in a judicial decision that would validate the constitutionality of secession (later removed by the Supreme Court ruling in "Texas v. White" (1869) declaring secession unconstitutional).

A jury of 12 black and 12 white men was recruited by United States Circuit Court judge John Curtiss Underwood in preparation for the trial.

After two years of imprisonment, Davis was released on bail of $100,000, which was posted by prominent citizens including Horace Greeley, Cornelius Vanderbilt and Gerrit Smith. (Smith was a former member of the Secret Six who had supported abolitionist John Brown.) Davis went to Montreal, Quebec to join his family which had fled there earlier, and lived in Lennoxville, Quebec until 1868, also visiting Cuba and Europe in search of work. At one stage he stayed as a guest of James Smith, a foundry owner in Glasgow, who had struck up a friendship with Davis when he toured the Southern States promoting his foundry business. Davis remained under indictment until Andrew Johnson issued on Christmas Day of 1868 a presidential "pardon and amnesty" for the offense of treason to "every person who directly or indirectly participated in the late insurrection or rebellion" and after a federal circuit court on February 15, 1869, dismissed the case against Davis after the government's attorney informed the court that he would no longer continue to prosecute Davis.

After his release from prison and pardon, Davis faced continued financial pressures, as well as an unsettled family life. His elder brother Joseph died in 1870, his son William Howell Davis in 1872 and Jefferson Davis Jr. in 1878. His wife Varina was often ill or abroad, and for a time refused to live with him in Memphis, Tennessee. Davis resented having to resort to charity, and would only accept jobs befitting his former positions as U.S. Senator and Confederate President; several that he accepted proved financial failures.

On one of his many trips to England, Davis sought a mercantile position in Liverpool. However, British companies were wary, both because Britons were not interested in Canadian mines, and because Mississippi defaulted on debts in the 1840s, and Judah Benjamin cautioned him against countering former wartime propaganda by Robert J. Walker. Davis also refused positions as head of Randolph-Macon Academy in Virginia and the University of the South in Sewanee, Tennessee for financial reasons.

In 1869, Davis became president of the Carolina Life Insurance Company in Memphis, Tennessee, at an annual salary of $12,000, plus travel expenses, and resided at the Peabody Hotel. He recruited former Confederate officers as agents, and the board ratified his position in 1870. By 1873, he suggested that the company have boards of trustees at its various branches, and that qualification for such be that the trustee either take out a policy of at least $5,000 or own at least $1,000 in the company's stock. By midyear the Panic of 1873 affected the company, and Davis resigned when it merged with another firm over his objections. He also planned a "Davis Land Company" in which investors would pay $10 per share for 5,700 acres Davis owned in Arkansas. He drafted a prospectus that stated he owed more than $40,000 and his income did not amount to $200.

Upon General Lee's death, Davis agreed to preside over the Presbyterian memorial in Richmond on November 3, 1870. That speech prompted further invitations, although he declined them until July 1871, when he was commencement speaker at the University of the South. Two years later Davis addressed the Virginia Historical Society at White Sulpher Springs, where Davis proclaimed southerners were "cheated not conquered" and would never have surrendered if they had foreseen Congressional Reconstruction. In the summer of 1875, Davis agreed to speak at 17 agricultural fairs in the Midwest. He received criticism from the Chicago Tribune and threats to his life in Indiana, but crowds in Kansas City, Missouri and Fairview, Kentucky received him well. During the next two years Davis began writing his books about the Confederacy, but only addressed fellow former soldiers: first veterans of the Mexican War (before which he attacked Congressional Reconstruction), then Confederate veterans (where he promoted reconciliation).

Early in Reconstruction, Davis publicly remained silent on his opinions, but privately condemned federal military rule and believed Republican authority over former Confederate states unjustified. Mississippi had elected Hiram Rhodes Revels, an African-American, as a U.S. Senator in 1870 to finish the term of Albert G. Brown. Furthermore, during the war, after Joseph Davis's departure from his plantations at Davis Bend and the Union capture of Vicksburg and the surrounding area, General Grant had continued Joseph Davis's utopian experiment and ordered that the land be leased to the freedman and black refugees allowed to settle in the area. Although Joseph Davis ultimately received the land back, many black leaders came from the plantation, which had its own political system, including elected black judges and sheriffs. After the 1867 floods changed the course of the Mississippi River, Joseph Davis sold the plantation to the former slave who had operated a store and handled the white brothers' cotton transaction, Ben Montgomery. Ben's son Isaiah Thornton Montgomery became the first black to hold office in Mississippi when General E.O.C. Ord appointed him Davis Bend's postmaster in 1867. Ben himself was elected justice of the peace. Other black leaders during Mississippi Reconstruction with Davis Bend ties included Israel Shadd, who became speaker of the state's House of Representatives, and legislator Albert Johnson (who also served in the state's constitutional convention).

Jefferson Davis considered "Yankee and Negroe" rule in the South oppressive, and said so in 1871 and especially after 1873. Like most of his white contemporaries, Davis believed that blacks were inferior to whites. One recent biographer believes Davis favored a Southern social order that included a "democratic white polity based firmly on dominance of a controlled and excluded black caste".

While seeking to reclaim Davis Bend ("Hurricane" and "Brierfield" plantations) in 1865, Joseph Davis had filed documents with the Freedmans Bureau insisting that he had intentionally never given Jefferson Davis title to the latter. After receiving first a pardon, and then the lands back, he sold both plantations to former slave Ben Montgomery and his sons, taking back a mortgage for $300,000 at 6% interest, with payments due each January 1 beginning in 1867. While Joseph Davis recognized he could not farm successfully without his 375 enslaved people, he expected the Montgomerys could better manage the labor situation, since in 1865 they had raised nearly 2000 bales of cotton and earned $160,000 in profits. However, when the Mississippi River flooded in spring 1867, it also changed course, ruining many acres and creating "Davis Island". After Joseph Davis died two years later, his 1869 will left property to his two orphaned grandchildren, as well as to his brother's children, and named Jefferson Davis one of three executors (with Dr. J. H. D. Bowmar and nephew Joseph Smith). After the Montgomery men entertained the three executors in May 1870, and he suffered losses in the Panic of 1873, Jefferson Davis decided the black men could never fulfill the land purchase contract, and filed suit against the other trustees on June 15, 1874. Jefferson Davis argued his late brother had an oral agreement with Ben Montgomery that allowed Jefferson Davis to rescind the deal and that an unassigned $70,000 from the land sale represented Brierfield's value (the orphaned Hamer grandchildren said it represented declining land values). The local Chancery Court (which then had a Republican judge, and two of the three Hamer lawyers were former Confederates) dismissed Davis's lawsuit in January 1876, citing estoppel, because Davis had been acting as executor for four years despite this claim based on alleged actions in the 1840s. In April 1878 (months after Ben Montgomery had died), the Mississippi Supreme Court overruled the Warren County chancery court, deciding that Jefferson Davis properly claimed the Brierfield land by adverse possession, since he had cleared and farmed it from the 1840s until the outbreak of the Civil War (more than the ten years the statute required). By that time, two of the Republicans on that appellate court had been replaced by Democrats, both former Confederate officers, To actually gain possession of Brierfield, Davis needed to convince the Warren County chancery court to foreclose the mortgage, which happened on June 1, 1880, and all appeals were rejected by December 1, 1881, allowing Jefferson Davis (for the first time in his life), to gain legal title.

While pursuing the Brierfield litigation, Davis took another business trip to Liverpool. This time he sought employment from the Royal Insurance Company (a fire and marine insurer) which refused him, citing Northern animosity toward the former Confederate President. Other insurers also rejected him both directly and through intermediaries. He then visited former Confederate ambassador John Slidell in Paris, but was unable to associate with a land company, either to aid the southern people or encourage emigration to the South. Davis returned to the United States and blamed race as the heart of what he called "the night of despotism" enveloping the South, citing Republicans who gave political rights to blacks that made them "more idle and ungovernable than before." Davis also investigated mine properties in Arkansas and backed an ice-making machine venture, which failed. He was invited to Texas, but turned down the opportunity to become the first president of the Agriculture and Mechanical College of Texas (now Texas A&M University) in 1876, citing the financial sacrifice (the offered salary was only $4,000/yr). The Mississippi Valley Society, based in England, sought to spur European immigration and English investment, but Davis declined to accept that presidency until salary details had been settled, though he took a speaking tour of the area to drum up public support.

Joseph Davis had encouraged his brother to write his memoirs just after his release from prison, but Davis had responded that he was not capable of doing so, either physically nor emotionally. His wartime assistant Preston Johnston had also encouraged Davis three years later. As Davis began to seriously consider the memoir endeavor in 1869, his early working title became "Our Cause," for he believed he could convert others to the rightness of the Confederacy's actions. In 1875, unable to come to terms with Preston Johnston, Davis authorized William T. Walthall, a former Confederate officer and Carolina Life agent in Mobile, Alabama to look for a publisher for the proposed book. Walthall contacted D. Appleton & Company in New York City, and editor Joseph C. Derby agreed to pay Walthall $250/month as an advance until the manuscript's completion, with the final product not to exceed two volumes of 800 pages each. Davis made minor changes and Appleton agreed.

In 1877, Sarah Anne Ellis Dorsey, a wealthy widow and writer whom he and Varina had known from childhood and who supported the Lost Cause, invited Davis to stay at her estate and plantation house, "Beauvoir", which faced the Gulf of Mexico in Biloxi, Mississippi. Her husband, Maryland-born Samuel Dorsey had bought Beauvoir in 1873, and died there two years later. Mrs. Dorsey wanted to provide Davis with a refuge in which he could write his memoirs per the Appleton contract. She provided him a cabin for his own use as well as helped him with his writing through organization, dictation, editing and encouragement. Davis refused to accept overt charity, but agreed to purchase the property at a modest price ($5,500, payable in installments over three years). In January 1878 Dorsey, knowing she too was ill (with breast cancer), made over her will with Walthall's assistance in order to leave her remaining three small Louisiana plantations and financial assets of $50,000 () to Davis and (acknowledging his still-precarious health) if he predeceased her, to his beloved daughter, Winnie Davis. Dorsey died in 1879, by which time both the Davises and Winnie were living at Beauvoir. Her relatives came to contest that last will, which excluded them and gave everything to Davis in fee simple. They argued Davis exerted undue influence over the widow. The court dismissed their lawsuit without comment in March 1880, and they filed no appeal.

Upon receiving the Appleton contract, Davis had sent letters to his former associates, seeking supporting documentation. When Walthall sent two proposed chapters to New York in 1878, Appleton returned them, cautioning that it did not want a long rehash of constitutional history, but rather an account of Davis's actions as the Confederacy's president. The publisher then sent William J. Tenney, a states-rights Democrat and staff member, to visit Beauvoir to get the problematic manuscript into publishable shape. When it still failed to arrive, Derby personally traveled to Mississippi in February 1880. By this time, Derby had advanced $8,000, but Davis confessed that he had seen few pages, asserting that Walthall had the rest. Since Davis did not want to give up on the book nor return the funds (and had already mortgaged the properties he received from Dorsey), he agreed that Tenney would take up residence in a cottage at Beauvoir. On May 1, 1880, Davis severed all connections with Walthall, who had made little progress in the preceding two years. Davis and Tenney then completed "The Rise and Fall of the Confederate Government" (1881), in two volumes of 700 and 800 pages respectively.

The Southern Historical Society had been formed in 1876 by Rev. J. William Jones (a Baptist minister and former Confederate chaplain) and Gen. Jubal A. Early. Jones became the Society's paid secretary and editor of the Southern Historical Review; Early became President and head of its executive committee. They made Davis a life member and helped him gather material for his book. They had tried to enlist him for a speaking tour in 1882, but Davis declined, citing his health and a yellow fever epidemic near Beauvoir, and only made one address in New Orleans on its behalf before 1882. Early also began visiting Davis when the Virginian visited New Orleans as supervisor in the Louisiana State Lottery Company. Like Judah Benjamin, Early repeatedly advised Davis not to participate publicly in personal vendettas and old battles, despite critical books and articles by former Confederate Generals Pierre Beauregard and Joseph E. Johnston. Nonetheless, when asked to speak at dedication of the Lee mausoleum in Lexington, Virginia, Davis declined when he learned Johnston would preside, and also vented in his personal correspondence. Davis also took issue with Gen. William T. Sherman in an address in St. Louis in 1884 and in a lengthy letter to the editor, and also criticized young New York politician Theodore Roosevelt for comparing him to Benedict Arnold.

When touring the South in 1886 and 1887, Davis attended many Lost Cause ceremonies, and large crowds showered him with affection as local leaders presented emotional speeches honoring his sacrifices to the would-be nation. According to the "Meriden Daily Journal", at a reception held in New Orleans in May 1887, Davis urged southerners to be loyal to the nation--"United you are now, and if the Union is ever to be broken, let the other side break it." He continued by lauding Confederate men who successfully fought for their own rights despite inferior numbers during the Civil War, and argued that northern historians ignored this view. Davis firmly believed that Confederate secession was constitutional, and was optimistic concerning American prosperity and the next generation.

In the summer of 1888, James Redpath, editor of the North American Review and a former political enemy who became an admirer upon meeting Davis, convinced him to write a series of articles at $250 per article, as well as a book. Davis then completed his final book "A Short History of the Confederate States of America" in October 1889.

On November 6 1889, Davis left Beauvoir to visit his Brierfield plantation. He embarked a steamboat in New Orleans during sleety rain and fell ill during the trip, so that he initially felt too sick to disembark at his stop, and spent the night upriver in Vicksburg before making his way to the plantation the next day. He refused to send for a doctor for four days before embarking on his return trip. Meanwhile, servants sent Varina a telegram, and she took a train to New Orleans, and then a steamboat upriver, finally reaching the vessel on which her husband was returning. Davis finally received medical care as two doctors came aboard further south and diagnosed acute bronchitis complicated by malaria. Upon arriving in New Orleans three days later, Davis was taken to Garden District home of Charles Erasmus Fenner, a former Confederate officer who became an Associate Justice of the Louisiana Supreme Court. Fenner was the son-in-law of Davis's old friend J. M. Payne. Davis's doctor Stanford E. Chaille pronounced him too ill to travel to Beauvoir; four medical students who were sons of Confederate veterans and a Catholic nun attended Davis in the Charity Hospital ambulance which took him to the Fenner home. Davis remained bedridden but stable for the next two weeks. He took a turn for the worse in early December. According to Fenner, just when Davis again appeared to be improving, he lost consciousness on the evening of December 5 and died at 12:45 a.m. on Friday, December 6, 1889, holding Varina's hand and in the presence of several friends.

His funeral was one of the largest in the South, and New Orleans draped itself in mourning as his body lay in state in the City Hall for several days. An Executive Committee decided to emphasize Davis's ties to the United States, so an American national flag was placed over the Confederate flag during the viewing, and many crossed American and Confederate flags nearby. Davis wore a new suit of Confederate grey fabric Jubal Early had given him, and Varina placed a sword Davis had carried during the Black Hawk War on the bier. A common decoration during the initial funeral was a small American flag in mourning, with a portrait of Davis in the center. The Grand Army of the Republic had a prominent role, even though the Grand Marshall was John G. Glynn, head of the Louisiana National Guard, and Georgia Governor John Gordon (head of the newly organized United Confederate Veterans) was honorary Grand Marshall. While the federal government officially ignored Davis's death, many church bells rang in the south, Confederate veterans held many processions, and Senators and congressmen crossed the Potomac River to join former Confederate officials and generals in eulogizing Davis in Alexandria, Virginia.

Although initially laid to rest in New Orleans in the Army of Northern Virginia tomb at Metairie Cemetery, in 1893 Davis was reinterred in Richmond, Virginia at Hollywood Cemetery, per his widow's request. Before his death, Davis left the location of his burial up to Varina, but within a day of his death "The New York Times" proclaimed Richmond wanted his body. Varina Davis had refused to accept direct charity, but let it be known that she would accept financial help through the Davis Land Company. Soon, many tourists in New Orleans visited the mausoleum. Several other locations in the South wanted Davis's remains. Louisville, Kentucky offered a site in Cave Hill cemetery, noting that two years earlier Davis had dedicated a church built on the site of his birthplace and claiming that he several times said he wanted to be buried in his native state. Memphis, Tennessee, Montgomery, Alabama, Macon and Atlanta, Georgia and both Jackson and Vicksburg, Mississippi also petitioned for Davis's remains. Richmond mayor and Confederate veteran J. Taylor Ellyson established the Jefferson Davis Monument Association, and on July 12, 1891 Varina revealed in a letter to Confederate Veterans and people of the Southern States that her first choice would be Davis's plantation in Mississippi, but that because she feared flooding, she had decided to urge Richmond as the proper place for his tomb.

After Davis's remains were exhumed in New Orleans, they lay in state for a day at Memorial Hall of the newly organized Louisiana Historical Association. Those paying final respects included Louisiana Governor Murphy J. Foster, Sr.. A continuous cortège, day and night, then accompanied Davis's remains from New Orleans to Richmond. The Louisville and Nashville Railroad car traveled past Beauvoir, then proceeded northeastward toward Richmond, with ceremonies at stops in Mobile and Montgomery, Alabama, Atlanta, Georgia, then Charlotte and Greensboro, North Carolina. The train also detoured to Raleigh, North Carolina for Davis's coffin to lie in state in that capital city, having been driven by James J. Jones, a free black man who had served Davis during the war and become a local businessman and politician. After a stop in Danville, Virginia, the Confederacy's last capital, and another ceremony at the Virginia State Capital, Davis was then interred at Hollywood Cemetery in Richmond. Per the association's agreement with Varina, their children's remains were exhumed from Washington, D.C., Memphis and another plot at the Hollywood cemetery, to rest in the new family plot.

A life sized statue of Davis was eventually erected as promised by the Jefferson Davis Monument Association, in cooperation with the Southern Press Davis Monument Association, the United Confederate Veterans and ultimately the United Daughters of the Confederacy. The monument's cornerstone was laid in an 1896 ceremony, and it was dedicated with great pomp and 125,000 spectators on June 3, 1907, the last day of a Confederate reunion. It continues to mark his tomb.

Jefferson Davis served in many roles. As a soldier, he was brave and resourceful. As a politician, he served as a United States senator and a Mississippi congressman and was active and accomplished, although he never completed a full term in any elected position. As a plantation owner, he employed slave labor as did most of his peers in the South, and supported slavery. As president of the Confederate States of America, he is widely viewed as an ineffective wartime leader; although the task of defending the Confederacy against the much stronger Union would have been a great challenge for any leader, Davis's performance in this role is considered poor. After the war, he contributed to reconciliation of the South with the North, but remained a symbol for Southern pride.

Some portions of his legacy were created not as memorials, but as contemporary recognition of his service at the time.

Fort Davis National Historic Site began as a frontier military post in October 1854, in the mountains of western Texas. It was named after then-United States Secretary of War Jefferson Davis. That fort gave its name to the surrounding Davis Mountains range, and the town of Fort Davis. The surrounding area was designated Jeff Davis County in 1887, with the town of Fort Davis as the county seat. Other states containing a Jefferson (or Jeff) Davis County/Parish include Georgia, Louisiana, and Mississippi.

Jefferson Davis Hospital began operations in 1924 and was the first centralized municipal hospital to treat indigent patients in Houston, Texas. The building was designated as a protected historic landmark on November 13, 2013, by the Houston City Council and is monitored by the Historic Preservation Office of the City of Houston Department of Planning and Development. The hospital was named for Jefferson Davis, former president of the Confederacy, in honor of the Confederate soldiers who had been buried in the cemetery and as a means to console the families of the deceased.

Numerous memorials to Jefferson Davis were created. The largest is the concrete obelisk located at the Jefferson Davis State Historic Site in Fairview, marking his birthplace. Construction of the monument began in 1917 and finished in 1924 at a cost of about $200,000.

In 1913, the United Daughters of the Confederacy conceived the Jefferson Davis Memorial Highway, a transcontinental highway to be built through the South. Portions of the highway's route in Virginia, Alabama and other states still bear the name of Jefferson Davis. However, in Alexandria, Virginia, the city council voted unanimously to rename the highway and has solicited public suggestions for a new name.

Davis appeared on several postage stamps issued by the Confederacy, including its first postage stamp (issued in 1861). In 1995, his portrait appeared on a United States postage stamp, part of a series of 20 stamps commemorating the 130th anniversary of the end of the Civil War. Davis was also celebrated on the 6-cent Stone Mountain Memorial Carving commemorative on September 19, 1970, at Stone Mountain, Georgia. The stamp portrayed Jefferson Davis, Robert E. Lee and Thomas J. "Stonewall" Jackson on horseback. It depicts a replica of the actual memorial, carved into the side of Stone Mountain at above ground level, the largest high-relief sculpture in the world.

The Jefferson Davis Presidential Library was established at Beauvoir in 1998. For some years, the white-columned Biloxi mansion that was Davis's final home had served as a Confederate Veterans Home. The house and library were damaged by Hurricane Katrina in 2005; the house reopened in 2008. Bertram Hayes-Davis, Davis's great-great grandson, is the executive director of Beauvoir, which is owned by the Mississippi Division of the Sons of Confederate Veterans.

Based at Rice University in Houston, Texas, "The Papers of Jefferson Davis" is an editing project to publish documents related to Davis. Since the early 1960s, it has published 13 volumes, the first in 1971 and the most recent in 2012; two more volumes are planned. The project has roughly 100,000 documents in its archives.
The birthday of Jefferson Davis is commemorated in several states. His actual birthday, June 3, is celebrated in Florida, Kentucky, Louisiana and Tennessee; in Alabama, it is celebrated on the first Monday in June. In Mississippi, the last Monday of May (Memorial Day) is celebrated as "National Memorial Day and Jefferson Davis's Birthday". In Texas, "Confederate Heroes Day" is celebrated on January 19, the birthday of Robert E. Lee; Jefferson Davis's birthday had been officially celebrated on June 3 but was combined with Lee's birthday in 1973.

Robert E. Lee's United States citizenship was posthumously restored in 1975. Davis had been specifically excluded from earlier resolutions restoring rights to other Confederate officials, and a movement arose to restore Davis's citizenship as well. This was accomplished with the passing of Senate Joint Resolution 16 on October 17, 1978. In signing the law, President Jimmy Carter referred to this as the last act of reconciliation in the Civil War.

On film and television Jefferson Davis has been portrayed by,


Primary sources

Official
Other


</doc>
<doc id="16208" url="https://en.wikipedia.org/wiki?curid=16208" title="James G. Blaine">
James G. Blaine

James Gillespie Blaine (January 31, 1830January 27, 1893) was an American statesman and Republican politician who represented Maine in the U.S. House of Representatives from 1863 to 1876, serving as Speaker of the U.S. House of Representatives from 1869 to 1875, and then in the United States Senate from 1876 to 1881.
Blaine twice served as Secretary of State (1881, 1889–1892), one of only two persons to hold the position under three separate presidents (the other being Daniel Webster), and unsuccessfully sought the Republican nomination for President in 1876 and 1880 before being nominated in 1884. In the general election, he was narrowly defeated by Democrat Grover Cleveland. Blaine was one of the late 19th century's leading Republicans and champion of the moderate reformist faction of the party known as the "Half-Breeds".

Blaine was born in the western Pennsylvania town of West Brownsville and after college moved to Maine, where he became a newspaper editor. Nicknamed "the Magnetic Man", he was a charismatic speaker in an era that prized oratory. He began his political career as an early supporter of Abraham Lincoln and the Union war effort in the American Civil War. In Reconstruction, Blaine was a supporter of black suffrage, but opposed some of the more coercive measures of the Radical Republicans. Initially a protectionist, he later worked for a reduction in the tariff and an expansion of American trade with foreign countries. Railroad promotion and construction were important issues in his time, and as a result of his interest and support, Blaine was widely suspected of corruption in the awarding of railroad charters; these allegations plagued his 1884 presidential candidacy.

As Secretary of State, Blaine was a transitional figure, marking the end of an isolationist era in foreign policy and foreshadowing the rise of the American Century that would begin with the Spanish–American War. His efforts at expanding the United States' trade and influence began the shift to a more active American foreign policy. Blaine was a pioneer of tariff reciprocity and urged greater involvement in Latin American affairs. An expansionist, Blaine's policies would lead in less than a decade to the establishment of the United States' acquisition of Pacific colonies and dominance of the Caribbean.

James Gillespie Blaine was born January 31, 1830 in West Brownsville, Pennsylvania, the third child of Ephraim Lyon Blaine and his wife Maria (Gillespie) Blaine. He had two older sisters, Harriet, and Margaret. Blaine's father was a western Pennsylvania businessman and landowner, and the family lived in relative comfort. On his father's side, Blaine was descended from Scotch-Irish settlers who first emigrated to Pennsylvania in 1745. His great-grandfather Ephraim Blaine served as a Commissary-General under George Washington in the American Revolutionary War. Blaine's mother and her forebears were Irish Catholics who immigrated to Pennsylvania in the 1780s. Blaine's parents were married in 1820 in a Roman Catholic ceremony, although Blaine's father remained a Presbyterian. Following a common compromise of the era, the Blaines agreed that their daughters would be raised in their mother's Catholic faith while their sons would be brought up in their father's religion. In politics, Blaine's father supported the Whig party.

Blaine's biographers describe his childhood as "harmonious," and note that the boy took an early interest in history and literature. At the age of thirteen, Blaine enrolled in his father's "alma mater", Washington College (now Washington & Jefferson College), in nearby Washington, Pennsylvania. There, he was a member of the Washington Literary Society, one of the college's debating societies. Blaine succeeded academically, graduating near the top of his class and delivering the salutatory address in June 1847. After graduation, Blaine considered attending law school at Yale Law School, but ultimately decided against it, instead moving west to find a job.

In 1848, Blaine was hired as a professor of mathematics and ancient languages at the Western Military Institute in Georgetown, Kentucky. Although he was only eighteen years old and younger than many of his students, Blaine adapted well to his new profession. Blaine grew to enjoy life in his adopted state and became an admirer of Kentucky Senator Henry Clay. He also made the acquaintance of Harriet Stanwood, a teacher at the nearby Millersburg Female College and native of Maine. On June 30, 1850, the two were married. Blaine once again considered taking up the study of law, but instead took his new bride to visit his family in Pennsylvania. They next lived with Harriet Blaine's family in Augusta, Maine for several months, where their first child, Stanwood Blaine, was born in 1851. The young family soon moved again, this time to Philadelphia where Blaine took a job at the Pennsylvania Institution for the Instruction of the Blind (now Overbrook School for the Blind) in 1852, teaching science and literature.

Philadelphia's law libraries gave Blaine the chance to at last begin to study the law, but in 1853 he received a more tempting offer: to become editor and co-owner of the "Kennebec Journal". Blaine had spent several vacations in his wife's native state of Maine and had become friendly with the "Journal"'s editors. When the newspaper's founder, Luther Severance, retired, Blaine was invited to purchase the publication along with co-editor Joseph Baker. He quickly accepted, borrowing the purchase price from his wife's brothers. Baker soon sold his share to John L. Stevens, a local minister, in 1854. The "Journal" had been a staunchly Whig newspaper, which coincided with Blaine's and Stevens' political opinions. The decision to become a newspaperman, unexpected as it was, started Blaine on the road to a lifelong career in politics. Blaine's purchase of the "Journal" coincided with the demise of the Whig party and birth of the Republican party, and Blaine and Stevens actively promoted the new party in their newspaper. The newspaper was financially successful, and Blaine was soon able to invest his profits in coal mines in Pennsylvania and Virginia, forming the basis of his future wealth.

Blaine's career as a Republican newspaperman led naturally to involvement in Republican party politics. In 1856, he was selected as a delegate to the first Republican National Convention. From the party's early days, Blaine identified with the conservative wing, supporting Supreme Court Justice John McLean for the presidential nomination over the more radical John C. Frémont, the eventual nominee. The following year, Blaine was offered the editorship of the "Portland Daily Advertiser", which he accepted, selling his interest in the "Journal" soon thereafter. He still maintained his home in Augusta, however, with his growing family. Although Blaine's first son, Stanwood, died in infancy, he and Harriet had two more sons soon afterward: Walker, in 1855, and Emmons, in 1857. They would have four more children in years to come: Alice, James, Margaret, and Harriet. It was around this time that Blaine left the Presbyterian church of his childhood and joined his wife's new denomination, becoming a member of the South Parish Congregational Church in Augusta.

In 1858, Blaine ran for a seat in the Maine House of Representatives, and was elected. He ran for reelection in 1859, 1860, and 1861, and was successful each time by large majorities. The added responsibilities led Blaine to reduce his duties with the "Advertiser" in 1860, and he soon ceased editorial work altogether. Meanwhile, his political power was growing as he became chairman of the Republican state committee in 1859, replacing Stevens. Blaine was not a delegate to the Republican convention in 1860, but attended anyway as an enthusiastic supporter of Abraham Lincoln. Returning to Maine, he was elected Speaker of the Maine House of Representatives in 1861 and reelected in 1862. With the outbreak of the Civil War in 1861, he supported Lincoln's war effort and saw that the Maine Legislature voted to organize and equip units to join the Union Army.

Blaine had considered running for the United States House of Representatives from Maine's 4th district in 1860, but agreed to step aside when Anson P. Morrill, a former governor, announced his interest in the seat. Morrill was successful, but after redistricting placed Blaine in the 3rd district for the 1862 elections, he allowed his name to be put forward. Running on a campaign of staunch support for the war effort, Blaine was elected with an ample majority despite Republican losses across the rest of the country.

Under the Congressional calendar of the 1860s, members of the 38th United States Congress, elected in November 1862, did not begin their work until December 1863; by the time Blaine finally took his seat that month, the Union had turned the tide in the war with victories at Gettysburg and Vicksburg. As a first-term congressman, he initially said little, mostly following the administration's lead in supporting the continuing war effort. He did clash several times with the leader of the Republicans' radical faction, Thaddeus Stevens of Pennsylvania, firstly over payment of states' debts incurred in supporting the war, and again over monetary policy concerning the new greenback currency. Blaine also spoke in support of the commutation provision of the military draft law passed in 1863 and proposed a constitutional amendment allowing the federal government to impose taxes on exports.

Blaine was reelected in 1864 and, when the 39th Congress assembled in December 1865, the main issue was the Reconstruction of the defeated Confederate States. Although he was not a member of the committee charged with drafting what became the Fourteenth Amendment, Blaine did make his views on the subject known and believed that three-fourths of the non-seceded states would be needed to ratify it, rather than three-fourths of all states, an opinion that did not prevail and placed him, atypically, in the radical camp. The Republican Congress also played a role in the governance of the conquered South, dissolving the state governments President Andrew Johnson had installed and substituting military governments under Congress' control. Blaine voted in favor of these new, harsher measures, but also supported some leniency toward the former rebels when he opposed a bill that would have barred Southerners from attending the United States Military Academy. Blaine voted to impeach Johnson in 1868, although he had initially opposed the effort. Later, Blaine was more ambiguous about the validity of the charges against Johnson, writing that "there was a very grave difference of opinion among those equally competent to decide," but at the time partisan zeal led him to follow his party's leaders.

Continuing his earlier battle with Stevens, Blaine led the fight in Congress for a strong dollar. After the issuance of 150 million dollars in greenbacks—non-gold-backed currency—the value of the dollar stood at a low ebb. A bipartisan group of inflationists, led by Republican Benjamin F. Butler and Democrat George H. Pendleton, wished to preserve the "status quo" and allow the Treasury to continue to issue greenbacks and even to use them to pay the interest due on pre-war bonds. Blaine called this idea a repudiation of the nation's promise to investors, which was made when the only currency was gold. Speaking several times on the matter, Blaine said that the greenbacks had only ever been an emergency measure to avoid bankruptcy during the war. Blaine and his hard money allies were successful, but the issue remained alive until 1879, when all remaining greenbacks were made redeemable in gold by the Specie Payment Resumption Act of 1875.

With Speaker Schuyler Colfax' election to the Vice Presidency in 1868, the leadership of the House became vacant. Blaine had only been a member of Congress since 1863, but he had developed a reputation for parliamentary skill and, aside from a growing feud with Roscoe Conkling of New York, was popular with his fellow Republicans. He was elected with the unanimous vote of the Republican members at the start of the 41st Congress in March 1869. Blaine was an effective Speaker with a magnetic personality. Moreover, President Ulysses S. Grant valued his skill and loyalty in leading the House. He enjoyed the job and made his presence in Washington more permanent by buying a large residence on Fifteenth Street in the city. At the same time, the Blaine family moved to a mansion in Augusta.

Republicans remained in control of the House in the 42nd and 43rd Congresses, and Blaine was reelected as Speaker at the start of both of them, for a total term of six years in the Speaker's chair. His popularity continued to grow, and Republicans dissatisfied with Grant mentioned Blaine as a potential candidate for President in 1872. Instead, Blaine worked steadfastly for Grant's reelection, which was a success. Blaine's growing fame brought growing opposition from the Democrats, as well, and during the 1872 campaign he was accused of receiving bribes in the Crédit Mobilier scandal Blaine denied any part in the scandal, which involved railroad companies bribing federal officials to turn a blind eye to fraudulent railroad contracts that overcharged the government by millions of dollars. No one was able to satisfactorily prove Blaine's involvement. Though not an absolute defense, it is true that the law that made the fraud possible had been written before he was elected to Congress. But other Republicans were exposed by the accusations, including Vice President Colfax, who was dropped from the ticket at the 1872 Republican National Convention.

Although he supported a general amnesty for former Confederates, Blaine opposed extending it to include Jefferson Davis, and he cooperated with Grant in helping to pass the Civil Rights Act of 1875 in response to increased violence and disenfranchisement of blacks in the South. He refrained from voting on the anti-third term resolution that overwhelmingly passed the House that same year, believing that to vote for it would look self-interested. Blaine was loyal to Grant, and the scandals of the Grant administration did not seem to affect how the public perceived him; according to his biographer, Blaine was never more popular than when he was Speaker of the House. Liberal Republicans saw him as an alternative to the evident corruption of other Republican leaders, and some even urged him to form a new, reformist party. Although he remained a Republican, this base of moderate reformers remained loyal to Blaine and became known as the Half Breed faction of the party.

The 1874 House elections produced a Democratic majority for the 44th Congress, and Blaine's time as Speaker was at an end. This gave Blaine more time to concentrate on his presidential ambitions, and to develop new policy ideas. One result was a foray into education policy. In late 1875, President Grant made several speeches on the importance of the separation of church and state and the duty of the states to provide free public education. Blaine saw in this an issue that would distract from the Grant administration scandals and let the Republican party regain the high moral ground. In December 1875, he proposed a joint resolution that became known as the Blaine Amendment.

The proposed amendment codified the church-state separation Blaine and Grant were promoting, stating that:

The effect was to prohibit the use of public funds by any religious school, although it did not advance Grant's other aim of requiring states to provide public education to all children. The bill passed the House but failed in the Senate. Although it never passed Congress, and left Blaine open to charges of anti-Catholicism, the proposed amendment served Blaine's purpose of rallying Protestants to the Republican party and promoting himself as one of the party's foremost leaders.

Blaine entered the 1876 presidential campaign as the favorite, but his chances were almost immediately harmed by the emergence of a scandal. Rumors had begun to spread in February of that year that Blaine had been involved in a transaction with the Union Pacific Railroad in which the railroad had paid Blaine $64,000 for some Little Rock and Fort Smith Railroad bonds he owned, even though the bonds were nearly worthless. In essence, the alleged transaction was presented as a sham designed to bribe Blaine. Blaine denied the charges, as did the Union Pacific's directors. Blaine claimed he never had any dealings with the Little Rock and Fort Smith Railroad except to purchase bonds at market price, and that he had lost money on the transaction. Democrats in the House of Representatives nevertheless demanded a Congressional investigation. The testimony appeared to favor Blaine's version of events until May 31, when James Mulligan, a Boston clerk formerly employed by Blaine's brother-in-law, testified that the allegations were true, that he had arranged the transaction, and that he had letters to prove it. The letters ended with the damning phrase, "Kindly burn this letter." When the investigating committee recessed, Blaine met with Mulligan that night in his hotel room. What transpired between the men is unclear, but Blaine either acquired the letters or, as Mulligan told the committee, snatched them from Mulligan's hands and fled the room. In any event, Blaine had the letters and refused the committee's demand to turn them over.

Opinion swiftly turned against Blaine; the June 3 "The New York Times" carried the headline "Blaine's Nomination Now Out of the Question." Blaine took his case to the House floor on June 5, theatrically proclaiming his innocence and calling the investigation a partisan attack by Southern Democrats, revenge for his exclusion of Jefferson Davis from the amnesty bill of the previous year. He read selected passages from the letters aloud, saying "Thank God Almighty, I am not afraid to show them!" Blaine even succeeded in extracting an apology from the committee chairman. The political tide turned anew in Blaine's favor. But now the pressure had begun to affect Blaine's health, and he collapsed while leaving church services on June 14. His opponents called the collapse a political stunt, with one Democratic newspaper reporting the event as "Blaine Feigns a Faint." Rumors of Blaine's ill health combined with the lack of hard evidence against him garnered him sympathy among Republicans, and when the Republican convention began in Cincinnati later that month, he was again seen as the front-runner.
Though he was damaged by the Mulligan letters, Blaine entered the convention as the favorite. Five other men were also considered serious candidates: Benjamin Bristow, the Kentucky-born Treasury Secretary; Roscoe Conkling, Blaine's old enemy and now a Senator from New York; Senator Oliver P. Morton of Indiana; Governor Rutherford B. Hayes of Ohio; and Governor John F. Hartranft of Pennsylvania. Blaine was nominated by Illinois orator Robert G. Ingersoll in what became a famous speech:

The speech was a success and Ingersoll's appellation of "plumed knight" remained a nickname for Blaine for years to come. On the first ballot, no candidate received the required majority of 378, but Blaine had the most votes, with 285 and no other candidate had more than 125. There were a few vote shifts in the next five ballots, and Blaine climbed to 308 votes, with his nearest competitor at just 111. On the seventh ballot the situation shifted drastically as anti-Blaine delegates began to coalesce around Hayes; by the time the balloting ended, Blaine's votes had risen to 351, but Hayes surpassed him at 384, a majority.

Blaine received the news at his home in Washington and telegraphed Hayes his congratulations. In the subsequent contest of 1876, Hayes was elected after a contentious compromise over disputed electoral votes. The results of the convention had further effects on Blaine's political career, as Bristow, having lost the nomination, also resigned as Treasury Secretary three days after the convention ended. President Grant selected Senator Lot M. Morrill of Maine to fill the cabinet post, and Maine's governor, Seldon Connor, appointed Blaine to the now-vacant Senate seat. When the Maine Legislature reconvened that autumn, they confirmed Blaine's appointment and elected him to the full six-year term that would begin on March 4, 1877.

Blaine was appointed to the Senate on July 10, 1876, but did not begin his duties there until the Senate convened in December of that year. While in the Senate, he served on the Appropriations Committee and held the chairmanship of the Committee on Civil Service and Retrenchment, but he never achieved the role of leadership that he had held as a member of the House. The Senate in the 45th Congress was controlled by a narrow Republican majority, but it was a majority often divided against itself and against the Hayes administration. Blaine did not number himself among the administration's defenders, but neither could he join the Republicans led by Conkling—later known as the Stalwarts—who opposed Hayes, because of the deep personal enmity between Blaine and Conkling. He opposed Hayes's withdrawal of federal troops from Southern capitals, which effectively ended the Reconstruction of the South, but to no avail. Blaine continued to antagonize Southern Democrats, voting against bills passed in the Democrat-controlled House that would reduce the Army's appropriation and repeal the post-war Enforcement Acts he had helped pass. Such bills passed Congress several times and Hayes vetoed them several times; ultimately, the Enforcement Acts remained in place, but the funds to enforce them dwindled. By 1879, there were only 1,155 soldiers stationed in the former Confederacy, and Blaine believed that this small force could never guarantee the civil and political rights of black Southerners—which would mean an end to the Republican party in the South.

On monetary issues, Blaine continued the advocacy for a strong dollar that he had begun as a Representative. The issue had shifted from debate over greenbacks to debate over which metal should back the dollar: gold and silver, or gold alone. The Coinage Act of 1873 stopped the coinage of silver for all coins worth a dollar or more, effectively tying the dollar to the value of gold. As a result, the money supply contracted and the effects of the Panic of 1873 grew worse, making it more expensive for debtors to pay debts they had entered into when currency was less valuable. Farmers and laborers, especially, clamored for the return of coinage in both metals, believing the increased money supply would restore wages and property values. Democratic Representative Richard P. Bland of Missouri proposed a bill, which passed the House, that required the United States to coin as much silver as miners could sell the government, thus increasing the money supply and aiding debtors. In the Senate, William B. Allison, a Republican from Iowa offered an amendment to limit the silver coinage to two to four million dollars per month. This was still too much for Blaine, and he denounced the bill and the proposed amendment, but the amended Bland–Allison Act passed the Senate by a 48 to 21 vote. Hayes vetoed the bill, but Congress mustered the two-thirds vote to pass it over his veto. Even after the Bland–Allison Act's passage, Blaine continued his opposition, making a series of speeches against it during the 1878 congressional campaign season.

His time in the Senate allowed Blaine to develop his foreign policy ideas. He advocated expansion of the American navy and merchant marine, which had been in decline since the Civil War. Blaine also bitterly opposed the results of the arbitration with Great Britain over American fishermen's right to fish in Canadian waters, which resulted in a $5.5 million award to Britain. Blaine's Anglophobia combined with his support of high tariffs. He had initially opposed a reciprocity treaty with Canada that would have reduced tariffs between the two nations, but by the end of his time in the Senate, he had changed his mind, believing that Americans had more to gain by increasing exports than they would lose by the risk of cheap imports.

Hayes had announced early in his presidency that he would not seek another term, which meant that the contest for the Republican nomination in 1880 was open to all challengers—including Blaine. Blaine was among the early favorites for the nomination, as were former President Grant, Treasury Secretary John Sherman of Ohio, and Senator George F. Edmunds of Vermont. Although Grant did not actively promote his candidacy, his entry into the race re-energized the Stalwarts and when the convention met in Chicago in June 1880, they instantly polarized the delegates into Grant and anti-Grant factions, with Blaine the most popular choice of the latter group. Blaine was nominated by James Frederick Joy of Michigan, but in contrast to Ingersoll's exciting speech of 1876, Joy's lengthy oration was remembered only for its maladroitness. After the other candidates were nominated, the first ballot showed Grant leading with 304 votes and Blaine in second with 284; no other candidate had more than Sherman's 93, and none had the required majority of 379. Sherman's delegates could swing the nomination to either Grant or Blaine, but he refused to release them through twenty-eight ballots in the hope that the anti-Grant forces would desert Blaine and flock to him. Eventually, they did desert Blaine, but instead of Sherman they shifted their votes to Ohio Congressman James A. Garfield, and by the thirty-sixth ballot he had 399 votes, enough for victory.

Garfield placated the Stalwarts by endorsing Chester A. Arthur of New York, a Conkling loyalist, as nominee for vice president, but it was to Blaine and his delegates that Garfield owed his nomination. When Garfield was elected over Democrat Winfield Scott Hancock, he turned to Blaine to guide him in selection of his cabinet and offered him the preeminent position: Secretary of State. Blaine accepted, resigning from the Senate on March 4, 1881.

Blaine saw presiding over the cabinet as a chance to preside over the Washington social scene, as well, and soon ordered construction of a new, larger home near Dupont Circle. Although his foreign policy experience was minimal, Blaine quickly threw himself into his new duties. By 1881, Blaine had completely abandoned his protectionist leanings and now used his position as Secretary of State to promote freer trade, especially within the western hemisphere. His reasons were twofold: firstly, Blaine's old fear of British interference in the Americas was undiminished, and he saw increased trade with Latin America as the best way to keep Britain from dominating the region. Secondly, he believed that by encouraging exports, he could increase American prosperity, and by doing so position the Republican party as the author of that prosperity, ensuring continued electoral success. Garfield agreed with his Secretary of State's vision and Blaine called for a Pan-American conference in 1882 to mediate disputes among the Latin American nations and to serve as a forum for talks on increasing trade. At the same time, Blaine hoped to negotiate a peace in the War of the Pacific then being fought by Bolivia, Chile, and Peru. Blaine favored a resolution that would not result in Peru yielding any territory, but Chile, which had by 1881 occupied the Peruvian capital, rejected any negotiations that would gain them nothing. Blaine sought to expand American influence in other areas, calling for renegotiation of the Clayton–Bulwer Treaty to allow the United States to construct a canal through Panama without British involvement, as well as attempting to reduce British involvement in the strategically located Kingdom of Hawaii. His plans for the United States' involvement in the world stretched even beyond the Western Hemisphere, as he sought commercial treaties with Korea and Madagascar.
On July 2, 1881, Blaine and Garfield were walking through the Sixth Street Station of the Baltimore and Potomac Railroad in Washington when Garfield was shot by an assassin, Charles J. Guiteau. Guiteau, a deranged man who had earlier pestered Blaine and other State Department officials to be appointed to ambassadorships for which he was grossly unqualified, believed that by assassinating the President he could ingratiate himself with Vice President Arthur and receive his coveted position. Guiteau was captured immediately and hanged just short of a year later; he survived longer than Garfield, who lingered for two-and-a-half months, then died on September 19, 1881. Garfield's death was not just a personal tragedy for Blaine; it also meant the end of his dominance of the cabinet and the end of his foreign policy initiatives. With Arthur's ascent to the presidency, the Stalwart faction now held sway and Blaine's days at the State Department were numbered. Arthur asked all of the cabinet members to postpone their resignations until Congress recessed that December; Blaine nonetheless tendered his resignation on October 19, 1881 but agreed to remain in office until December 19, when his successor was in place. Blaine's replacement was Frederick T. Frelinghuysen, a New Jersey Stalwart. Arthur and Frelinghuysen undid much of Blaine's work, cancelling the call for a Pan-American conference and stopping the effort to end the War of the Pacific, but they did continue the drive for tariff reductions, signing a reciprocity treaty with Mexico in 1882.

Blaine began the year 1882 without a political office for the first time since 1859. Troubled by poor health, he sought no employment other than the completion of the first volume of his memoir, "Twenty Years of Congress." Friends in Maine petitioned Blaine to run for Congress in the 1882 elections, but he declined, preferring to spend his time writing and supervising the move to the new home. His income from mining and railroad investments was sufficient to sustain the family's lifestyle and to allow for the construction of a vacation cottage, "Stanwood" on Mount Desert Island, Maine, designed by Frank Furness. Blaine appeared before Congress in 1882 during an investigation into his War of the Pacific diplomacy, defending himself against allegations that he owned an interest in the Peruvian guano deposits being occupied by Chile, but otherwise stayed away from the Capitol. The publication of the first volume of "Twenty Years" in early 1884 added to Blaine's financial security and thrust him back into the political spotlight. As the 1884 campaign loomed, Blaine's name was being circulated once more as a potential nominee, and despite some reservations, he soon found himself back in the hunt for the presidency.

In the months leading up to the 1884 convention, Blaine was once more considered the favorite for the nomination, but President Arthur was contemplating a run for election in his own right. George Edmunds was again the favored candidate among reformers and John Sherman had a few delegates pledged to him, but neither was expected to command much support at the convention. John A. Logan of Illinois hoped to attract Stalwart votes if Arthur's campaign was unsuccessful. Blaine was unsure he wanted to try for the nomination for the third time and even encouraged General William T. Sherman, John Sherman's older brother, to accept it if it came to him, but ultimately Blaine agreed to be a candidate again.

William H. West of Ohio nominated Blaine with an enthusiastic speech and after the first ballot, Blaine led the count with 334½ votes. While short of the necessary 417 for nomination, Blaine had far more than any other candidate with Arthur in second place at 278 votes. Blaine was unacceptable to the Arthur delegates just as Blaine's own delegates would never vote for the President, so the contest was between the two for the delegates of the remaining candidates. Blaine's total steadily increased as Logan and Sherman withdrew in his favor and some of the Edmunds delegates defected to him. Unlike in previous conventions, the momentum for Blaine in 1884 would not be halted. On the fourth ballot, Blaine received 541 votes and was, at last, nominated. Logan was named vice presidential nominee on the first ballot, and the Republicans had their ticket.

The Democrats held their convention in Chicago the following month and nominated Governor Grover Cleveland of New York. Cleveland's time on the national scene was brief, but Democrats hoped that his reputation as a reformer and an opponent of corruption would attract Republicans dissatisfied with Blaine and his reputation for scandal. They were correct, as reform-minded Republicans (called "Mugwumps") denounced Blaine as corrupt and flocked to Cleveland. The Mugwumps, including such men as Carl Schurz and Henry Ward Beecher, were more concerned with morality than with party, and felt Cleveland was a kindred soul who would promote civil service reform and fight for efficiency in government. However, even as the Democrats gained support from the Mugwumps, they lost some blue-collar workers to the Greenback Party, led by Benjamin F. Butler, Blaine's antagonist from their early days in the House.

The campaign focused on the candidates' personalities, as each candidate's supporters cast aspersions on their opponents. Cleveland's supporters rehashed the old allegations from the Mulligan letters that Blaine had corruptly influenced legislation in favor of railroads, later profiting on the sale of bonds he owned in both companies. Although the stories of Blaine's favors to the railroads had made the rounds eight years earlier, this time more of his correspondence was discovered, making his earlier denials less plausible. Blaine acknowledged that the letters were genuine, but denied that anything in them impugned his integrity or contradicted his earlier explanations. Nevertheless, what Blaine described as "stale slander" served to focus the public's attention negatively on his character. On some of the most damaging correspondence, Blaine had written "Burn this letter," giving Democrats the last line to their rallying cry: "Blaine, Blaine, James G. Blaine, the continental liar from the state of Maine, 'Burn this letter!'"

To counter Cleveland's image of superior morality, Republicans discovered reports that Cleveland had fathered an illegitimate child while he was a lawyer in Buffalo, New York, and chanted "Ma, Ma, where's my Pa?"—to which the Democrats, after Cleveland had been elected, appended, "Gone to the White House, Ha! Ha! Ha!" Cleveland admitted to paying child support in 1874 to Maria Crofts Halpin, the woman who claimed he fathered her child named Oscar Folsom Cleveland. Halpin was involved with several men at the time, including Cleveland's friend and law partner, Oscar Folsom, for whom the child was also named. Cleveland did not know which man was the father, and is believed to have assumed responsibility because he was the only bachelor among them. At the same time, Democratic operatives accused Blaine and his wife of not having been married when their eldest son, Stanwood, was born in 1851; this rumor was false, however, and caused little excitement in the campaign.

Both candidates believed that the states of New York, New Jersey, Indiana, and Connecticut would determine the election. In New York, Blaine received less support than he anticipated when Arthur and Conkling, still powerful in the New York Republican party, failed to actively campaign for him. Blaine hoped that he would have more support from Irish Americans than Republicans typically did; while the Irish were mainly a Democratic constituency in the 19th century, Blaine's mother was Irish Catholic, and he believed his career-long opposition to the British government would resonate with the Irish. Blaine's hope for Irish defections to the Republican standard were dashed late in the campaign when one of his supporters, Samuel D. Burchard, gave a speech denouncing the Democrats as the party of "Rum, Romanism, and Rebellion." The Democrats spread the word of this insult in the days before the election, and Cleveland narrowly won all four of the swing states, including New York by just over one thousand votes. While the popular vote total was close, with Cleveland winning by just one-quarter of a percent, the electoral votes gave Cleveland a majority of 219–182.

Blaine accepted his narrow defeat and spent most of the next year working on the second volume of "Twenty Years of Congress." The book continued to earn him enough money to support his lavish household and pay off his debts. Although he spoke to friends of retiring from politics, Blaine still attended dinners and commented on the Cleveland administration's policies. By the time of the 1886 Congressional elections, Blaine was giving speeches and promoting Republican candidates, especially in his home state of Maine. Republicans were successful in Maine, and after the Maine elections in September, Blaine went on a speaking tour from Pennsylvania to Tennessee, hoping to boost the prospects of Republican candidates there. Republicans were less successful nationwide, gaining seats in the House while losing seats in the Senate, but Blaine's speeches kept him and his opinions in the spotlight.

Blaine and his wife and daughters sailed for Europe in June 1887, visiting England, Ireland, Germany, France, Austria-Hungary, and finally Scotland, where they stayed at the summer home of Andrew Carnegie. While in France, Blaine wrote a letter to the "New-York Tribune" criticizing Cleveland's plans to reduce the tariff, saying that free trade with Europe would impoverish American workers and farmers. The family returned to the United States in August 1887. His letter in the "Tribune" had raised his political profile even higher, and by 1888 Theodore Roosevelt and Henry Cabot Lodge, both former opponents, urged Blaine to run against Cleveland again. Opinion within the party was overwhelmingly in favor of renominating Blaine.

As the state conventions drew nearer, Blaine announced that he would not be a candidate. His supporters doubted his sincerity and continued to encourage him to run, but Blaine still demurred. Hoping to make his intentions clear, Blaine left the country and was staying with Carnegie in Scotland when the 1888 Republican National Convention began in Chicago. Carnegie encouraged Blaine to accept if the convention nominated him, but the delegates finally accepted Blaine's refusal. John Sherman was the most prominent candidate and sought to attract the Blaine supporters to his candidacy, but instead found them flocking to former senator Benjamin Harrison of Indiana after a telegram from Carnegie suggested that Blaine favored him. Blaine returned to the United States in August 1888 and visited Harrison at his home in October, where twenty-five thousand residents paraded in Blaine's honor. Harrison defeated Cleveland in a close election, and offered Blaine his former position as Secretary of State.

Harrison had developed his foreign policy based largely on Blaine's ideas, and at the start of his term, Harrison and Blaine had very similar views on the United States' place in the world. In spite of their shared worldview, however, the two men became personally unfriendly as the term went on. Harrison was conscious that his Secretary of State was more popular than he, and while he admired Blaine's gift for diplomacy, he grew displeased with Blaine's frequent absence from his post because of illness, and suspected that Blaine was angling for the presidential nomination in 1892. Harrison tried to limit how many "Blaine men" filled subordinate positions in the State Department and denied Blaine's request that his son, Walker, be appointed First Assistant Secretary, instead naming him Solicitor of the Department of State. Despite the growing personal rancor, the two men continued, with one exception, to agree on the foreign policy questions of the day.

Blaine and Harrison wished to see American power and trade expanded across the Pacific and were especially interested in securing rights to harbors in Pearl Harbor, Hawaii, and Pago Pago, Samoa. When Blaine entered office, the United States, Great Britain, and the German Empire were disputing their respective rights in Samoa. Thomas F. Bayard, Blaine's predecessor, had accepted an invitation to a three-party conference in Berlin aimed at resolving the dispute, and Blaine appointed American representatives to attend. The result was a treaty that created a condominium among the three powers, allowing all of them access to the harbor.

In Hawaii, Blaine worked to bind the kingdom more closely to the United States and to avoid its becoming a British protectorate. When the McKinley Tariff of 1890 eliminated the duty on sugar, Hawaiian sugar-growers looked for a way to retain their once-exclusive access to the American market. The Hawaiian minister to the United States, Henry A. P. Carter, tried to arrange for Hawaii have complete trade reciprocity with the United States, but Blaine proposed instead that Hawaii become an American protectorate; Carter favored the idea, but the Hawaiian king, Kalākaua, rejected the infringement on his sovereignty. Blaine next procured the appointment of his former newspaper colleague John L. Stevens as minister to Hawaii. Stevens had long believed that the United States should annex Hawaii, and as minister he co-operated with Americans living in Hawaii in their efforts to bring about annexation. Their efforts ultimately culminated in a coup d'état against Kalākaua's successor, Liliuokalani, in 1893. Blaine's precise involvement is undocumented, but the results of Stevens' diplomacy were in accord with his ambitions for American power in the region. The new government petitioned the United States for annexation, but by that time Blaine was no longer in office.

Soon after taking office, Blaine revived his old idea of an international conference of western hemisphere nations. The result was the First International Conference of American States, which met in Washington in 1890. Blaine and Harrison had high hopes for the conference, including proposals for a customs union, a pan-American railroad line, and an arbitration process to settle disputes among member nations. Their overall goal was to extend trade and political influence over the entire hemisphere; some of the other nations understood this and were wary of deepening ties with the United States to the exclusion of European powers. Blaine said publicly that his only interest was in "annexation of trade," not annexation of territory, but privately he wrote to Harrison of a desire for some territorial enlargement of the United States:

Congress was not as enthusiastic about a customs union as Blaine and Harrison were, but tariff reciprocity provisions were ultimately included in the McKinley Tariff that reduced duties on some inter-American trade. Otherwise, the conference achieved none of Blaine's goals in the short-term, but did lead to further communication and what would eventually become the Organization of American States.

In 1891, a diplomatic crisis arose in Chile that drove a wedge between Harrison and Blaine. The American minister to Chile, Patrick Egan, a political friend of Blaine's, granted asylum to Chileans who were seeking refuge from the Chilean Civil War. Chile was already suspicious of Blaine because of his War of the Pacific diplomacy ten years earlier, and this incident raised tensions even further. When sailors from the "Baltimore" took shore leave in Valparaíso, a fight broke out, resulting in the deaths of two American sailors and three dozen arrested. When the news reached Washington, Blaine was in Bar Harbor recuperating from a bout of ill health and Harrison himself drafted a demand for reparations. The Chilean foreign minister, Manuel Antonio Matta, replied that Harrison's message was "erroneous or deliberately incorrect" and said that the Chilean government was treating the affair the same as any other criminal matter. Tensions increased as Harrison threatened to break off diplomatic relations unless the United States received a suitable apology. Blaine returned to the capital and made conciliatory overtures to the Chilean government, offering to submit the dispute to arbitration and recall Egan. Harrison still insisted on an apology and submitted a special message to Congress about the threat of war. Chile issued an apology for the incident, and the threat of war subsided.

Blaine's earliest expressions in the foreign policy sphere were those of a reactionary Anglophobe, but by the end of his career his relationship with the United Kingdom had become more moderate and nuanced. A dispute over seal hunting in the waters off Alaska was the cause of Blaine's first interaction with Britain as Harrison's Secretary of State. A law passed in 1889 required Harrison to ban seal hunting in Alaskan waters, but Canadian fishermen believed they had the right to continue fishing there. Soon thereafter, the United States Navy seized several Canadian ships near the Pribilof Islands. Blaine entered into negotiations with Britain and the two nations agreed to submit the dispute to arbitration by a neutral tribunal. Blaine was no longer in office when the tribunal began its work, but the result was to allow the hunting once more, albeit with some regulation, and to require the United States to pay damages of $473,151. Ultimately, the nations signed the North Pacific Fur Seal Convention of 1911, which outlawed open-water seal hunting.

At the same time as the Pribilof Islands dispute, an outbreak of mob violence in New Orleans became an international incident. After New Orleans police chief David Hennessy led a crackdown against local mafiosi, he was assassinated on October 14, 1890. After the alleged murderers were found not guilty on March 14, 1891, a mob stormed the jail and lynched eleven of them. Since many of those killed were Italian citizens the Italian minister, Saverio Fava, protested to Blaine. Blaine explained that federal officials could not control how state officials deal with criminal matters, and Fava announced that he would withdraw the legation back to Italy. Blaine and Harrison believed the Italians' response to be an overreaction, and did nothing. Tensions slowly cooled, and after nearly a year, the Italian minister returned to the United States to negotiate an indemnity. After some internal dispute—Blaine wanted conciliation with Italy, Harrison was reluctant to admit fault—the United States agreed to pay an indemnity of $25,000, and normal diplomatic relations resumed.

Blaine had always believed his health to be fragile, and by the time he joined Harrison's cabinet he truly was unwell. The years at the State Department also brought Blaine personal tragedy as two of his children, Walker and Alice, died suddenly in 1890. Another son, Emmons, died in 1892. With these family issues and his declining health, Blaine decided to retire and announced that he would resign from the cabinet on June 4, 1892. Because of their growing animosity, and because Blaine's resignation came three days before the 1892 Republican National Convention began, Harrison suspected that Blaine was preparing to run against him for the party's nomination for president.

Harrison was unpopular with the party and the country, and many of Blaine's old supporters encouraged him to run for the nomination. Blaine had denied any interest in the nomination months before his resignation, but some of his friends, including Senator Matthew Quay of Pennsylvania and James S. Clarkson, chairman of the Republican National Committee, took it for false modesty and worked for his nomination anyway. When Blaine resigned from the cabinet, his boosters were certain that he was a candidate, but the majority of the party stood by the incumbent. Harrison was renominated on the first ballot, but die-hard Blaine delegates still gave their champion 182 and 1/6 votes, good enough for second place.

Blaine spent the summer of 1892 at his Bar Harbor cottage, and did not involve himself in the presidential campaign other than to make a single speech in New York in October. Harrison was defeated soundly in his rematch against former president Cleveland and when Blaine returned to Washington at the close of 1892, he and Harrison were friendlier than they had been in years. Blaine's health declined rapidly in the winter of 1892–1893, and he died in his Washington home on January 27, 1893. After a funeral at the Presbyterian Church of the Covenant, he was buried in Oak Hill Cemetery in Washington. He was later re-interred in Blaine Memorial Park, Augusta, Maine, in 1920.

A towering figure in the Republican party of his day, Blaine fell into obscurity fairly soon after his death. A 1905 biography by his wife's cousin, Edward Stanwood, was written when the question was still in doubt, but by the time David Saville Muzzey published his biography of Blaine in 1934, the subtitle "A Political Idol of Other Days" already spoke to its subject's fading place in the popular mind, perhaps because of the nine men the Republican Party nominated for the Presidency from 1860 to 1912, Blaine is the only one who never became President. Although several authors studied Blaine's foreign policy career, including Edward P. Crapol's 2000 work, Muzzey's was the last full-scale biography of the man until Neil Rolde's 2006 book. Historian R. Hal Williams was working on a new biography of Blaine, tentatively titled "James G. Blaine: A Life in Politics", until his death in 2016.

Books

Articles



</doc>
<doc id="16425" url="https://en.wikipedia.org/wiki?curid=16425" title="Justus">
Justus

Justus (died on 10 November between 627 and 631) was the fourth Archbishop of Canterbury. He was sent from Italy to England by Pope Gregory the Great, on a mission to Christianize the Anglo-Saxons from their native paganism, probably arriving with the second group of missionaries despatched in 601. Justus became the first Bishop of Rochester in 604, and attended a church council in Paris in 614.

Following the death of King Æthelberht of Kent in 616, Justus was forced to flee to Gaul, but was reinstated in his diocese the following year. In 624 Justus became Archbishop of Canterbury, overseeing the despatch of missionaries to Northumbria. After his death he was revered as a saint, and had a shrine in St Augustine's Abbey, Canterbury.

Justus was a member of the Gregorian mission sent to England by Pope Gregory I. Almost everything known about Justus and his career is derived from the early 8th-century "Historia ecclesiastica gentis Anglorum" of Bede. As Bede does not describe Justus' origins, nothing is known about him prior to his arrival in England. He probably arrived in England with the second group of missionaries, sent at the request of Augustine of Canterbury in 601. Some modern writers describe Justus as one of the original missionaries who arrived with Augustine in 597, but Bede believed that Justus came in the second group. The second group included Mellitus, who later became Bishop of London and Archbishop of Canterbury.

If Justus was a member of the second group of missionaries, then he arrived with a gift of books and "all things which were needed for worship and the ministry of the Church". A 15th-century Canterbury chronicler, Thomas of Elmham, claimed that there were a number of books brought to England by that second group still at Canterbury in his day, although he did not identify them. An investigation of extant Canterbury manuscripts shows that one possible survivor is the St. Augustine Gospels, now in Cambridge, Corpus Christi College, Manuscript (MS) 286.

Augustine consecrated Justus as a bishop in 604, over a province including the Kentish town of Rochester. The historian Nicholas Brooks argues that the choice of Rochester was probably not because it had been a Roman-era bishopric, but rather because of its importance in the politics of the time. Although the town was small, with just one street, it was at the junction of Watling Street and the estuary of the Medway, and was thus a fortified town. Because Justus was probably not a monk (he was not called that by Bede), his cathedral clergy was very likely non-monastic too.

A charter purporting to be from King Æthelberht, dated 28 April 604, survives in the "Textus Roffensis", as well as a copy based on the Textus in the 14th-century "Liber Temporalium". Written mostly in Latin but using an Old English boundary clause, the charter records a grant of land near the city of Rochester to Justus' church. Among the witnesses is Laurence, Augustine's future successor, but not Augustine himself. The text turns to two different addressees. First, Æthelberht is made to admonish his son Eadbald, who had been established as a sub-ruler in the region of Rochester. The grant itself is addressed directly to Saint Andrew, the patron saint of the church, a usage parallelled by other charters in the same archive.

Historian Wilhelm Levison, writing in 1946, was sceptical about the authenticity of this charter. In particular, he felt that the two separate addresses were incongruous and suggested that the first address, occurring before the preamble, may have been inserted by someone familiar with Bede to echo Eadbald's future conversion (see below). A more recent and more positive appraisal by John Morris argues that the charter and its witness list are authentic because it incorporates titles and phraseology that had fallen out of use by 800.

Æthelberht built Justus a cathedral church in Rochester; the foundations of a nave and chancel partly underneath the present-day Rochester Cathedral may date from that time. What remains of the foundations of an early rectangular building near the southern part of the current cathedral might also be contemporary with Justus or may be part of a Roman building.

Together with Mellitus, the Bishop of London, Justus signed a letter written by Archbishop Laurence of Canterbury to the Irish bishops urging the native church to adopt the Roman method of calculating the date of Easter. This letter also mentioned the fact that Irish missionaries, such as Dagan, had refused to share meals with the missionaries. Although the letter has not survived, Bede quoted from parts of it.

In 614, Justus attended the Council of Paris, held by the Frankish king, Chlothar II. It is unclear why Justus and Peter, the abbot of Sts Peter and Paul in Canterbury, were present. It may have been just chance, but historian James Campbell has suggested that Chlothar summoned clergy from Britain to attend in an attempt to assert overlordship over Kent. The historian N. J. Higham offers another explanation for their attendance, arguing that Æthelberht sent the pair to the council because of shifts in Frankish policy towards the Kentish kingdom, which threatened Kentish independence, and that the two clergymen were sent to negotiate a compromise with Chlothar.

A pagan backlash against Christianity followed Æthelberht's death in 616, forcing Justus and Mellitus to flee to Gaul. The pair probably took refuge with Chlothar, hoping that the Frankish king would intervene and restore them to their sees, and by 617 Justus had been reinstalled in his bishopric by the new king. Mellitus also returned to England, but the prevailing pagan mood did not allow him to return to London; after Laurence's death, Mellitus became Archbishop of Canterbury. According to Bede, Justus received letters of encouragement from Pope Boniface V (619–625), as did Mellitus, although Bede does not record the actual letters. The historian J. M. Wallace-Hadrill assumes that both letters were general statements of encouragement to the missionaries.

Justus became Archbishop of Canterbury in 624, receiving his pallium—the symbol of the jurisdiction entrusted to archbishops—from Pope Boniface V, following which Justus consecrated Romanus as his successor at Rochester. Boniface also gave Justus a letter congratulating him on the conversion of King "Aduluald" (probably King Eadbald of Kent), a letter which is included in Bede's "Historia ecclesiastica gentis Anglorum". Bede's account of Eadbald's conversion states that it was Laurence, Justus' predecessor at Canterbury, who converted the King to Christianity, but the historian D. P. Kirby argues that the letter's reference to Eadbald makes it likely that it was Justus. Other historians, including Barbara Yorke and Henry Mayr-Harting, conclude that Bede's account is correct, and that Eadbald was converted by Laurence. Yorke argues that there were two kings of Kent during Eadbald's reign, Eadbald and Æthelwald, and that Æthelwald was the "Aduluald" referred to by Boniface. Yorke argues that Justus converted Æthelwald back to Christianity after Æthelberht's death.

Justus consecrated Paulinus as the first Bishop of York, before the latter accompanied Æthelburg of Kent to Northumbria for her marriage to King Edwin of Northumbria. Bede records Justus as having died on 10 November, but does not give a year, although it is likely to have between 627 and 631. After his death, Justus was regarded as a saint, and was given a feast day of 10 November. The ninth century Stowe Missal commemorates his feast day, along with Mellitus and Laurence. In the 1090s, his remains were translated, or ritually moved, to a shrine beside the high altar of St Augustine's Abbey in Canterbury. At about the same time, a "Life" was written about him by Goscelin of Saint-Bertin, as well as a poem by Reginald of Canterbury. Other material from Thomas of Elmham, Gervase of Canterbury, and William of Malmesbury, later medieval chroniclers, adds little to Bede's account of Justus' life.


</doc>
<doc id="16550" url="https://en.wikipedia.org/wiki?curid=16550" title="John, King of England">
John, King of England

John (24 December 1166 – 19 October 1216), also known as John Lackland, was King of England from 1199 until his death in 1216. John lost the Duchy of Normandy and most of his other French lands to King Philip II of France, resulting in the collapse of the Angevin Empire and contributing to the subsequent growth in power of the French Capetian dynasty during the 13th century. The baronial revolt at the end of John's reign led to the sealing of ", a document sometimes considered an early step in the evolution of the constitution of the United Kingdom.

John, the youngest of five sons of King Henry II of England and Duchess Eleanor of Aquitaine, was at first not expected to inherit significant lands. Following the failed rebellion of his elder brothers between 1173 and 1174, however, John became Henry's favourite child. He was appointed the Lord of Ireland in 1177 and given lands in England and on the continent. John's elder brothers William, Henry and Geoffrey died young; by the time Richard I became king in 1189, John was a potential heir to the throne. John unsuccessfully attempted a rebellion against Richard's royal administrators whilst his brother was participating in the Third Crusade. Despite this, after Richard died in 1199, John was proclaimed King of England, and came to an agreement with Philip II of France to recognise John's possession of the continental Angevin lands at the peace treaty of Le Goulet in 1200.

When war with France broke out again in 1202, John achieved early victories, but shortages of military resources and his treatment of Norman, Breton, and Anjou nobles resulted in the collapse of his empire in northern France in 1204. John spent much of the next decade attempting to regain these lands, raising huge revenues, reforming his armed forces and rebuilding continental alliances. John's judicial reforms had a lasting effect on the English common law system, as well as providing an additional source of revenue. An argument with Pope Innocent III led to John's excommunication in 1209, a dispute finally settled by the king in 1213. John's attempt to defeat Philip in 1214 failed due to the French victory over John's allies at the battle of Bouvines. When he returned to England, John faced a rebellion by many of his barons, who were unhappy with his fiscal policies and his treatment of many of England's most powerful nobles. Although both John and the barons agreed to the " peace treaty in 1215, neither side complied with its conditions. Civil war broke out shortly afterwards, with the barons aided by Louis of France. It soon descended into a stalemate. John died of dysentery contracted whilst on campaign in eastern England during late 1216; supporters of his son Henry III went on to achieve victory over Louis and the rebel barons the following year.

Contemporary chroniclers were mostly critical of John's performance as king, and his reign has since been the subject of significant debate and periodic revision by historians from the 16th century onwards. Historian Jim Bradbury has summarised the current historical opinion of John's positive qualities, observing that John is today usually considered a "hard-working administrator, an able man, an able general". Nonetheless, modern historians agree that he also had many faults as king, including what historian Ralph Turner describes as "distasteful, even dangerous personality traits", such as pettiness, spitefulness, and cruelty. These negative qualities provided extensive material for fiction writers in the Victorian era, and John remains a recurring character within Western popular culture, primarily as a villain in films and stories depicting the Robin Hood legends.

John was born to Henry II of England and Eleanor of Aquitaine on 24 December 1166. Henry had inherited significant territories along the Atlantic seaboard—Anjou, Normandy and England—and expanded his empire by conquering Brittany. Henry married the powerful Eleanor of Aquitaine, who reigned over the Duchy of Aquitaine and had a tenuous claim to Toulouse and Auvergne in southern France, in addition to being the former wife of Louis VII of France. The result was the Angevin Empire, named after Henry's paternal title as Count of Anjou and, more specifically, its seat in Angers. The Empire, however, was inherently fragile: although all the lands owed allegiance to Henry, the disparate parts each had their own histories, traditions and governance structures. As one moved south through Anjou and Aquitaine, the extent of Henry's power in the provinces diminished considerably, scarcely resembling the modern concept of an empire at all. Some of the traditional ties between parts of the empire such as Normandy and England were slowly dissolving over time. It was unclear what would happen to the empire on Henry's death. Although the custom of primogeniture, under which an eldest son would inherit all his father's lands, was slowly becoming more widespread across Europe, it was less popular amongst the Norman kings of England. Most believed that Henry would divide the empire, giving each son a substantial portion, and hoping that his children would continue to work together as allies after his death. To complicate matters, much of the Angevin empire was held by Henry only as a vassal of the King of France of the rival line of the House of Capet. Henry had often allied himself with the Holy Roman Emperor against France, making the feudal relationship even more challenging.

Shortly after his birth, John was passed from Eleanor into the care of a wet nurse, a traditional practice for medieval noble families. Eleanor then left for Poitiers, the capital of Aquitaine, and sent John and his sister Joan north to Fontevrault Abbey. This may have been done with the aim of steering her youngest son, with no obvious inheritance, towards a future ecclesiastical career. Eleanor spent the next few years conspiring against her husband Henry and neither parent played a part in John's very early life. John was probably, like his brothers, assigned a "magister" whilst he was at Fontevrault, a teacher charged with his early education and with managing the servants of his immediate household; John was later taught by Ranulf de Glanvill, a leading English administrator. John spent some time as a member of the household of his eldest living brother Henry the Young King, where he probably received instruction in hunting and military skills.

John grew up to be around tall, relatively short, with a "powerful, barrel-chested body" and dark red hair; he looked to contemporaries like an inhabitant of Poitou. John enjoyed reading and, unusually for the period, built up a travelling library of books. He enjoyed gambling, in particular at backgammon, and was an enthusiastic hunter, even by medieval standards. He liked music, although not songs. John would become a "connoisseur of jewels", building up a large collection, and became famous for his opulent clothes and also, according to French chroniclers, for his fondness for bad wine. As John grew up, he became known for sometimes being "genial, witty, generous and hospitable"; at other moments, he could be jealous, over-sensitive and prone to fits of rage, "biting and gnawing his fingers" in anger.

During John's early years, Henry attempted to resolve the question of his succession. Henry the Young King had been crowned King of England in 1170, but was not given any formal powers by his father; he was also promised Normandy and Anjou as part of his future inheritance. Richard was to be appointed the Count of Poitou with control of Aquitaine, whilst Geoffrey was to become the Duke of Brittany. At this time it seemed unlikely that John would ever inherit substantial lands, and he was jokingly nicknamed "Lackland" by his father.

Henry II wanted to secure the southern borders of Aquitaine and decided to betroth his youngest son to Alais, the daughter and heiress of Humbert III of Savoy. As part of this agreement John was promised the future inheritance of Savoy, Piedmont, Maurienne, and the other possessions of Count Humbert. For his part in the potential marriage alliance, Henry II transferred the castles of Chinon, Loudun and Mirebeau into John's name; as John was only five years old his father would continue to control them for practical purposes. Henry the Young King was unimpressed by this; although he had yet to be granted control of any castles in his new kingdom, these were effectively his future property and had been given away without consultation. Alais made the trip over the Alps and joined Henry II's court, but she died before marrying John, which left the prince once again without an inheritance.

In 1173 John's elder brothers, backed by Eleanor, rose in revolt against Henry in the short-lived rebellion of 1173 to 1174. Growing irritated with his subordinate position to Henry II and increasingly worried that John might be given additional lands and castles at his expense, Henry the Young King travelled to Paris and allied himself with Louis VII. Eleanor, irritated by her husband's persistent interference in Aquitaine, encouraged Richard and Geoffrey to join their brother Henry in Paris. Henry II triumphed over the coalition of his sons, but was generous to them in the peace settlement agreed at Montlouis. Henry the Young King was allowed to travel widely in Europe with his own household of knights, Richard was given Aquitaine back, and Geoffrey was allowed to return to Brittany; only Eleanor was imprisoned for her role in the revolt.

John had spent the conflict travelling alongside his father, and was given widespread possessions across the Angevin empire as part of the Montlouis settlement; from then onwards, most observers regarded John as Henry II's favourite child, although he was the furthest removed in terms of the royal succession. Henry II began to find more lands for John, mostly at various nobles' expense. In 1175 he appropriated the estates of the late Earl of Cornwall and gave them to John. The following year, Henry disinherited the sisters of Isabelle of Gloucester, contrary to legal custom, and betrothed John to the now extremely wealthy Isabelle. In 1177, at the Council of Oxford, Henry dismissed William FitzAldelm as the Lord of Ireland and replaced him with the ten-year-old John.
Henry the Young King fought a short war with his brother Richard in 1183 over the status of England, Normandy and Aquitaine. Henry II moved in support of Richard, and Henry the Young King died from dysentery at the end of the campaign. With his primary heir dead, Henry rearranged the plans for the succession: Richard was to be made King of England, albeit without any actual power until the death of his father; Geoffrey would retain Brittany; and John would now become the Duke of Aquitaine in place of Richard. Richard refused to give up Aquitaine; Henry II was furious and ordered John, with help from Geoffrey, to march south and retake the duchy by force. The two attacked the capital of Poitiers, and Richard responded by attacking Brittany. The war ended in stalemate and a tense family reconciliation in England at the end of 1184.

In 1185 John made his first visit to Ireland, accompanied by 300 knights and a team of administrators. Henry had tried to have John officially proclaimed King of Ireland, but Pope Lucius III would not agree. John's first period of rule in Ireland was not a success. Ireland had only recently been conquered by Anglo-Norman forces, and tensions were still rife between Henry II, the new settlers and the existing inhabitants. John infamously offended the local Irish rulers by making fun of their unfashionable long beards, failed to make allies amongst the Anglo-Norman settlers, began to lose ground militarily against the Irish and finally returned to England later in the year, blaming the viceroy, Hugh de Lacy, for the fiasco.

The problems amongst John's wider family continued to grow. His elder brother Geoffrey died during a tournament in 1186, leaving a posthumous son, Arthur of Brittany, and an elder daughter, Eleanor. Geoffrey's death brought John slightly closer to the throne of England. The uncertainty about what would happen after Henry's death continued to grow; Richard was keen to join a new crusade and remained concerned that whilst he was away Henry would appoint John his formal successor.

Richard began discussions about a potential alliance with Philip II in Paris during 1187, and the next year Richard gave homage to Philip in exchange for support for a war against Henry. Richard and Philip fought a joint campaign against Henry, and by the summer of 1189 the king made peace, promising Richard the succession. John initially remained loyal to his father, but changed sides once it appeared that Richard would win. Henry died shortly afterwards.

When John's elder brother Richard became king in September 1189, he had already declared his intention of joining the Third Crusade. Richard set about raising the huge sums of money required for this expedition through the sale of lands, titles and appointments, and attempted to ensure that he would not face a revolt while away from his empire. John was made Count of Mortain, was married to the wealthy Isabel of Gloucester, and was given valuable lands in Lancaster and the counties of Cornwall, Derby, Devon, Dorset, Nottingham and Somerset, all with the aim of buying his loyalty to Richard whilst the king was on crusade. Richard retained royal control of key castles in these counties, thereby preventing John from accumulating too much military and political power, and, for the time being, the king named the four-year-old Arthur of Brittany as the heir to the throne. In return, John promised not to visit England for the next three years, thereby in theory giving Richard adequate time to conduct a successful crusade and return from the Levant without fear of John seizing power. Richard left political authority in England – the post of justiciar – jointly in the hands of Bishop Hugh de Puiset and William Mandeville, and made William Longchamp, the Bishop of Ely, his chancellor. Mandeville immediately died, and Longchamp took over as joint justiciar with Puiset, which would prove a less than satisfactory partnership. Eleanor, the queen mother, convinced Richard to allow John into England in his absence.

The political situation in England rapidly began to deteriorate. Longchamp refused to work with Puiset and became unpopular with the English nobility and clergy. John exploited this unpopularity to set himself up as an alternative ruler with his own royal court, complete with his own justiciar, chancellor and other royal posts, and was happy to be portrayed as an alternative regent, and possibly the next king. Armed conflict broke out between John and Longchamp, and by October 1191 Longchamp was isolated in the Tower of London with John in control of the city of London, thanks to promises John had made to the citizens in return for recognition as Richard's heir presumptive. At this point Walter of Coutances, the Archbishop of Rouen, returned to England, having been sent by Richard to restore order. John's position was undermined by Walter's relative popularity and by the news that Richard had married whilst in Cyprus, which presented the possibility that Richard would have legitimate children and heirs.
The political turmoil continued. John began to explore an alliance with the French king Philip II, freshly returned from the crusade. John hoped to acquire Normandy, Anjou and the other lands in France held by Richard in exchange for allying himself with Philip. John was persuaded not to pursue an alliance by his mother. Longchamp, who had left England after Walter's intervention, now returned, and argued that he had been wrongly removed as justiciar. John intervened, suppressing Longchamp's claims in return for promises of support from the royal administration, including a reaffirmation of his position as heir to the throne. When Richard still did not return from the crusade, John began to assert that his brother was dead or otherwise permanently lost. Richard had in fact been captured en route to England by the Duke of Austria and was handed over to Emperor Henry VI, who held him for ransom. John seized the opportunity and went to Paris, where he formed an alliance with Philip. He agreed to set aside his wife, Isabella of Gloucester, and marry Philip's sister, Alys, in exchange for Philip's support. Fighting broke out in England between forces loyal to Richard and those being gathered by John. John's military position was weak and he agreed to a truce; in early 1194 the king finally returned to England, and John's remaining forces surrendered. John retreated to Normandy, where Richard finally found him later that year. Richard declared that his younger brother – despite being 27 years old – was merely "a child who has had evil counsellors" and forgave him, but removed his lands with the exception of Ireland.

For the remaining years of Richard's reign, John supported his brother on the continent, apparently loyally. Richard's policy on the continent was to attempt to regain through steady, limited campaigns the castles he had lost to Philip II whilst on crusade. He allied himself with the leaders of Flanders, Boulogne and the Holy Roman Empire to apply pressure on Philip from Germany. In 1195 John successfully conducted a sudden attack and siege of Évreux castle, and subsequently managed the defences of Normandy against Philip. The following year, John seized the town of Gamaches and led a raiding party within of Paris, capturing the Bishop of Beauvais. In return for this service, Richard withdrew his "malevolentia" (ill-will) towards John, restored him to the county of Gloucestershire and made him again the Count of Mortain.

After Richard's death on 6 April 1199 there were two potential claimants to the Angevin throne: John, whose claim rested on being the sole surviving son of Henry II, and young Arthur I of Brittany, who held a claim as the son of John's elder brother Geoffrey. Richard appears to have started to recognise John as his heir presumptive in the final years before his death, but the matter was not clear-cut and medieval law gave little guidance as to how the competing claims should be decided. With Norman law favouring John as the only surviving son of Henry II and Angevin law favouring Arthur as the only son of Henry's elder son, the matter rapidly became an open conflict. John was supported by the bulk of the English and Norman nobility and was crowned at Westminster Abbey, backed by his mother, Eleanor. Arthur was supported by the majority of the Breton, Maine and Anjou nobles and received the support of Philip II, who remained committed to breaking up the Angevin territories on the continent. With Arthur's army pressing up the Loire valley towards Angers and Philip's forces moving down the valley towards Tours, John's continental empire was in danger of being cut in two.

Warfare in Normandy at the time was shaped by the defensive potential of castles and the increasing costs of conducting campaigns. The Norman frontiers had limited natural defences but were heavily reinforced with castles, such as Château Gaillard, at strategic points, built and maintained at considerable expense. It was difficult for a commander to advance far into fresh territory without having secured his lines of communication by capturing these fortifications, which slowed the progress of any attack. Armies of the period could be formed from either feudal or mercenary forces. Feudal levies could only be raised for a fixed length of time before they returned home, forcing an end to a campaign; mercenary forces, often called Brabançons after the Duchy of Brabant but actually recruited from across northern Europe, could operate all year long and provide a commander with more strategic options to pursue a campaign, but cost much more than equivalent feudal forces. As a result, commanders of the period were increasingly drawing on larger numbers of mercenaries.

After his coronation, John moved south into France with military forces and adopted a defensive posture along the eastern and southern Normandy borders. Both sides paused for desultory negotiations before the war recommenced; John's position was now stronger, thanks to confirmation that the counts Baldwin IX of Flanders and Renaud of Boulogne had renewed the anti-French alliances they had previously agreed to with Richard. The powerful Anjou nobleman William des Roches was persuaded to switch sides from Arthur to John; suddenly the balance seemed to be tipping away from Philip and Arthur in favour of John. Neither side was keen to continue the conflict, and following a papal truce the two leaders met in January 1200 to negotiate possible terms for peace. From John's perspective, what then followed represented an opportunity to stabilise control over his continental possessions and produce a lasting peace with Philip in Paris. John and Philip negotiated the May 1200 Treaty of Le Goulet; by this treaty, Philip recognised John as the rightful heir to Richard in respect to his French possessions, temporarily abandoning the wider claims of his client, Arthur. John, in turn, abandoned Richard's former policy of containing Philip through alliances with Flanders and Boulogne, and accepted Philip's right as the legitimate feudal overlord of John's lands in France. John's policy earned him the disrespectful title of "John Softsword" from some English chroniclers, who contrasted his behaviour with his more aggressive brother, Richard.

The new peace would only last for two years; war recommenced in the aftermath of John's decision in August 1200 to marry Isabella of Angoulême. In order to remarry, John first needed to abandon Isabella, Countess of Gloucester, his first wife; John accomplished this by arguing that he had failed to get the necessary papal permission to marry Isabel in the first place – as a cousin, John could not have legally wed her without this. It remains unclear why John chose to marry Isabella of Angoulême. Contemporary chroniclers argued that John had fallen deeply in love with Isabella of Angoulême, and John may have been motivated by desire for an apparently beautiful, if rather young, girl. On the other hand, the Angoumois lands that came with her were strategically vital to John: by marrying Isabella, John was acquiring a key land route between Poitou and Gascony, which significantly strengthened his grip on Aquitaine.

Isabella, however, was already engaged to Hugh of Lusignan, an important member of a key Poitou noble family and brother of Count Raoul of Eu, who possessed lands along the sensitive eastern Normandy border. Just as John stood to benefit strategically from marrying Isabella, so the marriage threatened the interests of the Lusignans, whose own lands currently provided the key route for royal goods and troops across Aquitaine. Rather than negotiating some form of compensation, John treated Hugh "with contempt"; this resulted in a Lusignan uprising that was promptly crushed by John, who also intervened to suppress Raoul in Normandy.

Although John was the Count of Poitou and therefore the rightful feudal lord over the Lusignans, they could legitimately appeal John's actions in France to his own feudal lord, Philip. Hugh did exactly this in 1201 and Philip summoned John to attend court in Paris in 1202, citing the Le Goulet treaty to strengthen his case. John was unwilling to weaken his authority in western France in this way. He argued that he need not attend Philip's court because of his special status as the Duke of Normandy, who was exempt by feudal tradition from being called to the French court. Philip argued that he was summoning John not as the Duke of Normandy, but as the Count of Poitou, which carried no such special status. When John still refused to come, Philip declared John in breach of his feudal responsibilities, reassigned all of John's lands that fell under the French crown to Arthur – with the exception of Normandy, which he took back for himself – and began a fresh war against John.

John initially adopted a defensive posture similar to that of 1199: avoiding open battle and carefully defending his key castles. John's operations became more chaotic as the campaign progressed, and Philip began to make steady progress in the east. John became aware in July that Arthur's forces were threatening his mother, Eleanor, at Mirebeau Castle. Accompanied by William de Roches, his seneschal in Anjou, he swung his mercenary army rapidly south to protect her. His forces caught Arthur by surprise and captured the entire rebel leadership at the battle of Mirebeau. With his southern flank weakening, Philip was forced to withdraw in the east and turn south himself to contain John's army.

John's position in France was considerably strengthened by the victory at Mirebeau, but John's treatment of his new prisoners and of his ally, William de Roches, quickly undermined these gains. De Roches was a powerful Anjou noble, but John largely ignored him, causing considerable offence, whilst the king kept the rebel leaders in such bad conditions that twenty-two of them died. At this time most of the regional nobility were closely linked through kinship, and this behaviour towards their relatives was regarded as unacceptable. William de Roches and other of John's regional allies in Anjou and Brittany deserted him in favour of Philip, and Brittany rose in fresh revolt. John's financial situation was tenuous: once factors such as the comparative military costs of materiel and soldiers were taken into account, Philip enjoyed a considerable, although not overwhelming, advantage of resources over John.

Further desertions of John's local allies at the beginning of 1203 steadily reduced John's freedom to manoeuvre in the region. He attempted to convince Pope Innocent III to intervene in the conflict, but Innocent's efforts were unsuccessful. As the situation became worse for John, he appears to have decided to have Arthur killed, with the aim of removing his potential rival and of undermining the rebel movement in Brittany. Arthur had initially been imprisoned at Falaise and was then moved to Rouen. After this, Arthur's fate remains uncertain, but modern historians believe he was murdered by John. The annals of Margam Abbey suggest that "John had captured Arthur and kept him alive in prison for some time in the castle of Rouen ... when John was drunk he slew Arthur with his own hand and tying a heavy stone to the body cast it into the Seine." Rumours of the manner of Arthur's death further reduced support for John across the region. Arthur's sister, Eleanor, who had also been captured at Mirebeau, was kept imprisoned by John for many years, albeit in relatively good conditions.
In late 1203, John attempted to relieve Château Gaillard, which although besieged by Philip was guarding the eastern flank of Normandy. John attempted a synchronised operation involving land-based and water-borne forces, considered by most historians today to have been imaginative in conception, but overly complex for forces of the period to have carried out successfully. John's relief operation was blocked by Philip's forces, and John turned back to Brittany in an attempt to draw Philip away from eastern Normandy. John successfully devastated much of Brittany, but did not deflect Philip's main thrust into the east of Normandy. Opinions vary amongst historians as to the military skill shown by John during this campaign, with most recent historians arguing that his performance was passable, although not impressive.
John's situation began to deteriorate rapidly. The eastern border region of Normandy had been extensively cultivated by Philip and his predecessors for several years, whilst Angevin authority in the south had been undermined by Richard's giving away of various key castles some years before. His use of "routier" mercenaries in the central regions had rapidly eaten away his remaining support in this area too, which set the stage for a sudden collapse of Angevin power. John retreated back across the Channel in December, sending orders for the establishment of a fresh defensive line to the west of Chateau Gaillard. In March 1204, Gaillard fell. John's mother Eleanor died the following month. This was not just a personal blow for John, but threatened to unravel the widespread Angevin alliances across the far south of France. Philip moved south around the new defensive line and struck upwards at the heart of the Duchy, now facing little resistance. By August, Philip had taken Normandy and advanced south to occupy Anjou and Poitou as well. John's only remaining possession on the Continent was now the Duchy of Aquitaine.

The nature of government under the Angevin monarchs was ill-defined and uncertain. John's predecessors had ruled using the principle of "vis et voluntas", or "force and will", taking executive and sometimes arbitrary decisions, often justified on the basis that a king was above the law. Both Henry II and Richard had argued that kings possessed a quality of "divine majesty"; John continued this trend and claimed an "almost imperial status" for himself as ruler. During the 12th century, there were contrary opinions expressed about the nature of kingship, and many contemporary writers believed that monarchs should rule in accordance with the custom and the law, and take counsel of the leading members of the realm. There was as yet no model for what should happen if a king refused to do so. Despite his claim to unique authority within England, John would sometimes justify his actions on the basis that he had taken council with the barons. Modern historians remain divided as to whether John suffered from a case of "royal schizophrenia" in his approach to government, or if his actions merely reflected the complex model of Angevin kingship in the early 13th century.

John inherited a sophisticated system of administration in England, with a range of royal agents answering to the Royal Household: the Chancery kept written records and communications; the Treasury and the Exchequer dealt with income and expenditure respectively; and various judges were deployed to deliver justice around the kingdom. Thanks to the efforts of men like Hubert Walter, this trend towards improved record keeping continued into his reign. Like previous kings, John managed a peripatetic court that travelled around the kingdom, dealing with both local and national matters as he went. John was very active in the administration of England and was involved in every aspect of government. In part he was following in the tradition of Henry I and Henry II, but by the 13th century the volume of administrative work had greatly increased, which put much more pressure on a king who wished to rule in this style. John was in England for much longer periods than his predecessors, which made his rule more personal than that of previous kings, particularly in previously ignored areas such as the north.

The administration of justice was of particular importance to John. Several new processes had been introduced to English law under Henry II, including "novel disseisin" and "mort d'ancestor". These processes meant the royal courts had a more significant role in local law cases, which had previously been dealt with only by regional or local lords. John increased the professionalism of local sergeants and bailiffs, and extended the system of coroners first introduced by Hubert Walter in 1194, creating a new class of borough coroners. John worked extremely hard to ensure that this system operated well, through judges he had appointed, by fostering legal specialists and expertise, and by intervening in cases himself. John continued to try relatively minor cases, even during military crises. Viewed positively, Lewis Warren considers that John discharged "his royal duty of providing justice ... with a zeal and a tirelessness to which the English common law is greatly endebted". Seen more critically, John may have been motivated by the potential of the royal legal process to raise fees, rather than a desire to deliver simple justice; John's legal system also only applied to free men, rather than to all of the population. Nonetheless, these changes were popular with many free tenants, who acquired a more reliable legal system that could bypass the barons, against whom such cases were often brought. John's reforms were less popular with the barons themselves, especially as they remained subject to arbitrary and frequently vindictive royal justice.

One of John's principal challenges was acquiring the large sums of money needed for his proposed campaigns to reclaim Normandy. The Angevin kings had three main sources of income available to them, namely revenue from their personal lands, or "demesne"; money raised through their rights as a feudal lord; and revenue from taxation. Revenue from the royal demesne was inflexible and had been diminishing slowly since the Norman conquest. Matters were not helped by Richard's sale of many royal properties in 1189, and taxation played a much smaller role in royal income than in later centuries. English kings had widespread feudal rights which could be used to generate income, including the scutage system, in which feudal military service was avoided by a cash payment to the king. He derived income from fines, court fees and the sale of charters and other privileges. John intensified his efforts to maximise all possible sources of income, to the extent that he has been described as "avaricious, miserly, extortionate and moneyminded". John also used revenue generation as a way of exerting political control over the barons: debts owed to the crown by the king's favoured supporters might be forgiven; collection of those owed by enemies was more stringently enforced.
The result was a sequence of innovative but unpopular financial measures. John levied scutage payments eleven times in his seventeen years as king, as compared to eleven times in total during the reign of the preceding three monarchs. In many cases these were levied in the absence of any actual military campaign, which ran counter to the original idea that scutage was an alternative to actual military service. John maximised his right to demand relief payments when estates and castles were inherited, sometimes charging enormous sums, beyond barons' abilities to pay. Building on the successful sale of sheriff appointments in 1194, John initiated a new round of appointments, with the new incumbents making back their investment through increased fines and penalties, particularly in the forests. Another innovation of Richard's, increased charges levied on widows who wished to remain single, was expanded under John. John continued to sell charters for new towns, including the planned town of Liverpool, and charters were sold for markets across the kingdom and in Gascony. The king introduced new taxes and extended existing ones. The Jews, who held a vulnerable position in medieval England, protected only by the king, were subject to huge taxes; £44,000 was extracted from the community by the tallage of 1210; much of it was passed on to the Christian debtors of Jewish moneylenders. John created a new tax on income and movable goods in 1207 – effectively a version of a modern income tax – that produced £60,000; he created a new set of import and export duties payable directly to the crown. John found that these measures enabled him to raise further resources through the confiscation of the lands of barons who could not pay or refused to pay.

At the start of John's reign there was a sudden change in prices, as bad harvests and high demand for food resulted in much higher prices for grain and animals. This inflationary pressure was to continue for the rest of the 13th century and had long-term economic consequences for England. The resulting social pressures were complicated by bursts of deflation that resulted from John's military campaigns. It was usual at the time for the king to collect taxes in silver, which was then re-minted into new coins; these coins would then be put in barrels and sent to royal castles around the country, to be used to hire mercenaries or to meet other costs. At those times when John was preparing for campaigns in Normandy, for example, huge quantities of silver had to be withdrawn from the economy and stored for months, which unintentionally resulted in periods during which silver coins were simply hard to come by, commercial credit difficult to acquire and deflationary pressure placed on the economy. The result was political unrest across the country. John attempted to address some of the problems with the English currency in 1204 and 1205 by carrying out a radical overhaul of the coinage, improving its quality and consistency.

John's royal household was based around several groups of followers. One group was the "familiares regis", John's immediate friends and knights who travelled around the country with him. They also played an important role in organising and leading military campaigns. Another section of royal followers were the "curia regis"; these "curiales" were the senior officials and agents of the king and were essential to his day-to-day rule. Being a member of these inner circles brought huge advantages, as it was easier to gain favours from the king, file lawsuits, marry a wealthy heiress or have one's debts remitted. By the time of Henry II, these posts were increasingly being filled by "new men" from outside the normal ranks of the barons. This intensified under John's rule, with many lesser nobles arriving from the continent to take up positions at court; many were mercenary leaders from Poitou. These men included soldiers who would become infamous in England for their uncivilised behaviour, including Falkes de Breauté, Geard d'Athies, Engelard de Cigongé, and Philip Marc. Many barons perceived the king's household as what Ralph Turner has characterised as a "narrow clique enjoying royal favour at barons' expense" staffed by men of lesser status.

This trend for the king to rely on his own men at the expense of the barons was exacerbated by the tradition of Angevin royal "ira et malevolentia" – "anger and ill-will" – and John's own personality. From Henry II onwards, "ira et malevolentia" had come to describe the right of the king to express his anger and displeasure at particular barons or clergy, building on the Norman concept of "malevoncia" – royal ill-will. In the Norman period, suffering the king's ill-will meant difficulties in obtaining grants, honours or petitions; Henry II had infamously expressed his fury and ill-will towards Thomas Becket, which ultimately resulted in Becket's death. John now had the additional ability to "cripple his vassals" on a significant scale using his new economic and judicial measures, which made the threat of royal anger all the more serious.

John was deeply suspicious of the barons, particularly those with sufficient power and wealth to potentially challenge the king. Numerous barons were subjected to John's "malevolentia", even including William Marshal, a famous knight and baron normally held up as a model of utter loyalty. The most infamous case, which went beyond anything considered acceptable at the time, was that of William de Braose, a powerful marcher lord with lands in Ireland. De Braose was subjected to punitive demands for money, and when he refused to pay a huge sum of 40,000 marks (equivalent to £26,666 at the time), his wife and one of his sons were imprisoned by John, which resulted in their deaths. De Braose died in exile in 1211, and his grandsons remained in prison until 1218. John's suspicions and jealousies meant that he rarely enjoyed good relationships with even the leading loyalist barons.

John's personal life greatly affected his reign. Contemporary chroniclers state that John was sinfully lustful and lacking in piety. It was common for kings and nobles of the period to keep mistresses, but chroniclers complained that John's mistresses were married noblewomen, which was considered unacceptable. John had at least five children with mistresses during his first marriage to Isabelle of Gloucester, and two of those mistresses are known to have been noblewomen. John's behaviour after his second marriage to Isabella of Angoulême is less clear, however. None of John's known illegitimate children were born after he remarried, and there is no actual documentary proof of adultery after that point, although John certainly had female friends amongst the court throughout the period. The specific accusations made against John during the baronial revolts are now generally considered to have been invented for the purposes of justifying the revolt; nonetheless, most of John's contemporaries seem to have held a poor opinion of his sexual behaviour.

The character of John's relationship with his second wife, Isabella of Angoulême, is unclear. John married Isabella whilst she was relatively young – her exact date of birth is uncertain, and estimates place her between at most 15 and more probably towards nine years old at the time of her marriage. Even by the standards of the time, Isabella was married whilst very young. John did not provide a great deal of money for his wife's household and did not pass on much of the revenue from her lands, to the extent that historian Nicholas Vincent has described him as being "downright mean" towards Isabella. Vincent concluded that the marriage was not a particularly "amicable" one. Other aspects of their marriage suggest a closer, more positive relationship. Chroniclers recorded that John had a "mad infatuation" with Isabella, and certainly John had conjugal relationships with Isabella between at least 1207 and 1215; they had five children. In contrast to Vincent, historian William Chester Jordan concludes that the pair were a "companionable couple" who had a successful marriage by the standards of the day.

John's lack of religious conviction has been noted by contemporary chroniclers and later historians, with some suspecting that John was at best impious, or even atheistic, a very serious issue at the time. Contemporary chroniclers catalogued his various anti-religious habits at length, including his failure to take communion, his blasphemous remarks, and his witty but scandalous jokes about church doctrine, including jokes about the implausibility of the Resurrection. They commented on the paucity of John's charitable donations to the church. Historian Frank McLynn argues that John's early years at Fontevrault, combined with his relatively advanced education, may have turned him against the church. Other historians have been more cautious in interpreting this material, noting that chroniclers also reported John's personal interest in the life of St Wulfstan of Worcester and his friendships with several senior clerics, most especially with Hugh of Lincoln, who was later declared a saint. Financial records show a normal royal household engaged in the usual feasts and pious observances – albeit with many records showing John's offerings to the poor to atone for routinely breaking church rules and guidance. The historian Lewis Warren has argued that the chronicler accounts were subject to considerable bias and the King was "at least conventionally devout", citing his pilgrimages and interest in religious scripture and commentaries.

During the remainder of his reign, John focused on trying to retake Normandy. The available evidence suggests that John did not regard the loss of the Duchy as a permanent shift in Capetian power. Strategically, John faced several challenges: England itself had to be secured against possible French invasion, the sea-routes to Bordeaux needed to be secured following the loss of the land route to Aquitaine, and his remaining possessions in Aquitaine needed to be secured following the death of his mother, Eleanor, in April 1204. John's preferred plan was to use Poitou as a base of operations, advance up the Loire valley to threaten Paris, pin down the French forces and break Philip's internal lines of communication before landing a maritime force in the Duchy itself. Ideally, this plan would benefit from the opening of a second front on Philip's eastern frontiers with Flanders and Boulogne – effectively a re-creation of Richard's old strategy of applying pressure from Germany. All of this would require a great deal of money and soldiers.

John spent much of 1205 securing England against a potential French invasion. As an emergency measure, John recreated a version of Henry II's Assize of Arms of 1181, with each shire creating a structure to mobilise local levies. When the threat of invasion faded, John formed a large military force in England intended for Poitou, and a large fleet with soldiers under his own command intended for Normandy. To achieve this, John reformed the English feudal contribution to his campaigns, creating a more flexible system under which only one knight in ten would actually be mobilised, but would be financially supported by the other nine; knights would serve for an indefinite period. John built up a strong team of engineers for siege warfare and a substantial force of professional crossbowmen. The king was supported by a team of leading barons with military expertise, including William Longespée, William the Marshal, Roger de Lacy and, until he fell from favour, the marcher lord William de Braose.

John had already begun to improve his Channel forces before the loss of Normandy and he rapidly built up further maritime capabilities after its collapse. Most of these ships were placed along the Cinque Ports, but Portsmouth was also enlarged. By the end of 1204 he had around 50 large galleys available; another 54 vessels were built between 1209 and 1212. William of Wrotham was appointed "keeper of the galleys", effectively John's chief admiral. Wrotham was responsible for fusing John's galleys, the ships of the Cinque Ports and pressed merchant vessels into a single operational fleet. John adopted recent improvements in ship design, including new large transport ships called "buisses" and removable forecastles for use in combat.
Baronial unrest in England prevented the departure of the planned 1205 expedition, and only a smaller force under William Longespée deployed to Poitou. In 1206 John departed for Poitou himself, but was forced to divert south to counter a threat to Gascony from Alfonso VIII of Castile. After a successful campaign against Alfonso, John headed north again, taking the city of Angers. Philip moved south to meet John; the year's campaigning ended in stalemate and a two-year truce was made between the two rulers.

During the truce of 1206–1208, John focused on building up his financial and military resources in preparation for another attempt to recapture Normandy. John used some of this money to pay for new alliances on Philip's eastern frontiers, where the growth in Capetian power was beginning to concern France's neighbours. By 1212 John had successfully concluded alliances with his nephew Otto IV, a contender for the crown of Holy Roman Emperor in Germany, as well as with the counts Renaud of Boulogne and Ferdinand of Flanders. The invasion plans for 1212 were postponed because of fresh English baronial unrest about service in Poitou. Philip seized the initiative in 1213, sending his elder son, Louis, to invade Flanders with the intention of next launching an invasion of England. John was forced to postpone his own invasion plans to counter this threat. He launched his new fleet to attack the French at the harbour of Damme. The attack was a success, destroying Philip's vessels and any chances of an invasion of England that year. John hoped to exploit this advantage by invading himself late in 1213, but baronial discontent again delayed his invasion plans until early 1214, in what was his final Continental campaign.

In the late 12th and early 13th centuries the border and political relationship between England and Scotland was disputed, with the kings of Scotland claiming parts of what is now northern England. John's father, Henry II, had forced William the Lion to swear fealty to him at the Treaty of Falaise in 1174. This had been rescinded by Richard I in exchange for financial compensation in 1189, but the relationship remained uneasy. John began his reign by reasserting his sovereignty over the disputed northern counties. He refused William's request for the earldom of Northumbria, but did not intervene in Scotland itself and focused on his continental problems. The two kings maintained a friendly relationship, meeting in 1206 and 1207, until it was rumoured in 1209 that William was intending to ally himself with Philip II of France. John invaded Scotland and forced William to sign the Treaty of Norham, which gave John control of William's daughters and required a payment of £10,000. This effectively crippled William's power north of the border, and by 1212 John had to intervene militarily to support the Scottish king against his internal rivals. John made no efforts to reinvigorate the Treaty of Falaise, though, and both William and Alexander in turn remained independent kings, supported by, but not owing fealty to, John.

John remained Lord of Ireland throughout his reign. He drew on the country for resources to fight his war with Philip on the continent. Conflict continued in Ireland between the Anglo-Norman settlers and the indigenous Irish chieftains, with John manipulating both groups to expand his wealth and power in the country. During Richard's rule, John had successfully increased the size of his lands in Ireland, and he continued this policy as king. In 1210 the king crossed into Ireland with a large army to crush a rebellion by the Anglo-Norman lords; he reasserted his control of the country and used a new charter to order compliance with English laws and customs in Ireland. John stopped short of trying to actively enforce this charter on the native Irish kingdoms, but historian David Carpenter suspects that he might have done so, had the baronial conflict in England not intervened. Simmering tensions remained with the native Irish leaders even after John left for England.

Royal power in Wales was unevenly applied, with the country divided between the marcher lords along the borders, royal territories in Pembrokeshire and the more independent native Welsh lords of North Wales. John took a close interest in Wales and knew the country well, visiting every year between 1204 and 1211 and marrying his illegitimate daughter, Joan, to the Welsh prince Llywelyn the Great. The king used the marcher lords and the native Welsh to increase his own territory and power, striking a sequence of increasingly precise deals backed by royal military power with the Welsh rulers. A major royal expedition to enforce these agreements occurred in 1211, after Llywelyn attempted to exploit the instability caused by the removal of William de Braose, through the Welsh uprising of 1211. John's invasion, striking into the Welsh heartlands, was a military success. Llywelyn came to terms that included an expansion of John's power across much of Wales, albeit only temporarily.

When the Archbishop of Canterbury, Hubert Walter, died on 13 July 1205, John became involved in a dispute with Pope Innocent III that would lead to the king's excommunication. The Norman and Angevin kings had traditionally exercised a great deal of power over the church within their territories. From the 1040s onwards, however, successive popes had put forward a reforming message that emphasised the importance of the church being "governed more coherently and more hierarchically from the centre" and established "its own sphere of authority and jurisdiction, separate from and independent of that of the lay ruler", in the words of historian Richard Huscroft. After the 1140s, these principles had been largely accepted within the English church, albeit with an element of concern about centralising authority in Rome. These changes brought the customary rights of lay rulers such as John over ecclesiastical appointments into question. Pope Innocent was, according to historian Ralph Turner, an "ambitious and aggressive" religious leader, insistent on his rights and responsibilities within the church.

John wanted John de Gray, the Bishop of Norwich and one of his own supporters, to be appointed Archbishop of Canterbury after the death of Walter, but the cathedral chapter for Canterbury Cathedral claimed the exclusive right to elect Walter's successor. They favoured Reginald, the chapter's sub-prior. To complicate matters, the bishops of the province of Canterbury also claimed the right to appoint the next archbishop. The chapter secretly elected Reginald and he travelled to Rome to be confirmed; the bishops challenged the appointment and the matter was taken before Innocent. John forced the Canterbury chapter to change their support to John de Gray, and a messenger was sent to Rome to inform the papacy of the new decision. Innocent disavowed both Reginald and John de Gray, and instead appointed his own candidate, Stephen Langton. John refused Innocent's request that he consent to Langton's appointment, but the pope consecrated Langton anyway in June 1207.

John was incensed about what he perceived as an abrogation of his customary right as monarch to influence the election. He complained both about the choice of Langton as an individual, as John felt he was overly influenced by the Capetian court in Paris, and about the process as a whole. He barred Langton from entering England and seized the lands of the archbishopric and other papal possessions. Innocent set a commission in place to try to convince John to change his mind, but to no avail. Innocent then placed an interdict on England in March 1208, prohibiting clergy from conducting religious services, with the exception of baptisms for the young, and confessions and absolutions for the dying.
John treated the interdict as "the equivalent of a papal declaration of war". He responded by attempting to punish Innocent personally and to drive a wedge between those English clergy that might support him and those allying themselves firmly with the authorities in Rome. John seized the lands of those clergy unwilling to conduct services, as well as those estates linked to Innocent himself; he arrested the illicit concubines that many clerics kept during the period, only releasing them after the payment of fines; he seized the lands of members of the church who had fled England, and he promised protection for those clergy willing to remain loyal to him. In many cases, individual institutions were able to negotiate terms for managing their own properties and keeping the produce of their estates. By 1209 the situation showed no signs of resolution, and Innocent threatened to excommunicate John if he did not acquiesce to Langton's appointment. When this threat failed, Innocent excommunicated the king in November 1209. Although theoretically a significant blow to John's legitimacy, this did not appear to greatly worry the king. Two of John's close allies, Emperor Otto IV and Count Raymond VI of Toulouse, had already suffered the same punishment themselves, and the significance of excommunication had been somewhat devalued. John simply tightened his existing measures and accrued significant sums from the income of vacant sees and abbeys: one 1213 estimate, for example, suggested the church had lost an estimated 100,000 marks (equivalent to £66,666 at the time) to John. Official figures suggest that around 14% of annual income from the English church was being appropriated by John each year.

Innocent gave some dispensations as the crisis progressed. Monastic communities were allowed to celebrate Mass in private from 1209 onwards, and late in 1212 the Holy Viaticum for the dying was authorised. The rules on burials and lay access to churches appear to have been steadily circumvented, at least unofficially. Although the interdict was a burden to much of the population, it did not result in rebellion against John. By 1213, though, John was increasingly worried about the threat of French invasion. Some contemporary chroniclers suggested that in January Philip II of France had been charged with deposing John on behalf of the papacy, although it appears that Innocent merely prepared secret letters in case Innocent needed to claim the credit if Philip did successfully invade England.

Under mounting political pressure, John finally negotiated terms for a reconciliation, and the papal terms for submission were accepted in the presence of the papal legate Pandulf Verraccio in May 1213 at the Templar Church at Dover. As part of the deal, John offered to surrender the Kingdom of England to the papacy for a feudal service of 1,000 marks (equivalent to £666 at the time) annually: 700 marks (£466) for England and 300 marks (£200) for Ireland, as well as recompensing the church for revenue lost during the crisis. The agreement was formalised in the "Bulla Aurea", or Golden Bull. This resolution produced mixed responses. Although some chroniclers felt that John had been humiliated by the sequence of events, there was little public reaction. Innocent benefited from the resolution of his long-standing English problem, but John probably gained more, as Innocent became a firm supporter of John for the rest of his reign, backing him in both domestic and continental policy issues. Innocent immediately turned against Philip, calling upon him to reject plans to invade England and to sue for peace. John paid some of the compensation money he had promised the church, but he ceased making payments in late 1214, leaving two-thirds of the sum unpaid; Innocent appears to have conveniently forgotten this debt for the good of the wider relationship.

Tensions between John and the barons had been growing for several years, as demonstrated by the 1212 plot against the king. Many of the disaffected barons came from the north of England; that faction was often labelled by contemporaries and historians as "the Northerners". The northern barons rarely had any personal stake in the conflict in France, and many of them owed large sums of money to John; the revolt has been characterised as "a rebellion of the king's debtors". Many of John's military household joined the rebels, particularly amongst those that John had appointed to administrative roles across England; their local links and loyalties outweighed their personal loyalty to John. Tension also grew across North Wales, where opposition to the 1211 treaty between John and Llywelyn was turning into open conflict. For some the appointment of Peter des Roches as justiciar was an important factor, as he was considered an "abrasive foreigner" by many of the barons. The failure of John's French military campaign in 1214 was probably the final straw that precipitated the baronial uprising during John's final years as king; James Holt describes the path to civil war as "direct, short and unavoidable" following the defeat at Bouvines.

In 1214 John began his final campaign to reclaim Normandy from Philip. John was optimistic, as he had successfully built up alliances with the Emperor Otto, Renaud of Boulogne and Count Ferdinand of Flanders; he was enjoying papal favour; and he had successfully built up substantial funds to pay for the deployment of his experienced army. Nonetheless, when John left for Poitou in February 1214, many barons refused to provide military service; mercenary knights had to fill the gaps. John's plan was to split Philip's forces by pushing north-east from Poitou towards Paris, whilst Otto, Renaud and Ferdinand, supported by William Longespée, marched south-west from Flanders.

The first part of the campaign went well, with John outmanoeuvring the forces under the command of Prince Louis and retaking the county of Anjou by the end of June. John besieged the castle of Roche-au-Moine, a key stronghold, forcing Louis to give battle against John's larger army. The local Angevin nobles refused to advance with the king; left at something of a disadvantage, John retreated back to La Rochelle. Shortly afterwards, Philip won the hard-fought battle of Bouvines in the north against Otto and John's other allies, bringing an end to John's hopes of retaking Normandy. A peace agreement was signed in which John returned Anjou to Philip and paid the French king compensation; the truce was intended to last for six years. John arrived back in England in October.

Within a few months of John's return, rebel barons in the north and east of England were organising resistance to his rule. John held a council in London in January 1215 to discuss potential reforms and sponsored discussions in Oxford between his agents and the rebels during the spring. John appears to have been playing for time until Pope Innocent III could send letters giving him explicit papal support. This was particularly important for John, as a way of pressuring the barons but also as a way of controlling Stephen Langton, the Archbishop of Canterbury. In the meantime, John began to recruit fresh mercenary forces from Poitou, although some were later sent back to avoid giving the impression that the king was escalating the conflict. John announced his intent to become a crusader, a move which gave him additional political protection under church law.

Letters of support from the pope arrived in April but by then the rebel barons had organised. They congregated at Northampton in May and renounced their feudal ties to John, appointing Robert fitz Walter as their military leader. This self-proclaimed "Army of God" marched on London, taking the capital as well as Lincoln and Exeter. John's efforts to appear moderate and conciliatory had been largely successful, but once the rebels held London they attracted a fresh wave of defectors from John's royalist faction. John instructed Langton to organise peace talks with the rebel barons.

John met the rebel leaders at Runnymede, near Windsor Castle, on 15 June 1215. Langton's efforts at mediation created a charter capturing the proposed peace agreement; it was later renamed "Magna Carta", or "Great Charter". The charter went beyond simply addressing specific baronial complaints, and formed a wider proposal for political reform, albeit one focusing on the rights of free men, not serfs and unfree labour. It promised the protection of church rights, protection from illegal imprisonment, access to swift justice, new taxation only with baronial consent and limitations on scutage and other feudal payments. A council of twenty-five barons would be created to monitor and ensure John's future adherence to the charter, whilst the rebel army would stand down and London would be surrendered to the king.

Neither John nor the rebel barons seriously attempted to implement the peace accord. The rebel barons suspected that the proposed baronial council would be unacceptable to John and that he would challenge the legality of the charter; they packed the baronial council with their own hardliners and refused to demobilise their forces or surrender London as agreed. Despite his promises to the contrary, John appealed to Innocent for help, observing that the charter compromised the pope's rights under the 1213 agreement that had appointed him John's feudal lord. Innocent obliged; he declared the charter "not only shameful and demeaning, but illegal and unjust" and excommunicated the rebel barons. The failure of the agreement led rapidly to the First Barons' War.

The rebels made the first move in the war, seizing the strategic Rochester Castle, owned by Langton but left almost unguarded by the archbishop. John was well prepared for a conflict. He had stockpiled money to pay for mercenaries and ensured the support of the powerful marcher lords with their own feudal forces, such as William Marshal and Ranulf of Chester. The rebels lacked the engineering expertise or heavy equipment necessary to assault the network of royal castles that cut off the northern rebel barons from those in the south. John's strategy was to isolate the rebel barons in London, protect his own supply lines to his key source of mercenaries in Flanders, prevent the French from landing in the south-east, and then win the war through slow attrition. John put off dealing with the badly deteriorating situation in North Wales, where Llywelyn the Great was leading a rebellion against the 1211 settlement.

John's campaign started well. In November John retook Rochester Castle from rebel baron William d'Aubigny in a sophisticated assault. One chronicler had not seen "a siege so hard pressed or so strongly resisted", whilst historian Reginald Brown describes it as "one of the greatest [siege] operations in England up to that time". Having regained the south-east John split his forces, sending William Longespée to retake the north side of London and East Anglia, whilst John himself headed north via Nottingham to attack the estates of the northern barons. Both operations were successful and the majority of the remaining rebels were pinned down in London. In January 1216 John marched against Alexander II of Scotland, who had allied himself with the rebel cause. John took back Alexander's possessions in northern England in a rapid campaign and pushed up towards Edinburgh over a ten-day period.

The rebel barons responded by inviting the French prince Louis to lead them: Louis had a claim to the English throne by virtue of his marriage to Blanche of Castile, a granddaughter of Henry II. Philip may have provided him with private support but refused to openly support Louis, who was excommunicated by Innocent for taking part in the war against John. Louis' planned arrival in England presented a significant problem for John, as the prince would bring with him naval vessels and siege engines essential to the rebel cause. Once John contained Alexander in Scotland, he marched south to deal with the challenge of the coming invasion.

Prince Louis intended to land in the south of England in May 1216, and John assembled a naval force to intercept him. Unfortunately for John, his fleet was dispersed by bad storms and Louis landed unopposed in Kent. John hesitated and decided not to attack Louis immediately, either due to the risks of open battle or over concerns about the loyalty of his own men. Louis and the rebel barons advanced west and John retreated, spending the summer reorganising his defences across the rest of the kingdom. John saw several of his military household desert to the rebels, including his half-brother, William Longespée. By the end of the summer the rebels had regained the south-east of England and parts of the north.

In September 1216, John began a fresh, vigorous attack. He marched from the Cotswolds, feigned an offensive to relieve the besieged Windsor Castle, and attacked eastwards around London to Cambridge to separate the rebel-held areas of Lincolnshire and East Anglia. From there he travelled north to relieve the rebel siege at Lincoln and back east to King's Lynn, probably to order further supplies from the continent. In King's Lynn, John contracted dysentery, which would ultimately prove fatal. Meanwhile, Alexander II invaded northern England again, taking Carlisle in August and then marching south to give homage to Prince Louis for his English possessions; John narrowly missed intercepting Alexander along the way. Tensions between Louis and the English barons began to increase, prompting a wave of desertions, including William Marshal's son William and William Longespée, who both returned to John's faction.

The king returned west but is said to have lost a significant part of his baggage train along the way. Roger of Wendover provides the most graphic account of this, suggesting that the king's belongings, including the Crown Jewels, were lost as he crossed one of the tidal estuaries which empties into the Wash, being sucked in by quicksand and whirlpools. Accounts of the incident vary considerably between the various chroniclers and the exact location of the incident has never been confirmed; the losses may have involved only a few of his pack-horses. Modern historians assert that by October 1216 John faced a "stalemate", "a military situation uncompromised by defeat".

John's illness grew worse and by the time he reached Newark Castle he was unable to travel any farther; John died on the night of 18/19 October. Numerous – probably fictitious – accounts circulated soon after his death that he had been killed by poisoned ale, poisoned plums or a "surfeit of peaches". His body was escorted south by a company of mercenaries and he was buried in Worcester Cathedral in front of the altar of St Wulfstan. A new sarcophagus with an effigy was made for him in 1232, in which his remains now rest.

In the aftermath of John's death William Marshal was declared the protector of the nine-year-old Henry III. The civil war continued until royalist victories at the battles of Lincoln and Dover in 1217. Louis gave up his claim to the English throne and signed the Treaty of Lambeth. The failed "Magna Carta" agreement was resuscitated by Marshal's administration and reissued in an edited form in 1217 as a basis for future government. Henry III continued his attempts to reclaim Normandy and Anjou until 1259, but John's continental losses and the consequent growth of Capetian power in the 13th century proved to mark a "turning point in European history".

John's first wife, Isabel, Countess of Gloucester, was released from imprisonment in 1214; she remarried twice, and died in 1217. John's second wife, Isabella of Angoulême, left England for Angoulême soon after the king's death; she became a powerful regional leader, but largely abandoned the children she had had by John. John had five legitimate children, all by Isabella. His eldest son, Henry III, ruled as King of England for the majority of the 13th century. Richard became a noted European leader and ultimately the King of the Romans in the Holy Roman Empire. Joan became Queen of Scotland on her marriage to Alexander II. Isabella was Holy Roman Empress as the wife of Frederick II. His youngest daughter, Eleanor, married William Marshal's son, also called William, and later the famous English rebel Simon de Montfort. John had various mistresses. By them he had eight, possibly nine, sons – Richard, Oliver, John, Geoffrey, Henry, Osbert Gifford, Eudes, Bartholomew and probably Philip – and two or three daughters – Joan, Maud and probably Isabel. Of these, Joan became the most famous, marrying Prince Llywelyn the Great of Wales.

Historical interpretations of John have been subject to considerable change over the years. Medieval chroniclers provided the first contemporary, or near contemporary, histories of John's reign. One group of chroniclers wrote early in John's life, or around the time of his accession, including Richard of Devizes, William of Newburgh, Roger of Hoveden and Ralph de Diceto. These historians were generally unsympathetic to John's behaviour under Richard's rule, but slightly more positive towards the very earliest years of John's reign. Reliable accounts of the middle and later parts of John's reign are more limited, with Gervase of Canterbury and Ralph of Coggeshall writing the main accounts; neither of them were positive about John's performance as king. Much of John's later, negative reputation was established by two chroniclers writing after the king's death, Roger of Wendover and Matthew Paris, the latter claiming that John attempted conversion to Islam in exchange for military aid from the Almohad ruler Muhammad al-Nasir – a story modern historians consider untrue.

In the 16th century political and religious changes altered the attitude of historians towards John. Tudor historians were generally favourably inclined towards the king, focusing on John's opposition to the Papacy and his promotion of the special rights and prerogatives of a king. Revisionist histories written by John Foxe, William Tyndale and Robert Barnes portrayed John as an early Protestant hero, and John Foxe included the king in his "Book of Martyrs". John Speed's "Historie of Great Britaine" in 1632 praised John's "great renown" as a king; he blamed the bias of medieval chroniclers for the king's poor reputation.
By the Victorian period in the 19th century, historians were more inclined to draw on the judgements of the chroniclers and to focus on John's moral personality. Kate Norgate, for example, argued that John's downfall had been due not to his failure in war or strategy, but due to his "almost superhuman wickedness", whilst James Ramsay blamed John's family background and his cruel personality for his downfall. Historians in the "Whiggish" tradition, focusing on documents such as the Domesday Book and "Magna Carta", trace a progressive and universalist course of political and economic development in England over the medieval period. These historians were often inclined to see John's reign, and his signing of "Magna Carta" in particular, as a positive step in the constitutional development of England, despite the flaws of the king himself. Winston Churchill, for example, argued that "[w]hen the long tally is added, it will be seen that the British nation and the English-speaking world owe far more to the vices of John than to the labours of virtuous sovereigns".

In the 1940s, new interpretations of John's reign began to emerge, based on research into the record evidence of his reign, such as pipe rolls, charters, court documents and similar primary records. Notably, an essay by Vivian Galbraith in 1945 proposed a "new approach" to understanding the ruler. The use of recorded evidence was combined with an increased scepticism about two of the most colourful chroniclers of John's reign, Roger of Wendover and Matthew Paris. In many cases the detail provided by these chroniclers, both writing after John's death, was challenged by modern historians. Interpretations of "Magna Carta" and the role of the rebel barons in 1215 have been significantly revised: although the charter's symbolic, constitutional value for later generations is unquestionable, in the context of John's reign most historians now consider it a failed peace agreement between "partisan" factions. There has been increasing debate about the nature of John's Irish policies. Specialists in Irish medieval history, such as Sean Duffy, have challenged the conventional narrative established by Lewis Warren, suggesting that Ireland was less stable by 1216 than was previously supposed.

Most historians today, including John's recent biographers Ralph Turner and Lewis Warren, argue that John was an unsuccessful monarch, but note that his failings were exaggerated by 12th- and 13th-century chroniclers. Jim Bradbury notes the current consensus that John was a "hard-working administrator, an able man, an able general", albeit, as Turner suggests, with "distasteful, even dangerous personality traits", including pettiness, spitefulness and cruelty. John Gillingham, author of a major biography of Richard I, follows this line too, although he considers John a less effective general than do Turner or Warren, and describes him "one of the worst kings ever to rule England". Bradbury takes a moderate line, but suggests that in recent years modern historians have been overly lenient towards John's numerous faults. Popular historian Frank McLynn maintains a counter-revisionist perspective on John, arguing that the king's modern reputation amongst historians is "bizarre", and that as a monarch John "fails almost all those [tests] that can be legitimately set".

Popular representations of John first began to emerge during the Tudor period, mirroring the revisionist histories of the time. The anonymous play "The Troublesome Reign of King John" portrayed the king as a "proto-Protestant martyr", similar to that shown in John Bale's morality play "Kynge Johan", in which John attempts to save England from the "evil agents of the Roman Church". By contrast, Shakespeare's "King John", a relatively anti-Catholic play that draws on "The Troublesome Reign" for its source material, offers a more "balanced, dual view of a complex monarch as both a proto-Protestant victim of Rome's machinations and as a weak, selfishly motivated ruler". Anthony Munday's play "The Downfall and The Death of Robert Earl of Huntington" portrays many of John's negative traits, but adopts a positive interpretation of the king's stand against the Roman Catholic Church, in line with the contemporary views of the Tudor monarchs. By the middle of the 17th century, plays such as Robert Davenport's "King John and Matilda", although based largely on the earlier Elizabethan works, were transferring the role of Protestant champion to the barons and focusing more on the tyrannical aspects of John's behaviour.

Nineteenth-century fictional depictions of John were heavily influenced by Sir Walter Scott's historical romance, "Ivanhoe", which presented "an almost totally unfavourable picture" of the king; the work drew on 19th century histories of the period and on Shakespeare's play. Scott's work influenced the late 19th-century children's writer Howard Pyle's book "The Merry Adventures of Robin Hood", which in turn established John as the principal villain within the traditional Robin Hood narrative. During the 20th century, John was normally depicted in fictional books and films alongside Robin Hood. Sam De Grasse's role as John in the black-and-white 1922 film version shows John committing numerous atrocities and acts of torture. Claude Rains played John in the 1938 colour version alongside Errol Flynn, starting a trend for films to depict John as an "effeminate ... arrogant and cowardly stay-at-home". The character of John acts either to highlight the virtues of King Richard, or contrasts with the Sheriff of Nottingham, who is usually the "swashbuckling villain" opposing Robin. An extreme version of this trend can be seen in the 1973 Disney cartoon version, for example, which depicts John, voiced by Peter Ustinov, as a "cowardly, thumbsucking lion". Popular works that depict John beyond the Robin Hood legends, such as James Goldman's play and later film, "The Lion in Winter", set in 1183, commonly present him as an "effete weakling", in this instance contrasted with the more masculine Henry II, or as a tyrant, as in A. A. Milne's poem for children, "King John's Christmas".



</doc>
<doc id="16578" url="https://en.wikipedia.org/wiki?curid=16578" title="John Hay">
John Hay

John Milton Hay (October 8, 1838July 1, 1905) was an American statesman and official whose career in government stretched over almost half a century. Beginning as a private secretary and assistant to Abraham Lincoln, Hay's highest office was United States Secretary of State under Presidents William McKinley and Theodore Roosevelt. Hay was also an author and biographer and wrote poetry and other literature throughout much of his life.

Born in Indiana to an anti-slavery family that moved to Illinois when he was young, Hay showed great potential, and his family sent him to Brown University. After graduation in 1858, Hay read law in his uncle's office in Springfield, Illinois, adjacent to that of Lincoln. Hay worked for Lincoln's successful presidential campaign and became one of his private secretaries at the White House. Throughout the American Civil War, Hay was close to Lincoln and stood by his deathbed after the President was shot at Ford's Theatre. In addition to his other literary works, Hay co-authored with John George Nicolay a that helped shape the assassinated president's historical image.

After Lincoln's death, Hay spent several years at diplomatic posts in Europe, then worked for the "New-York Tribune" under Horace Greeley and Whitelaw Reid. Yet, Hay remained active in politics, and from 1879 to 1881 served as Assistant Secretary of State. Afterward, he remained in the private sector, until President McKinley, for whom he had been a major backer, made him Ambassador to the United Kingdom in 1897. Hay became Secretary of State the following year.

Hay served for almost seven years as Secretary of State, under President McKinley, and after McKinley's assassination, under Theodore Roosevelt. Hay was responsible for negotiating the Open Door Policy, which kept China open to trade with all countries on an equal basis, with international powers. By negotiating the Hay–Pauncefote Treaty with the United Kingdom, the (ultimately unratified) Hay–Herrán Treaty with Colombia, and finally the Hay–Bunau-Varilla Treaty with the newly-independent Republic of Panama, Hay also cleared the way for the building of the Panama Canal.

John Milton Hay was born in Salem, Indiana, on October 8, 1838. He was the third son of Dr. Charles Hay and the former Helen Leonard. Charles Hay, born in Lexington, Kentucky, hated slavery and moved to the North in the early 1830s. A doctor, he practiced in Salem. Helen's father, David Leonard, had moved his family west from Assonet, Massachusetts, in 1818, but died en route to Vincennes, Indiana, and Helen relocated to Salem in 1830 to teach school. They married there in 1831. Charles was not successful in Salem, and moved, with his wife and children, to Warsaw, Illinois, in 1841.

John attended the local schools, and in 1849 his uncle Milton Hay invited John to live at his home in Pittsfield, Pike County, and attend a well-regarded local school, the John D. Thomson Academy. Milton was a friend of Springfield attorney Abraham Lincoln and had read law in the firm Stuart and Lincoln. In Pittsfield, John first met John Nicolay, who was at the time a 20-year-old newspaperman. Once John Hay completed his studies there, the 13-year-old was sent to live with his grandfather in Springfield and attend school there. His parents and uncle Milton (who financed the boy's education) sent him to Brown University in Providence, Rhode Island, "alma mater" of his late maternal grandfather.

Hay enrolled at Brown in 1855. Although he enjoyed college life, he did not find it easy: his Western clothing and accent made him stand out; he was not well prepared academically and was often sick. Hay gained a reputation as a star student and became a part of Providence's literary circle that included Sarah Helen Whitman and Nora Perry. He wrote poetry and experimented with hashish. Hay received his Master of Arts degree in 1858, and was, like his grandfather before him, Class Poet. He returned to Illinois. Milton Hay had moved his practice to Springfield, and John became a clerk in his firm, where he could study law.

Milton Hay's firm was one of the most prestigious in Illinois. Lincoln maintained offices next door and was a rising star in the new Republican Party. Hay recalled an early encounter with Lincoln:

Hay was not a supporter of Lincoln for president until after his nomination in 1860. Hay then made speeches and wrote newspaper articles boosting Lincoln's candidacy. When Nicolay, who had been made Lincoln's private secretary for the campaign, found he needed help with the huge amounts of correspondence, Hay worked full-time for Lincoln for six months.

After Lincoln was elected, Nicolay, who continued as Lincoln's private secretary, recommended that Hay be hired to assist him at the White House. Lincoln is reported to have said, "We can't take all Illinois with us down to Washington" but then "Well, let Hay come". Kushner and Sherrill were dubious about "the story of Lincoln's offhand appointment of Hay" as fitting well into Hay's self-image of never having been an office-seeker, but "poorly into the realities of Springfield politics of the 1860s"—Hay must have expected some reward for handling Lincoln's correspondence for months. Hay biographer John Taliaferro suggests that Lincoln engaged Nicolay and Hay to assist him, rather than more seasoned men, both "out of loyalty and surely because of the competence and compatibility that his two young aides had demonstrated". Historian Joshua Zeitz argues that Lincoln was moved to hire Hay when Milton agreed to pay his nephew's salary for six months.

Milton Hay desired that his nephew go to Washington as a qualified attorney, and John Hay was admitted to the bar in Illinois on February 4, 1861. On February 11, he embarked with President-elect Lincoln on a circuitous journey to Washington. By this time, several Southern states had seceded to form the Confederate States of America in reaction to the election of Lincoln, seen as an opponent of slavery. When Lincoln was sworn in on March 4, Hay and Nicolay moved into the White House, sharing a shabby bedroom. As there was only authority for payment of one presidential secretary (Nicolay), Hay was appointed to a post in the Interior Department at $1,600 per year, seconded to service at the White House. They were available to Lincoln 24 hours a day. As Lincoln took no vacations as president and worked seven days a week, often until 11 pm (or later, during crucial battles) the burden on his secretaries was heavy.

Hay and Nicolay divided their responsibilities: Nicolay tending to assist Lincoln in his office and in meetings, while Hay dealt with the correspondence, which was very large. Both men tried to shield Lincoln from office-seekers and others who wanted to meet with the President. Unlike the dour Nicolay, Hay, with his charm, escaped much of the hard feelings from those denied Lincoln's presence. Abolitionist Thomas Wentworth Higginson described Hay as "a nice young fellow, who unfortunately looks about seventeen and is oppressed with the necessity of behaving like seventy". Hay continued to write, anonymously, for newspapers, sending in columns calculated to make Lincoln appear a sorrowful man, religious and competent, giving of his life and health to preserve the Union. Similarly, Hay served as what Taliaferro deemed a "White House propagandist", in his columns explaining away losses such as that at First Manassas in July 1861.
Despite the heavy workload—Hay wrote that he was busy 20 hours a day—he tried to make as normal a life as possible, eating his meals with Nicolay at Willard's Hotel, going to the theatre with Abraham and Mary Todd Lincoln, and reading "Les Misérables" in French. Hay, still in his early 20s, spent time both in barrooms and at cultured get-togethers in the homes of Washington's elite. The two secretaries often clashed with Mary Lincoln, who resorted to various stratagems to get the dilapidated White House restored without depleting Lincoln's salary, which had to cover entertainment and other expenses. Despite the secretaries' objections, Mrs. Lincoln was generally the victor and managed to save almost 70% of her husband's salary in his four years in office.

After the death of Lincoln's 11-year-old son Willie in February 1862 (an event not mentioned in Hay's diary or correspondence), "it was Hay who became, if not a surrogate son, then a young man who stirred a higher form of parental nurturing that Lincoln, despite his best intentions, did not successfully bestow on either of his surviving children". According to Hay biographer Robert Gale, "Hay came to adore Lincoln for his goodness, patience, understanding, sense of humor, humility, magnanimity, sense of justice, healthy skepticism, resilience and power, love of the common man, and mystical patriotism". Speaker of the House Galusha Grow stated, "Lincoln was very much attached to him"; writer Charles G. Halpine, who knew Hay then, later recorded that "Lincoln loved him as a son".

Hay and Nicolay accompanied Lincoln to Gettysburg, Pennsylvania, for the dedication of the cemetery there, where were interred many of those who fell at the Battle of Gettysburg. Although they made much of Lincoln's brief Gettysburg Address in their 1890 multi-volume biography of Lincoln, Hay's diary states "the President, in a firm, free way, with more grace than is his wont, said his half-dozen lines of consecration."

Lincoln sent Hay away from the White House on various missions. In August 1861, Hay escorted Mary Lincoln and her children to Long Branch, New Jersey, a resort on the Jersey Shore, both as their caretaker and as a means of giving Hay a much-needed break. The following month, Lincoln sent him to Missouri to deliver a letter to Union General John C. Frémont, who had irritated the President with military blunders and by freeing local slaves without authorization, endangering Lincoln's attempts to keep the border states in the Union.

In April 1863, Lincoln sent Hay to the Union-occupied South Carolina coast to report back on the ironclad vessels being used in an attempt to recapture Charleston Harbor. Hay then went on to the Florida coast. He returned to Florida in January 1864, after Lincoln had announced his Ten Percent Plan, that if ten percent of the 1860 electorate in a state took oaths of loyalty and to support emancipation, they could form a government with federal protection. Lincoln considered Florida, with its small population, a good test case, and made Hay a major, sending him to see if he could get sufficient men to take the oath. Hay spent a month in the state during February and March 1864, but Union defeats there reduced the area under federal control. Believing his mission impractical, he sailed back to Washington.

In July 1864, New York publisher Horace Greeley sent word to Lincoln that there were Southern peace emissaries in Canada. Lincoln doubted that they actually spoke for Confederate President Jefferson Davis, but had Hay journey to New York to persuade the publisher to go to Niagara Falls, Ontario, to meet with them and bring them to Washington. Greeley reported to Lincoln that the emissaries lacked accreditation by Davis, but were confident they could bring both sides together. Lincoln sent Hay to Ontario with what became known as the Niagara Manifesto: that if the South laid down its arms, freed the slaves, and reentered the Union, it could expect liberal terms on other points. The Southerners refused to come to Washington to negotiate.

By the end of 1864, with Lincoln reelected and the victorious war winding down, both Hay and Nicolay let it be known that they desired different jobs. Soon after Lincoln's second inauguration in March 1865, the two secretaries were appointed to the US delegation in Paris, Nicolay as consul and Hay as secretary of legation. Hay wrote to his brother Charles that the appointment was "entirely unsolicited and unexpected", a statement that Kushner and Sherrill found unconvincing given that Hay had spent hundreds of hours during the war with Secretary of State William H. Seward, who had often discussed personal and political matters with him, and the close relationship between the two men was so well known that office-seekers cultivated Hay as a means of getting to Seward. The two men were also motivated to find new jobs by their deteriorating relationship with Mary Lincoln, who sought their ouster, and by Nicolay's desire to wed his intended—he could not bring a bride to his shared room at the White House.They remained at the White House pending the arrival and training of replacements.

Hay did not accompany the Lincolns to Ford's Theatre on the night of April 14, 1865, but remained at the White House, drinking whiskey with Robert Lincoln. When the two were informed that the President had been shot, they hastened to the Petersen House, a boarding house where the stricken Lincoln had been taken. Hay remained by Lincoln's deathbed through the night and was present when he died. At the moment of Lincoln's death, Hay observed "a look of unspeakable peace came upon his worn features". He heard War Secretary Edwin Stanton's declaration, "Now he belongs to the ages."

According to Kushner and Sherrill, "Lincoln's death was for Hay a personal loss, like the loss of a father ... Lincoln's assassination erased any remaining doubts Hay had about Lincoln's greatness." In 1866, in a personal letter, Hay deemed Lincoln, "the greatest character since Christ". Taliaferro noted that "Hay would spend the rest of his life mourning Lincoln ... wherever Hay went and whatever he did, Lincoln would "always" be watching".

Hay sailed for Paris at the end of June 1865. There, he served under U.S. Minister to France John Bigelow. The workload was not heavy, and Hay found time to enjoy the pleasures of Paris. When Bigelow resigned in mid-1866, Hay, as was customary, submitted his resignation, though he was asked to remain until Bigelow's successor was in place, and stayed until January 1867. He consulted with Secretary of State William H. Seward, asking him for "anything worth having". Seward suggested the post of Minister to Sweden, but reckoned without the new president, Andrew Johnson, who had his own candidate. Seward offered Hay a job as his private secretary, but Hay declined, and returned home to Warsaw.

Initially happy to be home, Hay quickly grew restive, and he was glad to hear, in early June 1867, that he had been appointed secretary of legation to act as chargé d'affaires at Vienna. He sailed for Europe the same month, and while in England visited the House of Commons, where he was greatly impressed by the Chancellor of the Exchequer, Benjamin Disraeli. The Vienna post was only temporary, until Johnson could appoint a chargé d'affaires and have him confirmed by the Senate, and the workload was light, allowing Hay, who was fluent in German, to spend much of his time traveling. It was not until July 1868 that Henry Watts became Hay's replacement. Hay resigned, spent the remainder of the summer in Europe, then went home to Warsaw.

Unemployed again, in December 1868 Hay journeyed to the capital, writing to Nicolay that he "came to Washington in the peaceful pursuit of a fat office. But there is nothing just now available". Seward promised to "wrestle with Andy for anything that turns up", but nothing did prior to the departure of both Seward and Johnson from office on March 4, 1869. In May, Hay went back to Washington from Warsaw to press his case with the new Grant administration. The next month, due to the influence of his friends, he obtained the post of secretary of legation in Spain.

Although the salary was low, Hay was interested in serving in Madrid both because of the political situation there—Queen Isabella II had recently been deposed—and because the U.S. Minister was the swashbuckling former congressman, General Daniel Sickles. Hay hoped to assist Sickles in gaining U.S. control over Cuba, then a Spanish colony. Sickles was unsuccessful and Hay resigned in May 1870, citing the low salary, but remaining in his post until September. Two legacies of Hay's time in Madrid were magazine articles he wrote that became the basis of his first book, "Castilian Days", and his lifelong friendship with Sickles's personal secretary, Alvey A. Adee, who would be a close aide to Hay at the State Department.

While still in Spain, Hay had been offered the position of assistant editor at the "New-York Tribune"—both the editor, Horace Greeley, and his managing editor, Whitelaw Reid, were anxious to hire Hay. He joined the staff in October 1870. The "Tribune" was the leading reform newspaper in New York, and through mail subscriptions, the largest-circulating newspaper in the nation. Hay wrote editorials for the "Tribune", and Greeley soon proclaimed him the most brilliant writer of "breviers" (as they were called) that he had ever had.

With his success as an editorial writer, Hay's duties expanded. In October 1871, he journeyed to Chicago after the great fire there, interviewing Mrs. O'Leary, whose cow was said to have started the blaze, describing her as "a woman with a lamp [who went] to the barn behind the house, to milk the cow with the crumpled temper, that kicked the lamp, that spilled the kerosene, that fired the straw that burned Chicago". His work at the "Tribune" came as his fame as a poet was reaching its peak, and one colleague described it as "a liberal education in the delights of intellectual life to sit in intimate companionship with John Hay and watch the play of that well-stored and brilliant mind". In addition to writing, Hay was signed by the prestigious Boston Lyceum Bureau, whose clients included Mark Twain and Susan B. Anthony, to give lectures on the prospects for democracy in Europe, and on his years in the Lincoln White House.

By the time President Grant ran for reelection in 1872, Grant's administration had been rocked by scandal, and some disaffected members of his party formed the Liberal Republicans, naming Greeley as their candidate for president, a nomination soon joined in by the Democrats. Hay was unenthusiastic about the editor-turned-candidate, and in his editorials mostly took aim at Grant, who, despite the scandals, remained untarred, and who won a landslide victory in the election. Greeley died only weeks later, a broken man. Hay's stance endangered his hitherto sterling credentials in the Republican Party.

By 1873, Hay was wooing Clara Stone, daughter of Cleveland multimillionaire railroad and banking mogul Amasa Stone. The success of his suit (they married in 1874) made the salary attached to office a small consideration for the rest of his life. Amasa Stone needed someone to watch over his investments, and wanted Hay to move to Cleveland to fill the post. Although the Hays initially lived in John's New York apartment and later in a townhouse there, they moved in June 1875 to Stone's ornate home on Cleveland's Euclid Avenue, "Millionaire's Row", and a mansion was quickly under construction for the Hays next-door. The Hays had four children, Helen Hay Whitney, Adelbert Barnes Hay, Alice Evelyn Hay Wadsworth Boyd, and Clarence Leonard Hay. Their father proved successful as a money manager, though he devoted much of his time to literary and political activities, writing to Adee that "I do nothing but read and yawn".

On December 29, 1876, a bridge over Ohio's Ashtabula River collapsed. The bridge had been built from metal cast at one of Stone's mills, and was carrying a train owned and operated by Stone's Lake Shore and Michigan Railway. Ninety-two people died; it was the worst rail disaster in American history up to that point. Blame fell heavily on Stone, who departed for Europe to recuperate and left Hay in charge of his businesses. The summer of 1877 was marked by labor disputes; a strike over wage cuts on the Baltimore & Ohio Railroad soon spread to the Lake Shore, much to Hay's outrage. He blamed foreign agitators for the dispute, and vented his anger over the strike in his only novel, "The Bread-Winners" (1883).

Hay remained disaffected from the Republican Party in the mid-1870s. Seeking a candidate of either party he could support as a reformer, he watched as his favored Democrat, Samuel Tilden, gained his party's nomination, but his favored Republican, James G. Blaine, did not, falling to Ohio Governor Rutherford B. Hayes, whom Hay did not support during the campaign. Hayes's victory in the election left Hay an outsider as he sought a return to politics, and he was initially offered no place in the new administration. Nevertheless, Hay attempted to ingratiate himself with the new President by sending him a gold ring with a strand of George Washington's hair, a gesture that Hayes deeply appreciated. Hay spent time working with Nicolay on their Lincoln biography, and traveling in Europe. When Reid, who had succeeded Greeley as editor of the "Tribune", was offered the post of Minister to Germany in December 1878, he turned it down and recommended Hay. Secretary of State William M. Evarts indicated that Hay "had not been active enough in political efforts", to Hay's regret, who told Reid that he "would like a second-class mission uncommonly well".

From May to October 1879, Hay set out to reconfirm his credentials as a loyal Republican, giving speeches in support of candidates and attacking the Democrats. In October, President and Mrs. Hayes came to a reception at Hay's Cleveland home. When Assistant Secretary of State Frederick W. Seward resigned later that month, Hay was offered his place and accepted, after some hesitancy because he was considering running for Congress.

In Washington, Hay oversaw a staff of eighty employees, renewed his acquaintance with his friend Henry Adams, and substituted for Evarts at Cabinet meetings when the Secretary was out of town. In 1880, he campaigned for the Republican nominee for president, his fellow Ohioan, Congressman James A. Garfield. Hay felt that Garfield did not have enough backbone, and hoped that Reid and others would "inoculate him with the gall which I fear he lacks". Garfield consulted Hay before and after his election as president on appointments and other matters, but offered Hay only the post of private secretary (though he promised to increase its pay and power), and Hay declined. Hay resigned as assistant secretary effective March 31, 1881, and spent the next seven months as acting editor of the "Tribune" during Reid's extended absence in Europe. Garfield's death in September and Reid's return the following month left Hay again on the outside of political power, looking in. He would spend the next fifteen years in that position.

After 1881, Hay did not again hold public office until 1897. Amasa Stone committed suicide in 1883; his death left the Hays very wealthy. They spent several months in most years traveling in Europe. The Lincoln biography absorbed some of Hay's time, the hardest work being done with Nicolay in 1884 and 1885; beginning in 1886, portions began appearing serially, and the was published in 1890.

In 1884, Hay and Adams commissioned architect Henry Hobson Richardson to construct houses for them on Washington's Lafayette Square; these were completed by 1886. Hay's house, facing the White House and fronting on Sixteenth Street, was described even before completion as "the finest house in Washington". The price for the combined tract, purchased from William Wilson Corcoran, was $73,800, of which Adams paid a third for his lot. Hay budgeted the construction cost at $50,000; his ornate, mansion eventually cost over twice that. Despite their possession of two lavish houses, the Hays spent less than half the year in Washington and only a few weeks a year in Cleveland. They also spent time at The Fells, their summer residence in Newbury, New Hampshire. According to Gale, "for a full decade before his appointment in 1897 as ambassador to England, Hay was lazy and uncertain."

Hay continued to devote much of his energy to Republican politics. In 1884, he supported Blaine for president, donating considerable sums to the senator's unsuccessful campaign against New York Governor Grover Cleveland. Many of Hay's friends were unenthusiastic about Blaine's candidacy, to Hay's anger, and he wrote to editor Richard Watson Gilder, "I have never been able to appreciate the logic that induces some excellent people every four years because they cannot nominate the candidate they prefer to vote for the party they don't prefer." In 1888, Hay had to follow his own advice as his favored candidate, Ohio Senator John Sherman, was unsuccessful at the Republican convention. After some reluctance, Hay supported the nominee, former Indiana senator Benjamin Harrison, who was elected. Though Harrison appointed men whom Hay supported, including Blaine, Reid, and Robert Lincoln, Hay was not asked to serve in the Harrison administration. In 1890, Hay spoke for Republican congressional candidates, addressing a rally of 10,000 people in New York City, but the party was defeated, losing control of Congress. Hay contributed funds to Harrison's unsuccessful re-election effort, in part because Reid had been made Harrison's 1892 running mate.

Hay was an early supporter of Ohio's William McKinley and worked closely with McKinley's political manager, Cleveland industrialist Mark Hanna. In 1889, Hay supported McKinley in his unsuccessful effort to become Speaker of the House. Four years later, McKinley—by then Governor of Ohio—faced a crisis when a friend whose notes he had imprudently co-signed went bankrupt during the Panic of 1893. The debts were beyond the governor's means to pay, and the possibility of insolvency threatened McKinley's promising political career. Hay was among those Hanna called upon to contribute, buying up $3,000 of the debt of over $100,000. Although others paid more, "Hay's checks were two of the first, and his touch was more personal, a kindness McKinley never forgot". The governor wrote, "How can I ever repay you & other dear friends?"

The same panic that nearly ruined McKinley convinced Hay that men like himself must take office to save the country from disaster. By the end of 1894, he was deeply involved in efforts to lay the groundwork for the governor's 1896 presidential bid. It was Hay's job to persuade potential supporters that McKinley was worth backing. Nevertheless, Hay found time for a lengthy stay in New Hampshire—one visitor at The Fells in mid-1895 was Rudyard Kipling—and later in the year wrote, "The summer wanes and I have done nothing for McKinley." He atoned with a $500 check to Hanna, the first of many. During the winter of 1895–96, Hay passed along what he heard from other Republicans influential in Washington, such as Massachusetts Senator Henry Cabot Lodge.

Hay spent part of the spring and early summer of 1896 in the United Kingdom, and elsewhere in Europe. There was a border dispute between Venezuela and British Guiana, and Cleveland's Secretary of State, Richard Olney, supported the Venezuelan position, announcing the Olney interpretation of the Monroe Doctrine. Hay told British politicians that McKinley, if elected, would be unlikely to change course. McKinley was nominated in June 1896; still, many Britons were minded to support whoever became the Democratic candidate. This changed when the 1896 Democratic National Convention nominated former Nebraska congressman William Jennings Bryan on a "free silver" platform; he had electrified the delegates with his Cross of Gold speech. Hay reported to McKinley when he returned to Britain after a brief stay on the Continent during which Bryan was nominated in Chicago: "they were all scared out of their wits for fear Bryan would be elected, and very polite in their references to you."

Once Hay returned to the United States in early August, he went to The Fells and watched from afar as Bryan barnstormed the nation in his campaign while McKinley gave speeches from his front porch. Despite an invitation from the candidate, Hay was reluctant to visit McKinley at his home in Canton. "He has asked me to come, but I thought I would not struggle with the millions on his trampled lawn". In October, after basing himself at his Cleveland home and giving a speech for McKinley, Hay went to Canton at last, writing to Adams,

Hay was disgusted by Bryan's speeches, writing in language that Taliaferro compares to "The Bread-Winners" that the Democrat "simply reiterates the unquestioned truths that every man with a clean shirt is a thief and ought to be hanged: that there is no goodness and wisdom except among the illiterate & criminal classes". Despite Bryan's strenuous efforts, McKinley won the election easily, with a campaign run by himself and Hanna, and well-financed by supporters like Hay. Henry Adams later wondered, "I would give sixpence to know how much Hay paid for McKinley. His politics must have cost."

In the post-election speculation as to who would be given office under McKinley, Hay's name figured prominently, as did that of Whitelaw Reid; both men sought high office in the State Department, either as secretary or one of the major ambassadorial posts. Reid, in addition to his vice-presidential run, had been Minister to France under Harrison. Reid, an asthmatic, handicapped himself by departing for Arizona Territory for the winter, leading to speculation about his health.
Hay was faster than Reid to realize that the race for these posts would be affected by Hanna's desire to be senator from Ohio, as with one of the state's places about to be occupied by the newly elected Joseph B. Foraker, the only possible seat for him was that held by Senator Sherman. As the septuagenarian senator had served as Treasury Secretary under Hayes, only the secretaryship of state was likely to attract him and cause a vacancy that Hanna could fill. Hay knew that with only eight cabinet positions, only one could go to an Ohioan, and so he had no chance for a cabinet post. Accordingly, Hay encouraged Reid to seek the State position, while firmly ruling himself out as a possible candidate for that post, and quietly seeking the inside track to be ambassador in London. Zeitz states that Hay "aggressively lobbied" for the position.

According to Taliaferro, "only after the deed was accomplished and Hay was installed as the ambassador to the Court of St. James's would it be possible to detect just how subtly and completely he had finessed his ally and friend, Whitelaw Reid". A telegraph from Hay to McKinley in the latter's papers, dated December 26 (most likely 1896) reveals the former's suggestion that McKinley tell Reid that the editor's friends had insisted that Reid not endanger his health through office, especially in London's smoggy climes. The following month, in a letter, Hay set forth his own case for the ambassadorship, and urged McKinley to act quickly, as suitable accommodations in London would be difficult to secure. Hay gained his object (as did Hanna), and shifted his focus to appeasing Reid. Taliaferro states that Reid never blamed Hay, but Kushner and Sherrill recorded, "Reid was certain that he had been wronged" by Hay, and the announcement of Hay's appointment nearly ended their 26-year friendship.

Reaction in Britain to Hay's appointment was generally positive, with George Smalley of "The Times" writing to him, "we want a man who is a true American yet not anti-English". Hay secured a Georgian house on Carlton House Terrace, overlooking Horse Guards Parade, with 11 servants. He brought with him Clara, their own silver, two carriages, and five horses. Hay's salary of $17,000 "did not even begin to cover the cost of their extravagant lifestyle".

During his service as ambassador, Hay attempted to advance the relationship between the U.S. and Britain. The latter country had long been seen negatively by many Americans, a legacy of its colonial role that was refreshed by its Civil War neutrality, when British-built raiders such as the "Alabama" preyed on US-flagged ships. In spite of these past differences, according to Taliaferro, "rapprochement made more sense than at any time in their respective histories". In his Thanksgiving Day address to the American Society in London in 1897, Hay echoed these points, "The great body of people in the United States and England are friends ... [sharing] that intense respect and reverence for order, liberty, and law which is so profound a sentiment in both countries". Although Hay was not successful in resolving specific controversies in his year and a third as ambassador, both he and British policymakers regarded his tenure as a success, because of the advancement of good feelings and cooperation between the two nations.

An ongoing dispute between the U.S. and Britain was over the practice of pelagic sealing, that is, the capture of seals offshore of Alaska. The U.S. considered them American resources; the Canadians (Britain was still responsible for that dominion's foreign policy) contended that the mammals were being taken on the high seas, free to all. Soon after Hay's arrival, McKinley sent former Secretary of State John W. Foster to London to negotiate the issue. Foster quickly issued an accusatory note to the British that was printed in the newspapers. Although Hay was successful in getting Lord Salisbury, then both Prime Minister and Foreign Secretary, to agree to a conference to decide the matter, the British withdrew when the U.S. also invited Russia and Japan, rendering the conference ineffective. Another issue on which no agreement was reached was that of bimetallism: McKinley had promised silver-leaning Republicans to seek an international agreement varying the price ratio between silver and gold to allow for free coinage of silver, and Hay was instructed to seek British participation. The British would only join if the Indian colonial government (on a silver standard until 1893) was willing; this did not occur, and coupled with an improving economic situation that decreased support for bimetallism in the United States, no agreement was reached.

Hay had little involvement in the crisis over Cuba that culminated in the Spanish–American War. He met with Lord Salisbury in October 1897 and gained assurances Britain would not intervene if the U.S. found it necessary to go to war against Spain. Hay's role was "to make friends and to pass along the English point of view to Washington". Hay spent much of early 1898 on an extended trip to the Middle East, and did not return to London until the last week of March, by which time the USS "Maine" had exploded in Havana harbor. During the war, he worked to ensure U.S.-British amity, and British acceptance of the U.S. occupation of the Philippines—Salisbury and his government preferred that the U.S. have the islands than have them fall into the hands of the Germans.

In its early days, Hay described the war "as necessary as it is righteous". In July, writing to former Assistant Secretary of the Navy Theodore Roosevelt, who had gained wartime glory by leading the Rough Riders volunteer regiment, Hay made a description of the war for which, according to Zeitz, he "is best remembered by many students of American history":

Secretary Sherman had resigned on the eve of war, and been replaced by his first assistant, William R. Day. One of McKinley's Canton cronies, with little experience of statecraft, Day was never intended as more than a temporary wartime replacement. With America about to splash her flag across the Pacific, McKinley needed a secretary with stronger credentials. On August 14, 1898, Hay received a telegram from McKinley that Day would head the American delegation to the peace talks with Spain, and that Hay would be the new Secretary of State. After some indecision, Hay, who did not think he could decline and still remain as ambassador, accepted. British response to Hay's promotion was generally positive, and Queen Victoria, after he took formal leave of her at Osborne House, invited him again the following day, and subsequently pronounced him, "the most interesting of all the Ambassadors I have known."

John Hay was sworn in as Secretary of State on September 30, 1898. He needed little introduction to Cabinet meetings, and sat at the President's right hand. Meetings were held in the Cabinet Room of the White House, where he found his old office and bedroom each occupied by several clerks. Now responsible for 1,300 federal employees, he leaned heavily for administrative help on his old friend Alvey Adee, the second assistant.

By the time Hay took office, the war was effectively over and it had been decided to strip Spain of her overseas empire and transfer at least part of it to the United States. At the time of Hay's swearing-in, McKinley was still undecided whether to take the Philippines, but in October finally decided to do so, and Hay sent instructions to Day and the other peace commissioners to insist on it. Spain yielded, and the result was the Treaty of Paris, narrowly ratified by the Senate in February 1899 over the objections of anti-imperialists.

By the 1890s, China had become a major trading partner for Western nations, and for Japan. China lacked military muscle to resist these countries, and several, including Russia, Britain, and Germany, had carved off bits of China—some known as treaty ports—for use as trading or military bases. Within those jurisdictions, the nation in possession often gave preference to its own citizens in trade or in developing infrastructure such as railroads. Although the United States did not claim any parts of China, a third of the China trade was carried in American ships, and having an outpost near there was a major factor in deciding to retain the former Spanish colony of the Philippines in the Treaty of Paris.

Hay had been concerned about the Far East since the 1870s. As Ambassador, he had attempted to forge a common policy with the British, but the United Kingdom was willing to undertake territorial acquisition in China to guard its interests there whereas McKinley was not. In March 1898, Hay warned that Russia, Germany, and France were seeking to exclude Britain and America from the China trade, but he was disregarded by Sherman, who accepted assurances from Russia and Germany.

McKinley was of the view that equality of opportunity for American trade in China was key to success there, rather than colonial acquisitions; that Hay shared these views was one reason for his appointment as Secretary of State. Many influential Americans, seeing coastal China being divided into spheres of influence, urged McKinley to join in; still, in his annual message to Congress in December 1898, he stated that as long as Americans were not discriminated against, he saw no need for the United States to become "an actor in the scene".

As Secretary of State, it was Hay's responsibility to put together a workable China policy. He was advised by William Rockhill, an old China hand. Also influential was Charles Beresford, a British Member of Parliament who gave a number of speeches to American businessmen, met with McKinley and Hay, and in a letter to the secretary stated that "it is imperative for American interests as well as our own that the policy of the 'open door' should be maintained". Assuring that all would play on an even playing field in China would give the foreign powers little incentive to dismember the Chinese Empire through territorial acquisition.

In mid-1899, the British inspector of Chinese maritime customs, Alfred Hippisley, visited the United States. In a letter to Rockhill, a friend, he urged that the United States and other powers agree to uniform Chinese tariffs, including in the enclaves. Rockhill passed the letter on to Hay, and subsequently summarized the thinking of Hippisley and others, that there should be "an open market through China for our trade on terms of equality with all other foreigners". Hay was in agreement, but feared Senate and popular opposition, and wanted to avoid Senate ratification of a treaty. Rockhill drafted the first Open Door note, calling for equality of commercial opportunity for foreigners in China.

Hay formally issued his Open Door note on September 6, 1899. This was not a treaty, and did not require the approval of the Senate. Most of the powers had at least some caveats, and negotiations continued through the remainder of the year. On March 20, 1900, Hay announced that all powers had agreed, and he was not contradicted. Former secretary Day wrote to Hay, congratulating him, "moving at the right time and in the right manner, you have secured a diplomatic triumph in the 'open door' in China of the first importance to your country".

Little thought was given to the Chinese reaction to the Open Door note; the Chinese minister in Washington, Wu Ting-fang, did not learn of it until he read of it in the newspapers. Among those in China who opposed Western influence there was a movement in Shantung Province, in the north, that became known as the Fists of Righteous Harmony, or Boxers, after the martial arts they practiced. The Boxers were especially angered by missionaries and their converts. As late as June 1900, Rockhill dismissed the Boxers, contending that they would soon disband. By the middle of that month, the Boxers, joined by imperial troops, had cut the railroad between Peking and the coast, killed many missionaries and converts, and besieged the foreign legations. Hay faced a precarious situation; how to rescue the Americans trapped in Peking, and how to avoid giving the other powers an excuse to partition China, in an election year when there was already Democrat opposition to what they deemed American imperialism.

As American troops were sent to China to relieve the nation's legation, Hay sent a letter to foreign powers (often called the Second Open Door note), stating while the United States wanted to see lives preserved and the guilty punished, it intended that China not be dismembered. Hay issued this on July 3, 1900, suspecting that the powers were quietly making private arrangements to divide up China. Communication between the foreign legations and the outside world had been cut off, and the personnel there were falsely presumed slaughtered, but Hay realized that Minister Wu could get a message in, and Hay was able to establish communication. Hay suggested to the Chinese government that it now cooperate for its own good. When the foreign relief force, principally Japanese but including 2,000 Americans, relieved the legations and sacked Peking, China was made to pay a huge indemnity but there was no cession of land.

McKinley's vice president, Garret Hobart, had died in November 1899. Under the laws then in force, this made Hay next in line to the presidency should anything happen to McKinley. There was a presidential election in 1900, and McKinley was unanimously renominated at the Republican National Convention that year. He allowed the convention to make its own choice of running mate, and it selected Roosevelt, by then Governor of New York. Senator Hanna bitterly opposed that choice, but nevertheless raised millions for the McKinley/Roosevelt ticket, which was elected.

Hay accompanied McKinley on his nationwide train tour in mid-1901, during which both men visited California and saw the Pacific Ocean for the only times in their lives. The summer of 1901 was tragic for Hay; his older son Adelbert, who had been consul in Pretoria during the Boer War and was about to become McKinley's personal secretary, died in a fall from a New Haven hotel window.

Secretary Hay was at The Fells when McKinley was shot by Leon Czolgosz, an anarchist, on September 6 in Buffalo. With Vice President Roosevelt and much of the cabinet hastening to the bedside of McKinley, who had been operated on (it was thought successfully) soon after the shooting, Hay planned to go to Washington to manage the communication with foreign governments, but presidential secretary George Cortelyou urged him to come to Buffalo. He traveled to Buffalo on September 10; hearing on his arrival an account of the President's recovery, Hay responded that McKinley would die. He was more cheerful after visiting McKinley, giving a statement to the press, and went to Washington, as Roosevelt and other officials also dispersed. Hay was about to return to New Hampshire on the 13th, when word came that McKinley was dying. Hay remained at his office and the next morning, on the way to Buffalo, the former Rough Rider received from Hay his first communication as head of state, officially informing President Roosevelt of McKinley's death.

Hay, again next in line to the presidency, remained in Washington as McKinley's body was transported to the capital by funeral train, and stayed there as the late president was taken to Canton for interment. He had admired McKinley, describing him as "awfully like Lincoln in many respects" and wrote to a friend, "what a strange and tragic fate it has been of mine—to stand by the bier of three of my dearest friends, Lincoln, Garfield, and McKinley, three of the gentlest of men, all risen to be head of the State, and all done to death by assassins".

By letter, Hay offered his resignation to Roosevelt while the new president was still in Buffalo, amid newspaper speculation that Hay would be replaced—Garfield's Secretary of State, Blaine, had not remained long under the Arthur administration. When Hay met the funeral train in Washington, Roosevelt greeted him at the station and immediately told him he must stay on as Secretary. According to Zeitz, "Roosevelt's accidental ascendance to the presidency made John Hay an essential anachronism ... the wise elder statesman and senior member of the cabinet, he was indispensable to TR, who even today remains the youngest president ever".

The deaths of his son and of McKinley were not the only griefs Hay suffered in 1901—on September 26, John Nicolay died after a long illness, as did Hay's close friend Clarence King on Christmas Eve.

Hay's involvement in the efforts to have a canal joining the oceans in Central America went back to his time as Assistant Secretary of State under Hayes, when he served as translator for Ferdinand de Lesseps in his efforts to interest the American government in investing in his canal company. President Hayes was only interested in the idea of a canal under American control, which de Lesseps's project would not be. By the time Hay became Secretary of State, de Lesseps's project in Panama (then a Colombian province) had collapsed, as had an American-run project in Nicaragua. The 1850 Clayton–Bulwer Treaty (between the United States and Britain) forbade the United States from building a Central American canal that it exclusively controlled, and Hay, from early in his tenure, sought the removal of this restriction. But the Canadians, for whose foreign policy Britain was still available, saw the canal matter as their greatest leverage to get other disputes resolved in their favor, persuaded Salisbury not to resolve it independently. Shortly before Hay took office, Britain and the U.S. agreed to establish a Joint High Commission to adjudicate unsettled matters, which met in late 1898 but made slow progress, especially on the Canada-Alaska boundary.

The Alaska issue became less contentious in August 1899 when the Canadians accepted a provisional boundary pending final settlement. With Congress anxious to begin work on a canal bill, and increasingly likely to ignore the Clayton-Bulwer restriction, Hay and British Ambassador Julian Pauncefote began work on a new treaty in January 1900. The first Hay–Pauncefote Treaty was sent to the Senate the following month, where it met a cold reception, as the terms forbade the United States from blockading or fortifying the canal, that was to be open to all nations in wartime as in peace. The Senate Foreign Relations Committee added an amendment allowing the U.S. to fortify the canal, then in March postponed further consideration until after the 1900 election. Hay submitted his resignation, which McKinley refused. The treaty, as amended, was ratified by the Senate in December, but the British would not agree to the changes.

Despite the lack of agreement, Congress was enthusiastic about a canal, and was inclined to move forward, with or without a treaty. Authorizing legislation was slowed by discussion on whether to take the Nicaraguan or Panamanian route. Much of the negotiation of a revised treaty, allowing the U.S. to fortify the canal, took place between Hay's replacement in London, Joseph H. Choate, and the British Foreign Secretary, Lord Lansdowne, and the second Hay–Pauncefote Treaty was ratified by the Senate by a large margin on December 6, 1901.

Seeing that the Americans were likely to build a Nicaragua Canal, the owners of the defunct French company, including Philippe Bunau-Varilla, who still had exclusive rights to the Panama route, lowered their price. Beginning in early 1902, President Roosevelt became a backer of the latter route, and Congress passed legislation for it, if it could be secured within a reasonable time. In June, Roosevelt told Hay to take personal charge of the negotiations with Colombia. Later that year, Hay began talks with Colombia's acting minister in Washington, Tomás Herrán. The Hay–Herrán Treaty, granting $10 million to Colombia for the right to build a canal, plus $250,000 annually, was signed on January 22, 1903, and ratified by the United States Senate two months later. In August, however, the treaty was rejected by the Colombian Senate.

Roosevelt was minded to build the canal anyway, using an earlier treaty with Colombia that gave the U.S. transit rights in regard to the Panama Railroad. Hay predicted "an insurrection on the Isthmus [of Panama] against that regime of folly and graft ... at Bogotá". Bunau-Varilla gained meetings with both men, and assured them that a revolution, and a Panamanian government more friendly to a canal, was coming. In October, Roosevelt ordered Navy ships to be stationed near Panama. The Panamanians duly revolted in early November 1903, with Colombian interference deterred by the presence of U.S. forces. By prearrangement, Bunau-Varilla was appointed representative of the nascent nation in Washington, and quickly negotiated the Hay–Bunau-Varilla Treaty, signed on November 18, giving the United States the right to build the canal in a zone wide, over which the U.S. would exercise full jurisdiction. This was less than satisfactory to the Panamanian diplomats who arrived in Washington shortly after the signing, but they did not dare renounce it. The treaty was approved by the two nations, and work on the Panama Canal began in 1904. Hay wrote to Secretary of War Elihu Root, praising "the perfectly regular course which the President did follow" as much preferable to armed occupation of the isthmus.

Hay had met the President's father, Theodore Roosevelt, Sr., during the Civil War, and during his time at the "Tribune" came to know the adolescent "Teddy", twenty years younger than himself. Although before becoming president Roosevelt often wrote fulsome letters of praise to Secretary Hay, his letters to others then and later were less complimentary. Hay felt Roosevelt too impulsive, and privately opposed his inclusion on the ticket in 1900, though he quickly wrote a congratulatory note after the convention.

As President and Secretary of State, the two men took pains to cultivate a cordial relationship. Roosevelt read all ten volumes of the Lincoln biography and in mid-1903, wrote to Hay that by then "I have had a chance to know far more fully what a really great Secretary of State you are". Hay for his part publicly praised Roosevelt as "young, gallant, able, [and] brilliant", words that Roosevelt wrote that he hoped would be engraved on his tombstone.

Privately, and in correspondence with others, they were less generous: Hay grumbled that while McKinley would give him his full attention, Roosevelt was always busy with others, and it would be "an hour's wait for a minute's talk". Roosevelt, after Hay's death in 1905, wrote to Senator Lodge that Hay had not been "a great Secretary of State ... under me he accomplished little ... his usefulness to me was almost exclusively the usefulness of a fine figurehead". Nevertheless, when Roosevelt successfully sought election in his own right in 1904, he persuaded the aging and infirm Hay to campaign for him, and Hay gave a speech linking the administration's policies with those of Lincoln: "there is not a principle avowed by the Republican party to-day which is out of harmony with his [Lincoln's] teaching or inconsistent with his character." Kushner and Sherrill suggested that the differences between Hay and Roosevelt were more style than ideological substance.

In December 1902, the German government asked Roosevelt to arbitrate its dispute with Venezuela over unpaid debts. Hay did not think this appropriate, as Venezuela also owed the U.S. money, and quickly arranged for the International Court of Arbitration in The Hague to step in. Hay supposedly said, as final details were being worked out, "I have it all arranged. If Teddy will keep his mouth shut until tomorrow noon!" Hay and Roosevelt also differed over the composition of the Joint High Commission that was to settle the Alaska boundary dispute. The commission was to be composed of "impartial jurists" and the British and Canadians duly appointed notable judges. Roosevelt appointed politicians, including Secretary Root and Senator Lodge. Although Hay was supportive of the President's choices in public, in private he protested loudly to Roosevelt, complained by letter to his friends, and offered his resignation. Roosevelt declined it, but the incident confirmed him in his belief that Hay was too much of an Anglophile to be trusted where Britain was concerned. The American position on the boundary dispute was imposed on Canada by a 4–2 vote, with the one English judge joining the three Americans.
One incident involving Hay that benefitted Roosevelt politically was the kidnapping of Greek-American playboy Ion Perdicaris in Morocco by chieftain Mulai Ahmed er Raisuli, an opponent of Sultan Abdelaziz. Raisuli demanded a ransom, but also wanted political prisoners to be released and control of Tangier in place of the military governor. Raisuli supposed Perdicaris to be a wealthy American, and hoped United States pressure would secure his demands. In fact, Perdicaris, though born in New Jersey, had renounced his citizenship during the Civil War to avoid Confederate confiscation of property in South Carolina, and had accepted Greek naturalization, a fact not generally known until years later, but that decreased Roosevelt's appetite for military action. The sultan was ineffective in dealing with the incident, and Roosevelt considered seizing the Tangier waterfront, source of much of Abdelaziz's income, as a means of motivating him. With Raisuli's demands escalating, Hay, with Roosevelt's approval, finally cabled the consul-general in Tangier, Samuel Gummeré:

The 1904 Republican National Convention was in session, and the Speaker of the House, Joseph Cannon, its chair, read the first sentence of the cable—and only the first sentence—to the convention, electrifying what had been a humdrum coronation of Roosevelt. "The results were perfect. This was the fighting Teddy that America loved, and his frenzied supporters—and American chauvinists everywhere—roared in delight." In fact, by then the sultan had already agreed to the demands, and Perdicaris was released. What was seen as tough talk boosted Roosevelt's election chances.

Hay never fully recovered from the death of his son Adelbert, writing in 1904 to his close friend Lizzie Cameron that "the death of our boy made my wife and me old, at once and for the rest of our lives". Gale described Hay in his final years as a "saddened, slowly dying old man".

Although Hay gave speeches in support of Roosevelt, he spent much of the fall of 1904 at his New Hampshire house or with his younger brother Charles, who was ill in Boston. After the election, Roosevelt asked Hay to remain another four years. Hay asked for time to consider, but the President did not allow it, announcing to the press two days later that Hay would stay at his post. Early 1905 saw futility for Hay, as a number of treaties he had negotiated were defeated or amended by the Senate—one involving the British dominion of Newfoundland due to Senator Lodge's fears it would harm his fisherman constituents. Others, promoting arbitration, were voted down or amended because the Senate did not want to be bypassed in the settlement of international disputes.

By Roosevelt's inauguration on March 4, 1905, Hay's health was so bad that both his wife and his friend Henry Adams insisted on his going to Europe, where he could rest and get medical treatment. Presidential doctor Presley Rixey issued a statement that Hay was suffering from overwork, but in letters the secretary hinted his conviction that he did not have long to live. An eminent physician in Italy prescribed medicinal baths for Hay's heart condition, and he duly journeyed to Bad Nauheim, near Frankfurt, Germany. Kaiser Wilhelm II was among the monarchs who wrote to Hay asking him to visit, though he declined; Belgian King Leopold II succeeded in seeing him by showing up at his hotel, unannounced. Adams suggested that Hay retire while there was still enough life left in him to do so, and that Roosevelt would be delighted to act as his own Secretary of State. Hay jokingly wrote to sculptor Augustus Saint-Gaudens that "there is nothing the matter with me except old age, the Senate, and one or two other mortal maladies".

After the course of treatment, Hay went to Paris and began to take on his workload again by meeting with the French foreign minister, Théophile Delcassé. In London, King Edward VII broke protocol by meeting with Hay in a small drawing room, and Hay lunched with Whitelaw Reid, ambassador in London at last. There was not time to see all who wished to see Hay on what he knew was his final visit.

On his return to the United States, despite his family's desire to take him to New Hampshire, the secretary went to Washington to deal with departmental business and "say "Ave Caesar!" to the President", as Hay put it. He was pleased to learn that Roosevelt was well on his way to settling the Russo-Japanese War, an action for which the President would win the Nobel Peace Prize. Hay left Washington for the last time on June 23, 1905, arriving in New Hampshire the following day. He died there on July 1 of his heart ailment and complications. Hay was interred in Lake View Cemetery in Cleveland, near the grave of Garfield, in the presence of Roosevelt and many dignitaries, including Robert Lincoln.

Hay wrote some poetry while at Brown University, and more during the Civil War. In 1865, early in his Paris stay, Hay penned "Sunrise in the Place de la Concorde", a poem attacking Napoleon III for his reinstitution of the monarchy, depicting the Emperor as having been entrusted with the child Democracy by Liberty, and strangling it with his own hands. In "A Triumph of Order", set in the breakup of the Paris Commune, a boy promises soldiers that he will return from an errand to be executed with his fellow rebels. Much to their surprise, he keeps his word and shouts to them to "blaze away" as "The Chassepots tore the stout young heart,/And saved Society."

In poetry, he sought the revolutionary outcome for other nations that he believed had come to a successful conclusion in the United States. His 1871 poem, "The Prayer of the Romans", recites Italian history up to that time, with the "Risorgimento" in progress: liberty cannot be truly present until "crosier and crown pass away", when there will be "One freedom, one faith without fetters,/One republic in Italy free!" His stay in Vienna yielded "The Curse of Hungary", in which Hay foresees the end of the Austria-Hungarian Empire. After Hay's death in 1905, William Dean Howells suggested that the Europe-themed poems expressed "(now, perhaps, old-fashioned) American sympathy for all the oppressed." "Castilian Days", souvenir of Hay's time in Madrid, is a collection of seventeen essays about Spanish history and customs, first published in 1871, though several of the individual chapters appeared in "The Atlantic" in 1870. It went through eight editions in Hay's lifetime. The Spanish are depicted as afflicted by the "triple curse of crown, crozier, and sabre"—most kings and ecclesiastics are presented as useless—and Hay pins his hope in the republican movement in Spain. Gale deems "Castilian Days" "a remarkable, if biased, book of essays about Spanish civilization".

"Pike County Ballads", a grouping of six poems published (with other Hay poetry) as a book in 1871, brought him great success. Written in the dialect of Pike County, Illinois, where Hay went to school as a child, they are approximately contemporaneous with pioneering poems in similar dialect by Bret Harte and there has been debate as to which came first. The poem that brought the greatest immediate reaction was "Jim Bludso", about a boatman who is "no saint" with one wife in Mississippi and another in Illinois. Yet, when his steamboat catches fire, "He saw his duty, a dead-sure thing,—/And went for it, ther and then." Jim holds the burning steamboat against the riverbank until the last passenger gets ashore, at the cost of his life. Hay's narrator states that, "And Christ ain't a-going to be too hard/On a man that died for men." Hay's poem offended some clergymen, but was widely reprinted and even included in anthologies of verse.

"The Bread-Winners", one of the first novels to take an anti-labor perspective, was published anonymously in 1883 (published editions did not bear Hay's name until 1916) and he may have tried to disguise his writing style. The book examines two conflicts: between capital and labor, and between the "nouveau riche" and old money. In writing it, Hay was influenced by the labor unrest of the 1870s, that affected him personally, as corporations belonging to Stone, his father-in-law, were among those struck, at a time when Hay had been left in charge in Stone's absence. According to historian Scott Dalrymple, "in response, Hay proceeded to write an indictment of organized labor so scathing, so vehement, that he dared not attach his name to it."

The major character is Arthur Farnham, a wealthy Civil War veteran, likely based on Hay. Farnham, who inherited money, is without much influence in municipal politics, as his ticket is defeated in elections, symbolic of the decreasing influence of America's old-money patricians. The villain is Andrew Jackson Offitt (true name Ananias Offitt), who leads the Bread-winners, a labor organization that begins a violent general strike. Peace is restored by a group of veterans led by Farnham, and, at the end, he appears likely to marry Alice Belding, a woman of his own class.

Although unusual among the many books inspired by the labor unrest of the late 1870s in taking the perspective of the wealthy, it was the most successful of them, and was a sensation, gaining many favorable reviews. It was also attacked as an anti-labor polemic with an upper-class bias. There were many guesses as to authorship, with the supposed authors ranging from Hay's friend Henry Adams to New York Governor Grover Cleveland, and the speculation fueled sales.

Early in his presidency, Hay and Nicolay requested and received permission from Lincoln to write his biography. By 1872, Hay was "convinced that we ought to be at work on our 'Lincoln.' I don't think the time for publication has come, but the time for preparation is slipping away." Robert Lincoln in 1874 formally agreed to let Hay and Nicolay use his father's papers; by 1875, they were engaged in research. Hay and Nicolay enjoyed exclusive access to Lincoln's papers, which were not opened to other researchers until 1947. They gathered documents written by others, as well as many of the Civil War books already being published. They at rare times relied on memory, such as Nicolay's recollection of the moment at the 1860 Republican convention when Lincoln was nominated, but for much of the rest relied on research.

Hay began his part of the writing in 1876; the work was interrupted by illnesses of Hay, Nicolay, or family members, or by Hay's writing of "The Bread-Winners". By 1885, Hay had completed the chapters on Lincoln's early life, and they were submitted to Robert Lincoln for approval. Sale of the serialization rights to "The Century" magazine, edited by Hay's friend Richard Gilder, helped give the pair the impetus to bring what had become a massive project to an end.

The published work, "Abraham Lincoln: A History", alternates parts in which Lincoln is at center with discussions of contextual matters, such as legislative events or battles. The first serial installment, published in November 1886, received positive reviews. When the ten-volume set emerged in 1890, it was not sold in bookstores, but instead door-to-door, then a common practice. Despite a price of $50, and the fact that a good part of the work had been serialized, five thousand copies were quickly sold. The books helped forge the modern view of Lincoln as great war leader, against competing narratives that gave more credit to subordinates such as Seward. According to historian Joshua Zeitz, "it is easy to forget how widely underrated Lincoln the president and Lincoln the man were at the time of his death and how successful Hay and Nicolay were in elevating his place in the nation's collective historical memory."

In 1902, Hay wrote that when he died, "I shall not be much missed except by my wife." Nevertheless, due to his premature death at age 66, he was survived by most of his friends. These included Adams, who although he blamed the pressures of Hay's office, where he was badgered by Roosevelt and many senators, for the Secretary of State's death, admitted that Hay had remained in the position because he feared being bored. He memorialized his friend in the final pages of his autobiographical "The Education of Henry Adams": with Hay's death, his own education had ended.

Gale pointed out that Hay "accomplished a great deal in the realm of international statesmanship, and the world may be a better place because of his efforts as secretary of state ... the man was a scintillating ambassador". Yet, Gale felt, any assessment of Hay must include negatives as well, that after his marriage to the wealthy Clara Stone, Hay "allowed his deep-seated love of ease triumph over his Middle Western devotion to work and a fair shake for all." Despite his literary accomplishments, Hay "was often lazy. His first poetry was his best."

Taliaferro suggests that "if Hay put any ... indelible stamp on history, perhaps it was that he demonstrated how the United States ought to comport itself. He, not Roosevelt, was the adult in charge when the nation and the State Department attained global maturity." He quotes John St. Loe Strachey, "All that the world saw was a great gentleman and a great statesman doing his work for the State and for the President with perfect taste, perfect good sense, and perfect good humour".
Hay's efforts to shape Lincoln's image increased his own prominence and reputation in making his association (and that of Nicolay) with the assassinated president ever more remarkable and noteworthy. According to Zeitz, "the greater Lincoln grew in death, the greater they grew for having known him so well, and so intimately, in life. Everyone wanted to know them if only to ask what it had been like—what "he" had been like." Their answer to that, expressed in ten volumes of biography, Gale wrote, "has been incredibly influential". In 1974, Lincoln scholar Roy P. Basler stated that later biographers such as Carl Sandburg did not "ma[k]e revisions of the essential story told by N.[icolay] & H.[ay]. Zeitz concurs, "Americans today understand Abraham Lincoln much as Nicolay and Hay hoped that they would."

Hay brought about more than 50 treaties, including the Canal-related treaties, and settlement of the Samoan dispute, as a result of which the United States secured what became known as American Samoa. In 1900, Hay negotiated a treaty with Denmark for the cession of the Danish West Indies. That treaty failed in the Danish parliament on a tied vote.

In 1923 Mount Hay, also known as "Boundary Peak 167" on the Canada–United States border, was named after John Hay in recognition of his role in negotiating the US-Canada treaty resulting in the Alaska Boundary Tribunal. Brown University's John Hay Library is named for that prominent alumnus. Hay's New Hampshire estate has been conserved by various organizations. Although he and his family never lived there (Hay died while it was under construction), the Hay-McKinney House, home to the Cleveland History Center and thousands of artifacts, serves to remind Clevelanders of John Hay's lengthy service. During World War II the Liberty ship was built in Panama City, Florida, and named in his honor. Camp John Hay a United States military base established in 1903 in Baguio City, Philippines was named for John Hay, and the base name was maintained by the Philippine government even after its 1991 turnover to Philippine authorities.

According to historian Lewis L. Gould, in his account of McKinley's presidency,


Books

Journals and other sources




</doc>
<doc id="16808" url="https://en.wikipedia.org/wiki?curid=16808" title="King Arthur">
King Arthur

King Arthur was a legendary British leader who, according to medieval histories and romances, led the defence of Britain against Saxon invaders in the late 5th and early 6th centuries. The details of Arthur's story are mainly composed of folklore and literary invention, and his historical existence is debated and disputed by modern historians. The sparse historical background of Arthur is gleaned from various sources, including the "Annales Cambriae", the "Historia Brittonum", and the writings of Gildas. Arthur's name also occurs in early poetic sources such as "Y Gododdin".

Arthur is a central figure in the legends making up the Matter of Britain. The legendary Arthur developed as a figure of international interest largely through the popularity of Geoffrey of Monmouth's fanciful and imaginative 12th-century "Historia Regum Britanniae" ("History of the Kings of Britain"). In some Welsh and Breton tales and poems that date from before this work, Arthur appears either as a great warrior defending Britain from human and supernatural enemies or as a magical figure of folklore, sometimes associated with the Welsh otherworld Annwn. How much of Geoffrey's "Historia" (completed in 1138) was adapted from such earlier sources, rather than invented by Geoffrey himself, is unknown.

Although the themes, events and characters of the Arthurian legend varied widely from text to text, and there is no one canonical version, Geoffrey's version of events often served as the starting point for later stories. Geoffrey depicted Arthur as a king of Britain who defeated the Saxons and established a vast empire. Many elements and incidents that are now an integral part of the Arthurian story appear in Geoffrey's "Historia", including Arthur's father Uther Pendragon, the magician Merlin, Arthur's wife Guinevere, the sword Excalibur, Arthur's conception at Tintagel, his final battle against Mordred at Camlann, and final rest in Avalon. The 12th-century French writer Chrétien de Troyes, who added Lancelot and the Holy Grail to the story, began the genre of Arthurian romance that became a significant strand of medieval literature. In these French stories, the narrative focus often shifts from King Arthur himself to other characters, such as various Knights of the Round Table.

Arthurian literature thrived during the Middle Ages but waned in the centuries that followed until it experienced a major resurgence in the 19th century. In the 21st century, the legend lives on, not only in literature but also in adaptations for theatre, film, television, comics and other media.

The historical basis for King Arthur has long been debated by scholars. One school of thought, citing entries in the "Historia Brittonum" ("History of the Britons") and "Annales Cambriae" ("Welsh Annals"), sees Arthur as a genuine historical figure, a Romano-British leader who fought against the invading Anglo-Saxons some time in the late 5th to early 6th century. The "Historia Brittonum", a 9th-century Latin historical compilation attributed in some late manuscripts to a Welsh cleric called Nennius, contains the first datable mention of King Arthur, listing twelve battles that Arthur fought. These culminate in the Battle of Badon, where he is said to have single-handedly killed 960 men. Recent studies, however, question the reliability of the "Historia Brittonum".

The other text that seems to support the case for Arthur's historical existence is the 10th-century "Annales Cambriae", which also link Arthur with the Battle of Badon. The "Annales" date this battle to 516–518, and also mention the Battle of Camlann, in which Arthur and Medraut (Mordred) were both killed, dated to 537–539. These details have often been used to bolster confidence in the "Historia"<nowiki>'</nowiki>s account and to confirm that Arthur really did fight at Badon. Problems have been identified, however, with using this source to support the "Historia Brittonum"'s account. The latest research shows that the "Annales Cambriae" was based on a chronicle begun in the late 8th century in Wales. Additionally, the complex textual history of the "Annales Cambriae" precludes any certainty that the Arthurian annals were added to it even that early. They were more likely added at some point in the 10th century and may never have existed in any earlier set of annals. The Badon entry probably derived from the "Historia Brittonum".

This lack of convincing early evidence is the reason many recent historians exclude Arthur from their accounts of sub-Roman Britain. In the view of historian Thomas Charles-Edwards, "at this stage of the enquiry, one can only say that there may well have been an historical Arthur [but ...] the historian can as yet say nothing of value about him". These modern admissions of ignorance are a relatively recent trend; earlier generations of historians were less sceptical. The historian John Morris made the putative reign of Arthur the organising principle of his history of sub-Roman Britain and Ireland, "The Age of Arthur" (1973). Even so, he found little to say about a historical Arthur.

Partly in reaction to such theories, another school of thought emerged which argued that Arthur had no historical existence at all. Morris's "Age of Arthur" prompted the archaeologist Nowell Myres to observe that "no figure on the borderline of history and mythology has wasted more of the historian's time". Gildas' 6th-century polemic "De Excidio et Conquestu Britanniae" ("On the Ruin and Conquest of Britain"), written within living memory of Badon, mentions the battle but does not mention Arthur. Arthur is not mentioned in the "Anglo-Saxon Chronicle" or named in any surviving manuscript written between 400 and 820. He is absent from Bede's early-8th-century "Ecclesiastical History of the English People", another major early source for post-Roman history that mentions Badon. The historian David Dumville wrote: "I think we can dispose of him [Arthur] quite briefly. He owes his place in our history books to a 'no smoke without fire' school of thought ... The fact of the matter is that there is no historical evidence about Arthur; we must reject him from our histories and, above all, from the titles of our books."

Some scholars argue that Arthur was originally a fictional hero of folklore—or even a half-forgotten Celtic deity—who became credited with real deeds in the distant past. They cite parallels with figures such as the Kentish Hengist and Horsa, who may be totemic horse-gods that later became historicised. Bede ascribed to these legendary figures a historical role in the 5th-century Anglo-Saxon conquest of eastern Britain. It is not even certain that Arthur was considered a king in the early texts. Neither the "Historia" nor the "Annales" calls him ""rex"": the former calls him instead ""dux bellorum"" (leader of battles) and ""miles"" (soldier).

Historical documents for the post-Roman period are scarce, so a definitive answer to the question of Arthur's historical existence is unlikely. Sites and places have been identified as "Arthurian" since the 12th century, but archaeology can confidently reveal names only through inscriptions found in secure contexts. The so-called "Arthur stone", discovered in 1998 among the ruins at Tintagel Castle in Cornwall in securely dated 6th-century contexts, created a brief stir but proved irrelevant. Other inscriptional evidence for Arthur, including the Glastonbury cross, is tainted with the suggestion of forgery. Although several historical figures have been proposed as the basis for Arthur, no convincing evidence for these identifications has emerged.

The origin of the Welsh name "Arthur" remains a matter of debate. The most widely accepted etymology derives it from the Roman "nomen gentile" (family name) Artorius. Artorius itself is of obscure and contested etymology, but possibly of Messapian or Etruscan origin. Linguist Stephan Zimmer suggests Artorius possibly had a Celtic origin, being a Latinization of a hypothetical name "*Artorījos", in turn derived from an older patronym" *Arto-rīg-ios", meaning "son of the bear/warrior-king". This patronym is unattested, but the root, "*arto-rīg", "bear/warrior-king", is the source of the Old Irish personal name "Artrí". Some scholars have suggested it is relevant to this debate that the legendary King Arthur's name only appears as "Arthur" or "Arturus" in early Latin Arthurian texts, never as "Artōrius" (though Classical Latin Artōrius became Arturius in some Vulgar Latin dialects). However, this may not say anything about the origin of the name "Arthur", as "Artōrius" would regularly become "Art(h)ur" when borrowed into Welsh.

Another commonly proposed derivation of "Arthur" from Welsh "arth" "bear" + "(g)wr" "man" (earlier "*Arto-uiros" in Brittonic) is not accepted by modern scholars for phonological and orthographic reasons. Notably, a Brittonic compound name "*Arto-uiros" should produce Old Welsh "*Artgur" (where "u" represents the short vowel /u/) and Middle/Modern Welsh "*Arthwr", rather than "Arthur" (where "u" is a long vowel /ʉː/). In Welsh poetry the name is always spelled "Arthur" and is exclusively rhymed with words ending in "-ur"—never words ending in "-wr"—which confirms that the second element cannot be "[g]wr" "man".

An alternative theory, which has gained only limited acceptance among professional scholars, derives the name Arthur from Arcturus, the brightest star in the constellation Boötes, near Ursa Major or the Great Bear. Classical Latin "Arcturus" would also have become "Art(h)ur" when borrowed into Welsh, and its brightness and position in the sky led people to regard it as the "guardian of the bear" (which is the meaning of the name in Ancient Greek) and the "leader" of the other stars in Boötes.

The familiar literary persona of Arthur began with Geoffrey of Monmouth's pseudo-historical "Historia Regum Britanniae" ("History of the Kings of Britain"), written in the 1130s. The textual sources for Arthur are usually divided into those written before Geoffrey's "Historia" (known as pre-Galfridian texts, from the Latin form of Geoffrey, "Galfridus") and those written afterwards, which could not avoid his influence (Galfridian, or post-Galfridian, texts).

The earliest literary references to Arthur come from Welsh and Breton sources. There have been few attempts to define the nature and character of Arthur in the pre-Galfridian tradition as a whole, rather than in a single text or text/story-type. A 2007 academic survey that does attempt this by Caitlin Green identifies three key strands to the portrayal of Arthur in this earliest material. The first is that he was a peerless warrior who functioned as the monster-hunting protector of Britain from all internal and external threats. Some of these are human threats, such as the Saxons he fights in the "Historia Brittonum", but the majority are supernatural, including giant cat-monsters, destructive divine boars, dragons, dogheads, giants, and witches. The second is that the pre-Galfridian Arthur was a figure of folklore (particularly topographic or onomastic folklore) and localised magical wonder-tales, the leader of a band of superhuman heroes who live in the wilds of the landscape. The third and final strand is that the early Welsh Arthur had a close connection with the Welsh Otherworld, Annwn. On the one hand, he launches assaults on Otherworldly fortresses in search of treasure and frees their prisoners. On the other, his warband in the earliest sources includes former pagan gods, and his wife and his possessions are clearly Otherworldly in origin.

One of the most famous Welsh poetic references to Arthur comes in the collection of heroic death-songs known as "Y Gododdin" ("The Gododdin"), attributed to 6th-century poet Aneirin. One stanza praises the bravery of a warrior who slew 300 enemies, but says that despite this, "he was no Arthur" – that is, his feats cannot compare to the valour of Arthur. "Y Gododdin" is known only from a 13th-century manuscript, so it is impossible to determine whether this passage is original or a later interpolation, but John Koch's view that the passage dates from a 7th-century or earlier version is regarded as unproven; 9th- or 10th-century dates are often proposed for it. Several poems attributed to Taliesin, a poet said to have lived in the 6th century, also refer to Arthur, although these all probably date from between the 8th and 12th centuries. They include "Kadeir Teyrnon" ("The Chair of the Prince"), which refers to "Arthur the Blessed"; "Preiddeu Annwn" ("The Spoils of Annwn"), which recounts an expedition of Arthur to the Otherworld; and "Marwnat vthyr pen[dragon]" ("The Elegy of Uther Pen[dragon]"), which refers to Arthur's valour and is suggestive of a father-son relationship for Arthur and Uther that pre-dates Geoffrey of Monmouth.

Other early Welsh Arthurian texts include a poem found in the "Black Book of Carmarthen", "Pa gur yv y porthaur?" ("What man is the gatekeeper?"). This takes the form of a dialogue between Arthur and the gatekeeper of a fortress he wishes to enter, in which Arthur recounts the names and deeds of himself and his men, notably Cei (Kay) and Bedwyr (Bedivere). The Welsh prose tale "Culhwch and Olwen" (), included in the modern "Mabinogion" collection, has a much longer list of more than 200 of Arthur's men, though Cei and Bedwyr again take a central place. The story as a whole tells of Arthur helping his kinsman Culhwch win the hand of Olwen, daughter of Ysbaddaden Chief-Giant, by completing a series of apparently impossible tasks, including the hunt for the great semi-divine boar Twrch Trwyth. The 9th-century "Historia Brittonum" also refers to this tale, with the boar there named Troy(n)t. Finally, Arthur is mentioned numerous times in the Welsh Triads, a collection of short summaries of Welsh tradition and legend which are classified into groups of three linked characters or episodes to assist recall. The later manuscripts of the Triads are partly derivative from Geoffrey of Monmouth and later continental traditions, but the earliest ones show no such influence and are usually agreed to refer to pre-existing Welsh traditions. Even in these, however, Arthur's court has started to embody legendary Britain as a whole, with "Arthur's Court" sometimes substituted for "The Island of Britain" in the formula "Three XXX of the Island of Britain". While it is not clear from the "Historia Brittonum" and the "Annales Cambriae" that Arthur was even considered a king, by the time "Culhwch and Olwen" and the Triads were written he had become "Penteyrnedd yr Ynys hon", "Chief of the Lords of this Island", the overlord of Wales, Cornwall and the North.

In addition to these pre-Galfridian Welsh poems and tales, Arthur appears in some other early Latin texts besides the "Historia Brittonum" and the "Annales Cambriae". In particular, Arthur features in a number of well-known "vitae" ("Lives") of post-Roman saints, none of which are now generally considered to be reliable historical sources (the earliest probably dates from the 11th century). According to the "Life of Saint Gildas", written in the early 12th century by Caradoc of Llancarfan, Arthur is said to have killed Gildas' brother Hueil and to have rescued his wife Gwenhwyfar from Glastonbury. In the "Life of Saint Cadoc", written around 1100 or a little before by Lifris of Llancarfan, the saint gives protection to a man who killed three of Arthur's soldiers, and Arthur demands a herd of cattle as "wergeld" for his men. Cadoc delivers them as demanded, but when Arthur takes possession of the animals, they turn into bundles of ferns. Similar incidents are described in the medieval biographies of Carannog, Padarn, and Eufflam, probably written around the 12th century. A less obviously legendary account of Arthur appears in the "Legenda Sancti Goeznovii", which is often claimed to date from the early 11th century (although the earliest manuscript of this text dates from the 15th century and the text is now dated to the late 12th to early 13th century). Also important are the references to Arthur in William of Malmesbury's "De Gestis Regum Anglorum" and Herman's "De Miraculis Sanctae Mariae Laudensis", which together provide the first certain evidence for a belief that Arthur was not actually dead and would at some point return, a theme that is often revisited in post-Galfridian folklore.

Geoffrey of Monmouth's "Historia Regum Britanniae", completed , contains the first narrative account of Arthur's life. This work is an imaginative and fanciful account of British kings from the legendary Trojan exile Brutus to the 7th-century Welsh king Cadwallader. Geoffrey places Arthur in the same post-Roman period as do "Historia Brittonum" and "Annales Cambriae". He incorporates Arthur's father Uther Pendragon, his magician advisor Merlin, and the story of Arthur's conception, in which Uther, disguised as his enemy Gorlois by Merlin's magic, sleeps with Gorlois's wife Igerna (Igraine) at Tintagel, and she conceives Arthur. On Uther's death, the fifteen-year-old Arthur succeeds him as King of Britain and fights a series of battles, similar to those in the "Historia Brittonum", culminating in the Battle of Bath. He then defeats the Picts and Scots before creating an Arthurian empire through his conquests of Ireland, Iceland and the Orkney Islands. After twelve years of peace, Arthur sets out to expand his empire once more, taking control of Norway, Denmark and Gaul. Gaul is still held by the Roman Empire when it is conquered, and Arthur's victory leads to a further confrontation with Rome. Arthur and his warriors, including Kaius (Kay), Beduerus (Bedivere) and Gualguanus (Gawain), defeat the Roman emperor Lucius Tiberius in Gaul but, as he prepares to march on Rome, Arthur hears that his nephew Modredus (Mordred)—whom he had left in charge of Britain—has married his wife Guenhuuara (Guinevere) and seized the throne. Arthur returns to Britain and defeats and kills Modredus on the river Camblam in Cornwall, but he is mortally wounded. He hands the crown to his kinsman Constantine and is taken to the isle of Avalon to be healed of his wounds, never to be seen again.

How much of this narrative was Geoffrey's own invention is open to debate. He seems to have made use of the list of Arthur's twelve battles against the Saxons found in the 9th-century "Historia Brittonum", along with the battle of Camlann from the "Annales Cambriae" and the idea that Arthur was still alive. Arthur's status as the king of all Britain seems to be borrowed from pre-Galfridian tradition, being found in "Culhwch and Olwen", the Welsh Triads, and the saints' lives. Finally, Geoffrey borrowed many of the names for Arthur's possessions, close family, and companions from the pre-Galfridian Welsh tradition, including Kaius (Cei), Beduerus (Bedwyr), Guenhuuara (Gwenhwyfar), Uther (Uthyr) and perhaps also Caliburnus (Caledfwlch), the latter becoming Excalibur in subsequent Arthurian tales. However, while names, key events, and titles may have been borrowed, Brynley Roberts has argued that "the Arthurian section is Geoffrey's literary creation and it owes nothing to prior narrative." Geoffrey makes the Welsh Medraut into the villainous Modredus, but there is no trace of such a negative character for this figure in Welsh sources until the 16th century. There have been relatively few modern attempts to challenge the notion that the "Historia Regum Britanniae" is primarily Geoffrey's own work, with scholarly opinion often echoing William of Newburgh's late-12th-century comment that Geoffrey "made up" his narrative, perhaps through an "inordinate love of lying". Geoffrey Ashe is one dissenter from this view, believing that Geoffrey's narrative is partially derived from a lost source telling of the deeds of a 5th-century British king named Riotamus, this figure being the original Arthur, although historians and Celticists have been reluctant to follow Ashe in his conclusions.

Whatever his sources may have been, the immense popularity of Geoffrey's "Historia Regum Britanniae" cannot be denied. Well over 200 manuscript copies of Geoffrey's Latin work are known to have survived, as well as translations into other languages. For example, 60 manuscripts are extant containing the "Brut y Brenhinedd", Welsh-language versions of the "Historia", the earliest of which were created in the 13th century. The old notion that some of these Welsh versions actually underlie Geoffrey's "Historia", advanced by antiquarians such as the 18th-century Lewis Morris, has long since been discounted in academic circles. As a result of this popularity, Geoffrey's "Historia Regum Britanniae" was enormously influential on the later medieval development of the Arthurian legend. While it was not the only creative force behind Arthurian romance, many of its elements were borrowed and developed (e.g., Merlin and the final fate of Arthur), and it provided the historical framework into which the romancers' tales of magical and wonderful adventures were inserted.

The popularity of Geoffrey's "Historia" and its other derivative works (such as Wace's "Roman de Brut") gave rise to a significant numbers of new Arthurian works in continental Europe during the 12th and 13th centuries, particularly in France. It was not, however, the only Arthurian influence on the developing "Matter of Britain". There is clear evidence that Arthur and Arthurian tales were familiar on the Continent before Geoffrey's work became widely known (see for example, the Modena Archivolt), and "Celtic" names and stories not found in Geoffrey's "Historia" appear in the Arthurian romances. From the perspective of Arthur, perhaps the most significant effect of this great outpouring of new Arthurian story was on the role of the king himself: much of this 12th-century and later Arthurian literature centres less on Arthur himself than on characters such as Lancelot and Guinevere, Percival, Galahad, Gawain, Ywain, and Tristan and Iseult. Whereas Arthur is very much at the centre of the pre-Galfridian material and Geoffrey's "Historia" itself, in the romances he is rapidly sidelined. His character also alters significantly. In both the earliest materials and Geoffrey he is a great and ferocious warrior, who laughs as he personally slaughters witches and giants and takes a leading role in all military campaigns, whereas in the continental romances he becomes the "roi fainéant", the "do-nothing king", whose "inactivity and acquiescence constituted a central flaw in his otherwise ideal society". Arthur's role in these works is frequently that of a wise, dignified, even-tempered, somewhat bland, and occasionally feeble monarch. So, he simply turns pale and silent when he learns of Lancelot's affair with Guinevere in the "Mort Artu", whilst in "Yvain, the Knight of the Lion", he is unable to stay awake after a feast and has to retire for a nap. Nonetheless, as Norris J. Lacy has observed, whatever his faults and frailties may be in these Arthurian romances, "his prestige is never—or almost never—compromised by his personal weaknesses ... his authority and glory remain intact."

Arthur and his retinue appear in some of the "Lais" of Marie de France, but it was the work of another French poet, Chrétien de Troyes, that had the greatest influence with regard to the development of Arthur's character and legend. Chrétien wrote five Arthurian romances between and 1190. "Erec and Enide" and "Cligès" are tales of courtly love with Arthur's court as their backdrop, demonstrating the shift away from the heroic world of the Welsh and Galfridian Arthur, while "Yvain, the Knight of the Lion", features Yvain and Gawain in a supernatural adventure, with Arthur very much on the sidelines and weakened. However, the most significant for the development of the Arthurian legend are "Lancelot, the Knight of the Cart", which introduces Lancelot and his adulterous relationship with Arthur's queen Guinevere, extending and popularising the recurring theme of Arthur as a cuckold, and "Perceval, the Story of the Grail", which introduces the Holy Grail and the Fisher King and which again sees Arthur having a much reduced role. Chrétien was thus "instrumental both in the elaboration of the Arthurian legend and in the establishment of the ideal form for the diffusion of that legend", and much of what came after him in terms of the portrayal of Arthur and his world built upon the foundations he had laid. "Perceval", although unfinished, was particularly popular: four separate continuations of the poem appeared over the next half century, with the notion of the Grail and its quest being developed by other writers such as Robert de Boron, a fact that helped accelerate the decline of Arthur in continental romance. Similarly, Lancelot and his cuckolding of Arthur with Guinevere became one of the classic motifs of the Arthurian legend, although the Lancelot of the prose "Lancelot" () and later texts was a combination of Chrétien's character and that of Ulrich von Zatzikhoven's "Lanzelet". Chrétien's work even appears to feed back into Welsh Arthurian literature, with the result that the romance Arthur began to replace the heroic, active Arthur in Welsh literary tradition. Particularly significant in this development were the three Welsh Arthurian romances, which are closely similar to those of Chrétien, albeit with some significant differences: "Owain, or the Lady of the Fountain" is related to Chrétien's "Yvain"; "Geraint and Enid", to "Erec and Enide"; and "Peredur son of Efrawg", to "Perceval".

Up to , continental Arthurian romance was expressed primarily through poetry; after this date the tales began to be told in prose. The most significant of these 13th-century prose romances was the Vulgate Cycle (also known as the Lancelot-Grail Cycle), a series of five Middle French prose works written in the first half of that century. These works were the "Estoire del Saint Grail", the "Estoire de Merlin", the "Lancelot propre" (or Prose "Lancelot", which made up half the entire Vulgate Cycle on its own), the "Queste del Saint Graal" and the "Mort Artu", which combine to form the first coherent version of the entire Arthurian legend. The cycle continued the trend towards reducing the role played by Arthur in his own legend, partly through the introduction of the character of Galahad and an expansion of the role of Merlin. It also made Mordred the result of an incestuous relationship between Arthur and his sister Morgause and established the role of Camelot, first mentioned in passing in Chrétien's "Lancelot", as Arthur's primary court. This series of texts was quickly followed by the Post-Vulgate Cycle (), of which the "Suite du Merlin" is a part, which greatly reduced the importance of Lancelot's affair with Guinevere but continued to sideline Arthur, and to focus more on the Grail quest. As such, Arthur became even more of a relatively minor character in these French prose romances; in the Vulgate itself he only figures significantly in the "Estoire de Merlin" and the "Mort Artu". During this period, Arthur was made one of the Nine Worthies, a group of three pagan, three Jewish and three Christian exemplars of chivalry. The Worthies were first listed in Jacques de Longuyon's "Voeux du Paon" in 1312, and subsequently became a common subject in literature and art.

The development of the medieval Arthurian cycle and the character of the "Arthur of romance" culminated in "Le Morte d'Arthur", Thomas Malory's retelling of the entire legend in a single work in English in the late 15th century. Malory based his book—originally titled "The Whole Book of King Arthur and of His Noble Knights of the Round Table"—on the various previous romance versions, in particular the Vulgate Cycle, and appears to have aimed at creating a comprehensive and authoritative collection of Arthurian stories. Perhaps as a result of this, and the fact that "Le Morte D'Arthur" was one of the earliest printed books in England, published by William Caxton in 1485, most later Arthurian works are derivative of Malory's. 

The end of the Middle Ages brought with it a waning of interest in King Arthur. Although Malory's English version of the great French romances was popular, there were increasing attacks upon the truthfulness of the historical framework of the Arthurian romances – established since Geoffrey of Monmouth's time – and thus the legitimacy of the whole Matter of Britain. So, for example, the 16th-century humanist scholar Polydore Vergil famously rejected the claim that Arthur was the ruler of a post-Roman empire, found throughout the post-Galfridian medieval "chronicle tradition", to the horror of Welsh and English antiquarians. Social changes associated with the end of the medieval period and the Renaissance also conspired to rob the character of Arthur and his associated legend of some of their power to enthrall audiences, with the result that 1634 saw the last printing of Malory's "Le Morte d'Arthur" for nearly 200 years. King Arthur and the Arthurian legend were not entirely abandoned, but until the early 19th century the material was taken less seriously and was often used simply as a vehicle for allegories of 17th- and 18th-century politics. Thus Richard Blackmore's epics "Prince Arthur" (1695) and "King Arthur" (1697) feature Arthur as an allegory for the struggles of William III against James II. Similarly, the most popular Arthurian tale throughout this period seems to have been that of Tom Thumb, which was told first through chapbooks and later through the political plays of Henry Fielding; although the action is clearly set in Arthurian Britain, the treatment is humorous and Arthur appears as a primarily comedic version of his romance character. John Dryden's masque "King Arthur" is still performed, largely thanks to Henry Purcell's music, though seldom unabridged.

In the early 19th century, medievalism, Romanticism, and the Gothic Revival reawakened interest in Arthur and the medieval romances. A new code of ethics for 19th-century gentlemen was shaped around the chivalric ideals embodied in the "Arthur of romance". This renewed interest first made itself felt in 1816, when Malory's "Le Morte d'Arthur" was reprinted for the first time since 1634. Initially, the medieval Arthurian legends were of particular interest to poets, inspiring, for example, William Wordsworth to write "The Egyptian Maid" (1835), an allegory of the Holy Grail. Pre-eminent among these was Alfred Tennyson, whose first Arthurian poem "The Lady of Shalott" was published in 1832. Arthur himself played a minor role in some of these works, following in the medieval romance tradition. Tennyson's Arthurian work reached its peak of popularity with "Idylls of the King", however, which reworked the entire narrative of Arthur's life for the Victorian era. It was first published in 1859 and sold 10,000 copies within the first week. In the "Idylls", Arthur became a symbol of ideal manhood who ultimately failed, through human weakness, to establish a perfect kingdom on earth. Tennyson's works prompted a large number of imitators, generated considerable public interest in the legends of Arthur and the character himself, and brought Malory's tales to a wider audience. Indeed, the first modernisation of Malory's great compilation of Arthur's tales was published in 1862, shortly after "Idylls" appeared, and there were six further editions and five competitors before the century ended.

This interest in the "Arthur of romance" and his associated stories continued through the 19th century and into the 20th, and influenced poets such as William Morris and Pre-Raphaelite artists including Edward Burne-Jones. Even the humorous tale of Tom Thumb, which had been the primary manifestation of Arthur's legend in the 18th century, was rewritten after the publication of "Idylls". While Tom maintained his small stature and remained a figure of comic relief, his story now included more elements from the medieval Arthurian romances and Arthur is treated more seriously and historically in these new versions. The revived Arthurian romance also proved influential in the United States, with such books as Sidney Lanier's "The Boy's King Arthur" (1880) reaching wide audiences and providing inspiration for Mark Twain's satiric "A Connecticut Yankee in King Arthur's Court" (1889). Although the 'Arthur of romance' was sometimes central to these new Arthurian works (as he was in Burne-Jones's "The Sleep of Arthur in Avalon", 1881-1898), on other occasions he reverted to his medieval status and is either marginalized or even missing entirely, with Wagner's Arthurian operas providing a notable instance of the latter. Furthermore, the revival of interest in Arthur and the Arthurian tales did not continue unabated. By the end of the 19th century, it was confined mainly to Pre-Raphaelite imitators, and it could not avoid being affected by World War I, which damaged the reputation of chivalry and thus interest in its medieval manifestations and Arthur as chivalric role model. The romance tradition did, however, remain sufficiently powerful to persuade Thomas Hardy, Laurence Binyon and John Masefield to compose Arthurian plays, and T. S. Eliot alludes to the Arthur myth (but not Arthur) in his poem "The Waste Land", which mentions the Fisher King.

In the latter half of the 20th century, the influence of the romance tradition of Arthur continued, through novels such as T. H. White's "The Once and Future King" (1958) and Marion Zimmer Bradley's "The Mists of Avalon" (1982) in addition to comic strips such as "Prince Valiant" (from 1937 onward). Tennyson had reworked the romance tales of Arthur to suit and comment upon the issues of his day, and the same is often the case with modern treatments too. Bradley's tale, for example, takes a feminist approach to Arthur and his legend, in contrast to the narratives of Arthur found in medieval materials, and American authors often rework the story of Arthur to be more consistent with values such as equality and democracy. In John Cowper Powys's "" (1951), set in Wales in 499, just prior to the Saxon invasion, Arthur, the Emperor of Britain, is only a minor character, whereas Myrddin (Merlin) and Nineue, Tennyson's Vivien, are major figures. Myrddin's disappearance at the end of the novel is "in the tradition of magical hibernation when the king or mage leaves his people for some island or cave to return either at a more propitious or more dangerous time" (see King Arthur's messianic return). Powys's earlier novel, "A Glastonbury Romance" (1932) is concerned with both the Holy Grail and the legend that Arthur is buried at Glastonbury.

The romance Arthur has become popular in film and theatre as well. T. H. White's novel was adapted into the Lerner and Loewe stage musical "Camelot" (1960) and Walt Disney's animated film "The Sword in the Stone" (1963); "Camelot", with its focus on the love of Lancelot and Guinevere and the cuckolding of Arthur, was itself made into a film of the same name in 1967. The romance tradition of Arthur is particularly evident and in critically respected films like Robert Bresson's "Lancelot du Lac" (1974), Éric Rohmer's "Perceval le Gallois" (1978) and John Boorman's "Excalibur" (1981); it is also the main source of the material used in the Arthurian spoof "Monty Python and the Holy Grail" (1975).

Retellings and reimaginings of the romance tradition are not the only important aspect of the modern legend of King Arthur. Attempts to portray Arthur as a genuine historical figure of , stripping away the "romance", have also emerged. As Taylor and Brewer have noted, this return to the medieval "chronicle tradition" of Geoffrey of Monmouth and the "Historia Brittonum" is a recent trend which became dominant in Arthurian literature in the years following the outbreak of the Second World War, when Arthur's legendary resistance to Germanic enemies struck a chord in Britain. Clemence Dane's series of radio plays, "The Saviours" (1942), used a historical Arthur to embody the spirit of heroic resistance against desperate odds, and Robert Sherriff's play "The Long Sunset" (1955) saw Arthur rallying Romano-British resistance against the Germanic invaders. This trend towards placing Arthur in a historical setting is also apparent in historical and fantasy novels published during this period. In recent years the portrayal of Arthur as a real hero of the 5th century has also made its way into film versions of the Arthurian legend, most notably the TV series' "Arthur of the Britons" (1972–73) and "The Legend of King Arthur" (1979), and the feature films "King Arthur" (2004) and "The Last Legion" (2007).

Arthur has also been used as a model for modern-day behaviour. In the 1930s, the Order of the Fellowship of the Knights of the Round Table was formed in Britain to promote Christian ideals and Arthurian notions of medieval chivalry. In the United States, hundreds of thousands of boys and girls joined Arthurian youth groups, such as the Knights of King Arthur, in which Arthur and his legends were promoted as wholesome exemplars. However, Arthur's diffusion within modern culture goes beyond such obviously Arthurian endeavours, with Arthurian names being regularly attached to objects, buildings, and places. As Norris J. Lacy has observed, "The popular notion of Arthur appears to be limited, not surprisingly, to a few motifs and names, but there can be no doubt of the extent to which a legend born many centuries ago is profoundly embedded in modern culture at every level."





</doc>
<doc id="16838" url="https://en.wikipedia.org/wiki?curid=16838" title="Khalid al-Mihdhar">
Khalid al-Mihdhar

Khalid Muhammad Abdallah al-Mihdhar (, ; also transliterated as Almihdhar) (May 16, 1975 – September 11, 2001) was a Saudi Arabian terrorist. He was one of the five hijackers of American Airlines Flight 77, which was flown into the Pentagon as part of the September 11 attacks.

Mihdhar was born in Saudi Arabia and fought with the Bosnian mujahideen during the Bosnian War of the 1990s. In early 1999, he traveled to Afghanistan where, as an experienced and respected jihadist, he was selected by Osama bin Laden to participate in the attacks. Mihdhar arrived in California with fellow hijacker Nawaf al-Hazmi in January 2000, after traveling to Malaysia for the Kuala Lumpur al-Qaeda Summit. At this point, the CIA was aware of Mihdhar, and he was photographed in Malaysia with another al-Qaeda member who was involved in the USS "Cole" bombing. The CIA did not inform the FBI when it learned that Mihdhar and Hazmi had entered the United States, and Mihdhar was not placed on any watchlists until late August 2001.

Upon arriving in San Diego County, California, Mihdhar and Hazmi were to train as pilots, but spoke English poorly and did not do well with flight lessons. In June 2000, Mihdhar left the United States for Yemen, leaving Hazmi behind in San Diego. Mihdhar spent some time in Afghanistan in early 2001 and returned to the United States in early July 2001. He stayed in New Jersey in July and August, before arriving in the Washington, D.C. area at the beginning of September.

On the morning of September 11, 2001, Mihdhar boarded American Airlines Flight 77, which was hijacked approximately 30 minutes after take off. The plane was deliberately crashed into the Pentagon, killing all 64 people aboard the flight, along with 125 on the ground.

Al-Mihdhar was born on May 16, 1975, in Mecca, Saudi Arabia to a prominent family, related to the Quraysh tribe of Mecca. Little is known about his life before the age of 20, when he and childhood friend Nawaf al-Hazmi went to Bosnia and Herzegovina to fight with the mujahideen in the Bosnian War. After the war, Mihdhar and Hazmi went to Afghanistan where they fought alongside the Taliban against the Northern Alliance, and al-Qaeda would later dub Hazmi his "second in command". In 1997, Mihdhar told his family that he was leaving to fight in Chechnya, though it is not certain that he actually went to Chechnya. The same year, both men attracted the attention of Saudi Intelligence, who believed they were involved in arms smuggling, and the following year they were eyed as possible collaborators in the 1998 United States embassy bombings in East Africa after it emerged that Mohamed Rashed Daoud Al-Owhali had given the FBI the phone number of Mihdhar's father-in-law; 967-1-200578, which turned out to be a key communications hub for al-Qaeda militants, and eventually tipped off the Americans about the upcoming Kuala Lumpur al-Qaeda Summit.

In the late 1990s, Mihdhar married Hoda al-Hada, who was the sister of a comrade from Yemen, and they had two daughters. Through marriage, Mihdhar was related to a number of individuals involved with al-Qaeda in some way. Mihdhar's father-in-law, Ahmad Mohammad Ali al-Hada, helped facilitate al-Qaeda communications in Yemen, and in late 2001, Mihdhar's brother-in-law, Ahmed al-Darbi, was captured in Azerbaijan and sent to Guantanamo Bay on charges of supporting a plot to bomb ships in the Strait of Hormuz.

In Spring 1999, al-Qaeda founder Osama bin Laden committed to support the 9/11 attacks plot, which was largely organized by prominent al-Qaeda member Khalid Sheikh Mohammed. Mihdhar and Hazmi were among the first group of participants selected for the operation, along with Tawfiq bin Attash and Abu Bara al Yemeni, al-Qaeda members from Yemen. Mihdhar, who had spent time in al-Qaeda camps in the 1990s, was known and highly regarded by Bin Laden. Mihdhar was so eager to participate in jihad operations in the United States that he had already obtained a one-year B-1/B-2 (tourist/business) multiple-entry visa from the consulate in Jeddah, Saudi Arabia, on April 7, 1999, one day after obtaining a new passport. Mihdhar listed the Los Angeles Sheraton as his intended destination.

Once selected, Mihdhar and Hazmi were sent to the Mes Aynak training camp in Afghanistan. In late 1999, Hazmi, Attash and Yemeni went to Karachi, Pakistan to see Mohammed, who instructed them on Western culture and travel; however, Mihdhar did not go to Karachi, instead returning to Yemen. He was known as "Sinaan" during the preparations.

The CIA was aware of Mihdhar and Hazmi's involvement with al-Qaeda, having been informed by Saudi intelligence during a 1999 meeting in Riyadh. Based on information uncovered by the FBI in the 1998 United States embassy bombings case, the National Security Agency (NSA) began tracking the communications of Hada, Mihdhar's father-in-law. In late 1999, the NSA informed the CIA of an upcoming meeting in Malaysia, which Hada mentioned would involve "Khalid", "Nawaf", and "Salem", who was Hazmi's younger brother, Salem al-Hazmi.

On January 4, 2000, Mihdhar left Yemen and flew to Dubai, United Arab Emirates, where he spent the night. The CIA broke into his hotel room and photocopied his passport, which gave them his full name, birth information and passport number for the first time, and alerted them that he held an entry visa to the United States. The photocopy was sent to the CIA's Alec Station, which was tracking al-Qaeda.

On January 5, 2000, Mihdhar traveled to Kuala Lumpur, where he joined Hazmi, Attash and Yemeni, who were all arriving from Pakistan. Hamburg cell member Ramzi bin al-Shibh was also at the summit, and Mohammed possibly attended. The group was in Malaysia to meet with Hambali, the leader of Jemaah Islamiyah, an Asian al-Qaeda affiliate. During the Kuala Lumpur al-Qaeda Summit, many key details of the 9/11 attacks may have been arranged. At the time, the attacks plot had an additional component involving hijacking aircraft in Asia, as well as in the United States. Attash and Yemeni were slated for this part of the plot. However, it was later canceled by Bin Laden for being too difficult to coordinate with United States operations.

In Malaysia, the group stayed with Yazid Sufaat, a local Jemaah Islamiyah member, who provided accommodation at Hambali's request. Both Mihdhar and Hazmi were secretly photographed at the meeting by Malaysian authorities, whom the CIA had asked to provide surveillance. The Malaysians reported that Mihdhar spoke at length with Attash, and he met with Fahd al-Quso and others who were later involved in the USS "Cole" bombing. After the meeting, Mihdhar and Hazmi traveled to Bangkok, Thailand, on January 8 and left a week later on January 15 for the United States.

On January 15, 2000, Mihdhar and Hazmi arrived at Los Angeles International Airport from Bangkok and were admitted as tourists for a period of six months. Immediately after entering the country, Mihdhar and Hazmi met Omar al-Bayoumi in an airport restaurant. Bayoumi claimed he was merely being charitable in assisting the two seemingly out-of-place Muslims with moving to San Diego, where he helped them find an apartment near his own, co-signed their lease, and gave them $1,500 to help pay their rent. Mohammed later claimed that he suggested San Diego as their destination, based on information gleaned from a San Diego phone book that listed language and flight schools. Mohammed also recommended that the two seek assistance from the local Muslim community, since neither spoke English nor had experience with Western culture.

While in San Diego, witnesses told the FBI he and Hazmi had a close relationship with Anwar Al Awlaki, an imam who served as their spiritual advisor. Authorities say the two regularly attended the Masjid Ar-Ribat al-Islami mosque Awlaki led in San Diego, and Awlaki had many closed-door meetings with them, which led investigators to believe Awlaki knew about the 9/11 attacks in advance.

In early February 2000, Mihdhar and Hazmi rented an apartment at the Parkwood Apartments complex in the Clairemont Mesa area of San Diego, and Mihdhar purchased a used 1988 Toyota Corolla. Neighbors thought that Mihdhar and Hazmi were odd because months passed without the men getting any furniture, and they slept on mattresses on the floor, yet they carried briefcases, were frequently on their mobile phones, and were occasionally picked up by a limousine. Those who met Mihdhar in San Diego described him as "dark and brooding, with a disdain for American culture". Neighbors also said that the pair constantly played flight simulator games.

Mihdhar and Hazmi took flight lessons on May 5, 2000, at the Sorbi Flying Club in San Diego, with Mihdhar flying an aircraft for 42 minutes. They took additional lessons on May 10; however, with poor English skills, they did not do well with flight lessons. Mihdhar and Hazmi raised some suspicion when they offered extra money to their flight instructor, Richard Garza, if he would train them to fly jets. Garza refused the offer but did not report them to authorities. After the 9/11 attacks, Garza described the two men as "impatient students" who "wanted to learn to fly jets, specifically Boeings".

Mihdhar and Hazmi moved out of the Parkwood Apartments at the end of May 2000, and Mihdhar transferred registration for the Toyota Corolla to Hazmi. On June 10, 2000, Mihdhar left the United States and returned to Yemen to visit his wife, against the wishes of Mohammed who wanted him to remain in the United States to help Hazmi adapt. Mohammed was so angered by this that he decided to remove Mihdhar from the 9/11 plot, but he was overruled by bin Laden. Mihdhar remained part of the plot as a muscle hijacker, who would help take over the aircraft. On October 12, 2000, the USS "Cole" was bombed by a small boat laden with explosives. After the bombing, Yemeni Prime Minister Abdul Karim al-Iryani reported that Mihdhar had been one of the key planners of the attack and had been in the country at the time of the attacks. In late 2000, Mihdhar was back in Saudi Arabia, staying with a cousin in Mecca.

In February 2001, Mihdhar returned to Afghanistan for several months, possibly entering across the Iranian border after a flight from Syria. FBI director Robert Mueller later stated his belief that Mihdhar served as the coordinator and organizer for the muscle hijackers. He was the last of the muscle hijackers to return to the United States. On June 10, he returned to Saudi Arabia for a month, where he applied to re-enter the United States through the Visa Express program, indicating that he intended to stay at a Marriott hotel in New York City. On his visa application, Mihdhar falsely stated that he had never previously traveled to the United States.

On July 4, Mihdhar returned to the United States, arriving at New York City's John F. Kennedy International Airport, using a new passport obtained the previous month. A digital copy of one of Mihdhar's passports was later recovered during a search of an al-Qaeda safe house in Afghanistan, which held indicators, such as fake or altered passport stamps, that Mihdhar was a member of a known terrorist group. At the time when Mihdhar was admitted to the United States, immigration inspectors had not been trained to look for such indicators. Upon arriving, Mihdhar did not check into the Marriott but instead spent a night at another hotel in the city.

Mihdhar bought a fake ID on July 10 from All Services Plus in Passaic County, New Jersey, which was in the business of selling counterfeit documents, including another ID to Flight 11 hijacker Abdulaziz al-Omari. On August 1, Mihdhar and fellow Flight 77 hijacker Hani Hanjour drove to Virginia in order to obtain driver's licenses. Once they arrived, they scouted out a 7-Eleven convenience store and a dollar store in Falls Church, and found two Salvadoran immigrants who, for $50 each, were willing to vouch for Mihdhar and Hanjour as being Virginian residents. With notarized residency forms, Mihdhar and Hanjour were able to obtain driver's licenses at a Virginian motor vehicle office. Flight 77 hijackers Salem al-Hazmi and Majed Moqed, and United Airlines Flight 93 hijacker Ziad Jarrah used the same addresses obtained from the Salvadorans to obtain Virginian driver's licenses.

In August 2001, Mihdhar and Hazmi made several visits to the library at William Paterson University in Wayne, New Jersey, where they used computers to look up travel information and book flights. On August 22, Mihdhar and Hazmi tried to purchase flight tickets from the American Airlines online ticket-merchant, but had technical difficulties and gave up. Mihdhar and Moqed were able to make flight reservations for Flight 77 on August 25, using Moqed's credit card; however, the transaction did not fully go through because the billing address and the shipment address for the tickets did not match.

On August 31, Mihdhar closed an account at Hudson United Bank in New Jersey, having opened the account when he arrived in July, and was with Hanjour when he made a withdrawal from an ATM in Paterson on September 1. The next day, Mihdhar, Moqed and Hanjour traveled to Maryland, where they stayed at budget motels in Laurel. Mihdhar was among the muscle hijackers who worked out at a Gold's Gym in Greenbelt in early September. On September 5, Mihdhar and Moqed went to the American Airlines ticket counter at Baltimore-Washington International Airport to pick up their tickets for Flight 77, paying $2,300 in cash.

Mihdhar was placed on a CIA watchlist on August 21, 2001, and a note was sent on August 23 to the Department of State and the Immigration and Naturalization Service (INS) suggesting that Mihdhar and Hazmi be added to their watchlists. The Federal Aviation Administration (FAA) was not notified about the two men. On August 23, the CIA informed the FBI that Mihdhar had obtained a U.S. visa in Jeddah. The FBI headquarters received a copy of the Visa Express application from the Jeddah embassy on August 24, showing the New York Marriott as Mihdhar's destination.

On August 28, the FBI New York field office requested that a criminal case be opened to determine whether Mihdhar was still in the United States, but the request was refused. The FBI ended up treating Mihdhar as an intelligence case, which meant that the FBI's criminal investigators could not work on the case, due to the barrier separating intelligence and criminal case operations. An agent in the New York office sent an e-mail to FBI headquarters saying, "Whatever has happened to this, someday someone will die, and the public will not understand why we were not more effective and throwing every resource we had at certain 'problems.'" The reply from headquarters was, "we [at headquarters] are all frustrated with this issue ... [t]hese are the rules. NSLU does not make them up."

The FBI contacted Marriott on August 30, requesting that they check guest records, and on September 5, they reported that no Marriott hotels had any record of Mihdhar checking in. The day before the attacks, Robert Fuller of the New York office requested that the Los Angeles FBI office check all local Sheraton Hotels, as well as Lufthansa and United Airlines bookings, because those were the two airlines Mihdhar had used to enter the country. Neither the Treasury Department's Financial Crimes Enforcement Network nor the FBI's Financial Review Group, which have access to credit card and other private financial records, were notified about Mihdhar prior to September 11.

Regarding the CIA's refusal to inform the FBI about Mihdhar and Hazmi, author Lawrence Wright suggests the CIA wanted to protect its turf and was concerned about giving sensitive intelligence to FBI Agent John P. O'Neill, who Alec Station chief Michael Scheuer described as duplicitous. Wright also speculates that the CIA may have been protecting intelligence operations overseas, and might have been eying Mihdhar and Hazmi as recruitment targets to obtain intelligence on al-Qaeda, although the CIA was not authorized to operate in the United States and might have been leaving them for Saudi intelligence to recruit.

On September 10, 2001, Mihdhar and the other hijackers checked into the Marriott Residence Inn in Herndon, Virginia, near Washington Dulles International Airport. Saleh Ibn Abdul Rahman Hussayen, a prominent Saudi Arabian government official, was staying at the same hotel that night, although there is no evidence that they met or knew of each other's presence.

At 6:22 a.m. on September 11, 2001, the group checked out of the hotel and headed to Dulles airport. At 7:15 a.m., Mihdhar and Moqed checked in at the American Airlines ticket counter and arrived at the passenger security checkpoint at 7:20 a.m. Both men set off the metal detector and were put through secondary screening. Security video footage later released shows that Moqed was wanded, but the screener did not identify what set off the alarm, and both Moqed and Mihdhar were able to proceed without further hindrance. Mihdhar was also selected by the Computer Assisted Passenger Prescreening System (CAPPS), which involved extra screening of his luggage; however, because Mihdhar did not check any luggage, this had no effect. By 7:50 a.m., Mihdhar and the other hijackers, carrying knives and box cutters, had made it through the airport security checkpoint and boarded Flight 77 to Los Angeles. Mihdhar was seated in seat 12B, next to Moqed.

The flight was scheduled to depart from Gate D26 at 8:10 a.m. but was delayed by 10 minutes. The last routine radio communication from the plane to air traffic control occurred at 8:50:51 a.m. At 8:54 a.m., Flight 77 deviated from its assigned flight path and began to turn south, at which point the hijackers set the flight's autopilot setting for Washington, D.C. Passenger Barbara Olson called her husband, United States Solicitor General Ted Olson (whose 61st birthday was on that day), and reported that the plane had been hijacked. At 9:37:45 a.m, Flight 77 crashed into the west facade of the Pentagon, killing all 64 people aboard, along with 125 in the Pentagon. In the recovery process, remains of the five hijackers were identified through a process of elimination, since their DNA did not match any from the victims, and put into the custody of the FBI.

After the attacks, the identification of Mihdhar was one of the first links suggesting that bin Laden had played a role in their organization, since Mihdhar had been seen at the Malaysian conference speaking to bin Laden's associates. The FBI interrogated Quso, who was arrested following the USS "Cole" bombing and in custody in Yemen. Quso was able to identify Mihdhar, Hazmi and Attash in photos provided by the FBI, and he also knew Marwan al-Shehhi, a hijacker aboard United Airlines Flight 175. From Quso, the FBI was able to establish an al-Qaeda link to the attacks.

On September 12, 2001, the Toyota Corolla purchased by Mihdhar was found in Dulles International Airport's hourly parking lot. Inside the vehicle, authorities found a letter written by Mohamed Atta, a hijacker aboard American Airlines Flight 11; maps of Washington, D.C. and New York City; a cashier's check made out to a Phoenix, Arizona flight school; four drawings of a Boeing 757 cockpit; a box cutter; and a page with notes and phone numbers, which contained evidence that led investigators to San Diego.

On September 19, 2001, the Federal Deposit Insurance Corporation (FDIC) distributed a special alert that listed Mihdhar as still alive, and other reports began suggesting that a number of the alleged hijackers were likewise still alive. For instance, on September 23, 2001, the BBC published an article that suggested Mihdhar and others named as hijackers were still at large. The German magazine "Der Spiegel" later investigated the BBC's claims of "living" hijackers and reported they were cases of mistaken identities. In 2002, Saudi Arabian officials stated that the names of the hijackers were correct and that 15 of the 19 hijackers were Saudi Arabian. In 2006, in response to 9/11 conspiracy theories surrounding its original news story, the BBC said that confusion had arisen with the common Arabic names, and that its later reports on the hijackers superseded its original story.

In 2005, U.S. Army Lt. Col. Anthony Shaffer and Congressman Curt Weldon alleged that the Defense Department data mining project Able Danger identified Mihdhar, Hazmi, Shehhi, and Atta as members of a Brooklyn-based al-Qaeda cell in early 2000. Shaffer largely based his allegations on the recollections of Navy Captain Scott Phillpott, who later recanted his recollection, telling investigators that he was "convinced that Atta was not on the chart that we had". Phillpott said that Shaffer was "relying on my recollection 100 percent", and the Defense Department Inspector General's report indicated that Philpott strongly supported the social network analysis techniques used in Able Danger, and might have exaggerated claims of identifying the hijackers.




</doc>
<doc id="16861" url="https://en.wikipedia.org/wiki?curid=16861" title="Kurt Vonnegut">
Kurt Vonnegut

Kurt Vonnegut Jr. (; November 11, 1922April 11, 2007) was an American writer. In a career spanning over 50 years, Vonnegut published 14 novels, three short story collections, five plays, and five works of non-fiction, with further collections being published after his death. He is most famous for his darkly satirical, best-selling novel "Slaughterhouse-Five" (1969).

Born and raised in Indianapolis, Indiana, Vonnegut attended Cornell University but dropped out in January 1943 and enlisted in the United States Army. As part of his training, he studied mechanical engineering at Carnegie Institute of Technology (now Carnegie Mellon University) and the University of Tennessee. He was then deployed to Europe to fight in World War II and was captured by the Germans during the Battle of the Bulge. He was interned in Dresden and survived the Allied bombing of the city by taking refuge in a meat locker of the slaughterhouse where he was imprisoned. After the war, Vonnegut married Jane Marie Cox, with whom he had three children. He later adopted his sister's three sons, after she died of cancer and her husband was killed in a train accident.

Vonnegut published his first novel, "Player Piano", in 1952. The novel was reviewed positively but was not commercially successful. In the nearly 20 years that followed, Vonnegut published several novels that were only marginally successful, such as "Cat's Cradle" (1963) and "God Bless You, Mr. Rosewater" (1964). Vonnegut's breakthrough was his commercially and critically successful sixth novel, "Slaughterhouse-Five". The book's anti-war sentiment resonated with its readers amidst the ongoing Vietnam War and its reviews were generally positive. After its release, "Slaughterhouse-Five" went to the top of "The New York Times" Best Seller list, thrusting Vonnegut into fame. He was invited to give speeches, lectures and commencement addresses around the country and received many awards and honors.

Later in his career, Vonnegut published several autobiographical essays and short-story collections, including "Fates Worse Than Death" (1991), and "A Man Without a Country" (2005). After his death, he was hailed as a morbidly comical commentator on the society in which he lived and as one of the most important contemporary writers. Vonnegut's son Mark published a compilation of his father's unpublished compositions, titled "Armageddon in Retrospect". In 2017, Seven Stories Press published "Complete Stories", a collection of Vonnegut's short fiction including 5 previously unpublished stories. "Complete Stories" was collected and introduced by Vonnegut friends and scholars Jerome Klinkowitz and Dan Wakefield. Numerous scholarly works have examined Vonnegut's writing and humor.

Kurt Vonnegut Jr. was born on November 11, 1922, in Indianapolis, Indiana. He was the youngest of three children of Kurt Vonnegut Sr. and his wife Edith (born Lieber). His older siblings were Bernard (born 1914) and Alice (born 1917). Vonnegut was descended from German immigrants who settled in the United States in the mid-19th century; his patrilineal great-grandfather, Clemens Vonnegut of Westphalia, Germany, settled in Indianapolis and founded the Vonnegut Hardware Company. Kurt's father, and his father before him, Bernard, were architects; the architecture firm under Kurt Sr. designed such buildings as Das Deutsche Haus (now called "The Athenæum"), the Indiana headquarters of the Bell Telephone Company, and the Fletcher Trust Building. Vonnegut's mother was born into Indianapolis high society, as her family, the Liebers, were among the wealthiest in the city, their fortune derived from ownership of a successful brewery.

Although both of Vonnegut's parents were fluent German speakers, the ill feeling toward that country during and after World War I caused the Vonneguts to abandon that culture to show their American patriotism. Thus, they did not teach their youngest son German or introduce him to German literature and tradition, leaving him feeling "ignorant and rootless." Vonnegut later credited Ida Young, his family's African-American cook and housekeeper for the first 10 years of his life, for raising him and giving him values. "[She] gave me decent moral instruction and was exceedingly nice to me. So she was as great an influence on me as anybody." Vonnegut described Young as "humane and wise", adding that "the compassionate, forgiving aspects of [his] beliefs" came from her.

The financial security and social prosperity that the Vonneguts once enjoyed were destroyed in a matter of years. The Liebers's brewery was closed in 1921 after the advent of Prohibition in the United States. When the Great Depression hit, few people could afford to build, causing clients at Kurt Sr.'s architectural firm to become scarce. Vonnegut's brother and sister had finished their primary and secondary educations in private schools, but Vonnegut was placed in a public school, called Public School No. 43, now known as the James Whitcomb Riley School. He was not bothered by this, but both his parents were affected deeply by their economic misfortune. His father withdrew from normal life and became what Vonnegut called a "dreamy artist". His mother became depressed, withdrawn, bitter, and abusive. She labored to regain the family's wealth and status, and Vonnegut said she expressed hatred "as corrosive as hydrochloric acid" for her husband. Edith Vonnegut forayed into writing and tried to sell short stories to magazines like "Collier's" and "The Saturday Evening Post" with no success.

Vonnegut enrolled at Shortridge High School in Indianapolis in 1936. While there, he played clarinet in the school band and became a co-editor (along with Madelyn Pugh) for the Tuesday edition of the school newspaper, "The Shortridge Echo". Vonnegut said his tenure with the "Echo" allowed him to write for a large audience—his fellow students—rather than for a teacher, an experience he said was "fun and easy". "It just turned out that I could write better than a lot of other people", Vonnegut observed. "Each person has something he can do easily and can't imagine why everybody else has so much trouble doing it."

After graduating from Shortridge in 1940, Vonnegut enrolled at Cornell University in Ithaca, New York. He wanted to study the humanities or become an architect like his father, but his father and brother, a scientist, urged him to study a "useful" discipline. As a result, Vonnegut majored in biochemistry, but he had little proficiency in the area and was indifferent towards his studies. As his father had been a member at MIT, Vonnegut was entitled to join the Delta Upsilon fraternity, and did. He overcame stiff competition for a place at the university's independent newspaper, "The Cornell Daily Sun", first serving as a staff writer, then as an editor. By the end of his freshman year, he was writing a column titled "Innocents Abroad" which reused jokes from other publications. He later penned a piece, "Well All Right", focusing on pacifism, a cause he strongly supported, arguing against U.S. intervention in World War II.

The attack on Pearl Harbor brought the U.S. into the war. Vonnegut was a member of Reserve Officers' Training Corps, but poor grades and a satirical article in Cornell's newspaper cost him his place there. He was placed on academic probation in May 1942 and dropped out the following January. No longer eligible for a student deferment, he faced likely conscription into the United States Army. Instead of waiting to be drafted, he enlisted in the army and in March 1943 reported to Fort Bragg, North Carolina, for basic training. Vonnegut was trained to fire and maintain howitzers and later received instruction in mechanical engineering at the Carnegie Institute of Technology and the University of Tennessee as part of the Army Specialized Training Program (ASTP). In early 1944, the ASTP was canceled due to the Army's need for soldiers to support the D-Day invasion, and Vonnegut was ordered to an infantry battalion at Camp Atterbury, south of Indianapolis in Edinburgh, Indiana, where he trained as a scout. He lived so close to his home that he was "able to sleep in [his] own bedroom and use the family car on weekends". On May 14, 1944, Vonnegut returned home on leave for Mother's Day weekend to discover that his mother had committed suicide the previous night by overdosing on sleeping pills. Possible factors that contributed to Edith Vonnegut's suicide include the family's loss of wealth and status, Vonnegut's forthcoming deployment overseas, and her own lack of success as a writer. She was inebriated at the time and under the influence of prescription drugs.

Three months after his mother's suicide, Vonnegut was sent to Europe as an intelligence scout with the 106th Infantry Division. In December 1944, he fought in the Battle of the Bulge, the final German offensive of the war. During the battle, the 106th Infantry Division, which had only recently reached the front and was assigned to a "quiet" sector due to its inexperience, was overrun by advancing German armored forces. Over 500 members of the division were killed and over 6,000 were captured.

On December 22, Vonnegut was captured with about 50 other American soldiers. Vonnegut was taken by boxcar to a prison camp south of Dresden, in Saxony. During the journey, the Royal Air Force bombed the prisoner trains and killed about 150 men. Vonnegut was sent to Dresden, the "first fancy city [he had] ever seen". He lived in a slaughterhouse when he got to the city, and worked in a factory that made malt syrup for pregnant women. Vonnegut recalled the sirens going off whenever another city was bombed. The Germans did not expect Dresden to get bombed, Vonnegut said. "There were very few air-raid shelters in town and no war industries, just cigarette factories, hospitals, clarinet factories."
On February 13, 1945, Dresden became the target of Allied forces. In the hours and days that followed, the Allies engaged in a fierce firebombing of the city. The offensive subsided on February 15, with around 25,000 civilians killed in the bombing. Vonnegut marveled at the level of both the destruction in Dresden and the secrecy that attended it. He had survived by taking refuge in a meat locker three stories underground. "It was cool there, with cadavers hanging all around", Vonnegut said. "When we came up the city was gone ... They burnt the whole damn town down." Vonnegut and other American prisoners were put to work immediately after the bombing, excavating bodies from the rubble. He described the activity as a "terribly elaborate Easter-egg hunt".

The American prisoners of war were evacuated on foot to the border of Saxony and Czechoslovakia after General George S. Patton captured Leipzig. With the captives abandoned by their guards, Vonnegut reached a prisoner-of-war repatriation camp in Le Havre, France, before the end of May 1945, with the aid of the Soviets. He returned to the United States and continued to serve in the Army, stationed at Fort Riley, Kansas, typing discharge papers for other soldiers. Soon after he was awarded a Purple Heart about which he remarked "I myself was awarded my country's second-lowest decoration, a Purple Heart for frost-bite." He was discharged from the U.S. Army and returned to Indianapolis.

After he returned to the United States, 22-year-old Vonnegut married Jane Marie Cox, his high school girlfriend and classmate since kindergarten, on September 1, 1945. The pair relocated to Chicago; there, Vonnegut enrolled in the University of Chicago on the G.I. Bill, as an anthropology student in an unusual five-year joint undergraduate/graduate program that conferred a master's degree. He augmented his income by working as a reporter for the City News Bureau of Chicago at night. Jane accepted a scholarship from the university to study Russian literature as a graduate student. Jane dropped out of the program after becoming pregnant with the couple's first child, Mark (born May 1947), while Kurt also left the University without any degree (despite having completed his undergraduate education) when his master's thesis on the Ghost Dance religious movement was unanimously rejected by the department.

Shortly thereafter, General Electric (GE) hired Vonnegut as a publicist for the company's Schenectady, New York, research laboratory. Although the job required a college degree, Vonnegut was hired after claiming to hold a master's degree in anthropology from the University of Chicago. His brother Bernard had worked at GE since 1945, contributing significantly to an iodine-based cloud seeding project. In 1949, Kurt and Jane had a daughter named Edith. Still working for GE, Vonnegut had his first piece, titled "Report on the Barnhouse Effect", published in the February 11, 1950 issue of "Collier's", for which he received $750. Vonnegut wrote another story, after being coached by the fiction editor at "Collier's", Knox Burger, and again sold it to the magazine, this time for $950. Burger suggested he quit GE, a course he had contemplated before. Vonnegut moved with his family to Cape Cod, Massachusetts to write full-time, and left GE in 1951.

On Cape Cod, Vonnegut made most of his money writing pieces for magazines such as "Collier's", "The Saturday Evening Post", and "Cosmopolitan". He also did a stint as an English teacher, wrote copy for an advertising agency, and opened the first USA Saab dealership, which eventually failed. In 1952, Vonnegut's first novel, "Player Piano", was published by Scribner's. The novel has a post-Third World War setting, in which factory workers have been replaced by machines.

"Player Piano" draws upon Vonnegut's experience as an employee at GE. He satirizes the drive to climb the corporate ladder, one that in "Player Piano" is rapidly disappearing as automation increases, putting even executives out of work. His central character, Paul Proteus, has an ambitious wife, a backstabbing assistant, and a feeling of empathy for the poor. Sent by his boss, Kroner, as a double agent among the poor (who have all the material goods they want, but little sense of purpose), he leads them in a machine-smashing, museum-burning revolution. "Player Piano" expresses Vonnegut's opposition to McCarthyism, something made clear when the Ghost Shirts, the revolutionary organization Paul penetrates and eventually leads, is referred to by one character as "fellow travelers".

In "Player Piano", Vonnegut originates many of the techniques he would use in his later works. The comic, heavy-drinking Shah of Bratpuhr, an outsider to this dystopian corporate United States, is able to ask many questions that an insider would not think to ask, or would cause offense by doing so. For example, when taken to see the artificially intelligent supercomputer EPICAC, the Shah asks it "what are people for?" and receives no answer. Speaking for Vonnegut, he dismisses it as a "false god". This type of alien visitor would recur throughout Vonnegut's literature.

"The New York Times" writer and critic Granville Hicks gave "Player Piano" a positive review, favorably comparing it to Aldous Huxley's "Brave New World". Hicks called Vonnegut a "sharp-eyed satirist". None of the reviewers considered the novel particularly important. Several editions were printed—one by Bantam with the title "Utopia 14", and another by the Doubleday Science Fiction Book Club—whereby Vonnegut gained the repute of a science fiction writer, a genre held in disdain by writers at that time. He defended the genre, and deplored a perceived sentiment that "no one can simultaneously be a respectable writer and understand how a refrigerator works."

After "Player Piano", Vonnegut continued to sell short stories to various magazines. In 1954 the couple had a third child, Nanette. With a growing family and no financially successful novels yet, Vonnegut's short stories sustained the family. In 1958, his sister, Alice, died of cancer two days after her husband, James Carmalt Adams, was killed in a train accident. Vonnegut adopted Alice's three young sons—James, Steven, and Kurt, aged 14, 11, and 9, respectively.

Grappling with family challenges, Vonnegut continued to write, publishing novels vastly dissimilar in terms of plot. "The Sirens of Titan" (1959) features a Martian invasion of Earth, as experienced by a bored billionaire, Malachi Constant. He meets Winston Rumfoord, an aristocratic space traveler, who is virtually omniscient but stuck in a time warp that allows him to appear on Earth every 59 days. The billionaire learns that his actions and the events of all of history are determined by a race of robotic aliens from the planet Tralfamadore, who need a replacement part that can only be produced by an advanced civilization in order to repair their spaceship and return home—human history has been manipulated to produce it. Some human structures, such as the Kremlin, are coded signals from the aliens to their ship as to how long it may expect to wait for the repair to take place. Reviewers were uncertain what to think of the book, with one comparing it to Offenbach's opera "The Tales of Hoffmann".

Rumfoord, who is based on Franklin D. Roosevelt, also physically resembles the former president. Rumfoord is described, "he put a cigarette in a long, bone cigarette holder, lighted it. He thrust out his jaw. The cigarette holder pointed straight up." William Rodney Allen, in his guide to Vonnegut's works, stated that Rumfoord foreshadowed the fictional political figures who would play major roles in "God Bless You, Mr. Rosewater" and "Jailbird".

"Mother Night", published in 1961, received little attention at the time of its publication. Howard W. Campbell Jr., Vonnegut's protagonist, is an American who goes to Nazi Germany during the war as a double agent for the U.S. Office of Strategic Services, and rises to the regime's highest ranks as a radio propagandist. After the war, the spy agency refuses to clear his name and he is eventually imprisoned by the Israelis in the same cell block as Adolf Eichmann, and later commits suicide. Vonnegut wrote in a foreword to a later edition, "we are what we pretend to be, so we must be careful about what we pretend to be". Literary critic Lawrence Berkove considered the novel, like Mark Twain's "Adventures of Huckleberry Finn", to illustrate the tendency for "impersonators to get carried away by their impersonations, to become what they impersonate and therefore to live in a world of illusion".

Also published in 1961 was Vonnegut's short story, "Harrison Bergeron", set in a dystopic future where all are equal, even if that means disfiguring beautiful people and forcing the strong or intelligent to wear devices that negate their advantages. Fourteen-year-old Harrison is a genius and athlete forced to wear record-level "handicaps" and imprisoned for attempting to overthrow the government. He escapes to a television studio, tears away his handicaps, and frees a ballerina from her lead weights. As they dance, they are killed by the Handicapper General, Diana Moon Glampers. Vonnegut, in a later letter, suggested that "Harrison Bergeron" might have sprung from his envy and self-pity as a high school misfit. In his 1976 biography of Vonnegut, Stanley Schatt suggested that the short story shows "in any leveling process, what really is lost, according to Vonnegut, is beauty, grace, and wisdom". Darryl Hattenhauer, in his 1998 journal article on "Harrison Bergeron", theorized that the story was a satire on American Cold War misunderstandings of communism and socialism.

With "Cat's Cradle" (1963), Allen wrote, "Vonnegut hit full stride for the first time". The narrator, John, intends to write of Dr. Felix Hoenikker, one of the fictional fathers of the atomic bomb, seeking to cover the scientist's human side. Hoenikker, in addition to the bomb, has developed another threat to mankind, ice-9, solid water stable at room temperature, and if a particle of it is dropped in water, all of it becomes ice-9. Much of the second half of the book is spent on the fictional Caribbean island of San Lorenzo, where John explores a religion called Bokononism, whose holy books (excerpts from which are quoted), give the novel the moral core science does not supply. After the oceans are converted to ice-9, wiping out most of humankind, John wanders the frozen surface, seeking to have himself and his story survive.

Vonnegut based the title character of "God Bless You, Mr. Rosewater" (1964), on an accountant he knew on Cape Cod, who specialized in clients in trouble and often had to comfort them. Eliot Rosewater, the wealthy son of a Republican senator, seeks to atone for his wartime killing of noncombatant firefighters by serving in a volunteer fire department, and by giving away money to those in trouble or need. Stress from a battle for control of his charitable foundation pushes him over the edge, and he is placed in a mental hospital. He recovers, and ends the financial battle by declaring the children of his county to be his heirs. Allen deemed "God Bless You, Mr. Rosewater" more "a cry from the heart than a novel under its author's full intellectual control", that reflected family and emotional stresses Vonnegut was going through at the time.

In the mid-1960s, Vonnegut contemplated abandoning his writing career. In 1999 he wrote for the New York Times, "I had gone broke, was out of print and had a lot of kids..." But then, on the recommendation of an admirer, he received a surprise offer of a teaching job at the Iowa Writers' Workshop, employment that he likened to the rescue of a drowning man.

After spending almost two years at the writer's workshop at the University of Iowa, teaching one course each term, Vonnegut was awarded a Guggenheim Fellowship for research in Germany. By the time he won it, in March 1967, he was becoming a well-known writer. He used the funds to travel in Eastern Europe, including to Dresden, where he found many prominent buildings still in ruins. At the time of the bombing, Vonnegut had not appreciated the sheer scale of destruction in Dresden; his enlightenment came only slowly as information dribbled out, and based on early figures he came to believe that 135,000 had died there.

Vonnegut had been writing about his war experiences at Dresden ever since he returned from the war, but had never been able to write anything acceptable to himself or his publishers—Chapter 1 of "Slaughterhouse-Five" tells of his difficulties. Released in 1969, the novel rocketed Vonnegut to fame. It tells of the life of Billy Pilgrim, who like Vonnegut was born in 1922 and survives the bombing of Dresden. The story is told in a non-linear fashion, with many of the story's climaxes—Billy's death in 1976, his kidnapping by aliens from the planet Tralfamadore nine years earlier, and the execution of Billy's friend Edgar Derby in the ashes of Dresden for stealing a teapot—disclosed in the story's first pages. In 1970, he was also a correspondent in Biafra during the Nigerian Civil War.
"Slaughterhouse-Five" received generally positive reviews, with Michael Crichton writing in "The New Republic", "he writes about the most excruciatingly painful things. His novels have attacked our deepest fears of automation and the bomb, our deepest political guilts, our fiercest hatreds and loves. No one else writes books on these subjects; they are inaccessible to normal novelists." The book went immediately to the top of "The New York Times" Best Seller list. Vonnegut's earlier works had appealed strongly to many college students, and the antiwar message of "Slaughterhouse-Five" resonated with a generation marked by the Vietnam War. He later stated that the loss of confidence in government that Vietnam caused finally allowed for an honest conversation regarding events like Dresden.

After "Slaughterhouse-Five" was published, Vonnegut embraced the fame and financial security that attended its release. He was hailed as a hero of the burgeoning anti-war movement in the United States, was invited to speak at numerous rallies, and gave college commencement addresses around the country. In addition to briefly teaching at Harvard University as a lecturer in creative writing in 1970, Vonnegut taught at the City College of New York as a distinguished professor during the 1973–1974 academic year. He was later elected vice president of the National Institute of Arts and Letters, and given honorary degrees by, among others, Indiana University and Bennington College. Vonnegut also wrote a play called "Happy Birthday, Wanda June", which opened on October 7, 1970, at New York's Theatre de Lys. Receiving mixed reviews, it closed on March 14, 1971. In 1972, Universal Pictures adapted "Slaughterhouse-Five" into a film which the author said was "flawless".

Meanwhile, Vonnegut's personal life was disintegrating. His wife Jane had embraced Christianity, which was contrary to Vonnegut's atheistic beliefs, and with five of their six children having left home, Vonnegut said the two were forced to find "other sorts of seemingly important work to do." The couple battled over their differing beliefs until Vonnegut moved from their Cape Cod home to New York in 1971. Vonnegut called the disagreements "painful", and said the resulting split was a "terrible, unavoidable accident that we were ill-equipped to understand." The couple divorced and they remained friends until Jane's death in late 1986. Beyond his marriage, he was deeply affected when his son Mark suffered a mental breakdown in 1972, which exacerbated Vonnegut's chronic depression, and led him to take Ritalin. When he stopped taking the drug in the mid-1970s, he began to see a psychologist weekly.

Vonnegut's difficulties materialized in numerous ways; most distinctly though, was the painfully slow progress he was making on his next novel, the darkly comical "Breakfast of Champions". In 1971, Vonnegut stopped writing the novel altogether. When it was finally released in 1973, it was panned critically. In Thomas S. Hischak's book "American Literature on Stage and Screen", "Breakfast of Champions" was called "funny and outlandish", but reviewers noted that it "lacks substance and seems to be an exercise in literary playfulness." Vonnegut's 1976 novel "Slapstick", which meditates on the relationship between him and his sister (Alice), met a similar fate. In "The New York Times"'s review of "Slapstick", Christopher Lehmann-Haupt said Vonnegut "seems to be putting less effort into [storytelling] than ever before", and that "it still seems as if he has given up storytelling after all." At times, Vonnegut was disgruntled by the personal nature of his detractors' complaints.

In 1979, Vonnegut married Jill Krementz, a photographer whom he met while she was working on a series about writers in the early 1970s. With Jill, he adopted a daughter, Lily, when the baby was three days old. In subsequent years, his popularity resurged as he published several satirical books, including "Jailbird" (1979), "Deadeye Dick" (1982), "Galápagos" (1985), "Bluebeard" (1987), and "Hocus Pocus" (1990). Although he remained a prolific writer in the 1980s Vonnegut struggled with depression and attempted suicide in 1984. Two years later, Vonnegut was seen by a younger generation when he played himself in Rodney Dangerfield's film "Back to School". The last of Vonnegut's fourteen novels, "Timequake" (1997), was, as University of Detroit history professor and Vonnegut biographer Gregory Sumner said, "a reflection of an aging man facing mortality and testimony to an embattled faith in the resilience of human awareness and agency." Vonnegut's final book, a collection of essays entitled "A Man Without a Country" (2005), became a bestseller.

In a 2006 "Rolling Stone" interview, Vonnegut sardonically stated that he would sue the Brown & Williamson tobacco company, the maker of the Pall Mall-branded cigarettes he had been smoking since he was twelve or fourteen years old, for false advertising. "And do you know why?" he said. "Because I'm 83 years old. The lying bastards! On the package Brown & Williamson promised to kill me." He died on the night of April 11, 2007 in Manhattan, as a result of brain injuries incurred several weeks prior from a fall at his New York brownstone home. His death was reported by his wife Jill. Vonnegut was 84 years old. At the time of his death, Vonnegut had written fourteen novels, three short story collections, five plays and five non-fiction books. A book composed of Vonnegut's unpublished pieces, "Armageddon in Retrospect", was compiled and posthumously published by Vonnegut's son Mark in 2008.

When asked about the impact Vonnegut had on his work, author Josip Novakovich stated that he has "much to learn from Vonnegut—how to compress things and yet not compromise them, how to digress into history, quote from various historical accounts, and not stifle the narrative. The ease with which he writes is sheerly masterly, Mozartian." "Los Angeles Times" columnist Gregory Rodriguez said that the author will "rightly be remembered as a darkly humorous social critic and the premier novelist of the counterculture", and Dinitia Smith of "The New York Times" dubbed Vonnegut the "counterculture's novelist."

Vonnegut has inspired numerous posthumous tributes and works. In 2008, the Kurt Vonnegut Society was established, and in November 2010, the Kurt Vonnegut Memorial Library was opened in Vonnegut's hometown of Indianapolis. The Library of America published a compendium of Vonnegut's compositions between 1963 and 1973 the following April, and another compendium of his earlier works in 2012. Late 2011 saw the release of two Vonnegut biographies, Gregory Sumner's "Unstuck in Time" and Charles J. Shields's "And So It Goes". Shields's biography of Vonnegut created some controversy. According to "The Guardian", the book portrays Vonnegut as distant, cruel and nasty. "Cruel, nasty and scary are the adjectives commonly used to describe him by the friends, colleagues, and relatives Shields quotes", said "The Daily Beast"'s Wendy Smith. "Towards the end he was very feeble, very depressed and almost morose", said Jerome Klinkowitz of the University of Northern Iowa, who has examined Vonnegut in depth.

Vonnegut's works have evoked ire on several occasions. His most prominent novel, "Slaughterhouse-Five", has been objected to or removed at various institutions in at least 18 instances. In the case of "Island Trees School District v. Pico", the United States Supreme Court ruled that a school district's ban on "Slaughterhouse-Five"—which the board had called "anti-American, anti-Christian, anti-Semitic, and just plain filthy"—and eight other novels was unconstitutional. When a school board in Republic, Missouri decided to withdraw Vonnegut's novel from its libraries, the Kurt Vonnegut Memorial Library offered a free copy to all the students of the district.

Tally, writing in 2013, suggests that Vonnegut has only recently become the subject of serious study rather than fan adulation, and much is yet to be written about him. "The time for scholars to say 'Here's why Vonnegut is worth reading' has definitively ended, thank goodness. We know he's worth reading. Now tell us things we don't know." Todd F. Davis notes that Vonnegut's work is kept alive by his loyal readers, who have "significant influence as they continue to purchase Vonnegut's work, passing it on to subsequent generations and keeping his entire canon in print—an impressive list of more than twenty books that [Dell Publishing] has continued to refurbish and hawk with new cover designs." Donald E. Morse notes that Vonnegut, "is now firmly, if somewhat controversially, ensconced in the American and world literary canon as well as in high school, college and graduate curricula". Tally writes of Vonnegut's work:

The Science Fiction and Fantasy Hall of Fame inducted Vonnegut posthumously in 2015.

The asteroid 25399 Vonnegut is named in his honor.

In the introduction to "Slaughterhouse-Five" Vonnegut recounts meeting filmmaker Harrison Starr at a party who asked him whether his forthcoming book was an anti-war novel — "I guess" replied Vonnegut. Starr responded "Why don't you write an anti-glacier novel?". This underlined Vonnegut's belief that wars were, unfortunately, inevitable, but that it was important to ensure the wars one fought were just wars.
In 2011, NPR wrote, "Kurt Vonnegut's blend of anti-war sentiment and satire made him one of the most popular writers of the 1960s." Vonnegut stated in a 1987 interview that, "my own feeling is that civilization ended in World War I, and we're still trying to recover from that", and that he wanted to write war-focused works without glamorizing war itself. Vonnegut had not intended to publish again, but his anger against the George W. Bush administration led him to write "A Man Without a Country".

"Slaughterhouse-Five" is the Vonnegut novel best known for its antiwar themes, but the author expressed his beliefs in ways beyond the depiction of the destruction of Dresden. One character, Mary O'Hare, opines that "wars were partly encouraged by books and movies", made by "Frank Sinatra or John Wayne or some of those other glamorous, war-loving, dirty old men". Vonnegut made a number of comparisons between Dresden and the bombing of Hiroshima in "Slaughterhouse-Five" and wrote in "Palm Sunday" (1991) that "I learned how vile that religion of mine could be when the atomic bomb was dropped on Hiroshima".

Nuclear war, or at least deployed nuclear arms, is mentioned in almost all of Vonnegut's novels. In "Player Piano", the computer EPICAC is given control of the nuclear arsenal, and is charged with deciding whether to use high-explosive or nuclear arms. In "Cat's Cradle", John's original purpose in setting pen to paper was to write an account of what prominent Americans had been doing as Hiroshima was bombed.

Vonnegut was an atheist and a humanist, serving as the honorary president of the American Humanist Association. In an interview for "Playboy", he stated that his forebears who came to the United States did not believe in God, and he learned his atheism from his parents. He did not however disdain those who seek the comfort of religion, hailing church associations as a type of extended family. Like his great-grandfather Clemens, Vonnegut was a freethinker. He occasionally attended a Unitarian church, but with little consistency. In his autobiographical work "Palm Sunday", Vonnegut says he is a "Christ-worshipping agnostic"; in a speech to the Unitarian Universalist Association, he called himself a "Christ-loving atheist". However, he was keen to stress that he was not a Christian.

Vonnegut was an admirer of Jesus' Sermon on the Mount, particularly the Beatitudes, and incorporated it into his own doctrines. He also referred to it in many of his works. In his 1991 book "Fates Worse than Death", Vonnegut suggests that during the Reagan administration, "anything that sounded like the Sermon on the Mount was socialistic or communistic, and therefore anti-American". In "Palm Sunday", he wrote that "the Sermon on the Mount suggests a mercifulness that can never waver or fade." However, Vonnegut had a deep dislike for certain aspects of Christianity, often reminding his readers of the bloody history of the Crusades and other religion-inspired violence. He despised the televangelists of the late 20th century, feeling that their thinking was narrow-minded.

Religion features frequently in Vonnegut's work, both in his novels and elsewhere. He laced a number of his speeches with religion-focused rhetoric, and was prone to using such expressions as "God forbid" and "thank God". He once wrote his own version of the Requiem Mass, which he then had translated into Latin and set to music. In "God Bless You, Dr. Kevorkian", Vonnegut goes to heaven after he is euthanized by Dr. Jack Kevorkian. Once in heaven, he interviews 21 deceased celebrities, including Isaac Asimov, William Shakespeare, and Kilgore Trout—the last a fictional character from several of his novels. Vonnegut's works are filled with characters founding new faiths, and religion often serves as a major plot device, for example in "Player Piano", "The Sirens of Titan" and "Cat's Cradle". In "The Sirens of Titan", Rumfoord proclaims The Church of God the Utterly Indifferent. "Slaughterhouse-Five" sees Billy Pilgrim, lacking religion himself, nevertheless become a chaplain's assistant in the military and display a large crucifix on his bedroom wall. In "Cat's Cradle", Vonnegut invented the religion of Bokononism.

Vonnegut did not particularly sympathize with liberalism or conservatism, and mused on the specious simplicity of American politics. "If you want to take my guns away from me, and you're all for murdering fetuses, and love it when homosexuals marry each other ... you're a liberal. If you are against those perversions and for the rich, you're a conservative. What could be simpler?" Regarding political parties, Vonnegut said, "The two real political parties in America are the Winners and the Losers. The people don't acknowledge this. They claim membership in two imaginary parties, the Republicans and the Democrats, instead."

Vonnegut disregarded more mainstream political ideologies in favor of socialism, which he thought could provide a valuable substitute for what he saw as social Darwinism and a spirit of "survival of the fittest" in American society, believing that "socialism would be a good for the common man". Vonnegut would often return to a quote by socialist and five-time presidential candidate Eugene V. Debs: "As long as there is a lower class, I am in it. As long as there is a criminal element, I'm of it. As long as there is a soul in prison, I am not free." Vonnegut expressed disappointment that communism and socialism seemed to be unsavory topics to the average American, and believed that they may offer beneficial substitutes to contemporary social and economic systems.

Vonnegut's writing was inspired by an eclectic mix of sources. When he was younger, Vonnegut stated that he read works of pulp fiction, science fiction, fantasy, and action-adventure. He also read the classics, such as the plays of Aristophanes—like Vonnegut's works, humorous critiques of contemporary society. Vonnegut's life and work also share similarities with that of "Adventures of Huckleberry Finn" writer Mark Twain. Both shared pessimistic outlooks on humanity, and a skeptical take on religion, and, as Vonnegut put it, were both "associated with the enemy in a major war", as Twain briefly enlisted in the South's cause during the American Civil War, and Vonnegut's German name and ancestry connected him with the United States' enemy in both world wars.

Vonnegut called George Orwell his favorite writer, and admitted that he tried to emulate Orwell. "I like his concern for the poor, I like his socialism, I like his simplicity", Vonnegut said. Vonnegut also said that Orwell's "Nineteen Eighty-Four", and "Brave New World" by Aldous Huxley, heavily influenced his debut novel, "Player Piano", in 1952. Vonnegut commented that Robert Louis Stevenson's stories were emblems of thoughtfully put together works that he tried to mimic in his own compositions. Vonnegut also hailed playwright and socialist George Bernard Shaw as "a hero of [his]", and an "enormous influence." Within his own family, Vonnegut stated that his mother, Edith, had the greatest influence on him. "[My] mother thought she might make a new fortune by writing for the slick magazines. She took short-story courses at night. She studied magazines the way gamblers study racing forms."

Early on in his career, Vonnegut decided to model his style after Henry David Thoreau, who wrote as if from the perspective of a child, allowing Thoreau's works to be more widely comprehensible. Using a youthful narrative voice allowed Vonnegut to deliver concepts in a modest and straightforward way. Other influences on Vonnegut include "The War of the Worlds" author H. G. Wells, and satirist Jonathan Swift. Vonnegut credited American journalist and critic H. L. Mencken for inspiring him to become a journalist.

In his book "Popular Contemporary Writers", Michael D. Sharp describes Vonnegut's linguistic style as straightforward; his sentences concise, his language simple, his paragraphs brief, and his ordinary tone conversational. Vonnegut uses this style to convey normally complex subject matter in a way that is intelligible to a large audience. He credited his time as a journalist for his ability, pointing to his work with the Chicago City News Bureau, which required him to convey stories in telephone conversations. Vonnegut's compositions are also laced with distinct references to his own life, notably in "Slaughterhouse-Five" and "Slapstick".

Vonnegut believed that ideas, and the convincing communication of those ideas to the reader, were vital to literary art. He did not always sugarcoat his points: much of "Player Piano" leads up to the moment when Paul, on trial and hooked up to a lie detector, is asked to tell a falsehood, and states, "every new piece of scientific knowledge is a good thing for humanity". Robert T. Tally Jr., in his volume on Vonnegut's novels, wrote, "rather than tearing down and destroying the icons of twentieth-century, middle-class American life, Vonnegut gently reveals their basic flimsiness." Vonnegut did not simply propose utopian solutions to the ills of American society, but showed how such schemes would not allow ordinary people to live lives free from want and anxiety. The large artificial families that the U.S. population is formed into in "Slapstick" soon serve as an excuse for tribalism, with people giving no help to those not part of their group, and with the extended family's place in the social hierarchy becoming vital.

In the introduction to their essay "Kurt Vonnegut and Humor", Tally and Peter C. Kunze suggest that Vonnegut was not a "black humorist", but a "frustrated idealist" who used "comic parables" to teach the reader absurd, bitter or hopeless truths, with his grim witticisms serving to make the reader laugh rather than cry. "Vonnegut makes sense through humor, which is, in the author's view, as valid a means of mapping this crazy world as any other strategies." Vonnegut resented being called a black humorist, feeling that, as with many literary labels, it allows readers to disregard aspects of a writer's work that do not fit the label's stereotype.

Vonnegut's works have, at various times, been labeled science fiction, satire and postmodern. He also resisted such labels, but his works do contain common tropes that are often associated with those genres. In several of his books, Vonnegut imagines alien societies and civilizations, as is common in works of science fiction. Vonnegut does this to emphasize or exaggerate absurdities and idiosyncrasies in our own world. Furthermore, Vonnegut often humorizes the problems that plague societies, as is done in satirical works. However, literary theorist Robert Scholes noted in "Fabulation and Metafiction" that Vonnegut "reject[s] the traditional satirist's faith in the efficacy of satire as a reforming instrument. [He has] a more subtle faith in the humanizing value of laughter." Examples of postmodernism may also be found in Vonnegut's works. Postmodernism often entails a response to the theory that the truths of the world will be discovered through science. Postmodernists contend that truth is subjective, rather than objective, as it is biased towards each individual's beliefs and outlook on the world. They often use unreliable, first-person narration, and narrative fragmentation. One critic has argued that Vonnegut's most famous novel, "Slaughterhouse-Five", features a metafictional, Janus-headed outlook as it seeks both to represent actual historical events while problematizing the very notion of doing exactly that. This is encapsulated in the opening lines of the novel: "All this happened, more or less. The war parts, anyway, are pretty much true." This bombastic opening – "All this happened" – "reads like a declaration of complete mimesis" which is radically called into question in the rest of the quote and "[t]his creates an integrated perspective that seeks out extratextual themes [like war and trauma] while thematizing the novel's textuality and inherent constructedness at one and the same time." While Vonnegut does use elements as fragmentation and metafictional elements, in some of his works, he more distinctly focuses on the peril posed by individuals who find subjective truths, mistake them for objective truths, then proceed to impose these truths on others.

Vonnegut was a vocal critic of the society in which he lived, and this was reflected in his writings. Several key social themes recur in Vonnegut's works, such as wealth, the lack of it, and its unequal distribution among a society. In "The Sirens of Titan", the novel's protagonist, Malachi Constant, is exiled to one of Saturn's moons, Titan, as a result of his vast wealth, which has made him arrogant and wayward. In "God Bless You, Mr. Rosewater", readers may find it difficult to determine whether the rich or the poor are in worse circumstances as the lives of both groups' members are ruled by their wealth or their poverty. Further, in "Hocus Pocus", the protagonist is named Eugene Debs Hartke, a homage to the famed socialist Eugene V. Debs and Vonnegut's socialist views. In "Kurt Vonnegut: A Critical Companion", Thomas F. Marvin states: "Vonnegut points out that, left unchecked, capitalism will erode the democratic foundations of the United States." Marvin suggests that Vonnegut's works demonstrate what happens when a "hereditary aristocracy" develops, where wealth is inherited along familial lines: the ability of poor Americans to overcome their situations is greatly or completely diminished. Vonnegut also often laments social Darwinism, and a "survival of the fittest" view of society. He points out that social Darwinism leads to a society that condemns its poor for their own misfortune, and fails to help them out of their poverty because "they deserve their fate". Vonnegut also confronts the idea of free will in a number of his pieces. In "Slaughterhouse-Five" and "Timequake" the characters have no choice in what they do; in "Breakfast of Champions", characters are very obviously stripped of their free will and even receive it as a gift; and in "Cat's Cradle", Bokononism views free will as heretical.

The majority of Vonnegut's characters are estranged from their actual families and seek to build replacement or extended families. For example, the engineers in "Player Piano" called their manager's spouse "Mom". In "Cat's Cradle", Vonnegut devises two separate methods for loneliness to be combated: A "karass", which is a group of individuals appointed by God to do his will, and a "granfalloon", defined by Marvin as a "meaningless association of people, such as a fraternal group or a nation". Similarly, in "Slapstick", the U.S. government codifies that all Americans are a part of large extended families.

Fear of the loss of one's purpose in life is a theme in Vonnegut's works. The Great Depression forced Vonnegut to witness the devastation many people felt when they lost their jobs, and while at General Electric, Vonnegut witnessed machines being built to take the place of human labor. He confronts these things in his works through references to the growing use of automation and its effects on human society. This is most starkly represented in his first novel, "Player Piano", where many Americans are left purposeless and unable to find work as machines replace human workers. Loss of purpose is also depicted in "Galápagos", where a florist rages at her spouse for creating a robot able to do her job, and in "Timequake", where an architect kills himself when replaced by computer software.

Suicide by fire is another common theme in Vonnegut's works; the author often returns to the theory that "many people are not fond of life." He uses this as an explanation for why humans have so severely damaged their environments, and made devices such as nuclear weapons that can make their creators extinct. In "Deadeye Dick", Vonnegut features the neutron bomb, which he claims is designed to kill people, but leave buildings and structures untouched. He also uses this theme to demonstrate the recklessness of those who put powerful, apocalypse-inducing devices at the disposal of politicians.

"What is the point of life?" is a question Vonnegut often pondered in his works. When one of Vonnegut's characters, Kilgore Trout, finds the question "What is the purpose of life?" written in a bathroom, his response is, "To be the eyes and ears and conscience of the Creator of the Universe, you fool." Marvin finds Trout's theory curious, given that Vonnegut was an atheist, and thus for him, there is no Creator to report back to, and comments that, "[as] Trout chronicles one meaningless life after another, readers are left to wonder how a compassionate creator could stand by and do nothing while such reports come in." In the epigraph to "Bluebeard", Vonnegut quotes his son Mark, and gives an answer to what he believes is the meaning of life: "We are here to help each other get through this thing, whatever it is."

Unless otherwise cited, items in this list are taken from Thomas F. Marvin's 2002 book "Kurt Vonnegut: A Critical Companion", and the date in brackets is the date the work was first published:

Novels

Short fiction collections
Nonfiction

Interviews

Art





</doc>
<doc id="17011" url="https://en.wikipedia.org/wiki?curid=17011" title="Killer whale">
Killer whale

The killer whale or orca ("Orcinus orca") is a toothed whale belonging to the oceanic dolphin family, of which it is the largest member. Killer whales have a diverse diet, although individual populations often specialize in particular types of prey. Some feed exclusively on fish, while others hunt marine mammals such as seals and other species of dolphin. They have been known to attack baleen whale calves, and even adult whales. Killer whales are apex predators, as no animal preys on them. A cosmopolitan species, they can be found in each of the world's oceans in a variety of marine environments, from Arctic and Antarctic regions to tropical seas, absent only from the Baltic and Black seas, and some areas of the Arctic Ocean.

Killer whales are highly social; some populations are composed of matrilineal family groups (pods) which are the most stable of any animal species. Their sophisticated hunting techniques and vocal behaviours, which are often specific to a particular group and passed across generations, have been described as manifestations of animal culture.

The International Union for Conservation of Nature assesses the orca's conservation status as data deficient because of the likelihood that two or more killer whale types are separate species. Some local populations are considered threatened or endangered due to prey depletion, habitat loss, pollution (by PCBs), capture for marine mammal parks, and conflicts with human fisheries. In late 2005, the southern resident killer whales, which swim in British Columbia and Washington state waters, were placed on the U.S. Endangered Species list.

Wild killer whales are not considered a threat to humans, but there have been cases of captive orcas killing or injuring their handlers at marine theme parks. Killer whales feature strongly in the mythologies of indigenous cultures, with their reputation ranging from being the souls of humans to merciless killers.

Orcinus orca is the only recognized extant species in the genus "Orcinus", one of many animal species originally described by Linnaeus in 1758 in "Systema Naturae". Konrad Gessner wrote the first scientific description of a killer whale in his "Piscium & aquatilium animantium natura" of 1558, part of the larger "Historia animalium", based on examination of a dead stranded animal in the Bay of Greifswald that had attracted a great deal of local interest.

The killer whale is one of 35 species in the oceanic dolphin family, which first appeared about 11 million years ago. The killer whale lineage probably branched off shortly thereafter. Although it has morphological similarities with the pygmy killer whale, the false killer whale and the pilot whales, a study of cytochrome b gene sequences by Richard LeDuc indicated that its closest extant relatives are the snubfin dolphins of the genus "Orcaella".

Although the term "orca" is increasingly used, English-speaking scientists most often use the traditional name "killer whale". Indeed, the genus name "Orcinus" means "of the kingdom of the dead", or "belonging to Orcus".
Ancient Romans originally used "orca" (pl. "orcae") for these animals, possibly borrowing Greek ("óryx)", which referred (among other things) to a whale species. Since the 1960s, "orca" has steadily grown in popularity. The term "orca" is euphemistically preferred by some to avoid the negative connotations of "killer", and because, being part of the family Delphinidae, the species is more closely related to other dolphins than to whales.

According to some authors, the name "killer whale" is a mistranslation of the 18th-century Spanish name "asesina-ballenas" ("killer of" "whales"), possibly given by Basque whalers after observing pods of orcas hunting baleen whales.

They are sometimes referred to as "blackfish", a name also used for other whale species. "Grampus" is a former name for the species, but is now seldom used. This meaning of "grampus" should not be confused with the genus "Grampus", whose only member is Risso's dolphin.

The three to five types of killer whales may be distinct enough to be considered different races, subspecies, or possibly even species (see Species problem). The IUCN reported in 2008, "The taxonomy of this genus is clearly in need of review, and it is likely that "O. orca" will be split into a number of different species or at least subspecies over the next few years." Although large variation in the ecological distinctiveness of different killer whale groups complicate simple differentiation into types, research off the west coast of Canada and the United States in the 1970s and 1980s identified the following three types:
Transients and residents live in the same areas, but avoid each other.

Other populations have not been as well studied, although specialized fish and mammal eating killer whales have been distinguished elsewhere. In addition, separate populations of "generalist" (fish- and mammal-eating) and "specialist" (mammal-eating) killer whales have been identified off northwestern Europe. As with residents and transients, the lifestyle of these whales appears to reflect their diet; fish-eating killer whales in Alaska and Norway have resident-like social structures, while mammal-eating killer whales in Argentina and the Crozet Islands behave more like transients.

Three types have been documented in the Antarctic. Two dwarf species, named "Orcinus nanus" and "Orcinus glacialis", were described during the 1980s by Soviet researchers, but most cetacean researchers are skeptical about their status, and linking these directly to the types described below is difficult.


Types B and C live close to the ice pack, and diatoms in these waters may be responsible for the yellowish coloring of both types. Mitochondrial DNA sequences support the theory that these are recently diverged separate species. More recently, complete mitochondrial sequencing indicates the two Antarctic groups that eat seals and fish should be recognized as distinct species, as should the North Pacific transients, leaving the others as subspecies pending additional data. Advanced methods that sequenced the entire mitochondrial genome revealed systematic differences in DNA between different populations. A 2019 study of Type D orcas also found them to be distinct from other populations and possibly even a unique species.

Mammal-eating killer whales in different regions were long thought likely to be closely related, but genetic testing has refuted this hypothesis.

There are seven identified ecotypes inhabiting isolated ecological niches. Of three orca ecotypes in the Antarctic, one preys on minke whales, the second on seals and penguins, and the third on fish. Another ecotype lives in the eastern North Atlantic, while the three Northeast Pacific ecotypes are labeled the transient, resident and offshore populations described above. Research has supported a proposal to reclassify the Antarctic seal- and fish-eating populations and the North Pacific transients as a distinct species, leaving the remaining ecotypes as subspecies. The first split in the orca population, between the North Pacific transients and the rest, occurred an estimated 700,000 years ago. Such a designation would mean that each new species becomes subject to separate conservation assessments.

A typical killer whale distinctively bears a black back, white chest and sides, and a white patch above and behind the eye. Calves are born with a yellowish or orange tint, which fades to white. It has a heavy and robust body with a large dorsal fin up to tall. Behind the fin, it has a dark grey "saddle patch" across the back. Antarctic killer whales may have pale gray to nearly white backs. Adult killer whales are very distinctive, seldom confused with any other sea creature. When seen from a distance, juveniles can be confused with other cetacean species, such as the false killer whale or Risso's dolphin.

The killer whale's teeth are very strong, and its jaws exert a powerful grip; the upper teeth fall into the gaps between the lower teeth when the mouth is closed. The firm middle and back teeth hold prey in place, while the front teeth are inclined slightly forward and outward to protect them from powerful jerking movements.

Killer whales are the largest extant members of the dolphin family. Males typically range from long and weigh in excess of . Females are smaller, generally ranging from and weighing about . The largest male killer whale on record was , weighing , while the largest female was , weighing . Calves at birth weigh about and are about long. The killer whale's large size and strength make it among the fastest marine mammals, able to reach speeds in excess of . The skeleton of the killer whale is of the typical delphinid structure, but more robust. Its integument, unlike that of most other dolphin species, is characterized by a well-developed dermal layer with a dense network of fascicles of collagen fibers.

Killer whale pectoral fins, analogous to forelimbs, are large and rounded, resembling paddles, with those of males significantly larger than those of females. Dorsal fins also exhibit sexual dimorphism, with those of males about high, more than twice the size of the female's, with the male's fin more like a tall, elongated isosceles triangle, whereas the female's is shorter and more curved. Males and females also have different patterns of black and white skin in their genital areas. In the skull, adult males have longer lower jaws than females, as well as larger occipital crests.

An individual killer whale can often be identified from its dorsal fin and saddle patch. Variations such as nicks, scratches, and tears on the dorsal fin and the pattern of white or grey in the saddle patch are unique. Published directories contain identifying photographs and names for hundreds of North Pacific animals. Photographic identification has enabled the local population of killer whales to be counted each year rather than estimated, and has enabled great insight into lifecycles and social structures.

Occasionally a killer whale is white; they have been spotted in the northern Bering Sea and around St. Lawrence Island, and near the Russian coast. In February 2008, a white killer whale was photographed off Kanaga Volcano in the Aleutian Islands. In 2010, the Far East Russia Orca Project (FEROP), co-founded and co-directed by Alexander M. Burdin and Erich Hoyt, filmed an adult male nicknamed Iceberg

Killer whales have good eyesight above and below the water, excellent hearing, and a good sense of touch. They have exceptionally sophisticated echolocation abilities, detecting the location and characteristics of prey and other objects in the water by emitting clicks and listening for echoes, as do other members of the dolphin family. The mean body temperature of the orca is . Like most marine mammals, orcas have a layer of insulating blubber ranging from thick beneath the skin. The pulse is about 60 heartbeats per minute when the orca is at the surface, dropping to 30 beats/min when submerged.

Killer whales are found in all oceans and most seas. Due to their enormous range, numbers, and density, relative distribution is difficult to estimate, but they clearly prefer higher latitudes and coastal areas over pelagic environments. Areas which serve as major study sites for the species include the coasts of Iceland, Norway, the Valdes Peninsula of Argentina, the Crozet Islands, New Zealand and parts of the west coast of North America, from California to Alaska.

Systematic surveys indicate the highest densities of killer whales (>0.40 individuals per 100 km²) in the northeast Atlantic around the Norwegian coast, in the north Pacific along the Aleutian Islands, the Gulf of Alaska and in the Southern Ocean off much of the coast of Antarctica. They are considered "common" (0.20–0.40 individuals per 100 km²) in the eastern Pacific along the coasts of British Columbia, Washington and Oregon, in the North Atlantic Ocean around Iceland and the Faroe Islands. High densities have also been reported but not quantified in the western North Pacific around the Sea of Japan, Sea of Okhotsk, Kuril Islands, Kamchatka and the Commander Islands and in the Southern Hemisphere off southern Brazil and the tip of southern Africa. They are reported as seasonally common in the Canadian Arctic, including Baffin Bay between Greenland and Nunavut, as well as Tasmania and Macquarie Island and regularly occurring or distinct populations exist off Northwest Europe, California, Patagonia, the Crozet Islands, Marion Island, southern Australia and New Zealand. The northwest Atlantic population of at least 67 individuals ranges from Labrador and Newfoundland to New England with sightings to Cape Cod and Long Island.

Information for offshore regions and warmer waters is more scarce, but widespread sightings indicate the killer whale can survive in most water temperatures. They have been sighted, though more infrequently, in the Mediterranean, the Arabian Sea, the Gulf of Mexico, and the Caribbean. Over 50 individual whales have been documented in the northern Indian Ocean, including two individuals that were sighted in the Persian Gulf in 2008 and off Sri Lanka in 2015. Those orcas may occasionally enter the Red Sea through the Gulf of Aden. The modern status of the species along coastal mainland China and its vicinity is unknown. Recorded sightings have been made from almost the entire shoreline. A wide-ranging population is likely to exist in the central Pacific, with some sightings off Hawaii. Distinct populations may also exist off the west coast of tropical Africa, and Papua New Guinea. In the Mediterranean, killer whales are considered "visitors", likely from the North Atlantic, and sightings become less frequent further east. However, a small year-round population is known to exist in the Strait of Gibraltar, mostly on the Atlantic side. Killer whales also appear to regularly occur off the Galápagos Islands.

In the Antarctic, killer whales range up to the edge of the pack ice and are believed to venture into the denser pack ice, finding open leads much like beluga whales in the Arctic. However, killer whales are merely seasonal visitors to Arctic waters, and do not approach the pack ice in the summer. With the rapid Arctic sea ice decline in the Hudson Strait, their range now extends deep into the northwest Atlantic. Occasionally, killer whales swim into freshwater rivers. They have been documented up the Columbia River in the United States. They have also been found in the Fraser River in Canada and the Horikawa River in Japan.

Migration patterns are poorly understood. Each summer, the same individuals appear off the coasts of British Columbia and Washington. Despite decades of research, where these animals go for the rest of the year remains unknown. Transient pods have been sighted from southern Alaska to central California.

Worldwide population estimates are uncertain, but recent consensus suggests a minimum of 50,000. Local estimates include roughly 25,000 in the Antarctic, 8,500 in the tropical Pacific, 2,250–2,700 off the cooler northeast Pacific and 500–1,500 off Norway. Japan's Fisheries Agency estimated 2,321 killer whales were in the seas around Japan.

Killer whales are apex predators, meaning that they themselves have no natural predators. They are sometimes called the wolves of the sea, because they hunt in groups like wolf packs. Killer whales hunt varied prey including fish, cephalopods, mammals, sea birds, and sea turtles. Different populations or ecotypes may specialize, and some can have a dramatic impact on prey species. However, whales in tropical areas appear to have more generalized diets due to lower food productivity.

Fish-eating killer whales prey on around 30 species of fish. Some populations in the Norwegian and Greenland sea specialize in herring and follow that fish's autumnal migration to the Norwegian coast. Salmon account for 96% of northeast Pacific residents' diet, including 65% of large, fatty Chinook. Chum salmon are also eaten, but smaller sockeye and pink salmon are not a significant food item. Depletion of specific prey species in an area is, therefore, cause for concern for local populations, despite the high diversity of prey. On average, a killer whale eats each day. While salmon are usually hunted by an individual whale or a small group, herring are often caught using carousel feeding: the killer whales force the herring into a tight ball by releasing bursts of bubbles or flashing their white undersides. They then slap the ball with their tail flukes, stunning or killing up to 15 fish at a time, then eating them one by one. Carousel feeding has only been documented in the Norwegian killer whale population, as well as some oceanic dolphin species.

In New Zealand, sharks and rays appear to be important prey, including eagle rays, long-tail and short-tail stingrays, common threshers, smooth hammerheads, blue sharks, basking sharks and shortfin mako sharks. With sharks, orcas may herd them to the surface and strike them with their tail flukes, while bottom-dwelling rays are cornered, pinned to the ground and taken to the surface. In other parts of the world, killer whales have preyed on broadnose sevengill sharks, tiger sharks and even small whale sharks. Killer whales have also been recorded feeding on great white sharks, including one incident filmed near the Farallon Islands in October 1997, where a female orca killed a white shark, possibly inducing tonic immobility before feeding. A pod of orcas have been recorded killing a white shark off South Australia, with possible kills in South Africa. The whales appear to target the shark's liver. Competition between killer whales and white sharks is probable in regions where their diets overlap.

Killer whales are very sophisticated and effective predators of marine mammals. Thirty-two cetacean species have been recorded as prey, from observing orcas' feeding activity, examining the stomach contents of dead orcas, and seeing scars on the bodies of surviving prey animals. Groups even attack larger cetaceans such as minke whales, gray whales, and, rarely, sperm whales or blue whales.

Hunting a large whale usually takes several hours. Killer whales generally attack young or weak animals; however, a group of five or more may attack a healthy adult. When hunting a young whale, a group chases it and its mother to exhaustion. Eventually, they separate the pair and surround the calf, drowning it by keeping it from surfacing. Pods of female sperm whales sometimes protect themselves by forming a protective circle around their calves with their flukes facing outwards, using them to repel the attackers. Rarely, large killer whale pods can overwhelm even adult female sperm whales. Adult bull sperm whales, which are large, powerful and aggressive when threatened, and fully grown adult blue whales, which are possibly too large to overwhelm, are not believed to be prey for killer whales.

Prior to the advent of industrial whaling, great whales may have been the major food source for killer whales. The introduction of modern whaling techniques may have aided killer whales by the sound of exploding harpoons indicating availability of prey to scavenge, and compressed air inflation of whale carcasses causing them to float, thus exposing them to scavenging. However, the devastation of great whale populations by unfettered whaling has possibly reduced their availability for killer whales, and caused them to expand their consumption of smaller marine mammals, thus contributing to the decline of these as well.

It has been hypothesised that predation by orcas on whale calves in high-productivity, high-latitude areas is the reason for great whale migrations during breeding season to low-productivity tropical waters where orcas are scarcer.
Other marine mammal prey species include nearly 20 species of seal, sea lion and fur seal. Walruses and sea otters are less frequently taken. Often, to avoid injury, killer whales disable their prey before killing and eating it. This may involve throwing it in the air, slapping it with their tails, ramming it, or breaching and landing on it. Sea lions are killed by head-butting or after a stunning blow from a tail fluke. In the Aleutian Islands, a decline in sea otter populations in the 1990s was controversially attributed by some scientists to killer whale predation, although with no direct evidence. The decline of sea otters followed a decline in harbour seal and Steller sea lion populations, the killer whale's preferred prey, which in turn may be substitutes for their original prey, now decimated by industrial whaling.

In steeply banked beaches off Península Valdés, Argentina, and the Crozet Islands, killer whales feed on South American sea lions and southern elephant seals in shallow water, even beaching temporarily to grab prey before wriggling back to the sea. Beaching, usually fatal to cetaceans, is not an instinctive behaviour, and can require years of practice for the young. Killer whales can then release the animal near juvenile whales, allowing the younger whales to practice the difficult capture technique on the now-weakened prey. "Wave-hunting" killer whales spy-hop to locate Weddell seals, crabeater seals, leopard seals, and penguins resting on ice floes, and then swim in groups to create waves that wash over the floe. This washes the prey into the water, where other killer whales lie in wait.

Killer whales have also been observed preying on terrestrial mammals, such as deer swimming between islands off the northwest coast of North America. Killer whale cannibalism has also been reported based on analysis of stomach contents, but this is likely to be the result of scavenging remains dumped by whalers. One killer whale was also attacked by its companions after being shot. Although resident killer whales have never been observed to eat other marine mammals, they occasionally harass and kill porpoises and seals for no apparent reason.

Killer whales in many areas may prey on cormorants and gulls. A captive killer whale at MarineLand discovered it could regurgitate fish onto the surface, attracting sea gulls, and then eat the birds. Four others then learned to copy the behaviour.

Day-to-day killer whale behaviour generally consists of foraging, travelling, resting and socializing. Killer whales frequently engage in surface behaviour such as breaching (jumping completely out of the water) and tail-slapping. These activities may have a variety of purposes, such as courtship, communication, dislodging parasites, or play. Spyhopping is a behaviour in which a whale holds its head above water to view its surroundings.

Resident killer whales swim alongside porpoises, other dolphins, seals, and sea lions, which are common prey for transient killer whales.

Killer whales are notable for their complex societies. Only elephants and higher primates live in comparably complex social structures. Due to orcas' complex social bonds, many marine experts have concerns about how humane it is to keep them in captivity.

Resident killer whales in the eastern North Pacific live in particularly complex and stable social groups. Unlike any other known mammal social structure, resident whales live with their mothers for their entire lives. These family groups are based on matrilines consisting of the eldest female (matriarch) and her sons and daughters, and the descendants of her daughters, etc. The average size of a matriline is 5.5 animals. Because females can reach age 90, as many as four generations travel together. These matrilineal groups are highly stable. Individuals separate for only a few hours at a time, to mate or forage. With one exception, a killer whale named Luna, no permanent separation of an individual from a resident matriline has been recorded.

Closely related matrilines form loose aggregations called pods, usually consisting of one to four matrilines. Unlike matrilines, pods may separate for weeks or months at a time. DNA testing indicates resident males nearly always mate with females from other pods. Clans, the next level of resident social structure, are composed of pods with similar dialects, and common but older maternal heritage. Clan ranges overlap, mingling pods from different clans. The final association layer, perhaps more arbitrarily defined than the familial groupings, is called the community, and is defined as a set of clans that regularly commingle. Clans within a community do not share vocal patterns.

Transient pods are smaller than resident pods, typically consisting of an adult female and one or two of her offspring. Males typically maintain stronger relationships with their mothers than other females. These bonds can extend well into adulthood. Unlike residents, extended or permanent separation of transient offspring from natal matrilines is common, with juveniles and adults of both sexes participating. Some males become "rovers" and do not form long-term associations, occasionally joining groups that contain reproductive females. As in resident clans, transient community members share an acoustic repertoire, although regional differences in vocalizations have been noted.

Like all cetaceans, killer whales depend heavily on underwater sound for orientation, feeding, and communication. They produce three categories of sounds: clicks, whistles, and pulsed calls. Clicks are believed to be used primarily for navigation and discriminating prey and other objects in the surrounding environment, but are also commonly heard during social interactions.

Northeast Pacific resident groups tend to be much more vocal than transient groups in the same waters. Residents feed primarily on Chinook and chum salmon, species that are insensitive to killer whale calls (inferred from the audio-gram of Atlantic salmon). In contrast, the marine mammal prey of transients hear well underwater at the frequencies used in killer whale calls. As such, transients are typically silent, probably to avoid alerting their mammalian prey. They sometimes use a single click (called a cryptic click) rather than the long train of clicks observed in other populations. Residents are only silent when resting.

All members of a resident pod use similar calls, known collectively as a dialect. Dialects are composed of specific numbers and types of discrete, repetitive calls. They are complex and stable over time. Call patterns and structure are distinctive within matrilines. Newborns produce calls similar to their mothers, but have a more limited repertoire. Individuals likely learn their dialect through contact with their mother and other pod members. For instance, family-specific calls have been observed more frequently in the days following a calf's birth, which may help the calf learn them. Dialects are probably an important means of maintaining group identity and cohesiveness. Similarity in dialects likely reflects the degree of relatedness between pods, with variation building over time. When pods meet, dominant call types decrease and subset call types increase. The use of both call types is called biphonation. The increased subset call types may be the distinguishing factor between pods and inter-pod relations.

Dialects of killer whales not only distinguish them between pods, but also between types. Resident dialects contain seven to 17 (mean = 11) distinctive call types. All members of the North American west coast transient community express the same basic dialect, although minor regional variation in call types is evident. Preliminary research indicates offshore killer whales have group-specific dialects unlike those of residents and transients.

The vocalizations of killer whales in other parts of the world have also been studied. Norwegian and Icelandic herring-eating orcas appear to have different vocalizations for activities like hunting and traveling.

Killer whales have the second-heaviest brains among marine mammals (after sperm whales, which have the largest brain of any animal). They can be trained in captivity and are often described as intelligent, although defining and measuring "intelligence" is difficult in a species whose environment and behavioral strategies are very different from those of humans.
Killer whales imitate others, and seem to deliberately teach skills to their kin. Off the Crozet Islands, mothers push their calves onto the beach, waiting to pull the youngster back if needed.

People who have interacted closely with killer whales offer numerous anecdotes demonstrating the whales' curiosity, playfulness, and ability to solve problems. Alaskan killer whales have not only learned how to steal fish from longlines, but have also overcome a variety of techniques designed to stop them, such as the use of unbaited lines as decoys. Once, fishermen placed their boats several miles apart, taking turns retrieving small amounts of their catch, in the hope that the whales would not have enough time to move between boats to steal the catch as it was being retrieved. A researcher described what happened next:

In other anecdotes, researchers describe incidents in which wild killer whales playfully tease humans by repeatedly moving objects the humans are trying to reach, or suddenly start to toss around a chunk of ice after a human throws a snowball.

The killer whale's use of dialects and the passing of other learned behaviours from generation to generation have been described as a form of animal culture.

Female killer whales begin to mature at around the age of 10 and reach peak fertility around 20, experiencing periods of polyestrous cycling separated by non-cycling periods of three to 16 months. Females can often breed until age 40, followed by a rapid decrease in fertility. As such, orcas are among the few animals that undergo menopause and live for decades after they have finished breeding. The lifespans of wild females average 50 years. Some are claimed to have lived substantially longer: Granny (J2) was estimated by some researchers to have been as old as 105 years at the time of her death, though a biopsy sample indicated her age as 65 to 80 years.

To avoid inbreeding, males mate with females from other pods. Gestation varies from 15 to 18 months. Mothers usually calve a single offspring about once every five years. In resident pods, births occur at any time of year, although winter is the most common. Mortality is extremely high during the first seven months of life, when 37–50% of all calves die. Weaning begins at about 12 months of age, and is complete by two years. According to observations in several regions, all male and female pod members participate in the care of the young.

Males sexually mature at the age of 15, but do not typically reproduce until age 21. Wild males live around 29 years on average, with a maximum of about 60 years. One male, known as Old Tom, was reportedly spotted every winter between the 1840s and 1930 off New South Wales, Australia. This would have made him up to 90 years old. Examination of his teeth indicated he died around age 35, but this method of age determination is now believed to be inaccurate for older animals. One male known to researchers in the Pacific Northwest (identified as J1) was estimated to have been 59 years old when he died in 2010. Killer whales are unique among cetaceans, as their caudal sections enlongate with age, making their heads relatively shorter.

Infanticide, once thought to occur only in captive killer whales, was observed in wild populations by researchers off British Columbia on Dec. 2, 2016. In this incident, an adult male killed the calf of a female within the same pod, with his mother also joining in the assault. It is theorized that the male killed the young calf in order to mate with its mother (something that occurs in other carnivore species), while the male's mother supported the breeding opportunity for her son. The attack ended when the calf's mother struck and injured the attacking male. Such behavior matches that of many smaller dolphin species such as the bottlenose dolphin.

In 2008, the IUCN (International Union for Conservation of Nature) changed its assessment of the killer whale's conservation status from conservation dependent to data deficient, recognizing that one or more killer whale types may actually be separate, endangered species. Depletion of prey species, pollution, large-scale oil spills, and habitat disturbance caused by noise and conflicts with boats are the most significant worldwide threats.

Like other animals at the highest trophic levels, the killer whale is particularly at risk of poisoning from bioaccumulation of toxins, including polychlorinated biphenyls (PCBs). European harbor seals have problems in reproductive and immune functions associated with high levels of PCBs and related contaminants, and a survey off the Washington coast found PCB levels in killer whales were higher than levels that had caused health problems in harbor seals. Blubber samples in the Norwegian Arctic show higher levels of PCBs, pesticides and brominated flame-retardants than in polar bears. When food is scarce, killer whales metabolize blubber for energy, which increases pollutant concentrations in their blood.

In the Pacific Northwest, wild salmon stocks, a main resident food source, have declined dramatically in recent years. In the Puget Sound region only 75 whales remain with few births over the last few years. On the west coast of Alaska and the Aleutian Islands, seal and sea lion populations have also substantially declined.

In 2005, the United States government listed the southern resident community as an endangered population under the Endangered Species Act. This community comprises three pods which live mostly in the Georgia and Haro Straits and Puget Sound in British Columbia and Washington. They do not breed outside of their community, which was once estimated at around 200 animals and later shrank to around 90. In October 2008, the annual survey revealed seven were missing and presumed dead, reducing the count to 83. This is potentially the largest decline in the population in the past ten years. These deaths can be attributed to declines in Chinook salmon.

Scientist Ken Balcomb has extensively studied killer whales since 1976; he is the research biologist responsible for discovering U.S. Navy sonar may harm killer whales. He studied killer whales from the Center for Whale Research, located in Friday Harbor, Washington. He was also able to study killer whales from "his home porch perched above Puget Sound, where the animals hunt and play in summer months". In May 2003, Balcomb (along with other whale watchers near the Puget Sound coastline) noticed uncharacteristic behaviour displayed by the killer whales. The whales seemed "agitated and were moving haphazardly, attempting to lift their heads free of the water" to escape the sound of the sonars. "Balcomb confirmed at the time that strange underwater pinging noises detected with underwater microphones were sonar. The sound originated from a U.S. Navy frigate 12 miles (19 kilometers) distant, Balcomb said." The impact of sonar waves on killer whales is potentially life-threatening. Three years prior to Balcomb's discovery, research in the Bahamas showed 14 beaked whales washed up on the shore. These whales were beached on the day U.S. Navy destroyers were activated into sonar exercise. Of the 14 whales beached, six of them died. These six dead whales were studied, and CAT scans of two of the whale heads showed hemorrhaging around the brain and the ears, which is consistent with decompression sickness.

Another conservation concern was made public in September 2008 when the Canadian government decided it was not necessary to enforce further protections (including the Species at Risk Act in place to protect endangered animals along their habitats) for killer whales aside from the laws already in place. In response to this decision, six environmental groups sued the federal government, claiming killer whales were facing many threats on the British Columbia Coast and the federal government did nothing to protect them from these threats. A legal and scientific nonprofit organization, Ecojustice, led the lawsuit and represented the David Suzuki Foundation, Environmental Defence, Greenpeace Canada, International Fund for Animal Welfare, the Raincoast Conservation Foundation, and the Wilderness Committee. Many scientists involved in this lawsuit, including Bill Wareham, a marine scientist with the David Suzuki Foundation, noted increased boat traffic, water toxic wastes, and low salmon population as major threats, putting approximately 87 killer whales on the British Columbia Coast in danger.

Underwater noise from shipping, drilling, and other human activities is a significant concern in some key killer whale habitats, including Johnstone Strait and Haro Strait. In the mid-1990s, loud underwater noises from salmon farms were used to deter seals. Killer whales also avoided the surrounding waters. High-intensity sonar used by the Navy disturbs killer whales along with other marine mammals. Killer whales are popular with whale watchers, which may stress the whales and alter their behavior, particularly if boats approach too closely or block their lines of travel.

The "Exxon Valdez" oil spill adversely affected killer whales in Prince William Sound and Alaska's Kenai Fjords region. Eleven members (about half) of one resident pod disappeared in the following year. The spill damaged salmon and other prey populations, which in turn damaged local killer whales. By 2009, scientists estimated the AT1 transient population (considered part of a larger population of 346 transients), numbered only seven individuals and had not reproduced since the spill. This population is expected to die out.

A 2018 study published in "Science" found that global killer whale populations are poised to dramatically decline due to exposure to toxic chemical and PCB pollution.

The indigenous peoples of the Pacific Northwest Coast feature killer whales throughout their art, history, spirituality and religion. The Haida regarded killer whales as the most powerful animals in the ocean, and their mythology tells of killer whales living in houses and towns under the sea. According to these myths, they took on human form when submerged, and humans who drowned went to live with them. For the Kwakwaka'wakw, the killer whale was regarded as the ruler of the undersea world, with sea lions for slaves and dolphins for warriors. In Nuu-chah-nulth and Kwakwaka'wakw mythology, killer whales may embody the souls of deceased chiefs. The Tlingit of southeastern Alaska regarded the killer whale as custodian of the sea and a benefactor of humans.

The Maritime Archaic people of Newfoundland also had great respect for killer whales, as evidenced by stone carvings found in a 4,000-year-old burial at the Port au Choix Archaeological Site.

In the tales and beliefs of the Siberian Yupik people, killer whales are said to appear as wolves in winter, and wolves as killer whales in summer. Killer whales are believed to assist their hunters in driving walrus. Reverence is expressed in several forms: the boat represents the animal, and a wooden carving hung from the hunter's belt. Small sacrifices such as tobacco are strewn into the sea for them. Killer whales were believed to have helped the hunters even when in wolf guise, by forcing reindeer to allow themselves to be killed.

Indigenous Ainu tribe often refereed killer whales in their folklore and myth as "Repun Kamuy" (God of Sea/Offshore) to bring fortunes (whales) to the coasts, and there had been traditional funerals for stranded or deceased orcas akin to funerals for other animals such as brown bears.

In Western cultures, killer whales were historically feared as dangerous, savage predators. The first written description of a killer whale was given by Pliny the Elder "circa" AD 70, who wrote, "Orcas (the appearance of which no image can express, other than an enormous mass of savage flesh with teeth) are the enemy of [other whales]... they charge and pierce them like warships ramming."

Of the very few confirmed attacks on humans by wild killer whales, none have been fatal. In one instance, killer whales tried to tip ice floes on which a dog team and photographer of the Terra Nova Expedition were standing. The sled dogs' barking is speculated to have sounded enough like seal calls to trigger the killer whale's hunting curiosity. In the 1970s, a surfer in California was bitten, and in 2005, a boy in Alaska who was splashing in a region frequented by harbor seals was bumped by a killer whale that apparently misidentified him as prey. Unlike wild killer whales, captive killer whales are reported to have made nearly two dozen attacks on humans since the 1970s, some of which have been fatal.

Competition with fishermen also led to killer whales being regarded as pests. In the waters of the Pacific Northwest and Iceland, the shooting of killer whales was accepted and even encouraged by governments. As an indication of the intensity of shooting that occurred until fairly recently, about 25% of the killer whales captured in Puget Sound for aquarium through 1970 bore bullet scars. The U.S. Navy claimed to have deliberately killed hundreds of killer whales in Icelandic waters in 1956 with machine-guns, rockets, and depth charges.

Western attitudes towards killer whales have changed dramatically in recent decades. In the mid-1960s and early 1970s, killer whales came to much greater public and scientific awareness, starting with the first live-capture and display of a killer whale known as Moby Doll, a resident harpooned off Saturna Island in 1964. So little was known at the time, it was nearly two months before the whale's keepers discovered what food (fish) it was willing to eat. To the surprise of those who saw him, Moby Doll was a docile, nonaggressive whale that made no attempts to attack humans.

Between 1964 and 1976, 50 killer whales from the Pacific Northwest were captured for display in aquaria, and public interest in the animals grew. In the 1970s, research pioneered by Michael Bigg led to the discovery of the species' complex social structure, its use of vocal communication, and its extraordinarily stable mother–offspring bonds. Through photo-identification techniques, individuals were named and tracked over decades.

Bigg's techniques also revealed the Pacific Northwest population was in the low hundreds rather than the thousands that had been previously assumed. The southern resident community alone had lost 48 of its members to captivity; by 1976, only 80 remained. In the Pacific Northwest, the species that had unthinkingly been targeted became a cultural icon within a few decades.

The public's growing appreciation also led to growing opposition to whale–keeping in aquarium. Only one whale has been taken in North American waters since 1976. In recent years, the extent of the public's interest in killer whales has manifested itself in several high-profile efforts surrounding individuals. Following the success of the 1993 film "Free Willy", the movie's captive star Keiko was returned to the coast of his native Iceland in 1998. The director of the International Marine Mammal Project for the Earth Island Institute, David Phillips, led the efforts to return Keiko to the Iceland waters. In 2002, the orphan Springer was discovered in Puget Sound, Washington. She became the first whale to be successfully reintegrated into a wild pod after human intervention, crystallizing decades of research into the vocal behavior and social structure of the region's killer whales. The saving of Springer raised hopes that another young killer whale named Luna, which had become separated from his pod, could be returned to it. However, his case was marked by controversy about whether and how to intervene, and in 2006, Luna was killed by a boat propeller.

The earlier of known records of commercial hunting of killer whales date to the 18th century in Japan. During the 19th and early 20th centuries, the global whaling industry caught immense numbers of baleen and sperm whales, but largely ignored killer whales because of their limited amounts of recoverable oil, their smaller populations, and the difficulty of taking them. Once the stocks of larger species were depleted, killer whales were targeted by commercial whalers in the mid-20th century. Between 1954 and 1997, Japan took 1,178 killer whales (although the Ministry of the Environment claims that there had been domestic catches of about 1,600 whales between late 1940s to 1960s) and Norway took 987. Over 3,000 killer whales were taken by Soviet whalers, including an Antarctic catch of 916 in 1979–80 alone, prompting the International Whaling Commission to recommend a ban on commercial hunting of the species pending further research. (Compare with the situation on land, commercial hunting.) Today, no country carries out a substantial hunt, although Indonesia and Greenland permit small subsistence hunts (see Aboriginal whaling). Other than commercial hunts, killer whales were hunted along Japanese coasts out of public concern for potential conflicts with fisheries. Such cases include a semi-resident male-female pair in Akashi Strait and Harimanada being killed in the Seto Inland Sea in 1957, the killing of five whales from a pod of 11 members that swam into Tokyo Bay in 1970, and a catch record in southern Taiwan in the 1990s.

Killer whales have helped humans hunting other whales. One well-known example was the killer whales of Eden, Australia, including the male known as Old Tom. Whalers more often considered them a nuisance, however, as orcas would gather to scavenge meat from the whalers' catch. Some populations, such as in Alaska's Prince William Sound, may have been reduced significantly by whalers shooting them in retaliation.

Whale watching continues to increase in popularity, but may have some problematic impacts on killer whales. Exposure to exhaust gasses from large amounts of vessel traffic are causing concern for the overall health of the 75 remaining Southern Resident Killer Whales (SRKWs) left as of early 2019.. This population is followed by approximately 20 vessels for 12 hours a day during the months May-September. Researchers discovered that these vessels are in the line of sight for these whales for 98-99.5% of daylight hours. With so many vessels, the air quality around these whales deteriorates and impacts their health. Air pollutants that bind with exhaust fumes are responsible for the activation of the cytochrome P450 1A gene family. Researchers have successfully identified this gene in skin biopsies of live whales and also the lungs of deceased whales. A direct correlation between activation of this gene and the air pollutants can not be made because there are other known factors that will induce the same gene. Vessels can have either wet or dry exhaust systems, with wet exhaust systems leaving more pollutants in the water due to various gas solubility. A modeling study determined that the lowest-observed-adverse-effect-level (LOAEL) of exhaust pollutants was about 12% of the human dose. 

As a response to this, in 2017 boats off the British Columbia coast now have a minimum approach distance of 200 meters compared to the previous 100 meters. This new rule compliments Washington State’s minimum approach zone of 180 meters that has been in effect since 2011. If a whale approaches a vessel it must be placed in neutral until the whale passes. The World Health Organization has set air quality standards in an effort to control the emissions produced by these vessels.

The killer whale's intelligence, trainability, striking appearance, playfulness in captivity and sheer size have made it a popular exhibit at aquaria and aquatic theme parks. From 1976 to 1997, 55 whales were taken from the wild in Iceland, 19 from Japan, and three from Argentina. These figures exclude animals that died during capture. Live captures fell dramatically in the 1990s, and by 1999, about 40% of the 48 animals on display in the world were captive-born.

Organizations such as World Animal Protection and the Whale and Dolphin Conservation campaign against the practice of keeping them in captivity. In captivity, they often develop pathologies, such as the dorsal fin collapse seen in 60–90% of captive males. Captives have vastly reduced life expectancies, on average only living into their 20s. In the wild, females who survive infancy live 46 years on average, and up to 70–80 years in rare cases. Wild males who survive infancy live 31 years on average, and up to 50–60 years. Captivity usually bears little resemblance to wild habitat, and captive whales' social groups are foreign to those found in the wild. Critics claim captive life is stressful due to these factors and the requirement to perform circus tricks that are not part of wild killer whale behavior, see above. Wild killer whales may travel up to in a day, and critics say the animals are too big and intelligent to be suitable for captivity. Captives occasionally act aggressively towards themselves, their tankmates, or humans, which critics say is a result of stress. Between 1991 and 2010, the bull orca known as Tilikum was involved in the death of three people, and was featured in the critically acclaimed 2013 film, "Blackfish". Tilikum lived at SeaWorld from 1992 until his death in 2017.

A 2015 study coauthored by staff at SeaWorld and the Minnesota Zoo indicates that there is no significant difference in survivorship between free-ranging and captive killer whales. The authors speculate about the future utility of studying captive populations for the purposes of understanding orca biology and the implications of such research of captive animals in the overall health of both wild and marine park populations.

As of March 2016, SeaWorld has announced that they will be ending their orca breeding program and their theatrical shows. They previously announced, in November 2015, that the shows would be coming to an end in San Diego but it is now to happen in both Orlando and San Antonio as well.





</doc>
<doc id="17143" url="https://en.wikipedia.org/wiki?curid=17143" title="Koala">
Koala

The koala ("Phascolarctos cinereus", or, inaccurately, koala bear) is an arboreal herbivorous marsupial native to Australia. It is the only extant representative of the family Phascolarctidae and its closest living relatives are the wombats, which comprise the family Vombatidae.. The koala is found in coastal areas of the mainland's eastern and southern regions, inhabiting Queensland, New South Wales, Victoria, and South Australia. It is easily recognisable by its stout, tailless body and large head with round, fluffy ears and large, spoon-shaped nose. The koala has a body length of and weighs . Pelage colour ranges from silver grey to chocolate brown. Koalas from the northern populations are typically smaller and lighter in colour than their counterparts further south. These populations possibly are separate subspecies, but this is disputed.

Koalas typically inhabit open eucalypt woodlands, and the leaves of these trees make up most of their diet. Because this eucalypt diet has limited nutritional and caloric content, koalas are largely sedentary and sleep up to 20 hours a day. They are asocial animals, and bonding exists only between mothers and dependent offspring. Adult males communicate with loud bellows that intimidate rivals and attract mates. Males mark their presence with secretions from scent glands located on their chests. Being marsupials, koalas give birth to underdeveloped young that crawl into their mothers' pouches, where they stay for the first six to seven months of their lives. These young koalas, known as joeys, are fully weaned around a year old. Koalas have few natural predators and parasites, but are threatened by various pathogens, such as Chlamydiaceae bacteria and the koala retrovirus, as well as by bushfires and droughts.

Koalas were hunted by Indigenous Australians and depicted in myths and cave art for millennia. The first recorded encounter between a European and a koala was in 1798, and an image of the animal was published in 1810 by naturalist George Perry. Botanist Robert Brown wrote the first detailed scientific description of the koala in 1814, although his work remained unpublished for 180 years. Popular artist John Gould illustrated and described the koala, introducing the species to the general British public. Further details about the animal's biology were revealed in the 19th century by several English scientists. Because of its distinctive appearance, the koala is recognised worldwide as a symbol of Australia. Koalas are listed as Vulnerable by the International Union for Conservation of Nature. The Australian government similarly lists specific populations in Queensland and New South Wales as Vulnerable. The animal was hunted heavily in the early 20th century for its fur, and large-scale cullings in Queensland resulted in a public outcry that initiated a movement to protect the species. Sanctuaries were established, and translocation efforts moved to new regions koalas whose habitat had become fragmented or reduced. The biggest threat to their existence is habitat destruction caused by agriculture and urbanisation.

The word koala comes from the Dharug "gula". Although the vowel 'u' was originally written in the English orthography as "oo" (in spellings such as "coola" or "koolah"), it was changed to "oa", possibly in error. Because of the koala's supposed resemblance to a bear, it was often miscalled the koala bear, particularly by early settlers. The generic name, "Phascolarctos", is derived from the Greek words "phaskolos" "pouch" and "arktos" "bear". The specific name, "cinereus", is Latin for "ash coloured".

The koala was given its generic name "Phascolarctos" in 1816 by French zoologist Henri Marie Ducrotay de Blainville, who would not give it a specific name until further review. In 1819, German zoologist Georg August Goldfuss gave it the binomial "Lipurus cinereus". Because "Phascolarctos" was published first, according to the International Code of Zoological Nomenclature, it has priority as the official name of the genus. French naturalist Anselme Gaëtan Desmarest proposed the name "Phascolartos fuscus" in 1820, suggesting that the brown-coloured versions were a different species than the grey ones. Other names suggested by European authors included "Marodactylus cinereus" by Goldfuss in 1820, "P. flindersii" by René Primevère Lesson in 1827, and "P. koala" by John Edward Gray in 1827.

The koala is classified with wombats (family Vombatidae) and several extinct families (including marsupial tapirs, marsupial lions and giant wombats) in the suborder Vombatiformes within the order Diprotodontia. The Vombatiformes are a sister group to a clade that includes macropods (kangaroos and wallabies) and possums. The ancestors of vombatiforms were likely arboreal, and the koala's lineage was possibly the first to branch off around 40 million years ago during the Eocene.

The modern koala is the only extant member of Phascolarctidae, a family that once included several genera and species. During the Oligocene and Miocene, koalas lived in rainforests and had less specialised diets. Some species, such as the Riversleigh rainforest koala ("Nimiokoala greystanesi") and some species of "Perikoala", were around the same size as the modern koala, while others, such as species of "Litokoala", were one-half to two-thirds its size. Like the modern species, prehistoric koalas had well developed ear structures which suggests that long-distance vocalising and sedentism developed early. During the Miocene, the Australian continent began drying out, leading to the decline of rainforests and the spread of open "Eucalyptus" woodlands. The genus "Phascolarctos" split from "Litokoala" in the late Miocene and had several adaptations that allowed it to live on a specialised eucalyptus diet: a shifting of the palate towards the front of the skull; larger molars and premolars; smaller pterygoid fossa; and a larger gap between the molar and the incisor teeth.

During the Pliocene and Pleistocene, when Australia experienced changes in climate and vegetation, koala species grew larger. "P. cinereus" may have emerged as a dwarf form of the giant koala ("P. stirtoni"). The reduction in the size of large mammals has been seen as a common phenomenon worldwide during the late Pleistocene, and several Australian mammals, such as the agile wallaby, are traditionally believed to have resulted from this dwarfing. A 2008 study questions this hypothesis, noting that "P. cinereus" and "P. stirtoni" were sympatric during the middle to late Pleistocene, and possibly as early as the Pliocene. The fossil record of the modern koala extends back at least to the middle Pleistocene.

Traditionally, three distinct subspecies have been recognised: the Queensland koala ("P. c. adustus", Thomas 1923), the New South Wales koala ("P. c. cinereus", Goldfuss 1817), and the Victorian koala ("P. c. victor", Troughton 1935). These forms are distinguished by pelage colour and thickness, body size, and skull shape. The Queensland koala is the smallest of the three, with shorter, silver fur and a shorter skull. The Victorian koala is the largest, with shaggier, brown fur and a wider skull. The boundaries of these variations are based on state borders, and their status as subspecies is disputed. A 1999 genetic study suggests that the variations represent differentiated populations with limited gene flow between them, and that the three subspecies comprise a single evolutionarily significant unit. Other studies have found that koala populations have high levels of inbreeding and low genetic variation. Such low genetic diversity may have been a characteristic of koala populations since the late Pleistocene. Rivers and roads have been shown to limit gene flow and contribute to the genetic differentiation of southeast Queensland populations. In April 2013, scientists from the Australian Museum and Queensland University of Technology announced they had fully sequenced the koala genome.

The koala is a stocky animal with a large head and vestigial or non-existent tail. It has a body length of and a weight of , making it among the largest arboreal marsupials. Koalas from Victoria are twice as heavy as those from Queensland. The species is sexually dimorphic, with males 50% larger than females. Males are further distinguished from females by their more curved noses and the presence of chest glands, which are visible as hairless patches. As in most marsupials, the male koala has a bifurcated penis, and the female has two lateral vaginas and two separate uteri. The male's penile sheath contains naturally occurring bacteria that play an important role in fertilisation. The female's pouch opening is tightened by a sphincter that keeps the young from falling out.

The pelage of the koala is thicker and longer on the back, and shorter on the belly. The ears have thick fur on both the inside and outside. The back fur colour varies from light grey to chocolate brown. The belly fur is whitish; on the rump it is dappled whitish, and darker at the back. The koala has the most effective insulating back fur of any marsupial and is highly resilient to wind and rain, while the belly fur can reflect solar radiation. The koala's curved, sharp claws are well adapted for climbing trees. The large forepaws have two opposable digits (the first and second, which are opposable to the other three) that allow them to grasp small branches. On the hindpaws, the second and third digits are fused, a typical condition for members of the Diprotodontia, and the attached claws (which are still separate) are used for grooming. As in humans and other primates, koalas have friction ridges on their paws. The animal has a sturdy skeleton and a short, muscular upper body with proportionately long upper limbs that contribute to its climbing and grasping abilities. Additional climbing strength is achieved with thigh muscles that attach to the shinbone lower than other animals. The koala has a cartilaginous pad at the end of the spine that may make it more comfortable when it perches in the fork of a tree.
The koala has one of the smallest brains in proportion to body weight of any mammal, being 60% smaller than that of a typical diprotodont, weighing only . The brain's surface is fairly smooth, typical for a "primitive" animal. It occupies only 61% of the cranial cavity and is pressed against the inside surface by cerebrospinal fluid. The function of this relatively large amount of fluid is not known, although one possibility is that it acts as a shock absorber, cushioning the brain if the animal falls from a tree. The koala's small brain size may be an adaptation to the energy restrictions imposed by its diet, which is insufficient to sustain a larger brain. Because of its small brain, the koala has a limited ability to perform complex, unfamiliar behaviours. For example, when presented with plucked leaves on a flat surface, the animal cannot adapt to the change in its normal feeding routine and will not eat the leaves. The koala's olfactory senses are normal, and it is known to sniff the oils of individual branchlets to assess their edibility. Its nose is fairly large and covered in leathery skin. Its round ears provide it with good hearing, and it has a well-developed middle ear. A koala's vision is not well developed, and its relatively small eyes are unusual among marsupials in that the pupils have vertical slits. Koalas make use of a novel vocal organ to produce low-pitched sounds (see social spacing, below). Unlike typical mammalian vocal cords, which are folds in the larynx, these organs are placed in the velum (soft palate) and are called velar vocal cords.

The koala has several adaptations for its eucalypt diet, which is of low nutritive value, of high toxicity, and high in dietary fibre. The animal's dentition consists of the incisors and cheek teeth (a single premolar and four molars on each jaw), which are separated by a large gap (a characteristic feature of herbivorous mammals). The incisors are used for grasping leaves, which are then passed to the premolars to be snipped at the petiole before being passed to the highly cusped molars, where they are shredded into small pieces. Koalas may also store food in their cheek pouches before it is ready to be chewed. The partially worn molars of middle-aged koalas are optimal for breaking the leaves into small particles, resulting in more efficient stomach digestion and nutrient absorption in the small intestine, which digests the eucalyptus leaves to provide most of the animal's energy. A koala sometimes regurgitates the food into the mouth to be chewed a second time.

Unlike kangaroos and eucalyptus-eating possums, koalas are hindgut fermenters, and their digestive retention can last for up to 100 hours in the wild, or up to 200 hours in captivity. This is made possible by the extraordinary length of their caecum— long and in diameter—the largest proportionally of any animal. Koalas can select which food particles to retain for longer fermentation and which to pass through. Large particles typically pass through more quickly, as they would take more time to digest. While the hindgut is proportionally larger in the koala than in other herbivores, only 10% of the animal's energy is obtained from fermentation. Since the koala gains a low amount of energy from its diet, its metabolic rate is half that of a typical mammal, although this can vary between seasons and sexes. The koala conserves water by passing relatively dry faecal pellets high in undigested fibre, and by storing water in the caecum.

The koala's geographic range covers roughly , and 30 ecoregions. It extends throughout eastern and southeastern Australia, encompassing northeastern, central and southeastern Queensland, eastern New South Wales, Victoria, and southeastern South Australia. The koala was introduced near Adelaide and on several islands, including Kangaroo Island and French Island. The population on Magnetic Island represents the northern limit of its range. Fossil evidence shows that the koala's range stretched as far west as southwestern Western Australia during the late Pleistocene. They were likely driven to extinction in these areas by environmental changes and hunting by indigenous Australians.

In Queensland, koalas are unevenly distributed and uncommon except in the southeast, where they are numerous. In New South Wales, they are abundant only in Pilliga, while in Victoria they are common nearly everywhere. In South Australia, koalas were extirpated by 1920 and subsequently reintroduced. Koalas can be found in habitats ranging from relatively open forests to woodlands, and in climates ranging from tropical to cool temperate. In semi-arid climates, they prefer riparian habitats, where nearby streams and creeks provide refuge during times of drought and extreme heat.

Koalas are herbivorous, and while most of their diet consists of eucalypt leaves, they can be found in trees of other genera, such as "Acacia", "Allocasuarina", "Callitris", "Leptospermum", and "Melaleuca". They are able to digest the toxins present in eucalyptus leaves due to their production of cytochrome P450, which breaks down these poisons in the liver. Though the foliage of over 600 species of "Eucalyptus" is available, the koala shows a strong preference for around 30. They tend to choose species that have a high protein content and low proportions of fibre and lignin. The most favoured species are "Eucalyptus microcorys", "E. tereticornis", and "E. camaldulensis", which, on average, make up more than 20% of their diet. Despite its reputation as a fussy eater, the koala is more generalist than some other marsupial species, such as the greater glider. Since eucalypt leaves have a high water content, the koala does not need to drink often; its daily water turnover rate ranges from 71 to 91 ml/kg of body weight. Although females can meet their water requirements from eating leaves, larger males require additional water found on the ground or in tree hollows. When feeding, a koala holds onto a branch with hindpaws and one forepaw while the other forepaw grasps foliage. Small koalas can move close to the end of a branch, but larger ones stay near the thicker bases. Koalas consume up to of leaves a day, spread over four to six feeding sessions. Despite their adaptations to a low-energy lifestyle, they have meagre fat reserves and need to feed often.

Because they get so little energy from their diet, koalas must limit their energy use and sleep or rest 20 hours a day; only 4 hours a day are spent in active movement. They are predominantly active at night and spend most of their waking hours feeding. They typically eat and sleep in the same tree, possibly for as long as a day. 

On very hot days, a koala may climb down to the coolest part of the tree which is cooler than the surrounding air. The koala hugs the tree to lose heat without "panting". On warm days, a koala may rest with its back against a branch or lie on its stomach or back with its limbs dangling. During cold, wet periods, it curls itself into a tight ball to conserve energy. On windy days, a koala finds a lower, thicker branch on which to rest. While it spends most of the time in the tree, the animal descends to the ground to move to another tree, walking on all fours. The koala usually grooms itself with its hindpaws, but sometimes uses its forepaws or mouth.

Koalas are asocial animals and spend just 15 minutes a day on social behaviours. In Victoria, home ranges are small and have extensive overlap, while in central Queensland they are larger and overlap less. Koala society appears to consist of "residents" and "transients", the former being mostly adult females and the latter males. Resident males appear to be territorial and dominate others with their larger body size. Alpha males tend to establish their territories close to breeding females, while younger males are subordinate until they mature and reach full size. Adult males occasionally venture outside their home ranges; when they do so, dominant ones retain their status. When a male enters a new tree, he marks it by rubbing his chest gland against the trunk or a branch; males have occasionally been observed to dribble urine on the trunk. This scent-marking behaviour probably serves as communication, and individuals are known to sniff the base of a tree before climbing. Scent marking is common during aggressive encounters. Chest gland secretions are complex chemical mixtures—about 40 compounds were identified in one analysis—that vary in composition and concentration with the season and the age of the individual.

Adult males communicate with loud bellows—low pitched sounds that consist of snore-like inhalations and resonant exhalations that sound like growls. These sounds are thought to be generated by unique vocal organs found in koalas. Because of their low frequency, these bellows can travel far through air and vegetation. Koalas may bellow at any time of the year, particularly during the breeding season, when it serves to attract females and possibly intimidate other males. They also bellow to advertise their presence to their neighbours when they enter a new tree. These sounds signal the male's actual body size, as well as exaggerate it; females pay more attention to bellows that originate from larger males. Female koalas bellow, though more softly, in addition to making snarls, wails, and screams. These calls are produced when in distress and when making defensive threats. Young koalas squeak when in distress. As they get older, the squeak develops into a "squawk" produced both when in distress and to show aggression. When another individual climbs over it, a koala makes a low grunt with its mouth closed. Koalas make numerous facial expressions. When snarling, wailing, or squawking, the animal curls the upper lip and points its ears forward. During screams, the lips retract and the ears are drawn back. Females bring their lips forward and raise their ears when agitated.

Agonistic behaviour typically consists of squabbles between individuals climbing over or passing each other. This occasionally involves biting. Males that are strangers may wrestle, chase, and bite each other. In extreme situations, a male may try to displace a smaller rival from a tree. This involves the larger aggressor climbing up and attempting to corner the victim, which tries either to rush past him and climb down or to move to the end of a branch. The aggressor attacks by grasping the target by the shoulders and repeatedly biting him. Once the weaker individual is driven away, the victor bellows and marks the tree. Pregnant and lactating females are particularly aggressive and attack individuals that come too close. In general, however, koalas tend to avoid energy-wasting aggressive behaviour.

Koalas are seasonal breeders, and births take place from the middle of spring through the summer to early autumn, from October to May. Females in oestrus tend to hold their heads further back than usual and commonly display tremors and spasms. However, males do not appear to recognise these signs, and have been observed to mount non-oestrous females. Because of his much larger size, a male can usually force himself on a female, mounting her from behind, and in extreme cases, the male may pull the female out of the tree. A female may scream and vigorously fight off her suitors, but will submit to one that is dominant or is more familiar. The bellows and screams that accompany matings can attract other males to the scene, obliging the incumbent to delay mating and fight off the intruders. These fights may allow the female to assess which is dominant. Older males usually have accumulated scratches, scars, and cuts on the exposed parts of their noses and on their eyelids.

The koala's gestation period lasts 33–35 days, and a female gives birth to a single joey (although twins occur on occasion). As with all marsupials, the young are born while at the embryonic stage, weighing only . However, they have relatively well-developed lips, forelimbs, and shoulders, as well as functioning respiratory, digestive, and urinary systems. The joey crawls into its mother's pouch to continue the rest of its development. Unlike most other marsupials, the koala does not clean her pouch.

A female koala has two teats; the joey attaches itself to one of them and suckles for the rest of its pouch life. The koala has one of the lowest milk energy production rates in relation to body size of any mammal. The female makes up for this by lactating for as long as 12 months. At seven weeks of age, the joey's head grows longer and becomes proportionally large, pigmentation begins to develop, and its sex can be determined (the scrotum appears in males and the pouch begins to develop in females). At 13 weeks, the joey weighs around and its head has doubled in size. The eyes begin to open and fine fur grows on the forehead, nape, shoulders, and arms. At 26 weeks, the fully furred animal resembles an adult, and begins to poke its head out of the pouch.

As the young koala approaches six months, the mother begins to prepare it for its eucalyptus diet by predigesting the leaves, producing a faecal pap that the joey eats from her cloaca. The pap is quite different in composition from regular faeces, resembling instead the contents of the caecum, which has a high concentration of bacteria. Eaten for about a month, the pap provides a supplementary source of protein at a transition time from a milk to a leaf diet. The joey fully emerges from the pouch for the first time at six or seven months of age, when it weighs . It explores its new surroundings cautiously, clinging to its mother for support. By nine months, it weighs over and develops its adult fur colour. Having permanently left the pouch, it rides on its mother's back for transportation, learning to climb by grasping branches. Gradually, it spends more time away from its mother, and at 12 months it is fully weaned, weighing around . When the mother becomes pregnant again, her bond with her previous offspring is permanently severed. Newly weaned young are encouraged to disperse by their mothers' aggressive behaviour towards them.

Females become sexually mature at about three years of age and can then become pregnant; in comparison, males reach sexual maturity when they are about four years old, although they can produce sperm as early as two years. While the chest glands can be functional as early as 18 months of age, males do not begin scent-marking behaviours until they reach sexual maturity. Because the offspring have a long dependent period, female koalas usually breed in alternate years. Favourable environmental factors, such as a plentiful supply of high-quality food trees, allow them to reproduce every year.

Koalas may live from 13 to 18 years in the wild. While female koalas usually live this long, males may die sooner because of their more hazardous lives. Koalas usually survive falls from trees and immediately climb back up, but injuries and deaths from falls do occur, particularly in inexperienced young and fighting males. Around six years of age, the koala's chewing teeth begin to wear down and their chewing efficiency decreases. Eventually, the cusps disappear completely and the animal will die of starvation.

Koalas have few predators; dingos and large pythons may prey on them; birds of prey (such as powerful owls and wedge-tailed eagles) are threats to young. Koalas are generally not subject to external parasites, other than ticks in coastal areas. Koalas may also suffer mange from the mite "Sarcoptes scabiei", and skin ulcers from the bacterium "Mycobacterium ulcerans", but neither is common. Internal parasites are few and largely harmless. These include the tapeworm "Bertiella obesa", commonly found in the intestine, and the nematodes "Marsupostrongylus longilarvatus" and "Durikainema phascolarcti", which are infrequently found in the lungs. In a three-year study of almost 600 koalas admitted to the Australian Zoo Wildlife Hospital in Queensland, 73.8% of the animals were infected with at least one species of the parasitic protozoal genus "Trypanosoma", the most common of which was "T. irwini".

Koalas can be subject to pathogens such as Chlamydiaceae bacteria, which can cause keratoconjunctivitis, urinary tract infection, and reproductive tract infection. Such infections are widespread on the mainland, but absent in some island populations. The koala retrovirus (KoRV) may cause koala immune deficiency syndrome (KIDS) which is similar to AIDS in humans. Prevalence of KoRV in koala populations suggests a trend spreading from the north to the south of Australia. Northern populations are completely infected, while some southern populations (including Kangaroo Island) are free.

The animals are vulnerable to bushfires due to their slow movements and the flammability of eucalypt trees. The koala instinctively seeks refuge in the higher branches, where it is vulnerable to intense heat and flames. Bushfires also fragment the animal's habitat, which restricts their movement and leads to population decline and loss of genetic diversity. Dehydration and overheating can also prove fatal. Consequently, the koala is vulnerable to the effects of climate change. Models of climate change in Australia predict warmer and drier climates, suggesting that the koala's range will shrink in the east and south to more mesic habitats. Droughts also affect the koala's well-being. For example, a severe drought in 1980 caused many "Eucalyptus" trees to lose their leaves. Subsequently, 63% of the population in southwestern Queensland died, especially young animals that were excluded from prime feeding sites by older, dominant koalas, and recovery of the population was slow. Later, this population declined from an estimated mean population of 59,000 in 1995 to 11,600 in 2009, a reduction attributed largely to hotter and drier conditions resulting from droughts in most years between 2002 and 2007. Another predicted negative outcome of climate change is the effect of elevations in atmospheric levels on the koala's food supply: increases in cause "Eucalyptus" trees to reduce protein and increase tannin concentrations in their leaves, reducing the quality of the food source.

The first written reference of the koala was recorded by John Price, servant of John Hunter, the Governor of New South Wales. Price encountered the "cullawine" on 26 January 1798, during an expedition to the Blue Mountains, although his account was not published until nearly a century later in "Historical Records of Australia". In 1802, French-born explorer Francis Louis Barrallier encountered the animal when his two Aboriginal guides, returning from a hunt, brought back two koala feet they were intending to eat. Barrallier preserved the appendages and sent them and his notes to Hunter's successor, Philip Gidley King, who forwarded them to Joseph Banks. Similar to Price, Barrallier's notes were not published until 1897. Reports of the first capture of a live "koolah" appeared in "The Sydney Gazette" in August 1803. Within a few weeks Flinders' astronomer, James Inman, purchased a specimen pair for live shipment to Joseph Banks in England. They were described as 'somewhat larger than the Waumbut (Wombat)'. These encounters helped provide the impetus for King to commission the artist John Lewin to paint watercolours of the animal. Lewin painted three pictures, one of which was subsequently made into a print that was reproduced in Georges Cuvier's "The Animal Kingdom" (first published in 1827) and several European works on natural history.

Botanist Robert Brown was the first to write a detailed scientific description of the koala in 1814, based on a female specimen captured near what is now Mount Kembla in the Illawarra region of New South Wales. Austrian botanical illustrator Ferdinand Bauer drew the animal's skull, throat, feet, and paws. Brown's work remained unpublished and largely unnoticed, however, as his field books and notes remained in his possession until his death, when they were bequeathed to the British Museum (Natural History) in London. They were not identified until 1994, while Bauer's koala watercolours were not published until 1989. British surgeon Everard Home included details of the koala based on eyewitness accounts of William Paterson, who had befriended Brown and Bauer during their stay in New South Wales. Home, who in 1808 published his report in the journal "Philosophical Transactions of the Royal Society", gave the animal the scientific name "Didelphis coola".

The first published image of the koala appeared in George Perry's (1810) natural history work "Arcana". Perry called it the "New Holland Sloth" on account of its perceived similarities to the Central and South American tree-living mammals of genus "Bradypus". His disdain for the koala, evident in his description of the animal, was typical of the prevailing early 19th-century British attitude about the primitiveness and oddity of Australian fauna: "... the eye is placed like that of the Sloth, very close to the mouth and nose, which gives it a clumsy awkward appearance, and void of elegance in the combination ... they have little either in their character or appearance to interest the Naturalist or Philosopher. As Nature however provides nothing in vain, we may suppose that even these torpid, senseless creatures are wisely intended to fill up one of the great links of the chain of animated nature ...".
Naturalist and popular artist John Gould illustrated and described the koala in his three-volume work "The Mammals of Australia" (1845–63) and introduced the species, as well as other members of Australia's little-known faunal community, to the general British public. Comparative anatomist Richard Owen, in a series of publications on the physiology and anatomy of Australian mammals, presented a paper on the anatomy of the koala to the Zoological Society of London. In this widely cited publication, he provided the first careful description of its internal anatomy, and noted its general structural similarity to the wombat. English naturalist George Robert Waterhouse, curator of the Zoological Society of London, was the first to correctly classify the koala as a marsupial in the 1840s. He identified similarities between it and its fossil relatives "Diprotodon" and "Nototherium", which had been discovered just a few years before. Similarly, Gerard Krefft, curator of the Australian Museum in Sydney, noted evolutionary mechanisms at work when comparing the koala to its ancestral relatives in his 1871 "The Mammals of Australia".

The first living koala in Britain arrived in 1881, purchased by the Zoological Society of London. As related by prosecutor to the society, William Alexander Forbes, the animal suffered an accidental demise when the heavy lid of a washstand fell on it and it was unable to free itself. Forbes used the opportunity to dissect the fresh female specimen, thus was able to provide explicit anatomical details on the female reproductive system, the brain, and the liver—parts not previously described by Owen, who had access only to preserved specimens. Scottish embryologist William Caldwell—well known in scientific circles for determining the reproductive mechanism of the platypus—described the uterine development of the koala in 1884, and used the new information to convincingly place the koala and the monotremes into an evolutionary time frame.

Prince Henry, Duke of Gloucester, visited the Koala Park Sanctuary in Sydney in 1934 and was "intensely interested in the bears". His photograph, with Noel Burnet, the founder of the park, and a koala, appeared in "The Sydney Morning Herald". After World War II, when tourism to Australia increased and the animals were exported to zoos overseas, the koala's international popularity rose. Several political leaders and members of royal families had their pictures taken with koalas, including Queen Elizabeth II, Prince Harry, Crown Prince Naruhito, Crown Princess Masako, Pope John Paul II, US President Bill Clinton, Soviet premier Mikhail Gorbachev, South African President Nelson Mandela, Prime Minister Tony Abbott, and Russian President Vladimir Putin.

The koala is well known worldwide and is a major draw for Australian zoos and wildlife parks. It has been featured in advertisements, games, cartoons, and as soft toys. It benefited the national tourism industry by over an estimated billion Australian dollars in 1998, a figure that has since grown. In 1997, half of visitors to Australia, especially those from Korea, Japan, and Taiwan, sought out zoos and wildlife parks; about 75% of European and Japanese tourists placed the koala at the top of their list of animals to see. According to biologist Stephen Jackson: "If you were to take a straw poll of the animal most closely associated with Australia, it's a fair bet that the koala would come out marginally in front of the kangaroo". Factors that contribute to the koala's enduring popularity include its child-like body proportions and teddy bear-like face.

The koala is featured in the Dreamtime stories and mythology of indigenous Australians. The Tharawal people believed that the animal helped row the boat that brought them to the continent. Another myth tells of how a tribe killed a koala and used its long intestines to create a bridge for people from other parts of the world. This narrative highlights the koala's status as a game animal and the length of its intestines. Several stories tell of how the koala lost its tail. In one, a kangaroo cuts it off to punish the koala for being lazy and greedy. Tribes in both Queensland and Victoria regarded the koala as a wise animal and sought its advice. Bidjara-speaking people credited the koala for turning barren lands into lush forests. The animal is also depicted in rock carvings, though not as much as some other species.

Early European settlers in Australia considered the koala to be a prowling sloth-like animal with a "fierce and menacing look". At the beginning of the 20th century, the koala's reputation took a more positive turn, largely due to its growing popularity and depiction in several widely circulated children's stories. It is featured in Ethel Pedley's 1899 book "Dot and the Kangaroo", in which it is portrayed as the "funny native bear". Artist Norman Lindsay depicted a more anthropomorphic koala in "The Bulletin" cartoons, starting in 1904. This character also appeared as Bunyip Bluegum in Lindsay's 1918 book "The Magic Pudding". Perhaps the most famous fictional koala is Blinky Bill. Created by Dorothy Wall in 1933, the character appeared in several books and has been the subject of films, TV series, merchandise, and a 1986 environmental song by John Williamson. The first Australian stamp featuring a koala was issued by the Commonwealth in 1930. A television ad campaign for Australia's national airline Qantas, starting in 1967 and running for several decades, featured a live koala (voiced by Howard Morris), who complained that too many tourists were coming to Australia and concluded "I hate Qantas". The series has been ranked among the greatest commercials of all time.

The song "Ode to a Koala Bear" appears on the B-side of the 1983 Paul McCartney/Michael Jackson duet single "Say Say Say". A koala is the main character in Hanna-Barbera's "The Kwicky Koala Show" and Nippon Animation's "Noozles", both of which were animated cartoons of the early 1980s. Food products shaped like the koala include the Caramello Koala chocolate bar and the bite-sized cookie snack Koala's March. Dadswells Bridge in Victoria features a tourist complex shaped like a giant koala, and the Queensland Reds rugby team has a koala as its mascot. The Platinum Koala coin features the animal on the reverse and Elizabeth II on the obverse.

The drop bear is an imaginary creature in contemporary Australian folklore featuring a predatory, carnivorous version of the koala. This hoax animal is commonly spoken about in tall tales designed to scare tourists. While koalas are typically docile herbivores, drop bears are described as unusually large and vicious marsupials that inhabit treetops and attack unsuspecting people (or other prey) that walk beneath them by dropping onto their heads from above.

While the koala was previously classified as Least Concern on the Red List, it was uplisted to Vulnerable in 2016. Australian policy makers declined a 2009 proposal to include the koala in the Environment Protection and Biodiversity Conservation Act 1999. In 2012, the Australian government listed koala populations in Queensland and New South Wales as Vulnerable, because of a 40% population decline in the former and a 33% decline in the latter. Populations in Victoria and South Australia appear to be abundant; however, the Australian Koala Foundation argues that the exclusion of Victorian populations from protective measures is based on a misconception that the total koala population is 200,000, whereas they believe it is probably less than 100,000.

Koalas were hunted for food by Aboriginals. A common technique used to capture the animals was to attach a loop of ropey bark to the end of a long, thin pole, so as to form a noose. This would be used to snare an animal high in a tree, beyond the reach of a climbing hunter; an animal brought down this way would then be killed with a stone hand axe or hunting stick (waddy). According to the customs of some tribes, it was considered taboo to skin the animal, while other tribes thought the animal's head had a special status, and saved them for burial.
The koala was heavily hunted by European settlers in the early 20th century, largely for its thick, soft fur. More than two million pelts are estimated to have left Australia by 1924. Pelts were in demand for use in rugs, coat linings, muffs, and as trimming on women's garments. Extensive cullings occurred in Queensland in 1915, 1917, and again in 1919, when over one million koalas were killed with guns, poisons, and nooses. The public outcry over these cullings was probably the first wide-scale environmental issue that rallied Australians. Novelist and social critic Vance Palmer, writing in a letter to "The Courier-Mail", expressed the popular sentiment: "The shooting of our harmless and lovable native bear is nothing less than barbarous ... No one has ever accused him of spoiling the farmer's wheat, eating the squatter's grass, or even the spreading of the prickly pear. There is no social vice that can be put down to his account ... He affords no sport to the gun-man ... And he has been almost blotted out already from some areas." Despite the growing movement to protect native species, the poverty brought about by the drought of 1926–28 led to the killing of another 600,000 koalas during a one-month open season in August 1927. In 1934, Frederick Lewis, the Chief Inspector of Game in Victoria, said that the once-abundant animal had been brought to near extinction in that state, suggesting that only 500–1000 remained.
The first successful efforts at conserving the species were initiated by the establishment of Brisbane's Lone Pine Koala Sanctuary and Sydney's Koala Park Sanctuary in the 1920s and 1930s. The owner of the latter park, Noel Burnet, became the first to successfully breed koalas and earned a reputation as the foremost contemporary authority on the marsupial. In 1934, David Fleay, curator of Australian mammals at the Melbourne Zoo, established the first Australian faunal enclosure at an Australian zoo, and featured the koala. This arrangement allowed him to undertake a detailed study of its diet in captivity. Fleay later continued his conservation efforts at Healesville Sanctuary and the David Fleay Wildlife Park.

Since 1870, koalas have been introduced to several coastal and offshore islands, including Kangaroo Island and French Island. Their numbers have significantly increased, and since the islands are not large enough to sustain such high koala numbers, overbrowsing has become a problem. In the 1920s, Lewis initiated a program of large-scale relocation and rehabilitation programs to transfer koalas whose habitat had become fragmented or reduced to new regions, with the intent of eventually returning them to their former range. For example, in 1930–31, 165 koalas were translocated to Quail Island. After a period of population growth, and subsequent overbrowsing of gum trees on the island, about 1,300 animals were released into mainland areas in 1944. The practice of translocating koalas became commonplace; Victorian State manager Peter Menkorst estimated that from 1923 to 2006, about 25,000 animals were translocated to more than 250 release sites across Victoria. Since the 1990s, government agencies have tried to control their numbers by culling, but public and international outcry has forced the use of translocation and sterilisation, instead.
One of the biggest anthropogenic threats to the koala is habitat destruction and fragmentation. In coastal areas, the main cause of this is urbanisation, while in rural areas, habitat is cleared for agriculture. Native forest trees are also taken down to be made into wood products. In 2000, Australia ranked fifth in the world by deforestation rates, having cleared . The distribution of the koala has shrunk by more than 50% since European arrival, largely due to fragmentation of habitat in Queensland. The koala's "vulnerable" status in Queensland and New South Wales means that developers in these states must consider the impacts on this species when making building applications. In addition, koalas live in many protected areas.

While urbanisation can pose a threat to koala populations, the animals can survive in urban areas provided enough trees are present. Urban populations have distinct vulnerabilities: collisions with vehicles and attacks by domestic dogs kill about 4,000 animals every year. Injured koalas are often taken to wildlife hospitals and rehabilitation centres. In a 30-year retrospective study performed at a New South Wales koala rehabilitation centre, trauma (usually resulting from a motor vehicle accident or dog attack) was found to be the most frequent cause of admission, followed by symptoms of "Chlamydia" infection. Wildlife caretakers are issued special permits, but must release the animals back into the wild when they are either well enough or, in the case of joeys, old enough. As with most native animals, the koala cannot legally be kept as a pet in Australia or anywhere else.





</doc>
<doc id="17360" url="https://en.wikipedia.org/wiki?curid=17360" title="Komodo dragon">
Komodo dragon

The Komodo dragon ("Varanus komodoensis"), also known as the Komodo monitor, is a species of lizard found in the Indonesian islands of Komodo, Rinca, Flores, Gili Motang, and Padar. A member of the monitor lizard family Varanidae, it is the largest living species of lizard, growing to a maximum length of in rare cases and weighing up to approximately .

Their unusually large size has been attributed to island gigantism, since no other carnivorous animals fill the niche on the islands where they live. However, recent research suggests the large size of Komodo dragons may be better understood as representative of a relict population of very large varanid lizards that once lived across Indonesia and Australia, most of which, along with other megafauna, died out after the Pleistocene (as a result of human activity). Fossils very similar to "V. komodoensis" have been found in Australia dating to greater than 3.8 million years ago, and its body size remained stable on Flores, one of the handful of Indonesian islands where it is currently found, over the last 900,000 years, "a time marked by major faunal turnovers, extinction of the island's megafauna, and the arrival of early hominids by 880 ka [kiloannums]."

As a result of their size, these lizards dominate the ecosystems in which they live. Komodo dragons hunt and ambush prey including invertebrates, birds, and mammals. It has been claimed that they have a venomous bite; there are two glands in the lower jaw which secrete several toxic proteins. The biological significance of these proteins is disputed, but the glands have been shown to secrete an anticoagulant. Komodo dragons' group behaviour in hunting is exceptional in the reptile world. The diet of big Komodo dragons mainly consists of Timor deer, though they also eat considerable amounts of carrion. Komodo dragons also occasionally attack humans.

Mating begins between May and August, and the eggs are laid in September. About 20 eggs are deposited in abandoned megapode nests or in a self-dug nesting hole. The eggs are incubated for seven to eight months, hatching in April, when insects are most plentiful. Young Komodo dragons are vulnerable and therefore dwell in trees, safe from predators and cannibalistic adults. They take 8 to 9 years to mature, and are estimated to live up to 30 years.

Komodo dragons were first recorded by Western scientists in 1910. Their large size and fearsome reputation make them popular zoo exhibits. In the wild, their range has contracted due to human activities, and they are listed as vulnerable by the IUCN. They are protected under Indonesian law, and a national park, Komodo National Park, was founded to aid protection efforts.

Komodo dragons were first documented by Europeans in 1910, when rumors of a "land crocodile" reached Lieutenant van Steyn van Hensbroek of the Dutch colonial administration. Widespread notoriety came after 1912, when Peter Ouwens, the director of the Zoological Museum at Bogor, Java, published a paper on the topic after receiving a photo and a skin from the lieutenant, as well as two other specimens from a collector. The first two live Komodo dragons to arrive in Europe were exhibited in the Reptile House at London Zoo when it opened in 1927. Joan Beauchamp Procter made some of the earliest observations of these animals in captivity and she demonstrated the behaviour of one of these animals at a Scientific Meeting of the Zoological Society of London in 1928. The Komodo dragon was the driving factor for an expedition to Komodo Island by W. Douglas Burden in 1926. After returning with 12 preserved specimens and 2 live ones, this expedition provided the inspiration for the 1933 movie "King Kong". It was also Burden who coined the common name "Komodo dragon." Three of his specimens were stuffed and are still on display in the American Museum of Natural History.

The Dutch, realizing the limited number of individuals in the wild, outlawed sport hunting and heavily limited the number of individuals taken for scientific study. Collecting expeditions ground to a halt with the occurrence of World War II, not resuming until the 1950s and 1960s, when studies examined the Komodo dragon's feeding behavior, reproduction, and body temperature. At around this time, an expedition was planned in which a long-term study of the Komodo dragon would be undertaken. This task was given to the Auffenberg family, who stayed on Komodo Island for 11 months in 1969. During their stay, Walter Auffenberg and his assistant Putra Sastrawan captured and tagged more than 50 Komodo dragons. The research from the Auffenberg expedition would prove to be enormously influential in raising Komodo dragons in captivity. Research after that of the Auffenberg family has shed more light on the nature of the Komodo dragon, with biologists such as Claudio Ciofi continuing to study the creatures.

The Komodo dragon is also known as the Komodo monitor or the Komodo Island monitor in scientific literature, although this is not very common. To the natives of Komodo Island, it is referred to as "ora", "buaya darat" (land crocodile), or "biawak raksasa" (giant monitor).

The evolutionary development of the Komodo dragon started with the genus "Varanus", which originated in Asia about 40 million years ago and migrated to Australia, where it evolved into giant forms (the largest of all being the recently extinct "Megalania"), helped by the absence of competing placental carnivorans. Around 15 million years ago, a collision between Australia and Southeast Asia allowed these larger varanids to move back into what is now the Indonesian archipelago, extending their range as far east as the island of Timor. The Komodo dragon was believed to have differentiated from its Australian ancestors 4 million years ago. However, recent fossil evidence from Queensland suggests the Komodo dragon actually evolved in Australia before spreading to Indonesia. Dramatic lowering of sea level during the last glacial period uncovered extensive stretches of continental shelf that the Komodo dragon colonised, becoming isolated in their present island range as sea levels rose afterwards. Extinct Pliocene species of similar size to the modern Komodo dragon, such as "Varanus sivalensis", have been found in Eurasia as well, indicating that they fared well even in environments containing competition such as mammalian carnivores until the climate change and extinction events that marked the beginning of the Pleistocene.

In the wild, an adult Komodo dragon usually weighs around , although captive specimens often weigh more. According to "Guinness World Records", an average adult male will weigh and measure , while an average female will weigh and measure . The largest verified wild specimen was long and weighed , including undigested food.

The Komodo dragon has a tail as long as its body, as well as about 60 frequently replaced, serrated teeth that can measure up to in length. Its saliva is frequently blood-tinged, because its teeth are almost completely covered by gingival tissue that is naturally lacerated during feeding. It also has a long, yellow, deeply forked tongue. Komodo dragon skin is reinforced by armoured scales, which contain tiny bones called osteoderms that function as a sort of natural chain-mail. This rugged hide makes Komodo dragon skin a poor source of leather.

As with other varanids, Komodo dragons have only a single ear bone, the stapes, for transferring vibrations from the tympanic membrane to the cochlea. This arrangement means they are likely restricted to sounds in the 400 to 2,000 hertz range, compared to humans who hear between 20 and 20,000 hertz. It was formerly thought to be deaf when a study reported no agitation in wild Komodo dragons in response to whispers, raised voices, or shouts. This was disputed when London Zoological Garden employee Joan Proctor trained a captive specimen to come out to feed at the sound of her voice, even when she could not be seen.

The Komodo dragon can see objects as far away as , but because its retinas only contain cones, it is thought to have poor night vision. It can distinguish colours, but has poor visual discrimination of stationary objects.

The Komodo dragon uses its tongue to detect, taste, and smell stimuli, as with many other reptiles, with the vomeronasal sense using the Jacobson's organ, rather than using the nostrils. With the help of a favorable wind and its habit of swinging its head from side to side as it walks, a Komodo dragon may be able to detect carrion from away. It only has a few taste buds in the back of its throat. Its scales, some of which are reinforced with bone, have sensory plaques connected to nerves to facilitate its sense of touch. The scales around the ears, lips, chin, and soles of the feet may have three or more sensory plaques.

The Komodo dragon prefers hot and dry places, and typically lives in dry, open grassland, savanna, and tropical forest at low elevations. As an ectotherm, it is most active in the day, although it exhibits some nocturnal activity. Komodo dragons are solitary, coming together only to breed and eat. They are capable of running rapidly in brief sprints up to , diving up to , and climbing trees proficiently when young through use of their strong claws. To catch out-of-reach prey, the Komodo dragon may stand on its hind legs and use its tail as a support. As it matures, its claws are used primarily as weapons, as its great size makes climbing impractical.

For shelter, the Komodo dragon digs holes that can measure from wide with its powerful forelimbs and claws. Because of its large size and habit of sleeping in these burrows, it is able to conserve body heat throughout the night and minimise its basking period the morning after. The Komodo dragon hunts in the afternoon, but stays in the shade during the hottest part of the day. These special resting places, usually located on ridges with cool sea breezes, are marked with droppings and are cleared of vegetation. They serve as strategic locations from which to ambush deer.

Komodo dragons are carnivores. Although they have been considered as eating mostly carrion, they will frequently ambush live prey with a stealthy approach. When suitable prey arrives near a dragon's ambush site, it will suddenly charge at the animal at high speeds and go for the underside or the throat. Komodo dragons make no attempt to deliberately allow the prey to escape with fatal injuries, but try to kill prey outright using a combination of lacerating damage and blood loss. They have been recorded as killing wild pigs within seconds, and observations of Komodo dragons tracking prey for long distances are likely misinterpreted cases of prey escaping an attack before succumbing to infection. Komodo dragons have been observed knocking down large pigs and deer with their strong tails. It is able to locate carcasses using its keen sense of smell, which can locate a dead or dying animal from a range of up to .

Komodo dragons eat by tearing large chunks of flesh and swallowing them whole while holding the carcass down with their forelegs. For smaller prey up to the size of a goat, their loosely articulated jaws, flexible skulls, and expandable stomachs allow them to swallow prey whole. The vegetable contents of the stomach and intestines are typically avoided. Copious amounts of red saliva the Komodo dragons produce help to lubricate the food, but swallowing is still a long process (15–20 minutes to swallow a goat). A Komodo dragon may attempt to speed up the process by ramming the carcass against a tree to force it down its throat, sometimes ramming so forcefully, the tree is knocked down. A small tube under the tongue that connects to the lungs allows it to breathe while swallowing. After eating up to 80% of its body weight in one meal, it drags itself to a sunny location to speed digestion, as the food could rot and poison the dragon if left undigested for too long. Because of their slow metabolism, large dragons can survive on as few as 12 meals a year. After digestion, the Komodo dragon regurgitates a mass of horns, hair, and teeth known as the gastric pellet, which is covered in malodorous mucus. After regurgitating the gastric pellet, it rubs its face in the dirt or on bushes to get rid of the mucus, suggesting it does not relish the scent of its own excretions.

The largest animals eat first, while the smaller ones follow a hierarchy. The largest male asserts his dominance and the smaller males show their submission by use of body language and rumbling hisses. Dragons of equal size may resort to "wrestling". Losers usually retreat, though they have been known to be killed and eaten by victors.
The Komodo dragon's diet is wide-ranging, and includes invertebrates, other reptiles (including smaller Komodo dragons), birds, bird eggs, small mammals, monkeys, wild boar, goats, deer, horses, and water buffalo. Young Komodos will eat insects, eggs, geckos, and small mammals, while adults prefer to hunt large mammals. Occasionally, they attack and bite humans. Sometimes they consume human corpses, digging up bodies from shallow graves. This habit of raiding graves caused the villagers of Komodo to move their graves from sandy to clay ground and pile rocks on top of them to deter the lizards. The Komodo dragon may have evolved to feed on the extinct dwarf elephant "Stegodon" that once lived on Flores, according to evolutionary biologist Jared Diamond.

The Komodo dragon drinks by sucking water into its mouth via buccal pumping (a process also used for respiration), lifting its head, and letting the water run down its throat.

Although previous studies proposed that Komodo dragon saliva contains a variety of highly septic bacteria that would help to bring down prey, research in 2013 suggested that the bacteria in the mouths of Komodo dragons are ordinary and similar to those found in other carnivores. They actually have surprisingly good mouth hygiene. As Bryan Fry put it: "After they are done feeding, they will spend 10 to 15 minutes lip-licking and rubbing their head in the leaves to clean their mouth... Unlike people have been led to believe, they do not have chunks of rotting flesh from their meals on their teeth, cultivating bacteria." Nor do Komodo dragons wait for prey to die and track it at a distance, as vipers do; observations of them hunting deer, boar and in some cases buffalo reveal that they kill prey in less than half an hour, using their dentition to cause shock and trauma.

The observation of prey dying of sepsis would then be explained by the natural instinct of water buffalos, who are not native to the islands where the Komodo dragon lives, to run into water after escaping an attack. The warm, faeces-filled water would then cause the infections. The study used samples from 16 captive dragons (10 adults and six neonates) from three US zoos.

Researchers have isolated a powerful antibacterial peptide from the blood plasma of Komodo dragons, VK25. Based on their analysis of this peptide, they have synthesized a short peptide dubbed DRGN-1 and tested it against multidrug-resistant (MDR) pathogens. Preliminary results of these tests show that DRGN-1 is effective in killing drug-resistant bacterial strains and even some fungi. It has the added observed benefit of significantly promoting wound healing in both uninfected and mixed biofilm infected wounds.

In late 2005, researchers at the University of Melbourne speculated the perentie ("Varanus giganteus"), other species of monitors, and agamids may be somewhat venomous. The team believes the immediate effects of bites from these lizards were caused by mild envenomation. Bites on human digits by a lace monitor ("V. varius"), a Komodo dragon, and a spotted tree monitor ("V. scalaris") all produced similar effects: rapid swelling, localised disruption of blood clotting, and shooting pain up to the elbow, with some symptoms lasting for several hours.

In 2009, the same researchers published further evidence demonstrating Komodo dragons possess a venomous bite. MRI scans of a preserved skull showed the presence of two glands in the lower jaw. The researchers extracted one of these glands from the head of a terminally ill dragon in the Singapore Zoological Gardens, and found it secreted several different toxic proteins. The known functions of these proteins include inhibition of blood clotting, lowering of blood pressure, muscle paralysis, and the induction of hypothermia, leading to shock and loss of consciousness in envenomated prey. As a result of the discovery, the previous theory that bacteria were responsible for the deaths of Komodo victims was disputed.

Other scientists have stated that this allegation of venom glands "has had the effect of underestimating the variety of complex roles played by oral secretions in the biology of reptiles, produced a very narrow view of oral secretions and resulted in misinterpretation of reptilian evolution". According to these scientists "reptilian oral secretions contribute to many biological roles other than to quickly dispatch prey". These researchers concluded that, "Calling all in this clade venomous implies an overall potential danger that does not exist, misleads in the assessment of medical risks, and confuses the biological assessment of squamate biochemical systems". Evolutionary biologist Schwenk says that even if the lizards have venom-like proteins in their mouths they may be using them for a different function, and he doubts venom is necessary to explain the effect of a Komodo dragon bite, arguing that shock and blood loss are the primary factors.

Mating occurs between May and August, with the eggs laid in September. During this period, males fight over females and territory by grappling with one another upon their hind legs, with the loser eventually being pinned to the ground. These males may vomit or defecate when preparing for the fight. The winner of the fight will then flick his long tongue at the female to gain information about her receptivity. Females are antagonistic and resist with their claws and teeth during the early phases of courtship. Therefore, the male must fully restrain the female during coitus to avoid being hurt. Other courtship displays include males rubbing their chins on the female, hard scratches to the back, and licking. Copulation occurs when the male inserts one of his hemipenes into the female's cloaca. Komodo dragons may be monogamous and form "pair bonds", a rare behavior for lizards.

Female Komodos lay their eggs from August to September and may use several types of locality; in one study, 60% laid their eggs in the nests of orange-footed scrubfowl (a moundbuilder or megapode), 20% on ground level and 20% in hilly areas. The females make many camouflage nests/holes to prevent other dragons from eating the eggs. Clutches contain an average of 20 eggs, which have an incubation period of 7–8 months. Hatching is an exhausting effort for the neonates, which break out of their eggshells with an egg tooth that falls off before long. After cutting themselves out, the hatchlings may lie in their eggshells for hours before starting to dig out of the nest. They are born quite defenseless and are vulnerable to predation. Sixteen youngsters from a single nest were on average 46.5 cm long and weighed 105.1 grams.

Young Komodo dragons spend much of their first few years in trees, where they are relatively safe from predators, including cannibalistic adults, as juvenile dragons make up 10% of their diets. The habit of cannibalism may be advantageous in sustaining the large size of adults, as medium-sized prey on the islands is rare. When the young approach a kill, they roll around in faecal matter and rest in the intestines of eviscerated animals to deter these hungry adults. Komodo dragons take approximately 8 to 9 years to mature, and may live for up to 30 years.

A Komodo dragon at London Zoo named Sungai laid a clutch of eggs in late 2005 after being separated from male company for more than two years. Scientists initially assumed she had been able to store sperm from her earlier encounter with a male, an adaptation known as superfecundation. On 20 December 2006, it was reported that Flora, a captive Komodo dragon living in the Chester Zoo in England, was the second known Komodo dragon to have laid unfertilised eggs: she laid 11 eggs, and seven of them hatched, all of them male. Scientists at Liverpool University in England performed genetic tests on three eggs that collapsed after being moved to an incubator, and verified Flora had never been in physical contact with a male dragon. After Flora's eggs' condition had been discovered, testing showed Sungai's eggs were also produced without outside fertilization. On 31 January 2008, the Sedgwick County Zoo in Wichita, Kansas, became the first zoo in the Americas to document parthenogenesis in Komodo dragons. The zoo has two adult female Komodo dragons, one of which laid about 17 eggs on 19–20 May 2007. Only two eggs were incubated and hatched due to space issues; the first hatched on 31 January 2008, while the second hatched on 1 February. Both hatchlings were males.

Komodo dragons have the ZW chromosomal sex-determination system, as opposed to the mammalian XY system. Male progeny prove Flora's unfertilised eggs were haploid (n) and doubled their chromosomes later to become diploid (2n) (by being fertilised by a polar body, or by chromosome duplication without cell division), rather than by her laying diploid eggs by one of the meiosis reduction-divisions in her ovaries failing. When a female Komodo dragon (with ZW sex chromosomes) reproduces in this manner, she provides her progeny with only one chromosome from each of her pairs of chromosomes, including only one of her two sex chromosomes. This single set of chromosomes is duplicated in the egg, which develops parthenogenetically. Eggs receiving a Z chromosome become ZZ (male); those receiving a W chromosome become WW and fail to develop, meaning that only males are produced by parthenogenesis in this species.

It has been hypothesised that this reproductive adaptation allows a single female to enter an isolated ecological niche (such as an island) and by parthenogenesis produce male offspring, thereby establishing a sexually reproducing population (via reproduction with her offspring that can result in both male and female young). Despite the advantages of such an adaptation, zoos are cautioned that parthenogenesis may be detrimental to genetic diversity.

Attacks on humans are rare, but this species has been responsible for several human fatalities, in both the wild and captivity. According to a data from Komodo National Park, within 38 years in a period between 1974 and 2012, there were 24 reported attacks on humans, 5 of them deadly. Most of the victims are local villagers living around the national park. Reports of attacks include:

The Komodo dragon is a vulnerable species and is on the IUCN Red List. The Komodo National Park was founded in 1980 to protect Komodo dragon populations on islands including Komodo, Rinca, and Padar. Later, the Wae Wuul and Wolo Tado Reserves were opened on Flores to aid with Komodo dragon conservation.

Komodo dragons avoid encounters with humans. Juveniles are very shy and will flee quickly into a hideout if a human comes closer than about . Older animals will also retreat from humans from a shorter distance away. If cornered, they will react aggressively by gaping their mouth, hissing, and swinging their tail. If they are disturbed further, they may start an attack and bite. Although there are anecdotes of unprovoked Komodo dragons attacking or preying on humans, most of these reports are either not reputable or caused by defensive bites. Only a very few cases are truly the result of unprovoked attacks by abnormal individuals, which lost their fear towards humans.

Volcanic activity, earthquakes, loss of habitat, fire, loss of prey due to poaching, tourism, and illegal poaching of the dragons themselves have all contributed to the vulnerable status of the Komodo dragon. Under Appendix I of CITES (the Convention on International Trade in Endangered Species), commercial trade of skins or specimens is illegal.

In 2013, total population in the wild was assessed as 3,222 individuals, declining to 3,092 in 2014 and 3,014 in 2015. Populations remained relatively stable on the bigger islands (Komodo and Rinca), but decreased on smaller island such as Nusa Kode and Gili Motang, likely due to diminishing prey availability.
On Padar, a former population of the Komodo dragon became extinct, of which the last individuals were seen in 1975. It is widely assumed that the Komodo dragon died out on Padar after a strong decline of the populations of large ungulate prey, for which poaching was most likely responsible.

Komodo dragons have long been great zoo attractions, where their size and reputation make them popular exhibits. They are, however, rare in zoos because they are susceptible to infection and parasitic disease if captured from the wild, and do not readily reproduce. As of May 2009, there were 13 European, 2 African, 35 North American, 1 Singaporean, and 2 Australian institutions that kept Komodo dragons.

The first Komodo dragons were displayed at London Zoo in 1927. A Komodo dragon was exhibited in 1934 at the National Zoo in Washington, D.C., but it lived for only two years. More attempts to exhibit Komodo dragons were made, but the lifespan of these animals was very short, averaging five years in the National Zoological Park. Studies done by Walter Auffenberg, which were documented in his book "The Behavioral Ecology of the Komodo Monitor", eventually allowed for more successful managing and reproducing of the dragons in captivity.

A variety of behaviors have been observed from captive specimens. Most individuals are relatively tame within a short time, and are capable of recognising individual humans and discriminating between familiar keepers. Komodo dragons have also been observed to engage in play with a variety of objects, including shovels, cans, plastic rings, and shoes. This behavior does not seem to be "food-motivated predatory behavior".

Even seemingly docile dragons may become unpredictably aggressive, especially when the animal's territory is invaded by someone unfamiliar. In June 2001, a Komodo dragon seriously injured Phil Bronstein, the then husband of actress Sharon Stone, when he entered its enclosure at the Los Angeles Zoo after being invited in by its keeper. Bronstein was bitten on his bare foot, as the keeper had told him to take off his white shoes and socks, which the keeper stated could potentially excite the Komodo dragon as they were the same colour as the white rats the zoo fed the dragon. Although he escaped, Bronstein needed to have several tendons in his foot reattached surgically.




</doc>
<doc id="17450" url="https://en.wikipedia.org/wiki?curid=17450" title="Kirsten Dunst">
Kirsten Dunst

Kirsten Caroline Dunst (; born April 30, 1982) is an American actress. She made her debut in the 1989 anthology film "New York Stories", appearing in the segment "Oedipus Wrecks" directed by Woody Allen. At the age of twelve, Dunst gained widespread recognition as Claudia in "Interview with the Vampire" (1994), for which she was nominated for a Golden Globe for Best Supporting Actress. She appeared in "Little Women" the same year and in "Jumanji" the following year. After a recurring role on the third season of "ER" (1996–1997), and appearances in films such as "Wag the Dog" (1997), "Small Soldiers" (1998), the 1998 English dub of "Kiki's Delivery Service" (1989) and "The Virgin Suicides" (1999), Dunst starred in a string of comedies, including "Drop Dead Gorgeous", "Dick" (both 1999), "Bring It On" (2000), "Get Over It" and "Crazy/Beautiful" (both 2001).

Dunst achieved fame for her portrayal of Mary Jane Watson in Sam Raimi's "Spider-Man" trilogy (2002–2007). Since then, her films have included "Mona Lisa Smile" (2003), "Wimbledon", "Eternal Sunshine of the Spotless Mind" (both 2004), Cameron Crowe's "Elizabethtown" (2005), the title role in Sofia Coppola's "Marie Antoinette" (2006), "How to Lose Friends & Alienate People" (2008), "Bachelorette" (2012), and "The Two Faces of January" (2014). In 2011, she won Best Actress at Cannes for her performance in Lars von Trier's "Melancholia".

In 2015, Dunst starred as Peggy Blumquist on the second season of the television series "Fargo". Her performance garnered critical acclaim, leading to her winning the Critics' Choice Television Award for Best Actress, and being nominated for Golden Globe and Primetime Emmy awards.

In 2017, Dunst received a Screen Actors Guild Award for her performance in the film "Hidden Figures", and co-starred in her third collaboration with Sofia Coppola, "The Beguiled".

Dunst was born in Point Pleasant, New Jersey, to Klaus Hermann Dunst and Inez Rupprecht. She has a younger brother, Christian. Her father worked for Siemens as a medical services executive, and her mother worked for Lufthansa as a flight attendant. She was also an artist and one-time gallery owner. Dunst's father is German, originally from Hamburg, and her mother was born in New Jersey, of German and Swedish descent.

Until the age of eleven, Dunst lived in Brick Township, New Jersey, where she attended Ranney School. In 1993, her parents separated, and she subsequently moved with her mother and brother to Los Angeles, where she attended Laurel Hall School in North Hollywood and Notre Dame High School. Among her classmates was Rami Malek, who was a grade above; they were both in a musical theater class. In 1995, her mother filed for divorce.

After graduating from high school in 2000, Dunst continued acting. As a teenager, she found it difficult to deal with her rising fame, and for a period she blamed her mother for pushing her into acting as a child. However, she later said that her mother "always had the best intentions". When asked if she had any regrets about her childhood, Dunst said:

Dunst began her career when she was three years old as a child fashion model in television commercials. She was signed with Ford Models and Elite Model Management.

At the age of six, she made her feature film debut in a minor role in Woody Allen's short film "Oedipus Wrecks"; it was released as one-third of the anthology film "New York Stories" (1989). Soon after, Dunst performed in the comedy-drama "The Bonfire of the Vanities" (1990), based on Tom Wolfe's novel of the same name, in which she played the daughter of Tom Hanks's character. In 1993, Dunst made a guest appearance in an episode of the science fiction drama "".

Her breakthrough role came in 1994, in the horror drama "Interview with the Vampire" opposite Tom Cruise and Brad Pitt, based on Anne Rice's novel of the same name. She played Claudia, the child vampire who is a surrogate daughter to Cruise and Pitt's characters. The film received mixed reviews, but many critics praised Dunst's performance. Roger Ebert commented that Dunst's creation of the child vampire Claudia was one of the "creepier" aspects of the film, and mentioned her ability to convey the impression of great age inside apparent youth. Todd McCarthy in "Variety" said that Dunst was "just right" for the family.

The film featured a scene in which Dunst shared her first on-screen kiss with Pitt, who was almost two decades older. In an interview with "Interview" magazine, she revealed that kissing him had made her feel uncomfortable: "I thought it was gross, that Brad had cooties. I mean, I was 10." Her performance earned her the MTV Movie Award for Best Breakthrough Performance, the Saturn Award for Best Young Actress, and her first Golden Globe Award nomination.

Later in 1994, Dunst co-starred in the drama film "Little Women" opposite Winona Ryder and Claire Danes. The film received favorable reviews. Critic Janet Maslin of "The New York Times" wrote that the film was the greatest adaptation of Louisa May Alcott's novel of the same name and remarked on Dunst's performance,
"The perfect contrast to take-charge Jo comes from Kirsten Dunst's scene-stealing Amy, whose vanity and twinkling mischief make so much more sense coming from an 11-year-old vixen than they did from grown-up Joan Bennett in 1933. Ms. Dunst, also scarily effective as the baby bloodsucker of "Interview With the Vampire", is a little vamp with a big future."

In 1995, Dunst co-starred in the fantasy adventure film "Jumanji", loosely based on Chris Van Allsburg's 1981 children's book of the same name. The story is about a supernatural and ominous board game in which animals and other jungle hazards appear with each roll of the dice. She was part of an ensemble cast that included Robin Williams, Bonnie Hunt and David Alan Grier. The movie grossed $262 million worldwide. That year, and again in 2002, Dunst was named one of "People" magazine's 50 Most Beautiful People.

From 1996 to 1997, Dunst had a recurring role in season three of the NBC medical drama "ER". She played Charlie Chemingo, a child prostitute who was being cared for by the ER pediatrician Dr. Doug Ross (George Clooney). In 1997, she voiced Young Anastasia in the animated musical film "Anastasia". Also in 1997, Dunst appeared in the black comedy film "Wag the Dog", opposite Robert De Niro and Dustin Hoffman. The following year she voiced the title character, Kiki, a thirteen-year-old apprentice witch who leaves her home village to spend a year on her own, in the anime movie "Kiki's Delivery Service" (1998).

Dunst was offered the role of Angela in the 1999 drama film "American Beauty", but turned it down because she did not want to appear in the film's suggestive sexual scenes or kiss the film's star Kevin Spacey. She later explained: "When I read it, I was 15 and I don't think I was mature enough to understand the script's material." That same year, she co-starred in the comedy film "Dick", opposite Michelle Williams. The film is a parody retelling the events of the Watergate scandal that led to the resignation of U.S. president Richard Nixon.

Dunst appeared in Savage Garden's music video "I Knew I Loved You", the first single from their second and final album "Affirmation" (1999).

Dunst co-starred opposite James Woods in Sofia Coppola's drama film "The Virgin Suicides" (1999), based on Jeffrey Eugenides' novel of the same name. She played Lux Lisbon, one of the troubled teenage daughters of Ronald Lisbon (Woods). The film was screened as a special presentation at the 43rd San Francisco International Film Festival in 2000. The movie received generally favorable reviews. "San Francisco Chronicle" critic Peter Stack noted in his review that Dunst "beautifully balances innocence and wantonness."

In 2000, Dunst starred in the comedy "Bring It On" as Torrance Shipman, the captain of a cheerleading squad. The film generated mostly positive reviews, with many critics reserving praise for her performance. In his review, A. O. Scott called her "a terrific comic actress, largely because of her great expressive range, and the nimbleness with which she can shift from anxiety to aggression to genuine hurt." Charles Taylor of "Salon" noted that "among contemporary teenage actresses, Dunst has become the sunniest imaginable parodist", even though he thought the film had failed to provide her with as good a role as she had either in "Dick" or in "The Virgin Suicides." Jessica Winter from "The Village Voice" complimented Dunst, stating that her performance was "as sprightly and knowingly daft as her turn in "Dick"" and commenting that "[Dunst] provides the only major element of "Bring It On" that plays as tweaking parody rather than slick, strident, body-slam churlishness." Peter Stack of the "San Francisco Chronicle", despite giving the film an unfavorable review, commended Dunst for her willingness "to be as silly and cloyingly agreeable as it takes to get through a slapdash film."

The following year, Dunst starred in the comedy film "Get Over It" (2001). She later explained that she took the role for the chance to sing. Also in 2001, she starred in the historical drama "The Cat's Meow", directed by Peter Bogdanovich, as the American actress Marion Davies. Derek Elley of "Variety" described the film as "playful and sporty", saying that this was Dunst's best performance to date: "Believable as both a spoiled ingenue and a lover to two very different men, Dunst endows a potentially lightweight character with considerable depth and sympathy."
For her work, she won the Best Actress Silver Ombú category award at the 2002 Mar del Plata International Film Festival.

In 2002, Dunst co-starred opposite Tobey Maguire in the superhero film "Spider-Man", the most financially successful film of her career to date. She played Mary Jane Watson, the best friend and love interest of Peter Parker (Maguire). The film was directed by Sam Raimi. Owen Gleiberman of "Entertainment Weekly" remarked on Dunst's ability to "lend even the smallest line a tickle of flirtatious music." In the "Los Angeles Times" review, critic Kenneth Turan noted that Dunst and Maguire made a real connection on screen, concluding that their relationship "involved audiences to an extent rarely seen in films." "Spider-Man" was a commercial and critical success. The movie grossed $114 million during its opening weekend in North America and went on to earn $822 million worldwide.

Dunst next co-starred opposite Billy Bob Thornton, Morgan Freeman and Holly Hunter in Ed Solomon's drama "Levity" (2003). That same year, she co-starred opposite Julia Roberts, Maggie Gyllenhaal and Julia Stiles in the drama "Mona Lisa Smile" (2003). The film received mostly negative reviews, with Manohla Dargis of the "Los Angeles Times" describing it as "smug and reductive." She co-starred as Mary Svevo opposite Jim Carrey, Kate Winslet and Tom Wilkinson in Michel Gondry's science fiction romantic comedy-drama "Eternal Sunshine of the Spotless Mind" (2004). The latter film received very positive reviews, with "Entertainment Weekly" describing Dunst's subplot as "nifty and clever". The movie grossed $72 million worldwide.

The success of the first "Spider-Man" film led Dunst to reprise her role as Mary Jane Watson in 2004 in "Spider-Man 2". The movie was well received by critics and a financial success, setting a new opening weekend box office record for North America. With revenue of $783 million worldwide, it was the second highest-grossing film in 2004. Also in 2004, Dunst co-starred opposite Paul Bettany in the romantic comedy "Wimbledon" where she portrayed a rising tennis player in the Wimbledon Championships, while Bettany portrayed a fading former tennis star. The film received mixed reviews, but many critics enjoyed Dunst's performance. Claudia Puig of "USA Today" reported that the chemistry between Dunst and Bettany was potent, with Dunst doing a fine job as a sassy and self-assured player.

In 2005, she co-starred opposite Orlando Bloom in Cameron Crowe's romantic tragicomedy "Elizabethtown" as Claire Colburn, a flight attendant. The film premiered at the 2005 Toronto International Film Festival. Dunst revealed that working with Crowe was enjoyable, but more demanding than she had expected. The movie garnered mixed reviews, with the "Chicago Tribune" rating it one out of four stars and describing Dunst's portrayal of a flight attendant as "cloying." It was a box office disappointment.

In 2006, Dunst collaborated with Sofia Coppola again and starred as the title character in Coppola's historical drama "Marie Antoinette", based on Antonia Fraser's book "". The movie was screened at a special presentation at the 2006 Cannes Film Festival, and was reviewed favourably. International revenues were $45 million out of $60 million overall.

In 2007, Dunst reprised her role as Mary Jane Watson in "Spider-Man 3". In contrast to the previous two films' positive reviews, "Spider-Man 3" received mixed reviews from critics. Nonetheless, with a total worldwide gross of $891 million, it stands as the most commercially successful film in the series and Dunst's highest-grossing film to the end of 2008. Having initially signed on for three "Spider-Man" films, she said that she would do a fourth, but only if Raimi and Maguire also returned. In January 2010, it was announced that the fourth film was cancelled and that the "Spider-Man" film series would be restarted, and therefore dropping Dunst, Maguire and Raimi from the franchise.

In 2008, Dunst co-starred opposite Simon Pegg in the comedy "How to Lose Friends & Alienate People", based on former "Vanity Fair" contributing editor Toby Young's memoir of the same name.

Dunst made her screenwriting and directorial debut with the short film "Bastard", which premiered at the Tribeca Film Festival in 2010 and was later featured at the 2010 Cannes Film Festival. She co-starred opposite Ryan Gosling in the mystery drama "All Good Things" (2010), based on a true story as the wife of Gosling's character from a run-down neighborhood who goes missing. The film received reasonable reviews, and earned $640,000 worldwide. Dunst co-starred with Brian Geraghty in Carlos Cuarón's short film "The Second Bakery Attack", based on Haruki Murakami's short story.

In 2011, Dunst co-starred opposite Charlotte Gainsbourg, Kiefer Sutherland and Charlotte Rampling in Lars von Trier's drama film "Melancholia" as a woman suffering depression as the world ends. The film premiered at the 2011 Cannes Film Festival and received positive reviews and Dunst was singled out for praise. Steven Loeb of "Southampton Patch" wrote, "This film has brought the best out of von Trier, as well as his star. Dunst is so good in this film, playing a character unlike any other she has ever attempted... Even if the film itself were not the incredible work of art that it is, Dunst's performance alone would be incentive enough to recommend it."

Sukhdev Sandhu wrote from Cannes in "The Daily Telegraph" that "Dunst is exceptional, so utterly convincing in the lead role – trouble, serene, a fierce savant – that it feels like a career breakthrough. Dunst won several awards for her performance, including the Best Actress Award at the Cannes Film Festival and the Best Actress Award from the U.S. National Society of Film Critics

Dunst has signed to star in "Sweet Relief" as Marla Ruzicka, a peace activist and U.S. relief worker killed by a suicide bomb in Baghdad. She has expressed interest in playing the role of Blondie frontwoman Debbie Harry in Michel Gondry's upcoming biographical film about the band.

In 2012, Dunst co-starred in Juan Diego Solanas' science fiction romantic drama "Upside Down" opposite Jim Sturgess. She co-starred opposite Isla Fisher, Rebel Wilson and Lizzy Caplan in Leslye Headland's romantic comedy "Bachelorette", produced by Will Ferrell and Adam McKay. In 2012, she co-starred opposite Sam Riley, Kristen Stewart and Garrett Hedlund in the adventure drama "On the Road" as Camille Moriarty, based on Jack Kerouac's novel of the same name. She made a cameo appearance in the short film "Fight For Your Right Revisited". It premiered at the 2011 Sundance Film Festival.

In 2015, Dunst co-starred as Peggy Blumquist in the second season of the critically acclaimed FX crime comedy-drama "Fargo", for which she received a Golden Globe nomination. In 2016, Dunst co-starred in Jeff Nichols' science fiction drama "Midnight Special" with Michael Shannon and Joel Edgerton. In May 2016, she was a member of the main competition jury of the 2016 Cannes Film Festival.

In 2017, Dunst starred with Colin Farrell, Nicole Kidman, and Elle Fanning in the drama "The Beguiled", her third collaboration with Sofia Coppola, who directed, wrote, and produced. The film is a remake of Don Siegel's original 1971 film about a wounded Union soldier who seeks shelter at an all-girls' school deep in Confederate country. That same year, Dunst starred in the Rodarte label founders' feature directorial debut "Woodshock" about a woman who falls deeper into paranoia after taking a deadly drug.

In October 2015, Dunst said that she was co-writing and set to direct a film adaptation of a novel. In July 2016, it was announced that Dunst would be making her feature film directorial debut with an adaptation of Sylvia Plath's novel "The Bell Jar", with Dakota Fanning in the lead role. Dunst will next star in the upcoming YouTube Premium dark comedy series, "On Becoming a God in Central Florida". Filming began in October 2018.

Dunst made her singing debut in the comedy film "Get Over It", performing two songs written by Marc Shaiman.

She recorded Henry Creamer and Turner Layton's jazz standard "After You've Gone" that was used in the end credits of "The Cat's Meow". In "Spider-Man 3", she sang two songs as Mary Jane Watson, one during a Broadway performance, and one as a singing waitress in a jazz club. Dunst recorded the songs earlier and lip-synced while filming. She appeared in the music videos for Savage Garden's "I Knew I Loved You", Beastie Boys' "Make Some Noise" and R.E.M.'s "We All Go Back to Where We Belong" and she sang two tracks which were "This Old Machine" and "Summer Day" on Jason Schwartzman's 2007 solo album "Nighttiming".

In 2007, Dunst said she had no plans to release albums, saying, "It worked when Barbra Streisand was doing it, but now it's a little cheesy, I think. It works better when singers are in movies."

Dunst starred as the magical princess Majokko in the Takashi Murakami and McG directed short "Akihabara Majokko Princess" singing a cover of The Vapors' 1980 song "Turning Japanese". This was shown at the "Pop Life" exhibition in London's Tate Modern museum from October 1, 2009, to January 17, 2010. It shows Dunst prancing around Akihabara, a crowded shopping district in Tokyo, Japan.

Dunst dated actor Jake Gyllenhaal from 2002 to 2004. She dated Razorlight frontman Johnny Borrell in 2007. She dated her "On the Road" co-star Garrett Hedlund from 2012 to 2016. Dunst began dating her "Fargo" co-star Jesse Plemons in 2016. As of 2018, they are engaged. Dunst gave birth to their son, Ennis Howard Plemons, on May 3, 2018, in Santa Monica, California.

Dunst was treated for depression in early 2008 at the Cirque Lodge treatment center in Utah. She explained that she had been feeling low in the six months before her admission. In late March 2008, she checked out of the treatment center and began filming the mystery drama "All Good Things". In May 2008, she went public with this information in order to dispel rumors of drug and alcohol abuse, stating that "Now that I'm feeling stronger, I was prepared to say something (...) Depression is pretty serious and should not be gossiped about".

Dunst gained German citizenship in 2011, which enabled her to "film in Europe without a problem" and holds dual citizenship of Germany and the United States.

Dunst supported Democratic candidate John Kerry for the 2004 U.S. presidential election. She supported Barack Obama for the 2008 presidential election, directing and narrating a documentary, "Why Tuesday", about the tradition of voting on Tuesdays and the low voter turnout in the U.S., as she felt it important to "influence people in a positive way".

Dunst works with the Elizabeth Glaser Pediatric AIDS Foundation, for which she helped design and promote a necklace whose sales proceeds went to the Foundation. She worked in breast cancer awareness, participating in the Stand Up to Cancer telethon in September 2008 to raise funds for cancer research. On December 5, 2009, she participated in the Teletón in Mexico, to raise funds for cancer treatment and children's rehabilitation.

Dunst bought a home in Toluca Lake, Los Angeles, California, in 2001. In 2010, she sold a residence in Nichols Canyon, Los Angeles. She also lived in a Lower Manhattan apartment which she listed for sale in 2017.




</doc>
<doc id="17747" url="https://en.wikipedia.org/wiki?curid=17747" title="Lead">
Lead

Lead () is a chemical element with symbol Pb (from the Latin "plumbum") and atomic number 82. It is a heavy metal that is denser than most common materials. Lead is soft and malleable, and also has a relatively low melting point. When freshly cut, lead is silvery with a hint of blue; it tarnishes to a dull gray color when exposed to air. Lead has the highest atomic number of any stable element and three of its isotopes each include a major decay chain of heavier elements.

Lead is a relatively unreactive post-transition metal. Its weak metallic character is illustrated by its amphoteric nature; lead and lead oxides react with acids and bases, and it tends to form covalent bonds. Compounds of lead are usually found in the +2 oxidation state rather than the +4 state common with lighter members of the carbon group. Exceptions are mostly limited to organolead compounds. Like the lighter members of the group, lead tends to bond with itself; it can form chains and polyhedral structures.

Lead is easily extracted from its ores; prehistoric people in Western Asia knew of it. Galena, a principal ore of lead, often bears silver, interest in which helped initiate widespread extraction and use of lead in ancient Rome. Lead production declined after the fall of Rome and did not reach comparable levels until the Industrial Revolution. In 2014, the annual global production of lead was about ten million tonnes, over half of which was from recycling. Lead's high density, low melting point, ductility and relative inertness to oxidation make it useful. These properties, combined with its relative abundance and low cost, resulted in its extensive use in construction, plumbing, batteries, bullets and shot, weights, solders, pewters, fusible alloys, white paints, leaded gasoline, and radiation shielding.

In the late 19th century, lead's toxicity was recognized, and its use has since been phased out of many applications. However, many countries still allow the sale of products that expose humans to lead, including some types of paints and bullets. Lead is a toxin that accumulates in soft tissues and bones, it acts as a neurotoxin damaging the nervous system and interfering with the function of biological enzymes, causing neurological disorders, such as brain damage and behavioral problems.

A lead atom has 82 electrons, arranged in an electron configuration of [Xe]4f5d6s6p. The sum of lead's first and second ionization energies—the total energy required to remove the two 6p electrons—is close to that of tin, lead's upper neighbor in the carbon group. This is unusual; ionization energies generally fall going down a group, as an element's outer electrons become more distant from the nucleus, and more shielded by smaller orbitals. The similarity of ionization energies is caused by the lanthanide contraction—the decrease in element radii from lanthanum (atomic number 57) to lutetium (71), and the relatively small radii of the elements from hafnium (72) onwards. This is due to poor shielding of the nucleus by the lanthanide 4f electrons. The sum of the first four ionization energies of lead exceeds that of tin, contrary to what periodic trends would predict. Relativistic effects, which become significant in heavier atoms, contribute to this behavior. One such effect is the inert pair effect: the 6s electrons of lead become reluctant to participate in bonding, making the distance between nearest atoms in crystalline lead unusually long.

Lead's lighter carbon group congeners form stable or metastable allotropes with the tetrahedrally coordinated and covalently bonded diamond cubic structure. The energy levels of their outer s- and p-orbitals are close enough to allow mixing into four hybrid sp orbitals. In lead, the inert pair effect increases the separation between its s- and p-orbitals, and the gap cannot be overcome by the energy that would be released by extra bonds following hybridization. Rather than having a diamond cubic structure, lead forms metallic bonds in which only the p-electrons are delocalized and shared between the Pb ions. Lead consequently has a face-centered cubic structure like the similarly sized divalent metals calcium and strontium.

Pure lead has a bright, silvery appearance with a hint of blue. It tarnishes on contact with moist air and takes on a dull appearance, the hue of which depends on the prevailing conditions. Characteristic properties of lead include high density, malleability, ductility, and high resistance to corrosion due to passivation.
Lead's close-packed face-centered cubic structure and high atomic weight result in a density of 11.34 g/cm, which is greater than that of common metals such as iron (7.87 g/cm), copper (8.93 g/cm), and zinc (7.14 g/cm). This density is the origin of the idiom "to go over like a lead balloon". Some rarer metals are denser: tungsten and gold are both at 19.3 g/cm, and osmium—the densest metal known—has a density of 22.59 g/cm, almost twice that of lead.

Lead is a very soft metal with a Mohs hardness of 1.5; it can be scratched with a fingernail. It is quite malleable and somewhat ductile. The bulk modulus of lead—a measure of its ease of compressibility—is 45.8 GPa. In comparison, that of aluminium is 75.2 GPa; copper 137.8 GPa; and mild steel 160–169 GPa. Lead's tensile strength, at 12–17 MPa, is low (that of aluminium is 6 times higher, copper 10 times, and mild steel 15 times higher); it can be strengthened by adding small amounts of copper or antimony.

The melting point of lead—at 327.5 °C (621.5 °F)—is very low compared to most metals. Its boiling point of 1749 °C (3180 °F) is the lowest among the carbon group elements. The electrical resistivity of lead at 20 °C is 192 nanoohm-meters, almost an order of magnitude higher than those of other industrial metals (copper at 15.43 nΩ·m; gold 20.51 nΩ·m; and aluminium at 24.15 nΩ·m). Lead is a superconductor at temperatures lower than 7.19 K; this is the highest critical temperature of all type-I superconductors and the third highest of the elemental superconductors.

Natural lead consists of four stable isotopes with mass numbers of 204, 206, 207, and 208, and traces of five short-lived radioisotopes. The high number of isotopes is consistent with lead's atomic number being even. Lead has a magic number of protons (82), for which the nuclear shell model accurately predicts an especially stable nucleus. Lead-208 has 126 neutrons, another magic number, which may explain why lead-208 is extraordinarily stable.

With its high atomic number, lead is the heaviest element whose natural isotopes are regarded as stable; lead-208 is the heaviest stable nucleus. (This distinction formerly fell to bismuth, with an atomic number of 83, until its only primordial isotope, bismuth-209, was found in 2003 to decay very slowly.) The four stable isotopes of lead could theoretically undergo alpha decay to isotopes of mercury with a release of energy, but this has not been observed for any of them; their predicted half-lives range from 10 to 10 years (at least 10 times the current age of the universe).

Three of the stable isotopes are found in three of the four major decay chains: lead-206, lead-207, and lead-208 are the final decay products of uranium-238, uranium-235, and thorium-232, respectively. These decay chains are called the uranium chain, the actinium chain, and the thorium chain. Their isotopic concentrations in a natural rock sample depends greatly on the presence of these three parent uranium and thorium isotopes. For example, the relative abundance of lead-208 can range from 52% in normal samples to 90% in thorium ores; for this reason, the standard atomic weight of lead is given to only one decimal place. As time passes, the ratio of lead-206 and lead-207 to lead-204 increases, since the former two are supplemented by radioactive decay of heavier elements while the latter is not; this allows for lead–lead dating. As uranium decays into lead, their relative amounts change; this is the basis for uranium–lead dating. Lead-207 exhibits nuclear magnetic resonance, a property that has been used to study its compounds in solution and solid state, including in human body.
Apart from the stable isotopes, which make up almost all lead that exists naturally, there are trace quantities of a few radioactive isotopes. One of them is lead-210; although it has a half-life of only 22.3 years, small quantities occur in nature because lead-210 is produced by a long decay series that starts with uranium-238 (which has been present for billions of years on Earth). Lead-211, -212, and -214 are present in the decay chains of uranium-235, thorium-232, and uranium-238, respectively, so traces of all three of these lead isotopes are found naturally. Minute traces of lead-209 arise from the very rare cluster decay of radium-223, one of the daughter products of natural uranium-235, and the decay chain of neptunium-237, traces of which are produced by neutron capture in uranium ores. Lead-210 is particularly useful for helping to identify the ages of samples by measuring its ratio to lead-206 (both isotopes are present in a single decay chain).

In total, 43 lead isotopes have been synthesized, with mass numbers 178–220. Lead-205 is the most stable radioisotope, with a half-life of around 1.5 years. The second-most stable is lead-202, which has a half-life of about 53,000 years, longer than any of the natural trace radioisotopes.

Bulk lead exposed to moist air forms a protective layer of varying composition. Lead(II) carbonate is a common constituent; the sulfate or chloride may also be present in urban or maritime settings. This layer makes bulk lead effectively chemically inert in the air. Finely powdered lead, as with many metals, is pyrophoric, and burns with a bluish-white flame.

Fluorine reacts with lead at room temperature, forming lead(II) fluoride. The reaction with chlorine is similar but requires heating, as the resulting chloride layer diminishes the reactivity of the elements. Molten lead reacts with the chalcogens to give lead(II) chalcogenides.

Lead metal resists sulfuric and phosphoric acid but not hydrochloric or nitric acid; the outcome depends on insolubility and subsequent passivation of the product salt. Organic acids, such as acetic acid, dissolve lead in the presence of oxygen. Concentrated alkalis will dissolve lead and form plumbites.

Lead shows two main oxidation states: +4 and +2. The tetravalent state is common for the carbon group. The divalent state is rare for carbon and silicon, minor for germanium, important (but not prevailing) for tin, and is the more important of the two oxidation states for lead. This is attributable to relativistic effects, specifically the inert pair effect, which manifests itself when there is a large difference in electronegativity between lead and oxide, halide, or nitride anions, leading to a significant partial positive charge on lead. The result is a stronger contraction of the lead 6s orbital than is the case for the 6p orbital, making it rather inert in ionic compounds. The inert pair effect is less applicable to compounds in which lead forms covalent bonds with elements of similar electronegativity, such as carbon in organolead compounds. In these, the 6s and 6p orbitals remain similarly sized and sp hybridization is still energetically favorable. Lead, like carbon, is predominantly tetravalent in such compounds.

There is a relatively large difference in the electronegativity of lead(II) at 1.87 and lead(IV) at 2.33. This difference marks the reversal in the trend of increasing stability of the +4 oxidation state going down the carbon group; tin, by comparison, has values of 1.80 in the +2 oxidation state and 1.96 in the +4 state.

Lead(II) compounds are characteristic of the inorganic chemistry of lead. Even strong oxidizing agents like fluorine and chlorine react with lead to give only PbF and PbCl. Lead(II) ions are usually colorless in solution, and partially hydrolyze to form Pb(OH) and finally [Pb(OH)] (in which the hydroxyl ions act as bridging ligands), but are not reducing agents as tin(II) ions are. Techniques for identifying the presence of the Pb ion in water generally rely on the precipitation of lead(II) chloride using dilute hydrochloric acid. As the chloride salt is sparingly soluble in water, in very dilute solutions the precipitation of lead(II) sulfide is achieved by bubbling hydrogen sulfide through the solution.

Lead monoxide exists in two polymorphs, litharge α-PbO (red) and massicot β-PbO (yellow), the latter being stable only above around 488 °C. Litharge is the most commonly used inorganic compound of lead. There is no lead(II) hydroxide; increasing the pH of solutions of lead(II) salts leads to hydrolysis and condensation.
Lead commonly reacts with heavier chalcogens. Lead sulfide is a semiconductor, a photoconductor, and an extremely sensitive infrared radiation detector. The other two chalcogenides, lead selenide and lead telluride, are likewise photoconducting. They are unusual in that their color becomes lighter going down the group.
Lead dihalides are well-characterized; this includes the diastatide, and mixed halides, such as PbFCl. The relative insolubility of the latter forms a useful basis for the gravimetric determination of fluorine. The difluoride was the first solid ionically conducting compound to be discovered (in 1834, by Michael Faraday). The other dihalides decompose on exposure to ultraviolet or visible light, especially the diiodide. Many lead(II) pseudohalides are known, such as the cyanide, cyanate, and thiocyanate. Lead(II) forms an extensive variety of halide coordination complexes, such as [PbCl], [PbCl], and the [PbCl] chain anion.

Lead(II) sulfate is insoluble in water, like the sulfates of other heavy divalent cations. Lead(II) nitrate and lead(II) acetate are very soluble, and this is exploited in the synthesis of other lead compounds.

Few inorganic lead(IV) compounds are known. They are only formed in highly oxidizing solutions and do not normally exist under standard conditions. Lead(II) oxide gives a mixed oxide on further oxidation, PbO. It is described as lead(II,IV) oxide, or structurally 2PbO·PbO, and is the best-known mixed valence lead compound. Lead dioxide is a strong oxidizing agent, capable of oxidizing hydrochloric acid to chlorine gas. This is because the expected PbCl that would be produced is unstable and spontaneously decomposes to PbCl and Cl. Analogously to lead monoxide, lead dioxide is capable of forming plumbate anions. Lead disulfide and lead diselenide are only stable at high pressures. Lead tetrafluoride, a yellow crystalline powder, is stable, but less so than the difluoride. Lead tetrachloride (a yellow oil) decomposes at room temperature, lead tetrabromide is less stable still, and the existence of lead tetraiodide is questionable.

Some lead compounds exist in formal oxidation states other than +4 or +2. Lead(III) may be obtained, as an intermediate between lead(II) and lead(IV), in larger organolead complexes; this oxidation state is not stable, as both the lead(III) ion and the larger complexes containing it are radicals. The same applies for lead(I), which can be found in such radical species.

Numerous mixed lead(II,IV) oxides are known. When PbO is heated in air, it becomes PbO at 293 °C, PbO at 351 °C, PbO at 374 °C, and finally PbO at 605 °C. A further sesquioxide, PbO, can be obtained at high pressure, along with several non-stoichiometric phases. Many of them show defective fluorite structures in which some oxygen atoms are replaced by vacancies: PbO can be considered as having such a structure, with every alternate layer of oxygen atoms absent.

Negative oxidation states can occur as Zintl phases, as either free lead anions, as in BaPb, with lead formally being lead(−IV), or in oxygen-sensitive ring-shaped or polyhedral cluster ions such as the trigonal bipyramidal Pb ion, where two lead atoms are lead(−I) and three are lead(0). In such anions, each atom is at a polyhedral vertex and contributes two electrons to each covalent bond along an edge from their sp hybrid orbitals, the other two being an external lone pair. They may be made in liquid ammonia via the reduction of lead by sodium.

Lead can form multiply-bonded chains, a property it shares with its lighter homologs in the carbon group. Its capacity to do so is much less because the Pb–Pb bond energy is over three and a half times lower than that of the C–C bond. With itself, lead can build metal–metal bonds of an order up to three. With carbon, lead forms organolead compounds similar to, but generally less stable than, typical organic compounds (due to the Pb–C bond being rather weak). This makes the organometallic chemistry of lead far less wide-ranging than that of tin. Lead predominantly forms organolead(IV) compounds, even when starting with inorganic lead(II) reactants; very few organolead(II) compounds are known. The most well-characterized exceptions are Pb[CH(SiMe)] and Pb("η"-CH).

The lead analog of the simplest organic compound, methane, is plumbane. Plumbane may be obtained in a reaction between metallic lead and atomic hydrogen. Two simple derivatives, tetramethyllead and tetraethyllead, are the best-known organolead compounds. These compounds are relatively stable: tetraethyllead only starts to decompose if heated or if exposed to sunlight or ultraviolet light. (Tetraphenyllead is even more thermally stable, decomposing at 270 °C.) With sodium metal, lead readily forms an equimolar alloy that reacts with alkyl halides to form organometallic compounds such as tetraethyllead. The oxidizing nature of many organolead compounds is usefully exploited: lead tetraacetate is an important laboratory reagent for oxidation in organic synthesis, and tetraethyllead was once produced in larger quantities than any other organometallic compound. Other organolead compounds are less chemically stable. For many organic compounds, a lead analog does not exist.

Lead's per-particle abundance in the Solar System is 0.121 ppb (parts per billion). This figure is two and a half times higher than that of platinum, eight times more than mercury, and seventeen times more than gold. The amount of lead in the universe is slowly increasing as most heavier atoms (all of which are unstable) gradually decay to lead. The abundance of lead in the Solar System since its formation 4.5 billion years ago has increased by about 0.75%. The solar system abundances table shows that lead, despite its relatively high atomic number, is more prevalent than most other elements with atomic numbers greater than 40.

Primordial lead—which comprises the isotopes lead-204, lead-206, lead-207, and lead-208—was mostly created as a result of repetitive neutron capture processes occurring in stars. The two main modes of capture are the s- and r-processes.

In the s-process (s is for "slow"), captures are separated by years or decades, allowing less stable nuclei to undergo beta decay. A stable thallium-203 nucleus can capture a neutron and become thallium-204; this undergoes beta decay to give stable lead-204; on capturing another neutron, it becomes lead-205, which has a half-life of around 15 million years. Further captures result in lead-206, lead-207, and lead-208. On capturing another neutron, lead-208 becomes lead-209, which quickly decays into bismuth-209. On capturing another neutron, bismuth-209 becomes bismuth-210, and this beta decays to polonium-210, which alpha decays to lead-206. The cycle hence ends at lead-206, lead-207, lead-208, and bismuth-209.
In the r-process (r is for "rapid"), captures happen faster than nuclei can decay. This occurs in environments with a high neutron density, such as a supernova or the merger of two neutron stars. The neutron flux involved may be on the order of 10 neutrons per square centimeter per second. The r-process does not form as much lead as the s-process. It tends to stop once neutron-rich nuclei reach 126 neutrons. At this point, the neutrons are arranged in complete shells in the atomic nucleus, and it becomes harder to energetically accommodate more of them. When the neutron flux subsides, these nuclei beta decay into stable isotopes of osmium, iridium, and platinum.

Lead is classified as a chalcophile under the Goldschmidt classification, meaning it is generally found combined with sulfur. It rarely occurs in its native, metallic form. Many lead minerals are relatively light and, over the course of the Earth's history, have remained in the crust instead of sinking deeper into the Earth's interior. This accounts for lead's relatively high crustal abundance of 14 ppm; it is the 38th most abundant element in the crust.

The main lead-bearing mineral is galena (PbS), which is mostly found with zinc ores. Most other lead minerals are related to galena in some way; boulangerite, PbSbS, is a mixed sulfide derived from galena; anglesite, PbSO, is a product of galena oxidation; and cerussite or white lead ore, PbCO, is a decomposition product of galena. Arsenic, tin, antimony, silver, gold, copper, and bismuth are common impurities in lead minerals.
World lead resources exceed two billion tons. Significant deposits are located in Australia, China, Ireland, Mexico, Peru, Portugal, Russia, and the United States. Global reserves—resources that are economically feasible to extract—totaled 88 million tons in 2016, of which Australia had 35 million, China 17 million, and Russia 6.4 million.

Typical background concentrations of lead do not exceed 0.1 μg/m in the atmosphere; 100 mg/kg in soil; and 5 μg/L in freshwater and seawater.

The modern English word "lead" is of Germanic origin; it comes from the Middle English "leed" and Old English "lēad" (with the macron above the "e" signifying that the vowel sound of that letter is long). The Old English word is derived from the hypothetical reconstructed Proto-Germanic "*lauda-" ("lead"). According to linguistic theory, this word bore descendants in multiple Germanic languages of exactly the same meaning.

The origin of the Proto-Germanic "*lauda-" is not agreed in the linguistic community. One hypothesis suggests it is derived from Proto-Indo-European "*lAudh-" ("lead"; capitalization of the vowel is equivalent to the macron). Another hypothesis suggests it is borrowed from Proto-Celtic "*ɸloud-io-" ("lead"). This word is related to the Latin "plumbum", which gave the element its chemical symbol "Pb". The word "*ɸloud-io-" is thought to be the origin of Proto-Germanic "*bliwa-" (which also means "lead"), from which stemmed the German "Blei".

The name of the chemical element is not related to the verb of the same spelling, which is derived from Proto-Germanic "*laidijan-" ("to lead").

Metallic lead beads dating back to 7000–6500 BCE have been found in Asia Minor and may represent the first example of metal smelting. At that time lead had few (if any) applications due to its softness and dull appearance. The major reason for the spread of lead production was its association with silver, which may be obtained by burning galena (a common lead mineral). The Ancient Egyptians were the first to use lead minerals in cosmetics, an application that spread to Ancient Greece and beyond; the Egyptians may have used lead for sinkers in fishing nets, glazes, glasses, enamels, and for ornaments. Various civilizations of the Fertile Crescent used lead as a writing material, as currency, and as a construction material. Lead was used in the Ancient Chinese royal court as a stimulant, as currency, and as a contraceptive; the Indus Valley civilization and the Mesoamericans used it for making amulets; and the eastern and southern African peoples used lead in wire drawing.

Because silver was extensively used as a decorative material and an exchange medium, lead deposits came to be worked in Asia Minor since 3000 BCE; later, lead deposits were developed in the Aegean and Laurion. These three regions collectively dominated production of mined lead until c. 1200 BCE. Since 2000 BCE, the Phoenicians worked deposits in the Iberian peninsula; by 1600 BCE, lead mining existed in Cyprus, Greece, and Sardinia.

Rome's territorial expansion in Europe and across the Mediterranean, and its development of mining, led to it becoming the greatest producer of lead during the classical era, with an estimated annual output peaking at 80,000 tonnes. Like their predecessors, the Romans obtained lead mostly as a by-product of silver smelting. Lead mining occurred in Central Europe, Britain, the Balkans, Greece, Anatolia, and Hispania, the latter accounting for 40% of world production.

Lead tablets were commonly used as a material for letters. Lead coffins, cast in flat sand forms, with interchangeable motifs to suit the faith of the deceased were used in ancient Judea.

Lead was used for making water pipes in the Roman Empire; the Latin word for the metal, "plumbum", is the origin of the English word "plumbing". Its ease of working and resistance to corrosion ensured its widespread use in other applications including pharmaceuticals, roofing, currency, and warfare. Writers of the time, such as Cato the Elder, Columella, and Pliny the Elder, recommended lead (or lead-coated) vessels for the preparation of sweeteners and preservatives added to wine and food. The lead conferred an agreeable taste due to the formation of "sugar of lead" (lead(II) acetate), whereas copper or bronze vessels could impart a bitter flavor through verdigris formation.

The Roman author Vitruvius reported the health dangers of lead and modern writers have suggested that lead poisoning played a major role in the decline of the Roman Empire. Other researchers have criticized such claims, pointing out, for instance, that not all abdominal pain is caused by lead poisoning. According to archaeological research, Roman lead pipes increased lead levels in tap water but such an effect was "unlikely to have been truly harmful". When lead poisoning did occur, victims were called "saturnine", dark and cynical, after the ghoulish father of the gods, Saturn. By association, lead was considered the father of all metals. Its status in Roman society was low as it was readily available and cheap.

During the classical era (and even up to the 17th century), tin was often not distinguished from lead: Romans called lead "plumbum nigrum" ("black lead"), and tin "plumbum candidum" ("bright lead"). The association of lead and tin can be seen in other languages: the word "olovo" in Czech translates to "lead", but in Russian, its cognate олово ("olovo") means "tin". To add to the confusion, lead bore a close relation to antimony: both elements commonly occur as sulfides (galena and stibnite), often together. Pliny incorrectly wrote that stibnite would give lead on heating, instead of antimony. In countries such as Turkey and India, the originally Persian name "surma" came to refer to either antimony sulfide or lead sulfide, and in some languages, such as Russian, gave its name to antimony (сурьма).

Lead mining in Western Europe declined after the fall of the Western Roman Empire, with Arabian Iberia being the only region having a significant output. The largest production of lead occurred in South and East Asia, especially China and India, where lead mining grew rapidly.

In Europe, lead production began to increase in the 11th and 12th centuries, when it was again used for roofing and piping. Starting in the 13th century, lead was used to create stained glass. In the European and Arabian traditions of alchemy, lead (symbol in the European tradition) was considered an impure base metal which, by the separation, purification and balancing of its constituent essences, could be transformed to pure and incorruptible gold. During the period, lead was used increasingly for adulterating wine. The use of such wine was forbidden for use in Christian rites by a papal bull in 1498, but it continued to be imbibed and resulted in mass poisonings up to the late 18th century. Lead was a key material in parts of the printing press, which was invented around 1440; lead dust was commonly inhaled by print workers, causing lead poisoning. Firearms were invented at around the same time, and lead, despite being more expensive than iron, became the chief material for making bullets. It was less damaging to iron gun barrels, had a higher density (which allowed for better retention of velocity), and its lower melting point made the production of bullets easier as they could be made using a wood fire. Lead, in the form of Venetian ceruse, was extensively used in cosmetics by Western European aristocracy as whitened faces were regarded as a sign of modesty. This practice later expanded to white wigs and eyeliners, and only faded out with the French Revolution in the late 18th century. A similar fashion appeared in Japan in the 18th century with the emergence of the geishas, a practice that continued long into the 20th century. The white faces of women "came to represent their feminine virtue as Japanese women", with lead commonly used in the whitener.

In the New World, lead production was recorded soon after the arrival of European settlers. The earliest record dates to 1621 in the English Colony of Virginia, fourteen years after its foundation. In Australia, the first mine opened by colonists on the continent was a lead mine, in 1841. In Africa, lead mining and smelting were known in the Benue Trough and the lower Congo Basin, where lead was used for trade with Europeans, and as a currency by the 17th century, well before the scramble for Africa. 

In the second half of the 18th century, Britain, and later continental Europe and the United States, experienced the Industrial Revolution. This was the first time during which lead production rates exceeded those of Rome. Britain was the leading producer, losing this status by the mid-19th century with the depletion of its mines and the development of lead mining in Germany, Spain, and the United States. By 1900, the United States was the leader in global lead production, and other non-European nations—Canada, Mexico, and Australia—had begun significant production; production outside Europe exceeded that within. A great share of the demand for lead came from plumbing and painting—lead paints were in regular use. At this time, more (working class) people were exposed to the metal and lead poisoning cases escalated. This led to research into the effects of lead intake. Lead was proven to be more dangerous in its fume form than as a solid metal. Lead poisoning and gout were linked; British physician Alfred Baring Garrod noted a third of his gout patients were plumbers and painters. The effects of chronic ingestion of lead, including mental disorders, were also studied in the 19th century. The first laws aimed at decreasing lead poisoning in factories were enacted during the 1870s and 1880s in the United Kingdom.

Further evidence of the threat that lead posed to humans was discovered in the late 19th and early 20th centuries. Mechanisms of harm were better understood, lead blindness was documented, and the element was phased out of public use in the United States and Europe. The United Kingdom introduced mandatory factory inspections in 1878 and appointed the first Medical Inspector of Factories in 1898; as a result, a 25-fold decrease in lead poisoning incidents from 1900 to 1944 was reported. Most European countries banned lead paint—commonly used because of its opacity and water resistance—for interiors by 1930.

The last major human exposure to lead was the addition of tetraethyllead to gasoline as an antiknock agent, a practice that originated in the United States in 1921. It was phased out in the United States and the European Union by 2000.

In the 1970s, the United States and Western European countries introduced legislation to reduce lead air pollution. The impact was significant: while a study conducted by the Centers for Disease Control and Prevention in the United States in 1976–1980 showed that 77.8% of the population had elevated blood lead levels, in 1991–1994, a study by the same institute showed the share of people with such high levels dropped to 2.2%. The main product made of lead by the end of the 20th century was the lead–acid battery, which posed no direct threat to humans.

From 1960 to 1990, lead output in the Western Bloc grew by about 31%. The share of the world's lead production by the Eastern Bloc increased from 10% to 30%, from 1950 to 1990, with the Soviet Union being the world's largest producer during the mid-1970s and the 1980s, and China starting major lead production in the late 20th century. Unlike the European communist countries, China was largely unindustrialized by the mid-20th century; in 2004, China surpassed Australia as the largest producer of lead. As was the case during European industrialization, lead has had a negative effect on health in China.

As of 2014, production of lead is increasing worldwide due to its use in lead–acid batteries. There are two major categories of production: primary from mined ores, and secondary from scrap. In 2014, 4.58 million metric tons came from primary production and 5.64 million from secondary production. The top three producers of mined lead concentrate in that year were China, Australia, and the United States. The top three producers of refined lead were China, the United States, and India. According to the International Resource Panel's Metal Stocks in Society report of 2010, the total amount of lead in use, stockpiled, discarded, or dissipated into the environment, on a global basis, is 8 kg per capita. Much of this is in more developed countries (20–150 kg per capita) rather than less developed ones (1–4 kg per capita).

The primary and secondary lead production processes are similar. Some primary production plants now supplement their operations with scrap lead, and this trend is likely to increase in the future. Given adequate techniques, lead obtained via secondary processes is indistinguishable from lead obtained via primary processes. Scrap lead from the building trade is usually fairly clean and is re-melted without the need for smelting, though refining is sometimes needed. Secondary lead production is therefore cheaper, in terms of energy requirements, than is primary production, often by 50% or more.

Most lead ores contain a low percentage of lead (rich ores have a typical content of 3–8%) which must be concentrated for extraction. During initial processing, ores typically undergo crushing, dense-medium separation, grinding, froth flotation, and drying. The resulting concentrate, which has a lead content of 30–80% by mass (regularly 50–60%), is then turned into (impure) lead metal.

There are two main ways of doing this: a two-stage process involving roasting followed by blast furnace extraction, carried out in separate vessels; or a direct process in which the extraction of the concentrate occurs in a single vessel. The latter has become the most common route, though the former is still significant.

First, the sulfide concentrate is roasted in air to oxidize the lead sulfide:

As the original concentrate was not pure lead sulfide, roasting yields not only the desired lead(II) oxide, but a mixture of oxides, sulfates, and silicates of lead and of the other metals contained in the ore. This impure lead oxide is reduced in a coke-fired blast furnace to the (again, impure) metal:

Impurities are mostly arsenic, antimony, bismuth, zinc, copper, silver, and gold. Typically they are removed in a series of pyrometallurgical processes. The melt is treated in a reverberatory furnace with air, steam, and sulfur, which oxidizes the impurities except for silver, gold, and bismuth. Oxidized contaminants float to the top of the melt and are skimmed off. Metallic silver and gold are removed and recovered economically by means of the Parkes process, in which zinc is added to lead. Zinc, which is immiscible in lead, dissolves the silver and gold. The zinc solution can be separated from the lead, and the silver and gold retrieved. De-silvered lead is freed of bismuth by the Betterton–Kroll process, treating it with metallic calcium and magnesium. The resulting bismuth dross can be skimmed off.

Alternatively to the pyrometallurgical processes, very pure lead can be obtained by processing smelted lead electrolytically using the Betts process. Anodes of impure lead and cathodes of pure lead are placed in an electrolyte of lead fluorosilicate (PbSiF). Once electrical potential is applied, impure lead at the anode dissolves and plates onto the cathode, leaving the majority of the impurities in solution. This is a high-cost process and thus mostly reserved for refining bullion containing high percentages of impurities.

In this process, lead bullion and slag is obtained directly from lead concentrates. The lead sulfide concentrate is melted in a furnace and oxidized, forming lead monoxide. Carbon (as coke or coal gas) is added to the molten charge along with fluxing agents. The lead monoxide is thereby reduced to metallic lead, in the midst of a slag rich in lead monoxide.

If the input is rich in lead, as much as 80% of the original lead can be obtained as bullion; the remaining 20% forms a slag rich in lead monoxide. For a low-grade feed, all of the lead can be oxidized to a high-lead slag. Metallic lead is further obtained from the high-lead (25–40%) slags via submerged fuel combustion or injection, reduction assisted by an electric furnace, or a combination of both.

Research on a cleaner, less energy-intensive lead extraction process continues; a major drawback is that either too much lead is lost as waste, or the alternatives result in a high sulfur content in the resulting lead metal. Hydrometallurgical extraction, in which anodes of impure lead are immersed into an electrolyte and pure lead is deposited onto a cathode, is a technique that may have potential, but is not currently economical except in cases where electricity is very cheap.

Smelting, which is an essential part of the primary production, is often skipped during secondary production. It is only performed when metallic lead has undergone significant oxidation. The process is similar to that of primary production in either a blast furnace or a rotary furnace, with the essential difference being the greater variability of yields: blast furnaces produce hard lead (10% antimony) while reverberatory and rotary kiln furnaces produced semisoft lead (3–4% antimony). The Isasmelt process is a more recent smelting method that may act as an extension to primary production; battery paste from spent lead–acid batteries (containing lead sulfate and lead oxides) has its sulfate removed by treating it with alkali, and is then treated in a coal-fueled furnace in the presence of oxygen, which yields impure lead, with antimony the most common impurity. Refining of secondary lead is similar to that of primary lead; some refining processes may be skipped depending on the material recycled and its potential contamination.

Of the sources of lead for recycling, lead–acid batteries are the most important; lead pipe, sheet, and cable sheathing are also significant.

Contrary to popular belief, pencil leads in wooden pencils have never been made from lead. When the pencil originated as a wrapped graphite writing tool, the particular type of graphite used was named "plumbago" (literally, "act for lead" or "lead mockup").

Lead metal has several useful mechanical properties, including high density, low melting point, ductility, and relative inertness. Many metals are superior to lead in some of these aspects but are generally less common and more difficult to extract from parent ores. Lead's toxicity has led to its phasing out for some uses.

Lead has been used for bullets since their invention in the Middle Ages. It is inexpensive; its low melting point means small arms ammunition and shotgun pellets can be cast with minimal technical equipment; and it is denser than other common metals, which allows for better retention of velocity. It remains the main material for bullets, alloyed with other metals as hardeners. Concerns have been raised that lead bullets used for hunting can damage the environment.

Lead's high density and resistance to corrosion have been exploited in a number of related applications. It is used as ballast in sailboat keels; its density allows it to take up a small volume and minimize water resistance, thus counterbalancing the heeling effect of wind on the sails. It is used in scuba diving weight belts to counteract the diver's buoyancy. In 1993, the base of the Leaning Tower of Pisa was stabilized with 600 tonnes of lead. Because of its corrosion resistance, lead is used as a protective sheath for underwater cables.
Lead has many uses in the construction industry; lead sheets are used as architectural metals in roofing material, cladding, flashing, gutters and gutter joints, and on roof parapets. Detailed lead moldings are used as decorative motifs to fix lead sheet. Lead is still used in statues and sculptures, including for armatures. In the past it was often used to balance the wheels of cars; for environmental reasons this use is being phased out in favor of other materials.

Lead is added to copper alloys, such as brass and bronze, to improve machinability and for its lubricating qualities. Being practically insoluble in copper the lead forms solid globules in imperfections throughout the alloy, such as grain boundaries. In low concentrations, as well as acting as a lubricant, the globules hinder the formation of swarf as the alloy is worked, thereby improving machinability. Copper alloys with larger concentrations of lead are used in bearings. The lead provides lubrication, and the copper provides the load-bearing support.

Lead's high density, atomic number, and formability form the basis for use of lead as a barrier that absorbs sound, vibration, and radiation. Lead has no natural resonance frequencies; as a result, sheet-lead is used as a sound deadening layer in the walls, floors, and ceilings of sound studios. Organ pipes are often made from a lead alloy, mixed with various amounts of tin to control the tone of each pipe. Lead is an established shielding material from radiation in nuclear science and in X-ray rooms due to its denseness and high attenuation coefficient. Molten lead has been used as a coolant for lead-cooled fast reactors.

The largest use of lead in the early 21st century is in lead–acid batteries. The lead in batteries undergoes no direct contact with humans, so there are fewer toxicity concerns. People who work in battery production plants may be exposed to lead dust and inhale it.} The reactions in the battery between lead, lead dioxide, and sulfuric acid provide a reliable source of voltage. Supercapacitors incorporating lead–acid batteries have been installed in kilowatt and megawatt scale applications in Australia, Japan, and the United States in frequency regulation, solar smoothing and shifting, wind smoothing, and other applications. These batteries have lower energy density and charge-discharge efficiency than lithium-ion batteries, but are significantly cheaper.

Lead is used in high voltage power cables as sheathing material to prevent water diffusion into insulation; this use is decreasing as lead is being phased out. Its use in solder for electronics is also being phased out by some countries to reduce the amount of environmentally hazardous waste. Lead is one of three metals used in the Oddy test for museum materials, helping detect organic acids, aldehydes, and acidic gases.

In addition to being the main application for lead metal, lead-acid batteries are also the main consumer of lead compounds. The energy storage/release reaction used in these devices involves lead sulfate and lead dioxide:

Other applications of lead compounds are very specialized and often fading. Lead-based coloring agents are used in ceramic glazes and glass, especially for red and yellow shades. While lead paints are phased out in Europe and North America, they remain in use in less developed countries such as China, India, or Indonesia. Lead tetraacetate and lead dioxide are used as oxidizing agents in organic chemistry. Lead is frequently used in the polyvinyl chloride coating of electrical cords. It can be used to treat candle wicks to ensure a longer, more even burn. Because of its toxicity, European and North American manufacturers use alternatives such as zinc. Lead glass is composed of 12–28% lead oxide, changing its optical characteristics and reducing the transmission of ionizing radiation. Lead-based semiconductors such as lead telluride and lead selenide are used in photovoltaic cells and infrared detectors.

Lead has no confirmed biological role, and there is no confirmed safe level of lead exposure. A 2009 Canadian–American study concluded that even at levels that are considered to pose little to no risk, lead may cause "adverse mental health outcomes". Its prevalence in the human body—at an adult average of 120 mg—is nevertheless exceeded only by zinc (2500 mg) and iron (4000 mg) among the heavy metals. Lead salts are very efficiently absorbed by the body. A small amount of lead (1%) is stored in bones; the rest is excreted in urine and feces within a few weeks of exposure. Only about a third of lead is excreted by a child. Continual exposure may result in the bioaccumulation of lead.

Lead is a highly poisonous metal (whether inhaled or swallowed), affecting almost every organ and system in the human body. At airborne levels of 100 mg/m, it is immediately dangerous to life and health. Most ingested lead is absorbed into the bloodstream. The primary cause of its toxicity is its predilection for interfering with the proper functioning of enzymes. It does so by binding to the sulfhydryl groups found on many enzymes, or mimicking and displacing other metals which act as cofactors in many enzymatic reactions. Among the essential metals that lead interacts with are calcium, iron, and zinc. High levels of calcium and iron tend to provide some protection from lead poisoning; low levels cause increased susceptibility.

Lead can cause severe damage to the brain and kidneys and, ultimately, death. By mimicking calcium, lead can cross the blood–brain barrier. It degrades the myelin sheaths of neurons, reduces their numbers, interferes with neurotransmission routes, and decreases neuronal growth. In the human body, lead inhibits porphobilinogen synthase and ferrochelatase, preventing both porphobilinogen formation and the incorporation of iron into protoporphyrin IX, the final step in heme synthesis. This causes ineffective heme synthesis and microcytic anemia.

Symptoms of lead poisoning include nephropathy, colic-like abdominal pains, and possibly weakness in the fingers, wrists, or ankles. Small blood pressure increases, particularly in middle-aged and older people, may be apparent and can cause anemia. Several studies, mostly cross-sectional, found an association between increased lead exposure and decreased heart rate variability. In pregnant women, high levels of exposure to lead may cause miscarriage. Chronic, high-level exposure has been shown to reduce fertility in males.

In a child's developing brain, lead interferes with synapse formation in the cerebral cortex, neurochemical development (including that of neurotransmitters), and the organization of ion channels. Early childhood exposure has been linked with an increased risk of sleep disturbances and excessive daytime drowsiness in later childhood. High blood levels are associated with delayed puberty in girls. The rise and fall in exposure to airborne lead from the combustion of tetraethyl lead in gasoline during the 20th century has been linked with historical increases and decreases in crime levels, a hypothesis which is not universally accepted.

Lead exposure is a global issue since lead mining and smelting, and battery manufacturing/disposal/recycling, are common in many countries. Lead enters the body via inhalation, ingestion, or skin absorption. Almost all inhaled lead is absorbed into the body; for ingestion, the rate is 20–70%, with children absorbing a higher percentage than adults.

Poisoning typically results from ingestion of food or water contaminated with lead, and less commonly after accidental ingestion of contaminated soil, dust, or lead-based paint. Seawater products can contain lead if affected by nearby industrial waters. Fruit and vegetables can be contaminated by high levels of lead in the soils they were grown in. Soil can be contaminated through particulate accumulation from lead in pipes, lead paint, and residual emissions from leaded gasoline.

The use of lead for water pipes is problematic in areas with soft or acidic water. Hard water forms insoluble layers in the pipes whereas soft and acidic water dissolves the lead pipes. Dissolved carbon dioxide in the carried water may result in the formation of soluble lead bicarbonate; oxygenated water may similarly dissolve lead as lead(II) hydroxide. Drinking such water, over time, can cause health problems due to the toxicity of the dissolved lead. The harder the water the more calcium bicarbonate and sulfate it will contain, and the more the inside of the pipes will be coated with a protective layer of lead carbonate or lead sulfate.

Ingestion of applied lead-based paint is the major source of exposure for children:
a direct source is chewing on old painted window sills. Alternatively, as the applied dry paint deteriorates, it peels, is pulverized into dust and then enters the body through hand-to-mouth contact or contaminated food, water, or alcohol. Ingesting certain home remedies may result in exposure to lead or its compounds.

Inhalation is the second major exposure pathway, affecting smokers and especially workers in lead-related occupations. Cigarette smoke contains, among other toxic substances, radioactive lead-210.

Skin exposure may be significant for people working with organic lead compounds. The rate of skin absorption is lower for inorganic lead.

Treatment for lead poisoning normally involves the administration of dimercaprol and succimer. Acute cases may require the use of disodium calcium edetate, the calcium chelate, and the disodium salt of ethylenediaminetetraacetic acid (EDTA). It has a greater affinity for lead than calcium, with the result that lead chelate is formed by exchange and excreted in the urine, leaving behind harmless calcium.

The extraction, production, use, and disposal of lead and its products have caused significant contamination of the Earth's soils and waters. Atmospheric emissions of lead were at their peak during the Industrial Revolution, and the leaded gasoline period in the second half of the twentieth century. Lead releases originate from natural sources (i.e., concentration of the naturally occurring lead), industrial production, incineration and recycling, and mobilization of previously buried lead. Elevated concentrations of lead persist in soils and sediments in post-industrial and urban areas; industrial emissions, including those arising from coal burning, continue in many parts of the world, particularly in the developing countries.

Lead can accumulate in soils, especially those with a high organic content, where it remains for hundreds to thousands of years. Environmental lead can compete with other metals found in and on plants surfaces potentially inhibiting photosynthesis and at high enough concentrations, negatively affecting plant growth and survival. Contamination of soils and plants can allow lead to ascend the food chain affecting microorganisms and animals. In animals, lead exhibits toxicity in many organs, damaging the nervous, renal, reproductive, hematopoietic, and cardiovascular systems after ingestion, inhalation, or skin absorption. Fish uptake lead from both water and sediment; bioaccumulation in the food chain poses a hazard to fish, birds, and sea mammals.

Anthropogenic lead includes lead from shot and sinkers. These are among the most potent sources of lead contamination along with lead production sites. Lead was banned for shot and sinkers in the United States in 2017, although that ban was only effective for a month, and a similar ban is being considered in the European Union.

Analytical methods for the determination of lead in the environment include spectrophotometry, X-ray fluorescence, atomic spectroscopy and electrochemical methods. A specific ion-selective electrode has been developed based on the ionophore S,S'-methylenebis(N,N-diisobutyldithiocarbamate). An important biomarker assay for lead poisoning is δ-aminolevulinic acid levels in plasma, serum, and urine.

By the mid-1980s, there was significant decline in the use of lead in industry. In the United States, environmental regulations reduced or eliminated the use of lead in non-battery products, including gasoline, paints, solders, and water systems. Particulate control devices were installed in coal-fired power plants to capture lead emissions. In 1992, U.S. Congress required the Environmental Protection Agency to reduce the blood lead levels of the country's children. Lead use was further curtailed by the European Union's 2003 Restriction of Hazardous Substances Directive. A large drop in lead deposition occurred in the Netherlands after the 1993 national ban on use of lead shot for hunting and sport shooting: from 230 tonnes in 1990 to 47.5 tonnes in 1995.

In the United States, the permissible exposure limit for lead in the workplace, comprising metallic lead, inorganic lead compounds, and lead soaps, was set at 50 μg/m over an 8-hour workday, and the blood lead level limit at 5 μg per 100 g of blood in 2012. Lead may still be found in harmful quantities in stoneware, vinyl (such as that used for tubing and the insulation of electrical cords), and Chinese brass. Old houses may still contain lead paint. White lead paint has been withdrawn from sale in industrialized countries, but specialized uses of other pigments such as yellow lead chromate remain. Stripping old paint by sanding produces dust which can be inhaled. Lead abatement programs have been mandated by some authorities in properties where young children live.

Lead waste, depending on the jurisdiction and the nature of the waste, may be treated as household waste (in order to facilitate lead abatement activities), or potentially hazardous waste requiring specialized treatment or storage. Lead is released to the wildlife in shooting places and a number of lead management practices, such as stewardship of the environment and reduced public scrutiny, have been developed to counter the lead contamination. Lead migration can be enhanced in acidic soils; to counter that, it is advised soils be treated with lime to neutralize the soils and prevent leaching of lead.

Research has been conducted on how to remove lead from biosystems by biological means: Fish bones are being researched for their ability to bioremediate lead in contaminated soil. The fungus "Aspergillus versicolor" is effective at absorbing lead ions from industrial waste before being released to water bodies. Several bacteria have been researched for their ability to remove lead from the environment, including the sulfate-reducing bacteria "Desulfovibrio" and "Desulfotomaculum", both of which are highly effective in aqueous solutions.






</doc>
<doc id="17860" url="https://en.wikipedia.org/wiki?curid=17860" title="Logarithm">
Logarithm

In mathematics, the logarithm is the inverse function to exponentiation. That means the logarithm of a given number  is the exponent to which another fixed number, the "base" , must be raised, to produce that number . In the simplest case, the logarithm counts repeated multiplication of the same factor; e.g., since , the "logarithm to base " of is . The logarithm of to "base" is denoted as (or, without parentheses, as , or even without explicit base as , when no confusion is possible). More generally, exponentiation allows any positive real number to be raised to any real power, always producing a positive result, so the logarithm for any two positive real numbers  and  where  is not equal to , is always a unique real number . More explicitly, the defining relation between exponentiation and logarithm is:

For example, , as .

The logarithm to base (that is ) is called the common logarithm and has many applications in science and engineering. The natural logarithm has the number (that is ) as its base; its use is widespread in mathematics and physics, because of its simpler derivative. The binary logarithm uses base (that is ) and is commonly used in computer science.

Logarithms were introduced by John Napier in the early 17th century as a means to simplify calculations. They were rapidly adopted by navigators, scientists, engineers, and others to perform computations more easily, using slide rules and logarithm tables. Tedious multi-digit multiplication steps can be replaced by table look-ups and simpler addition because of the fact—important in its own right—that the logarithm of a product is the sum of the logarithms of the factors:
provided that , and are all positive and .
The present-day notion of logarithms comes from Leonhard Euler, who connected them to the exponential function in the 18th century.

Logarithmic scales reduce wide-ranging quantities to tiny scopes. For example, the decibel (dB) is a unit used to express ratio as logarithms, mostly for signal power and amplitude (of which sound pressure is a common example). In chemistry, pH is a logarithmic measure for the acidity of an aqueous solution. Logarithms are commonplace in scientific formulae, and in measurements of the complexity of algorithms and of geometric objects called fractals. They help describing frequency ratios of musical intervals, appear in formulas counting prime numbers or approximating factorials, inform some models in psychophysics, and can aid in forensic accounting.

In the same way as the logarithm reverses exponentiation, the complex logarithm is the inverse function of the exponential function applied to complex numbers. The discrete logarithm is another variant; it has uses in public-key cryptography.

Addition, multiplication, and exponentiation are three fundamental arithmetic operations. Addition, the simplest of these, can be undone by subtraction: adding, say, 2 to 3 gives 5. The process of adding 2 can be undone by subtracting 2: 5 − 2 = 3. Multiplication, the next-simplest operation, can be undone by division: doubling a number , i.e., multiplying "x" by 2, the result is . To get back , it is necessary to divide by 2. For example formula_4 and the process of multiplying by 2 is undone by dividing by 2: formula_5. The idea and purpose of logarithms is also to undo a fundamental arithmetic operation, namely raising a number to a certain power, an operation also known as exponentiation. For example, raising 2 to the third power yields 8, because 8 is the product of three factors of 2:

The logarithm (with respect to base 2) of 8 is 3, reflecting the fact that 2 was raised to the "third" power to get 8.

This subsection contains a short overview of the exponentiation operation, which is fundamental to understanding logarithms.
Raising to the power, where is a natural number, is done by multiplying factors equal to . The power of is written , so that

Exponentiation may be extended to , where is a positive number and the "exponent" is any real number. For example, is the reciprocal of , that is, . Raising "b" to the power 1/2 is the square root of "b". More generally, raising "b" to a rational power "p"/"q", where "p" and "q" are integers, is given by
the "q"-th root of "b". Finally, any irrational number (a real number which is not rational) "y" can be approximated to arbitrary precision by rational numbers. This can be used to compute the "y"-th power of "b": for example formula_9 and formula_10 is increasingly well approximated by formula_11. A more detailed explanation, as well as the formula is contained in the article on exponentiation.

The "logarithm" of a positive real number with respect to base is the exponent by which must be raised to yield . In other words, the logarithm of to base is the solution to the equation

The logarithm is denoted "" (pronounced as "the logarithm of to base " or "the logarithm of " or (most commonly) "the log, base , of ").

In the equation , the value is the answer to the question "To what power must be raised, in order to yield ?".


Several important formulas, sometimes called "logarithmic identities" or "logarithmic laws", relate logarithms to one another.

The logarithm of a product is the sum of the logarithms of the numbers being multiplied; the logarithm of the ratio of two numbers is the difference of the logarithms. The logarithm of the power of a number is "p" times the logarithm of the number itself; the logarithm of a root is the logarithm of the number divided by "p". The following table lists these identities with examples. Each of the identities can be derived after substitution of the logarithm definitions formula_15 or formula_16 in the left hand sides.

The logarithm can be computed from the logarithms of and with respect to an arbitrary base "k" using the following formula:
Starting from the defining identity

we can apply to both sides of this equation, to get

Solving for formula_20 yields:

showing the conversion factor from given formula_22-values to their corresponding formula_23-values to be formula_24
Typical scientific calculators calculate the logarithms to bases 10 and . Logarithms with respect to any base can be determined using either of these two logarithms by the previous formula:
Given a number and its logarithm to an unknown base , the base is given by:

Among all choices for the base, three are particularly common. These are , (the irrational mathematical constant ≈ 2.71828), and (the binary logarithm). In mathematical analysis, the logarithm to base is widespread because of its particular analytical properties explained below. On the other hand, logarithms are easy to use for manual calculations in the decimal number system:
Thus, is related to the number of decimal digits of a positive integer : the number of digits is the smallest integer strictly bigger than log"x". For example, is approximately 3.15. The next integer is 4, which is the number of digits of 1430. Both the natural logarithm and the logarithm to base two are used in information theory, corresponding to the use of nats or bits as the fundamental units of information, respectively. Binary logarithms are also used in computer science, where the binary system is ubiquitous, in music theory, where a pitch ratio of two (the octave) is ubiquitous and the cent is the binary logarithm (scaled by 1200) of the ratio between two adjacent equally-tempered pitches in European classical music, and in photography to measure exposure values.

The following table lists common notations for logarithms to these bases and the fields where they are used. Many disciplines write instead of , when the intended base can be determined from the context. The notation also occurs. The "ISO notation" column lists designations suggested by the International Organization for Standardization (ISO 31-11). Because the notation has been used for all three bases (or when the base is indeterminate or immaterial), the intended base must often be inferred based on context or discipline. In computer science and mathematics, log usually refers to and , respectively. In other contexts log often means .

The history of logarithm in seventeenth-century Europe is the discovery of a new function that extended the realm of analysis beyond the scope of algebraic methods. The method of logarithms was publicly propounded by John Napier in 1614, in a book titled "Mirifici Logarithmorum Canonis Descriptio" ("Description of the Wonderful Rule of Logarithms"). Prior to Napier's invention, there had been other techniques of similar scopes, such as the prosthaphaeresis or the use of tables of progressions, extensively developed by Jost Bürgi around 1600.

The common logarithm of a number is the index of that power of ten which equals the number. Speaking of a number as requiring so many figures is a rough allusion to common logarithm, and was referred to by Archimedes as the "order of a number". The first real logarithms were heuristic methods to turn multiplication into addition, thus facilitating rapid computation. Some of these methods used tables derived from trigonometric identities.
Such methods are called prosthaphaeresis.

Invention of the function now known as natural logarithm began as an attempt to perform a quadrature of a rectangular hyperbola by Grégoire de Saint-Vincent, a Belgian Jesuit residing in Prague. Archimedes had written "The Quadrature of the Parabola" in the third century BC, but a quadrature for the hyperbola eluded all efforts until Saint-Vincent published his results in 1647. The relation that the logarithm provides between a geometric progression in its argument and an arithmetic progression of values, prompted A. A. de Sarasa to make the connection of Saint-Vincent’s quadrature and the tradition of logarithms in prosthaphaeresis, leading to the term "hyperbolic logarithm", a synonym for natural logarithm. Soon the new function was appreciated by Christiaan Huygens, Patavii, and James Gregory. The notation Log y was adopted by Leibniz in 1675, and the next year he connected it to the integral
formula_30

By simplifying difficult calculations, logarithms contributed to the advance of science, especially astronomy. They were critical to advances in surveying, celestial navigation, and other domains. Pierre-Simon Laplace called logarithms

A key tool that enabled the practical use of logarithms before calculators and computers was the "table of logarithms". The first such table was compiled by Henry Briggs in 1617, immediately after Napier's invention. Subsequently, tables with increasing scope were written. These tables listed the values of and for any number in a certain range, at a certain precision, for a certain base (usually ). For example, Briggs' first table contained the common logarithms of all integers in the range 1–1000, with a precision of 14 digits. As the function is the inverse function of log"x", it has been called the antilogarithm. The product and quotient of two positive numbers "c" and "d" were routinely calculated as the sum and difference of their logarithms. The product "cd" or quotient "c"/"d" came from looking up the antilogarithm of the sum or difference, also via the same table:
and

For manual calculations that demand any appreciable precision, performing the lookups of the two logarithms, calculating their sum or difference, and looking up the antilogarithm is much faster than performing the multiplication by earlier methods such as prosthaphaeresis, which relies on trigonometric identities. Calculations of powers and roots are reduced to multiplications or divisions and look-ups by

and

Many logarithm tables give logarithms by separately providing the characteristic and mantissa of , that is to say, the integer part and the fractional part of . The characteristic of is one plus the characteristic of , and their significands are the same. This extends the scope of logarithm tables: given a table listing for all integers ranging from 1 to 1000, the logarithm of 3542 is approximated by

Another critical application was the slide rule, a pair of logarithmically divided scales used for calculation. The non-sliding logarithmic scale, Gunter's rule, was invented shortly after Napier's invention. William Oughtred enhanced it to create the slide rule—a pair of logarithmic scales movable with respect to each other. Numbers are placed on sliding scales at distances proportional to the differences between their logarithms. Sliding the upper scale appropriately amounts to mechanically adding logarithms, as illustrated here:

For example, adding the distance from 1 to 2 on the lower scale to the distance from 1 to 3 on the upper scale yields a product of 6, which is read off at the lower part. The slide rule was an essential calculating tool for engineers and scientists until the 1970s, because it allows, at the expense of precision, much faster computation than techniques based on tables.

A deeper study of logarithms requires the concept of a "function". A function is a rule that, given one number, produces another number. An example is the function producing the power of from any real number , where the base is a fixed number. This function is written: formula_36

To justify the definition of logarithms, it is necessary to show that the equation
has a solution and that this solution is unique, provided that is positive and that is positive and unequal to 1. A proof of that fact requires the intermediate value theorem from elementary calculus. This theorem states that a continuous function that produces two values "m" and "n" also produces any value that lies between "m" and "n". A function is "continuous" if it does not "jump", that is, if its graph can be drawn without lifting the pen.

This property can be shown to hold for the function . Because "f" takes arbitrarily large and arbitrarily small positive values, any number lies between and for suitable and . Hence, the intermediate value theorem ensures that the equation has a solution. Moreover, there is only one solution to this equation, because the function "f" is strictly increasing (for ), or strictly decreasing (for ).

The unique solution is the logarithm of to base , . The function that assigns to its logarithm is called "logarithm function" or "logarithmic function" (or just "logarithm").

The function is essentially characterized by the above product formula
More precisely, the logarithm to any base is the only increasing function "f" from the positive reals to the reals satisfying and 

The formula for the logarithm of a power says in particular that for any number ,
In prose, taking the power of and then the logarithm gives back . Conversely, given a positive number , the formula
says that first taking the logarithm and then exponentiating gives back . Thus, the two possible ways of combining (or composing) logarithms and exponentiation give back the original number. Therefore, the logarithm to base is the "inverse function" of .

Inverse functions are closely related to the original functions. Their graphs correspond to each other upon exchanging the - and the -coordinates (or upon reflection at the diagonal line = ), as shown at the right: a point on the graph of "f" yields a point on the graph of the logarithm and vice versa. As a consequence, log("x") diverges to infinity (gets bigger than any given number) if grows to infinity, provided that is greater than one. In that case, is an increasing function. For , tends to minus infinity instead. When approaches zero, goes to minus infinity for (plus infinity for , respectively).

Analytic properties of functions pass to their inverses. Thus, as is a continuous and differentiable function, so is . Roughly, a continuous function is differentiable if its graph has no sharp "corners". Moreover, as the derivative of evaluates to by the properties of the exponential function, the chain rule implies that the derivative of is given by
That is, the slope of the tangent touching the graph of the logarithm at the point equals .

The derivative of ln is 1/"x"; this implies that ln is the unique antiderivative of that has the value 0 for . It is this very simple formula that motivated to qualify as "natural" the natural logarithm; this is also one of the main reasons of the importance of the constant .

The derivative with a generalised functional argument is
The quotient at the right hand side is called the logarithmic derivative of "f". Computing by means of the derivative of is known as logarithmic differentiation. The antiderivative of the natural logarithm is:
Related formulas, such as antiderivatives of logarithms to other bases can be derived from this equation using the change of bases.

The natural logarithm of "t" equals the integral of 1/"x" "dx" from 1 to "t":
In other words, equals the area between the axis and the graph of the function , ranging from to (figure at the right). This is a consequence of the fundamental theorem of calculus and the fact that the derivative of is . The right hand side of this equation can serve as a definition of the natural logarithm. Product and power logarithm formulas can be derived from this definition. For example, the product formula is deduced as:

The equality (1) splits the integral into two parts, while the equality (2) is a change of variable (). In the illustration below, the splitting corresponds to dividing the area into the yellow and blue parts. Rescaling the left hand blue area vertically by the factor "t" and shrinking it by the same factor horizontally does not change its size. Moving it appropriately, the area fits the graph of the function again. Therefore, the left hand blue area, which is the integral of from "t" to "tu" is the same as the integral from 1 to "u". This justifies the equality (2) with a more geometric proof.

The power formula may be derived in a similar way:

The second equality uses a change of variables (integration by substitution), .

The sum over the reciprocals of natural numbers,
is called the harmonic series. It is closely tied to the natural logarithm: as "n" tends to infinity, the difference,
converges (i.e., gets arbitrarily close) to a number known as the Euler–Mascheroni constant . This relation aids in analyzing the performance of algorithms such as quicksort.

There are also some other integral representations of the logarithm that are useful in some situations:

The first identity can be verified by showing that it has the same value at , and the same derivative.
The second identity can be proven by writing
and then inserting the Laplace transform of (and ).

Real numbers that are not algebraic are called transcendental; for example, and "e" are such numbers, but formula_53 is not. Almost all real numbers are transcendental. The logarithm is an example of a transcendental function. The Gelfond–Schneider theorem asserts that logarithms usually take transcendental, i.e., "difficult" values.

Logarithms are easy to compute in some cases, such as . In general, logarithms can be calculated using power series or the arithmetic–geometric mean, or be retrieved from a precalculated logarithm table that provides a fixed precision.
Newton's method, an iterative method to solve equations approximately, can also be used to calculate the logarithm, because its inverse function, the exponential function, can be computed efficiently. Using look-up tables, CORDIC-like methods can be used to compute logarithms if the only available operations are addition and bit shifts. Moreover, the binary logarithm algorithm calculates recursively based on repeated squarings of , taking advantage of the relation

For any real number that satisfies , the following formula holds:
This is a shorthand for saying that can be approximated to a more and more accurate value by the following expressions:
For example, with the third approximation yields 0.4167, which is about 0.011 greater than . This series approximates with arbitrary precision, provided the number of summands is large enough. In elementary calculus, is therefore the limit of this series. It is the Taylor series of the natural logarithm at . The Taylor series of provides a particularly useful approximation to when is small, , since then
For example, with the first-order approximation gives , which is less than 5% off the correct value 0.0953.

Another series is based on the area hyperbolic tangent function:
for any real number . Using sigma notation, this is also written as
This series can be derived from the above Taylor series. It converges more quickly than the Taylor series, especially if is close to 1. For example, for , the first three terms of the second series approximate with an error of about . The quick convergence for close to 1 can be taken advantage of in the following way: given a low-accuracy approximation and putting
the logarithm of is:
The better the initial approximation is, the closer is to 1, so its logarithm can be calculated efficiently. can be calculated using the exponential series, which converges quickly provided is not too large. Calculating the logarithm of larger can be reduced to smaller values of by writing , so that .

A closely related method can be used to compute the logarithm of integers. Putting formula_62 in the above series, it follows that:
If the logarithm of a large integer is known, then this series yields a fast converging series for , with a rate of convergence of formula_64.

The arithmetic–geometric mean yields high precision approximations of the natural logarithm. Sasaki and Kanada showed in 1982 that it was particularly fast for precisions between 400 and 1000 decimal places, while Taylor series methods were typically faster when less precision was needed. In their work is approximated to a precision of (or "p" precise bits) by the following formula (due to Carl Friedrich Gauss):

Here denotes the arithmetic–geometric mean of and . It is obtained by repeatedly calculating the average (arithmetic mean) and formula_66 (geometric mean) of and then let those two numbers become the next and . The two numbers quickly converge to a common limit which is the value of . "m" is chosen such that

to ensure the required precision. A larger "m" makes the calculation take more steps (the initial x and y are farther apart so it takes more steps to converge) but gives more precision. The constants and can be calculated with quickly converging series.

While at Los Alamos National Laboratory working on the Manhattan Project, Richard Feynman developed a bit processing algorithm that is similar to long division and was later used in the Connection Machine. The algorithm uses the fact that every real number formula_68 is uniquely representable as a product of distinct factors of the form formula_69. The algorithm sequentially builds that product formula_70: if formula_71, then it changes formula_70 to formula_73. It then increase formula_74 by one regardless. The algorithm stops when formula_74 is large enough to give the desired accuracy. Because formula_76 is the sum of the terms of the form formula_77 corresponding to those formula_74 for which the factor formula_79 was included in the product formula_70, formula_76 may be computed by simple addition, using a table of formula_77 for all formula_74. Any base may be used for the logarithm table.

Logarithms have many applications inside and outside mathematics. Some of these occurrences are related to the notion of scale invariance. For example, each chamber of the shell of a nautilus is an approximate copy of the next one, scaled by a constant factor. This gives rise to a logarithmic spiral. Benford's law on the distribution of leading digits can also be explained by scale invariance. Logarithms are also linked to self-similarity. For example, logarithms appear in the analysis of algorithms that solve a problem by dividing it into two similar smaller problems and patching their solutions. The dimensions of self-similar geometric shapes, that is, shapes whose parts resemble the overall picture are also based on logarithms.
Logarithmic scales are useful for quantifying the relative change of a value as opposed to its absolute difference. Moreover, because the logarithmic function grows very slowly for large , logarithmic scales are used to compress large-scale scientific data. Logarithms also occur in numerous scientific formulas, such as the Tsiolkovsky rocket equation, the Fenske equation, or the Nernst equation.

Scientific quantities are often expressed as logarithms of other quantities, using a "logarithmic scale". For example, the decibel is a unit of measurement associated with logarithmic-scale quantities. It is based on the common logarithm of ratios—10 times the common logarithm of a power ratio or 20 times the common logarithm of a voltage ratio. It is used to quantify the loss of voltage levels in transmitting electrical signals, to describe power levels of sounds in acoustics, and the absorbance of light in the fields of spectrometry and optics. The signal-to-noise ratio describing the amount of unwanted noise in relation to a (meaningful) signal is also measured in decibels. In a similar vein, the peak signal-to-noise ratio is commonly used to assess the quality of sound and image compression methods using the logarithm.

The strength of an earthquake is measured by taking the common logarithm of the energy emitted at the quake. This is used in the moment magnitude scale or the Richter magnitude scale. For example, a 5.0 earthquake releases 32 times and a 6.0 releases 1000 times the energy of a 4.0. Another logarithmic scale is apparent magnitude. It measures the brightness of stars logarithmically. Yet another example is pH in chemistry; pH is the negative of the common logarithm of the activity of hydronium ions (the form hydrogen ions take in water). The activity of hydronium ions in neutral water is 10 mol·L, hence a pH of 7. Vinegar typically has a pH of about 3. The difference of 4 corresponds to a ratio of 10 of the activity, that is, vinegar's hydronium ion activity is about .

Semilog (log-linear) graphs use the logarithmic scale concept for visualization: one axis, typically the vertical one, is scaled logarithmically. For example, the chart at the right compresses the steep increase from 1 million to 1 trillion to the same space (on the vertical axis) as the increase from 1 to 1 million. In such graphs, exponential functions of the form appear as straight lines with slope equal to the logarithm of .
Log-log graphs scale both axes logarithmically, which causes functions of the form to be depicted as straight lines with slope equal to the exponent "k". This is applied in visualizing and analyzing power laws.

Logarithms occur in several laws describing human perception:
Hick's law proposes a logarithmic relation between the time individuals take to choose an alternative and the number of choices they have. Fitts's law predicts that the time required to rapidly move to a target area is a logarithmic function of the distance to and the size of the target. In psychophysics, the Weber–Fechner law proposes a logarithmic relationship between stimulus and sensation such as the actual vs. the perceived weight of an item a person is carrying. (This "law", however, is less realistic than more recent models, such as Stevens's power law.)

Psychological studies found that individuals with little mathematics education tend to estimate quantities logarithmically, that is, they position a number on an unmarked line according to its logarithm, so that 10 is positioned as close to 100 as 100 is to 1000. Increasing education shifts this to a linear estimate (positioning 1000 10x as far away) in some circumstances, while logarithms are used when the numbers to be plotted are difficult to plot linearly.

Logarithms arise in probability theory: the law of large numbers dictates that, for a fair coin, as the number of coin-tosses increases to infinity, the observed proportion of heads approaches one-half. The fluctuations of this proportion about one-half are described by the law of the iterated logarithm.

Logarithms also occur in log-normal distributions. When the logarithm of a random variable has a normal distribution, the variable is said to have a log-normal distribution. Log-normal distributions are encountered in many fields, wherever a variable is formed as the product of many independent positive random variables, for example in the study of turbulence.

Logarithms are used for maximum-likelihood estimation of parametric statistical models. For such a model, the likelihood function depends on at least one parameter that must be estimated. A maximum of the likelihood function occurs at the same parameter-value as a maximum of the logarithm of the likelihood (the ""log likelihood""), because the logarithm is an increasing function. The log-likelihood is easier to maximize, especially for the multiplied likelihoods for independent random variables.

Benford's law describes the occurrence of digits in many data sets, such as heights of buildings. According to Benford's law, the probability that the first decimal-digit of an item in the data sample is "d" (from 1 to 9) equals , "regardless" of the unit of measurement. Thus, about 30% of the data can be expected to have 1 as first digit, 18% start with 2, etc. Auditors examine deviations from Benford's law to detect fraudulent accounting.

Analysis of algorithms is a branch of computer science that studies the performance of algorithms (computer programs solving a certain problem). Logarithms are valuable for describing algorithms that divide a problem into smaller ones, and join the solutions of the subproblems.

For example, to find a number in a sorted list, the binary search algorithm checks the middle entry and proceeds with the half before or after the middle entry if the number is still not found. This algorithm requires, on average, comparisons, where "N" is the list's length. Similarly, the merge sort algorithm sorts an unsorted list by dividing the list into halves and sorting these first before merging the results. Merge sort algorithms typically require a time approximately proportional to . The base of the logarithm is not specified here, because the result only changes by a constant factor when another base is used. A constant factor is usually disregarded in the analysis of algorithms under the standard uniform cost model.

A function is said to grow logarithmically if is (exactly or approximately) proportional to the logarithm of . (Biological descriptions of organism growth, however, use this term for an exponential function.) For example, any natural number "N" can be represented in binary form in no more than bits. In other words, the amount of memory needed to store "N" grows logarithmically with "N".

Entropy is broadly a measure of the disorder of some system. In statistical thermodynamics, the entropy "S" of some physical system is defined as
The sum is over all possible states "i" of the system in question, such as the positions of gas particles in a container. Moreover, is the probability that the state "i" is attained and "k" is the Boltzmann constant. Similarly, entropy in information theory measures the quantity of information. If a message recipient may expect any one of "N" possible messages with equal likelihood, then the amount of information conveyed by any one such message is quantified as bits.

Lyapunov exponents use logarithms to gauge the degree of chaoticity of a dynamical system. For example, for a particle moving on an oval billiard table, even small changes of the initial conditions result in very different paths of the particle. Such systems are chaotic in a deterministic way, because small measurement errors of the initial state predictably lead to largely different final states. At least one Lyapunov exponent of a deterministically chaotic system is positive.

Logarithms occur in definitions of the dimension of fractals. Fractals are geometric objects that are self-similar: small parts reproduce, at least roughly, the entire global structure. The Sierpinski triangle (pictured) can be covered by three copies of itself, each having sides half the original length. This makes the Hausdorff dimension of this structure . Another logarithm-based notion of dimension is obtained by counting the number of boxes needed to cover the fractal in question.

Logarithms are related to musical tones and intervals. In equal temperament, the frequency ratio depends only on the interval between two tones, not on the specific frequency, or pitch, of the individual tones. For example, the note "A" has a frequency of 440 Hz and "B-flat" has a frequency of 466 Hz. The interval between "A" and "B-flat" is a semitone, as is the one between "B-flat" and "B" (frequency 493 Hz). Accordingly, the frequency ratios agree:
Therefore, logarithms can be used to describe the intervals: an interval is measured in semitones by taking the logarithm of the frequency ratio, while the logarithm of the frequency ratio expresses the interval in cents, hundredths of a semitone. The latter is used for finer encoding, as it is needed for non-equal temperaments.

Natural logarithms are closely linked to counting prime numbers (2, 3, 5, 7, 11, ...), an important topic in number theory. For any integer , the quantity of prime numbers less than or equal to is denoted . The prime number theorem asserts that is approximately given by
in the sense that the ratio of and that fraction approaches 1 when tends to infinity. As a consequence, the probability that a randomly chosen number between 1 and is prime is inversely proportional to the number of decimal digits of . A far better estimate of is given by the
offset logarithmic integral function , defined by
The Riemann hypothesis, one of the oldest open mathematical conjectures, can be stated in terms of comparing and . The Erdős–Kac theorem describing the number of distinct prime factors also involves the natural logarithm.

The logarithm of "n" factorial, , is given by
This can be used to obtain Stirling's formula, an approximation of for large "n".

All the complex numbers that solve the equation

are called "complex logarithms" of , when is (considered as) a complex number. A complex number is commonly represented as , where and are real numbers and is an imaginary unit, the square of which is −1. Such a number can be visualized by a point in the complex plane, as shown at the right. The polar form encodes a non-zero complex number by its absolute value, that is, the (positive, real) distance to the origin, and an angle between the real () axis "Re" and the line passing through both the origin and . This angle is called the argument of .

The absolute value of is given by

Using the geometrical interpretation of formula_91 and formula_92 and their periodicity in formula_93 any complex number may be denoted as

for any integer number . Evidently the argument of is not uniquely specified: both and ' = + 2"k" are valid arguments of for all integers , because adding 2"k" radian or "k"⋅360° to corresponds to "winding" around the origin counter-clock-wise by turns. The resulting complex number is always , as illustrated at the right for . One may select exactly one of the possible arguments of as the so-called "principal argument", denoted , with a capital , by requiring to belong to one, conveniently selected turn, e.g., formula_95 or formula_96 These regions, where the argument of is uniquely determined are called "branches" of the argument function.

Euler's formula connects the trigonometric functions sine and cosine to the complex exponential:

Using this formula, and again the periodicity, the following identities hold:

where is the unique real natural logarithm, denote the complex logarithms of , and is an arbitrary integer. Therefore, the complex logarithms of , which are all those complex values for which the power of equals , are the infinitely many values

Taking such that formula_100 is within the defined interval for the principal arguments, then is called the "principal value" of the logarithm, denoted , again with a capital . The principal argument of any positive real number is 0; hence is a real number and equals the real (natural) logarithm. However, the above formulas for logarithms of products and powers do "not" generalize to the principal value of the complex logarithm.

The illustration at the right depicts , confining the arguments of to the interval . This way the corresponding branch of the complex logarithm has discontinuities all along the negative real axis, which can be seen in the jump in the hue there. This discontinuity arises from jumping to the other boundary in the same branch, when crossing a boundary, i.e., not changing to the corresponding -value of the continuously neighboring branch. Such a locus is called a branch cut. Dropping the range restrictions on the argument makes the relations "argument of ", and consequently the "logarithm of ", multi-valued functions.

Exponentiation occurs in many areas of mathematics and its inverse function is often referred to as the logarithm. For example, the logarithm of a matrix is the (multi-valued) inverse function of the matrix exponential. Another example is the "p"-adic logarithm, the inverse function of the "p"-adic exponential. Both are defined via Taylor series analogous to the real case. In the context of differential geometry, the exponential map maps the tangent space at a point of a manifold to a neighborhood of that point. Its inverse is also called the logarithmic (or log) map.

In the context of finite groups exponentiation is given by repeatedly multiplying one group element with itself. The discrete logarithm is the integer "n" solving the equation
where is an element of the group. Carrying out the exponentiation can be done efficiently, but the discrete logarithm is believed to be very hard to calculate in some groups. This asymmetry has important applications in public key cryptography, such as for example in the Diffie–Hellman key exchange, a routine that allows secure exchanges of cryptographic keys over unsecured information channels. Zech's logarithm is related to the discrete logarithm in the multiplicative group of non-zero elements of a finite field.

Further logarithm-like inverse functions include the "double logarithm" ln(ln("x")), the "super- or hyper-4-logarithm" (a slight variation of which is called iterated logarithm in computer science), the Lambert W function, and the logit. They are the inverse functions of the double exponential function, tetration, of , and of the logistic function, respectively.

From the perspective of group theory, the identity expresses a group isomorphism between positive reals under multiplication and reals under addition. Logarithmic functions are the only continuous isomorphisms between these groups. By means of that isomorphism, the Haar measure (Lebesgue measure) "dx" on the reals corresponds to the Haar measure on the positive reals. The non-negative reals not only have a multiplication, but also have addition, and form a semiring, called the probability semiring; this is in fact a semifield. The logarithm then takes multiplication to addition (log multiplication), and takes addition to log addition (LogSumExp), giving an isomorphism of semirings between the probability semiring and the log semiring.

Logarithmic one-forms appear in complex analysis and algebraic geometry as differential forms with logarithmic poles.

The polylogarithm is the function defined by
It is related to the natural logarithm by . Moreover, equals the Riemann zeta function .




</doc>
<doc id="17862" url="https://en.wikipedia.org/wiki?curid=17862" title="L. Ron Hubbard">
L. Ron Hubbard

Lafayette Ronald Hubbard ( ; March 13, 1911 – January 24, 1986) was an American author of science fiction and fantasy stories, and the founder of the Church of Scientology. In 1950, Hubbard authored "" and established a series of organizations to promote Dianetics. In 1952, Hubbard lost the rights to Dianetics in bankruptcy proceedings, and he subsequently founded Scientology. Thereafter Hubbard oversaw the growth of the Church of Scientology into a worldwide organization. Hubbard was cited by "Smithsonian" magazine as one of the 100 most significant Americans of all time.

Born in Tilden, Nebraska in 1911, Hubbard spent much of his childhood in Helena, Montana. After his father was posted to the U.S. naval base on Guam, Hubbard traveled to Asia and the South Pacific in the late 1920s. In 1930, Hubbard enrolled at George Washington University to study civil engineering, but dropped out in his second year. He began his career as a prolific writer of pulp fiction stories and married Margaret "Polly" Grubb, who shared his interest in aviation.

Hubbard served briefly in the Marine Corps Reserve and was an officer in the Navy during World War II. He briefly commanded two ships, but was removed from command both times. The last few months of his active service were spent in a hospital, being treated for a duodenal ulcer.

During the late 1960s and early 1970s, he spent much of his time at sea on his personal fleet of ships as "Commodore" of the Sea Organization, an elite, paramilitary group of Scientologists. Some ex-members and scholars have described the Sea Org as a totalitarian organization marked by intensive surveillance and a lack of freedom. His expedition came to an end when Britain, Greece, Spain, Portugal, and Venezuela all closed their ports to his fleet.

Hubbard returned to the United States in 1975 and went into seclusion in the California desert. In 1978, a trial court in France convicted Hubbard of fraud "in absentia". In 1983 Hubbard was named as an unindicted co-conspirator in an international information infiltration and theft project called "Operation Snow White". He spent the remaining years of his life in a luxury motor home on his California property, attended to by a small group of Scientology officials including his physician. In 1986, L. Ron Hubbard died at age 74.

The Church of Scientology describes Hubbard in hagiographic terms, and he portrayed himself as a pioneering explorer, world traveler, and nuclear physicist with expertise in a wide range of disciplines, including photography, art, poetry, and philosophy. Though many of Hubbard's autobiographical statements have been found to be fictitious, the Church rejects any suggestion that its account of Hubbard's life is not historical fact. In Scientology publications, he is referred to as "Founder" and "Source" of Scientology and Dianetics.

His critics have characterized Hubbard as a mentally-unstable chronic liar.

Lafayette Ronald Hubbard was born in 1911, in Tilden, Nebraska. He was the only child of Ledora May ( Waterbury), who had trained as a teacher, and Harry Ross Hubbard, a former United States Navy officer. After moving to Kalispell, Montana, they settled in Helena in 1913. Hubbard's father rejoined the Navy in April 1917, during World War I, while his mother worked as a clerk for the state government.

During the 1920s the Hubbards repeatedly relocated around the United States and overseas. After Hubbard's father Harry rejoined the Navy, his posting aboard the USS "Oklahoma" in 1921 required the family to relocate to the ship's home ports, first San Diego, then Seattle. Hubbard was active in the Boy Scouts in Washington, D.C. and earned the rank of Eagle Scout in 1924, two weeks after his 13th birthday.

The following year, Harry Ross Hubbard was posted to Puget Sound Naval Shipyard at Bremerton, Washington. His son was enrolled at Union High School, Bremerton, and later studied at Queen Anne High School in Seattle. In 1927 Hubbard's father was sent to the U.S. Naval Station on Guam. Hubbard's mother accompanied her husband, while their child was placed in his grandparents' care in Helena, Montana to complete his schooling.

In 1927, Hubbard and his mother traveled to Guam. It consisted of a brief stop-over in a couple of Chinese ports before traveling on to Guam, where he stayed for six weeks before returning home. He recorded his impressions of the places he visited and disdained the poverty of the inhabitants of Japan and China, whom he described as "gooks" and "lazy [and] ignorant".
After his return to the United States in September 1927, Hubbard enrolled at Helena High School, where he contributed to the school paper, but earned only poor grades. He abandoned school the following May and went back west to stay with his aunt and uncle in Seattle. He joined his parents in Guam in June 1928. His mother took over his education in the hope of putting him forward for the entrance examination to the United States Naval Academy at Annapolis, Maryland.

Between October and December 1928 a number of naval families, including Hubbard's, traveled from Guam to China aboard the cargo ship . The ship stopped at Manila in the Philippines before traveling on to Qingdao (Tsingtao) in China. Hubbard and his parents made a side trip to Beijing before sailing on to Shanghai and Hong Kong, from where they returned to Guam. Back on Guam, Hubbard spent much of his time writing dozens of short stories and essays and failed the Naval Academy entrance examination.

In September 1929 Hubbard was enrolled at the Swavely Preparatory School in Manassas, Virginia, to prepare him for a second attempt at the examination. However, he was ruled out of consideration due to his near-sightedness. He was instead sent to Woodward School for Boys in Washington, D.C. to qualify for admission to George Washington University. He successfully graduated from the school in June 1930 and entered the university the following September.

On September 24, 1930, Hubbard was to the School of Engineering at George Washington University, with a stated major of civil engineering at the behest of his father. Academically, Hubbard did poorly: his transcripts show he failed many courses including atomic physics, though later in life he would claim to have been nuclear physicist. In September 1931 he was placed on probation due to grades, and again on April 23, 1932 he was issued a warning due to his grades.

During his first year, Hubbard helped organize the university Glider Club and was elected its president. 

During what would become Hubbard's final semester at GWU, he organized an ill-fated expedition to the Caribbean aboard the schooner "Doris Hamlin" commencing in June 1932. The aims of the "Caribbean Motion Picture Expedition" were stated as being to explore and film the pirate "strongholds and bivouacs of the Spanish Main" and to "collect whatever one collects for exhibits in museums". It ran into trouble even before it left Baltimore: Ten participants quit and storms blew the ship far off course to Bermuda. Eleven more members of the expedition quit there and more still left when the ship arrived at Martinique. With the expedition running critically short of money, the ship's owners ordered it to return to Baltimore. Some of its participants made legal claims against him for refunds, and Hubbard failed to return to University the following year. 

After his father volunteered him for a Red Cross relief effort following 1932 San Ciprian hurricane, on October 23, 1932 Hubbard traveled aboard the USS "Kittery" to Puerto Rico. Miller writes: "Somewhere between Norfolk, Virginia, and Port au Prince it seems that Ron decided to abandon the Red Cross". Instead, Hubbard appears to have done some work for a firm called West Indies Minerals Incorporated, accompanying a surveyor in an investigation of a small property near the town of Luquillo, Puerto Rico.

Hubbard returned from Puerto Rico to D.C. in February 1933. He struck up with a relationship with a fellow glider pilot named Margaret "Polly" Grubb. Years later, Hubbard told his associates that his guardian angel, described as a "smiling woman," protected him when he was flying gliders. The two were married on April 13. She was already pregnant when they married, but had a miscarriage shortly afterwards; a few months later, she became pregnant again. On May 7, 1934, she gave birth prematurely to a son who was named Lafayette Ronald Hubbard, Jr., whose nickname was "Nibs". Their second child, Katherine May, was born on January 15, 1936. The Hubbards lived for a while in Laytonsville, Maryland, but were chronically short of money.

Hubbard became a well-known and prolific writer for pulp fiction magazines during the 1930s. His literary career began with contributions to the George Washington University student newspaper, "The University Hatchet", as a reporter for a few months in 1931. Six of his pieces were published commercially during 1932 to 1933. The going rate for freelance writers at the time was only a cent a word, so Hubbard's total earnings from these articles would have been less than $100 (). The pulp magazine "Thrilling Adventure" became the first to publish one of his short stories, in February 1934. Over the next six years, pulp magazines published many of his short stories under a variety of pen names, including Winchester Remington Colt, Kurt von Rachen, René Lafayette, Joe Blitz and Legionnaire 148.

Although he was best known for his fantasy and science fiction stories, Hubbard wrote in a wide variety of genres, including adventure fiction, aviation, travel, mysteries, westerns and even romance. Hubbard knew and associated with writers such as Isaac Asimov, Robert A. Heinlein, L. Sprague de Camp and A. E. van Vogt. 

In the spring of 1936 they moved to Bremerton, Washington. They lived there for a time with Hubbard's aunts and grandmother before finding a place of their own at nearby South Colby. According to one of his friends at the time, Robert MacDonald Ford, the Hubbards were "in fairly dire straits for money" but sustained themselves on the income from Hubbard's writing.

His first full-length novel, "Buckskin Brigades", was published in 1937. He became a "highly idiosyncratic" writer of science fiction after being taken under the wing of editor John W. Campbell, who published many of Hubbard's short stories and also serialized a number of well-received novelettes that Hubbard wrote for Campbell's magazines "Unknown" and "Astounding Science Fiction". These included "Fear", "Final Blackout" and "Typewriter in the Sky". Science fiction newsletter Xignals reported that Hubbard wrote "over 100,000 words a month" during his peak. Martin Gardner asserted that his writing "[wa]s done at lightning speed."

He wrote the script for "The Secret of Treasure Island", a 1938 Columbia Pictures movie serial.

Hubbard spent an increasing amount of time in New York City, working out of a hotel room where his wife suspected him of carrying on affairs with other women.

Hubbard's authorship in mid-1938 of a still-unpublished manuscript called "Excalibur" is highlighted by the Church of Scientology as a key step in developing the principles of Scientology and Dianetics. The manuscript is said by Scientologists to have outlined "the basic principles of human existence" and to have been the culmination of twenty years of research into "twenty-one races and cultures including Pacific Northwest Indian tribes, Philippine Tagalogs and, as he was wont to joke, the people of the Bronx".

According to Arthur J. Cox, a contributor to John W. Campbell's "Astounding Science Fiction" magazine, Hubbard told a 1948 convention of science fiction fans that "Excalibur" inspiration came during an operation in which he "died" for eight minutes. (Gerry Armstrong, Hubbard's archivist, explains this as a dental extraction performed under nitrous oxide, a chemical known for its hallucinogenic effects):

Arthur J. Burks, the President of the American Fiction Guild, wrote that an excited Hubbard called him and said: "I want to see you right away. I have written THE book." Hubbard believed that "Excalibur" would "revolutionize everything" and that "it was somewhat more important, and would have a greater impact upon people, than the Bible." It proposed that all human behavior could be explained in terms of survival and that to understand survival was to understand life. As Hubbard biographer Jon Atack notes, "the notion that everything that exists is trying to survive became the basis of Dianetics and Scientology."

According to Burks, Hubbard "was so sure he had something 'away out and beyond' anything else that he had sent telegrams to several book publishers, telling them that he had written 'THE book' and that they were to meet him at Penn Station, and he would discuss it with them and go with whomever gave him the best offer." However, nobody bought the manuscript. Forrest J Ackerman, later Hubbard's literary agent, recalled that Hubbard told him "whoever read it either went insane or committed suicide. And he said that the last time he had shown it to a publisher in New York, he walked into the office to find out what the reaction was, the publisher called for the reader, the reader came in with the manuscript, threw it on the table and threw himself out of the skyscraper window." Hubbard's failure to sell "Excalibur" depressed him; he told his wife in an October 1938 letter: "Writing action pulp doesn't have much agreement with what I want to do because it retards my progress by demanding incessant attention and, further, actually weakens my name. So you see I've got to do something about it and at the same time strengthen the old financial position." He went on:

The manuscript later became part of Scientology mythology. An early 1950s Scientology publication offered signed "gold-bound and locked" copies for the sum of $1,500 apiece (). It warned that "four of the first fifteen people who read it went insane" and that it would be "[r]eleased only on sworn statement not to permit other readers to read it. Contains data not to be released during Mr. Hubbard's stay on earth."

Hubbard joined The Explorers Club in February 1940 on the strength of his claimed explorations in the Caribbean and survey flights in the United States. He persuaded the club to let him carry its flag on an "Alaskan Radio-Experimental Expedition" to update the U.S. Coast Pilot guide to the coastlines of Alaska and British Columbia and investigate new methods of radio position-finding. The expedition consisted of Hubbard and his wife—the children were left at South Colby—aboard his ketch "Magician".

Hubbard told "The Seattle Star" in a November 1940 letter that the expedition was plagued by problems and did not get any further than Ketchikan near the southern end of the Alaska Panhandle, far from the Aleutian Islands. "Magician's" engine broke down only two days after setting off in July 1940. The Hubbards reached Ketchikan on August 30, 1940, after many delays following repeated engine breakdowns. The "Ketchikan Chronicle" reported—making no mention of the expedition—that Hubbard's purpose in coming to Alaska "was two-fold, one to win a bet and another to gather material for a novel of Alaskan salmon fishing". Having underestimated the cost of the trip, he did not have enough money to repair the broken engine. He raised money by writing stories and contributing to the local radio station and eventually earned enough to fix the engine, making it back to Puget Sound on December 27, 1940.

After returning from Alaska, Hubbard applied to join the United States Navy. His friend Robert MacDonald Ford, by now a State Representative for Washington, sent a letter of recommendation describing Hubbard as "one of the most brilliant men I have ever known". Ford later said that Hubbard had written the letter himself: "I don't know why Ron wanted a letter. I just gave him a letter-head and said, 'Hell, you're the writer, you write it!'"

Hubbard was commissioned as a Lieutenant (junior grade) in the U.S. Naval Reserve on July 19, 1941. By November, he was posted to New York for training as an Intelligence Officer. 

On December 18, he was posted to the Philippines and set out for the posting via Australia. While in Melbourne awaiting transport to Manilla, Hubbard was sent back to the United States. US Naval Attaché reported: "This officer is not satisfactory for independent duty assignment. He is garrulous and tries to give impressions of his importance. He also seems to think he has unusual ability in most lines. These characteristics indicate that he will require close supervision for satisfactory performance of any intelligence duty."

After a brief stint censoring cables, Hubbard's request for sea duty was approved and he reported to a Neponset, Massachusetts shipyard which was converting a trawler into a gunboat to be classified as USS "YP-422". On September 25, 1942, the Commandant of Boston Navy Yard informed Washington that, in his view, Hubbard was "not temperamentally fitted for independent command." Days later, on October 1, Hubbard was summarily relieved of his command. 

Hubbard was sent to Submarine Chaser Training, and in 1943 was posted to Portland, Oregon to take command of a submarine chaser, the USS "PC-815", which was under construction. On May 18, USS PC-815 sailed on her shakedown cruise, bound for San Diego. Only five hours into the voyage, Hubbard believed he had detected an enemy submarine. Hubbard spent the next 68 hours engaged in combat, until finally receiving orders to return to Astoria. Admiral Fletcher, commander of the Northwest Sea Frontier, concluded: "An analysis of all reports convinces me that there was no submarine in the area." Fletcher suggested Hubbard had mistaken a "known magnetic deposit" for an enemy sub.

The following month, Hubbard unwittingly sailed the "PC-815" into Mexican territorial waters and conducted gunnery practice off the Coronado Islands, in the belief that they were uninhabited and belonged to the United States. The Mexican government complained and Hubbard was relieved of command. A report written after the incident rated Hubbard as unsuitable for independent duties and "lacking in the essential qualities of judgment, leadership and cooperation". The report recommended he be assigned "duty on a large vessel where he can be properly supervised".

After being relieved of command of the "PC-815", Hubbard was assigned to temporary duty in San Diego. There he began reporting sick, citing a variety of ailments, including malaria, ulcers, and back pains. Hubbard was admitted to the naval hospital for observation -- he would remain there nearly three months. Years later, Hubbard would privately write to himself: "Your stomach trouble you used as an excuse to keep the Navy from punishing you. You are free of the Navy."

In 1944, Hubbard was posted to Portland where the USS "Algol" was under construction. The ship was commissioned in July and Hubbard served as the Navigation and Training Officer. Hubbard requested, and was granted, a transfer to the School of Military Government in Princeton. The night before his departure, the ship's log reports that "The Navigating Officer [Hubbard] reported to the OOD [Officer On Duty] that an attempt at sabatage [sic] had been made sometime between 1530-1600. A coke bottle filled with gasoline with a cloth wick inserted had been concealed among cargo which was to be hoisted aboard and stored in No 1 hold. It was discovered before being taken on board. ONI, FBI and NSD authorities reported on the scene and investigations were started."

Hubbard attended school in Princeton until January 1945, when he was assigned to Monterey, California. In April, he again reported sick and was re-admitted to Oak Knoll Naval Hospital, Oakland. His complaints included "headaches, rheumatism, conjunctivitis, pains in his side, stomach aches, pains in his shoulder, arthritis, haemorrhoids". 

An October 1945 Naval Board found that Hubbard was "considered physically qualified to perform duty ashore, preferably within the continental United States". He was discharged from hospital on December 4, 1945, and transferred to inactive duty on February 17, 1946. 

Hubbard would ultimately resign his commission after the publication of "Dianetics", with effect from October 30, 1950.

Hubbard's life underwent a turbulent period immediately after the war. According to his own account, he "was abandoned by family and friends as a supposedly hopeless cripple and a probable burden upon them for the rest of my days". His daughter Katherine presented a rather different version: his wife had refused to uproot their children from their home in Bremerton, Washington, to join him in California. Their marriage was by now in terminal difficulties and he chose to stay in California.

In August 1945 Hubbard moved into the Pasadena mansion of John "Jack" Whiteside Parsons. A leading rocket propulsion researcher at the California Institute of Technology and a founder of the Jet Propulsion Laboratory, Parsons led a double life as an avid occultist and Thelemite, follower of the English ceremonial magician Aleister Crowley and leader of a lodge of Crowley's magical order, Ordo Templi Orientis (OTO). He let rooms in the house only to tenants who he specified should be "atheists and those of a Bohemian disposition".

Hubbard befriended Parsons and soon became sexually involved with Parsons's 21-year-old girlfriend, Sara "Betty" Northrup. Despite this Parsons was very impressed with Hubbard and reported to Crowley:

Hubbard, whom Parsons referred to in writing as "Frater H", became an enthusiastic collaborator in the Pasadena OTO. The two men collaborated on the "Babalon Working", a sex magic ritual intended to summon an incarnation of Babalon, the supreme Thelemite Goddess. It was undertaken over several nights in February and March 1946 in order to summon an "elemental" who would participate in further sex magic. As Richard Metzger describes it,

The "elemental" arrived a few days later in the form of Marjorie Cameron, who agreed to participate in Parsons' rites. Soon afterwards, Parsons, Hubbard and Sara agreed to set up a business partnership, "Allied Enterprises", in which they invested nearly their entire savings—the vast majority contributed by Parsons. The plan was for Hubbard and Sara to buy yachts in Miami and sail them to the West Coast to sell for a profit. Hubbard had a different idea; he wrote to the U.S. Navy requesting permission to leave the country "to visit Central & South America & China" for the purposes of "collecting writing material"—in other words, undertaking a world cruise. Aleister Crowley strongly criticized Parsons's actions, writing: "Suspect Ron playing confidence trick—Jack Parsons weak fool—obvious victim prowling swindlers." Parsons attempted to recover his money by obtaining an injunction to prevent Hubbard and Sara leaving the country or disposing of the remnants of his assets. They attempted to sail anyway but were forced back to port by a storm. A week later, Allied Enterprises was dissolved. Parsons received only a $2,900 promissory note from Hubbard and returned home "shattered". He had to sell his mansion to developers soon afterwards to recoup his losses.

Hubbard's fellow writers were well aware of what had happened between him and Parsons. L. Sprague de Camp wrote to Isaac Asimov on August 27, 1946, to tell him:

On August 10, 1946, Hubbard bigamously married Sara, while still married to Polly. It was not until 1947 that his first wife learned that he had remarried. Hubbard agreed to divorce Polly in June that year and the marriage was dissolved shortly afterwards, with Polly given custody of the children.

During this period, Hubbard authored a document called The "Affirmations" (also referred to as the "Admissions"). They consist of a series of statements by and addressed to Hubbard, relating to various physical, sexual, psychological and social issues that he was encountering in his life. The Affirmations appear to have been intended to be used as a form of self-hypnosis with the intention of resolving the author's psychological problems and instilling a positive mental attitude. In , Reitman called the Affirmations "the most revealing psychological self-assessment, complete with exhortations to himself, that [Hubbard] had ever made."
Among the Affirmations:

After Hubbard's wedding to Sara, the couple settled at Laguna Beach, California, where Hubbard took a short-term job looking after a friend's yacht before resuming his fiction writing to supplement the small disability allowance that he was receiving as a war veteran. Working from a trailer in a run-down area of North Hollywood, Hubbard sold a number of science fiction stories that included his "Ole Doc Methuselah" series and the serialized novels "The End Is Not Yet" and "To the Stars". However, he remained short of money and his son, L. Ron Hubbard Jr, testified later that Hubbard was dependent on his own father and Margaret's parents for money and his writings, which he was paid at a penny per word, never garnered him any more than $10,000 prior to the founding of Scientology. He repeatedly wrote to the Veterans Administration (VA) asking for an increase in his war pension. 

In October 1947 he wrote to request psychiatric treatment:

The VA eventually did increase his pension, but his money problems continued. On August 31, 1948, he was arrested in San Luis Obispo, California, and subsequently pleaded guilty to a charge of petty theft, for which he was ordered to pay a $25 fine ().

In 1948, Hubbard and his second wife Sara moved from California to Savannah, Georgia, where he would later claim to have "worked" as a "volunteer" in the psychiatric clinic. Hubbard later wrote of having observed a "Dr. Center" in Savannah. In Savannah, Hubbard began to make the first public mentions of what was to become Dianetics. 

He wrote in January 1949 that he was working on a "book of psychology" about "the cause and cure of nervous tension", which he was going to call "The Dark Sword", "Excalibur" or "Science of the Mind". On March 8, 1949, Hubbard wrote to friend and fellow science-fiction author Robert Heinlein from Savannah, Georgia. Hubbard referenced Heinlein's earlier work Coventry, in
in which a utopian government has the ability to psychologically "cure" criminals of violent personality traits. Wrote Hubbard: 
His first published articles in Dianetics were "Terra Incognita: The Mind" in the Explorer Club Journal and another one that impacted people more heavily in Astounding Science Fiction.

In April 1949, Hubbard wrote to several professional organizations to offer his research. None were interested, so he turned to his editor John W. Campbell, who was more receptive due to a long-standing fascination with fringe psychologies and psychic powers ("psionics") that "permeated both his fiction and non-fiction".

Campbell invited Hubbard and Sara to move into a cottage at Bay Head, New Jersey, not far from his own home at Plainfield. In July 1949, Campbell recruited an acquaintance, Dr. Joseph Winter, to help develop Hubbard's new therapy of "Dianetics". Campbell told Winter:

Hubbard collaborated with Campbell and Winter to refine his techniques, testing them on science fiction fans recruited by Campbell. The basic principle of Dianetics was that the brain recorded every experience and event in a person's life, even when unconscious. Bad or painful experiences were stored as what he called "engrams" in a "reactive mind". These could be triggered later in life, causing emotional and physical problems. By carrying out a process he called "auditing", a person could be regressed through his engrams to re-experiencing past experiences. This enabled engrams to be "cleared". The subject, who would now be in a state of "Clear", would have a perfectly functioning mind with an improved IQ and photographic memory. The "Clear" would be cured of physical ailments ranging from poor eyesight to the common cold, which Hubbard asserted were purely psychosomatic.

Winter submitted a paper on Dianetics to the "Journal of the American Medical Association" and the "American Journal of Psychiatry" but both journals rejected it. Hubbard and his collaborators decided to announce Dianetics in Campbell's "Astounding Science Fiction" instead. In an editorial, Campbell said: "Its power is almost unbelievable; it proves the mind not only can but does rule the body completely; following the sharply defined basic laws set forth, physical ills such as ulcers, asthma and arthritis can be cured, as can all other psychosomatic ills." The birth of Hubbard's second daughter Alexis Valerie, delivered by Winter on March 8, 1950, came in the middle of the preparations to launch Dianetics. A "Hubbard Dianetic Research Foundation" was established in April 1950 in Elizabeth, New Jersey, with Hubbard, Sara, Winter and Campbell on the board of directors.

Hubbard described Dianetics as "the hidden source of all psychosomatic ills and human aberration" when he introduced Dianetics to the world in the 1950s. He further claimed that "skills have been developed for their invariable cure." Dianetics was duly launched in "Astounding's" May 1950 issue and on May 9, Hubbard's companion book "" was published by Hermitage House. Hubbard abandoned freelance writing in order to promote Dianetics, writing several books about it in the next decade, delivering an estimated 4,000 lectures while founding Dianetics research organizations.

Dianetics was an immediate commercial success and sparked what Martin Gardner calls "a nationwide cult of incredible proportions". By August 1950, Hubbard's book had sold 55,000 copies, was selling at the rate of 4,000 a week and was being translated into French, German and Japanese. Five hundred Dianetic auditing groups had been set up across the United States.

Dianetics was poorly received by the press and the scientific and medical professions. The American Psychological Association criticized Hubbard's claims as "not supported by empirical evidence". "Scientific American" said that Hubbard's book contained "more promises and less evidence per page than any publication since the invention of printing", while "The New Republic" called it a "bold and immodest mixture of complete nonsense and perfectly reasonable common sense, taken from long acknowledged findings and disguised and distorted by a crazy, newly invented terminology". Some of Hubbard's fellow science fiction writers also criticized it; Isaac Asimov considered it "gibberish" while Jack Williamson called it "a lunatic revision of Freudian psychology".

Several famous individuals became involved with Dianetics. Aldous Huxley received auditing from Hubbard; the poet Jean Toomer and the science fiction writers Theodore Sturgeon and A. E. van Vogt became trained Dianetics auditors. Van Vogt temporarily abandoned writing and became the head of the newly established Los Angeles branch of the Hubbard Dianetic Research Foundation. Other branches were established in New York, Washington, D.C., Chicago, and Honolulu.

Although Dianetics was not cheap, a great many people were nonetheless willing to pay; van Vogt later recalled "doing little but tear open envelopes and pull out $500 checks from people who wanted to take an auditor's course". Financial controls were lax. Hubbard himself large sums with no explanation of what he was doing with it. On one occasion, van Vogt saw Hubbard taking a lump sum of $56,000 (equivalent to $0.5 million at 2010 prices) out of the Los Angeles Foundation's proceeds. One of Hubbard's employees, Helen O'Brien, commented that at the Elizabeth, N.J. branch of the Foundation, the books showed that "a month's income of $90,000 is listed, with only $20,000 accounted for".

Hubbard played a very active role in the Dianetics boom, writing, lecturing and training auditors. Many of those who knew him spoke of being impressed by his personal charisma. Jack Horner, who became a Dianetics auditor in 1950, later said, "He was very impressive, dedicated and amusing. The man had tremendous charisma; you just wanted to hear every word he had to say and listen for any pearl of wisdom." Isaac Asimov recalled in his autobiography how, at a dinner party, he, Robert Heinlein, L. Sprague de Camp and their wives "all sat as quietly as pussycats and listened to Hubbard. He told tales with perfect aplomb and in complete paragraphs." As Atack comments, he was "a charismatic figure who compelled the devotion of those around him". Christopher Evans described the personal qualities that Hubbard brought to Dianetics and Scientology:

Hubbard's supporters soon began to have doubts about Dianetics. Winter became disillusioned and wrote that he had never seen a single convincing Clear: "I have seen some individuals who are supposed to have been 'clear,' but their behavior does not conform to the definition of the state. Moreover, an individual supposed to have been 'clear' has undergone a relapse into conduct which suggests an incipient psychosis." He also deplored the Foundation's omission of any serious scientific research. 

Dianetics lost public credibility in August 1950 when a presentation by Hubbard before an audience of 6,000 at the Shrine Auditorium in Los Angeles failed disastrously. He introduced a Clear named Sonya Bianca and told the audience that as a result of undergoing Dianetic therapy she now possessed perfect recall. However, Gardner writes, "in the demonstration that followed, she failed to remember a single formula in physics (the subject in which she was majoring) or the color of Hubbard's tie when his back was turned. At this point, a large part of the audience got up and left."

Hubbard also faced other practitioners moving into leadership positions within the Dianetics community. It was structured as an open, public practice in which others were free to pursue their own lines of research and claim that their approaches to auditing produced better results than Hubbard's. The community rapidly splintered and its members mingled Hubbard's ideas with a wide variety of esoteric and occult practices. 

By late 1950, the Elizabeth, N.J. Foundation was in financial crisis and the Los Angeles Foundation was more than $200,000 in debt (). Winter and Art Ceppos, the publisher of Hubbard's book, resigned under acrimonious circumstances. Campbell also resigned, criticizing Hubbard for being impossible to work with, and blamed him for the disorganization and financial ruin of the Foundations. By the summer of 1951, the Elizabeth, N.J. Foundation and all of its branches had closed.

The collapse of Hubbard's marriage to Sara created yet more problems. He had begun an affair with his 20-year-old public relations assistant in late 1950, while Sara started a relationship with Dianetics auditor Miles Hollister. Hubbard secretly denounced the couple to the FBI in March 1951, portraying them in a letter as communist infiltrators. According to Hubbard, Sara was "currently intimate with [communists] but evidently under coercion. Drug addiction set in fall 1950. Nothing of this known to me until a few weeks ago." Hollister was described as having a "sharp chin, broad forehead, rather Slavic". He was said to be the "center of most turbulence in our organization" and "active and dangerous". The FBI did not take Hubbard seriously: an agent annotated his correspondence with the comment, "Appears mental."

Three weeks later, Hubbard and two Foundation staff seized Sara and his year-old daughter Alexis and forcibly took them to San Bernardino, California, where he attempted unsuccessfully to find a doctor to examine Sara and declare her insane. He let Sara go but took Alexis to Havana, Cuba. Sara filed a divorce suit on April 23, 1951, that accused him of marrying her bigamously and subjecting her to sleep deprivation, beatings, strangulation, kidnapping and exhortations to commit suicide. The case led to newspaper headlines such as "Ron Hubbard Insane, Says His Wife." Sara finally secured the return of her daughter in June 1951 by agreeing to a settlement with her husband in which she signed a statement, written by him, declaring:

Dianetics appeared to be on the edge of total collapse. However, it was saved by Don Purcell, a millionaire businessman and Dianeticist who agreed to support a new Foundation in Wichita, Kansas. Their collaboration ended after less than a year when they fell out over the future direction of Dianetics. The Wichita Foundation became financially nonviable after a court ruled that it was liable for the unpaid debts of its defunct predecessor in Elizabeth, N.J. The ruling prompted Purcell and the other directors of the Wichita Foundation to file for voluntary bankruptcy in February 1952. Hubbard resigned immediately and accused Purcell of having been bribed by the American Medical Association to destroy Dianetics. Hubbard established a "Hubbard College" on the other side of town where he continued to promote Dianetics while fighting Purcell in the courts over the Foundation's intellectual property.

Only six weeks after setting up the Hubbard College and marrying a staff member, 18-year-old Mary Sue Whipp, Hubbard closed it down and moved with his new bride to Phoenix, Arizona. He established a Hubbard Association of Scientologists International to promote his new "Science of Certainty"—Scientology. Scientology and Dianetics have been differentiated as follows: Dianetics is all about releasing the mind from the "distorting influence of engrams", and Scientology "is the study and handling of the spirit in relation to itself, universes and other life".

The Church of Scientology attributes its genesis to Hubbard's discovery of "a new line of research"—"that man is most fundamentally a spiritual being (a thetan)". Non-Scientologist writers have suggested alternative motives: that he aimed "to reassert control over his creation", that he believed "he was about to lose control of Dianetics", or that he wanted to ensure "he would be able to stay in business even if the courts eventually awarded control of Dianetics and its valuable copyrights to ... the hated Don Purcell." Harlan Ellison has told a story of seeing Hubbard at a gathering of the Hydra Club in 1953 or 1954. Hubbard was complaining of not being able to make a living on what he was being paid as a science fiction writer. Ellison says that Lester del Rey told Hubbard that what he needed to do to get rich was start a religion.

Hubbard expanded upon the basics of Dianetics to construct a spiritually oriented (though at this stage not religious) doctrine based on the concept that the true self of a person was a thetan — an immortal, omniscient and potentially omnipotent entity. Hubbard taught that thetans, having created the material universe, had forgotten their god-like powers and become trapped in physical bodies. Scientology aimed to "rehabilitate" each person's self (the thetan) to restore its original capacities and become once again an "Operating Thetan". Hubbard insisted humanity was imperiled by the forces of "aberration", which were the result of engrams carried by immortal thetans for billions of years.

In 2012, Ohio State University professor Hugh Urban asserted that Hubbard had adopted many of his theories from the early to mid 20th century astral projection pioneer Sylvan Muldoon stating that Hubbard's description of exteriorizing the thetan is extremely similar if not identical to the descriptions of astral projection in occult literature popularized by Muldoon's widely read Phenomena of Astral Projection (1951) (co-written with Hereward Carrington) and that Muldoon's description of the astral body as being connected to the physical body by a long thin, elastic cord is virtually identical to the one described in Hubbard's "Excalibur" vision.

Hubbard introduced a device called an E-meter that he presented as having, as Miller puts it, "an almost mystical power to reveal an individual's innermost thoughts". He promulgated Scientology through a series of lectures, bulletins and books such as "" ("a cold-blooded and factual account of your last sixty trillion years") and "Scientology: 8-8008" ("With this book, the ability to make one's body old or young at will, the ability to heal the ill without physical contact, the ability to cure the insane and the incapacitated, is set forth for the physician, the layman, the mathematician and the physicist.")

Scientology was organized in a very different way from the decentralized Dianetics movement. The Hubbard Association of Scientologists (HAS) was the only official Scientology organization. Training procedures and doctrines were standardized and promoted through HAS publications, and administrators and auditors were not permitted to deviate from Hubbard's approach. Branches or "orgs" were organized as franchises, rather like a fast food restaurant chain. Each franchise holder was required to pay ten percent of income to Hubbard's central organization. They were expected to find new recruits, known as "raw meat", but were restricted to providing only basic services. Costlier higher-level auditing was only provided by Hubbard's central organization.

Although this model would eventually be extremely successful, Scientology was a very small-scale movement at first. Hubbard started off with only a few dozen followers, generally dedicated Dianeticists; a seventy-hour series of lectures in Philadelphia in December 1952 was attended by just 38 people. Hubbard was joined in Phoenix by his 18-year-old son Nibs, who had been unable to settle down in high school. Nibs had decided to become a Scientologist, moved into his father's home and went on to become a Scientology staff member and "professor". Hubbard also traveled to the United Kingdom to establish his control over a Dianetics group in London. It was very much a shoestring operation; as Helen O'Brien later recalled, "there was an atmosphere of extreme poverty and undertones of a grim conspiracy over all. At 163 Holland Park Avenue was an ill-lit lecture room and a bare-boarded and poky office some eight by ten feet—mainly infested by long haired men and short haired and tatty women." On September 24, 1952, only a few weeks after arriving in London, Hubbard's wife Mary Sue gave birth to her first child, a daughter whom they named Diana Meredith de Wolfe Hubbard.

In February 1953, Hubbard acquired a doctorate from the unaccredited degree mill called Sequoia University. 

As membership declined and finances grew tighter, Hubbard had reversed the hostility to religion he voiced in "Dianetics". A few weeks after becoming "Dr." Hubbard, he authored a letter outlining plans for transforming Scientology into a religion. In that letter, Hubbard proposed setting up a chain of "Spiritual Guidance Centers" charging customers $500 for twenty-four hours of auditing proposing that Scientology should be transformed into a religion:

The letter's recipient, Helen O'Brien, resigned the following September. She criticized Hubbard for creating "a temperate zone voodoo, in its inelasticity, unexplainable procedures, and mindless group euphoria". 
The idea may not have been new; Hubbard has been quoted as telling a science fiction convention in 1948: "Writing for a penny a word is ridiculous. If a man really wants to make a million dollars, the best way would be to start his own religion." Scholar J. Gordon Melton notes, "There is no record of Hubbard having ever made this statement, though several of his science fiction colleagues have noted the broaching of the subject on one of their informal conversations." 

Despite objections, on December 18, 1953, Hubbard incorporated the Church of Scientology, Church of American Science and Church of Spiritual Engineering in Camden, New Jersey. Hubbard, his wife Mary Sue and his secretary John Galusha became the trustees of all three corporations. The reason for Scientology's religious transformation was explained by officials of the HAS:

Scientology franchises became Churches of Scientology and some auditors began dressing as clergymen, complete with clerical collars. If they were arrested in the course of their activities, Hubbard advised, they should sue for massive damages for molesting "a Man of God going about his business". A few years later he told Scientologists: "If attacked on some vulnerable point by anyone or anything or any organization, always find or manufacture enough threat against them to cause them to sue for peace ... Don't ever defend, always attack." Any individual breaking away from Scientology and setting up his own group was to be shut down:

The 1950s saw Scientology growing steadily. Hubbard finally achieved victory over Don Purcell in 1954 when the latter, worn out by constant litigation, handed the copyrights of Dianetics back to Hubbard. Most of the formerly independent Scientology and Dianetics groups were either driven out of business or were absorbed into Hubbard's organizations. Hubbard marketed Scientology through medical claims, such as attracting polio sufferers by presenting the Church of Scientology as a scientific research foundation investigating polio cases. One advertisement during this period stated:

Scientology became a highly profitable enterprise for Hubbard. He implemented a scheme under which he was paid a percentage of the Church of Scientology's gross income and by 1957 he was being paid about $250,000 (). His family grew, too, with Mary Sue giving birth to three more children—Geoffrey Quentin McCaully on January 6, 1954; Mary Suzette Rochelle on February 13, 1955; and Arthur Ronald Conway on June 6, 1958. In the spring of 1959, he used his new-found wealth to purchase Saint Hill Manor, an 18th-century country house in Sussex, formerly owned by Sawai Man Singh II, the Maharaja of Jaipur. The house became Hubbard's permanent residence and an international training center for Scientologists.

By the start of the 1960s, Hubbard was the leader of a worldwide movement with thousands of followers. A decade later, however, he had left Saint Hill Manor and moved aboard his own private fleet of ships as the Church of Scientology faced worldwide controversy.

The Church of Scientology says that the problems of this period were due to "vicious, covert international attacks" by the United States government, "all of which were proven false and baseless, which were to last 27 years and finally culminated in the Government being sued for 750 million dollars for conspiracy." Behind the attacks, stated Hubbard, lay a vast conspiracy of "psychiatric front groups" secretly controlling governments: "Every single lie, false charge and attack on Scientology has been traced directly to this group's members. They have sought at great expense for nineteen years to crush and eradicate any new development in the field of the mind. They are actively preventing any effectiveness in this field."

Hubbard believed that Scientology was being infiltrated by saboteurs and spies and introduced "security checking" to identify those he termed "potential trouble sources" and "suppressive persons". Members of the Church of Scientology were interrogated with the aid of E-meters and were asked questions such as "Have you ever practiced homosexuality?" and "Have you ever had unkind thoughts about L. Ron Hubbard?" For a time, Scientologists were even interrogated about crimes committed in past lives: "Have you ever destroyed a culture?" "Did you come to Earth for evil purposes?" "Have you ever zapped anyone?"

He also sought to exert political influence, advising Scientologists to vote against Richard Nixon in the 1960 presidential election and establishing a Department of Government Affairs "to bring government and hostile philosophies or societies into a state of complete compliance with the goals of Scientology". This, he said, "is done by high-level ability to control and in its absence by a low-level ability to overwhelm. Introvert such agencies. Control such agencies."

The U.S. Government was already well aware of Hubbard's activities. The FBI had a lengthy file on him, including a 1951 interview with an agent who considered him a "mental case". Police forces in a number of jurisdictions began exchanging information about Scientology through the auspices of Interpol, which eventually led to prosecutions. In 1958, the U.S. Internal Revenue Service withdrew the Washington, D.C. Church of Scientology's tax exemption after it found that Hubbard and his family were profiting unreasonably from Scientology's ostensibly non-profit income. The Food and Drug Administration took action against Scientology's medical claims, seizing thousands of pills being marketed as "radiation cures" as well as publications and E-meters. The Church of Scientology was required to label them as being "ineffective in the diagnosis or treatment of disease".

Following the FDA's actions, Scientology attracted increasingly unfavorable publicity across the English-speaking world. It faced particularly hostile scrutiny in Victoria, Australia, where it was accused of brainwashing, blackmail, extortion and damaging the mental health of its members. The Victorian state government established a Board of Inquiry into Scientology in November 1963. Its report, published in October 1965, condemned every aspect of Scientology and Hubbard himself. He was described as being of doubtful sanity, having a persecution complex and displaying strong indications of paranoid schizophrenia with delusions of grandeur. His writings were characterized as nonsensical, abounding in "self-glorification and grandiosity, replete with histrionics and hysterical, incontinent outbursts". Sociologist Roy Wallis comments that the report drastically changed public perceptions of Scientology:

The report led to Scientology being banned in Victoria, Western Australia and South Australia, and led to more negative publicity around the world. Newspapers and politicians in the UK pressed the British government for action against Scientology. In April 1966, hoping to form a remote "safe haven" for Scientology, Hubbard traveled to the southern African country Rhodesia (today Zimbabwe) and looked into setting up a base there at a hotel on Lake Kariba. Despite his attempts to curry favour with the local government—he personally delivered champagne to Prime Minister Ian Smith's house, but Smith refused to see him—Rhodesia promptly refused to renew Hubbard's visa, compelling him to leave the country. In July 1968, the British Minister of Health, Kenneth Robinson, announced that foreign Scientologists would no longer be permitted to enter the UK and Hubbard himself was excluded from the country as an "undesirable alien". Further inquiries were launched in Canada, New Zealand and South Africa.

Hubbard took three major new initiatives in the face of these challenges. "Ethics Technology" was introduced to tighten internal discipline within Scientology. It required Scientologists to "disconnect" from any organization or individual—including family members—deemed to be disruptive or "suppressive". According to church-operated websites, "A person who disconnects is simply exercising his right to communicate or not to communicate with a particular person." Hubbard stated: "Communication, however, is a two-way flow. If one has the right to communicate, then one must also have the right to not receive communication from another. It is this latter corollary of the right to communicate that gives us our right to privacy." Scientologists were also required to write "Knowledge Reports" on each other, reporting transgressions or misapplications of Scientology methods. Hubbard promulgated a long list of punishable "Misdemeanors", "Crimes", and "High Crimes". The "Fair Game" policy was introduced, which was applicable to anyone deemed an "enemy" of Scientology: "May be deprived of property or injured by any means by any Scientologist without any discipline of the Scientologist. May be tricked, sued or lied to or destroyed."

At the start of March 1966, Hubbard created the Guardian's Office (GO), a new agency within the Church of Scientology that was headed by his wife Mary Sue. It dealt with Scientology's external affairs, including public relations, legal actions and the gathering of intelligence on perceived threats. As Scientology faced increasingly negative media attention, the GO retaliated with hundreds of writs for libel and slander; it issued more than forty on a single day. Hubbard ordered his staff to find "lurid, blood sex crime actual evidence on [Scientology's] attackers".

Finally, at the end of 1966, Hubbard acquired his own fleet of ships. He established the "Hubbard Explorational Company Ltd" which purchased three ships—the "Enchanter", a forty-ton schooner, the "Avon River", an old trawler, and the "Royal Scotman" , a former Irish Sea cattle ferry that he made his home and flagship. The ships were crewed by the Sea Organization or Sea Org, a group of Scientologist volunteers, with the support of a couple of professional seamen.

After Hubbard created the Sea Org "fleet" in early 1967 it began an eight-year voyage, sailing from port to port in the Mediterranean Sea and eastern North Atlantic. The fleet traveled as far as Corfu in the eastern Mediterranean and Dakar and the Azores in the Atlantic, but rarely stayed anywhere for longer than six weeks. Ken Urquhart, Hubbard's personal assistant at the time, later recalled:

When Hubbard established the Sea Org he publicly declared that he had relinquished his management responsibilities. According to Miller, this was not true. He received daily telex messages from Scientology organizations around the world reporting their statistics and income. The Church of Scientology sent him $15,000 () a week and millions of dollars were transferred to his bank accounts in Switzerland and Liechtenstein. Couriers arrived regularly, conveying luxury food for Hubbard and his family or cash that had been smuggled from England to avoid currency export restrictions.

Along the way, Hubbard sought to establish a safe haven in "a friendly little country where Scientology would be allowed to prosper", as Miller puts it. The fleet stayed at Corfu for several months in 1968–1969. Hubbard renamed the ships after Greek gods—the "Royal Scotman" was rechristened "Apollo"—and he praised the recently established military dictatorship. The Sea Org was represented as "Professor Hubbard's Philosophy School" in a telegram to the Greek government. In March 1969, however, Hubbard and his ships were ordered to leave. In mid-1972, Hubbard tried again in Morocco, establishing contacts with the country's secret police and training senior policemen and intelligence agents in techniques for detecting subversives. The program ended in failure when it became caught up in internal Moroccan politics, and Hubbard left the country hastily in December 1972.

At the same time, Hubbard was still developing Scientology's doctrines. A Scientology biography states that "free of organizational duties and aided by the first Sea Org members, L. Ron Hubbard now had the time and facilities to confirm in the physical universe some of the events and places he had encountered in his journeys down the track of time." In 1965, he designated several existing Scientology courses as confidential, repackaging them as the first of the esoteric "OT levels". Two years later he announced the release of OT3, the "Wall of Fire", revealing the secrets of an immense disaster that had occurred "on this planet, and on the other seventy-five planets which form this Confederacy, seventy-five million years ago". Scientologists were required to undertake the first two OT levels before learning how Xenu, the leader of the Galactic Confederacy, had shipped billions of people to Earth and blown them up with hydrogen bombs, following which their traumatized spirits were stuck together at "implant stations", brainwashed with false memories and eventually became contained within human beings. The discovery of OT3 was said to have taken a major physical toll on Hubbard, who announced that he had broken a knee, an arm, and his back during the course of his research. A year later, in 1968, he unveiled OT levels 4 to 6 and began delivering OT training courses to Scientologists aboard the "Royal Scotman".

Scientologists around the world were presented with a glamorous picture of life in the Sea Org and many applied to join Hubbard aboard the fleet. What they found was rather different from the image. Most of those joining had no nautical experience at all. Mechanical difficulties and blunders by the crews led to a series of embarrassing incidents and near-disasters. Following one incident in which the rudder of the "Royal Scotman" was damaged during a storm, Hubbard ordered the ship's entire crew to be reduced to a "condition of liability" and wear gray rags tied to their arms. The ship itself was treated the same way, with dirty tarpaulins tied around its funnel to symbolize its lower status. According to those aboard, conditions were appalling; the crew was worked to the point of exhaustion, given meagre rations and forbidden to wash or change their clothes for several weeks. Hubbard maintained a harsh disciplinary regime aboard the fleet, punishing mistakes by confining people in the "Royal Scotman" bilge tanks without toilet facilities and with food provided in buckets. At other times erring crew members were thrown overboard with Hubbard looking on and, occasionally, filming. David Mayo, a Sea Org member at the time, later recalled:

From about 1970, Hubbard was attended aboard ship by the children of Sea Org members, organized as the Commodore's Messenger Organization (CMO). They were mainly young girls dressed in hot pants and halter tops, who were responsible for running errands for Hubbard such as lighting his cigarettes, dressing him or relaying his verbal commands to other members of the crew. In addition to his wife Mary Sue, he was accompanied by all four of his children by her, though not his first son Nibs, who had defected from Scientology in late 1959. The younger Hubbards were all members of the Sea Org and shared its rigors, though Quentin Hubbard reportedly found it difficult to adjust and attempted suicide in mid-1974.

During the 1970s, Hubbard faced an increasing number of legal threats. French prosecutors charged him and the French Church of Scientology with fraud and customs violations in 1972. He was advised that he was at risk of being extradited to France. Hubbard left the Sea Org fleet temporarily at the end of 1972, living incognito in Queens, New York, until he returned to his flagship in September 1973 when the threat of extradition had abated. Scientology sources say that he carried out "a sociological study in and around New York City".

Hubbard's health deteriorated significantly during this period. A chain-smoker, he also suffered from bursitis and excessive weight, and had a prominent growth on his forehead. He suffered serious injuries in a motorcycle accident in 1973 and had a heart attack in 1975 that required him to take anticoagulant drugs for the next year. In September 1978, Hubbard had a pulmonary embolism, falling into a coma, but recovered.

He remained active in managing and developing Scientology, establishing the controversial Rehabilitation Project Force in 1974 and issuing policy and doctrinal bulletins. However, the Sea Org's voyages were coming to an end. The "Apollo" was banned from several Spanish ports and was expelled from Curaçao in October 1975. The Sea Org came to be suspected of being a CIA operation, leading to a riot in Funchal, Madeira, when the "Apollo" docked there. At the time, "The Apollo Stars", a musical group founded by Hubbard and made up entirely of shipbound members of the Sea Org, was offering free on-pier concerts in an attempt to promote Scientology, and the riot occurred at one of these events. Hubbard decided to relocate back to the United States to establish a "land base" for the Sea Org in Florida. The Church of Scientology attributes this decision to the activities on the "Apollo" having "outgrow[n] the ship's capacity".

In October 1975, Hubbard moved into a hotel suite in Daytona Beach. The Fort Harrison Hotel in Clearwater, Florida, was secretly acquired as the location for the "land base". On December 5, 1975, Hubbard and his wife Mary Sue moved into a condominium complex in nearby Dunedin. Their presence was meant to be a closely guarded secret but was accidentally compromised the following month. Hubbard immediately left Dunedin and moved to Georgetown, Washington, D.C., accompanied by a handful of aides and messengers, but not his wife. Six months later, following another security alert in July 1976, Hubbard moved to another safe house in Culver City, California. He lived there for only about three months, relocating in October to the more private confines of the Olive Tree Ranch near La Quinta. His second son Quentin committed suicide a few weeks later in Las Vegas.

Throughout this period, Hubbard was heavily involved in directing the activities of the Guardian's Office (GO), the legal bureau/intelligence agency that he had established in 1966. He believed that Scientology was being attacked by an international Nazi conspiracy, which he termed the "Tenyaka Memorial", through a network of drug companies, banks and psychiatrists in a bid to take over the world. In 1973, he instigated the "Snow White Program" and directed the GO to remove negative reports about Scientology from government files and track down their sources. The GO was ordered to "get all false and secret files on Scientology, LRH  ... that cannot be obtained legally, by all possible lines of approach ... i.e., job penetration, janitor penetration, suitable guises utilizing covers." His involvement in the GO's operations was concealed through the use of codenames. The GO carried out covert campaigns on his behalf such as Operation Bulldozer Leak, intended "to effectively spread the rumor that will lead Government, media, and individual <nowiki>[</nowiki>Suppressive Persons<nowiki>]</nowiki> to conclude that LRH has no control of the C of S and no legal liability for Church activity". He was kept informed of GO operations, such as the theft of medical records from a hospital, harassment of psychiatrists and infiltrations of organizations that had been critical of Scientology at various times, such as the Better Business Bureau, the American Medical Association, and American Psychiatric Association.

Members of the GO infiltrated and burglarized numerous government organizations, including the U.S. Department of Justice and the Internal Revenue Service. After two GO agents were caught in the Washington, D.C. headquarters of the IRS, the FBI carried out simultaneous raids on GO offices in Los Angeles and Washington, D.C. on July 7, 1977. They retrieved wiretap equipment, burglary tools and some 90,000 pages of incriminating documents. Hubbard was not prosecuted, though he was labeled an "unindicted co-conspirator" by government prosecutors. His wife Mary Sue was indicted and subsequently convicted of conspiracy. She was sent to a federal prison along with ten other Scientologists.

Hubbard's troubles increased in February 1978 when a French court convicted him in absentia for obtaining money under false pretenses. He was sentenced to four years in prison and a 35,000FF ($7,000) fine, . He went into hiding in April 1979, moving to an apartment in Hemet, California, where his only contact with the outside world was via ten trusted Messengers. He cut contact with everyone else, even his wife, whom he saw for the last time in August 1979. Hubbard faced a possible indictment for his role in Operation Freakout, the GO's campaign against New York journalist Paulette Cooper, and in February 1980 he disappeared into deep cover in the company of two trusted Messengers, Pat and Anne Broeker.

For the first few years of the 1980s, Hubbard and the Broekers lived on the move, touring the Pacific Northwest in a recreational vehicle and living for a while in apartments in Newport Beach and Los Angeles. Hubbard used his time in hiding to write his first new works of science fiction for nearly thirty years—"Battlefield Earth" (1982) and "Mission Earth", a ten-volume series published between 1985 and 1987. They received mixed responses; as writer Jeff Walker puts it, they were "treated derisively by most critics but greatly admired by followers". Hubbard also wrote and composed music for three of his albums, which were produced by the Church of Scientology. The book soundtrack "Space Jazz" was released in 1982. "Mission Earth" and "The Road to Freedom" were released posthumously in 1986.

In Hubbard's absence, members of the Sea Org staged a takeover of the Church of Scientology and purged many veteran Scientologists. A young Messenger, David Miscavige, became Scientology's "de facto" leader. Mary Sue Hubbard was forced to resign her position and her daughter Suzette became Miscavige's personal maid.

For the last two years of his life, Hubbard lived in a luxury Blue Bird motorhome on Whispering Winds, a 160-acre ranch near Creston, California. He remained in deep hiding while controversy raged in the outside world about whether he was still alive and if so, where. He spent his time "writing and researching", according to a spokesperson, and pursued photography and music, overseeing construction work and checking on his animals. He repeatedly redesigned the property, spending millions of dollars remodeling the ranch house—which went virtually uninhabited—and building a quarter-mile horse-racing track with an observation tower, which reportedly was never used.

He was still closely involved in managing the Church of Scientology via secretly delivered orders and continued to receive large amounts of money, of which "Forbes" magazine estimated "at least $200 million [was] gathered in Hubbard's name through 1982." In September 1985, the IRS notified the Church that it was considering indicting Hubbard for tax fraud.

Hubbard suffered further ill-health, including chronic pancreatitis, during his residence at Whispering Winds. He suffered a stroke on January 17, 1986, and died a week later. His body was cremated and the ashes were scattered at sea. Scientology leaders announced that his body had become an impediment to his work and that he had decided to "drop his body" to continue his research on another planet, having "learned how to do it without a body".

Hubbard was survived by his wife Mary Sue and all of his children except his second son Quentin. His will provided a trust fund to support Mary Sue; her children Arthur, Diana and Suzette; and Katherine, the daughter of his first wife Polly. He disinherited two of his other children. L. Ron Hubbard, Jr. had become estranged, changed his name to "Ronald DeWolf" and, in 1982, sued unsuccessfully for control of his father's estate. Alexis Valerie, Hubbard's daughter by his second wife Sara, had attempted to contact her father in 1971. She was rebuffed with the implied claim that her real father was Jack Parsons rather than Hubbard, and that her mother had been a Nazi spy during the war. Both later accepted settlements when litigation was threatened. In 2001, Diana and Suzette were reported to still be Church members, while Arthur had left and become an artist. Hubbard's great-grandson, Jamie DeWolf, is a noted slam poet.

The copyrights of his works and much of his estate and wealth were willed to the Church of Scientology. In a bulletin dated May 5, 1980, Hubbard told his followers to preserve his teachings until an eventual reincarnation when he would return "not as a religious leader but as a political one". The Church of Spiritual Technology (CST), a sister organization of the Church of Scientology, has engraved Hubbard's entire corpus of Scientology and Dianetics texts on steel tablets stored in titanium containers. They are buried at the Trementina Base in a vault under a mountain near Trementina, New Mexico, on top of which the CST's logo has been bulldozed on such a gigantic scale that it is visible from space.

Hubbard is the Guinness World Record holder for the most published author, with 1,084 works, most translated book (70 languages for "The Way to Happiness") and most audiobooks (185 as of April 2009). According to Galaxy Press, Hubbard's "Battlefield Earth" has sold over 6 million copies and "Mission Earth" a further 7 million, with each of its ten volumes becoming "New York Times" bestsellers on their release; however, the "Los Angeles Times" reported in 1990 that Hubbard's followers had been buying large numbers of the books and re-issuing them to stores, so as to boost sales figures. Opinions are divided about his literary legacy. Scientologists have written of their desire to "make Ron the most acclaimed and widely known author of all time". The sociologist William Sims Bainbridge writes that even at his peak in the late 1930s Hubbard was regarded by readers of "Astounding Science Fiction" as merely "a passable, familiar author but not one of the best", while by the late 1970s "the [science fiction] subculture wishes it could forget him" and fans gave him a worse rating than any other of the "Golden Age" writers.

Posthumously, the Los Angeles City Council named a part of the street close to the headquarters of Scientology in 1996, as recognition of Hubbard. In 2011, the West Valley City Council declared March 13 as L. Ron Hubbard Centennial Day. On April 2016, the New Jersey State Board of Education approved Hubbard's birthday as one of its religious holidays.

In 2004, eighteen years after Hubbard's death, the Church claimed eight million followers worldwide. According to religious scholar J. Gordon Melton, this is an overestimate, counting as Scientologists people who had merely bought a book. The City University of New York's American Religious Identification Survey found that by 2009 only 25,000 Americans identified as Scientologists. Hubbard's presence still pervades Scientology. Every Church of Scientology maintains an office reserved for Hubbard, with a desk, chair and writing equipment, ready to be used. Lonnie D. Kliever notes that Hubbard was "the only source of the religion, and he has no successor". Hubbard is referred to simply as "Source" within Scientology and the theological acceptability of any Scientology-related activity is determined by how closely it adheres to Hubbard's doctrines. Hubbard's name and signature are official trademarks of the Religious Technology Center, established in 1982 to control and oversee the use of Hubbard's works and Scientology's trademarks and copyrights. The RTC is the central organization within Scientology's complex corporate hierarchy and has put much effort into re-checking the accuracy of all Scientology publications to "ensur[e] the availability of the pure unadulterated writings of Mr. Hubbard to the coming generations".

The Danish historian of religions Mikael Rothstein describes Scientology as "a movement focused on the figure of Hubbard". He comments: "The fact that [Hubbard's] life is mythologized is as obvious as in the cases of Jesus, Muhammad or Siddartha Gotama. This is how religion works. Scientology, however, rejects this analysis altogether, and goes to great lengths to defend every detail of Hubbard's amazing and fantastic life as plain historical fact." Hubbard is presented as "the master of a multitude of disciplines" who performed extraordinary feats as a photographer, composer, scientist, therapist, explorer, navigator, philosopher, poet, artist, humanitarian, adventurer, soldier, scout, musician and many other fields of endeavor. The Church of Scientology portrays Hubbard's life and work as having proceeded seamlessly, "as if they were a continuous set of predetermined events and discoveries that unfolded through his lifelong research" even up to and beyond his death.

According to Rothstein's assessment of Hubbard's legacy, Scientology consciously aims to transfer the charismatic authority of Hubbard to institutionalize his authority over the organization, even after his death. Hubbard is presented as a virtually superhuman religious ideal just as Scientology itself is presented as the most important development in human history. As Rothstein puts it, "reverence for Scientology's scripture is reverence for Hubbard, the man who in the Scientological perspective single-handedly brought salvation to all human beings." David G. Bromley of the University of Virginia comments that the real Hubbard has been transformed into a "prophetic persona", "LRH", which acts as the basis for his prophetic authority within Scientology and transcends his biographical history. According to Dorthe Refslund Christensen, Hubbard's hagiography directly compares him with Buddha. Hubbard is viewed as having made Eastern traditions more accessible by approaching them with a scientific attitude. "Hubbard is seen as the ultimate-cross-cultural savior; he is thought to be able to release man from his miserable condition because he had the necessary background, and especially the right attitude."

Hubbard, although increasingly deified after his death, is the model Operating Thetan to Scientologists and their founder, and not God. Hubbard then is the "Source", "inviting others to follow his path in ways comparable to a Bodhisattva figure" according to religious scholar Donald A. Westbrook. Scientologists refer to L. Ron Hubbard as "Ron", referring to him as a personal friend.

In the late 1970s two men began to assemble a picture of Hubbard's life. Michael Linn Shannon, a resident of Portland, Oregon, became interested in Hubbard's life story after an encounter with a Scientology recruiter. Over the next four years he collected previously undisclosed records and documents. He intended to write an exposé of Hubbard and sent a copy of his findings and key records to a number of contacts but was unable to find a publisher.

Shannon's findings were acquired by Gerry Armstrong, a Scientologist who had been appointed Hubbard's official archivist. He had been given the job of assembling documents relating to Hubbard's life for the purpose of helping Omar V. Garrison, a non-Scientologist who had written two books sympathetic to Scientology, to write an official biography. However, the documents that he uncovered convinced both Armstrong and Garrison that Hubbard had systematically misrepresented his life. Garrison refused to write a "puff piece" and declared that he would not "repeat all the falsehoods they [the Church of Scientology] had perpetuated over the years". He wrote a "warts and all" biography while Armstrong quit Scientology, taking five boxes of papers with him. The Church of Scientology and Mary Sue Hubbard sued for the return of the documents while settling out of court with Garrison, requiring him to turn over the nearly completed manuscript of the biography. In October 1984 Judge Paul G. Breckenridge ruled in Armstrong's favor, saying:

In November 1987, the British journalist and writer Russell Miller published "Bare-faced Messiah", the first full-length biography of L. Ron Hubbard. He drew on Armstrong's papers, official records and interviews with those who had known Hubbard including ex-Scientologists and family members. The book was well-received by reviewers but the Church of Scientology sought unsuccessfully to prohibit its publication on the grounds of copyright infringement. Other critical biographical accounts are found in Bent Corydon's "L. Ron Hubbard, Messiah or Madman?" (1987) and Jon Atack's "A Piece of Blue Sky" (1990).

Hagiographical accounts published by the Church of Scientology describe Hubbard as "a child prodigy of sorts" who rode a horse before he could walk and was able to read and write by the age of four. A Scientology profile says that he was brought up on his grandfather's "large cattle ranch in Montana" where he spent his days "riding, breaking broncos, hunting coyote and taking his first steps as an explorer". His grandfather is described as a "wealthy Western cattleman" from whom Hubbard "inherited his fortune and family interests in America, Southern Africa, etc." Scientology claims that Hubbard became a "blood brother" of the Native American Blackfeet tribe at the age of six through his friendship with a Blackfeet medicine man.

However, contemporary records show that his grandfather, Lafayette Waterbury, was a veterinarian, not a rancher, and was not wealthy. Hubbard was actually raised in a townhouse in the center of Helena. According to his aunt, his family did not own a ranch but did own one cow and four or five horses on a few acres of land outside the city. Hubbard lived over a hundred miles from the Blackfeet reservation. While some sources support Scientology's claim of Hubbard's blood brotherhood, other sources say that the tribe did not practice blood brotherhood and no evidence has been found that he had ever been a Blackfeet blood brother.

According to Scientology biographies, during a journey to Washington, D.C. in 1923 Hubbard learned of Freudian psychology from Commander Joseph "Snake" Thompson, a U.S. Navy psychoanalyst and medic. Scientology biographies describe this encounter as giving Hubbard training in a particular scientific approach to the mind, which he found unsatisfying. In his diary, Hubbard claimed he was the youngest Eagle Scout in the U.S.

Scientology texts present Hubbard's travels in Asia as a time when he was intensely curious for answers to human suffering and explored ancient Eastern philosophies for answers, but found them lacking. He is described as traveling to China "at a time when few Westerners could enter" and according to Scientology, spent his time questioning Buddhist lamas and meeting old Chinese magicians. According to church materials, his travels were funded by his "wealthy grandfather".

Scientology accounts say that Hubbard "made his way deep into Manchuria's Western Hills and beyond — to break bread with Mongolian bandits, share campfires with Siberian shamans and befriend the last in the line of magicians from the court of Kublai Khan". However, Hubbard did not record these events in his diary. He remained unimpressed with China and the Chinese, writing: "A Chinaman can not live up to a thing, he always drags it down." He characterized the sights of Beijing as "rubberneck stations" for tourists and described the palaces of the Forbidden City as "very trashy-looking" and "not worth mentioning". He was impressed by the Great Wall of China near Beijing, but concluded of the Chinese: "They smell of all the baths they didn't take. The trouble with China is, there are too many chinks here."

Despite not graduating from George Washington, Hubbard claimed "to be not only a graduate engineer, but 'a member of the first United States course in formal education in what is called today nuclear physics.'" However, a Church of Scientology biography describes him as "never noted for being in class" and says that he "thoroughly detest[ed] his subjects". He earned poor grades, was placed on probation in September 1931 and dropped out altogether in the fall of 1932.

Scientology accounts say that he "studied nuclear physics at George Washington University in Washington, D.C., before he started his studies about the mind, spirit and life" and Hubbard himself stated that he "set out to find out from nuclear physics a knowledge of the physical universe, something entirely lacking in Asian philosophy". His university records indicate that his exposure to "nuclear physics" consisted of one class in "atomic and molecular phenomena" for which he earned an "F" grade.

Scientologists claim he was more interested in extracurricular activities, particularly writing and flying. According to church materials, "he earned his wings as a pioneering barnstormer at the dawn of American aviation" and was "recognized as one of the country's most outstanding pilots. With virtually no training time, he takes up powered flight and barnstorms throughout the Midwest." His airman certificate, however, records that he qualified to fly only gliders rather than powered aircraft and gave up his certificate when he could not afford the renewal fee.
After leaving university Hubbard traveled to Puerto Rico on what the Church of Scientology calls the "Puerto Rican Mineralogical Expedition". Scientologists claim he "made the first complete mineralogical survey of Puerto Rico" as a means of "augmenting his [father's] pay with a mining venture", during which he "sluiced inland rivers and crisscrossed the island in search of elusive gold" as well as carrying out "much ethnological work amongst the interior villages and native hillsmen". Hubbard's unofficial biographer Russell Miller writes that neither the United States Geological Survey nor the Puerto Rican Department of Natural Resources have any record of any such expedition.

According to the Church of Scientology, Hubbard was "called to Hollywood" to work on film scripts in the mid-1930s, although Scientology accounts differ as to exactly when this was (whether 1935, 1936 or 1937). The Church of Scientology claims he also worked on the Columbia serials "The Mysterious Pilot" (1937), "The Great Adventures of Wild Bill Hickok" (1938) and "The Spider Returns" (1941), though his name does not appear on the credits. Hubbard also claimed to have written "Dive Bomber" (1941), Cecil B. DeMille's "The Plainsman" (1936) and John Ford's "Stagecoach" (1939).

Scientology accounts of the expedition to Alaska describe "Hubbard's recharting of an especially treacherous Inside Passage, and his ethnological study of indigenous Aleuts and Haidas" and tell of how "along the way, he not only roped a Kodiak Bear, but braved seventy-mile-an-hour winds and commensurate seas off the Aleutian Islands." They are divided about how far Hubbard's expedition actually traveled, whether or .

The Church disputes the official record of Hubbard's naval career. It asserts that the records are incomplete and perhaps falsified "to conceal Hubbard's secret activities as an intelligence officer". In 1990 the Church provided the "Los Angeles Times" with a document that was said to be a copy of Hubbard's official record of service. The U.S. Navy told the "Times" that "its contents are not supported by Hubbard's personnel record." "The New Yorker" reported in February 2011 that the Scientology document was considered by federal archivists to be a forgery.

The Church of Scientology presents him as a "much-decorated war hero who commanded a corvette and during hostilities was crippled and wounded". Scientology publications say he served as a "Commodore of Corvette squadrons" in "all five theaters of World War II" and was awarded "twenty-one medals and palms" for his service. He was "severely wounded and was taken crippled and blinded" to a military hospital, where he "worked his way back to fitness, strength and full perception in less than two years, using only what he knew and could determine about Man and his relationship to the universe". He said that he had seen combat repeatedly, telling A. E. van Vogt that he had once sailed his ship "right into the harbor of a Japanese occupied island in the Dutch East Indies. His attitude was that if you took your flag down the Japanese would not know one boat from another, so he tied up at the dock, went ashore and wandered around by himself for three days."

Hubbard's war service has great significance in the history and mythology of the Church of Scientology, as he is said to have cured himself through techniques that would later underpin Scientology and Dianetics. According to Moulton, Hubbard told him that he had been machine-gunned in the back near the Dutch East Indies. Hubbard asserted that his eyes had been damaged as well, either "by the flash of a large-caliber gun" or when he had "a bomb go off in my face". Scientology texts say that he returned from the war "[b]linded with injured optic nerves, and lame with physical injuries to hip and back" and was twice pronounced dead. Hubbard's official Navy service records indicate that "his military performance was, at times, substandard" and he received only four campaign medals rather than the claimed twenty-one. He was never recorded as being injured or wounded in combat and never received a Purple Heart.

The Church of Scientology says that Hubbard's key breakthrough in the development of Dianetics was made at Oak Knoll Naval Hospital in Oakland, California. According to the Church,

Scientology accounts do not mention Hubbard's involvement in occultism. He is instead described as "continu[ing] to write to help support his research" during this period into "the development of a means to better the condition of man". The Church of Scientology has nonetheless acknowledged Hubbard's involvement with the OTO; a 1969 statement, written by Hubbard himself, said:

The Church of Scientology says Hubbard was "sent in" by his fellow science fiction author Robert Heinlein, "who was running off-book intelligence operations for naval intelligence at the time". However, Heinlein's authorized biographer has said that he looked into the matter at the suggestion of Scientologists but found nothing to corroborate claims that Heinlein had been involved, and his biography of Heinlein makes no mention of the matter.

The Church of Scientology says Hubbard quit the Navy because it "attempted to monopolize all his researches and force him to work on a project 'to make man more suggestible' and when he was unwilling, tried to blackmail him by ordering him back to active duty to perform this function. Having many friends he was able to instantly resign from the Navy and escape this trap." The Navy said in a statement in 1980: "There is no evidence on record of an attempt to recall him to active duty."

Following Hubbard's death, Bridge Publications has published several stand-alone biographical accounts of his life. Marco Frenschkowski notes that "non-Scientologist readers immediately recognize some parts of Hubbard's life are here systematically left out: no information whatsoever is given about his private life (his marriages, divorces, children), his legal affairs and so on." The Church maintains an extensive website presenting the official version of Hubbard's life. It also owns a number of properties dedicated to Hubbard including the Los Angeles-based L. Ron Hubbard Life Exhibition (a presentation of Hubbard's life), the Author Services Center (a presentation of Hubbard's writings), and the L. Ron Hubbard House in Washington, D.C.

In late 2012, Bridge published a comprehensive official biography of Hubbard, titled "The L. Ron Hubbard Series: A Biographical Encyclopedia", written primarily by Dan Sherman, the official Hubbard biographer at the time. This most recent official Church of Scientology biography of Hubbard is a 17 volume series, with each volume focusing on a different aspect of Hubbard's life, including his music, photography, geographic exploration, humanitarian work, and nautical career. It is advertised as a "Biographic Encyclopedia" and is primarily authored by the official biographer, Dan Sherman.

To date, there has not been a single-volume comprehensive official biography published During his lifetime, a number of brief biographical sketches were also published in his Scientology books. The Church of Scientology issued "the only authorized LRH Biography" in October 1977 (it has since been followed by the Sherman "Biographic Encyclopedia"). His life was illustrated in print in "What Is Scientology?", a glossy publication published in 1978 with paintings of Hubbard's life contributed by his son Arthur.

According to the Church of Scientology, Hubbard produced some 65 million words on Dianetics and Scientology, contained in about 500,000 pages of written material, 3,000 recorded lectures and 100 films. His works of fiction included some 500 novels and short stories. Hubbard "published nearly 600 books, stories, and articles during his lifetime." He sold over 23 million copies of fiction and 27 million copies of nonfiction.






</doc>
<doc id="17926" url="https://en.wikipedia.org/wiki?curid=17926" title="League of Nations">
League of Nations

The League of Nations, abbreviated as LN or LoN, (, abbreviated as "SDN" or "SdN" and meaning "Society of Nations") was an intergovernmental organisation founded on 10 January 1920 as a result of the Paris Peace Conference that ended the First World War. It was the first worldwide intergovernmental organisation whose principal mission was to maintain world peace. Its primary goals, as stated in its Covenant, included preventing wars through collective security and disarmament and settling international disputes through negotiation and arbitration. Other issues in this and related treaties included labour conditions, just treatment of native inhabitants, 
human and drug trafficking, the arms trade, global health, prisoners of war, and protection of minorities in Europe. At its greatest extent from 28 September 1934 to 23 February 1935, it had 58 members.

The diplomatic philosophy behind the League represented a fundamental shift from the preceding hundred years. The League lacked its own armed force and depended on the victorious Great Powers of World War I (France, the United Kingdom, Italy and Japan were the permanent members of the executive Council) to enforce its resolutions, keep to its economic sanctions, or provide an army when needed. The Great Powers were often reluctant to do so. Sanctions could hurt League members, so they were reluctant to comply with them. During the Second Italo-Abyssinian War, when the League accused Italian soldiers of targeting Red Cross medical tents, Benito Mussolini responded that "the League is very well when sparrows shout, but no good at all when eagles fall out."

After some notable successes and some early failures in the 1920s, the League ultimately proved incapable of preventing aggression by the Axis powers in the 1930s. The credibility of the organization was weakened by the fact that the United States never officially joined the League and the Soviet Union joined late and only briefly. Germany withdrew from the League, as did Japan, Italy, Spain and others. The onset of the Second World War showed that the League had failed its primary purpose, which was to prevent any future world war. The League lasted for 26 years; the United Nations (UN) replaced it after the end of the Second World War and inherited several agencies and organisations founded by the League.

The concept of a peaceful community of nations had been proposed as far back as 1795, when Immanuel Kant's "" outlined the idea of a league of nations to control conflict and promote peace between states. Kant argued for the establishment of a peaceful world community, not in a sense of a global government, but in the hope that each state would declare itself a free state that respects its citizens and welcomes foreign visitors as fellow rational beings, thus promoting peaceful society worldwide. International co-operation to promote collective security originated in the Concert of Europe that developed after the Napoleonic Wars in the 19th century in an attempt to maintain the "status quo" between European states and so avoid war. This period also saw the development of international law, with the first Geneva Conventions establishing laws dealing with humanitarian relief during wartime, and the international Hague Conventions of 1899 and 1907 governing rules of war and the peaceful settlement of international disputes. As historians William H. Harbaugh and Ronald E. Powaski point out, Theodore Roosevelt was the first American President to call for an international league. At the acceptance for his Nobel Prize, Roosevelt said: "it would be a masterstroke if those great powers honestly bent on peace would form a League of Peace."

The forerunner of the League of Nations, the Inter-Parliamentary Union (IPU), was formed by the peace activists William Randal Cremer and Frédéric Passy in 1889 (and is currently still in existence as an international body with a focus on the various elected legislative bodies of the world.) The IPU was founded with an international scope, with a third of the members of parliaments (in the 24 countries that had parliaments) serving as members of the IPU by 1914. Its foundational aims were to encourage governments to solve international disputes by peaceful means. Annual conferences were established to help governments refine the process of international arbitration. Its structure was designed as a council headed by a president, which would later be reflected in the structure of the League.

At the start of the First World War the first schemes for international organisation to prevent future wars began to gain considerable public support, particularly in Great Britain and the United States. Goldsworthy Lowes Dickinson, a British political scientist, coined the term "League of Nations" in 1914 and drafted a scheme for its organisation. Together with Lord Bryce, he played a leading role in the founding of the group of internationalist pacifists known as the Bryce Group, later the League of Nations Union. The group became steadily more influential among the public and as a pressure group within the then governing Liberal Party. In Dickinson's 1915 pamphlet "After the War" he wrote of his "League of Peace" as being essentially an organisation for arbitration and conciliation. He felt that the secret diplomacy of the early twentieth century had brought about war and thus could write that, "the impossibility of war, I believe, would be increased in proportion as the issues of foreign policy should be known to and controlled by public opinion." The ‘Proposals’ of the Bryce Group were circulated widely, both in England and the US, where they had a profound influence on the nascent international movement.

Within two weeks of the start of the war, feminists began to mobilise against the war. Having been barred from participating in prior peace organizations, American women formed a Women's Peace Parade Committee to plan a silent protest to the war. Led by chairwoman Fanny Garrison Villard, women from trade unions, feminist organizations, and social reform organizations, such as Kate Waller Barrett, Mary Ritter Beard, Carrie Chapman Catt, Rose Schneiderman, Lillian Wald, and others, organized 1500 women, who marched down Manhattan's Fifth Avenue on 29 August 1914. As a result of the parade, Jane Addams became interested in proposals by two European suffragists—Hungarian Rosika Schwimmer and British Emmeline Pethick-Lawrence—to hold a peace conference. On 9–10 January 1915, a peace conference directed by Addams was held in Washington, D. C., where the delegates adopted a platform calling for creation of international bodies with administrative and legislative powers to develop a "permanent league of neutral nations" to work for peace and disarmament.

Within months a call was made for an international women's conference to be held in The Hague. Coordinated by Mia Boissevain, Aletta Jacobs and Rosa Manus, the Congress, which opened on 28 April 1915 was attended by 1,136 participants from both neutral and non-belligerent nations, and resulted in the establishment of an organization which would become the Women's International League for Peace and Freedom (WILPF). At the close of the conference, two delegations of women were dispatched to meet European heads of state over the next several months. They secured agreement from reluctant Foreign Ministers, who overall felt that such a body would be ineffective, but agreed to participate or not impede creation of a neutral mediating body, if other nations agreed and if President Woodrow Wilson would initiate a body. In the midst of the War, Wilson refused.

In 1915, a similar body to the Bryce group proposals was set up in the United States by a group of like-minded individuals, including William Howard Taft. It was called the League to Enforce Peace and was substantially based on the proposals of the Bryce Group. It advocated the use of arbitration in conflict resolution and the imposition of sanctions on aggressive countries. None of these early organisations envisioned a continuously functioning body; with the exception of the Fabian Society in England, they maintained a legalistic approach that would limit the international body to a court of justice. The Fabians were the first to argue for a "Council" of states, necessarily the Great Powers, who would adjudicate world affairs, and for the creation of a permanent secretariat to enhance international co-operation across a range of activities.

In the course of the diplomatic efforts surrounding World War I, both sides had to clarify their long-term war aims. By 1916 in Britain, the leader of the Allies, and in neutral United States, long-range thinkers had begun to design a unified international organisation to prevent future wars. Historian Peter Yearwood argues that when the new coalition government of David Lloyd George took power in December 1916, there was widespread discussion among intellectuals and diplomats of the desirability of establishing such an organisation, when Lloyd George was challenged by Wilson to state his position With an eye on the postwar situation, he endorsed such an organisation. Wilson himself included in his Fourteen Points in January 1918 a "league of nations to insure peace and justice." British foreign secretary, Arthur Balfour, argued that, as a condition of durable peace, "behind international law, and behind all treaty arrangements for preventing or limiting hostilities, some form of international sanction should be devised which would give pause to the hardiest aggressor."

The war had had a profound impact, affecting the social, political and economic systems of Europe and inflicting psychological and physical damage. Several empires collapsed: first the Russian Empire in February 1917, followed by the German Empire, Austro-Hungarian Empire and Ottoman Empire. Anti-war sentiment rose across the world; the First World War was described as "the war to end all wars", and its possible causes were vigorously investigated. The causes identified included arms races, alliances, militaristic nationalism, secret diplomacy, and the freedom of sovereign states to enter into war for their own benefit. One proposed remedy was the creation of an international organisation whose aim was to prevent future war through disarmament, open diplomacy, international co-operation, restrictions on the right to wage war, and penalties that made war unattractive.

In London Balfour commissioned the first official report into the matter in early 1918, under the initiative of Lord Robert Cecil. The British committee was finally appointed in February 1918. It was led by Walter Phillimore (and became known as the Phillimore Committee), but also included Eyre Crowe, William Tyrrell, and Cecil Hurst. The recommendations of the so-called Phillimore Commission included the establishment of a "Conference of Allied States" that would arbitrate disputes and impose sanctions on offending states. The proposals were approved by the British government, and much of the commission's results were later incorporated into the Covenant of the League of Nations.
The French also drafted a much more far-reaching proposal in June 1918; they advocated annual meetings of a council to settle all disputes, as well as an "international army" to enforce its decisions.

The American President Woodrow Wilson instructed Edward M. House to draft a US plan which reflected Wilson's own idealistic views (first articulated in the Fourteen Points of January 1918), as well as the work of the Phillimore Commission. The outcome of House's work, and Wilson's own first draft, proposed the termination of "unethical" state behaviour, including forms of espionage and dishonesty. Methods of compulsion against recalcitrant states would include severe measures, such as "blockading and closing the frontiers of that power to commerce or intercourse with any part of the world and to use any force that may be necessary..."

The two principal drafters and architects of the covenant of the League of Nations were the British politician Lord Robert Cecil and the South African statesman Jan Smuts. Smuts' proposals included the creation of a Council of the great powers as permanent members and a non-permanent selection of the minor states. He also proposed the creation of a Mandate system for captured colonies of the Central Powers during the war. Cecil focused on the administrative side, and proposed annual Council meetings and quadrennial meetings for the Assembly of all members. He also argued for a large and permanent secretariat to carry out the League's administrative duties.

At the Paris Peace Conference in 1919, Wilson, Cecil and Smuts all put forward their draft proposals. After lengthy negotiations between the delegates, the Hurst–Miller draft was finally produced as a basis for the Covenant. After more negotiation and compromise, the delegates finally approved of the proposal to create the League of Nations (, ) on 25 January 1919. The final Covenant of the League of Nations was drafted by a special commission, and the League was established by Part I of the Treaty of Versailles. On 28 June 1919, 44 states signed the Covenant, including 31 states which had taken part in the war on the side of the Triple Entente or joined it during the conflict.

French women's rights advocates invited international feminists to participate in a parallel conference to the Paris Conference in hopes that they could gain permission to participate in the official conference. The Inter-Allied Women's Conference asked to be allowed to submit suggestions to the peace negotiations and commissions and were granted the right to sit on commissions dealing specifically with women and children. Though they asked for enfranchisement and full legal protection under the law equal with men, those rights were ignored. Women won the right to serve in all capacities, including as staff or delegates in the League of Nations organization. They also won a declaration that member nations should prevent trafficking of women and children and should equally support humane conditions for children, women and men labourers. At the Zürich Peace Conference held between 17–19 May 1919, the women of the WILPF condemned the terms of the Treaty of Versailles for both its punitive measures, as well as its failure to provide for condemnation of violence and exclusion of women from civil and political participation. Upon reading the Rules of Procedure for the League of Nations, Catherine Marshall, a British suffragist, discovered that the guidelines were completely undemocratic and they were modified based on her suggestion.

The League would be made up of a General Assembly (representing all member states), an Executive Council (with membership limited to major powers), and a permanent secretariat. Member states were expected to "respect and preserve as against external aggression" the territorial integrity of other members and to disarm "to the lowest point consistent with domestic safety." All states were required to submit complaints for arbitration or judicial inquiry before going to war. The Executive Council would create a Permanent Court of International Justice to make judgements on the disputes.

Despite Wilson's efforts to establish and promote the League, for which he was awarded the Nobel Peace Prize in October 1919, the United States never joined. Senate Republicans led by Henry Cabot Lodge wanted a League with the reservation that only Congress could take the U.S. into war. Lodge gained a majority of Senators. Wilson refused to allow a compromise and the needed 2/3 majority was lacking.

The League held its first council meeting in Paris on 16 January 1920, six days after the Versailles Treaty and the Covenant of the League of Nations came into force. On 1 November 1920, the headquarters of the League was moved from London to Geneva, where the first General Assembly was held on 15 November 1920. The Palais Wilson on Geneva's western lakeshore, named after US President Woodrow Wilson in recognition of his efforts towards the establishment of the League, was the League's first permanent home.

The official languages of the League of Nations were French and English. The League rejected adopting Esperanto as its working language. China and Japan wanted Esperanto but France was strongly opposed.

In 1939, a semi-official emblem for the League of Nations emerged: two five-pointed stars within a blue pentagon. They symbolised the Earth's five continents and "five races." A bow at the top displayed the English name ("League of Nations"), while another at the bottom showed the French (""Société des Nations"").

The main constitutional organs of the League were the Assembly, the Council, and the Permanent Secretariat. It also had two essential wings: the Permanent Court of International Justice and the International Labour Organization. In addition, there were several auxiliary agencies and commissions. Each organ's budget was allocated by the Assembly (the League was supported financially by its member states).

The relations between the Assembly and the Council and the competencies of each were for the most part not explicitly defined. Each body could deal with any matter within the sphere of competence of the League or affecting peace in the world. Particular questions or tasks might be referred to either.

Unanimity was required for the decisions of both the Assembly and the Council, except in matters of procedure and some other specific cases such as the admission of new members. This requirement was a reflection of the League's belief in the sovereignty of its component nations; the League sought solution by consent, not by dictation. In case of a dispute, the consent of the parties to the dispute was not required for unanimity.

The Permanent Secretariat, established at the seat of the League at Geneva, comprised a body of experts in various spheres under the direction of the general secretary. Its principal sections were Political, Financial and Economics, Transit, Minorities and Administration (administering the Saar and Danzig), Mandates, Disarmament, Health, Social (Opium and Traffic in Women and Children), Intellectual Cooperation and International Bureaux, Legal, and Information. The staff of the Secretariat was responsible for preparing the agenda for the Council and the Assembly and publishing reports of the meetings and other routine matters, effectively acting as the League's civil service. In 1931 the staff numbered 707.

The Assembly consisted of representatives of all members of the League, with each state allowed up to three representatives and one vote. It met in Geneva and, after its initial sessions in 1920, it convened once a year in September. The special functions of the Assembly included the admission of new members, the periodical election of non-permanent members to the Council, the election with the Council of the judges of the Permanent Court, and control of the budget. In practice, the Assembly was the general directing force of League activities.

The League Council acted as a type of executive body directing the Assembly's business. It began with four permanent members (Great Britain, France, Italy, and Japan) and four non-permanent members that were elected by the Assembly for a three-year term. The first non-permanent members were Belgium, Brazil, Greece, and Spain.

The composition of the Council was changed several times. The number of non-permanent members was first increased to six on 22 September 1922 and to nine on 8 September 1926. Werner Dankwort of Germany pushed for his country to join the League; joining in 1926, Germany became the fifth permanent member of the Council. Later, after Germany and Japan both left the League, the number of non-permanent seats was increased from nine to eleven, and the Soviet Union was made a permanent member giving the Council a total of fifteen members. The Council met, on average, five times a year and in extraordinary sessions when required. In total, 107 sessions were held between 1920 and 1939.

The League oversaw the Permanent Court of International Justice and several other agencies and commissions created to deal with pressing international problems. These included the Disarmament Commission, the International Labour Organization (ILO), the Mandates Commission, the International Commission on Intellectual Cooperation (precursor to UNESCO), the Permanent Central Opium Board, the Commission for Refugees, and the Slavery Commission. Three of these institutions were transferred to the United Nations after the Second World War: the International Labour Organization, the Permanent Court of International Justice (as the International Court of Justice), and the Health Organisation (restructured as the World Health Organization).

The Permanent Court of International Justice was provided for by the Covenant, but not established by it. The Council and the Assembly established its constitution. Its judges were elected by the Council and the Assembly, and its budget was provided by the latter. The Court was to hear and decide any international dispute which the parties concerned submitted to it. It might also give an advisory opinion on any dispute or question referred to it by the Council or the Assembly. The Court was open to all the nations of the world under certain broad conditions.

The International Labour Organization was created in 1919 on the basis of Part XIII of the Treaty of Versailles. The ILO, although having the same members as the League and being subject to the budget control of the Assembly, was an autonomous organisation with its own Governing Body, its own General Conference and its own Secretariat. Its constitution differed from that of the League: representation had been accorded not only to governments but also to representatives of employers' and workers' organisations. Albert Thomas was its first director.
The ILO successfully restricted the addition of lead to paint, and convinced several countries to adopt an eight-hour work day and forty-eight-hour working week. It also campaigned to end child labour, increase the rights of women in the workplace, and make shipowners liable for accidents involving seamen. After the demise of the League, the ILO became an agency of the United Nations in 1946.

The League's health organisation had three bodies: the Health Bureau, containing permanent officials of the League; the General Advisory Council or Conference, an executive section consisting of medical experts; and the Health Committee. The Committee's purpose was to conduct inquiries, oversee the operation of the League's health work, and prepare work to be presented to the Council. This body focused on ending leprosy, malaria, and yellow fever, the latter two by starting an international campaign to exterminate mosquitoes. The Health Organisation also worked successfully with the government of the Soviet Union to prevent typhus epidemics, including organising a large education campaign.

The League of Nations had devoted serious attention to the question of international intellectual co-operation since its creation. The First Assembly in December 1920 recommended that the Council take action aiming at the international organisation of intellectual work, which it did by adopting a report presented by the Fifth Committee of the Second Assembly and inviting a Committee on Intellectual Cooperation to meet in Geneva in August 1922. The French philosopher Henri Bergson became the first chairman of the committee. The work of the committee included: inquiry into the conditions of intellectual life, assistance to countries where intellectual life was endangered, creation of national committees for intellectual co-operation, co-operation with international intellectual organisations, protection of intellectual property, inter-university co-operation, co-ordination of bibliographical work and international interchange of publications, and international co-operation in archaeological research.

Introduced by the second International Opium Convention, the Permanent Central Opium Board had to supervise the statistical reports on trade in opium, morphine, cocaine and heroin. The board also established a system of import certificates and export authorisations for the legal international trade in narcotics.

The Slavery Commission sought to eradicate slavery and slave trading across the world, and fought forced prostitution. Its main success was through pressing the governments who administered mandated countries to end slavery in those countries. The League secured a commitment from Ethiopia to end slavery as a condition of membership in 1923, and worked with Liberia to abolish forced labour and intertribal slavery. The United Kingdom had not supported Ethiopian membership of the League on the grounds that "Ethiopia had not reached a state of civilisation and internal security sufficient to warrant her admission."

The League also succeeded in reducing the death rate of workers constructing the Tanganyika railway from 55 to 4 percent. Records were kept to control slavery, prostitution, and the trafficking of women and children. Partly as a result of pressure brought by the League of Nations, Afghanistan abolished slavery in 1923, Iraq in 1924, Nepal in 1926, Transjordan and Persia in 1929, Bahrain in 1937, and Ethiopia in 1942.
Led by Fridtjof Nansen, the Commission for Refugees was established on 27 June 1921 to look after the interests of refugees, including overseeing their repatriation and, when necessary, resettlement. At the end of the First World War, there were two to three million ex-prisoners of war from various nations dispersed throughout Russia; within two years of the commission's foundation, it had helped 425,000 of them return home. It established camps in Turkey in 1922 to aid the country with an ongoing refugee crisis, helping to prevent disease and hunger. It also established the Nansen passport as a means of identification for stateless people.

The Committee for the Study of the Legal Status of Women sought to inquire into the status of women all over the world. It was formed in 1937, and later became part of the United Nations as the Commission on the Status of Women.

Of the League's 42 founding members, 23 (24 counting Free France) remained members until it was dissolved in 1946. In the founding year, six other states joined, only two of which remained members throughout the League's existence. Under the Weimar Republic, Germany (in fact the "Deutsches Reich" or German Empire) was admitted to the League of Nations through a resolution passed on 8 September 1926.

An additional 15 countries joined later. The largest number of member states was 58, between 28 September 1934 (when Ecuador joined) and 23 February 1935 (when Paraguay withdrew).

On 26 May 1937, Egypt became the last state to join the League. The first member to withdraw permanently from the League was Costa Rica on 22 January 1925; having joined on 16 December 1920, this also makes it the member to have most quickly withdrawn. Brazil was the first founding member to withdraw (14 June 1926), and Haiti the last (April 1942). Iraq, which joined in 1932, was the first member that had previously been a League of Nations mandate.

The Soviet Union became a member on 18 September 1934, and was expelled on 14 December 1939 for invading Finland. In expelling the Soviet Union, the League broke its own rule: only 7 of 15 members of the Council voted for expulsion (United Kingdom, France, Belgium, Bolivia, Egypt, South Africa, and the Dominican Republic), short of the majority required by the Covenant. Three of these members had been made Council members the day before the vote (South Africa, Bolivia, and Egypt). This was one of the League's final acts before it practically ceased functioning due to the Second World War.

At the end of the First World War, the Allied powers were confronted with the question of the disposal of the former German colonies in Africa and the Pacific, and the several Arabic-speaking provinces of the Ottoman Empire. The Peace Conference adopted the principle that these territories should be administered by different governments on behalf of the League – a system of national responsibility subject to international supervision. This plan, defined as the mandate system, was adopted by the "Council of Ten" (the heads of government and foreign ministers of the main Allied powers: Britain, France, the United States, Italy, and Japan) on 30 January 1919 and transmitted to the League of Nations.

League of Nations mandates were established under Article 22 of the Covenant of the League of Nations. The Permanent Mandates Commission supervised League of Nations mandates, and also organised plebiscites in disputed territories so that residents could decide which country they would join. There were three mandate classifications: A, B and C.

The A mandates (applied to parts of the old Ottoman Empire) were "certain communities" that had 

The B mandates were applied to the former German colonies that the League took responsibility for after the First World War. These were described as "peoples" that the League said were 

South West Africa and certain South Pacific Islands were administered by League members under C mandates. These were classified as "territories" 

The territories were governed by mandatory powers, such as the United Kingdom in the case of the Mandate of Palestine, and the Union of South Africa in the case of South West Africa, until the territories were deemed capable of self-government. Fourteen mandate territories were divided up among seven mandatory powers: the United Kingdom, the Union of South Africa, France, Belgium, New Zealand, Australia and Japan. With the exception of the Kingdom of Iraq, which joined the League on 3 October 1932, these territories did not begin to gain their independence until after the Second World War, in a process that did not end until 1990. Following the demise of the League, most of the remaining mandates became United Nations Trust Territories.

In addition to the mandates, the League itself governed the Territory of the Saar Basin for 15 years, before it was returned to Germany following a plebiscite, and the Free City of Danzig (now Gdańsk, Poland) from 15 November 1920 to 1 September 1939.

The aftermath of the First World War left many issues to be settled, including the exact position of national boundaries and which country particular regions would join. Most of these questions were handled by the victorious Allied powers in bodies such as the Allied Supreme Council. The Allies tended to refer only particularly difficult matters to the League. This meant that, during the early interwar period, the League played little part in resolving the turmoil resulting from the war. The questions the League considered in its early years included those designated by the Paris Peace treaties.

As the League developed, its role expanded, and by the middle of the 1920s it had become the centre of international activity. This change can be seen in the relationship between the League and non-members. The United States and Russia, for example, increasingly worked with the League. During the second half of the 1920s, France, Britain and Germany were all using the League of Nations as the focus of their diplomatic activity, and each of their foreign secretaries attended League meetings at Geneva during this period. They also used the League's machinery to try to improve relations and settle their differences.

Åland is a collection of around 6,500 islands in the Baltic Sea, midway between Sweden and Finland. The islands are almost exclusively Swedish-speaking, but in 1809, the Åland Islands, along with Finland, were taken by Imperial Russia. In December 1917, during the turmoil of the Russian October Revolution, Finland declared its independence, but most of the Ålanders wished to rejoin Sweden. The Finnish government considered the islands to be a part of their new nation, as the Russians had included Åland in the Grand Duchy of Finland, formed in 1809. By 1920, the dispute had escalated to the point that there was danger of war. The British government referred the problem to the League's Council, but Finland would not let the League intervene, as they considered it an internal matter. The League created a small panel to decide if it should investigate the matter and, with an affirmative response, a neutral commission was created. In June 1921, the League announced its decision: the islands were to remain a part of Finland, but with guaranteed protection of the islanders, including demilitarisation. With Sweden's reluctant agreement, this became the first European international agreement concluded directly through the League.

The Allied powers referred the problem of Upper Silesia to the League after they had been unable to resolve the territorial dispute. After the First World War, Poland laid claim to Upper Silesia, which had been part of Prussia. The Treaty of Versailles had recommended a plebiscite in Upper Silesia to determine whether the territory should become part of Germany or Poland. Complaints about the attitude of the German authorities led to rioting and eventually to the first two Silesian Uprisings (1919 and 1920). A plebiscite took place on 20 March 1921, with 59.6 percent (around 500,000) of the votes cast in favour of joining Germany, but Poland claimed the conditions surrounding it had been unfair. This result led to the Third Silesian Uprising in 1921.

On 12 August 1921, the League was asked to settle the matter; the Council created a commission with representatives from Belgium, Brazil, China and Spain to study the situation. The committee recommended that Upper Silesia be divided between Poland and Germany according to the preferences shown in the plebiscite and that the two sides should decide the details of the interaction between the two areas – for example, whether goods should pass freely over the border due to the economic and industrial interdependence of the two areas. In November 1921, a conference was held in Geneva to negotiate a convention between Germany and Poland. A final settlement was reached, after five meetings, in which most of the area was given to Germany, but with the Polish section containing the majority of the region's mineral resources and much of its industry. When this agreement became public in May 1922, bitter resentment was expressed in Germany, but the treaty was still ratified by both countries. The settlement produced peace in the area until the beginning of the Second World War.

The frontiers of the Principality of Albania had not been set during the Paris Peace Conference in 1919, as they were left for the League to decide; they had not yet been determined by September 1921, creating an unstable situation. Greek troops conducted military operations in the south of Albania. Kingdom of Serbs, Croats and Slovenes (Yugoslav) forces became engaged, after clashes with Albanian tribesmen, in the northern part of the country. The League sent a commission of representatives from various powers to the region. In November 1921, the League decided that the frontiers of Albania should be the same as they had been in 1913, with three minor changes that favoured Yugoslavia. Yugoslav forces withdrew a few weeks later, albeit under protest.

The borders of Albania again became the cause of international conflict when Italian General Enrico Tellini and four of his assistants were ambushed and killed on 24 August 1923 while marking out the newly decided border between Greece and Albania. Italian leader Benito Mussolini was incensed, and demanded that a commission investigate the incident within five days. Whatever the results of the investigation, Mussolini insisted that the Greek government pay Italy fifty million lire in reparations. The Greeks said they would not pay unless it was proved that the crime was committed by Greeks.

Mussolini sent a warship to shell the Greek island of Corfu, and Italian forces occupied the island on 31 August 1923. This contravened the League's covenant, so Greece appealed to the League to deal with the situation. The Allies agreed (at Mussolini's insistence) that the Conference of Ambassadors should be responsible for resolving the dispute because it was the conference that had appointed General Tellini. The League Council examined the dispute, but then passed on their findings to the Conference of Ambassadors to make the final decision. The conference accepted most of the League's recommendations, forcing Greece to pay fifty million lire to Italy, even though those who committed the crime were never discovered. Italian forces then withdrew from Corfu.

The port city of Memel (now Klaipėda) and the surrounding area, with a predominantly German population, was under provisional Entente control according to Article 99 of the Treaty of Versailles. The French and Polish governments favoured turning Memel into an international city, while Lithuania wanted to annex the area. By 1923, the fate of the area had still not been decided, prompting Lithuanian forces to invade in January 1923 and seize the port. After the Allies failed to reach an agreement with Lithuania, they referred the matter to the League of Nations. In December 1923, the League Council appointed a Commission of Inquiry. The commission chose to cede Memel to Lithuania and give the area autonomous rights. The Klaipėda Convention was approved by the League Council on 14 March 1924, and then by the Allied powers and Lithuania. In 1939 Germany retook the region following the rise of the Nazis and an ultimatum to Lithuania, demanding the return of the region under threat of war. The League of Nations failed to prevent the secession of the Memel region to Germany.

With League oversight, the Sanjak of Alexandretta in the French Mandate of Syria was given autonomy in 1937. Renamed Hatay, its parliament declared independence as the Republic of Hatay in September 1938, after elections the previous month. It was annexed by Turkey with French consent in mid-1939.

The League resolved a dispute between the Kingdom of Iraq and the Republic of Turkey over control of the former Ottoman province of Mosul in 1926. According to the British, who had been awarded a League of Nations mandate over Iraq in 1920 and therefore represented Iraq in its foreign affairs, Mosul belonged to Iraq; on the other hand, the new Turkish republic claimed the province as part of its historic heartland. A League of Nations Commission of Inquiry, with Belgian, Hungarian and Swedish members, was sent to the region in 1924; it found that the people of Mosul did not want to be part of either Turkey or Iraq, but if they had to choose, they would pick Iraq. In 1925, the commission recommended that the region stay part of Iraq, under the condition that the British hold the mandate over Iraq for another 25 years, to ensure the autonomous rights of the Kurdish population. The League Council adopted the recommendation and decided on 16 December 1925 to award Mosul to Iraq. Although Turkey had accepted League of Nations' arbitration in the Treaty of Lausanne (1923), it rejected the decision, questioning the Council's authority. The matter was referred to the Permanent Court of International Justice, which ruled that, when the Council made a unanimous decision, it must be accepted. Nonetheless, Britain, Iraq and Turkey ratified a separate treaty on 5 June 1926 that mostly followed the decision of the League Council and also assigned Mosul to Iraq. It was agreed that Iraq could still apply for League membership within 25 years and that the mandate would end upon its admission.

After the First World War, Poland and Lithuania both regained their independence but soon became immersed in territorial disputes. During the Polish–Soviet War, Lithuania signed the Moscow Peace Treaty with the Soviet Union that laid out Lithuania's frontiers. This agreement gave Lithuanians control of the city of Vilnius (, ), the old Lithuanian capital, but a city with a majority Polish population. This heightened tension between Lithuania and Poland and led to fears that they would resume the Polish–Lithuanian War, and on 7 October 1920, the League negotiated the Suwałki Agreement establishing a cease-fire and a demarcation line between the two nations. On 9 October 1920, General Lucjan Żeligowski, commanding a Polish military force in contravention of the Suwałki Agreement, took the city and established the Republic of Central Lithuania.

After a request for assistance from Lithuania, the League Council called for Poland's withdrawal from the area. The Polish government indicated they would comply, but instead reinforced the city with more Polish troops. This prompted the League to decide that the future of Vilnius should be determined by its residents in a plebiscite and that the Polish forces should withdraw and be replaced by an international force organised by the League. The plan was met with resistance in Poland, Lithuania, and the Soviet Union, which opposed any international force in Lithuania. In March 1921, the League abandoned plans for the plebiscite. After unsuccessful proposals by Paul Hymans to create a federation between Poland and Lithuania, which was intended as a reincarnation of the former union which both Poland and Lithuania had once shared before losing its independence, Vilnius and the surrounding area was formally annexed by Poland in March 1922. After Lithuania took over the Klaipėda Region, the Allied Conference set the frontier between Lithuania and Poland, leaving Vilnius within Poland, on 14 March 1923. Lithuanian authorities refused to accept the decision, and officially remained in a state of war with Poland until 1927. It was not until the 1938 Polish ultimatum that Lithuania restored diplomatic relations with Poland and thus "de facto" accepted the borders.

There were several border conflicts between Colombia and Peru in the early part of the 20th century, and in 1922, their governments signed the Salomón-Lozano Treaty in an attempt to resolve them. As part of this treaty, the border town of Leticia and its surrounding area was ceded from Peru to Colombia, giving Colombia access to the Amazon River. On 1 September 1932, business leaders from Peruvian rubber and sugar industries who had lost land as a result organised an armed takeover of Leticia. At first, the Peruvian government did not recognise the military takeover, but President of Peru Luis Sánchez Cerro decided to resist a Colombian re-occupation. The Peruvian Army occupied Leticia, leading to an armed conflict between the two nations. After months of diplomatic negotiations, the governments accepted mediation by the League of Nations, and their representatives presented their cases before the Council. A provisional peace agreement, signed by both parties in May 1933, provided for the League to assume control of the disputed territory while bilateral negotiations proceeded. In May 1934, a final peace agreement was signed, resulting in the return of Leticia to Colombia, a formal apology from Peru for the 1932 invasion, demilitarisation of the area around Leticia, free navigation on the Amazon and Putumayo Rivers, and a pledge of non-aggression.

Saar was a province formed from parts of Prussia and the Rhenish Palatinate and placed under League control by the Treaty of Versailles. A plebiscite was to be held after fifteen years of League rule to determine whether the province should belong to Germany or France. When the referendum was held in 1935, 90.3 percent of voters supported becoming part of Germany, which was quickly approved by the League Council.

In addition to territorial disputes, the League also tried to intervene in other conflicts between and within nations. Among its successes were its fight against the international trade in opium and sexual slavery, and its work to alleviate the plight of refugees, particularly in Turkey in the period up to 1926. One of its innovations in this latter area was the 1922 introduction of the Nansen passport, which was the first internationally recognised identity card for stateless refugees.

After an incident involving sentries on the Greek-Bulgarian border in October 1925, fighting began between the two countries. Three days after the initial incident, Greek troops invaded Bulgaria. The Bulgarian government ordered its troops to make only token resistance, and evacuated between ten thousand and fifteen thousand people from the border region, trusting the League to settle the dispute. The League condemned the Greek invasion, and called for both Greek withdrawal and compensation to Bulgaria.

Following accusations of forced labour on the large American-owned Firestone rubber plantation and American accusations of slave trading, the Liberian government asked the League to launch an investigation. The resulting commission was jointly appointed by the League, the United States, and Liberia. In 1930, a League report confirmed the presence of slavery and forced labour. The report implicated many government officials in the selling of contract labour and recommended that they be replaced by Europeans or Americans, which generated anger within Liberia and led to the resignation of President Charles D. B. King and his vice-president. The Liberian government outlawed forced labour and slavery and asked for American help in social reforms.

The Mukden Incident, also known as the "Manchurian Incident" was a decisive setback that weakened The League because its major members refused to tackle Japanese aggression. Japan itself withdrew.

Under the agreed terms of the Twenty-One Demands with China, the Japanese government had the right to station its troops in the area around the South Manchurian Railway, a major trade route between the two countries, in the Chinese region of Manchuria. In September 1931, a section of the railway was lightly damaged by the Japanese Kwantung Army as a pretext for an invasion of Manchuria. The Japanese army claimed that Chinese soldiers had sabotaged the railway and in apparent retaliation (acting contrary to orders from Tokyo, ) occupied all of Manchuria. They renamed the area Manchukuo, and on 9 March 1932 set up a puppet government, with Pu Yi, the former emperor of China, as its executive head. This new entity was recognised only by the governments of Italy, Spain and Nazi Germany; the rest of the world still considered Manchuria legally part of China.

The League of Nations sent observers. The Lytton Report appeared a year later (October 1932). It declared Japan to be the aggressor and demanded Manchuria be returned to China. The report passed 42–1 in the Assembly in 1933 (only Japan voting against), but instead of removing its troops from China, Japan withdrew from the League. In the end, as British historian Charles Mowat argued, collective security was dead:

The League failed to prevent the 1932 war between Bolivia and Paraguay over the arid Gran Chaco region. Although the region was sparsely populated, it contained the Paraguay River, which would have given either landlocked country access to the Atlantic Ocean, and there was also speculation, later proved incorrect, that the Chaco would be a rich source of petroleum. Border skirmishes throughout the late 1920s culminated in an all-out war in 1932 when the Bolivian army attacked the Paraguayans at Fort Carlos Antonio López at Lake Pitiantuta. Paraguay appealed to the League of Nations, but the League did not take action when the Pan-American Conference offered to mediate instead. The war was a disaster for both sides, causing 57,000 casualties for Bolivia, whose population was around three million, and 36,000 dead for Paraguay, whose population was approximately one million. It also brought both countries to the brink of economic disaster. By the time a ceasefire was negotiated on 12 June 1935, Paraguay had seized control of most of the region, as was later recognised by the 1938 truce.

In October 1935, Italian dictator Benito Mussolini sent 400,000 troops to invade Abyssinia (Ethiopia). Marshal Pietro Badoglio led the campaign from November 1935, ordering bombing, the use of chemical weapons such as mustard gas, and the poisoning of water supplies, against targets which included undefended villages and medical facilities. The modern Italian Army defeated the poorly armed Abyssinians and captured Addis Ababa in May 1936, forcing Emperor of Ethiopia Haile Selassie to flee.

The League of Nations condemned Italy's aggression and imposed economic sanctions in November 1935, but the sanctions were largely ineffective since they did not ban the sale of oil or close the Suez Canal (controlled by Britain). As Stanley Baldwin, the British Prime Minister, later observed, this was ultimately because no one had the military forces on hand to withstand an Italian attack. In October 1935, the US President, Franklin D. Roosevelt, invoked the recently passed Neutrality Acts and placed an embargo on arms and munitions to both sides, but extended a further "moral embargo" to the belligerent Italians, including other trade items. On 5 October and later on 29 February 1936, the United States endeavoured, with limited success, to limit its exports of oil and other materials to normal peacetime levels. The League sanctions were lifted on 4 July 1936, but by that point Italy had already gained control of the urban areas of Abyssinia.

The Hoare–Laval Pact of December 1935 was an attempt by the British Foreign Secretary Samuel Hoare and the French Prime Minister Pierre Laval to end the conflict in Abyssinia by proposing to partition the country into an Italian sector and an Abyssinian sector. Mussolini was prepared to agree to the pact, but news of the deal leaked out. Both the British and French public vehemently protested against it, describing it as a sell-out of Abyssinia. Hoare and Laval were forced to resign, and the British and French governments dissociated themselves from the two men. In June 1936, although there was no precedent for a head of state addressing the Assembly of the League of Nations in person, Haile Selassie spoke to the Assembly, appealing for its help in protecting his country.

The Abyssinian crisis showed how the League could be influenced by the self-interest of its members; one of the reasons why the sanctions were not very harsh was that both Britain and France feared the prospect of driving Mussolini and Adolf Hitler into an alliance.

On 17 July 1936, the Spanish Army launched a coup d'état, leading to a prolonged armed conflict between Spanish Republicans (the elected leftist national government) and the Nationalists (conservative, anti-communist rebels who included most officers of the Spanish Army). Julio Álvarez del Vayo, the Spanish Minister of Foreign Affairs, appealed to the League in September 1936 for arms to defend Spain's territorial integrity and political independence. The League members would not intervene in the Spanish Civil War nor prevent foreign intervention in the conflict. Adolf Hitler and Mussolini continued to aid General Francisco Franco's Nationalists, while the Soviet Union helped the Spanish Republic. In February 1937, the League did ban foreign volunteers, but this was in practice a symbolic move.

Following a long record of instigating localised conflicts throughout the 1930s, Japan began a full-scale invasion of China on 7 July 1937. On 12 September, the Chinese representative, Wellington Koo, appealed to the League for international intervention. Western countries were sympathetic to the Chinese in their struggle, particularly in their stubborn defence of Shanghai, a city with a substantial number of foreigners. The League was unable to provide any practical measures; on 4 October, it turned the case over to the Nine Power Treaty Conference.

Article 8 of the Covenant gave the League the task of reducing "armaments to the lowest point consistent with national safety and the enforcement by common action of international obligations". A significant amount of the League's time and energy was devoted to this goal, even though many member governments were uncertain that such extensive disarmament could be achieved or was even desirable. The Allied powers were also under obligation by the Treaty of Versailles to attempt to disarm, and the armament restrictions imposed on the defeated countries had been described as the first step toward worldwide disarmament. The League Covenant assigned the League the task of creating a disarmament plan for each state, but the Council devolved this responsibility to a special commission set up in 1926 to prepare for the 1932–1934 World Disarmament Conference. Members of the League held different views towards the issue. The French were reluctant to reduce their armaments without a guarantee of military help if they were attacked; Poland and Czechoslovakia felt vulnerable to attack from the west and wanted the League's response to aggression against its members to be strengthened before they disarmed. Without this guarantee, they would not reduce armaments because they felt the risk of attack from Germany was too great. Fear of attack increased as Germany regained its strength after the First World War, especially after Adolf Hitler gained power and became German Chancellor in 1933. In particular, Germany's attempts to overturn the Treaty of Versailles and the reconstruction of the German military made France increasingly unwilling to disarm.

The World Disarmament Conference was convened by the League of Nations in Geneva in 1932, with representatives from 60 states. It was a failure. A one-year moratorium on the expansion of armaments, later extended by a few months, was proposed at the start of the conference. The Disarmament Commission obtained initial agreement from France, Italy, Spain, Japan, and Britain to limit the size of their navies but no final agreement was reached. Ultimately, the Commission failed to halt the military build-up by Germany, Italy, Spain and Japan during the 1930s.

The League was mostly silent in the face of major events leading to the Second World War, such as Hitler's remilitarisation of the Rhineland, occupation of the Sudetenland and "Anschluss" of Austria, which had been forbidden by the Treaty of Versailles. In fact, League members themselves re-armed. In 1933, Japan simply withdrew from the League rather than submit to its judgement, as did Germany the same year (using the failure of the World Disarmament Conference to agree to arms parity between France and Germany as a pretext), Italy and Spain in 1937. The final significant act of the League was to expel the Soviet Union in December 1939 after it invaded Finland.

The onset of the Second World War demonstrated that the League had failed in its primary purpose, the prevention of another world war. There were a variety of reasons for this failure, many connected to general weaknesses within the organisation. Additionally, the power of the League was limited by the United States' refusal to join.

The origins of the League as an organisation created by the Allied powers as part of the peace settlement to end the First World War led to it being viewed as a "League of Victors". The League's neutrality tended to manifest itself as indecision. It required a unanimous vote of nine, later fifteen, Council members to enact a resolution; hence, conclusive and effective action was difficult, if not impossible. It was also slow in coming to its decisions, as certain ones required the unanimous consent of the entire Assembly. This problem mainly stemmed from the fact that the primary members of the League of Nations were not willing to accept the possibility of their fate being decided by other countries, and by enforcing unanimous voting had effectively given themselves veto power.

Representation at the League was often a problem. Though it was intended to encompass all nations, many never joined, or their period of membership was short. The most conspicuous absentee was the United States. President Woodrow Wilson had been a driving force behind the League's formation and strongly influenced the form it took, but the US Senate voted not to join on 19 November 1919. Ruth Henig has suggested that, had the United States become a member, it would have also provided support to France and Britain, possibly making France feel more secure, and so encouraging France and Britain to co-operate more fully regarding Germany, thus making the rise to power of the Nazi Party less likely. Conversely, Henig acknowledges that if the US had been a member, its reluctance to engage in war with European states or to enact economic sanctions might have hampered the ability of the League to deal with international incidents. The structure of the US federal government might also have made its membership problematic, as its representatives at the League could not have made decisions on behalf of the executive branch without having the prior approval of the legislative branch.

In January 1920, when the League was born, Germany was not permitted to join because it was seen as having been the aggressor in the First World War. Soviet Russia was also initially excluded because Communist regimes were not welcomed and membership would have been initially dubious due to the Russian Civil War in which both sides claimed to be the legitimate government of the country. The League was further weakened when major powers left in the 1930s. Japan began as a permanent member of the Council since the country was an Allied Power in the First World War, but withdrew in 1933 after the League voiced opposition to its occupation of Manchuria. Italy began as a permanent member of the Council, but withdrew in 1937 after roughly a year following the end of the Second Italo-Ethiopian War. Spain also began as a permanent member of the Council, but withdrew in 1939 after the Spanish Civil War ended in a victory for the Nationalists. The League had accepted Germany, also as a permanent member of the Council, in 1926, deeming it a "peace-loving country", but Adolf Hitler pulled Germany out when he came to power in 1933.

Another important weakness grew from the contradiction between the idea of collective security that formed the basis of the League and international relations between individual states. The League's collective security system required nations to act, if necessary, against states they considered friendly, and in a way that might endanger their national interests, to support states for which they had no normal affinity. This weakness was exposed during the Abyssinia Crisis, when Britain and France had to balance maintaining the security they had attempted to create for themselves in Europe "to defend against the enemies of internal order", in which Italy's support played a pivotal role, with their obligations to Abyssinia as a member of the League.

On 23 June 1936, in the wake of the collapse of League efforts to restrain Italy's war against Abyssinia, the British Prime Minister, Stanley Baldwin, told the House of Commons that collective security had 

Ultimately, Britain and France both abandoned the concept of collective security in favour of appeasement in the face of growing German militarism under Hitler.
In this context, the League of Nations was also the institution where the first international debate on terrorism took place following the 1934 assassination of King Alexander I of Yugoslavia in Marseille, France, showing its conspiratorial features, many of which are detectable in the discourse of terrorism among states after 9/11.

American diplomatic historian Samuel Flagg Bemis originally supported the League, but after two decades changed his mind:

The League of Nations lacked an armed force of its own and depended on the Great Powers to enforce its resolutions, which they were very unwilling to do. Its two most important members, Britain and France, were reluctant to use sanctions and even more reluctant to resort to military action on behalf of the League. Immediately after the First World War, pacifism became a strong force among both the people and governments of the two countries. The British Conservatives were especially tepid to the League and preferred, when in government, to negotiate treaties without the involvement of that organisation. Moreover, the League's advocacy of disarmament for Britain, France, and its other members, while at the same time advocating collective security, meant that the League was depriving itself of the only forceful means by which it could uphold its authority.

When the British cabinet discussed the concept of the League during the First World War, Maurice Hankey, the Cabinet Secretary, circulated a memorandum on the subject. He started by saying, "Generally it appears to me that any such scheme is dangerous to us, because it will create a sense of security which is wholly fictitious". He attacked the British pre-war faith in the sanctity of treaties as delusional and concluded by claiming:

The Foreign Office minister Sir Eyre Crowe also wrote a memorandum to the British cabinet claiming that "a solemn league and covenant" would just be "a treaty, like other treaties". "What is there to ensure that it will not, like other treaties, be broken?" Crowe went on to express scepticism of the planned "pledge of common action" against aggressors because he believed the actions of individual states would still be determined by national interests and the balance of power. He also criticised the proposal for League economic sanctions because it would be ineffectual and that "It is all a question of real military preponderance". Universal disarmament was a practical impossibility, Crowe warned.

As the situation in Europe escalated into war, the Assembly transferred enough power to the Secretary General on 30 September 1938 and 14 December 1939 to allow the League to continue to exist legally and carry on reduced operations. The headquarters of the League, the Palace of Nations, remained unoccupied for nearly six years until the Second World War ended.

At the 1943 Tehran Conference, the Allied powers agreed to create a new body to replace the League: the United Nations. Many League bodies, such as the International Labour Organization, continued to function and eventually became affiliated with the UN. The designers of the structures of the United Nations intended to make it more effective than the League.

The final meeting of the League of Nations took place on 18 April 1946 in Geneva. Delegates from 34 nations attended the assembly. This session concerned itself with liquidating the League: it transferred assets worth approximately $22,000,000 (U.S.) in 1946 (including the Palace of Nations and the League's archives) to the UN, returned reserve funds to the nations that had supplied them, and settled the debts of the League. Robert Cecil, addressing the final session, said:
The Assembly passed a resolution that "With effect from the day following the close of the present session of the Assembly [i.e., April 19], the League of Nations shall cease to exist except for the sole purpose of the liquidation of its affairs as provided in the present resolution." A Board of Liquidation consisting of nine persons from different countries spent the next 15 months overseeing the transfer of the League's assets and functions to the United Nations or specialised bodies, finally dissolving itself on 31 July 1947.

The archive of the League of Nations was transferred to the United Nations Office at Geneva and is now an entry in the UNESCO Memory of the World Register.

In the past few decades, by research using the League Archives at Geneva, historians have reviewed the legacy of the League of Nations as the United Nations has faced similar troubles to those of the interwar period. Current consensus views that, even though the League failed to achieve its ultimate goal of world peace, it did manage to build new roads towards expanding the rule of law across the globe; strengthened the concept of collective security, giving a voice to smaller nations; helped to raise awareness to problems like epidemics, slavery, child labour, colonial tyranny, refugee crises and general working conditions through its numerous commissions and committees; and paved the way for new forms of statehood, as the mandate system put the colonial powers under international observation.

Professor David Kennedy portrays the League as a unique moment when international affairs were "institutionalised", as opposed to the pre–First World War methods of law and politics.

The principal Allies in the Second World War (the UK, the USSR, France, the U.S., and the Republic of China) became permanent members of the United Nations Security Council in 1946; in 1971, the People's Republic of China replaced the Republic of China (then only in control of Taiwan) as permanent member of the UN Security Council, and in 1991 the Russian Federation assumed the seat of the dissolved USSR.

Decisions of the Security Council are binding on all members of the UN, and unanimous decisions are not required, unlike in the League Council. Permanent members of the Security Council can wield a veto to protect their vital interests.








</doc>
<doc id="18053" url="https://en.wikipedia.org/wiki?curid=18053" title="Bodyline">
Bodyline

Bodyline, also known as fast leg theory bowling, was a cricketing tactic devised by the English cricket team for their 1932–33 Ashes tour of Australia, specifically to combat the extraordinary batting skill of Australia's Don Bradman. A bodyline delivery was one where the cricket ball was bowled at the body of the batsman, in the hope that when he defended himself with his bat, a resulting deflection could be caught by one of several fielders standing close by.

Critics considered the tactic intimidating and physically threatening, to the point of being unfair in a game that was supposed to uphold gentlemanly traditions. England's use of a tactic perceived by some as overly aggressive or even unfair ultimately threatened diplomatic relations between the two countries before the situation was calmed.

Although no serious injuries arose from any short-pitched deliveries while a leg theory field was actually set, the tactic still led to considerable ill feeling between the two teams, particularly when Australian batsmen suffered actual injuries in separate incidents, which inflamed the watching crowds. The controversy eventually spilled into the diplomatic arena.

Short-pitched bowling continues to be permitted in cricket, even when aimed at the batsman. However, over time, several of the Laws of Cricket were changed to render the bodyline tactic less effective.

Bodyline is a tactic devised for and primarily used in the Ashes series between England and Australia in 1932–33. The tactic involved bowling at leg stump or just outside it, pitching the ball short so that it reared at the body of a batsman standing in an orthodox batting position. A ring of fielders ranged on the leg side would catch any defensive deflection from the bat. The batsman's options were to evade the ball through ducking or moving aside, allow the ball to strike his body or play the ball with his bat. The last course carried additional risks. Defensive shots brought few runs and could carry far enough to be caught by the fielders on the leg side; pull and hook shots could be caught on the edge of the field where two men were usually placed for such a shot.

Bodyline bowling is intimidatory, and was largely designed as an attempt to curb the prolific scoring of Donald Bradman, although other prolific Australian batsmen such as Bill Woodfull, Bill Ponsford and Alan Kippax were also targeted.

Several different terms were used to describe this style of bowling before the name "bodyline" was used. Among the first to use it was the writer and former Australian Test cricketer Jack Worrall; in the match between the English team and an Australian XI, when bodyline was first used in full, he referred to "half-pitched slingers on the body line" and first used it in print after the first Test. Other writers used a similar phrase around this time, but the first use of "bodyline" in print seems to have been by the journalist Hugh Buggy in the Melbourne "Herald", in his report on the first day's play of the first Test.

In the 19th century, most cricketers considered it unsportsmanlike to bowl the ball at the leg stump or for batsmen to hit on the leg side. But by the early years of the 20th century, some bowlers, usually slow or medium-paced, used leg theory as a tactic; the ball was aimed outside the line of leg stump and the fielders placed on that side of the field, the object being to test the batsman's patience and force a rash stroke. Two English left-arm bowlers, George Hirst in 1903—04 and Frank Foster in 1911—12, bowled leg theory to packed leg side fields in Test matches in Australia; Warwick Armstrong used it regularly for Australia. In the years immediately before the First World War, several bowlers used leg theory in county cricket.

When cricket resumed after the war, few bowlers maintained the tactic, which was unpopular with spectators owing to its negativity. Fred Root, the Worcestershire bowler, used it regularly and with considerable success in county cricket. Root later defended the use of leg theory—and bodyline—observing that when bowlers bowled outside off stump, the batsmen were able to let the ball pass them without playing a shot.

Some fast bowlers experimented with leg theory prior to 1932, sometimes accompanying the tactic with short-pitched bowling. In 1925, Australian Jack Scott first bowled a form of what would later have been called bodyline in a state match for New South Wales; his captain Herbie Collins disliked it and would not let him use it again. Other Australian captains were less particular, including Vic Richardson who let Scott use those tactics when he moved to South Australia. He repeated them against the MCC in 1928–29. In 1927, in a Test trial match, "Nobby" Clark bowled short to a leg-trap (a cluster of fielders placed close on the leg side). He was representing England in a side captained by Douglas Jardine. In 1928–29, Harry Alexander bowled fast leg theory at an England team, and Harold Larwood briefly used a similar tactic on that same tour in two Test matches. Freddie Calthorpe, the England captain, criticised Learie Constantine's use of short-pitched bowling to a leg side field in a Test match in 1930; one such ball struck Andy Sandham, but Constantine only reverted to more conventional tactics after a complaint from the England team.

The Australian cricket team toured England in 1930. Australia won the five-Test series 2–1, and Donald Bradman scored 974 runs at a batting average of 139.14, an aggregate record that still stands. By the time of the next Ashes series of 1932–33, Bradman's average hovered around 100, approximately twice that of all other world-class batsmen. The English cricket authorities felt that new tactics would be required to prevent Bradman being even more successful on Australian pitches; some critics believed that Bradman could be dismissed by leg-spin as Walter Robins and Ian Peebles had supposedly caused him problems; two leg-spinners were included in the English touring party of 1932–33.

Gradually, the idea developed that Bradman was vulnerable to pace bowling. In the final Test of the 1930 Ashes series, while he was batting, the pitch became briefly difficult following rain. Bradman was seen to be uncomfortable facing deliveries which bounced higher than usual at a faster pace, being seen to step back out of the line of the ball. Former England player and Surrey captain Percy Fender was one who noticed, and the incident was much discussed by cricketers. Given that Bradman scored 232, it was not initially thought that a way to curb his prodigious scoring had been found. When Douglas Jardine later saw film footage of the Oval incident and noticed Bradman's discomfort, according to his daughter he shouted, "I've got it! He's yellow!" The theory of Bradman's vulnerability developed when Fender received correspondence from Australia in 1932, describing how Australian batsmen were increasingly moving across the stumps towards the off side to play the ball on the on side. Fender showed these letters to Jardine when it became clear that he was to captain the English team in Australia during the 1932–33 tour, and he also discussed Bradman's discomfort at the Oval. It was also known in England that Bradman was dismissed for a four-ball duck by fast bowler Eddie Gilbert, and looked very uncomfortable. Bradman had also appeared uncomfortable against the pace of Sandy Bell in his innings of 299 not out at the Adelaide Oval in South Africa's tour of Australia earlier in 1932, when the desperate bowler decided to bowl short to him, and fellow South African Herbie Taylor, according to Jack Fingleton, may have mentioned this to English cricketers in 1932. Fender felt Bradman might be vulnerable to fast, short-pitched deliveries on the line of leg stump. Jardine felt that Bradman was afraid to stand his ground against intimidatory bowling, citing instances in 1930 when he shuffled about, contrary to orthodox batting technique.

Jardine's first experience against Australia came when he scored an unbeaten 96 to secure a draw against the 1921 Australian touring side for Oxford University. The tourists were criticised in the press for not allowing Jardine to reach his hundred, but had tried to help him with some easy bowling. There has been speculation that this incident helped develop Jardine's antipathy towards Australians, although Jardine's biographer Christopher Douglas denies this. Jardine's attitude towards Australia hardened after he toured the country in 1928–29. When he scored three consecutive hundreds in the early games, he was frequently jeered by the crowd for slow play; the Australian spectators took an increasing dislike to him, mainly for his superior attitude and bearing, his awkward fielding, and particularly his choice of headwear—a Harlequin cap that was given to successful Oxford cricketers. Although Jardine may simply have worn the cap out of superstition, it conveyed a negative impression to the spectators; his general demeanour drew one comment of "Where's the butler to carry the bat for you?" By this stage Jardine had developed an intense dislike for Australian crowds. During his third century at the start of the tour, during a period of abuse from the spectators, he observed to Hunter Hendry that "All Australians are uneducated, and an unruly mob". After the innings, when teammate Patsy Hendren remarked that the Australian crowds did not like Jardine, he replied "It's fucking mutual". During the tour, Jardine fielded next to the crowd on the boundary. There, he was roundly abused and mocked for his awkward fielding, particularly when chasing the ball. On one occasion, he spat towards the crowd while fielding on the boundary as he changed position for the final time.

Jardine was appointed captain of England for the 1931 season, replacing Percy Chapman who had led the team in 1930. He defeated New Zealand in his first series, but opinion was divided as to how effective he had been. The following season, he led England again and was appointed to lead the team to tour Australia for the 1932–33 Ashes series. A meeting was arranged between Jardine, Nottinghamshire captain Arthur Carr and his two fast bowlers Harold Larwood and Bill Voce at London's Piccadilly Hotel to discuss a plan to combat Bradman. Jardine asked Larwood and Voce if they could bowl on leg stump and make the ball rise into the body of the batsman. The bowlers agreed they could, and that it might prove effective. Jardine also visited Frank Foster to discuss his field-placing in Australia in 1911–12.

Larwood and Voce practised the plan over the remainder of the 1932 season with varying but increasing success and several injuries to batsmen. Ken Farnes experimented with short-pitched, leg-theory bowling but was not selected for the tour. Bill Bowes also used short-pitched bowling, notably against Jack Hobbs.

The England team which toured Australia in 1932–33 contained four fast bowlers and a few medium pacers; such a heavy concentration on pace was unusual at the time, and drew comment from the Australian press and players, including Bradman. On the journey, Jardine instructed his team on how to approach the tour and discussed tactics with several players, including Larwood; at this stage, he seems to have settled on leg theory, if not full bodyline, as his main tactic. Some players later reported that he told them to hate the Australians in order to defeat them, while instructing them to refer to Bradman as "the little bastard." Upon arrival, Jardine quickly alienated the press and crowds through his manner and approach.

In the early matches, although there were instances of the English bowlers pitching the ball short and causing problems with their pace, full bodyline tactics were not used. There had been little unusual about the English bowling except the number of fast bowlers. Larwood and Voce were given a light workload in the early matches by Jardine. The English tactics changed in a game against an Australian XI team at Melbourne in mid-November, when full bodyline tactics were deployed for the first time. Jardine had left himself out of the English side, which was led instead by Bob Wyatt who later wrote that the team experimented with a diluted form of bodyline bowling. He reported to Jardine that Bradman, who was playing for the opposition, seemed uncomfortable against the bowling tactics of Larwood, Voce and Bowes. The crowd, press and Australian players were shocked by what they experienced and believed that the bowlers were targeting the batsmen's heads. Bradman adopted unorthodox tactics—ducking, weaving and moving around the crease—which did not meet with universal approval from Australians and he scored just 36 and 13 in the match.

The tactic continued to be used in the next game by Voce (Larwood and Bowes did not play in this game), against New South Wales, for whom Jack Fingleton made a century and received several blows in the process. Bradman again failed twice, and had scored just 103 runs in six innings against the touring team; many Australian fans were now worried by Bradman's form. Meanwhile, Jardine wrote to tell Fender that his information about the Australian batting technique was correct and that it meant he was having to move more and more fielders onto the leg side: "if this goes on I shall have to move the whole bloody lot to the leg side."

The Australian press were shocked and criticised the hostility of Larwood in particular. Some former Australian players joined the criticism, saying the tactics were ethically wrong. But at this stage, not everyone was opposed, and the Australian Board of Control believed the English team had bowled fairly. On the other hand, Jardine increasingly came into disagreement with tour manager Warner over bodyline as the tour progressed. Warner hated bodyline but would not speak out against it. He was accused of hypocrisy for not taking a stand on either side, particularly after expressing sentiments at the start of the tour that cricket "has become a synonym for all that is true and honest. To say 'that is not cricket' implies something underhand, something not in keeping with the best ideals ... all who love it as players, as officials or spectators must be careful lest anything they do should do it harm."

Bradman missed the first Test at Sydney, worn out by constant cricket and the ongoing argument with the Board of Control. Jardine later wrote that the real reason was that the batsman had suffered a nervous breakdown. The English bowlers used bodyline intermittently in the first match, to the crowd's vocal displeasure, and the Australians lost the game by ten wickets. Larwood was particularly successful, returning match figures of ten wickets for 124 runs. One of the English bowlers, Gubby Allen, refused to bowl with fielders on the leg side, clashing with Jardine over these tactics. The only Australian batsman to make an impact was Stan McCabe, who hooked and pulled everything aimed at his upper body, to score 187 not out in four hours from 233 deliveries. Behind the scenes, administrators began to express concerns to each other. Yet the English tactics still did not earn universal disapproval; former Australian captain Monty Noble praised the English bowling.

Meanwhile, Woodfull was being encouraged to retaliate to the short-pitched English attack, not least by members of his own side such as Vic Richardson, or to include pace bowlers such as Eddie Gilbert or Laurie Nash to match the aggression of the opposition. But Woodfull refused to consider doing so. He had to wait until minutes before the game before he was confirmed as captain by the selectors.

For the second Test, Bradman returned to the team after his newspaper employers released him from his contract. England continued to use bodyline and Bradman was dismissed by his first ball in the first innings. In the second innings, against the full bodyline attack, he scored an unbeaten century which helped Australia to win the match and level the series at one match each. Critics began to believe bodyline was not quite the threat that had been perceived and Bradman's reputation, which had suffered slightly with his earlier failures, was restored. However, the pitch was slightly slower than others in the series, and Larwood was suffering from problems with his boots which reduced his effectiveness.

The controversy reached its peak during the Third Test at Adelaide. On the second day, a Saturday, before a crowd of 50,962 spectators, Australia bowled out England who had batted through the first day. In the third over of the Australian innings, Larwood bowled to Woodfull. The fifth ball narrowly missed Woodfull's head and the final ball, delivered short on the line of middle stump, struck Woodfull over the heart. The batsman dropped his bat and staggered away holding his chest, bent over in pain. The England players surrounded Woodfull to offer sympathy but the crowd began to protest noisily. Jardine called to Larwood: "Well bowled, Harold!" Although the comment was aimed at unnerving Bradman, who was also batting at the time, Woodfull was appalled. Play resumed after a brief delay, once it was certain the Australian captain was fit to carry on and, since Larwood's over had ended, Woodfull did not have to face the bowling of Allen in the next over. However, when Larwood was ready to bowl at Woodfull again, play was halted once more when the fielders were moved into bodyline positions, causing the crowd to protest and call abuse at the England team. Subsequently, Jardine claimed that Larwood requested a field change, Larwood said that Jardine had done so. Many commentators condemned the alteration of the field as unsporting, and the angry spectators became extremely volatile. Jardine, although writing that Woodfull could have retired hurt if he was unfit, later expressed his regret at making the field change at that moment. The fury of the crowd was such that a riot may have occurred had another incident taken place and several writers suggested that the anger of the spectators was the culmination of feelings built up over the two months that bodyline had developed.

During the over, another rising Larwood delivery knocked the bat out of Woodfull's hands. He batted for 89 minutes, being hit a few more times before Allen bowled him for 22. Later in the day, Pelham Warner, one of the England managers, visited the Australian dressing room. He expressed sympathy to Woodfull but was surprised by the Australian's response. According to Warner, Woodfull replied, "I don't want to see you, Mr Warner. There are two teams out there. One is trying to play cricket and the other is not." Fingleton wrote that Woodfull had added, "This game is too good to be spoilt. It is time some people got out of it." Woodfull was usually dignified and quietly spoken, making his reaction surprising to Warner and others present. Warner was so shaken that he was found in tears later that day in his hotel room.

There was no play on the following day, Sunday being a rest day, but on Monday morning, the exchange between Warner and Woodfull was reported in several Australian newspapers. The players and officials were horrified that a sensitive private exchange had been reported to the press. Leaks to the press were practically unknown in 1933. David Frith notes that discretion and respect were highly prized and such a leak was "regarded as a moral offence of the first order." Woodfull made it clear that he severely disapproved of the leak, and later wrote that he "always expected cricketers to do the right thing by their team-mates." As the only full-time journalist in the Australian team, suspicion immediately fell on Fingleton, although as soon as the story was published, he told Woodfull he was not responsible. Warner offered Larwood a reward of one pound if he could dismiss Fingleton in the second innings; Larwood obliged by bowling him for a duck. Fingleton later claimed that Sydney Sun reporter Claude Corbett had received the information from Bradman; for the rest of their lives, Fingleton and Bradman made claim and counter-claim that the other man was responsible for the leak.
The following day, as Australia faced a large deficit on the first innings, Bert Oldfield played a long innings in support of Bill Ponsford, who scored 85. In the course of the innings, the English bowlers used bodyline against him, and he faced several short-pitched deliveries but took several fours from Larwood to move to 41. Having just conceded a four, Larwood bowled fractionally shorter and slightly slower. Oldfield attempted to hook but lost sight of the ball and edged it onto his temple; the ball fractured his skull. Oldfield staggered away and fell to his knees and play stopped as Woodfull came onto the pitch and the angry crowd jeered and shouted, once more reaching the point where a riot seemed likely. Several English players thought about arming themselves with stumps should the crowd come onto the field. The ball which injured Oldfield was bowled to a conventional, non-bodyline field; Larwood immediately apologised but Oldfield said that it was his own fault before he was helped back to the dressing room and play continued. Jardine later secretly sent a telegram of sympathy to Oldfield's wife and arranged for presents to be given to his young daughters.

At the end of the fourth day's play of the third Test match, the Australian Board of Control sent a cable to the Marylebone Cricket Club (MCC), cricket's ruling body and the club that selected the England team, in London:

Not all Australians, including the press and players, believed that the cable should have been sent, particularly immediately following a heavy defeat. The suggestion of unsportsmanlike behaviour was deeply resented by the MCC, and was one of the worst accusations that could have been levelled at the team at the time. Additionally, members of the MCC believed that the Australians had over-reacted to the English bowling. The MCC took some time to draft a reply:

At this point, the remainder of the series was under threat. Jardine was shaken by the events and by the hostile reactions to his team. Stories appeared in the press, possibly leaked by the disenchanted Nawab of Pataudi, about fights and arguments between the England players. Jardine offered to stop using bodyline if the team did not support him, but after a private meeting (not attended by Jardine or either of the team managers) the players released a statement fully supporting the captain and his tactics. Even so, Jardine would not have played in the fourth Test without the withdrawal of the unsportsmanlike accusation.

The Australian Board met to draft a reply cable, which was sent on 30 January, indicating that they wished the series to continue and offering to postpone consideration of the fairness of bodyline bowling until after the series. The MCC's reply, on 2 February, suggested that continuing the series would be impossible unless the accusation of unsporting behaviour was withdrawn.

The situation escalated into a diplomatic incident. Figures high up in both the British and Australian government saw bodyline as potentially fracturing an international relationship that needed to remain strong. The Governor of South Australia, Alexander Hore-Ruthven, who was in England at the time, expressed his concern to British Secretary of State for Dominion Affairs James Henry Thomas that this would cause a significant impact on trade between the nations. The standoff was settled when the Australian prime minister, Joseph Lyons, met with members of the Australian Board and outlined to them the severe economic hardships that could be caused in Australia if the British public boycotted Australian trade. Following considerable discussion and debate in the English and Australian press, the Australian Board sent a cable to the MCC which, while maintaining its opposition to bodyline bowling, stated "We do not regard the sportsmanship of your team as being in question". Even so, correspondence between the Australian Board and the MCC continued for almost a year.

Voce missed the fourth Test of the series, being replaced by a leg spinner, Tommy Mitchell. Larwood continued to use bodyline, but he was the only bowler in the team using the tactic; even so, he used it less frequently than usual and seemed less effective in high temperatures and humidity. England won the game by eight wickets, thanks in part to an innings of 83 by Eddie Paynter who had been admitted to hospital with tonsillitis but left in order to bat when England were struggling in their innings. Voce returned for the final Test, but neither he nor Allen were fully fit, and despite the use of bodyline tactics, Australia scored 435 at a rapid pace, aided by several dropped catches. Australia included a fast bowler for this final game, Harry Alexander who bowled some short deliveries but was not allowed to use many fielders on the leg side by his captain, Woodfull. England built a lead of 19 but their tactics in Australia's second innings were disrupted when Larwood left the field with an injured foot; Hedley Verity, a spinner, claimed five wickets to bowl Australia out; England won by eight wickets and won the series by four Tests to one.

Bodyline continued to be bowled occasionally in the 1933 English season—most notably by Nottinghamshire, who had Carr, Voce and Larwood in their team. This gave the English crowds their first chance to see what all the fuss was about. Ken Farnes, the Cambridge University fast bowler, also bowled it in the University Match, hitting a few Oxford batsmen.

Jardine himself had to face bodyline bowling in a Test match. The West Indian cricket team toured England in 1933, and, in the second Test at Old Trafford, Jackie Grant, their captain, decided to try bodyline. He had a couple of fast bowlers, Manny Martindale and Learie Constantine. Facing bodyline tactics for the first time, England first suffered, falling to 134 for 4, with Wally Hammond being hit on the chin, though he recovered to continue his innings. Then Jardine himself faced Martindale and Constantine. Jardine never flinched. With Les Ames finding himself in difficulties, Jardine said, "You get yourself down this end, Les. I'll take care of this bloody nonsense." He played right back to the bouncers, standing on tiptoe, and played them with a dead bat, sometimes playing the ball one handed for more control. While the Old Trafford pitch was not as suited to bodyline as the hard Australian wickets, Martindale did take 5 for 73, but Constantine only took 1 for 55. Jardine himself made 127, his only Test century. In the West Indian second innings, Clark bowled bodyline back to the West Indians, taking 2 for 64. The match in the end was drawn but played a large part in turning English opinion against bodyline. "The Times" used the word bodyline, without using inverted commas or using the qualification "so-called", for the first time. "Wisden" also said that "most of those watching it for the first time must have come to the conclusion that, while strictly within the law, it was not nice."

In 1934, Bill Woodfull led Australia back to England on a tour that had been under a cloud after the tempestuous cricket diplomacy of the previous bodyline series. Jardine had retired from International cricket in early 1934 after captaining a fraught tour of India and under England's new captain, Bob Wyatt, agreements were put in place so that bodyline would not be used. However, there were occasions when the Australians felt that their hosts had crossed the mark with tactics resembling bodyline.

In a match between the Australians and Nottinghamshire, Voce, one of the bodyline practitioners of 1932–33, employed the strategy with the wicket-keeper standing to the leg side and took 8/66. In the second innings, Voce repeated the tactic late in the day, in fading light against Woodfull and Bill Brown. Of his 12 balls, 11 were no lower than head height. Woodfull told the Nottinghamshire administrators that, if Voce's leg-side bowling was repeated, his men would leave the field and return to London. He further said that Australia would not return to the country in the future. The following day, Voce was absent, ostensibly due to a leg injury. Already angered by the absence of Larwood, the Nottinghamshire faithful heckled the Australians all day. Australia had previously and privately complained that some pacemen had strayed past the agreement in the Tests.

As a direct consequence of the 1932–33 tour, the MCC introduced a new rule to the laws of cricket for the 1935 English cricket season. Originally, the MCC hoped that captains would ensure that the game was played in the correct spirit, and passed a resolution that bodyline bowling would breach this spirit. When this proved to be insufficient, the MCC passed a law that "direct attack" bowling was unfair and became the responsibility of the umpires to identify and stop. In 1957, the laws were altered to prevent more than two fielders standing behind square on the leg side; the intention was to prevent negative bowling tactics whereby off spinners and slow inswing bowlers aimed at the leg stump of batsmen with fielders concentrated on the leg side. However, an indirect effect was to make bodyline fields impossible to implement.

Later law changes, under the heading of "Intimidatory Short Pitched Bowling", also restricted the number of "bouncers" which may be bowled in an over. Nevertheless, the tactic of intimidating the batsman is still used to an extent that would have been shocking in 1933, although it is less dangerous now because today's players wear helmets and generally far more protective gear. The West Indies teams of the 1980s, who regularly fielded a bowling attack comprising some of the best fast bowlers in cricket history, were perhaps the most feared exponents.

The English players and management were consistent in referring to their tactic as "fast leg theory" considering it to be a variant of the established and unobjectionable leg theory tactic. The inflammatory term "bodyline" was coined and perpetuated by the Australian press (see below). English writers used the term "fast leg theory". The terminology reflected differences in understanding, as neither the English public nor the Board of the Marylebone Cricket Club (MCC)—the governing body of English cricket—could understand why the Australians were complaining about what they perceived as a commonly used tactic. Some concluded that the Australian cricket authorities and public were sore losers. Of the four fast bowlers in the tour party, Gubby Allen was a voice of dissent in the English camp, refusing to bowl short on the leg side, and writing several letters home to England critical of Jardine, although he did not express this in public in Australia. A number of other players, while maintaining a united front in public, also deplored bodyline in private. The amateurs Bob Wyatt (the vice-captain), Freddie Brown and the Nawab of Pataudi opposed it, as did Wally Hammond and Les Ames among the professionals.

During the season, Woodfull's physical courage, stoic and dignified leadership won him many admirers. He flatly refused to employ retaliatory tactics and did not publicly complain even though he and his men were repeatedly hit.

Jardine however insisted his tactic was not designed to cause injury and that he was leading his team in a sportsmanlike and gentlemanly manner, arguing that it was up to the Australian batsmen to play their way out of trouble.

It was subsequently revealed that several of the players had private reservations, but they did not express them publicly at the time.

Following the 1932–33 series, several authors, including many of the players involved, released books expressing various points of view about bodyline. Many argued that it was a scourge on cricket and must be stamped out, while some did not see what all the fuss was about. The series has been described as the most controversial period in Australian cricket history, and voted the most important Australian moment by a panel of Australian cricket identities. The MCC asked Harold Larwood to sign an apology to them for his bowling in Australia, making his selection for England again conditional upon it. Larwood was furious at the notion, pointing out that he had been following orders from his upper-class captain, and that was where any blame should lie. Larwood refused, never played for England again, and became vilified in his own country. Douglas Jardine always defended his tactics and in the book he wrote about the tour, "In Quest of the Ashes", described allegations that the England bowlers directed their attack with the intention of causing physical harm as stupid and patently untruthful. The immediate effect of the law change which banned bodyline in 1935 was to make commentators and spectators sensitive to the use of short-pitched bowling; bouncers became exceedingly rare and bowlers who delivered them were practically ostracised. This attitude ended after the Second World War, and among the first teams to make extensive use of short-pitched bowling was the Australian team captained by Bradman between 1946 and 1948. Other teams soon followed.

Outside the sport, there were significant consequences for Anglo-Australian relations, which remained strained until the outbreak of World War II made cooperation paramount. Business between the two countries was adversely affected as citizens of each country avoided goods manufactured in the other. Australian commerce also suffered in British colonies in Asia: the "North China Daily News" published a pro-bodyline editorial, denouncing Australians as sore losers. An Australian journalist reported that several business deals in Hong Kong and Shanghai were lost by Australians because of local reactions. English immigrants in Australia found themselves shunned and persecuted by locals, and Australian visitors to England were treated similarly. In 1934–35 a statue of Prince Albert in Sydney was vandalised, with an ear being knocked off and the word "BODYLINE" painted on it. Both before and after World War II, numerous satirical cartoons and comedy skits were written, mostly in Australia, based on events of the bodyline tour. Generally, they poked fun at the English.

In 1984, Australia's Network Ten produced a television mini-series titled "Bodyline", dramatising the events of the 1932–33 English tour of Australia. It starred Gary Sweet as Don Bradman, Hugo Weaving as Douglas Jardine, Jim Holt as Harold Larwood, Rhys McConnochie as Pelham Warner, and Frank Thring as Jardine's mentor Lord Harris. The series took some liberties with historical accuracy for the sake of drama, including a depiction of angry Australian fans burning a British flag at the Sydney Cricket Ground, an event which was never documented. Larwood, having emigrated to Australia in 1950, received several threatening and obscene phone calls after the series aired. The series was widely and strongly attacked by the surviving players for its inaccuracy and sensationalism.

To this day, the bodyline tour remains one of the most significant events in the history of cricket, and strong in the consciousness of many cricket followers. In a poll of cricket journalists, commentators, and players in 2004, the bodyline tour was ranked the most important event in cricket history.




</doc>
<doc id="18119" url="https://en.wikipedia.org/wiki?curid=18119" title="Liverpool F.C.">
Liverpool F.C.

Liverpool Football Club is a professional football club in Liverpool, England, that competes in the Premier League, the top tier of English football. The club has won 5 European Cups, more than any other English club, 3 UEFA Cups, 3 UEFA Super Cups, 18 League titles, 7 FA Cups, a record 8 League Cups, and 15 FA Community Shields.

Founded in 1892, the club joined the Football League the following year and has played at Anfield since its formation. Liverpool established itself as a major force in English and European football in the 1970s and 1980s when Bill Shankly and Bob Paisley led the club to 11 League titles and seven European trophies. Under the management of Rafael Benítez and captained by Steven Gerrard, Liverpool became European champions for the fifth time in 2005.

Liverpool was the ninth highest-earning football club in the world in 2016–17, with an annual revenue of €424.2 million, and the world's eighth most valuable football club in 2018, valued at $1.944 billion. The club is one of the best supported teams in the world. Liverpool has long-standing rivalries with Manchester United and Everton. 

The club's supporters have been involved in two major tragedies: the Heysel Stadium disaster, where escaping fans were pressed against a collapsing wall at the 1985 European Cup Final in Brussels, with 39 people – mostly Italians and Juventus fans – dying, after which English clubs were given a five-year ban from European competition, and the Hillsborough disaster in 1989, where 96 Liverpool supporters died in a crush against perimeter fencing.

The team changed from red shirts and white shorts to an all-red home strip in 1964 which has been used ever since. The club's anthem is "You'll Never Walk Alone".

Liverpool F.C. was founded following a dispute between the Everton committee and John Houlding, club president and owner of the land at Anfield. After eight years at the stadium, Everton relocated to Goodison Park in 1892 and Houlding founded Liverpool F.C. to play at Anfield. Originally named "Everton F.C. and Athletic Grounds Ltd" (Everton Athletic for short), the club became Liverpool F.C. in March 1892 and gained official recognition three months later, after The Football Association refused to recognise the club as Everton. The team won the Lancashire League in its début season, and joined the Football League Second Division at the start of the 1893–94 season. After finishing in first place the club was promoted to the First Division, which it won in 1901 and again in 1906.

Liverpool reached its first FA Cup Final in 1914, losing 1–0 to Burnley. It won consecutive League championships in 1922 and 1923, but did not win another trophy until the 1946–47 season, when the club won the First Division for a fifth time under the control of ex-West Ham Utd centre half George Kay. Liverpool suffered its second Cup Final defeat in 1950, playing against Arsenal. The club was relegated to the Second Division in the 1953–54 season. Soon after Liverpool lost 2–1 to non-league Worcester City in the 1958–59 FA Cup, Bill Shankly was appointed manager. Upon his arrival he released 24 players and converted a boot storage room at Anfield into a room where the coaches could discuss strategy; here, Shankly and other "Boot Room" members Joe Fagan, Reuben Bennett, and Bob Paisley began reshaping the team.

The club was promoted back into the First Division in 1962 and won it in 1964, for the first time in 17 years. In 1965, the club won its first FA Cup. In 1966, the club won the First Division but lost to Borussia Dortmund in the European Cup Winners' Cup final. Liverpool won both the League and the UEFA Cup during the 1972–73 season, and the FA Cup again a year later. Shankly retired soon afterwards and was replaced by his assistant, Bob Paisley. In 1976, Paisley's second season as manager, the club won another League and UEFA Cup double. The following season, the club retained the League title and won the European Cup for the first time, but it lost in the 1977 FA Cup Final. Liverpool retained the European Cup in 1978 and regained the First Division title in 1979. During Paisley's nine seasons as manager Liverpool won 21 trophies, including three European Cups, a UEFA Cup, six League titles and three consecutive League Cups; the only domestic trophy he did not win was the FA Cup.

Paisley retired in 1983 and was replaced by his assistant, Joe Fagan. Liverpool won the League, League Cup and European Cup in Fagan's first season, becoming the first English side to win three trophies in a season. Liverpool reached the European Cup final again in 1985, against Juventus at the Heysel Stadium. Before kick-off, Liverpool fans breached a fence which separated the two groups of supporters, and charged the Juventus fans. The resulting weight of people caused a retaining wall to collapse, killing 39 fans, mostly Italians. The incident became known as the Heysel Stadium disaster. The match was played in spite of protests by both managers, and Liverpool lost 1–0 to Juventus. As a result of the tragedy, English clubs were banned from participating in European competition for five years; Liverpool received a ten-year ban, which was later reduced to six years. Fourteen Liverpool fans received convictions for involuntary manslaughter.

Fagan had announced his retirement just before the disaster and Kenny Dalglish was appointed as player-manager. During his tenure, the club won another three league titles and two FA Cups, including a League and Cup "Double" in the 1985–86 season. Liverpool's success was overshadowed by the Hillsborough disaster: in an FA Cup semi-final against Nottingham Forest on 15 April 1989, hundreds of Liverpool fans were crushed against perimeter fencing. Ninety-four fans died that day; the 95th victim died in hospital from his injuries four days later and the 96th died nearly four years later, without regaining consciousness. After the Hillsborough disaster there was a government review of stadium safety. The resulting Taylor Report paved the way for legislation that required top-division teams to have all-seater stadiums. The report ruled that the main reason for the disaster was overcrowding due to a failure of police control.

Liverpool was involved in the closest finish to a league season during the 1988–89 season. Liverpool finished equal with Arsenal on both points and goal difference, but lost the title on total goals scored when Arsenal scored the final goal in the last minute of the season.

Dalglish cited the Hillsborough disaster and its repercussions as the reason for his resignation in 1991; he was replaced by former player Graeme Souness. Under his leadership Liverpool won the 1992 FA Cup Final, but their league performances slumped, with two consecutive sixth-place finishes, eventually resulting in his dismissal in January 1994. Souness was replaced by Roy Evans, and Liverpool went on to win the 1995 Football League Cup Final. While they made some title challenges under Evans, third-place finishes in 1996 and 1998 were the best they could manage, and so Gérard Houllier was appointed co-manager in the 1998–99 season, and became the sole manager in November 1998 after Evans resigned. In 2001, Houllier's second full season in charge, Liverpool won a "Treble": the FA Cup, League Cup and UEFA Cup. Houllier underwent major heart surgery during the 2001–02 season and Liverpool finished second in the League, behind Arsenal. They won a further League Cup in 2003, but failed to mount a title challenge in the two seasons that followed.

Houllier was replaced by Rafael Benítez at the end of the 2003–04 season. Despite finishing fifth in Benítez's first season, Liverpool won the 2004–05 UEFA Champions League, beating A.C. Milan 3–2 in a penalty shootout after the match ended with a score of 3–3. The following season, Liverpool finished third in the Premier League and won the 2006 FA Cup Final, beating West Ham United in a penalty shootout after the match finished 3–3. American businessmen George Gillett and Tom Hicks became the owners of the club during the 2006–07 season, in a deal which valued the club and its outstanding debts at £218.9 million. The club reached the 2007 UEFA Champions League Final against Milan, as it had in 2005, but lost 2–1. During the 2008–09 season Liverpool achieved 86 points, its highest Premier League points total, and finished as runners up to Manchester United.

In the 2009–10 season, Liverpool finished seventh in the Premier League and failed to qualify for the Champions League. Benítez subsequently left by mutual consent and was replaced by Fulham manager Roy Hodgson. At the start of the 2010–11 season Liverpool was on the verge of bankruptcy and the club's creditors asked the High Court to allow the sale of the club, overruling the wishes of Hicks and Gillett. John W. Henry, owner of the Boston Red Sox and of Fenway Sports Group, bid successfully for the club and took ownership in October 2010. Poor results during the start of that season led to Hodgson leaving the club by mutual consent and former player and manager Kenny Dalglish taking over. In the 2011–12 season, Liverpool secured a record 8th League Cup success and reached the FA Cup final, but finished in eighth position, the worst league finish in 18 years; this led to the sacking of Dalglish. He was replaced by Brendan Rodgers, whose Liverpool team in the 2013–14 season mounted an unexpected title charge to finish second behind champions Manchester City and subsequently return to the Champions League, scoring 101 goals in the process, the most since the 106 scored in the 1895–96 season. Following a disappointing 2014–15 season, where Liverpool finished sixth in the league, and a poor start to the following campaign, Rodgers was sacked in October 2015. He was replaced by Jürgen Klopp, who in his first season at Liverpool, took the club to the finals of both the Football League Cup and UEFA Europa League, finishing as runner-up in both competitions.
For much of Liverpool's history its home colours have been all red, but when the club was founded its kit was more like the contemporary Everton kit. The blue and white quartered shirts were used until 1894, when the club adopted the city's colour of red. The city's symbol of the liver bird was adopted as the club's badge in 1901, although it was not incorporated into the kit until 1955. Liverpool continued to wear red shirts and white shorts until 1964, when manager Bill Shankly decided to change to an all red strip. Liverpool played in all red for the first time against Anderlecht, as Ian St. John recalled in his autobiography:

The Liverpool away strip has more often than not been all yellow or white shirts and black shorts, but there have been several exceptions. An all grey kit was introduced in 1987, which was used until the 1991–92 centenary season, when it was replaced by a combination of green shirts and white shorts. After various colour combinations in the 1990s, including gold and navy, bright yellow, black and grey, and ecru, the club alternated between yellow and white away kits until the 2008–09 season, when it re-introduced the grey kit. A third kit is designed for European away matches, though it is also worn in domestic away matches on occasions when the current away kit clashes with a team's home kit. Between 2012–15, the kits were designed by Warrior Sports, who became the club's kit providers at the start of the 2012–13 season. In February 2015, Warrior's parent company New Balance announced it would be entering the global football market, with teams sponsored by Warrior now being outfitted by New Balance. The only other branded shirts worn by the club were made by Umbro until 1985, when they were replaced by Adidas, who produced the kits until 1996 when Reebok took over. They produced the kits for 10 years before Adidas made the kits from 2006 to 2012.

Liverpool was the first English professional club to have a sponsor's logo on its shirts, after agreeing a deal with Hitachi in 1979. Since then the club has been sponsored by Crown Paints, Candy, Carlsberg and Standard Chartered. The contract with Carlsberg, which was signed in 1992, was the longest-lasting agreement in English top-flight football. The association with Carlsberg ended at the start of the 2010–11 season, when Standard Chartered Bank became the club's sponsor.

The Liverpool badge is based on the city's liver bird, which in the past had been placed inside a shield. In 1992, to commemorate the centennial of the club, a new badge was commissioned, including a representation of the Shankly Gates. The next year twin flames were added at either side, symbolic of the Hillsborough memorial outside Anfield, where an eternal flame burns in memory of those who died in the Hillsborough disaster. In 2012, Warrior Sports' first Liverpool kit removed the shield and gates, returning the badge to what had adorned Liverpool shirts in the 1970s; the flames were moved to the back collar of the shirt, surrounding the number 96 for the number who died at Hillsborough.

Anfield was built in 1884 on land adjacent to Stanley Park. It was originally used by Everton before the club moved to Goodison Park after a dispute over rent with Anfield owner John Houlding. Left with an empty ground, Houlding founded Liverpool in 1892 and the club has played at Anfield ever since. The capacity of the stadium at the time was 20,000, although only 100 spectators attended Liverpool's first match at Anfield.

The Kop was built in 1906 due to the high turnout for matches and was called the Oakfield Road Embankment initially. Its first game was on 1 September 1906 when the home side beat Stoke City 1–0. In 1906 the banked stand at one end of the ground was formally renamed the Spion Kop after a hill in KwaZulu-Natal. The hill was the site of the Battle of Spion Kop in the Second Boer War, where over 300 men of the Lancashire Regiment died, many of them from Liverpool. At its peak, the stand could hold 28,000 spectators and was one of the largest single-tier stands in the world. Many stadia in England had stands named after Spion Kop, but Anfield's was the largest of them at the time; it could hold more supporters than some entire football grounds.

Anfield could accommodate more than 60,000 supporters at its peak, and had a capacity of 55,000 until the 1990s. The Taylor Report and Premier League regulations obliged Liverpool to convert Anfield to an all-seater stadium in time for the 1993–94 season, reducing the capacity to 45,276. The findings of the "Taylor Report" precipitated the redevelopment of the Kemlyn Road Stand, which was rebuilt in 1992, coinciding with the centenary of the club, and was known as the Centenary Stand until 2017 when it was renamed the Kenny Dalglish Stand. An extra tier was added to the Anfield Road end in 1998, which further increased the capacity of the ground but gave rise to problems when it was opened. A series of support poles and stanchions were inserted to give extra stability to the top tier of the stand after movement of the tier was reported at the start of the 1999–2000 season.

Because of restrictions on expanding the capacity at Anfield, Liverpool announced plans to move to the proposed Stanley Park Stadium in May 2002. Planning permission was granted in July 2004, and in September 2006, Liverpool City Council agreed to grant Liverpool a 999-year lease on the proposed site. Following the takeover of the club by George Gillett and Tom Hicks in February 2007, the proposed stadium was redesigned. The new design was approved by the Council in November 2007. The stadium was scheduled to open in August 2011 and would hold 60,000 spectators, with HKS, Inc. contracted to build the stadium. Construction was halted in August 2008, as Gillett and Hicks had difficulty in financing the £300 million needed for the development. In October 2012, BBC Sport reported that Fenway Sports Group, the new owners of Liverpool FC, had decided to redevelop their current home at Anfield stadium, rather than building a new stadium in Stanley Park. As part of the redevelopment the capacity of Anfield was to increase from 45,276 to approximately 60,000 and would cost approximately £150m. When construction was completed on the new Main stand the capacity of Anfield was increased to 54,074. This £100 million expansion added a third tier to the stand. This was all part of a £260 million project to improve the Anfield area. Jurgen Klopp the manager at the time described the stand as "impressive."

Liverpool is one of the best supported clubs in the world. The club states that its worldwide fan base includes more than 200 officially recognised Club of the LFC Official Supporters Clubs in at least 50 countries. Notable groups include Spirit of Shankly. The club takes advantage of this support through its worldwide summer tours, which has included playing in front of 101,000 in Michigan, U.S., and 95,000 in Melbourne, Australia. Liverpool fans often refer to themselves as Kopites, a reference to the fans who once stood, and now sit, on the Kop at Anfield. In 2008 a group of fans decided to form a splinter club, A.F.C. Liverpool, to play matches for fans who had been priced out of watching Premier League football.

The song "You'll Never Walk Alone", originally from the Rodgers and Hammerstein musical "Carousel" and later recorded by Liverpool musicians Gerry and the Pacemakers, is the club's anthem and has been sung by the Anfield crowd since the early 1960s. It has since gained popularity among fans of other clubs around the world. The song's title adorns the top of the Shankly Gates, which were unveiled on 2 August 1982 in memory of former manager Bill Shankly. The "You'll Never Walk Alone" portion of the Shankly Gates is also reproduced on the club's crest.

The club's supporters have been involved in two stadium disasters. The first was the 1985 Heysel Stadium disaster, in which 39 Juventus supporters were killed. They were confined to a corner by Liverpool fans who had charged in their direction; the weight of the cornered fans caused a wall to collapse. UEFA laid the blame for the incident solely on the Liverpool supporters, and banned all English clubs from European competition for five years. Liverpool was banned for an additional year, preventing it from participating in the 1990–91 European Cup, even though it won the League in 1990. Twenty-seven fans were arrested on suspicion of manslaughter and were extradited to Belgium in 1987 to face trial. In 1989, after a five-month trial in Belgium, 14 Liverpool fans were given three-year sentences for involuntary manslaughter; half of the terms were suspended.

The second disaster took place during an FA Cup semi-final between Liverpool and Nottingham Forest at Hillsborough Stadium, Sheffield, on 15 April 1989. Ninety-six Liverpool fans died as a consequence of overcrowding at the Leppings Lane end, in what became known as the Hillsborough disaster. In the following days "The Sun" newspaper published an article entitled "The Truth", in which it claimed that Liverpool fans had robbed the dead and had urinated on and attacked the police. Subsequent investigations proved the allegations false, leading to a boycott of the newspaper by Liverpool fans across the city and elsewhere; many still refuse to buy "The Sun" more than 20 years later. Many support organisations were set up in the wake of the disaster, such as the Hillsborough Justice Campaign, which represents bereaved families, survivors and supporters in their efforts to secure justice.

Liverpool's longest-established rivalry is with fellow Liverpool team Everton, against whom they contest the Merseyside derby. The rivalry stems from Liverpool's formation and the dispute with Everton officials and the then owners of Anfield. The Merseyside derby is one of the few local derbies which do not enforce fan segregation, and hence has been known as the "friendly derby". Since the mid-1980s, the rivalry has intensified both on and off the field and, since the inception of the Premier League in 1992, the Merseyside derby has had more players sent off than any other Premier League game. It has been referred to as "the most ill-disciplined and explosive fixture in the Premier League".

Liverpool's rivalry with Manchester United stems from the cities' competition in the Industrial Revolution of the 19th century. The two clubs alternated as champions between 1964 and 1967, and Manchester United became the first English team to win the European Cup in 1968, followed by Liverpool's four European Cup victories. Despite the 38 league titles and eight European Cups between them the two rivals have rarely been successful at the same time – Liverpool's run of titles in the 1970s and 1980s coincided with Manchester United's 26-year title drought, and United's success in the Premier League-era has likewise coincided with Liverpool's ongoing drought, and the two clubs have finished first and second in the league only five times. Nonetheless, former Manchester United manager Alex Ferguson said in 2002, "My greatest challenge was knocking Liverpool right off their fucking perch", and the last player to be transferred between the two clubs was Phil Chisnall, who moved to Liverpool from Manchester United in 1964.

As the owner of Anfield and founder of Liverpool, John Houlding was the club's first chairman, a position he held from its founding in 1892 until 1904. John McKenna took over as chairman after Houlding's departure. McKenna subsequently became President of the Football League. The chairmanship changed hands many times before John Smith, whose father was a shareholder of the club, took up the role in 1973. He oversaw the most successful period in Liverpool's history before stepping down in 1990. His successor was Noel White who became chairman in 1990. In August 1991 David Moores, whose family had owned the club for more than 50 years became chairman. His uncle John Moores was also a shareholder at Liverpool and was chairman of Everton from 1961 to 1973. Moores owned 51 percent of the club, and in 2004 expressed his willingness to consider a bid for his shares in Liverpool.

Moores eventually sold the club to American businessmen George Gillett and Tom Hicks on 6 February 2007. The deal valued the club and its outstanding debts at £218.9 million. The pair paid £5,000 per share, or £174.1m for the total shareholding and £44.8m to cover the club's debts. Disagreements between Gillett and Hicks, and the fans' lack of support for them, resulted in the pair looking to sell the club. Martin Broughton was appointed chairman of the club on 16 April 2010 to oversee its sale. In May 2010, accounts were released showing the holding company of the club to be £350m in debt (due to leveraged takeover) with losses of £55m, causing auditor KPMG to qualify its audit opinion. The group's creditors, including the Royal Bank of Scotland, took Gillett and Hicks to court to force them to allow the board to proceed with the sale of the club, the major asset of the holding company. A High Court judge, Mr Justice Floyd, ruled in favour of the creditors and paved the way for the sale of the club to Fenway Sports Group (formerly New England Sports Ventures), although Gillett and Hicks still had the option to appeal. Liverpool was sold to Fenway Sports Group on 15 October 2010 for £300m.

Liverpool has been described as a global brand; a 2010 report valued the club's trademarks and associated intellectual property at £141m, an increase of £5m on the previous year. Liverpool was given a brand rating of AA (Very Strong). In April 2010 business magazine "Forbes" ranked Liverpool as the sixth most valuable football team in the world, behind Manchester United, Real Madrid, Arsenal, Barcelona and Bayern Munich; they valued the club at $822m (£532m), excluding debt. Accountants Deloitte ranked Liverpool eighth in the Deloitte Football Money League, which ranks the world's football clubs in terms of revenue. Liverpool's income in the 2009–10 season was €225.3m.

Because of its successful history, Liverpool is often featured when football is depicted in British culture and has appeared in a number of media firsts. The club appeared in the first edition of the BBC's "Match of the Day", which screened highlights of its match against Arsenal at Anfield on 22 August 1964. The first football match to be televised in colour was between Liverpool and West Ham United, broadcast live in March 1967. Liverpool fans featured in the Pink Floyd song "Fearless", in which they sang excerpts from "You'll Never Walk Alone". To mark the club's appearance in the 1988 FA Cup Final, Liverpool released a song known as the "Anfield Rap", featuring John Barnes and other members of the squad.

A documentary drama on the Hillsborough disaster, written by Jimmy McGovern, was screened in 1996. It featured Christopher Eccleston as Trevor Hicks, whose story is the focus of the script. Hicks, who lost two teenage daughters in the disaster, went on to campaign for safer stadiums and helped to form the Hillsborough Families Support Group. Liverpool featured in the film "The 51st State" (also known as "Formula 51"), in which ex-hitman Felix DeSouza (Robert Carlyle) is a keen supporter of the team and the last scene takes place at a match between Liverpool and Manchester United. The club was featured in a children's television show called "Scully"; the plot revolved around a young boy, Francis Scully, who tried to gain a trial match with Liverpool. The show featured prominent Liverpool players of the time such as Kenny Dalglish.

Since the establishment of the club in 1892, 45 players have been club captain of Liverpool F.C. Andrew Hannah became the first captain of the club after Liverpool separated from Everton and formed its own club. Initially Alex Raisbeck, who was club captain from 1899 to 1909, was the longest serving captain before being overtaken by Steven Gerrard who served 12 seasons as Liverpool captain starting from the 2003–04 season. The present captain is Jordan Henderson, who replaced Gerrard in the 2015–16 season following Gerrard's move to LA Galaxy.




Liverpool's first trophy was the Lancashire League, which it won in the club's first season. In 1901, the club won its first League title, while its first success in the FA Cup was in 1965. In terms of the number of trophies won, Liverpool's most successful decade was the 1980s, when the club won six League titles, two FA Cups, four League Cups, five Charity Shields (one shared) and two European Cups.

The club has accumulated more top-flight wins and points than any other English team. Liverpool also has the highest average league finishing position (3.3) for the 50-year period to 2015 and second-highest average league finishing position for the period 1900–1999 after Arsenal, with an average league placing of 8.7. Liverpool has won the European Cup, UEFA's premier club competition, five times, an English record and only surpassed by Real Madrid and Milan. Liverpool's fifth European Cup win, in 2005, meant that the club was awarded the trophy permanently and was also awarded a multiple-winner badge. Liverpool also hold the English record of three wins in the UEFA Cup, UEFA's secondary club competition.





Especially short competitions, such as the FA Community Shield and the UEFA Super Cup, are not generally considered to contribute towards a Double or Treble.

Footnotes
Citations





</doc>
<doc id="18356" url="https://en.wikipedia.org/wiki?curid=18356" title="Lindow Man">
Lindow Man

Lindow Man, also known as Lindow II and (in jest) as Pete Marsh, is the preserved bog body of a man discovered in a peat bog at Lindow Moss near Wilmslow in Cheshire, North West England. The human remains were found on 1 August 1984 by commercial peat-cutters. Lindow Man is not the only bog body to have been found in the moss; Lindow Woman was discovered the year before, and other body parts have also been recovered. The find, described as "one of the most significant archaeological discoveries of the 1980s", caused a media sensation. It helped invigorate study of British bog bodies, which had previously been neglected in comparison to those found in the rest of Europe.

At the time of death, Lindow Man was a healthy male in his mid-20s, and he may have been someone of high status, as his body shows little evidence of heavy or rough work. There has been debate over the reason for Lindow Man's death, because the nature of his demise was violent, perhaps ritualistic; after a last meal of charred bread, Lindow Man was strangled, hit on the head, and his throat cut. Dating the body has proven problematic, but it is thought that Lindow Man was deposited into Lindow Moss, face down, some time between 2 BC and 119 AD, in either the Iron Age or Romano-British period. The recovered body has been preserved by freeze-drying and is on permanent display at the British Museum, although it occasionally travels to other venues such as the Manchester Museum.

Lindow Moss is a peat bog in Lindow, an area of Wilmslow, Cheshire, which has been used as common land since the medieval period. It formed after the last ice age, one of many such peat bogs in north-east Cheshire and the Mersey basin that formed in hollows caused by melting ice. Investigations have not yet discovered settlement or agricultural activity around the edge of Lindow Moss that would have been contemporary with Lindow Man; however, analysis of pollen in the peat suggests there was some cultivation in the vicinity. Once covering over , the bog has now shrunk to a tenth of its original size. It is a dangerous place; an 18th-century writer recorded people drowning there. For centuries the peat from the bog was used as fuel, and it continued to be extracted until the 1980s, by which time the process had been mechanised. Lindow Moss is a lowland raised mire; this type of peat bog often produces the best preserved bog bodies, allowing more detailed analysis. Lowland raised mires occur mainly in northern England and extend south to the Midlands. Lindow Man is one of 27 bodies to be recovered from such areas.

On 13 May 1983, two peat workers at Lindow Moss, Andy Mould and Stephen Dooley, noticed an unusual object—about the size of a football—on the elevator taking peat to the shredding machine. They removed the object for closer inspection, joking that it was a dinosaur egg. Once the peat had been removed, their discovery turned out to be a decomposing, incomplete human head with one eye and some hair intact. Forensics identified the skull as belonging to a European woman, probably aged 30–50. Police initially thought the skull was that of Malika Reyn-Bardt, who had disappeared in 1960 and was the subject of an ongoing investigation. While in prison on another charge, her husband, Peter Reyn-Bardt, had boasted that he had killed his wife and buried her in the back garden of their bungalow, which was on the edge of the area of mossland where peat was being dug. The garden was examined but no body was recovered there. When Reyn-Bardt was confronted with the discovery of the skull from Lindow Moss, he confessed to the murder of his wife. It was later radiocarbon dated, revealing it to be nearly 2,000 years old. "Lindow Woman", as it became known, dated from around 210 AD. This emerged shortly before Reyn-Bardt went to trial, but he was convicted on the evidence of his confession.

A year later a further discovery was made at Lindow Moss, just south-west of the Lindow Woman. On 1 August 1984, Andy Mould, who had been involved in the discovery of Lindow Woman, took what he thought was a piece of wood off the elevator of the peat-shredding machine. He threw the object at Eddie Slack, his workmate. When it hit the ground, peat fell off the object and revealed it to be a human foot. The police were called and the foot was taken away for examination. Rick Turner, the Cheshire County Archaeologist, was notified of the discovery and succeeded in finding the rest of the body, which later became known as Lindow Man. Some skin had been exposed and had started to decay, so to prevent further deterioration of the body, it was re-covered with peat. The complete excavation of the block containing the remains was performed on 6 August. Until it could be dated, it was moved to the Macclesfield District General Hospital for storage. As the body of Malika Reyn-Bardt had still not been found, it was thought possible the body might be hers, until it was determined to be male, and radiocarbon dated. The owners of the land on which Lindow Man was found donated the body to the British Museum, and on 21 August it was transported to London.

At the time, the body was dubbed "Pete Marsh" (a pun on "peat marsh") by Middlesex Hospital radiologists, a name subsequently adopted by local journalists, as was the similar "Pete Bogg" (a pun on "peat bog"). The find was announced to the press during the second week of investigation. As the best preserved bog body found in Britain, its discovery caused a domestic media sensation and received global coverage. Sparking excitement in the country's archaeological community, who had long expected such a find, it was hailed as one of the most important archaeological discoveries of the 1980s. A "Q.E.D." documentary about Lindow Man broadcast by the BBC in 1985 attracted 10 million viewers.

Lindow Man's official name is Lindow II, as there are other finds from the area: Lindow I (Lindow Woman) refers to a human skull, Lindow III to a "fragmented headless body", and Lindow IV to the upper thigh of an adult male, possibly that of Lindow Man. After the discovery of Lindow Man, there were no further archaeological excavations at Lindow Moss until 1987. A large piece of skin was found by workmen on the elevator on 6 February 1987. On this occasion, the police left the investigation to the archaeologists. Over 70 pieces were found, constituting Lindow III. Although the bone was not as well preserved as that of Lindow Man, the other tissues survived in better condition. The final discovery was that of Lindow IV on 14 June 1988. Part of a left leg and buttocks were found on the elevator, from a site just west of where Lindow Man was found. Nearly three months later, on 12 September, a right thigh was discovered in the peat on the bucket of a digger. The proximity of the discovery sites, coupled with the fact that the remains were shown to come from an adult male, means that Lindow IV is probably part of Lindow Man.

Lindow Man marked the first discovery in Britain of a well-preserved bog body; its condition was comparable to that of Grauballe Man and Tollund Man from Denmark. Before Lindow Man was found, it was estimated that 41 bog bodies had been found in England and Wales and 15 in Scotland. Encouraged by the discovery of Lindow Man, a gazetteer was compiled, which revealed a far higher number of bog bodies: over 85 in England and Wales and over 36 in Scotland. Prior to the discovery of the bodies in Lindow Moss, British bog bodies had been a relatively neglected subject compared to European examples. The interest caused by Lindow Man led to more in-depth research of accounts of discoveries in bogs since the 17th century; by 1995, the numbers had changed to 106 in England and Wales and 34 in Scotland. The remains covered a large time frame.

In life, Lindow Man would have measured between 5'6" and 5'8" (1.68 and 1.73 m) tall and weighed about . It was possible to ascertain that his age at death was around the mid-20s. The body retains a trimmed beard, moustache, and sideburns of brown hair, as well as healthy teeth with no visible cavities, and manicured fingernails, indicating he did little heavy or rough work. Apart from a fox-fur armband, Lindow Man was discovered completely naked. When he died, Lindow Man was suffering from slight osteoarthritis and an infestation of whipworm and maw worm. As a result of decalcification of the bones and pressure from the peat under which Lindow Man was buried, his skull was distorted. While some preserved human remains may contain DNA, peat bogs such as Lindow Moss are generally poor for such a purpose, and it is unlikely that DNA could be recovered from Lindow Man.

Lindow Man and Lindow III were found to have elevated levels of copper on their skin. The cause for this was uncertain as there could have been natural causes, although a study by Pyatt "et al." proposed that the bodies may have been painted with a copper-based pigment. To test this, skin samples were taken from places likely to be painted and tested against samples from areas where painting was unlikely. It was found that the copper content of the skin of the torso was higher than the control areas, suggesting that the theory of Pyatt "et al." may have been correct. However, the conclusion was ambiguous as the overall content was above that expected of a male, and variations across the body may have been due to environmental factors. Similarly, green deposits were found in the hair, originally thought to be a copper-based pigment used for decoration, but it was later found to be the result of a reaction between the keratin in the hair and the acid of the peat bog.

Dating Lindow Man is problematic as samples from the body and surrounding peat have produced dates spanning a 900-year period. Although the peat encasing Lindow Man has been radiocarbon dated to about 300 BC, Lindow Man himself has a different date. Early tests at different laboratories returned conflicting dates for the body; later tests suggested a date between 2 BC and 119 AD. There has been a tendency to ascribe the body to the Iron Age period rather than Roman due to the interpretation that Lindow Man's death may have been a ritual sacrifice or execution. Explanations for why the peat in which he was found is much older have been sought. Archaeologist P. C. Buckland suggests that as the stratigraphy of the peat appears undisturbed, Lindow Man may have been deposited into a pool that was already some 300 years old. Geographer K. E. Barber has argued against this hypothesis, saying that pools at Lindow Moss would have been too shallow, and suggests that the peat may have been peeled back to allow the burial and then replaced, leaving the stratigraphy apparently undisturbed.

Lindow Man's last meal was preserved in his stomach and intestines and was analysed in some detail. It was hoped that investigations into the contents of the stomach would shed light on the contemporary diet, as was the case with Grauballe Man and Tollund Man in the 1950s. The analysis of the contents of the digestive system of bog bodies had become one of the principal endeavours of investigating such remains. Analysis of the grains present revealed his diet to be mostly of cereals. He probably ate slightly charred bread, although the burning may have had ritual significance rather than being an accident. Some mistletoe pollen was also found in the stomach, indicating that Lindow Man died in March or April.

One of the conclusions of the study was that the people buried in Lindow Moss may have had a less varied diet than their European counterparts. According to Jody Joy, curator of the Iron Age collection at the British Museum, the importance of Lindow Man lies more in how he lived rather than how he died, as the circumstances surrounding his demise may never be fully established.

As the peat was cleaned off the body in the laboratory, it became clear that Lindow Man had suffered a violent death. The injuries included a V-shaped, cut on top of his head; a possible laceration at the back of the head, ligature marks on the neck where a sinew cord was found, a possible wound on the right side of the neck, a possible stab wound in the upper right chest, a broken neck, and a fractured rib. Xeroradiography revealed that the blow on top of the head (causing the V-shaped cut) was caused by a relatively blunt object; it had fractured the skull and driven fragments into the brain. Swelling along the edges of the wound indicated that Lindow Man had lived after being struck. The blow, possibly from a small axe, would have caused unconsciousness, but Lindow Man could have survived for several hours afterwards. The ligature marks on the neck were caused by tightening the sinew cord found around his neck, possibly a garrotte or necklace.

It is not possible to confirm whether some injuries took place before or after death, due to the body's state of decay. This is the case for the wound in the upper right chest and the laceration on the back of the skull. The cut on the right of the neck may have been the result of the body becoming bloated, causing the skin to split; however, the straight edges to the wound suggest that it may have been caused by a sharp instrument, such as a knife. The ligature marks on the neck may have occurred after death. In some interpretations of Lindow Man's death, the sinew is a garrotte used to break the man's neck. However, Robert Connolly, a lecturer in physical anthropology, suggests that the sinew may have been ornamental and that ligature marks may have been caused by the body swelling when submerged. The rib fracture may also have occurred after death, perhaps during the discovery of the body, but is included in some narratives of Lindow Man's death. The broken neck would have proven the fatal injury, whether caused by the sinew cord tightening around the neck or by blows to the back of the head. After death, Lindow Man was deposited into Lindow Moss face down.

Archaeologist Don Brothwell considers that many of the older bodies need re-examining with modern techniques, such as those used in the analysis of Lindow Man. The study of bog bodies, including these found in Lindow Moss, has contributed to a wider understanding of well-preserved human remains, helping to develop new methods in analysis and investigation. The use of sophisticated techniques, such as computer tomography (CT) scans, has marked the investigation of the Lindow bodies as particularly important. Such scans allow the reconstruction of the body and internal examination. Of the 27 bodies recovered from lowland raised mires in England and Wales, only those from Lindow Moss and the remains of Worsley Man have survived, together with a shoe from another body. The remains have a date range from the early 1st to the 4th centuries. Investigation into the other bodies relies on contemporary descriptions of the discovery.

The physical evidence allows a general reconstruction of how Lindow Man was killed, although some details are debated, but it does not explain why he was killed. In North West England, there is little evidence for religious or ritual activity in the Iron Age period. What evidence does survive is usually in the form of artefacts recovered from peat bogs. Late Iron Age burials in the region often took the form of a crouched inhumation, sometimes with personal ornaments. Although dated to the mid-1st century AD, the type of burial of Lindow Man was more common in the pre-historic period. In the latter half of the 20th century, scholars widely believed that bog bodies demonstrating injuries to the neck or head area were examples of ritual sacrifice. Bog bodies were associated with Germanic and Celtic cultures, specifically relating to head worship.

According to Brothwell, Lindow Man is one of the most complex examples of "overkill" in a bog body, and possibly has ritual meaning as it was "extravagant" for a straightforward murder. Archaeologists John Hodgson and Mark Brennand suggest that bog bodies may have been related to religious practice, although there is division in the academic community over this issue. In the case of Lindow Man, scholars debate whether the killing was murder or done as part of ritual. Anne Ross, an expert on Iron Age religion, proposed that the death was an example of human sacrifice and that the "triple death" (throat cut, strangled, and hit on the head) was an offering to several different gods. The wide date range for Lindow Man's death (2 BC to 119 AD) means he may have met his demise after the Romans conquered northern England in the 60s AD. As the Romans outlawed human sacrifice, such timing would open up other possibilities. This conclusion was emphasised by historian Ronald Hutton, who challenged the interpretation of sacrificial death. Connolly suggests that as Lindow Man was found naked, he could have been the victim of a violent robbery.

Joy said,
"The jury really is still out on these bodies, whether they were aristocrats, priests, criminals, outsiders, whether they went willingly to their deaths or whether they were executed – but Lindow was a very remote place in those days, an unlikely place for an ambush or a murder".

 Environment and situation are the crucial factors that determine how corpses decay. For instance, corpses will decay differently depending on the weather, the way they are buried, and the medium in which they are buried. Peat slows the decay of corpses. It was feared that, once Lindow Man was removed from that environment, which had preserved the body for nearly 2,000 years, the remains would rapidly start to deteriorate, so steps were taken to ensure preservation. After rejecting methods that had been used to maintain the integrity of other bog bodies, such as the "pit-tanning" used on Grauballe Man, which took a year and a half, scientists settled on freeze-drying. In preparation, the body was covered in a solution of 15% polyethylene glycol 400 and 85% water to prevent its becoming distorted. The body was then frozen solid and the ice vaporised to ensure Lindow Man did not shrink. Afterwards, Lindow Man was put in a specially constructed display case to control the environment, maintaining the temperature at and the humidity at 55%.

Lindow Man is held in the British Museum. Before the remains were transferred there, people from North West England launched an unsuccessful campaign to keep the body in Manchester. The bog body has been on temporary display in other venues: at the Manchester Museum on three occasions, April to , March to , and to ; and at the Great North Museum in Newcastle from August to . The 2008–09 Manchester display, titled "Lindow Man: A Bog Body Mystery Exhibition at the Manchester Museum", won the category "Best Archaeological Innovation" in the 2010 British Archaeological Awards, run by the Council for British Archaeology.

Critics have complained that, by museum display of the remains, the body of Lindow Man has been objectified rather than treated with the respect due the dead. Emma Restall Orr, a neo-druid, has questioned whether the body should be displayed at all. This is part of a wider discussion about the scientific treatment of human remains and museum researchers and archaeologists using them as information sources.






</doc>
<doc id="18367" url="https://en.wikipedia.org/wiki?curid=18367" title="Luton Town F.C.">
Luton Town F.C.

Luton Town Football Club () is a professional association football club based in the town of Luton, Bedfordshire, England, that competes in League One, the third tier of the English football league system. Founded in 1885, it is nicknamed "the Hatters" and affiliated to the Bedfordshire County Football Association. The team plays its home matches at Kenilworth Road, where it has been based since 1905. The club's history includes major trophy wins, several financial crises, numerous promotions and relegations, and some spells of sustained success. It was perhaps most prominent between 1982 and 1992, when it was a member of English football's top division, at that time the First Division; the team won its only major honour, the Football League Cup, in 1988.

The club was the first in southern England to turn professional, making payments to players as early as 1890 and turning fully professional a year later. It joined the Football League before the 1897–98 season, left in 1900 because of financial problems, and rejoined in 1920. Luton reached the First Division in 1955–56 and contested a major final for the first time when playing Nottingham Forest in the 1959 FA Cup Final. The team was then relegated from the top division in 1959–60, and demoted twice more in the following five years, playing in the Fourth Division from the 1965–66 season. However, it was promoted back to the top level by 1974–75.

Luton Town's most recent successful period began in 1981–82, when the club won the Second Division, and thereby gained promotion to the First. Luton defeated Arsenal 3–2 in the 1988 Football League Cup Final and remained in the First Division until relegation at the end of the 1991–92 season. Between 2007 and 2009, financial difficulties caused the club to fall from the second tier of English football to the fifth in successive seasons. The last of these relegations came during the 2008–09 season, when 30 points were docked from Luton's record for various financial irregularities. Luton thereafter spent five seasons in non-League football before winning the Conference Premier in 2013–14, securing promotion back into the Football League.

Luton Town Football Club was formed on 11 April 1885. Before this there were many clubs in the town, the most prominent of which were Luton Wanderers and Luton Excelsior. A Wanderers player, George Deacon, came up with the idea of a "Town" club which would include all the best players in Luton. Wanderers secretary Herbert Spratley seized upon Deacon's idea and arranged a secret meeting on 13 January 1885 at the St Matthews school rooms in High Town. The Wanderers committee resolved to rename the club Luton Town—which was not well received by the wider community. The local newspapers referred to the club as "Luton Town (late Wanderers)". When George Deacon and John Charles Lomax then arranged a public meeting with the purpose of forming a "Luton Town Football Club", Spratley protested, saying there was already a Luton Town club; and the atmosphere was tense when the meeting convened in the town hall on the 11 April 1885. The meeting, attended by most football lovers in the town, heard about Spratley's secret January meeting and voted down his objections. The motion to form a "Luton Town Football Club", put forward by G H Small and seconded by E H Lomax, was carried. A club committee was elected by ballot and the team colours were agreed to be pink and dark blue shirts and caps.

Initially based at Excelsior's Dallow Lane ground, Luton Town began making payments to certain individual players in 1890. The following year, Luton became the first club in southern England to be fully professional. The club was a founder member of the Southern Football League in the 1894–95 season and finished as runners-up in its first two seasons. It then left to help form the United League and came second in that league's inaugural season before joining the Football League (then based mostly in northern and central England) for 1897–98, concurrently moving to a new ground at Dunstable Road. The club continued to enter a team to the United League for two more seasons, and won the title in 1897–98. Poor attendance, high wages and the high travel and accommodation costs that resulted from Luton's distance from the northern heartlands of the Football League crippled the club financially, and made it too expensive to compete in that league. A return to the Southern League was therefore arranged for the 1900–01 season.

Eight years after arriving at Dunstable Road, Luton moved again, settling at their current ground, Kenilworth Road, in 1905. Captain and left winger Bob Hawkes became Luton's first international player when he was picked to play for England against Ireland on 16 February 1907. A poor 1911–12 season saw Luton relegated to the Southern League's Second Division; the club won promotion back two years later. After the First World War broke out, Luton took part in The London Combination during 1915–16, and afterwards filled each season with friendly matches. A key player of the period was Ernie Simms, a forward. Simms was invalided back to England after being wounded on the Italian front, but recovered enough to regain his place in the Luton team and scored 40 goals during the 1916–17 season.

The Luton side first played in the white and black colours which it has retained for much of its history during the 1920–21 season, when the club rejoined the Football League; the players had previously worn an assortment of colour combinations, most permanently sky blue shirts with white shorts and navy socks. Such was the quality of Luton's team at this time that despite playing in the third tier, a fixture between Ireland and England at Windsor Park on 22 October 1921 saw three Luton players on the pitch—Louis Bookman and Allan Mathieson for Ireland, and the club's top goalscorer, Simms, for England. However, after Luton finished fourth in the division, the squad was broken up as Simms, Bookman and Mathieson joined South Shields, Port Vale and Exeter City respectively. Luton stayed in the Third Division South until 1936–37, when the team finished top and won promotion to the Second Division, at that time the second tier of English football. During the promotion season, striker Joe Payne scored 55 goals in 39 games; during the previous season he had scored 10 in one match against Bristol Rovers, which remains a Football League record today.

During the early 1950s, one of Luton's greatest sides emerged under manager Dally Duncan. The team included Gordon Turner, who went on to become Luton's all-time top goalscorer, Bob Morton, who holds the record for the most club appearances, and Syd Owen, an England international. During this period, Luton sides also featured two England international goalkeepers, Ron Baynham and Bernard Streten, as well as Irish internationals Seamus Dunne, Tom Aherne and George Cummins. This team reached the top flight for the first time in 1955–56, after finishing the season in second place behind Birmingham City on goal average. A few years of success followed, including an FA Cup Final appearance against Nottingham Forest in 1958–59; at the end of the season, Owen was voted FWA Footballer of the Year. However, the club was relegated the following season and, by 1964–65, was playing in the fourth tier.

In yo-yo club fashion, Luton were to return. A team including Bruce Rioch, John Moore and Graham French won the Fourth Division championship in 1967–68 under the leadership of former player Allan Brown; two years later Malcolm Macdonald's goals helped them to another promotion, while comedian Eric Morecambe became a director of the club. Luton Town won promotion back to the First Division in 1973–74, but were relegated the following season by a solitary point. Former Luton player David Pleat was made manager in 1978, and by 1982–83 the team was back in the top flight. The team which Pleat assembled at Kenilworth Road was notable at the time for the number of black players it included; during an era when many English squads were almost entirely white, Luton often fielded a mostly black team. Talented players such as Ricky Hill, Brian Stein and Emeka Nwajiobi made key contributions to the club's success during this period, causing it to accrue "a richer history of black stars than any in the country", in the words of journalist Gavin Willacy.

On the last day of the 1982–83 season, the club's first back in the top tier, it narrowly escaped relegation: playing Manchester City at Maine Road, Luton needed to win to stay up, while City could escape with a draw. A late winner by Yugoslavian substitute Raddy Antić saved the team and prompted Pleat to dance across the pitch performing a "jig of joy", an image that has become iconic. The club achieved its highest ever league position, seventh, under John Moore in 1986–87, and, managed by Ray Harford, won the Football League Cup a year later with a 3–2 win over Arsenal. With ten minutes left on the clock and Arsenal 2–1 ahead, a penalty save from stand-in goalkeeper Andy Dibble sparked a late Luton rally: Danny Wilson equalised, before Brian Stein scored the winner with the last kick of the match. The club reached the League Cup Final once more in 1988–89, but lost 3–1 to Nottingham Forest.

The club was relegated from the top division at the end of the 1991–92 season, and sank to the third tier four years later. Luton stayed in the third-tier Second Division until relegation at the end of the 2000–01 season. Under the management of Joe Kinnear, who had arrived halfway through the previous season, the team won promotion from the fourth tier at the first attempt. "Controversial" owner John Gurney unsettled the club in 2003, terminating Kinnear's contract on his arrival in May; Gurney replaced Kinnear with Mike Newell before leaving Luton as the club entered administration. Newell's team finished as champions of the rebranded third-tier Football League One in 2004–05.

While Newell's place was taken first by Kevin Blackwell and later former player Mick Harford, the team was then relegated twice in a row, starting in 2006–07, and spent the latter part of the 2007–08 season in administration, thus incurring a ten-point deduction from that season's total. The club then had a total of 30 points docked from its 2008–09 record by the Football Association and the Football League for financial irregularities dating back several years. These deductions proved to be too large an obstacle to overcome, but Luton came from behind in the final of the Football League Trophy to win the competition for the first time.

Relegation meant that 2009–10 saw Luton playing in the Conference Premier, a competition in which the club had never before participated. The club unsuccessfully contested the promotion play-offs three times in four seasons during their time as a non-League club, employing five different managers. In the 2012–13 FA Cup fourth round, Luton won their away tie against Premier League club Norwich City 1–0 and, in doing so, became the first non-League team to beat a side from England's top division since 1989. In the 2013–14 season, under the management of John Still, Luton won the Conference Premier title with three games to spare, and thereby secured a return to the Football League from 2014–15. Another promotion followed three years later, putting Luton back in League One from the start of the 2018–19 campaign.

The club's nickname, "the Hatters", reflects Luton's historical connection with the hat making trade, which has been prominent there since the 17th century. The nickname was originally a variant on the now rarely seen straw-plaiters. Supporters of the club are also called Hatters.

The club is associated with two very different colour schemes—white and black (first permanently adopted in 1920), and orange, navy and white (first used in 1973, and worn by the team as of the 2015–16 season). Luton mainly wore a combination of light blue and white before 1920, when white shirts and black shorts were first adopted. These colours were retained for over half a century, with the colour of the socks varying between white and black, until Luton changed to orange, navy and white at the start of the 1973–74 season. Luton began playing in white shirts, shorts and socks in 1979, with the orange and navy motif reduced to trim; navy shorts were adopted in 1984. This palette was retained until the 1999–2000 season, when the team played in orange shirts and blue shorts. From 2000 to 2008, Luton returned to white shirts and black shorts; orange was included as trim until 2007. The white, navy and orange palette favoured in the 1980s was brought back in 2008, following the results of a club poll, but a year later the colours were changed yet again, this time to a predominantly orange strip with white shorts. Navy shorts were readopted in 2011. Luton are wearing orange shirts, navy shorts and white socks during the 2015–16 season.

Luton Town have traditionally used the town's crest as its own in a manner similar to many other teams. The club's first badge was a white eight-pointed star, which was emblazoned across the team's shirts (then a deep cochineal red) in 1892. Four years later a crest comprising the club's initials intertwined was briefly adopted. The shirts were thereafter plain until 1933, when Luton first adopted a badge depicting a straw boater, which appeared on Luton shirts. The letters "LTFC" were added in 1935, and this basic design remained until 1947. The club then played without a badge until 1970, when the club began to wear the town crest regularly, having first done so in the 1959 FA Cup Final.

In 1973, concurrently with the club's switch to the orange kit, a new badge was introduced featuring the new colours. The new emblem depicted a stylised orange football, bearing the letters "Lt", surrounded by the club's name in navy blue text. In 1987, the club switched back to a derivative of the town emblem, with the shield portion of the heraldic crest becoming the team's badge; the only similarity with the previous design was the inclusion of the club name around the shield in navy blue. The "rainbow" badge, introduced in 1994, featured the town crest below an orange and blue bow which curved around to meet two footballs, positioned on either side of the shield, with the club name underneath. This badge was used until 2005, when a replacement very similar to the 1987 version was adopted, featuring black text rather than blue and a straw boater in place of the outstretched arm depicted in the older design. The club's founding year, 1885, was added in 2008. The badge was altered once more during the 2009–10 pre-season, with the red of the town crest being replaced with orange to better reflect the club colours.

The first sponsor to appear on a Luton Town shirt was Tricentrol, a local motor company based in Dunstable, who sponsored the club from March 1980 to 1982; the deal was worth £50,000. Subsequent sponsors have been Bedford Trucks (1982 to 1990), Vauxhall (1990 to 1991), Universal Salvage Auctions (1991 to 1999), SKF (1999 to 2003), Travel Extras (2003 to 2005), Electrolux (2005 to 2008), Carbrini Sportswear (2008 to 2009), EasyJet and NICEIC (concurrently, 2009 to 2015), and Barnfield College and NICEIC (concurrently, 2015 to 2016). Since June 2016, the club's kit has been sponsored by NICEIC and SsangYong Motor UK.

The club released the song "Hatters, Hatters", a collaboration between the Luton team and the Bedfordshire-based musical comedy group the Barron Knights, in 1974. Eight years later another song featuring vocals by the Luton players, "We're Luton Town", was released to celebrate the club's promotion to the First Division.

Luton Town's first ground was at Dallow Lane, the former ground of Excelsior. The ground was next to the Dunstable to Luton railway line, and players regularly claimed to have trouble seeing the ball because of smoke from the trains. A damaging financial loss during 1896–97 forced Luton to sell the stadium to stay afloat and, as a result, the club moved across the tracks to a stadium between the railway and Dunstable Road. The Dunstable Road ground was opened by Herbrand Russell, 11th Duke of Bedford, who also donated £50 towards the £800 building costs. When the site was sold for housing in 1905, the club was forced to move again at short notice, to its present Kenilworth Road site, in time for the start of the 1905–06 season.

The 10,356 capacity all-seater stadium is in the Bury Park area of Luton and named after the road that runs along one end of it, although the official address of the club is 1 Maple Road. Opposite the eponymous Kenilworth Stand is the Oak Road End, which has evolved from a stand first used exclusively by Luton supporters, then later by away supporters, and now used by both except in times of high ticket demand from away clubs. The Main Stand is flanked by the David Preece Stand, and opposite them stands a row of executive boxes. These boxes replaced the Bobbers Stand in 1986, as the club sought to maximise income.

The original Main Stand burnt down in 1921, and was replaced by the current stand before the 1922–23 season. The ground underwent extensive redevelopment during the 1930s, and the capacity by the start of the Second World War was 30,000. Floodlights were installed before the 1953–54 season, but it was 20 years before any further modernisation was carried out. In 1973 the Bobbers Stand became all-seated, and in 1985 the grass pitch was replaced with an artificial playing surface; it quickly became unpopular and was derided as "the plastic pitch".

A serious incident involving hooliganism before, during and after a match against Millwall in 1985 caused the club's then chairman, Conservative MP David Evans, to introduce a scheme effective from the start of 1986–87 banning all visiting supporters from the ground, and requiring home fans to carry membership cards when attending matches. Conversion to an all-seater ground also began in 1986. Away fans returned for 1990–91, and grass a year later. The David Preece Stand was erected in 1991, and the conversion of the Kenilworth Stand to an all-seater was completed in 2005.

The club first stated its intent to leave Kenilworth Road in 1955. Even then the ground was small compared to rival stadia, and its location made significant redevelopment difficult. The team has since made several attempts to relocate. Leaving Luton for the nearby new town of Milton Keynes was unsuccessfully proposed several times, most notably in the 1980s. The club sold Kenilworth Road to Luton Council in 1989, and has since leased it. A planning application for a new ground, the "Kohlerdome" proposed by chairman David Kohler in 1995, was turned down by the Secretary of State in 1998, and Kohler left soon after.

In 2007, the club's then-owners proposed a controversial plan to relocate to a site near Junction 12 of the M1 motorway, near Harlington and Toddington. A planning application was made on the club's behalf by former chairman Cliff Bassett, but the application was withdrawn almost immediately following the club's takeover in 2008. In 2009, the club began an independent feasibility study to determine a viable location to move to. The club did not rule out redeveloping Kenilworth Road and, in October 2012, entered talks to buy the stadium back from Luton Borough Council. By 2015, these plans had been dropped in favour of a move to a new location, with managing director Gary Sweet confirming that the club was in a position to "buy land, secure the best possible professional advice ... and to see the [planning] application process through to the receipt of consent."

In April 2016, the club announced its intention to build and move into a 17,500-capacity stadium on the Power Court site in central Luton. Planning permission for this ground, with potential to expand to 23,000 seats, was granted by Luton Borough Council on 16 January 2019..

During the 2014–15 season, Luton Town had an average home league attendance of 8,702—the second highest in League Two behind only Portsmouth. In the 2013–14 season, when the club were in the Conference Premier, the club had significantly higher support than the other clubs in its league, with an average home attendance of 7,387; more than twice compared to the second highest of 3,568. Average attendances at Kenilworth Road fell with the installation of seats and the club's reduction in stature, dropping from 13,452 in 1982–83 to their 2014–15 level—a slump of 35% over 32 years. A supporters' trust, Trust in Luton, owns shares in the club and elects a representative to the club's board. The club's official supporters' group, Luton Town Supporters' Club, merged with Trust in Luton in 2014. The club is associated with another supporters' group, the breakaway Loyal Luton Supporters Club. Trust in Luton has, since March 2014, held the legal right to veto any changes to the club's identity, including name, nickname, colours, club crest and mascot.

Luton Town supporters maintain a bitter rivalry with Hertfordshire-based Watford. Watford have remained the higher ranked team at the end of every season since 1997. However, overall Luton still hold the superior record in the fixture between the two clubs; out of 118 competitive matches there have been 53 Luton victories and 36 for Watford, with 29 draws. A survey taken in 2003 showed that there was also animosity between Luton Town fans and those of west London club Queens Park Rangers.

The club produces an official match programme for home games, "Talk of the Town". A character known as Happy Harry, a smiling man wearing a straw boater, serves as the team's mascot and appears on the Kenilworth Road pitch before matches. In December 2014, after the seafront statue of Eric Morecambe in his birthplace Morecambe was restored, Luton and Morecambe F.C. jointly announced that the winners of future Luton–Morecambe fixtures would be awarded the "Eric Morecambe Trophy".

The record for the most appearances for Luton is held by Bob Morton, who turned out for Luton 562 times in all competitions. Morton also holds the record for the most Football League appearances for the club, with 495. Fred Hawkes holds the record for the most league appearances for Luton, having played in 509 league matches. Six players, Gordon Turner, Andy Rennie, Brian Stein, Ernie Simms, Herbert Moody and Steve Howard, have scored more than 100 goals for Luton.

The first player to be capped while playing for Luton was left winger Robert Hawkes, who took to the field for England against Ireland at Goodison Park on 16 February 1907. The most capped player is Mal Donaghy, who earned 58 Northern Ireland caps while at the club. The first player to score in an international match was Joe Payne, who scored twice in his only game for England against Finland on 20 May 1937. Payne also holds the Football League record for the most goals in a game—he hit 10 past Bristol Rovers on 13 April 1936.

The club's largest wins have been a 15–0 victory over Great Yarmouth Town on 21 November 1914 in the FA Cup and a 12–0 win over Bristol Rovers in the Third Division South on 13 April 1936. Luton's heaviest loss was a 9–0 defeat against Small Heath in the Second Division on 12 November 1898.

Luton's highest home attendances are 30,069 against Blackpool in the FA Cup on 4 March 1959 and 27,911 against Wolverhampton Wanderers in the First Division on 5 November 1955.

The highest transfer fee received for a Luton Town player is the £3 million West Bromwich Albion paid for Curtis Davies on 31 August 2005. The most expensive player Luton Town have ever bought was Lars Elstrup, who cost £850,000 from Odense Boldklub on 21 August 1989.

The youngest player to make a first-team appearance for Luton Town is Connor Tomlinson at 15 years and 199 days old in the EFL Trophy, replacing Zane Banton as a 92nd-minute substitute in a 2–1 win over Gillingham on 30 August 2016, after the club were given permission for him to play from his headteacher.

The club operates a Development Squad, made up of contracted senior players, youth team scholars and trialists, which plays in the Southern Division of The Central League. The club also fields an under-18 team in the Football League Youth Alliance South East Conference. Luton's youth set-up consists of ten Soccer Centres across Bedfordshire and North Hertfordshire, two Centres of Excellence (one in Luton, one in Dunstable), and an Academy in Baldock that caters for players in the under-9 to under-16 age groups.






</doc>
<doc id="18450" url="https://en.wikipedia.org/wiki?curid=18450" title="Lung cancer">
Lung cancer

Lung cancer, also known as lung carcinoma, is a malignant lung tumor characterized by uncontrolled cell growth in tissues of the lung. This growth can spread beyond the lung by the process of metastasis into nearby tissue or other parts of the body. Most cancers that start in the lung, known as primary lung cancers, are carcinomas. The two main types are small-cell lung carcinoma (SCLC) and non-small-cell lung carcinoma (NSCLC). The most common symptoms are coughing (including coughing up blood), weight loss, shortness of breath, and chest pains.
The vast majority (85%) of cases of lung cancer are due to long-term tobacco smoking. About 10–15% of cases occur in people who have never smoked. These cases are often caused by a combination of genetic factors and exposure to radon gas, asbestos, second-hand smoke, or other forms of air pollution. Lung cancer may be seen on chest radiographs and computed tomography (CT) scans. The diagnosis is confirmed by biopsy which is usually performed by bronchoscopy or CT-guidance.
Avoidance of risk factors, including smoking and air pollution, is the primary method of prevention. Treatment and long-term outcomes depend on the type of cancer, the stage (degree of spread), and the person's overall health. Most cases are not curable. Common treatments include surgery, chemotherapy, and radiotherapy. NSCLC is sometimes treated with surgery, whereas SCLC usually responds better to chemotherapy and radiotherapy.
Worldwide in 2012, lung cancer occurred in 1.8 million people and resulted in 1.6 million deaths. This makes it the most common cause of cancer-related death in men and second most common in women after breast cancer. The most common age at diagnosis is 70 years. Overall, 17.4% of people in the United States diagnosed with lung cancer survive five years after the diagnosis, while outcomes on average are worse in the developing world.
Signs and symptoms which may suggest lung cancer include:

If the cancer grows in the airways, it may obstruct airflow, causing breathing difficulties. The obstruction can lead to accumulation of secretions behind the blockage, and predispose to pneumonia.

Depending on the type of tumor, paraneoplastic phenomena—symptoms not due to the local presence of cancer—may initially attract attention to the disease. In lung cancer, these phenomena may include hypercalcemia, syndrome of inappropriate antidiuretic hormone (SIADH, abnormally concentrated urine and diluted blood), ectopic ACTH production, or Lambert–Eaton myasthenic syndrome (muscle weakness due to autoantibodies). Tumors in the top of the lung, known as Pancoast tumors, may invade the local part of the sympathetic nervous system, leading to Horner's syndrome (dropping of the eyelid and a small pupil on that side), as well as damage to the brachial plexus.

Many of the symptoms of lung cancer (poor appetite, weight loss, fever, fatigue) are not specific. In many people, the cancer has already spread beyond the original site by the time they have symptoms and seek medical attention. Symptoms that suggest the presence of metastatic disease include weight loss, bone pain and neurological symptoms (headaches, fainting, convulsions, or limb weakness). Common sites of spread include the brain, bone, adrenal glands, opposite lung, liver, pericardium, and kidneys. About 10% of people with lung cancer do not have symptoms at diagnosis; these cancers are incidentally found on routine chest radiography.

Cancer develops after genetic damage to DNA and epigenetic changes. Those changes affect the cell's normal functions, including cell proliferation, programmed cell death (apoptosis), and DNA repair. As more damage accumulates, the risk of cancer increases.

Tobacco smoking is by far the main contributor to lung cancer. Cigarette smoke contains at least 73 known carcinogens, including benzo["a"]pyrene, NNK, 1,3-butadiene, and a radioactive isotope of polonium – polonium-210. Across the developed world, 90% of lung cancer deaths in men and 70% of those in women during the year 2000 were attributed to smoking. Smoking accounts for about 85% of lung cancer cases.

Passive smoking – the inhalation of smoke from another's smoking – is a cause of lung cancer in nonsmokers. A passive smoker can be defined as someone either living or working with a smoker. Studies from the US, Europe, and the UK have consistently shown a significantly-increased risk among those exposed to passive smoking. Those who live with someone who smokes have a 20–30% increase in risk while those who work in an environment with secondhand smoke have a 16–19% increase in risk. Investigations of sidestream smoke suggest that it is more dangerous than direct smoke. Passive smoking results in roughly 3,400 lung cancer-related deaths each year in the U.S.

Marijuana smoke contains many of the same carcinogens as those in tobacco smoke. However, the effect of smoking cannabis on lung cancer risk is not clear. A 2013 review did not find an increased risk from light to moderate use. A 2014 review found that smoking cannabis doubled the risk of lung cancer.

Radon is a colorless and odorless gas generated by the breakdown of radioactive radium, which in turn is the decay product of uranium, found in the Earth's crust. The radiation decay products ionize genetic material, causing mutations that sometimes become cancerous. Radon is the second-most common cause of lung cancer in the US, causing about 21,000 deaths each year. The risk increases 8–16% for every 100 Bq/m³ increase in the radon concentration. Radon gas levels vary by locality and the composition of the underlying soil and rocks. About one in 15 homes in the US have radon levels above the recommended guideline of 4 picocuries per liter (pCi/l) (148 Bq/m³).

Asbestos can cause a variety of lung diseases such as lung cancer. Tobacco smoking and asbestos both have synergistic effects on the development of lung cancer. In smokers who work with asbestos, the risk of lung cancer is increased 45-fold compared to the general population. Asbestos can also cause cancer of the pleura, called mesothelioma – which actually is different from lung cancer.

Outdoor air pollutants, especially chemicals released from the burning of fossil fuels, increase the risk of lung cancer. Fine particulates (PM) and sulfate aerosols, which may be released in traffic exhaust fumes, are associated with a slightly-increased risk. For nitrogen dioxide, an incremental increase of 10 parts per billion increases the risk of lung cancer by 14%. Outdoor air pollution is estimated to cause 1–2% of lung cancers.

Tentative evidence supports an increased risk of lung cancer from indoor air pollution in relation to the burning of wood, charcoal, dung, or crop residue for cooking and heating. Women who are exposed to indoor coal smoke have roughly twice the risk, and many of the by-products of burning biomass are known or suspected carcinogens. This risk affects about 2.4 billion people worldwide, and it is believed to result in 1.5% of lung cancer deaths.

About 8% of lung cancer is caused by inherited factors. In relatives of people that are diagnosed with lung cancer, the risk is doubled, likely due to a combination of genes. Polymorphisms on chromosomes 5, 6, and 15 are known to affect the risk of lung cancer. Single-nucleotide polymorphisms (SNPs) of the genes encoding the nicotinic acetylcholine receptor (nAChR) – "CHRNA5", "CHRNA3", and "CHRNB4" – are of those associated with an increased risk of lung cancer, as well as "RGS17" – a gene regulating G-protein signaling.

Numerous other substances, occupations, and environmental exposures have been linked to lung cancer. The International Agency for Research on Cancer (IARC) states that there is some "sufficient evidence" to show that the following are carcinogenic in the lungs:

Similar to many other cancers, lung cancer is initiated by either the activation of oncogenes or the inactivation of tumor suppressor genes. Carcinogens cause mutations in these genes that induce the development of cancer.

Mutations in the "K-ras" proto-oncogene cause roughly 10–30% of lung adenocarcinomas. Nearly 4% of non-small-cell lung carcinomas involve an EML4-ALK tyrosine kinase fusion gene.

Epigenetic changes such as alteration of DNA methylation, histone tail modification, or microRNA regulation may result in the inactivation of tumor suppressor genes. Importantly, cancer cells develop resistance to oxidative stress, which enables them to withstand and exacerbate inflammatory conditions that inhibit the activity of the immune system against the tumor.

The epidermal growth factor receptor (EGFR) regulates cell proliferation, apoptosis, angiogenesis, and tumor invasion. Mutations and amplification of EGFR are common in non-small-cell lung carcinoma, and they provide the basis for treatment with EGFR-inhibitors. "Her2/neu" is affected less frequently. Other genes that are often mutated or amplified include "c-MET", "NKX2-1", "LKB1", "PIK3CA", and "BRAF".

The cell lines of origin are not fully understood. The mechanism may involve the abnormal activation of stem cells. In the proximal airways, stem cells that express keratin 5 are more likely to be affected, typically leading to squamous-cell lung carcinoma. In the middle airways, implicated stem cells include club cells and neuroepithelial cells that express club cell secretory protein. Small-cell lung carcinoma may originate from these cell lines or neuroendocrine cells, and it may express CD44.

Metastasis of lung cancer requires transition from epithelial to mesenchymal cell type. This may occur through the activation of signaling pathways such as Akt/GSK3Beta, MEK-ERK, Fas, and Par6.

Performing a chest radiograph is one of the first investigative steps if a person reports symptoms that may be suggestive of lung cancer. This may reveal an obvious mass, the widening of the mediastinum (suggestive of spread to lymph nodes there), atelectasis (lung collapse), consolidation (pneumonia), or pleural effusion. CT imaging is typically used to provide more information about the type and extent of disease. Bronchoscopic or CT-guided biopsy is often used to sample the tumor for histopathology.

Lung cancer often appears as a solitary pulmonary nodule on a chest radiograph. However, the differential diagnosis is wide. Many other diseases can also give this appearance, including metastatic cancer, hamartomas, and infectious granulomas caused by tuberculosis, histoplasmosis or coccidioidomycosis. Lung cancer can also be an incidental finding, as a solitary pulmonary nodule on a chest radiograph or CT scan done for an unrelated reason. The definitive diagnosis of lung cancer is based on the histological examination of the suspicious tissue in the context of the clinical and radiological features.

Clinical practice guidelines recommend frequencies for pulmonary nodule surveillance. CT imaging should not be used for longer or more frequently than indicated, as the extended surveillance exposes people to increased radiation and is costly.

Lung cancers are classified according to histological type. This classification is important for determining both the management and predicting outcomes of the disease. Lung cancers are carcinomas – malignancies that arise from epithelial cells. Lung carcinomas are categorized by the size and appearance of the malignant cells seen by a histopathologist under a microscope. For therapeutic purposes, two broad classes are distinguished: non-small-cell lung carcinoma and small-cell lung carcinoma.

The three main subtypes of NSCLC are adenocarcinoma, squamous-cell carcinoma, and large-cell carcinoma.

Nearly 40% of lung cancers are adenocarcinoma, which usually comes from peripheral lung tissue. Although most cases of adenocarcinoma are associated with smoking, adenocarcinoma is also the most-common form of lung cancer among people who have smoked fewer than 100 cigarettes in their lifetimes ("never-smokers") and ex-smokers with a modest smoking history. A subtype of adenocarcinoma, the bronchioloalveolar carcinoma, is more common in female never-smokers, and may have a better long-term survival.

Squamous-cell carcinoma causes about 30% of lung cancers. They typically occur close to large airways. A hollow cavity and associated cell death are commonly found at the center of the tumor.

Nearly 9% of lung cancers are large-cell carcinoma. These are so named because the cancer cells are large, with excess cytoplasm, large nuclei, and conspicuous nucleoli.

In SCLC, the cells contain dense neurosecretory granules (vesicles containing neuroendocrine hormones), which give this tumor an endocrine or paraneoplastic syndrome association. Most cases arise in the larger airways (primary and secondary bronchi). Sixty to seventy percent have extensive disease (which cannot be targeted within a single radiation therapy field) at presentation.

Four main histological subtypes are recognised, although some cancers may contain a combination of different subtypes, such as adenosquamous carcinoma. Rare subtypes include carcinoid tumors, bronchial gland carcinomas, and sarcomatoid carcinomas.

The lungs are a common place for the spread of tumors from other parts of the body. Secondary cancers are classified by the site of origin; for example, breast cancer that has been spread to the lung is called metastatic breast cancer. Metastases often have a characteristic round appearance on chest radiograph.

Primary lung cancers also most commonly metastasize to the brain, bones, liver, and adrenal glands. Immunostaining of a biopsy usually helps determine the original source. The presence of Napsin-A, TTF-1, CK7, and CK20 help confirm the subtype of lung carcinoma. SCLC that originates from neuroendocrine cells may express CD56, neural cell adhesion molecule, synaptophysin, or chromogranin.

Lung cancer staging is an assessment of the degree of spread of the cancer from its original source. It is one of the factors affecting both the prognosis and the potential treatment of lung cancer.

The evaluation of non-small-cell lung carcinoma (NSCLC) staging uses the TNM classification (tumor, node, metastasis). This is based on the size of the primary tumor, lymph node involvement, and distant metastasis.

Using the TNM descriptors, a group is assigned, ranging from occult cancer, through stages 0, IA (one-A), IB, IIA, IIB, IIIA, IIIB, and IV (four). This stage group assists with the choice of treatment and estimation of prognosis.

SCLC has traditionally been classified as "limited stage" (confined to one-half of the chest and within the scope of a single tolerable radiotherapy field) or "extensive stage" (more widespread disease). However, the TNM classification and grouping are useful in estimating prognosis.

For both NSCLC and SCLC, the two general types of staging evaluations are clinical staging and surgical staging. Clinical staging is performed before definitive surgery. It is based on the results of imaging studies (such as CT scans and PET scans) and biopsy results. Surgical staging is evaluated either during or after the operation. It is based on the combined results of surgical and clinical findings, including surgical sampling of thoracic lymph nodes.

Smoking prevention and smoking cessation are effective ways of preventing the development of lung cancer.

While in most countries industrial and domestic carcinogens have been identified and banned, tobacco smoking is still widespread. Eliminating tobacco smoking is a primary goal in the prevention of lung cancer, and smoking cessation is an important preventive tool in this process.

Policy interventions to decrease passive smoking in public areas such as restaurants and workplaces have become more common in many Western countries. Bhutan has had a complete smoking ban since 2005 while India introduced a ban on smoking in public in October 2008. The World Health Organization has called for governments to institute a total ban on tobacco advertising to prevent young people from taking up smoking. They assess that such bans have reduced tobacco consumption by 16% where instituted.

Cancer screening uses medical tests to detect disease in large groups of people who have no symptoms. For individuals with high risk of developing lung cancer, computed tomography (CT) screening can detect cancer and give a person options to respond to it in a way that prolongs life. This form of screening reduces the chance of death from lung cancer by an absolute amount of 0.3% (relative amount of 20%). High risk people are those age 55–74 who have smoked equivalent amount of a pack of cigarettes daily for 30 years including time within the past 15 years.

CT screening is associated with a high rate of falsely positive tests which may result in unneeded treatment. For each true positive scan there are about 19 falsely positives scans. Other concerns include radiation exposure and the cost of testing along with follow up. Research has not found two other available tests—sputum cytology or chest radiograph (CXR) screening tests—to have any benefit.

The United States Preventive Services Task Force (USPSTF) recommends yearly screening using low-dose computed tomography in those who have a total smoking history of 30 pack-years and are between 55 and 80 years old until a person has not been smoking for more than 15 years. Screening should not be done in those with other health problems that would make treatment of lung cancer if found not an option. The English National Health Service was in 2014 re-examining the evidence for screening.

The long-term use of supplemental vitamin A, vitamin C, vitamin D or vitamin E does not reduce the risk of lung cancer. Some studies suggest that people who eat diets with a higher proportion of vegetables and fruit tend to have a lower risk, but this may be due to confounding—with the lower risk actually due to the association of a high fruit and vegetables diet with less smoking. Several rigorous studies have not demonstrated a clear association between diet and lung cancer risk, although meta-analysis that accounts for smoking status may show benefit from a healthy diet.

Treatment for lung cancer depends on the cancer's specific cell type, how far it has spread, and the person's performance status. Common treatments include palliative care, surgery, chemotherapy, and radiation therapy. Targeted therapy of lung cancer is growing in importance for advanced lung cancer.

If investigations confirm NSCLC, the stage is assessed to determine whether the disease is localized and amenable to surgery or if it has spread to the point where it cannot be cured surgically. CT scan and positron emission tomography are used for this determination. If mediastinal lymph node involvement is suspected, the nodes may be sampled to assist staging. Techniques used for this include transthoracic needle aspiration, transbronchial needle aspiration (with or without endobronchial ultrasound), endoscopic ultrasound with needle aspiration, mediastinoscopy, and thoracoscopy. Blood tests and pulmonary function testing are used to assess whether a person is well enough for surgery. If pulmonary function tests reveal poor respiratory reserve, surgery may not be possible.

In most cases of early-stage NSCLC, removal of a lobe of lung (lobectomy) is the surgical treatment of choice. In people who are unfit for a full lobectomy, a smaller sublobar excision (wedge resection) may be performed. However, wedge resection has a higher risk of recurrence than lobectomy. Radioactive iodine brachytherapy at the margins of wedge excision may reduce the risk of recurrence. Rarely, removal of a whole lung (pneumonectomy) is performed. Video-assisted thoracoscopic surgery (VATS) and VATS lobectomy use a minimally invasive approach to lung cancer surgery. VATS lobectomy is equally effective compared to conventional open lobectomy, with less postoperative illness.

In SCLC, chemotherapy and/or radiotherapy is typically used. However the role of surgery in SCLC is being reconsidered. Surgery might improve outcomes when added to chemotherapy and radiation in early stage SCLC.

Radiotherapy is often given together with chemotherapy, and may be used with curative intent in people with NSCLC who are not eligible for surgery. This form of high-intensity radiotherapy is called radical radiotherapy. A refinement of this technique is continuous hyperfractionated accelerated radiotherapy (CHART), in which a high dose of radiotherapy is given in a short time period. Postoperative (adjuvant) thoracic radiotherapy generally should not be used after curative-intent surgery for NSCLC. Some people with mediastinal N2 lymph node involvement might benefit from post-operative radiotherapy.

For potentially curable SCLC cases, chest radiotherapy is often recommended in addition to chemotherapy.
If cancer growth blocks a short section of bronchus, brachytherapy (localized radiotherapy) may be given directly inside the airway to open the passage. Compared to external beam radiotherapy, brachytherapy allows a reduction in treatment time and reduced radiation exposure to healthcare staff. Evidence for brachytherapy, however, is less than that for external beam radiotherapy.

Prophylactic cranial irradiation (PCI) is a type of radiotherapy to the brain, used to reduce the risk of metastasis. PCI is most useful in SCLC. In limited-stage disease, PCI increases three-year survival from 15% to 20%; in extensive disease, one-year survival increases from 13% to 27%.

Recent improvements in targeting and imaging have led to the development of stereotactic radiation in the treatment of early-stage lung cancer. In this form of radiotherapy, high doses are delivered over a number of sessions using stereotactic targeting techniques. Its use is primarily in patients who are not surgical candidates due to medical comorbidities.

For both NSCLC and SCLC patients, smaller doses of radiation to the chest may be used for symptom control (palliative radiotherapy).

The chemotherapy regimen depends on the tumor type. SCLC, even relatively early stage disease, is treated primarily with chemotherapy and radiation. In SCLC, cisplatin and etoposide are most commonly used. Combinations with carboplatin, gemcitabine, paclitaxel, vinorelbine, topotecan, and irinotecan are also used. In advanced NSCLC, chemotherapy improves survival and is used as first-line treatment, provided the person is well enough for the treatment. Typically, two drugs are used, of which one is often platinum-based (either cisplatin or carboplatin). Other commonly used drugs are gemcitabine, paclitaxel, docetaxel, pemetrexed, etoposide or vinorelbine. Platinum-based drugs and combinations that include platinum therapy may lead to a higher risk of serious adverse effects in people over 70 years old.

Adjuvant chemotherapy refers to the use of chemotherapy after apparently curative surgery to improve the outcome. In NSCLC, samples are taken of nearby lymph nodes during surgery to assist staging. If stage II or III disease is confirmed, adjuvant chemotherapy (including or not including postoperative radiotherapy) improves survival by 4% at five years. The combination of vinorelbine and cisplatin is more effective than older regimens. Adjuvant chemotherapy for people with stage IB cancer is controversial, as clinical trials have not clearly demonstrated a survival benefit. Chemotherapy before surgery in NSCLC that can be removed surgically may improve outcomes.

Chemotherapy may be combined with palliative care in the treatment of the NSCLC. In advanced cases, appropriate chemotherapy improves average survival over supportive care alone, as well as improving quality of life. With adequate physical fitness maintaining chemotherapy during lung cancer palliation offers 1.5 to 3 months of prolongation of survival, symptomatic relief, and an improvement in quality of life, with better results seen with modern agents. The NSCLC Meta-Analyses Collaborative Group recommends if the recipient wants and can tolerate treatment, then chemotherapy should be considered in advanced NSCLC.

Several drugs that target molecular pathways in lung cancer are available, especially for the treatment of advanced disease. Erlotinib, gefitinib and afatinib inhibit tyrosine kinase at the epidermal growth factor receptor. Denosumab is a monoclonal antibody directed against receptor activator of nuclear factor kappa-B ligand. It may be useful in the treatment of bone metastases.

Several treatments can be administered via bronchoscopy for the management of airway obstruction or bleeding. If an airway becomes obstructed by cancer growth, options include rigid bronchoscopy, balloon bronchoplasty, stenting, and microdebridement. Laser photosection involves the delivery of laser light inside the airway via a bronchoscope to remove the obstructing tumor.

Palliative care when added to usual cancer care benefits people even when they are still receiving chemotherapy. These approaches allow additional discussion of treatment options and provide opportunities to arrive at well-considered decisions. Palliative care may avoid unhelpful but expensive care not only at the end of life, but also throughout the course of the illness. For individuals who have more advanced disease, hospice care may also be appropriate.

Of all people with lung cancer in the US, 16.8% survive for at least five years after diagnosis. In England and Wales, between 2010 and 2011, overall five-year survival for lung cancer was estimated at 9.5%. Outcomes are generally worse in the developing world. Stage is often advanced at the time of diagnosis. At presentation, 30–40% of cases of NSCLC are stage IV, and 60% of SCLC are stage IV. Survival for lung cancer falls as the stage at diagnosis becomes more advanced: the English data suggest that around 70% of patients survive at least a year when diagnosed at the earliest stage, but this falls to just 14% for those diagnosed with the most advanced disease (stage IV).

Prognostic factors in NSCLC include presence of pulmonary symptoms, large tumor size (>3 cm), non-squamous cell type (histology), degree of spread (stage) and metastases to multiple lymph nodes, and vascular invasion. For people with inoperable disease, outcomes are worse in those with poor performance status and weight loss of more than 10%. Prognostic factors in small cell lung cancer include performance status, biological sex, stage of disease, and involvement of the central nervous system or liver at the time of diagnosis.

For NSCLC, the best prognosis is achieved with complete surgical resection of stage IA disease, with up to 70% five-year survival. People with extensive-stage SCLC have an average five-year survival rate of less than 1%. The average survival time for limited-stage disease is 20 months, with a five-year survival rate of 20%.

According to data provided by the National Cancer Institute, the median age at diagnosis of lung cancer in the US is 70 years, and the median age at death is 72 years. In the US, people with medical insurance are more likely to have a better outcome.

Worldwide, lung cancer is the most-common cancer among men in terms of both incidence and mortality, and among women has the third-highest incidence, and is second after breast cancer in mortality. In 2012, there were 1.82 million new cases worldwide, and 1.56 million deaths due to lung cancer, representing 19.4% of all deaths from cancer. The highest rates are in North America, Europe, and East Asia, with over a third of new cases in China that year. Rates in Africa and South Asia are much lower.

The population segment that is most likely to develop lung cancer is people aged over 50 who have a history of smoking. Unlike the mortality rate in men – which began declining more than 20 years ago, women's lung cancer mortality rates have risen over the last decades, and are just recently beginning to stabilize. In the US, the lifetime risk of developing lung cancer is 8% in men and 6% in women.

For every 3–4 million cigarettes smoked, one lung cancer death can occur. The influence of "Big Tobacco" plays a significant role in smoking. Young nonsmokers who see tobacco advertisements are more likely to smoke. The role of passive smoking is increasingly being recognized as a risk factor for lung cancer, resulting in policy interventions to decrease the undesired exposure of nonsmokers to others' tobacco smoke.

In the US, both black men and black women have a higher incidence. Lung cancer rates are currently lower in developing countries. With increased smoking in developing countries, the rates are expected to increase in the next few years, notably in both China and India.

Also in the US, military veterans have a 25–50% higher rate of lung cancer primarily due to higher rates of smoking. During World War II and the Korean War, asbestos also played a role, and Agent Orange may have caused some problems during the Vietnam War.

Lung cancer is the third most-common cancer in the UK (around 46,400 people were diagnosed with the disease in 2014), and it is the most common cause of cancer-related death (around 35,900 people died in 2014).

From the 1960s, the rates of lung adenocarcinoma started to rise in relation to other kinds of lung cancer, partially due to the introduction of filter cigarettes. The use of filters removes larger particles from tobacco smoke, thus reducing deposition in larger airways. However, the smoker has to inhale more deeply to receive the same amount of nicotine, increasing particle deposition in small airways where adenocarcinoma tends to arise. The incidence of lung adenocarcinoma continue to rise.

Lung cancer was uncommon before the advent of cigarette smoking; it was not even recognized as a distinct disease until 1761. Different aspects of lung cancer were described further in 1810. Malignant lung tumors made up only 1% of all cancers seen at autopsy in 1878, but had risen to 10–15% by the early 1900s. Case reports in the medical literature numbered only 374 worldwide in 1912, but a review of autopsies showed the incidence of lung cancer had increased from 0.3% in 1852 to 5.66% in 1952. In Germany in 1929, physician Fritz Lickint recognized the link between smoking and lung cancer, which led to an aggressive antismoking campaign. The British Doctors' Study, published in the 1950s, was the first solid epidemiological evidence of the link between lung cancer and smoking. As a result, in 1964 the Surgeon General of the United States recommended smokers should stop smoking.

The connection with radon gas was first recognized among miners in the Ore Mountains near Schneeberg, Saxony. Silver has been mined there since 1470, and these mines are rich in uranium, with its accompanying radium and radon gas. Miners developed a disproportionate amount of lung disease, eventually recognized as lung cancer in the 1870s. Despite this discovery, mining continued into the 1950s, due to the USSR's demand for uranium. Radon was confirmed as a cause of lung cancer in the 1960s.

The first successful pneumonectomy for lung cancer was performed in 1933. Palliative radiotherapy has been used since the 1940s. Radical radiotherapy, initially used in the 1950s, was an attempt to use larger radiation doses in patients with relatively early-stage lung cancer, but who were otherwise unfit for surgery. In 1997, CHART was seen as an improvement over conventional radical radiotherapy. With SCLC, initial attempts in the 1960s at surgical resection and radical radiotherapy were unsuccessful. In the 1970s, successful chemotherapy regimens were developed.

Current research directions for lung cancer treatment include immunotherapy, which encourages the body's immune system to attack the tumor cells, epigenetics, and new combinations of chemotherapy and radiotherapy, both on their own and together. Many of these new treatments work through immune checkpoint blockade, disrupting cancer's ability to evade the immune system.

Ipilimumab blocks signaling through a receptor on T cells known as CTLA-4 which dampens down the immune system. It has been approved by the US Food and Drug Administration (FDA) for treatment of melanoma and is undergoing clinical trials for both NSCLC and SCLC.

Other immunotherapy treatments interfere with the binding of programmed cell death 1 (PD-1) protein with its ligand PD-1 ligand 1 (PD-L1), and have been approved as first- and subsequent-line treatments for various subsets of lung cancers. Signaling through PD-1 inactivates T cells. Some cancer cells appear to exploit this by expressing PD-L1 in order to switch off T cells that might recognise them as a threat. Monoclonal antibodies targeting both PD-1 and PD-L1, such as pembrolizumab, nivolumab, atezolizumab, and durvalumab are currently in clinical trials for treatment for lung cancer.

Epigenetics is the study of small, usually heritable, molecular modifications—or "tags"—that bind to DNA and modify gene expression levels. Targeting these tags with drugs can kill cancer cells. Early-stage research in NSCLC using drugs aimed at epigenetic modifications shows that blocking more than one of these tags can kill cancer cells with fewer side effects. Studies also show that giving patients these drugs before standard treatment can improve its effectiveness. Clinical trials are underway to evaluate how well these drugs kill lung cancer cells in humans. Several drugs that target epigenetic mechanisms are in development. Histone deacetylase inhibitors in development include valproic acid, vorinostat, belinostat, panobinostat, entinostat, and romidepsin. DNA methyltransferase inhibitors in development include decitabine, azacytidine, and hydralazine.

The TRACERx project is looking at how NSCLC develops and evolves, and how these tumors become resistant to treatment. The project will look at tumor samples from 850 NSCLC patients at various stages including diagnosis, after first treatment, post-treatment, and relapse. By studying samples at different points of tumor development, the researchers hope to identify the changes that drive tumor growth and resistance to treatment. The results of this project will help scientists and doctors gain a better understanding of NSCLC and potentially lead to the development of new treatments for the disease.

For lung cancer cases that develop resistance to epidermal growth factor receptor (EGFR) and anaplastic lymphoma kinase (ALK) tyrosine kinase inhibitors, new drugs are in development. New EGFR inhibitors include afatinib and dacomitinib. An alternative signaling pathway, c-Met, can be inhibited by tivantinib and onartuzumab. New ALK inhibitors include crizotinib and ceritinib. If the MAPK/ERK pathway is involved, the BRAF kinase inhibitor dabrafenib and the MAPK/MEK inhibitor trametinib may be beneficial.

Lung cancer stem cells are often resistant to conventional chemotherapy and radiotherapy. This may lead to relapse after treatment. New approaches target protein or glycoprotein markers that are specific to the stem cells. Such markers include CD133, CD90, ALDH1A1, CD44 and ABCG2. Signaling pathways such as Hedgehog, Wnt and Notch are often implicated in the self-renewal of stem cell lines. Thus treatments targeting these pathways may help to prevent relapse.


</doc>
<doc id="18557" url="https://en.wikipedia.org/wiki?curid=18557" title="Laurence of Canterbury">
Laurence of Canterbury

Laurence (died 2 February 619) was the second Archbishop of Canterbury from about 604 to 619. He was a member of the Gregorian mission sent from Italy to England to Christianise the Anglo-Saxons from their native Anglo-Saxon paganism, although the date of his arrival is disputed. He was consecrated archbishop by his predecessor, Augustine of Canterbury, during Augustine's lifetime, to ensure continuity in the office. While archbishop, he attempted unsuccessfully to resolve differences with the native British bishops by corresponding with them about points of dispute. Laurence faced a crisis following the death of King Æthelberht of Kent, when the king's successor abandoned Christianity; he eventually reconverted. Laurence was revered as a saint after his death in 619.

Laurence was part of the Gregorian mission originally dispatched from Rome in 595 to convert the Anglo-Saxons from their native paganism to Christianity; he landed at Thanet, Kent, with Augustine in 597, or, as some sources state, first arrived in 601 and was not a part of the first group of missionaries. He had been a monk in Rome before his travels to England, but nothing else is known of his history or background. The medieval chronicler Bede says that Augustine sent Laurence back to Pope Gregory I to report on the success of converting King Æthelberht of Kent and to carry a letter with questions for the pope. Accompanied by Peter of Canterbury, another missionary, he set off some time after July 598, and had returned by June 601. He brought back with him Gregory's replies to Augustine's questions, a document commonly known as the "Libellus responsionum", that Bede incorporated in his "Historia ecclesiastica gentis Anglorum". Laurence is probably the Laurence referred to in the letter from Gregory to Bertha, queen of Kent. In that letter, Gregory praises Bertha for her part in the conversion of her husband, details of which Gregory says he received from Laurence the priest. It is known that Laurence returned to England with Mellitus and others of the second group of missionaries in the summer of 601, but there is no record of Peter being with them.

Laurence succeeded Augustine to the see of Canterbury in about 604, and ruled until his death on 2 February 619. To secure the succession, Augustine had consecrated Laurence before he died, even though that was prohibited by canon law. Augustine was afraid though that if someone did not step into the office immediately, it would damage the missionary efforts in Britain. However, Laurence never received a pallium from Rome, so he may have been considered uncanonical by the papacy. Bede makes a point of comparing Augustine's action in consecrating Laurence to Saint Peter's action of consecrating Clement as Bishop of Rome during Peter's lifetime, which the theologian J. Robert Wright believes may be Bede's way of criticising the practices of the church in his day.

In 610 Laurence received letters from Pope Boniface IV, addressed to him as archbishop and Augustine's successor. The correspondence was in response to Laurence having sent Mellitus to Rome earlier in 610, to solicit advice from the papacy on matters concerning the English Church. While in Rome Mellitus attended a synod, and brought the synodical decrees back with him to Laurence.

In 613 Laurence consecrated the monastery church built by Augustine in Canterbury, and dedicated it to saints Peter and Paul; it was later re-consecrated as St Augustine's Abbey, Canterbury. Laurence also wrote to the bishops in the lands held by the Scots and by the Britons, urging them to hold Easter on the day that the Roman church celebrated it, instead of their traditional date, part of the Easter controversy. The letter is also preserved in Bede's history. Laurence in 609 stated that Dagan, a native bishop, would not eat with Laurence or share a roof with the archbishop, due to the differences between the two Churches.

Æthelberht died in 616, during Laurence's tenure; his son Eadbald abandoned Christianity in favour of Anglo-Saxon paganism, forcing many of the Gregorian missionaries to flee the pagan backlash that followed Æthelberht's death. Among them in Gaul were Mellitus, who was Bishop of London, and Justus, who was Bishop of Rochester. Remaining in Britain, Laurence succeeded in reconverting Eadbald to Christianity. Bede relates the story that Laurence had been prepared to give up when he was visited by St Peter in a dream or vision. St Peter chastised Laurence and whipped him, and the marks of the whipping remained after the vision or dream ended. Laurence then displayed them to Eadbald, and the king was converted on the spot. Bede, however, hints that it was the death of some of the leaders of the pagan party in battle that really persuaded Laurence to stay. According to Benedicta Ward, a historian of Christianity, Bede uses the story of the whipping as an example of how suffering was a reminder of Christ's suffering for humans, and how that example could lead to conversion. Wright argues that another point Bede is making is that it is because of the intercession of St Peter himself that the mission continued. David Farmer, in the "Oxford Dictionary of Saints", suggests that the whipping story may have been a blending of the "Quo Vadis" story with some information given by Jerome in a letter.

Modern historians have seen political overtones in the pagan reaction. The historian D. P. Kirby sees Eadbald's actions as a repudiation of his father's pro-Frankish policies. Alcuin, a later medieval writer, wrote that Laurence was "censured by apostolic authority". This may have been a letter from Pope Adeodatus I, commanding Laurence to stay in Kent. Kirby goes on to argue that it was Justus, not Laurence, who converted Eadbald, and this while Justus was archbishop, sometime around 624. Not all historians agree with this argument, however. Nicholas Brooks states that the king was converted during Laurence's archiepiscopate, within a year of him succeeding his father. The historian Barbara Yorke argues that there were two co-rulers of Kent after Æthelberht's death, Eadbald and a Æthelwald, and that Eadbald was converted by Laurence while Æthelwald was converted by Justus after his return to Rochester. Another factor in the pagan reaction was Laurence's objection to Eadbald's marriage to his father's widow, something that Christians considered to be unlawful.

All efforts to extend the church beyond Kent encountered difficulties due to the attitude of King Rædwald of East Anglia, who had become the leading king in the south after Æthelberht's death. Rædwald was converted before the death of Æthelberht, perhaps at the urging of Æthelberht, but his kingdom was not, and Rædwald seems to have converted only to the extent of placing a Christian altar in his pagan temple. It proved impossible for Mellitus to return to London as bishop, although Justus did resume his duties at Rochester.

Laurence died on 2 February 619, and was buried in the abbey of St Peter and Paul in Canterbury, later renamed St Augustine's; his relics, or remains, were moved, or translated, to the new church of St Augustine's in 1091. His shrine was in the axial chapel of the abbey church, flanking the shrine of Augustine, his predecessor. Laurence came to be regarded as a saint, and was given the feast day of 3 February. The ninth century Stowe Missal commemorates his feast day, along with Mellitus and Justus. A "Vita" (or "Life") was written about the time of his translation, by Goscelin, but it is mainly based on information in Bede. His tomb was opened in 1915. Besides his feast day, the date of his translation, 13 September, was also celebrated after his death. Laurence's tenure as archbishop is mainly remembered for his failure to secure a settlement with the Celtic church, and for his reconversion of Eadbald following Æthelbert's death. He was succeeded as archbishop by Mellitus, the Bishop of London.




</doc>
<doc id="18739" url="https://en.wikipedia.org/wiki?curid=18739" title="Laika">
Laika

Laika (; c. 1954 – 3 November 1957) was a Soviet space dog who became one of the first animals in space, and the first animal to orbit the Earth. Laika, a stray mongrel from the streets of Moscow, was selected to be the occupant of the Soviet spacecraft Sputnik 2 that was launched into outer space on 3 November 1957.

Little was known about the impact of spaceflight on living creatures at the time of Laika's mission, and the technology to de-orbit had not yet been developed, so Laika's survival was never expected. Some scientists believed humans would be unable to survive the launch or the conditions of outer space, so engineers viewed flights by animals as a necessary precursor to human missions. The experiment aimed to prove that a living passenger could survive being launched into orbit and endure a micro-g environment, paving the way for human spaceflight and providing scientists with some of the first data on how living organisms react to spaceflight environments.

Laika died within hours from overheating, possibly caused by a failure of the central R-7 sustainer to separate from the payload. The true cause and time of her death were not made public until 2002; instead, it was widely reported that she died when her oxygen ran out on day six or, as the Soviet government initially claimed, she was euthanised prior to oxygen depletion.

On 11 April 2008, Russian officials unveiled a monument to Laika. A small monument in her honour was built near the military research facility in Moscow that prepared Laika's flight to space. It portrayed a dog standing on top of a rocket. She also appears on the Monument to the Conquerors of Space in Moscow.

After the success of Sputnik 1 in October 1957, Nikita Khrushchev, the Soviet leader, wanted a spacecraft launched on 7 November 1957, the 40th anniversary of the October Revolution. Construction had already started on a more sophisticated satellite, but it would not be ready until December; this satellite would later become Sputnik 3.

Meeting the November deadline meant building a new craft. Khrushchev specifically wanted his engineers to deliver a "space spectacular", a mission that would repeat the triumph of Sputnik 1, stunning the world with Soviet prowess. Planners settled on an orbital flight with a dog. Soviet rocket engineers had long intended a canine orbit before attempting human spaceflight; since 1951, they had lofted 12 dogs into sub-orbital space on ballistic flights, working gradually toward an orbital mission set for some time in 1958. To satisfy Khrushchev's demands, they expedited the orbital canine flight for the November launch.

According to Russian sources, the official decision to launch Sputnik 2 was made on 10 or 12 October, leaving less than four weeks to design and build the spacecraft. Sputnik 2, therefore, was something of a rush job, with most elements of the spacecraft being constructed from rough sketches. Aside from the primary mission of sending a living passenger into space, Sputnik 2 also contained instrumentation for measuring solar irradiance and cosmic rays.

The craft was equipped with a life-support system consisting of an oxygen generator and devices to avoid oxygen poisoning and to absorb carbon dioxide. A fan, designed to activate whenever the cabin temperature exceeded , was added to keep the dog cool. Enough food (in a gelatinous form) was provided for a seven-day flight, and the dog was fitted with a bag to collect waste. A harness was designed to be fitted to the dog, and there were chains to restrict her movements to standing, sitting, or lying down; there was no room to turn around in the cabin. An electrocardiogram monitored heart rate and further instrumentation tracked respiration rate, maximum arterial pressure, and the dog's movements.

Laika was found as a stray wandering the streets of Moscow. Soviet scientists chose to use Moscow strays since they assumed that such animals had already learned to endure conditions of extreme cold and hunger. This specimen was a mongrel female, approximately three years old. Another account reported that she weighed about . Soviet personnel gave her several names and nicknames, among them Kudryavka (Russian for "Little Curly"), Zhuchka ("Little Bug"), and Limonchik ("Little Lemon"). Laika, the Russian name for several breeds of dogs similar to the husky, was the name popularised around the world. The American press dubbed her Muttnik ("mutt" + suffix "-nik") as a pun on Sputnik, or referred to her as "Curly". Her true pedigree is unknown, although it is generally accepted that she was part husky or other Nordic breed, and possibly part terrier. NASA refers to Laika as a "part-Samoyed terrier." A Russian magazine described her temperament as phlegmatic, saying that she did not quarrel with other dogs. Vladimir Yazdovsky, who led the program of test dogs used on rockets, in a later publication wrote that “Laika was quiet and charming”.

The Soviet Union and United States had previously sent animals only on sub-orbital flights. Three dogs were trained for the Sputnik 2 flight: Albina, Mushka, and Laika. Soviet space-life scientists Vladimir Yazdovsky and Oleg Gazenko trained the dogs.

To adapt the dogs to the confines of the tiny cabin of Sputnik 2, they were kept in progressively smaller cages for periods of up to 20 days. The extensive close confinement caused them to stop urinating or defecating, made them restless, and caused their general condition to deteriorate. Laxatives did not improve their condition, and the researchers found that only long periods of training proved effective. The dogs were placed in centrifuges that simulated the acceleration of a rocket launch and were placed in machines that simulated the noises of the spacecraft. This caused their pulses to double and their blood pressure to increase by 30–65 torr. The dogs were trained to eat a special high-nutrition gel that would be their food in space.

Before the launch, one of the mission scientists took Laika home to play with his children. In a book chronicling the story of Soviet space medicine, Dr. Vladimir Yazdovsky wrote, "Laika was quiet and charming...I wanted to do something nice for her: She had so little time left to live."

Vladimir Yazdovsky made the final selection of dogs and their designated roles. Laika was to be the "flight dog"—a sacrifice to science on a one-way mission to space. Albina, who had already flown twice on a high-altitude test rocket, was to act as Laika's backup. The third dog Mushka was a "control dog"—she was to stay on the ground and be used to test instrumentation and life support.

Before leaving for the Baikonur Cosmodrome, Yazdovsky and Gazenko conducted surgery on the dogs, routing the cables from the transmitters to the sensors that would measure breathing, pulse, and blood pressure.

Because the existing airstrip at Turatam near the cosmodrome was small, the dogs and crew had to be first flown aboard a Tu-104 plane to Tashkent. From there, a smaller and lighter Il-14 plane took them to Turatam. Training of dogs continued upon arrival; one after another they were placed in the capsules to get familiar with the feeding system.

According to a NASA document, Laika was placed in the capsule of the satellite on 31 October 1957—three days before the start of the mission. At that time of year, the temperatures at the launch site were extremely cold, and a hose connected to a heater was used to keep her container warm. Two assistants were assigned to keep a constant watch on Laika before launch. Just prior to liftoff on 3 November 1957, from Baikonur Cosmodrome, Laika's fur was sponged in a weak alcohol solution and carefully groomed, while iodine was painted onto the areas where sensors would be placed to monitor her bodily functions.

One of the technicians preparing the capsule before final liftoff stated that "after placing Laika in the container and before closing the hatch, we kissed her nose and wished her bon voyage, knowing that she would not survive the flight."

The exact time of the liftoff varies from source to source and is mentioned as 05:30:42 Moscow Time or 07:22 Moscow Time.

At peak acceleration Laika's respiration increased to between three and four times the pre-launch rate. The sensors showed her heart rate was 103 beats/min before launch and increased to 240 beats/min during the early acceleration. After reaching orbit, Sputnik 2's nose cone was jettisoned successfully; however the "Block A" core did not separate as planned, preventing the thermal control system from operating correctly. Some of the thermal insulation tore loose, raising the cabin temperature to . After three hours of weightlessness, Laika's pulse rate had settled back to 102 beats/min, three times longer than it had taken during earlier ground tests, an indication of the stress she was under. The early telemetry indicated that Laika was agitated but eating her food. After approximately five to seven hours into the flight, no further signs of life were received from the spacecraft.

The Soviet scientists had planned to euthanise Laika with a poisoned serving of food. For many years, the Soviet Union gave conflicting statements that she had died either from asphyxia, when the batteries failed, or that she had been euthanised. Many rumours circulated about the exact manner of her death. In 1999, several Russian sources reported that Laika had died when the cabin overheated on the fourth orbit. In October 2002, Dimitri Malashenkov, one of the scientists behind the Sputnik 2 mission, revealed that Laika had died by the fourth circuit of flight from overheating. According to a paper he presented to the World Space Congress in Houston, Texas, "It turned out that it was practically impossible to create a reliable temperature control system in such limited time constraints."

Over five months later, after 2,570 orbits, Sputnik 2—including Laika's remains—disintegrated during re-entry on 14 April 1958.

Due to the overshadowing issue of the Soviet vs. U.S. Space Race, the ethical issues raised by this experiment went largely unaddressed for some time. As newspaper clippings from 1957 show, the press was initially focused on reporting the political perspective, while the health and retrieval—or lack thereof—of Laika only became an issue later.

Sputnik 2 was not designed to be retrievable, and Laika had always been intended to die. The mission sparked a debate across the globe on the mistreatment of animals and animal testing in general to advance science. In the United Kingdom, the National Canine Defence League called on all dog owners to observe a minute's silence, while the Royal Society for the Prevention of Cruelty to Animals (RSPCA) received protests even before Radio Moscow had finished announcing the launch. Animal rights groups at the time called on members of the public to protest at Soviet embassies. Others demonstrated outside the United Nations in New York. These protests were largely stirred up and instrumentalized as an ideological struggle by various interest groups. Laboratory researchers in the U.S. offered some support for the Soviets, at least before the news of Laika's death.

In the Soviet Union, there was less controversy. Neither the media, books in the following years, nor the public openly questioned the decision to send a dog into space. In 1998, after the collapse of the Soviet regime, Oleg Gazenko, one of the scientists responsible for sending Laika into space, expressed regret for allowing her to die:
In other Warsaw Pact countries, open criticism of the Soviet space program was difficult because of political censorship, but there were notable cases of criticism in Polish scientific circles. A Polish scientific periodical, ""Kto, Kiedy, Dlaczego"" ("Who, When, Why"), published in 1958, discussed the mission of Sputnik 2. In the periodical's section dedicated to astronautics, Krzysztof Boruń described the Sputnik 2 mission as "regrettable" and criticised not bringing Laika back to Earth alive as "undoubtedly a great loss for science".

Laika is memorialised in the form of a statue and plaque at Star City, Russia, the Russian Cosmonaut training facility. Created in 1997, Laika is positioned behind the cosmonauts with her ears erect. The Monument to the Conquerors of Space, constructed in 1964, also includes Laika. On 11 April 2008 at the military research facility where staff had been responsible for readying Laika for the flight, officials unveiled a monument of her poised on top of a space rocket. Stamps and envelopes picturing Laika were produced, as well as branded cigarettes and matches.

Future space missions carrying dogs would be designed to be recovered. Four other dogs died in Soviet space missions: Bars and Lisichka were killed when their R-7 rocket exploded shortly after launch on 28 July 1960; Pchyolka and Mushka died when Korabl-Sputnik 3 was purposely destroyed with an explosive charge to prevent foreign powers from inspecting the capsule after a wayward atmospheric reentry trajectory on 1 December 1960.

Although never shown, Laika is prominently mentioned in the 1985 film "My Life as a Dog", in which the main character (a young Swedish boy in the late 1950s) identifies strongly with the dog. "Laika", a 2007 graphic novel by Nick Abadzis giving a fictionalized account of Laika's life, won the Eisner Award for Best Publication for Teens.





</doc>
<doc id="18756" url="https://en.wikipedia.org/wiki?curid=18756" title="Master of Puppets">
Master of Puppets

Master of Puppets is the third studio album by American heavy metal band Metallica. It was released on March 3, 1986 by Elektra Records. Recorded at the Sweet Silence Studios with producer Flemming Rasmussen, it was the first Metallica album released on a major record label. "Master of Puppets" was the band's last album to feature bassist Cliff Burton, who died in a bus accident in Sweden during the album's promotional tour. The album peaked at number 29 on the "Billboard" 200 and became the first thrash metal album to be certified platinum. It was certified 6× platinum by the Recording Industry Association of America (RIAA) in 2003 for shipping six million copies in the United States. The album was eventually certified 6× platinum by Music Canada and gold by the British Phonographic Industry (BPI).

Released to critical acclaim, the album is considered to be one of the best in history, and one of the most influential to heavy metal. Its driving, virtuosic music and angry political lyrics drew praise from critics outside the metal community. With its atmospheric and meticulously performed songs, critics credit it for consolidating the American thrash metal scene. Many bands from all genres of heavy metal have covered the album's songs, including tribute albums. "Master of Puppets" was deemed "culturally, historically, or aesthetically significant" enough for preservation in the National Recording Registry by the United States Library of Congress in 2015, the first metal recording to do so.

The cover was designed by Metallica and Peter Mensch and painted by Don Brautigam. It depicts a cemetery field of white crosses tethered to strings, manipulated by a pair of hands in a blood-red sky. Instead of releasing a single or video in advance of the album's release, Metallica embarked on a five-month American tour in support of Ozzy Osbourne. The European leg was canceled after Burton's death in September 1986, and the band returned home to audition a new bassist. Metallica honored the album's 20th anniversary on the Escape from the Studio '06 tour, by playing it in its entirety. A remastered version was released in November 2017.

Metallica's 1983 debut "Kill 'Em All" laid the foundation for thrash metal with its aggressive musicianship and vitriolic lyrics. The album revitalized the American underground scene, and inspired similar records by contemporaries. The band's second album "Ride the Lightning" extended the limits of the genre with its more sophisticated songwriting and improved production. The album caught the attention of Elektra Records representative Michael Alago, who signed the group to an eight-album deal in the fall of 1984, halfway through the album's promotional tour. Elektra reissued "Ride the Lightning" on November 19, and the band began touring larger venues and festivals throughout 1985. After parting with manager Jon Zazula, Metallica hired Q Prime executives Cliff Burnstein and Peter Mensch. During the summer, the band played the Monsters of Rock festival at Castle Donington, alongside Bon Jovi and Ratt to an audience of 70,000. 

Metallica was motivated to make an album that would impress critics and fans, and began writing new material in mid-1985. Lead vocalist and rhythm guitarist James Hetfield and drummer Lars Ulrich were the main songwriters on the album, already titled "Master of Puppets". The two developed ideas at a garage in El Cerrito, California, before inviting bassist Cliff Burton and guitarist Kirk Hammett for rehearsals. Hetfield and Ulrich described the songwriting process as starting with "guitar riffs, assembled and reassembled until they start to sound like a song". After that, the band came up with a song title and topic, and Hetfield wrote lyrics to match the title. "Master of Puppets" is Metallica's first album not to feature songwriting contributions from former lead guitarist Dave Mustaine. Mustaine claimed he had co-written "Leper Messiah", based on an old song called "The Hills Ran Red". The band denied this, but stated that one section incorporated Mustaine's ideas.

The band was not satisfied with the acoustics of the American studios they considered, and decided to record in Ulrich's native Denmark. Ulrich took drum lessons, and Hammett worked with Joe Satriani to learn how to record more efficiently. Ulrich was in talks with Rush's bassist and vocalist Geddy Lee to produce the album, but the collaboration never materialized because of uncoordinated schedules. Metallica recorded the album with producer Flemming Rasmussen at Sweet Silence Studios in Copenhagen, Denmark, from September 1 to December 27, 1985. The writing of all the songs except "Orion" and "The Thing That Should Not Be" was completed before the band's arrival in Copenhagen. Rasmussen stated that the band brought well-prepared demos of the songs, and only slight changes were made to the compositions in the studio. The recording took longer than the previous album because Metallica had developed a sense of perfectionism and had higher ambitions. Metallica eschewed the slick production and synthesizers of contemporary hard rock and heavy metal albums by Bon Jovi, Iron Maiden, and Judas Priest. With a reputation for drinking, the band stayed sober on recording days. Hammett recalled that the group was "just making another album" at the time and "had no idea that the record would have such a range of influence that it went on to have". He also said that the group was "definitely peaking" at the time and that the album had "the sound of a band really gelling, really learning how to work well together".

Rasmussen and Metallica did not manage to complete the mixtapes as planned. Instead, the multitrack recordings were sent in January 1986 to Michael Wagener, who finished the album's mixing. The cover was designed by Metallica and Peter Mensch and painted by Don Brautigam. It depicts a cemetery field of white crosses tethered to strings, manipulated by a pair of hands in a blood-red sky. Ulrich explained that the artwork summarized the lyrical content of the album—people being subconsciously manipulated. The original artwork was sold at Rockefeller Plaza, New York City for $28,000 in 2008. The band mocked the warning stickers promoted by the PMRC with a facetious Parental Advisory label on the cover: "The only track you probably won't want to play is 'Damage, Inc.' due to the multiple use of the infamous 'F' word. Otherwise, there aren't any 'shits', 'fucks', 'pisses', 'cunts', 'motherfuckers', or 'cocksuckers' anywhere on this record".

The album was recorded with the following equipment: Hammett's guitars were a 1974 Gibson Flying V, a Jackson Randy Rhoads, and a Fernandes Stratocaster copy; Hetfield used a Jackson King V played through a Mesa Boogie Mark IIC+ amplifier modified as a pre-amp; Burton played an Aria Pro II SB1000 through Mesa Boogie amplifier heads and cabinets; Ulrich played Tama drum equipment, and borrowed a rare S.L.P. Black Brass from Def Leppard drummer Rick Allen.

"Master of Puppets" features dynamic music and thick arrangements. Metallica delivered a more refined approach and performance compared to the previous two albums, with multilayered songs and technical dexterity. This album and its predecessor "Ride the Lightning" follow a similar track sequencing: both open with an up-tempo song with an acoustic intro, followed by a lengthy title track, and a fourth track with ballad qualities. Although both albums are similarly structured, the musicianship on "Master of Puppets" is more powerful and epic in scope, with tight rhythms and delicate guitar solos. According to music writer Joel McIver, "Master of Puppets" introduced a new level of heaviness and complexity in thrash metal, displaying atmospheric and precisely executed songs. Hetfield's vocals had matured from the hoarse shouting of the first two albums to a deeper, in-control yet aggressive style. The songs explore themes such as control and the abuse of power. The lyrics describe the consequences of alienation, oppression, and feelings of powerlessness. Author Ryan Moore thought the lyrics depicted "ominous yet unnamed forces of power wielding total control over helpless human subjects". The lyrics were considered perceptive and harrowing, and were praised for being honest and socially conscious by writer Brock Helander. Referring to the epic proportions of the songs, BBC Music's Eamonn Stack stated that "at this stage in their careers Metallica weren't even doing songs, they were telling stories". The compositions and arrangements benefited from Burton's classical training and understanding of harmony.

"Battery" refers to angry violence, as in the term "assault and battery". Some critics contended that the title actually refers to an artillery battery, and interpreted it as "Hetfield of a war tactic as the aggressor" personifying destruction. The song begins with bass-heavy acoustic guitars that build upon multitracked layers until they are joined by a sonic wall of distorted electric guitars. It then breaks into fast, aggressive riffing featuring off-beat rhythms and heavily distorted minor dyads where root-fifth power chords might be expected. Hetfield improvised the riff while relaxing in London. "Master of Puppets" consists of several riffs with odd meters and a cleanly picked middle section with melodic solo. The song shares a similar structure with "The Four Horsemen" from the band's first album: two verse-chorus sets lead to a lengthy interlude to another verse-chorus set. The opening and pre-verse sections feature fast downstroked chromatic riffing at 220 beats per minute. The persistent and precise eighth-note riffing of the verse is made more intense by switching to an off-kilter time signature on each fourth bar. A lengthy interlude follows the second chorus, beginning with a clean, arpeggiated section over which Hetfield contributes a melodic solo; the riffing becomes distorted and progressively more heavy and Hammett provides a more virtuosic solo before the song returns to the main verse. The song closes with a fade-out of sinister laughter. The theme is cocaine addiction, a topic considered taboo at the time.

"The Thing That Should Not Be" was inspired by the Cthulhu Mythos created by famed horror writer H.P. Lovecraft, with notable direct references to "The Shadow Over Innsmouth" and to Cthulhu himself, who is the subject matter of the song's chorus. It is considered the heaviest track on the album, with the main riff emulating a beast dragging itself into the sea. The Black Sabbath-influenced guitars are downtuned, creating slow and moody ambiance. "Welcome Home (Sanitarium)" was based on Ken Kesey's novel "One Flew Over the Cuckoo's Nest" and conveys the thoughts of a patient unjustly caged in a mental institution. The song opens with a section of clean single strings and harmonics. The clean, arpeggiated main riff is played in alternating and time signatures. The song is structured with alternating somber clean guitars in the verses, and distorted heavy riffing in the choruses, unfolding into an aggressive finale. This structure follows a pattern of power ballads Metallica set with "Fade to Black" on "Ride the Lightning" and would revisit with "One" on "...And Justice for All".

"Disposable Heroes" is an anti-war song about a young soldier whose fate is controlled by his superiors. With sections performed at 220 beats per minute, it is one of the most intense tracks on the record. The guitar passage at the end of each verse was Hammett's imitation of the sort of music he found in war films. The syncopated riffing of "Leper Messiah" challenges the hypocrisy of the televangelism that emerged in the 1980s. The song describes how people are willingly turned into blind religious followers who mindlessly do whatever they are told. The 136 beats per minute mid-tempo riffing of the verses culminates in a descending chromatic riff in the chorus; it increases to a galloping 184 beats per minute for the middle section that climaxes in a distorted scream of "Lie!". The title derives from the lyrics to the David Bowie song "Ziggy Stardust". "Orion" is a multipart instrumental highlighting Burton's bass playing. It opens with a fade-in bass section, heavily processed to resemble an orchestra. It continues with mid-tempo riffing, followed by a bass solo at half-tempo. The tempo accelerates during the latter part, and ends with music fading out. Burton arranged the middle section, which features its moody bass line and multipart guitar harmonies. "Damage, Inc." rants about senseless violence and reprisal at an unspecified target. It starts with a series of reversed bass chords based on the chorale prelude of Bach's "Come, Sweet Death". The song then jumps into a rapid rhythm with a pedal-point riff in E that Hammett says was influenced by Deep Purple.

"Master of Puppets" was hailed as a masterpiece by critics outside of the heavy metal audience and cited by some as the genre's greatest album. In a contemporary review, Tim Holmes of "Rolling Stone" asserted that the band had redefined heavy metal with the technical skill and subtlety showcased on the album, which he described as "the sound of global paranoia". "Kerrang!" wrote that "Master of Puppets" "finally put Metallica into the big leagues where they belong". Editor Tom King said Metallica was at an "incredible song-writing peak" during the recording sessions, partially because Burton contributed to the songwriting. By contrast, "Spin" magazine's Judge I-Rankin was disappointed with the album and said, although the production is exceptional and Metallica's experimentation is commendable, it eschews the less "intellectual" approach of "Kill 'Em All" for a MDC-inspired direction that is inconsistent.

In a retrospective review, AllMusic's Steve Huey viewed "Master of Puppets" as Metallica's best album and remarked that, although it was not as unexpected as "Ride the Lightning", it is a more musically and thematically consistent album. Greg Kot of the "Chicago Tribune" said the songs were the band's most intense at that point, and veer toward "the progressive tendency of Rush." Adrien Begrand of PopMatters praised the production as "a metal version of Phil Spector's Wall of Sound" and believed none of Metallica's subsequent albums could match its passionate and intense musical quality. BBC Music's Eamonn Stack called the album "hard, fast, rock with substance" and likened the songs to stories of "biblical proportions". Canadian journalist Martin Popoff compared the album to "Ride the Lightning" and found "Master of Puppets" not a remake, though similar in "awesome power and effect". Robert Christgau was more critical. Writing in "" (1990), he said the band's energy and political motivations are respectable, but the music evokes clichéd images of "revolutionary heroes" who are "male chauvinists too inexperienced to know better".

Released on March 3, 1986, the album had a 72-week run on the "Billboard" 200 album charts and earned the band its first gold certification. The album debuted on March 29, 1986, at number 128 and peaked at number 29 on the "Billboard" 200 chart. "Billboard" reported that 300,000 copies were sold in its first three weeks. More than 500,000 copies were sold in its first year, even with virtually no radio airplay and no music videos. In 2003, "Master of Puppets" was certified 6× platinum by the Recording Industry Association of America (RIAA), with six million copies shipped in the United States. Between the beginning of the Nielsen SoundScan era in 1991 and 2009, 4,578,000 copies were sold. The album was less successful on an international level, entering the top 40 on the German and Swiss album charts in its inaugural year. In 2004, it peaked within the top 10 in Finland and into the top 15 in Sweden. In 2008, the album reached the top 40 on the Australian and Norwegian album charts. It received 6× platinum certification from Music Canada and a golden award from the British Phonographic Industry (BPI) for shipments of 600,000 and 100,000 copies, respectively.

"Master of Puppets" has appeared in several publications' best album lists. It was ranked number 167 on the list of Rolling Stone's 500 Greatest Albums of All Time; the magazine would later rank it second on its 2017 list of "100 Greatest Metal Albums of All Time", behind Black Sabbath's "Paranoid". "Time" included the album in its list of the 100 best albums of all time. According to the magazine's Josh Tyrangiel, "Master of Puppets" reinforced the velocity of playing in heavy metal and diminished some of its clichés. "Slant Magazine" placed the album at number 90 on its list of the best albums of the 1980s, saying "Master of Puppets" is Metallica's best and most sincere recording. The album is featured in Robert Dimery's book "1001 Albums You Must Hear Before You Die". IGN named "Master of Puppets" the best heavy metal album of all time. The website stated it was Metallica's best because it "built upon and perfected everything they had experimented with prior" and that "all the pieces come together in glorious cohesion". Music journalist Martin Popoff also ranked it the best heavy metal album. The album was voted the fourth greatest guitar album of all time by "Guitar World" in 2006, and the title track ranked number 61 on the magazine's list of the 100 greatest guitar solos. "Total Guitar" ranked the main riff of the title track at number 7 among the top 20 guitar riffs. The April 2006 edition of "Kerrang!" was dedicated to the album and gave away to readers the cover album "Master of Puppets: Remastered".

"Master of Puppets " became thrash metal's first platinum album and by the early 1990s thrash metal successfully challenged and redefined the mainstream of heavy metal. Metallica and a few other bands headlined arena concerts and appeared regularly on MTV, although radio play remained incommensurate with their popularity. "Master of Puppets" is widely accepted as the genre's most accomplished album, and paved the way for subsequent development. The album, in the words of writer Christopher Knowles, "ripped Metallica away from the underground and put them atop the metal mountain". David Hayter from "Guitar Planet" recognized the album as one of the most influential records ever made and a benchmark by which other metal albums should be judged. MTV's Kyle Anderson had similar thoughts, saying that 25 years after its release the album remained a "stone cold classic". Carlos Ramirez from Noisecreep believes that "Master of Puppets" stands as one of the most representative albums of its genre.

1986 is seen as a pinnacle year for thrash metal in which the genre broke out of the underground due to albums such as Megadeth's "Peace Sells... but Who's Buying?" and Slayer's "Reign in Blood". Anthrax released "Among the Living" in 1987, and by the end of the year these bands, alongside Metallica, were being called the "Big Four" of thrash metal. "Master of Puppets" frequently tops critic and fan polls of favorite thrash metal albums—the most frequent rival is Slayer's "Reign in Blood", also released in 1986 and also considered that band's peak. The rivalry partially stemmed from a contrast in approaches on the two albums, between the sophistication of "Master of Puppets" and the velocity of "Reign in Blood". Histories of the band tend to position "Ride the Lightning", "Master of Puppets", and "...And Justice for All" as a trilogy over the course of which the band's music progressively matured and became more sophisticated. In 2015, the album was deemed "culturally, historically, or aesthetically significant" by the Library of Congress and was selected for preservation in the National Recording Registry.

Metallica opted for extensive touring instead of releasing a single or video to promote the album. Metallica spent March to August 1986 touring as the opening act for Ozzy Osbourne in the United States, the first tour Metallica played to arena-sized audiences. During sound checks, the group played riffs from Osbourne's previous band Black Sabbath, which Osbourne perceived as a mockery toward him. Referring to that occasion, Ulrich stated that Metallica was honored to play with Osbourne, who treated the band well on the tour. Metallica was noted by the media for its excessive drinking habit while touring and earned the nickname "Alcoholica". The band members occasionally wore satirical T-shirts reading "Alcoholica/Drank 'Em All". The band usually played a 45-minute set often followed by an encore. According to Ulrich, the audiences in bigger cities were already familiar with Metallica's music, unlike in the smaller towns they've visited. "In the B-markets, people really don't know what we're all about. But after 45 or 50 minutes we can tell we've won them over. And fans who come to hear Ozzy go home liking Metallica." Metallica won over Osbourne's fans and slowly began to establish a mainstream following.

The tour, however, was notable for several incidents. Hetfield broke his wrist in a mid-tour skateboarding accident, and his guitar technician John Marshall played rhythm guitar on several dates. The European leg of the Damage, Inc. Tour commenced in September, with Anthrax as the supporting band. After the performance of September 26 in Stockholm, the band's bus rolled over on a stretch of icy road the following morning. Burton was thrown through a window and killed instantly. The driver was charged with manslaughter but was not convicted. The band returned to San Francisco and hired Flotsam and Jetsam bassist Jason Newsted to replace Burton. Many of the songs that appeared on the band's next album, "...And Justice for All", were composed during Burton's career with the band.

All of the songs have been performed live and some became permanent setlist features. Four tracks were featured on the nine-song set list for the album's promotional tour: "Battery" as opener, "Master of Puppets", "Welcome Home (Sanitarium)", and "Damage, Inc." The title track, which was issued as a single in France, became a live staple and the most played Metallica song. "Loudwire"s Chad Childers characterized the band's performance as "furious" and the song as the set's highlight. "Rolling Stone" described the live performance as "a classic in all its eight-minute glory". While filming its 3D movie "" (2013) at the Rogers Arena in Vancouver, crosses were rising from the stage during the song, reminiscent of the album's cover art.

"Welcome Home (Sanitarium)" is the second-most performed song from the album. The live performance is often accompanied by lasers, pyrotechnical effects and film screens. "Battery" is usually played at the beginning of the setlist or during the encore, accompanied by lasers and flame plumes. "Disposable Heroes" is featured in the video album "" (2009) filmed in Mexico City, in which the song was played on the second of three nights at the Foro Sol. "Orion" is the least-performed song from the album. Its first live performance was during the Escape from the Studio '06 tour, when the band performed the album in its entirety, honoring the 20th anniversary of its release. The band performed the album in the middle of the set. "Battery", "Welcome Home (Sanitarium)", "Damage, Inc." and the full-length "Master of Puppets" were revived for the band's concerts in 1998 and 1999, after having been retired for a number of years.

All lyrics written by James Hetfield. The bonus tracks on the digital re-release were recorded live at the Seattle Coliseum, Seattle, Washington on August 29 and 30, 1989, and also appeared on the live album "" (1993).

Credits are adapted from the album's liner notes.

Metallica

Production

Artwork


</doc>
