<doc id="46720" url="https://en.wikipedia.org/wiki?curid=46720" title="William Tecumseh Sherman">
William Tecumseh Sherman

William Tecumseh Sherman (February 8, 1820 – February 14, 1891) was an American soldier, businessman, educator, and author. He served as a general in the Union Army during the American Civil War (1861–65), for which he received recognition for his outstanding command of military strategy as well as criticism for the harshness of the scorched earth policies he implemented in conducting total war against the Confederate States.

Sherman was born into a prominent political family. He graduated from the United States Military Academy in 1840 and was stationed in California. He married Ellen Ewing Sherman and together they raised eight children. Sherman's wife and children were all devout Catholics, while Sherman was originally a member of the faith but later left it. In 1859, he gained a position as superintendent of the Louisiana State Seminary of Learning & Military Academy. Living in the South, Sherman grew to respect Southern culture and sympathize with the practice of Southern slavery, although he opposed secession.

Sherman began his Civil War career serving with distinction in the First Battle of Bull Run before being transferred to the Western Theater. He served in Kentucky in 1861, where he acted overly paranoid, exaggerating the presence of spies in the region and providing what seemed to be alarmingly high estimates of the number of troops needed to pacify Kentucky. He was granted leave, and fell into depression. Sherman returned to serve under General Ulysses S. Grant in the winter of 1862 during the battles of forts Henry and Donelson. Before the Battle of Shiloh, Sherman commanded a division. Failing to make proper preparations for a Confederate offensive, his men were surprised and overrun. He later rallied his division and helped drive the Confederates back. Sherman later served in the Siege of Corinth and commanded the XV Corps during the Vicksburg Campaign, which led to the fall of the critical Confederate stronghold of Vicksburg on the Mississippi River. After Grant was promoted to command of all Western armies, Sherman took over the Army of the Tennessee and led it during the Chattanooga Campaign, which culminated with the routing of the Confederate armies in the state of Tennessee.

In 1864, Sherman succeeded Grant as the Union commander in the western theater of the war. He proceeded to lead his troops to the capture of the city of Atlanta, a military success that contributed to the re-election of Abraham Lincoln. Sherman's subsequent march through Georgia and the Carolinas further undermined the Confederacy's ability to continue fighting by destroying large amounts of supplies and demoralizing the Southern people. The tactics that he used during this march, though effective, remain a subject of controversy. He accepted the surrender of all the Confederate armies in the Carolinas, Georgia, and Florida in April 1865, after having been present at most major military engagements in the West. When Grant assumed the U.S. presidency in 1869, Sherman succeeded him as Commanding General of the Army, in which capacity he served from 1869 until 1883. As such, he was responsible for the U.S. Army's engagement in the Indian Wars over the next 15 years. Sherman advocated total war against hostile Indians to force them back onto their reservations. He was skeptical of the Reconstruction era policies of the federal government in the South. Sherman steadfastly refused to be drawn into politics and in 1875 published his "Memoirs", one of the best-known first-hand accounts of the Civil War. British military historian B. H. Liddell Hart declared that Sherman was "the first modern general".

Sherman was born in 1820 in Lancaster, Ohio, near the banks of the Hocking River. His father, Charles Robert Sherman, a successful lawyer who sat on the Ohio Supreme Court, died unexpectedly in 1829. He left his widow, Mary Hoyt Sherman, with eleven children and no inheritance. After his father's death, the nine-year-old Sherman was raised by a Lancaster neighbor and family friend, attorney Thomas Ewing, Sr., a prominent member of the Whig Party who served as senator from Ohio and as the first Secretary of the Interior. Sherman was distantly related to American founding father Roger Sherman and grew to admire him.

Sherman's older brother Charles Taylor Sherman became a federal judge. One of his younger brothers, John Sherman, served as a U.S. senator and Cabinet secretary. Another younger brother, Hoyt Sherman, was a successful banker. Two of his foster brothers served as major generals in the Union Army during the Civil War: Hugh Boyle Ewing, later an ambassador and author, and Thomas Ewing, Jr., who would serve as defense attorney in the military trials of the Lincoln conspirators. Sherman would marry his foster sister, Ellen Boyle Ewing, at age 30 and have eight children with her.

Sherman's unusual given name has always attracted considerable attention. Sherman reported that his middle name came from his father having "caught a fancy for the great chief of the Shawnees, 'Tecumseh". Since an account in a 1932 biography about Sherman, it has often been reported that, as an infant, Sherman was named simply Tecumseh. According to these accounts, Sherman only acquired the name "William" at age nine or ten, after being taken into the Ewing household. His foster mother, Maria Willis Boyle (Maria Ewing), was of Irish ancestry and a devout Roman Catholic. Sherman was raised in a Roman Catholic household, although he later left the church, citing the effect of the Civil War on his religious views. According to a story that may be myth, Sherman was baptized in the Ewing home by a Dominican priest, who named him William for the saint's day: possibly June 25, the feast day of Saint William of Montevergine. The story is contested, however. Sherman wrote in his "Memoirs" that his father named him William Tecumseh; Sherman was baptized by a Presbyterian minister as an infant and given the name William at that time. As an adult, Sherman signed all his correspondence – including to his wife – "W.T. Sherman." His friends and family always called him "Cump."

Senator Ewing secured an appointment for the 16-year-old Sherman as a cadet in the United States Military Academy at West Point, where he roomed and became good friends with another important future Civil War General, George H. Thomas. While there Sherman excelled academically, but he treated the demerit system with indifference. Fellow cadet William Rosecrans would later remember Sherman at West Point as "one of the brightest and most popular fellows" and "a bright-eyed, red-headed fellow, who was always prepared for a lark of any kind." About his time at West Point, Sherman says only the following in his "Memoirs":

Upon graduation in 1840, Sherman entered the army as a second lieutenant in the 3rd U.S. Artillery and saw action in Florida in the Second Seminole War against the Seminole tribe. He was later stationed in Georgia and South Carolina. As the foster son of a prominent Whig politician, in Charleston, the popular Lt. Sherman moved within the upper circles of Old South society.

While many of his colleagues saw action in the Mexican–American War, Sherman performed administrative duties in the captured territory of California. Along with fellow Lieutenants Henry Halleck and Edward Ord, Sherman embarked from New York on the 198-day journey around Cape Horn aboard the converted sloop USS "Lexington". Due to the confined spaces aboard-ship, Sherman grew close to Halleck and Ord, and in his "Memoirs" references a hike with Halleck to the summit of Corcovado overlooking Rio de Janeiro in Brazil, notable as the future spot of the "Cristo Redentor" statue. Sherman and Ord reached the town of Yerba Buena, in California, two days before its name was changed to San Francisco. In 1848, Sherman accompanied the military governor of California, Col. Richard Barnes Mason, in the inspection that officially confirmed that gold had been discovered in the region, thus inaugurating the California Gold Rush. Sherman, along with Ord, assisted in surveys for the sub-divisions of the town that would become Sacramento.

Sherman earned a brevet promotion to captain for his "meritorious service", but his lack of a combat assignment discouraged him and may have contributed to his decision to resign his commission. He would eventually become one of the few high-ranking officers during the Civil War who had not fought in Mexico.

In 1850, Sherman was promoted to the substantive rank of Captain and married his foster sister, Ellen Boyle Ewing, four years younger, in a Washington ceremony attended by President Zachary Taylor and other political luminaries. Thomas Ewing was serving as the Secretary of the Interior at the time.

Like her mother, Ellen Ewing Sherman was a devout Roman Catholic, and the Shermans' eight children were reared in that faith. In 1864, Ellen took up temporary residence in South Bend, Indiana, to have her young family educated at the University of Notre Dame and St. Mary's College. In 1874, with Sherman having become world-famous, their eldest child, Marie Ewing ("Minnie") Sherman, also had a politically prominent wedding, attended by President Ulysses S. Grant and commemorated by a generous gift from the Khedive of Egypt. (Eventually, one of Minnie's daughters married a grandson of Confederate general Lewis Addison Armistead.) Another of the Sherman daughters, Eleanor, was married to Alexander Montgomery Thackara at General Sherman's home in Washington, D.C., on May 5, 1880. To Sherman's great displeasure and sorrow, his oldest surviving son, Thomas Ewing Sherman, joined the religious order of the Jesuits in 1878 and was ordained as a priest in 1889.

In 1853, Sherman resigned his captaincy and became manager of the San Francisco branch of the St. Louis-based bank Lucas, Turner & Co. He returned to San Francisco at a time of great turmoil in the West. He survived two shipwrecks and floated through the Golden Gate on the overturned hull of a foundering lumber schooner. Sherman suffered from stress-related asthma because of the city's aggressive business culture. Late in life, regarding his time in a San Francisco experiencing a frenzy of real estate speculation, Sherman recalled: "I can handle a hundred thousand men in battle, and take the City of the Sun, but am afraid to manage a lot in the swamp of San Francisco." In 1856, during the vigilante period, he served briefly as a major general of the California militia.

Sherman's San Francisco branch closed in May 1857, and he relocated to New York on behalf of the same bank. When the bank failed during the financial Panic of 1857, he closed the New York branch. In early 1858, he returned to California to wrap up the bank's affairs there. Later in 1858, he moved to Leavenworth, Kansas, where he tried his hand at law practice and other ventures without much success.

In 1859, Sherman accepted a job as the first superintendent of the Louisiana State Seminary of Learning & Military Academy in Pineville, Louisiana, a position he sought at the suggestion of Major D. C. Buell and secured because of General George Mason Graham. He proved an effective and popular leader of the institution, which later became Louisiana State University (LSU). Colonel Joseph P. Taylor, the brother of the late President Zachary Taylor, declared that "if you had hunted the whole army, from one end of it to the other, you could not have found a man in it more admirably suited for the position in every respect than Sherman."

Although his brother John was well known as an antislavery congressman, Sherman did not oppose slavery and was sympathetic to Southerners' defense of the institution. He opposed, however, any attempt at dissolving the Union. On hearing of South Carolina's secession from the United States, Sherman observed to a close friend, Professor David F. Boyd of Virginia, an enthusiastic secessionist:

He thus very accurately described the four years of war to come.

In January 1861, as more Southern states were seceding from the Union, Sherman was required to accept receipt of arms surrendered to the State Militia by the U.S. Arsenal at Baton Rouge, Louisiana. Instead of complying, he resigned his position as superintendent and returned to the North, declaring to the governor of Louisiana, "On no earthly account will I do any act or think any thought hostile ... to the ... United States."

Immediately following his departure from Louisiana, Sherman traveled to Washington, D.C., possibly in the hope of securing a position in the army, and met with Abraham Lincoln in the White House during inauguration week. Sherman expressed concern about the North's poor state of preparedness but found Lincoln unresponsive.

Thereafter, Sherman became president of the St. Louis Railroad, a streetcar company, a position he would hold for only a few months. Thus, he was living in border-state Missouri as the secession crisis came to a climax. While trying to hold himself aloof from controversy, he observed firsthand the efforts of Congressman Frank Blair, who later served under Sherman, to hold Missouri in the Union. In early April, he declined an offer from the Lincoln administration to take a position in the War Department as a prelude to his becoming Assistant Secretary of War. After the bombardment of Fort Sumter, Sherman hesitated about committing to military service and ridiculed Lincoln's call for 75,000 three-month volunteers to quell secession, reportedly saying: "Why, you might as well attempt to put out the flames of a burning house with a squirt-gun." However, in May, he offered himself for service in the regular army, and his brother (Senator John Sherman) and other connections maneuvered to get him a commission in the regular army. On June 3, he wrote that "I still think it is to be a long war – very long – much longer than any Politician thinks." He received a telegram summoning him to Washington on June 7.

Sherman was first commissioned as colonel of the 13th U.S. Infantry Regiment, effective May 14, 1861. This was a new regiment yet to be raised, and Sherman's first command was actually of a brigade of three-month volunteers, at the head of which he became one of the few Union officers to distinguish himself at the First Battle of Bull Run on July 21, 1861, where he was grazed by bullets in the knee and shoulder. The disastrous Union defeat at Bull Run led Sherman to question his own judgment as an officer and the capacities of his volunteer troops. President Lincoln, however, was impressed by Sherman while visiting the troops on July 23 and promoted him to brigadier general of volunteers (effective May 17, 1861, with seniority in rank to Ulysses S. Grant, his future commander). He was assigned to serve under Robert Anderson in the Department of the Cumberland in Louisville, Kentucky, and in October Sherman succeeded Anderson in command of the department. Sherman considered that his new assignment broke a promise from Lincoln that he would not be given such a prominent position.

Having succeeded Anderson at Louisville, Sherman now had principal military responsibility for Kentucky, a border state in which Confederate troops held Columbus and Bowling Green and were present near the Cumberland Gap. He became exceedingly pessimistic about the outlook for his command and he complained frequently to Washington, D.C. about shortages while providing exaggerated estimates of the strength of the rebel forces. Critical press reports appeared about him after an October visit to Louisville by the secretary of war, Simon Cameron, and in early November 1861 Sherman insisted that he be relieved. He was promptly replaced by Brigadier General Don Carlos Buell and transferred to St. Louis, Missouri. In December, he was put on leave by Maj. Gen. Henry W. Halleck, commander of the Department of the Missouri, who considered him unfit for duty. Sherman went to Lancaster, Ohio, to recuperate. While he was at home, his wife Ellen wrote to his brother, Senator John Sherman, seeking advice. She complained of "that melancholy insanity to which your family is subject". Sherman later wrote that the concerns of command "broke me down", and he admitted contemplating suicide. His problems were compounded when the "Cincinnati Commercial" described him as "insane".

By mid-December 1861 Sherman had recovered sufficiently to return to service under Halleck in the Department of the Missouri. (In March, Halleck's command was redesignated the Department of the Mississippi and enlarged to unify command in the West). Sherman's initial assignments were rear-echelon commands, first of an instructional barracks near St. Louis and then in command of the District of Cairo. Operating from Paducah, Kentucky, he provided logistical support for the operations of Brig. Gen. Ulysses S. Grant to capture Fort Donelson (February 1862). Grant, the previous commander of the District of Cairo, had recently won a major victory at Fort Henry (February 6, 1862) and been given command of the ill-defined District of West Tennessee. Although Sherman was technically the senior officer at this time, he wrote to Grant, "I feel anxious about you as I know the great facilities [the Confederates] have of concentration by means of the River and R Road, but [I] have faith in you—Command me in any way."

After Grant captured Fort Donelson, Sherman got his wish to serve under Grant when he was assigned on March 1, 1862, to the Army of West Tennessee as commander of the 5th Division. His first major test under Grant was at the Battle of Shiloh. The massive Confederate attack on the morning of April 6, 1862, took most of the senior Union commanders by surprise. Sherman had dismissed the intelligence reports received from militia officers, refusing to believe that Confederate General Albert Sidney Johnston would leave his base at Corinth. He took no precautions beyond strengthening his picket lines, and refused to entrench, build abatis, or push out reconnaissance patrols. At Shiloh, he may have wished to avoid appearing overly alarmed in order to escape the kind of criticism he had received in Kentucky. He had written to his wife that, if he took more precautions, "they'd call me crazy again".

Despite being caught unprepared by the attack, Sherman rallied his division and conducted an orderly, fighting retreat that helped avert a disastrous Union rout. Finding Grant at the end of the day sitting under an oak tree in the darkness and smoking a cigar, Sherman felt, in his words, "some wise and sudden instinct not to mention retreat". In what would become one of the most notable conversations of the war, Sherman said simply: "Well, Grant, we've had the devil's own day, haven't we?" After a puff of his cigar, Grant replied calmly: "Yes. Lick 'em tomorrow, though." Sherman proved instrumental to the successful Union counterattack of April 7, 1862. At Shiloh, Sherman was wounded twice—in the hand and shoulder—and had three horses shot out from under him. His performance was praised by Grant and Halleck and after the battle, and he was promoted to major general of volunteers, effective May 1, 1862.

Beginning in late April, a Union force of 100,000 moved slowly against Corinth, under Halleck's command with Grant relegated to second-in-command; Sherman commanded the division on the extreme right of the Union's right wing (under George H. Thomas). Shortly after the Union forces occupied Corinth on May 30, Sherman persuaded Grant not to leave his command, despite the serious difficulties he was having with Halleck. Sherman offered Grant an example from his own life, "Before the battle of Shiloh, I was cast down by a mere newspaper assertion of 'crazy', but that single battle gave me new life, and I'm now in high feather." He told Grant that, if he remained in the army, "some happy accident might restore you to favor and your true place". In July, Grant's situation improved when Halleck left for the East to become general-in-chief, and Sherman became the military governor of occupied Memphis.

The careers of both officers ascended considerably after that time. In Sherman's case, this was in part because he developed close personal ties to Grant during the two years they served together in the West. During the long and complicated campaign against Vicksburg, one newspaper complained that the "army was being ruined in mud-turtle expeditions, under the leadership of a drunkard [Grant], whose confidential adviser [Sherman] was a lunatic".

Sherman's military record in 1862–63 was mixed. In December 1862, forces under his command suffered a severe repulse at the Battle of Chickasaw Bayou, just north of Vicksburg, Mississippi. Soon after, his XV Corps was ordered to join Maj. Gen. John A. McClernand in his successful assault on Arkansas Post, generally regarded as a politically motivated distraction from the effort to capture Vicksburg. Before the Vicksburg Campaign in the spring of 1863, Sherman expressed serious reservations about the wisdom of Grant's unorthodox strategy, but he went on to perform well in that campaign under Grant's supervision.

The historian John D. Winters in "The Civil War in Louisiana" (1963) describes Sherman:

After the surrender of Vicksburg to the Union forces under Grant on July 4, 1863, Sherman was given the rank of brigadier general in the regular army, in addition to his rank as a major general of volunteers. Sherman's family came from Ohio to visit his camp near Vicksburg; his nine-year-old son, Willie, the Little Sergeant, died from typhoid fever contracted during the trip.

Command in the West was unified under Grant (Military Division of the Mississippi), and Sherman succeeded Grant in command of the Army of the Tennessee. Following the defeat of the Army of the Cumberland at the Battle of Chickamauga by Confederate General Braxton Bragg's Army of Tennessee, the army was besieged in Chattanooga, Tennessee. Sherman's troops were sent to relieve them. While traveling to Chattanooga, Sherman departed Memphis on a train that arrived at the Battle of Collierville, Tennessee, while the Union garrison there was under attack on October 11, 1863. General Sherman took command of the 550 men and successfully defended against an attack of 3,500 Confederate cavalry.

During the Chattanooga Campaign in November, under Grant's overall command, Sherman quickly took his assigned target of Billy Goat Hill at the north end of Missionary Ridge, only to discover that it was not part of the ridge at all, but rather a detached spur separated from the main spine by a rock-strewn ravine. When he attempted to attack the main spine at Tunnel Hill, his troops were repeatedly repulsed by Patrick Cleburne's heavy division, the best unit in Bragg's army. Sherman's efforts were assisted by George Henry Thomas's army's successful assault on the center of the Confederate line, a movement originally intended as a diversion. Subsequently, Sherman led a column to relieve Union forces under Ambrose Burnside thought to be in peril at Knoxville. In February 1864, he led an expedition to Meridian, Mississippi, to disrupt Confederate infrastructure.

Despite this mixed record, Sherman enjoyed Grant's confidence and friendship. When Lincoln called Grant east in the spring of 1864 to take command of all the Union armies, Grant appointed Sherman (by then known to his soldiers as "Uncle Billy") to succeed him as head of the Military Division of the Mississippi, which entailed command of Union troops in the Western Theater of the war. As Grant took overall command of the armies of the United States, Sherman wrote to him outlining his strategy to bring the war to an end concluding that "if you can whip Lee and I can march to the Atlantic I think ol' Uncle Abe will give us twenty days leave to see the young folks."

Sherman proceeded to invade the state of Georgia with three armies: the 60,000-strong Army of the Cumberland under George Henry Thomas, the 25,000-strong Army of the Tennessee under James B. McPherson, and the 13,000-strong Army of the Ohio under John M. Schofield. He fought a lengthy campaign of maneuver through mountainous terrain against Confederate General Joseph E. Johnston's Army of Tennessee, attempting a direct assault only at the disastrous Battle of Kennesaw Mountain. In July, the cautious Johnston was replaced by the more aggressive John Bell Hood, who played to Sherman's strength by challenging him to direct battles on open ground. Meanwhile, in August, Sherman "learned that I had been commissioned a major-general in the regular army, which was unexpected, and not desired until successful in the capture of Atlanta."

Sherman's Atlanta Campaign concluded successfully on September 2, 1864, with the capture of the city, which Hood had been forced to abandon. This success made Sherman a household name and helped ensure Lincoln's presidential re-election in November. In August, the Democratic Party had nominated as its candidate George B. McClellan, the popular former Union army commander, and it had seemed likely that Lincoln would lose to McClellan. Lincoln's defeat could well have meant the victory of the Confederacy, as the Democratic Party platform called for peace negotiations based on the acknowledgment of the Confederacy's independence. Thus the capture of Atlanta, coming when it did, may have been Sherman's greatest contribution to the Union cause.

After ordering almost all civilians to leave the city in September, Sherman gave instructions that all military and government buildings in Atlanta be burned, although many private homes and shops were burned as well. This was to set a precedent for future behavior by his armies.

During September and October, Sherman and Hood played cat-and-mouse in north Georgia (and Alabama) as Hood threatened Sherman's communications to the north. Eventually, Sherman won approval from his superiors for a plan to cut loose from his communications and march south, having advised Grant that he could "make Georgia howl". This created the threat that Hood would move north into Tennessee. Trivializing that threat, Sherman reportedly said that he would "give [Hood] his rations" to go in that direction as "my business is down south". However, Sherman left forces under Maj. Gens. George H. Thomas and John M. Schofield to deal with Hood; their forces eventually smashed Hood's army in the battles of Franklin (November 30) and Nashville (December 15–16). Meanwhile, after the November elections, Sherman began a march with 62,000 men to the port of Savannah, Georgia, living off the land and causing, by his own estimate, more than $100 million in property damage. Sherman called this harsh tactic of material war "hard war," often seen as a species of total war. At the end of this campaign, known as Sherman's March to the Sea, his troops captured Savannah on December 21, 1864. Sherman then dispatched a famous message to Lincoln, offering him the city as a Christmas present.

Sherman's success in Georgia received ample coverage in the Northern press at a time when Grant seemed to be making little progress in his fight against Confederate General Robert E. Lee's Army of Northern Virginia. A bill was introduced in Congress to promote Sherman to Grant's rank of lieutenant general, probably with a view towards having him replace Grant as commander of the Union Army. Sherman wrote both to his brother, Senator John Sherman, and to General Grant vehemently repudiating any such promotion. According to a war-time account, it was around this time that Sherman made his memorable declaration of loyalty to Grant:

While in Savannah, Sherman learned from a newspaper that his infant son Charles Celestine had died during the Savannah Campaign; the general had never seen the child.

Grant then ordered Sherman to embark his army on steamers and join the Union forces confronting Lee in Virginia, but Sherman instead persuaded Grant to allow him to march north through the Carolinas, destroying everything of military value along the way, as he had done in Georgia. He was particularly interested in targeting South Carolina, the first state to secede from the Union, because of the effect that it would have on Southern morale. His army proceeded north through South Carolina against light resistance from the troops of Confederate General Joseph E. Johnston. Upon hearing that Sherman's men were advancing on corduroy roads through the Salkehatchie swamps at a rate of a dozen miles per day, Johnston "made up his mind that there had been no such army in existence since the days of Julius Caesar."

Sherman captured the state capital of Columbia, South Carolina, on February 17, 1865. Fires began that night and by next morning most of the central city was destroyed. The burning of Columbia has engendered controversy ever since, with some claiming the fires were accidental, others a deliberate act of vengeance, and still others that the retreating Confederates burned bales of cotton on their way out of town.

Local Native American Lumbee guides helped Sherman's army cross the Lumber River, which was flooded by torrential rains, into North Carolina. According to Sherman, the trek across the Lumber River, and through the swamps, pocosins, and creeks of Robeson County was "the damnedest marching I ever saw." Thereafter, his troops did little damage to the civilian infrastructure, as North Carolina, unlike its southern neighbor, was regarded by his men as a reluctant Confederate state, having been the second from last state to secede from the Union, before Tennessee. Sherman's final significant military engagement was a victory over Johnston's troops at the Battle of Bentonville, March 19–21. He soon rendezvoused at Goldsborough, North Carolina, with Union troops awaiting him there after the capture of Fort Fisher and Wilmington.

In late March, Sherman briefly left his forces and traveled to City Point, Virginia to consult with Grant. Lincoln happened to be at City Point at the same time, allowing the only three-way meetings of Lincoln, Grant, and Sherman during the war.

Following Lee's surrender to Grant at Appomattox Court House and the assassination of President Lincoln, Sherman met with Johnston in mid-April at Bennett Place in Durham, North Carolina, to negotiate a Confederate surrender. At the insistence of Johnston and of Confederate President Jefferson Davis, Sherman conditionally agreed to generous terms that dealt with both political and military issues. Sherman thought that those terms were consistent with the views Lincoln had expressed at City Point, but the general had not been given the authority, by General Grant, the newly installed President Andrew Johnson, or the Cabinet, to offer those terms.

The government in Washington, D.C., refused to approve Sherman's terms and the Secretary of War, Edwin M. Stanton, denounced Sherman publicly, precipitating a long-lasting feud between the two men. Confusion over this issue lasted until April 26, 1865, when Johnston, ignoring instructions from President Davis, agreed to purely military terms and formally surrendered his army and all the Confederate forces in the Carolinas, Georgia, and Florida, in what was the largest single capitulation of the war. Sherman proceeded with 60,000 of his troops to Washington, D.C., where they marched in the Grand Review of the Armies, on May 24, 1865, and were then disbanded. Having become the second most important general in the Union army, he thus had come full circle to the city where he started his war-time service as colonel of a non-existent infantry regiment.

Sherman was not an abolitionist before the war and, like others of his time and background, he did not believe in "Negro equality". Before the war, Sherman at times even expressed some sympathy with the view of Southern whites that the black race was benefiting from slavery, although he opposed breaking up slave families and advocated teaching slaves to read and write. During the Civil War, Sherman declined to employ black troops in his armies.

Sherman's military campaigns of 1864 and 1865 freed many slaves, who greeted him "as a second Moses or Aaron" and joined his marches through Georgia and the Carolinas by the tens of thousands. The fate of these refugees became a pressing military and political issue. Some abolitionists accused Sherman of doing little to alleviate the precarious living conditions of the freed slaves. To address this issue, on January 12, 1865, Sherman met in Savannah with Secretary of War Stanton and with twenty local black leaders. After Sherman's departure, Garrison Frazier, a Baptist minister, declared in response to an inquiry about the feelings of the black community:

Four days later, Sherman issued his Special Field Orders, No. 15. The orders provided for the settlement of 40,000 freed slaves and black refugees on land expropriated from white landowners in South Carolina, Georgia, and Florida. Sherman appointed Brig. Gen. Rufus Saxton, an abolitionist from Massachusetts who had previously directed the recruitment of black soldiers, to implement that plan. Those orders, which became the basis of the claim that the Union government had promised freed slaves "40 acres and a mule", were revoked later that year by President Andrew Johnson.

Although the context is often overlooked, and the quotation usually chopped off, one of Sherman's most famous statements about his hard-war views arose in part from the racial attitudes summarized above. In his "Memoirs", Sherman noted political pressures in 1864–1865 to encourage the escape of slaves, in part to avoid the possibility that "'able-bodied slaves will be called into the military service of the rebels.'" Sherman thought concentration on such policies would have delayed the "successful end" of the war and the "liberat[ion of] "all" slaves". He went on to summarize vividly his hard-war philosophy and to add, in effect, that he really did not want the help of liberated slaves in subduing the South:

Sherman's record as a tactician was mixed, and his military legacy rests primarily on his command of logistics and on his brilliance as a strategist. The influential 20th-century British military historian and theorist B. H. Liddell Hart ranked Sherman as one of the most important strategists in the annals of war, along with Scipio Africanus, Belisarius, Napoleon Bonaparte, T. E. Lawrence, and Erwin Rommel. Liddell Hart credited Sherman with mastery of maneuver warfare (also known as the "indirect approach"), as demonstrated by his series of turning movements against Johnston during the Atlanta Campaign. Liddell Hart also stated that study of Sherman's campaigns had contributed significantly to his own "theory of strategy and tactics in mechanized warfare", which had in turn influenced Heinz Guderian's doctrine of "Blitzkrieg" and Rommel's use of tanks during the Second World War. Another World War II-era student of Liddell Hart's writings about Sherman was George S. Patton, who "'spent a long vacation studying Sherman's campaigns on the ground in Georgia and the Carolinas, with the aid of [Liddell Hart's] book'" and later "'carried out his [bold] plans, in super-Sherman style'".

Sherman's greatest contribution to the war, the strategy of total warfare—endorsed by General Grant and President Lincoln—has been the subject of controversy. Sherman himself downplayed his role in conducting total war, often saying that he was simply carrying out orders as best he could in order to fulfill his part of Grant's master plan for ending the war.

Like Grant, Sherman was convinced that the Confederacy's strategic, economic, and psychological ability to wage further war needed to be definitively crushed if the fighting were to end. Therefore, he believed that the North had to conduct its campaign as a war of conquest and employ scorched earth tactics to break the backbone of the rebellion. He called this strategy "hard war".

Sherman's advance through Georgia and South Carolina was characterized by widespread destruction of civilian supplies and infrastructure. Although looting was officially forbidden, historians disagree on how well this regulation was enforced. Union soldiers who foraged from Southern homes became known as bummers. The speed and efficiency of the destruction by Sherman's army was remarkable. The practice of heating rails and bending them around trees, leaving behind what came to be known as "Sherman's neckties," made repairs difficult. Accusations that civilians were targeted and war crimes were committed on the march have made Sherman a controversial figure to this day, particularly in the American South.
The damage done by Sherman was almost entirely limited to the destruction of property. Though exact figures are not available, the loss of civilian life appears to have been very small. Consuming supplies, wrecking infrastructure, and undermining morale were Sherman's stated goals, and several of his Southern contemporaries noted this and commented on it. For instance, Alabama-born Major Henry Hitchcock, who served in Sherman's staff, declared that "it is a terrible thing to consume and destroy the sustenance of thousands of people," but if the scorched earth strategy served "to paralyze their husbands and fathers who are fighting ... it is mercy in the end".

The severity of the destructive acts by Union troops was significantly greater in South Carolina than in Georgia or North Carolina. This appears to have been a consequence of the animosity among both Union soldiers and officers to the state that they regarded as the "cockpit of secession". One of the most serious accusations against Sherman was that he allowed his troops to burn the city of Columbia. In 1867, Gen. O. O. Howard, commander of Sherman's 15th Corps, reportedly said, "It is useless to deny that our troops burnt Columbia, for I saw them in the act." However, Sherman himself stated that "[i]f I had made up my mind to burn Columbia I would have burnt it with no more feeling than I would a common prairie dog village; but I did not do it ..." Sherman's official report on the burning placed the blame on Confederate Lt. Gen. Wade Hampton III, who Sherman said had ordered the burning of cotton in the streets. In his memoirs, Sherman said, "In my official report of this conflagration I distinctly charged it to General Wade Hampton, and confess I did so pointedly to shake the faith of his people in him, for he was in my opinion a braggart and professed to be the special champion of South Carolina." Historian James M. McPherson has concluded that:

In this general connection, it is also noteworthy that Sherman and his subordinates (particularly John A. Logan) took steps to protect Raleigh, North Carolina, from acts of revenge after the assassination of President Lincoln.

After the fall of Atlanta in 1864, Sherman ordered the city's evacuation. When the city council appealed to him to rescind that order, on the grounds that it would cause great hardship to women, children, the elderly, and others who bore no responsibility for the conduct of the war, Sherman sent a written response in which he sought to articulate his conviction that a lasting peace would be possible only if the Union were restored, and that he was therefore prepared to do all he could do to quash the rebellion:

Literary critic Edmund Wilson found in Sherman's "Memoirs" a fascinating and disturbing account of an "appetite for warfare" that "grows as it feeds on the South". Former U.S. Defense Secretary Robert McNamara refers equivocally to the statement that "war is cruelty and you cannot refine it" in both the book "Wilson's Ghost" and in his interview for the film "The Fog of War".

But when comparing Sherman's scorched-earth campaigns to the actions of the British Army during the Second Boer War (1899–1902)—another war in which civilians were targeted because of their central role in sustaining an armed resistance—South African historian Hermann Giliomee declares that it "looks as if Sherman struck a better balance than the British commanders between severity and restraint in taking actions proportional to legitimate needs". The admiration of scholars such as Victor Davis Hanson, B. H. Liddell Hart, Lloyd Lewis, and John F. Marszalek for General Sherman owes much to what they see as an approach to the exigencies of modern armed conflict that was both effective and principled.

In May 1865, after the major Confederate armies had surrendered, Sherman wrote in a personal letter:

In June 1865, two months after Robert E. Lee's surrender at Appomattox, General Sherman received his first postwar command, originally called the Military Division of the Mississippi, later the Military Division of the Missouri, which came to comprise the territory between the Mississippi River and the Rocky Mountains. Sherman's efforts in that position were focused on protecting the main wagon roads, such as the Oregon, Bozeman and Santa Fe Trails. Tasked with guarding a vast territory with a limited force, Sherman was wary of the multitude of requests by territories and settlements for protection.

One of Sherman's main concerns in postwar commands was to protect the construction and operation of the railroads from attack by hostile Indians. Sherman's views on Indian matters were often strongly expressed. He regarded the railroads "as the most important element now in progress to facilitate the military interests of our Frontier". Hence, in 1867, he wrote to Grant that "we are not going to let a few thieving, ragged Indians check and stop the progress of [the railroads]." After the 1866 Fetterman Massacre, Sherman wrote Grant that "we must act with vindictive earnestness against the Sioux, even to their extermination, men, women and children."

Despite this language, there was little large-scale military action taken against the Indians during the first three years of Sherman's tenure, as Sherman was willing to let the process of negotiations play out in order to buy time to procure more troops and allow the completion of the Union Pacific and Kansas Pacific Railroads. During his time as departmental commander, Sherman was a member of the Indian Peace Commission. Though the commission was responsible for the negotiation of the Medicine Lodge Treaty and the Sioux Treaty of 1868, Sherman was not particularly privy in either due to being called away to Washington during the negotiations of both. In one such instance, he was called to testify in the impeachment trial of Andrew Johnson. However, Sherman was successful in negotiating other treaties, such as the removal of Navajos from the Bosque Redondo to traditional lands in Western New Mexico. When the Medicine Lodge Treaty was broken in 1868, Sherman authorized his subordinate in Missouri, Philip Sheridan, to conduct the Winter Campaign of 1868–69 (of which the Battle of Washita River was a part), where Sheridan used hard-war tactics similar to those he and Sherman had employed in the Civil War. Sherman was also involved with the trial of Satanta and Big Tree: he ordered that the two chiefs should be tried as common criminals for their role in the Warren Wagon Train Raid, a raid that came dangerously close to killing Sherman himself.

On July 25, 1866, Congress created the rank of General of the Army for Grant and then promoted Sherman to lieutenant general. When Grant became president in 1869, Sherman was appointed Commanding General of the United States Army and promoted to General of the Army. After the death of John A. Rawlins, Sherman also served for one month as interim Secretary of War. His tenure as commanding general was marred by political difficulties, many of which stemmed from disagreements with Secretaries of War Rawlins and William W. Belknap, whom Sherman felt had usurped too much of the Commanding General's powers, reducing him to a sinecure office. Sherman also clashed with Eastern humanitarians, who were critical of the Army's killing of Indians and had apparently found an ally in President Grant. To escape these difficulties, from 1874 to 1876, he moved his headquarters to St. Louis, Missouri, returning to Washington only upon the appointment of Alphonso Taft as Secretary of War and the promise of more authority.

Much of Sherman's time as Commanding General was devoted to making the Western and Plains states safe for settlement through the continuation of the Indian Wars, which included three significant campaigns: the Modoc War, the Great Sioux War of 1876, and the Nez Perce War. The displacement of Indians was facilitated by the growth of the railroad and the eradication of the buffalo. Sherman believed that the intentional eradication of the buffalo should be encouraged as a means of weakening Indian resistance to assimilation. He voiced this view in remarks to a joint session of the Texas legislature in 1875. However he never engaged in any program to actually eradicate the buffalo. During this time, Sherman reorganized frontier forts to reflect the shifting frontier.

After George Armstrong Custer's defeat at the Battle of Little Bighorn, Sherman wrote that "hostile savages like Sitting Bull and his band of outlaw Sioux ... must feel the superior power of the Government." He further wrote that "during an assault, the soldiers can not pause to distinguish between male and female, or even discriminate as to age." Despite his harsh treatment of the warring tribes, Sherman spoke out against the unfair way speculators and government agents treated the natives within the reservations.

In 1875 Sherman published his memoirs in two volumes. According to critic Edmund Wilson, Sherman:

During the election of 1876, Southern Democrats who supported Wade Hampton for governor used mob violence to attack and intimidate African American voters in Charleston, South Carolina. Republican Governor Daniel Chamberlain appealed to President Ulysses S. Grant for military assistance. In October 1876, Grant, after issuing a proclamation, instructed Sherman to gather all available Atlantic region troops and dispatch them to South Carolina to stop the mob violence.

On June 19, 1879, Sherman delivered an address to the graduating class of the Michigan Military Academy, in which he may have uttered the famous phrase "War Is Hell". On April 11, 1880, he addressed a crowd of more than 10,000 at Columbus, Ohio: "There is many a boy here today who looks on war as all glory, but, boys, it is all hell." In 1945, President Harry S. Truman would say: "Sherman was wrong. I'm telling you I find peace is hell."

One of Sherman's significant contributions as head of the Army was the establishment of the Command School (now the Command and General Staff College) at Fort Leavenworth in 1881. Sherman stepped down as commanding general on November 1, 1883, and retired from the army on February 8, 1884.

He lived most of the rest of his life in New York City. He was devoted to the theater and to amateur painting and was much in demand as a colorful speaker at dinners and banquets, in which he indulged a fondness for quoting Shakespeare. During this period, he stayed in contact with war veterans, and through them accepted honorary membership into the Phi Kappa Psi Fraternity and the Irving Literary Society. Sherman was proposed as a Republican candidate for the presidential election of 1884, but declined as emphatically as possible, saying, "I will not accept if nominated and will not serve if elected." Such a categorical rejection of a candidacy is now referred to as a "Shermanesque statement".

In 1888 he joined the newly formed Boone and Crockett Club, a wildlife conservation organization founded by Theodore Roosevelt and George Bird Grinnell.

Sherman died of pneumonia in New York City at 1:50 PM on February 14, 1891, six days after his 71st birthday. President Benjamin Harrison sent a telegram to General Sherman's family and ordered all national flags to be flown at half mast. Harrison, in a message to the Senate and the House of Representatives, wrote that:

Sherman's birth family was Presbyterian and he was originally baptized as such. His foster family, including his future wife Ellen, were devout Catholics, and Sherman was re-baptized and later married in the Catholic rite. According to his son Thomas, who became a Catholic priest, Sherman attended the Catholic Church until the outbreak of the Civil War, but not thereafter. In 1888, Sherman wrote publicly that "my immediate family are strongly Catholic. I am "not" and cannot be." A memoirist reports that Sherman told him in 1887 that "my family is strongly Roman Catholic, but I am not."
On 19 February, a funeral service was held at his home, followed by a military procession. General Joseph E. Johnston, the Confederate officer who had commanded the resistance to Sherman's troops in Georgia and the Carolinas, served as a pallbearer in New York City. It was a bitterly cold day and a friend of Johnston, fearing that the general might become ill, asked him to put on his hat. Johnston famously replied: "If I were in [Sherman's] place, and he were standing in mine, he would not put on his hat." Johnston did catch a serious cold and died one month later of pneumonia.

General Sherman's body was then transported to St. Louis, where another service was conducted on 21 February 1891 at a local Catholic church. His son, Thomas Ewing Sherman, a Jesuit priest, presided over his father's funeral mass. Sherman is buried in Calvary Cemetery in St. Louis.

Major monuments to Sherman include the gilded bronze Sherman Memorial (1902) by Augustus Saint-Gaudens at the main entrance to Central Park in New York City, and the Sherman Monument (1903) by Carl Rohl-Smith near President's Park in Washington, D.C. The Sherman Monument (1900) in Muskegon, Michigan features a bronze statue by John Massey Rhind, and the Sherman Monument (1903) in Arlington National Cemetery features a smaller version of Saint-Gaudens's equestrian statue. Copies of Saint-Gaudens's "Bust of William Tecumseh Sherman" are in the Metropolitan Museum of Art, and elsewhere.

Other posthumous tributes include Sherman Circle in the Petworth neighborhood of Washington, DC, the naming of the World War II M4 Sherman tank, and the "General Sherman" Giant Sequoia tree, the most massive documented single-trunk tree in the world.

In the years immediately after the war, Sherman's conservative politics was attractive to white Southerners. By the 1880s, however, Southern "Lost Cause" writers began to demonize Sherman for his attacks on civilians in the "March". The magazine "Confederate Veteran", based in Nashville, gave Sherman more attention than anyone else, in part to enhance the visibility of the western theater. His devastation of railroads and plantations mattered less than the March's insult to southern dignity, especially its unprotected womanhood. Moody criticizes English historians Field Marshal Viscount Garnet Wolseley, Maj. Gen. John F. C. Fuller, and especially Capt. Basil H. Liddell Hart, who built up Sherman's reputation by exaggerating his "atrocities" and filtering his actions through their ideas about modern warfare.

By contrast Sherman was a popular hero in the North and well regarded by his soldiers. Military historians have paid special attention to his Atlanta campaign and the March to the Sea, generally giving him high marks as an innovative strategist and quick-witted tactician.

Around 1868, Sherman began to write a "private" recollection for his children about his life before the Civil War, identified now as his unpublished "Autobiography, 1828–1861". This manuscript is held by the Ohio Historical Society. Much of the material in it would eventually be incorporated in revised form in his memoirs.

In 1875, ten years after the end of the Civil War, Sherman became one of the first Civil War generals to publish a memoir. His "Memoirs of General William T. Sherman. By Himself", published by D. Appleton & Co., in two volumes, began with the year 1846 (when the Mexican War began) and ended with a chapter about the "military lessons of the [civil] war" (1875 edition: Volume I;
Volume II ).
The memoirs were controversial, and sparked complaints from many quarters. Grant (serving as President when Sherman's memoirs first appeared) later remarked that others had told him that Sherman treated Grant unfairly but "when I finished the book, I found I approved every word; that ... it was a true book, an honorable book, creditable to Sherman, just to his companions—to myself particularly so—just such a book as I expected Sherman would write."

In 1886, after the publication of Grant's memoirs, Sherman produced a "second edition, revised and corrected" of his memoirs with Appleton. The new edition added a second preface, a chapter about his life up to 1846, a chapter concerning the post-war period (ending with his 1884 retirement from the army), several appendices, portraits, improved maps, and an index (1886 edition:
Volume I,
Volume II). For the most part, Sherman refused to revise his original text on the ground that "I disclaim the character of historian, but assume to be a witness on the stand before the great tribunal of history" and "any witness who may disagree with me should publish his own version of [the] facts in the truthful narration of which he is interested." However, Sherman did add the appendices, in which he published the views of some others.

Subsequently, Sherman shifted to the publishing house of Charles L. Webster & Co., the publisher of Grant's memoirs. The new publishing house brought out a "third edition, revised and corrected" in 1890. This difficult-to-find edition was substantively identical to the second (except for the probable omission of Sherman's short 1875 and 1886 prefaces).

After Sherman died in 1891, there were dueling new editions of his memoirs. His first publisher, Appleton, reissued the original (1875) edition with two new chapters about Sherman's later years added by the journalist W. Fletcher Johnson (1891 Johnson edition:
Volume I, Volume II). Meanwhile, Charles L. Webster & Co. issued a "fourth edition, revised, corrected, and complete" with the text of Sherman's second edition, a new chapter prepared under the auspices of the Sherman family bringing the general's life from his retirement to his death and funeral, and an appreciation by politician James G. Blaine (who was related to Sherman's wife). Unfortunately, this edition omits Sherman's prefaces to the 1875 and 1886 editions (1891 Blaine edition: Volume I,
Volume II).

In 1904 and 1913, Sherman's youngest son (Philemon Tecumseh Sherman) republished the memoirs, with Appleton (not Charles L. Webster & Co.). This was designated as a "second edition, revised and corrected". This edition contains Sherman's two prefaces, his 1886 text, and the materials added in the 1891 Blaine edition. Thus, this virtually invisible edition of Sherman's memoirs is actually the most comprehensive version.

There are many modern editions of Sherman's memoirs. The edition most useful for research purposes is the 1990 Library of America version, edited by Charles Royster. It contains the entire text of Sherman's 1886 edition, together with annotations, a note on the text, and a detailed chronology of Sherman's life. Missing from this edition is the useful biographical material contained in the 1891 Johnson and Blaine editions.

Many of Sherman's official war-time letters (and other items) appear in the "Official Records of the War of the Rebellion". Some of these letters are rather personal in nature, rather than relating directly to operational activities of the army. There also are at least five published collections of Sherman correspondence:


The presentation of Sherman in popular culture is now discussed at book-length in "Sherman's March in Myth and Memory" (Rowman and Littlefield, 2008), by Edward Caudill and Paul Ashdown. Some of the artistic treatments of Sherman's march are the Civil War era song "Marching Through Georgia" by Henry Clay Work; Herman Melville's poem "The March to the Sea"; Ross McElwee's film "Sherman's March"; and E. L. Doctorow's novel "The March".

Sherman is one of the few generals to have appeared on several different US postage stamp issues. The first stamp issue to honor him was released on March 21, 1893, a little more than two years after his death. The engraving was modeled after a taken by Napoleon Sarony in 1888. The Post Office released a second and third Sherman issue of 1895, both almost identical to the first issue, with slight changes in the framework design and color. Sherman appeared again in the , a commemorative postage stamp jointly honoring Generals Sherman, Grant and Sheridan. The last stamp issue to honor Sherman was released in 1995 and was a 32-cent stamp. With five different issues to his name, Sherman has featured more prominently in US postage than most US presidents.







</doc>
<doc id="46721" url="https://en.wikipedia.org/wiki?curid=46721" title="Edward VII">
Edward VII

Edward VII (Albert Edward; 9 November 1841 – 6 May 1910) was King of the United Kingdom of Great Britain and Ireland and Emperor of India from 22 January 1901 until his death in 1910.

The eldest son of Queen Victoria and Prince Albert of Saxe-Coburg and Gotha, Edward was related to royalty throughout Europe. He was heir apparent to the British throne and held the title of Prince of Wales for longer than any of his predecessors. He was heir presumptive to the Duchy of Saxe-Coburg and Gotha until before his marriage he renounced his right to the duchy, which then devolved to his younger brother Alfred. During the long reign of his mother, he was largely excluded from political power, and came to personify the fashionable, leisured elite. He travelled throughout Britain performing ceremonial public duties, and represented Britain on visits abroad. His tours of North America in 1860 and the Indian subcontinent in 1875 were popular successes, but despite public approval his reputation as a playboy prince soured his relationship with his mother.

As king, Edward played a role in the modernisation of the British Home Fleet and the reorganisation of the British Army after the Second Boer War. He reinstituted traditional ceremonies as public displays and broadened the range of people with whom royalty socialised. He fostered good relations between Britain and other European countries, especially France, for which he was popularly called "Peacemaker", but his relationship with his nephew, the German Emperor Wilhelm II, was poor. The Edwardian era, which covered Edward's reign and was named after him, coincided with the start of a new century and heralded significant changes in technology and society, including steam turbine propulsion and the rise of socialism. He died in 1910 in the midst of a constitutional crisis that was resolved the following year by the Parliament Act 1911, which restricted the power of the unelected House of Lords.

Edward was born at 10:48 in the morning on 9 November 1841 in Buckingham Palace. He was the eldest son and second child of Queen Victoria and her husband Prince Albert of Saxe-Coburg and Gotha. He was christened "Albert Edward" at St George's Chapel, Windsor Castle, on 25 January 1842. He was named Albert after his father and Edward after his maternal grandfather Prince Edward, Duke of Kent and Strathearn. He was known as "Bertie" to the royal family throughout his life.

As the eldest son of the British sovereign, he was automatically Duke of Cornwall and Duke of Rothesay at birth. As a son of Prince Albert, he also held the titles of Prince of Saxe-Coburg and Gotha and Duke of Saxony. He was created Prince of Wales and Earl of Chester on 8 December 1841, Earl of Dublin on 10 September 1849 or 17 January 1850, a Knight of the Garter on 9 November 1858, and a Knight of the Thistle on 24 May 1867. In 1863, he renounced his succession rights to the Duchy of Saxe-Coburg and Gotha in favour of his younger brother, Prince Alfred.

Queen Victoria and Prince Albert were determined that their eldest son should have an education that would prepare him to be a model constitutional monarch. At age seven, Edward embarked on a rigorous educational programme devised by Prince Albert, and supervised by several tutors. Unlike his elder sister Victoria, Edward did not excel in his studies. He tried to meet the expectations of his parents, but to no avail. Although Edward was not a diligent student—his true talents were those of charm, sociability and tact—Benjamin Disraeli described him as informed, intelligent and of sweet manner. After the completion of his secondary-level studies, his tutor was replaced by a personal governor, Robert Bruce.

After an educational trip to Rome, undertaken in the first few months of 1859, he spent the summer of that year studying at the University of Edinburgh under, among others, the chemist Lyon Playfair. In October, he matriculated as an undergraduate at Christ Church, Oxford. Now released from the educational strictures imposed by his parents, he enjoyed studying for the first time and performed satisfactorily in examinations. In 1861, he transferred to Trinity College, Cambridge, where he was tutored in history by Charles Kingsley, Regius Professor of Modern History. Kingsley's efforts brought forth the best academic performances of Edward's life, and Edward actually looked forward to his lectures.

In 1860, Edward undertook the first tour of North America by a Prince of Wales. His genial good humour and confident "bonhomie" made the tour a great success. He inaugurated the Victoria Bridge, Montreal, across the St Lawrence River, and laid the cornerstone of Parliament Hill, Ottawa. He watched Charles Blondin traverse Niagara Falls by highwire, and stayed for three days with President James Buchanan at the White House. Buchanan accompanied the Prince to Mount Vernon, to pay his respects at the tomb of George Washington. Vast crowds greeted him everywhere. He met Henry Wadsworth Longfellow, Ralph Waldo Emerson and Oliver Wendell Holmes. Prayers for the royal family were said in Trinity Church, New York, for the first time since 1776. The four-month tour throughout Canada and the United States considerably boosted Edward's confidence and self-esteem, and had many diplomatic benefits for Great Britain.

Edward had hoped to pursue a career in the British Army, but his mother vetoed an active military career. He had been gazetted colonel on 9 November 1858—to his disappointment, as he had wanted to earn his commission by examination. In September 1861, Edward was sent to Germany, supposedly to watch military manoeuvres, but actually in order to engineer a meeting between him and Princess Alexandra of Denmark, the eldest daughter of Prince Christian of Denmark and his wife Louise. Queen Victoria and Prince Albert had already decided that Edward and Alexandra should marry. They met at Speyer on 24 September under the auspices of his elder sister, Victoria, who had married the Crown Prince of Prussia in 1858. Edward's elder sister, acting upon instructions from their mother, had met Princess Alexandra at Strelitz in June; the young Danish princess made a very favourable impression. Edward and Alexandra were friendly from the start; the meeting went well for both sides, and marriage plans advanced.

From this time, Edward gained a reputation as a playboy. Determined to get some army experience, Edward attended manoeuvres in Ireland, during which he spent three nights with an actress, Nellie Clifden, who was hidden in the camp by his fellow officers. Prince Albert, though ill, was appalled and visited Edward at Cambridge to issue a reprimand. Albert died in December 1861 just two weeks after the visit. Queen Victoria was inconsolable, wore mourning clothes for the rest of her life and blamed Edward for his father's death. At first, she regarded her son with distaste as frivolous, indiscreet and irresponsible. She wrote to her eldest daughter, "I never can, or shall, look at him without a shudder."

Once widowed, Queen Victoria effectively withdrew from public life. Shortly after Prince Albert's death, the queen arranged for Edward to embark on an extensive tour of the Middle East, visiting Egypt, Jerusalem, Damascus, Beirut and Constantinople. The British Government wanted Edward to secure the friendship of Egypt's ruler, Said Pasha, to prevent French control of the Suez Canal if the Ottoman Empire collapsed. It was the first royal tour on which an official photographer, Francis Bedford, was in attendance. As soon as Edward returned to Britain, preparations were made for his engagement, which was sealed at Laeken in Belgium on 9 September 1862. Edward married Princess Alexandra of Denmark at St George's Chapel, Windsor Castle, on 10 March 1863. He was 21; she was 18.

The couple established Marlborough House as their London residence and Sandringham House in Norfolk as their country retreat. They entertained on a lavish scale. Their marriage met with disapproval in certain circles because most of Queen Victoria's relations were German, and Denmark was at loggerheads with Germany over the territories of Schleswig and Holstein. When Alexandra's father inherited the throne of Denmark in November 1863, the German Confederation took the opportunity to invade and annex Schleswig-Holstein. Queen Victoria was of two minds whether it was a suitable match given the political climate. After the marriage, she expressed anxiety about their socialite lifestyle and attempted to dictate to them on various matters, including the names of their children.

Edward had mistresses throughout his married life. He socialised with actress Lillie Langtry; Lady Randolph Churchill; Daisy Greville, Countess of Warwick; actress Sarah Bernhardt; noblewoman Lady Susan Vane-Tempest; singer Hortense Schneider; prostitute Giulia Beneni (known as "La Barucci"); wealthy humanitarian Agnes Keyser; and Alice Keppel. At least fifty-five liaisons are conjectured. How far these relationships went is not always clear. Edward always strove to be discreet, but this did not prevent society gossip or press speculation. Keppel's great-granddaughter, Camilla Parker Bowles, became the mistress and subsequent wife of Charles, Prince of Wales, Edward's great-great-grandson. It was rumoured that Camilla's grandmother, Sonia Keppel, was fathered by Edward, but she was "almost certainly" the daughter of George Keppel, whom she resembled. Edward never acknowledged any illegitimate children. Alexandra was aware of his affairs, and seems to have accepted them.

In 1869, Sir Charles Mordaunt, a British Member of Parliament, threatened to name Edward as co-respondent in his divorce suit. Ultimately, he did not do so but Edward was called as a witness in the case in early 1870. It was shown that Edward had visited the Mordaunts' house while Sir Charles was away sitting in the House of Commons. Although nothing further was proven and Edward denied he had committed adultery, the suggestion of impropriety was damaging.

During Queen Victoria's widowhood, Edward pioneered the idea of royal public appearances as we understand them today—for example, opening the Thames Embankment in 1871, the Mersey Tunnel in 1886, and Tower Bridge in 1894—but his mother did not allow Edward an active role in the running of the country until 1898. He was sent summaries of important government documents, but she refused to give him access to the originals. He annoyed his mother by siding with Denmark on the Schleswig-Holstein Question in 1864 (she was pro-German) and in the same year annoyed her again by making a special effort to meet Giuseppe Garibaldi. Liberal Prime Minister William Ewart Gladstone sent him papers secretly. From 1886, Foreign Secretary Lord Rosebery sent him Foreign Office despatches, and from 1892 some Cabinet papers were opened to him.

In 1870 republican sentiment in Britain was given a boost when the French Emperor, Napoleon III, was defeated in the Franco-Prussian War and the French Third Republic was declared. However, in the winter of 1871, a brush with death led to an improvement in both Edward's popularity with the public and his relationship with his mother. While staying at Londesborough Lodge, near Scarborough, North Yorkshire, Edward contracted typhoid fever, the disease that was believed to have killed his father. There was great national concern, and one of his fellow guests (Lord Chesterfield) died. Edward's recovery was greeted with almost universal relief. Public celebrations included the composition of Arthur Sullivan's Festival Te Deum. Edward cultivated politicians from all parties, including republicans, as his friends, and thereby largely dissipated any residual feelings against him.
On 26 September 1875, Edward set off for India on an extensive eight-month tour; on the way, he visited Malta, Brindisi and Greece. His advisors remarked on his habit of treating all people the same, regardless of their social station or colour. In letters home, he complained of the treatment of the native Indians by the British officials: "Because a man has a black face and a different religion from our own, there is no reason why he should be treated as a brute." Consequently, Lord Salisbury, the Secretary of State for India, issued new guidance and at least one resident was removed from office. He returned to England on 11 May 1876, after stopping off at Portugal. At the end of the tour, Queen Victoria was given the title Empress of India by Parliament, in part as a result of the tour's success.

Edward was regarded worldwide as an arbiter of men's fashions. He made wearing tweed, Homburg hats and Norfolk jackets fashionable, and popularised the wearing of black ties with dinner jackets, instead of white tie and tails. He pioneered the pressing of trouser legs from side to side in preference to the now normal front and back creases, and was thought to have introduced the stand-up turn-down shirt collar, created for him by Charvet. A stickler for proper dress, he is said to have admonished Lord Salisbury for wearing the trousers of an Elder Brother of Trinity House with a Privy Councillor's coat. Deep in an international crisis, Salisbury informed the Prince that it had been a dark morning, and that "my mind must have been occupied by some subject of less importance." The tradition of men not buttoning the bottom button of waistcoats is said to be linked to Edward, who supposedly left his undone because of his large girth. His waist measured 48 inches (122 cm) shortly before his coronation. He introduced the practice of eating roast beef and potatoes with horseradish sauce and yorkshire pudding on Sundays, a meal that remains a staple British favourite for Sunday lunch. He was not a heavy drinker, though he did drink champagne and, occasionally, port.

Edward was a patron of the arts and sciences and helped found the Royal College of Music. He opened the college in 1883 with the words, "Class can no longer stand apart from class ... I claim for music that it produces that union of feeling which I much desire to promote." At the same time, he enjoyed gambling and country sports and was an enthusiastic hunter. He ordered all the clocks at Sandringham to run half an hour ahead to provide more daylight time for shooting. This so-called tradition of Sandringham Time continued until 1936, when it was abolished by Edward VIII. He also laid out a golf course at Windsor. By the 1870s the future king had taken a keen interest in horseracing and steeplechasing. In 1896, his horse Persimmon won both the Derby Stakes and the St Leger Stakes. In 1900, Persimmon's brother, Diamond Jubilee, won five races (Derby, St Leger, 2,000 Guineas Stakes, Newmarket Stakes and Eclipse Stakes) and another of Edward's horses, Ambush II, won the Grand National.
In 1891 Edward was embroiled in the royal baccarat scandal, when it was revealed he had played an illegal card game for money the previous year. The Prince was forced to appear as a witness in court for a second time when one of the participants unsuccessfully sued his fellow players for slander after being accused of cheating. In the same year Edward was involved in a personal conflict, when Lord Charles Beresford threatened to reveal details of Edward's private life to the press, as a protest against Edward interfering with Beresford's affair with Daisy Greville, Countess of Warwick. The friendship between the two men was irreversibly damaged, and their bitterness would last for the remainder of their lives. Usually, Edward's outbursts of temper were short-lived, and "after he had let himself go ... [he would] smooth matters by being especially nice".

In late 1891, Edward's eldest son, Albert Victor, was engaged to Princess Victoria Mary of Teck. Just a few weeks later, in early 1892, Albert Victor died of pneumonia. Edward was grief-stricken. "To lose our eldest son", he wrote, "is one of those calamities one can never really get over". Edward told Queen Victoria, "[I would] have given my life for him, as I put no value on mine". Albert Victor was the second of Edward's children to die. In 1871, his youngest son, Alexander John, had died just 24 hours after being born. Edward had insisted on placing Alexander John in a coffin personally with "the tears rolling down his cheeks".

On his way to Denmark through Belgium on 4 April 1900, Edward was the victim of an attempted assassination when fifteen-year-old Jean-Baptiste Sipido shot at him in protest over the Second Boer War. Sipido, though obviously guilty, was acquitted by a Belgian court because he was underage. The perceived laxity of the Belgian authorities, combined with British disgust at Belgian atrocities in the Congo, worsened the already poor relations between the United Kingdom and the Continent. However, in the next ten years, Edward's affability and popularity, as well as his use of family connections, assisted Britain in building European alliances.

When Queen Victoria died on 22 January 1901, Edward became King of the United Kingdom, Emperor of India and, in an innovation, King of the British Dominions. He chose to reign under the name Edward VII, instead of Albert Edward—the name his mother had intended for him to use—declaring that he did not wish to "undervalue the name of Albert" and diminish the status of his father with whom the "name should stand alone". The numeral VII was occasionally omitted in Scotland, even by the national church, in deference to protests that the previous Edwards were English kings who had "been excluded from Scotland by battle". J. B. Priestley recalled, "I was only a child when he succeeded Victoria in 1901, but I can testify to his extraordinary popularity. He was in fact the most popular king England had known since the earlier 1660s."

He donated his parents' house, Osborne on the Isle of Wight, to the state and continued to live at Sandringham. He could afford to be magnanimous; his private secretary, Sir Francis Knollys, claimed that he was the first heir to succeed to the throne in credit. Edward's finances had been ably managed by Sir Dighton Probyn, Comptroller of the Household, and had benefited from advice from Edward's financier friends, some of whom were Jewish, such as Ernest Cassel, Maurice de Hirsch and the Rothschild family. At a time of widespread anti-Semitism, Edward attracted criticism for openly socialising with Jews.

Edward's coronation had originally been scheduled for 26 June 1902. However, two days before, on 24 June, he was diagnosed with appendicitis. Appendicitis was generally not treated operatively and carried a high mortality rate, but developments in anaesthesia and antisepsis in the preceding 50 years made life-saving surgery possible. Sir Frederick Treves, with the support of Lord Lister, performed a then-radical operation of draining a pint of pus from the infected abscess through a small incision (through -inch thickness of belly fat and abdomen wall); this outcome showed thankfully that the cause was not cancer. The next day, Edward was sitting up in bed, smoking a cigar. Two weeks later, it was announced that the King was out of danger. Treves was honoured with a baronetcy (which the King had arranged before the operation) and appendix surgery entered the medical mainstream. Edward was crowned at Westminster Abbey on 9 August 1902 by the 80-year-old Archbishop of Canterbury, Frederick Temple, who died only four months later.

Edward refurbished the royal palaces, reintroduced the traditional ceremonies, such as the State Opening of Parliament, that his mother had forgone, and founded new honours, such as the Order of Merit, to recognise contributions to the arts and sciences. In 1902, the Shah of Persia, Mozzafar-al-Din, visited England expecting to receive the Order of the Garter. Edward refused to bestow the honour on the Shah because the order was meant to be in his personal gift and the Foreign Secretary, Lord Lansdowne, had promised it without his consent. Edward also objected to inducting a Muslim into a Christian order of chivalry. His refusal threatened to damage British attempts to gain influence in Persia, but Edward resented his ministers' attempts to reduce the King's traditional powers. Eventually, he relented and Britain sent a special embassy to the Shah with a full Order of the Garter the following year.

As king, Edward's main interests lay in the fields of foreign affairs and naval and military matters. Fluent in French and German, he reinvented royal diplomacy by numerous state visits across Europe. He took annual holidays in Biarritz and Marienbad. One of his most important foreign trips was an official visit to France in May 1903 as the guest of President Émile Loubet. Following a visit to Pope Leo XIII in Rome, this trip helped create the atmosphere for the Anglo-French Entente Cordiale, an agreement delineating British and French colonies in North Africa, and ruling out any future war between the two countries. The Entente was negotiated in 1904 between the French foreign minister, Théophile Delcassé, and the British foreign secretary, Lord Lansdowne. It marked the end of centuries of Anglo-French rivalry and Britain's splendid isolation from Continental affairs, and attempted to counterbalance the growing dominance of the German Empire and its ally, Austria-Hungary.

Edward was related to nearly every other European monarch, and came to be known as the "uncle of Europe". German Emperor Wilhelm II and Emperor Nicholas II of Russia were his nephews; Queen Victoria Eugenia of Spain, Crown Princess Margaret of Sweden, Crown Princess Marie of Romania, Crown Princess Sophia of Greece, and Empress Alexandra of Russia were his nieces; King Haakon VII of Norway was both his nephew and his son-in-law; kings Frederick VIII of Denmark and George I of Greece were his brothers-in-law; kings Albert I of Belgium, Ferdinand of Bulgaria, and Charles I and Manuel II of Portugal were his second cousins. Edward doted on his grandchildren, and indulged them, to the consternation of their governesses. However, there was one relation whom Edward did not like: Wilhelm II. Edward's difficult relationship with his nephew exacerbated the tensions between Germany and Britain.

In April 1908, during Edward's annual stay at Biarritz, he accepted the resignation of British Prime Minister Sir Henry Campbell-Bannerman. In a break with precedent, Edward asked Campbell-Bannerman's successor, H. H. Asquith, to travel to Biarritz to kiss hands. Asquith complied, but the press criticised the action of the King in appointing a prime minister on foreign soil instead of returning to Britain. In June 1908, Edward became the first reigning British monarch to visit the Russian Empire, despite refusing to visit in 1906, when Anglo-Russian relations were strained in the aftermath of the Russo-Japanese War, the Dogger Bank incident, and the Tsar's dissolution of the Duma. The previous month, Edward visited the Scandinavian countries, becoming the first British monarch to visit Sweden.

While Prince of Wales, Edward had to be dissuaded from breaking with constitutional precedent by openly voting for W. E. Gladstone's Representation of the People Bill (1884) in the House of Lords. On other matters he was less progressive: he did not, for example, favour giving votes to women, although he did suggest that the social reformer Octavia Hill serve on the Commission for Working Class Housing. He was also opposed to Irish Home Rule, instead preferring a form of dual monarchy.

As Prince of Wales, he had come to enjoy warm and mutually respectful relations with Gladstone, whom his mother detested. But the statesman's son, Home Secretary Herbert Gladstone, angered the King by planning to permit Roman Catholic priests in vestments to carry the Host through the streets of London, and by appointing two ladies, Lady Frances Balfour and Mrs H. J. Tennant, to serve on a Royal Commission on reforming divorce law—Edward thought divorce could not be discussed with "delicacy or even decency" before ladies. Edward's biographer Philip Magnus suggests that Gladstone may have become a whipping-boy for the King's general irritation with the Liberal government. Gladstone was sacked in the reshuffle the following year and the King agreed, with some reluctance, to appoint him Governor-General of South Africa.

Edward involved himself heavily in discussions over army reform, the need for which had become apparent with the failings of the Boer War. He supported the redesign of army command, the creation of the Territorial Force, and the decision to provide an Expeditionary Force supporting France in the event of war with Germany. Reform of the Royal Navy was also suggested, partly due to the ever-increasing Naval Estimates, and because of the emergence of the Imperial German Navy as a new strategic threat. Ultimately a dispute arose between Admiral Lord Charles Beresford, who favoured increased spending and a broad deployment, and the First Sea Lord Admiral Sir John Fisher, who favoured efficiency savings, scrapping obsolete vessels, and a strategic realignment of the Royal Navy relying on torpedo craft for home defence backed by the new dreadnoughts.

The King lent support to Fisher, in part because he disliked Beresford, and eventually Beresford was dismissed. Beresford continued his campaign outside of the navy and Fisher ultimately announced his resignation in late 1909, although the bulk of his policies were retained. The King was intimately involved in the appointment of Fisher's successor as the Fisher-Beresford feud had split the service, and the only truly qualified figure known to be outside of both camps was Sir Arthur Wilson, who had retired in 1907. Wilson was reluctant to return to active duty, but Edward persuaded him to do so, and Wilson became First Sea Lord on 25 January 1910.

Edward was rarely interested in politics, although his views on some issues were notably liberal for the time. During his reign he said use of the word "nigger" was "disgraceful", despite it then being in common parlance. In 1904, during an Anglo-German summit in Kiel between Wilhelm II and Edward, Wilhelm with the Russo-Japanese War in mind started to go on about the "Yellow Peril", which he called "the greatest peril menacing ... Christendom and European civilisation. If the Russians went on giving ground, the yellow race would, in twenty years time, be in Moscow and Posen". Wilhelm went on to attack his British guests for supporting Japan against Russia, suggesting that the British were committing "race treason". In response, Edward stated that he "could not see it. The Japanese were an intelligent, brave and chivalrous nation, quite as civilised as the Europeans, from whom they only differed by the pigmentation of their skin".

Edward lived a life of luxury that was often far removed from that of the majority of his subjects. However, his personal charm with people at all levels of society and his strong condemnation of prejudice went some way to assuage republican and racial tensions building during his lifetime.

In the last year of his life, Edward became embroiled in a constitutional crisis when the Conservative majority in the House of Lords refused to pass the "People's Budget" proposed by the Liberal government of Prime Minister H. H. Asquith. The crisis eventually led—after Edward's death—to the removal of the Lords' right to veto legislation.

The King was displeased at Liberal attacks on the peers, which included a polemical speech by David Lloyd George at Limehouse. Cabinet minister Winston Churchill publicly demanded a general election, for which Asquith apologised to the King's adviser Lord Knollys and rebuked Churchill at a Cabinet meeting. Edward was so dispirited at the tone of class warfare—although Asquith told him that party rancour had been just as bad over the First Home Rule Bill in 1886—that he introduced his son to Secretary of State for War Richard Haldane as "the last King of England". After the King's horse Minoru won the Derby on 26 July 1909, he returned to the racetrack the following day, and laughed when a man shouted: "Now, King. You've won the Derby. Go back home and dissolve this bloody Parliament!"

In vain, the King urged Conservative leaders Arthur Balfour and Lord Lansdowne to pass the Budget, which Lord Esher had advised him was not unusual, as Queen Victoria had helped to broker agreements between the two Houses over Irish disestablishment in 1869 and the Third Reform Act in 1884. On Asquith's advice, however, he did not offer them an election (at which, to judge from recent by-elections, they were likely to gain seats) as a reward for doing so.

The Finance Bill passed the Commons on 5 November 1909, but was rejected by the Lords on 30 November; they instead passed a resolution of Lord Lansdowne's stating that they were entitled to oppose the bill as it lacked an electoral mandate. The King was annoyed that his efforts to urge passage of the budget had become public knowledge and had forbidden his adviser Lord Knollys, who was an active Liberal peer, from voting for the budget, although Knollys had suggested that this would be a suitable gesture to indicate royal desire to see the Budget pass. In December 1909, a proposal to create peers (to give the Liberals a majority in the Lords) or give the prime minister the right to do so was considered "outrageous" by Knollys, who thought the King should abdicate rather than agree to it.

The January 1910 election was dominated by talk of removing the Lords' veto. During the election campaign Lloyd George talked of "guarantees" and Asquith of "safeguards" that would be necessary before forming another Liberal government, but the King informed Asquith that he would not be willing to contemplate creating peers until after a second general election. Balfour refused to be drawn on whether or not he would be willing to form a Conservative government, but advised the King not to promise to create peers until he had seen the terms of any proposed constitutional change. During the campaign the leading Conservative Walter Long had asked Knollys for permission to state that the King did not favour Irish Home Rule, but Knollys refused on the grounds that it was not appropriate for the monarch's views to be known in public.

The election resulted in a hung parliament, with the Liberal government dependent on the support of the third largest party, the Irish nationalists. The King suggested a compromise whereby only 50 peers from each side would be allowed to vote, which would also redress the large Conservative majority in the Lords, but Lord Crewe, Liberal leader in the Lords, advised that this would reduce the Lords' independence as only peers who were loyal party supporters would be picked. Pressure to remove the Lords' veto now came from the Irish nationalist MPs, who wanted to remove the Lords' ability to block the introduction of Irish Home Rule. They threatened to vote against the Budget unless they had their way (an attempt by Lloyd George to win their support by amending whiskey duties was abandoned as the Cabinet felt this would recast the Budget too much). Asquith now revealed that there were no "guarantees" for the creation of peers. The Cabinet considered resigning and leaving it up to Balfour to try to form a Conservative government.

The King's Speech from the Throne on 21 February made reference to introducing measures restricting the Lords' power of veto to one of delay, but Asquith inserted a phrase "in the opinion of my advisers" so the King could be seen to be distancing himself from the planned legislation.

The Commons passed resolutions on 14 April that would form the basis for the 1911 Parliament Act: to remove the power of the Lords to veto money bills, to replace their veto of other bills with a power to delay, and to reduce the term of Parliament from seven years to five (the King would have preferred four). But in that debate Asquith hinted—to ensure the support of the nationalist MPs—that he would ask the King to break the deadlock "in that Parliament" (i.e. contrary to Edward's earlier stipulation that there be a second election). The Budget was passed by both Commons and Lords in April.

By April the Palace was having secret talks with Balfour and the Archbishop of Canterbury, who both advised that the Liberals did not have sufficient mandate to demand the creation of peers. The King thought the whole proposal "simply disgusting" and that the government was "in the hands of Redmond & Co". Lord Crewe announced publicly that the government's wish to create peers should be treated as formal "ministerial advice" (which, by convention, the monarch must obey) although Lord Esher argued that the monarch was entitled "in extremis" to dismiss the government rather than take their "advice". Esher's view has been called "obsolete and unhelpful".

Edward habitually smoked twenty cigarettes and twelve cigars a day. In 1907, a rodent ulcer, a type of cancer affecting the skin next to his nose, was cured with radium. Towards the end of his life he increasingly suffered from bronchitis. He suffered a momentary loss of consciousness during a state visit to Berlin in February 1909. In March 1910, he was staying at Biarritz when he collapsed. He remained there to convalesce, while in London Asquith tried to get the Finance Bill passed. The King's continued ill health was unreported and he attracted criticism for staying in France while political tensions were so high. On 27 April he returned to Buckingham Palace, still suffering from severe bronchitis. Alexandra returned from visiting her brother, King George I of Greece, in Corfu a week later on 5 May.

The following day, the King suffered several heart attacks, but refused to go to bed, saying, "No, I shall not give in; I shall go on; I shall work to the end." Between moments of faintness, his son the Prince of Wales (shortly to be King George V) told him that his horse, Witch of the Air, had won at Kempton Park that afternoon. The King replied, "Yes, I have heard of it. I am very glad": his final words. At 11:30 p.m. he lost consciousness for the last time and was put to bed. He died 15 minutes later.

Alexandra refused to allow the King's body to be moved for eight days afterwards, though she allowed small groups of visitors to enter his room. On 11 May, the late King was dressed in his uniform and placed in a massive oak coffin, which was moved on 14 May to the throne room, where it was sealed and lay in state, with a guardsman stood at each corner of the bier. Despite the time that had elapsed since his death, Alexandra noted the King's body remained "wonderfully preserved". On the morning of 17 May, the coffin was placed on a gun carriage and drawn by black horses to Westminster Hall, with the new King and his family walking behind. Following a brief service, the royal family left, and the hall was opened to the public; over 400,000 people filed past the coffin over the next two days.

As Barbara Tuchman noted in "The Guns of August", his funeral, held on 20 May 1910, marked "the greatest assemblage of royalty and rank ever gathered in one place and, of its kind, the last." A royal train conveyed the King's coffin from London to Windsor Castle, where Edward VII was buried at St George's Chapel.

Before his accession to the throne, Edward was the longest-serving heir apparent in British history. He was surpassed by his great-great-grandson Prince Charles on 20 April 2011. The title Prince of Wales is not automatically held by the heir apparent; it is bestowed by the reigning monarch at a time of his or her choosing. Edward was the longest-serving holder of that title until surpassed by Charles on 9 September 2017; Edward was Prince of Wales between 8 December 1841 and 22 January 1901 (59 years, 45 days). Charles was created Prince of Wales on 26 July 1958 ( ago).

As king, Edward VII proved a greater success than anyone had expected, but he was already past the average life expectancy and had little time left to fulfil the role. In his short reign, he ensured that his second son and heir, George V, was better prepared to take the throne. Contemporaries described their relationship as more like affectionate brothers than father and son, and on Edward's death George wrote in his diary that he had lost his "best friend and the best of fathers ... I never had a [cross] word with him in my life. I am heart-broken and overwhelmed with grief".

Edward has been recognised as the first truly constitutional British sovereign and the last sovereign to wield effective political power. Though lauded as "Peacemaker", he had been afraid his nephew, the German Emperor Wilhelm II, would tip Europe into war. Four years after Edward's death, World War I broke out. The naval reforms he had supported and his part in securing the Triple Entente between Britain, France and Russia, as well as his relationships with his extended family, fed the paranoia of the German Emperor, who blamed Edward for the war. Publication of the official biography of Edward was delayed until 1927 by its author, Sidney Lee, who feared German propagandists would select material to portray Edward as an anti-German warmonger. Lee was also hampered by the extensive destruction of Edward's personal papers; Edward had left orders that all his letters should be burned on his death. Subsequent biographers have been able to construct a more rounded picture of Edward by using material and sources that were unavailable to Lee.

Historian R. C. K. Ensor, writing in 1936, praised the King's political personality:

Ensor rejects the widespread notion that the King exerted important influence on British foreign policy. Ensor believed Edward gained that reputation by making frequent trips abroad, with many highly publicized visits to foreign courts, but surviving documents paint a different picture of "how comparatively crude his views on foreign policy were, how little he read, and of what naïve indiscretions he was capable."

Edward received criticism for his apparent pursuit of self-indulgent pleasure, but he received great praise for his affable manners and diplomatic tact. As his grandson Edward VIII wrote, "his lighter side ... obscured the fact that he had both insight and influence." "He had a tremendous zest for pleasure but he also had a real sense of duty", wrote J. B. Priestley. Lord Esher wrote that Edward was "kind and debonair and not undignified—but too human".





Edward's coat of arms as the Prince of Wales was the royal arms differenced by a label of three points argent, and an inescutcheon of the Duchy of Saxony, representing his paternal arms. When he acceded as King, he gained the royal arms undifferenced.






</doc>
<doc id="46793" url="https://en.wikipedia.org/wiki?curid=46793" title="Death Valley National Park">
Death Valley National Park

Death Valley National Park is an American national park that straddles the California—Nevada border, east of the Sierra Nevada. The park boundaries include Death Valley, the northern section of Panamint Valley, the southern section of Eureka Valley, and most of Saline Valley. The park occupies an interface zone between the arid Great Basin and Mojave deserts, protecting the northwest corner of the Mojave Desert and its diverse environment of salt-flats, sand dunes, badlands, valleys, canyons, and mountains. Death Valley is the largest national park in the lower 48 states, and the hottest, driest and lowest of all the national parks in the United States. The second-lowest point in the Western Hemisphere is in Badwater Basin, which is below sea level. Approximately 91% of the park is a designated wilderness area. The park is home to many species of plants and animals that have adapted to this harsh desert environment. Some examples include creosote bush, bighorn sheep, coyote, and the Death Valley pupfish, a survivor from much wetter times. UNESCO included Death Valley as the principal feature of its Mojave and Colorado Deserts Biosphere Reserve in 1984.

A series of Native American groups inhabited the area from as early as 7000 BC, most recently the Timbisha around 1000 AD who migrated between winter camps in the valleys and summer grounds in the mountains. A group of European-Americans, trapped in the valley in 1849 while looking for a shortcut to the gold fields of California, gave the valley its name, even though only one of their group died there. Several short-lived boom towns sprang up during the late 19th and early 20th centuries to mine gold and silver. The only long-term profitable ore to be mined was borax, which was transported out of the valley with twenty-mule teams. The valley later became the subject of books, radio programs, television series, and movies. Tourism expanded in the 1920s when resorts were built around Stovepipe Wells and Furnace Creek. Death Valley National Monument was declared in 1933 and the park was substantially expanded and became a national park in 1994.

The natural environment of the area has been shaped largely by its geology. The valley is actually a graben with the oldest rocks being extensively metamorphosed and at least 1.7 billion years old. Ancient, warm, shallow seas deposited marine sediments until rifting opened the Pacific Ocean. Additional sedimentation occurred until a subduction zone formed off the coast. The subduction uplifted the region out of the sea and created a line of volcanoes. Later the crust started to pull apart, creating the current Basin and Range landform. Valleys filled with sediment and, during the wet times of glacial periods, with lakes, such as Lake Manly.

In 2013, Death Valley National Park was designated as a dark sky park by the International Dark-Sky Association.

There are two major valleys in the park, Death Valley and Panamint Valley. Both of these valleys were formed within the last few million years and both are bounded by north–south-trending mountain ranges. These and adjacent valleys follow the general trend of Basin and Range topography with one modification: there are parallel strike-slip faults that perpendicularly bound the central extent of Death Valley. The result of this shearing action is additional extension in the central part of Death Valley which causes a slight widening and more subsidence there.

Uplift of surrounding mountain ranges and subsidence of the valley floor are both occurring. The uplift on the Black Mountains is so fast that the alluvial fans (fan-shaped deposits at the mouth of canyons) there are small and steep compared to the huge alluvial fans coming off the Panamint Range. Fast uplift of a mountain range in an arid environment often does not allow its canyons enough time to cut a classic V-shape all the way down to the stream bed. Instead, a V-shape ends at a slot canyon halfway down, forming a 'wine glass canyon.' Sediment is deposited on a small and steep alluvial fan.

At below sea level at its lowest point, Badwater Basin on Death Valley's floor is the second-lowest depression in the Western Hemisphere (behind Laguna del Carbón in Argentina), while Mount Whitney, only to the west, rises to . This topographic relief is the greatest elevation gradient in the contiguous United States and is the terminus point of the Great Basin's southwestern drainage. Although the extreme lack of water in the Great Basin makes this distinction of little current practical use, it does mean that in wetter times the lake that once filled Death Valley (Lake Manly) was the last stop for water flowing in the region, meaning the water there was saturated in dissolved materials. Thus the salt pans in Death Valley are among the largest in the world and are rich in minerals, such as borax and various salts and hydrates. The largest salt pan in the park extends from the Ashford Mill Site to the Salt Creek Hills, covering some of the valley floor. The best known playa in the park is the Racetrack, known for its moving rocks.

Death Valley is the hottest and driest place in North America due to its lack of surface water and low relief. It is so frequently the hottest spot in the United States that many tabulations of the highest daily temperatures in the country omit Death Valley as a matter of course.

On the afternoon of July 10, 1913, the United States Weather Bureau recorded a high temperature of 134 °F (56.7 °C) at Greenland Ranch (now Furnace Creek) in Death Valley. This temperature stands as the highest ambient air temperature ever recorded at the surface of the Earth. (A report of a temperature of 58 °C (136.4 °F) recorded in Libya in 1922 was later determined to be inaccurate.) Daily summer temperatures of or greater are common, as well as below freezing nightly temperatures in the winter. July is the hottest month, with an average high of and an average low of . December is the coldest month, with an average high of and an average low of . The record low is . 

Several of the larger Death Valley springs derive their water from a regional aquifer, which extends as far east as southern Nevada and Utah. Much of the water in this aquifer has been there for many thousands of years, since the Pleistocene ice ages, when the climate was cooler and wetter. Today's drier climate does not provide enough precipitation to recharge the aquifer at the rate at which water is being withdrawn.
The highest range within the park is the Panamint Range with Telescope Peak being its highest point at . The Death Valley region is a transitional zone in the northernmost part of the Mojave Desert and consists of five mountain ranges removed from the Pacific Ocean. Three of these are significant barriers: the Sierra Nevada, the Argus Range, and the Panamint Range. Air masses tend to lose moisture as they are forced up over mountain ranges, in what climatologists call a rainshadow effect.

The exaggerated rainshadow effect for the Death Valley area makes it North America's driest spot, receiving about of rainfall annually at Badwater (some years fail to register any measurable rainfall). Annual average precipitation varies from overall below sea level to over in the higher mountains that surround the valley. When rain does arrive it often does so in intense storms that cause flash floods which remodel the landscape and sometimes create very shallow ephemeral lakes.
The hot, dry climate makes it difficult for soil to form. Mass wasting, the down-slope movement of loose rock, is therefore the dominant erosive force in mountainous area, resulting in "skeletonized" ranges (mountains with very little soil on them). Sand dunes in the park, while famous, are not nearly as widespread as their fame or the dryness of the area may suggest. The Mesquite Flat dune field is the most easily accessible from the paved road just east of Stovepipe Wells in the north-central part of the valley and is primarily made of quartz sand. Another dune field is just to the north but is instead mostly composed of travertine sand. The highest dunes in the park, and some of the highest in North America, are located in the Eureka Valley about to the north of Stovepipe Wells, while the Panamint Valley dunes and the Saline Valley dunes are located west and northwest of the town, respectively. The Ibex dune field is near the seldom-visited Ibex Hill in the southernmost part of the park, just south of the Saratoga Springs marshland. All of the latter four dune fields are accessible only via unpaved roads. Prevailing winds in the winter come from the north, and prevailing winds in the summer come from the south. Thus the overall position of the dune fields remains more or less fixed.

There are rare exceptions to the dry nature of the area. In 2005, an unusually wet winter created a 'lake' in the Badwater Basin and led to the greatest wildflower season in the park's history. In October 2015, a "1000 year flood event" with over three inches of rain caused major damage in Death Valley National Park.

Four Native American cultures are known to have lived in the area during the last 10,000 years. The first known group, the Nevares Spring People, were hunters and gatherers who arrived in the area perhaps 9,000 years ago (7000 BC) when there were still small lakes in Death Valley and neighboring Panamint Valley. A much milder climate persisted at that time, and large game animals were still plentiful. By 5,000 years ago (3000 BC) the Mesquite Flat People displaced the Nevares Spring People. Around 2,000 years ago the Saratoga Spring People moved into the area, which by then was probably already a hot, dry desert. This culture was more advanced at hunting and gathering and was skillful at handcrafts. They also left mysterious stone patterns in the valley.

One-thousand years ago, the nomadic Timbisha (formerly called Shoshone and also known as Panamint or Koso) moved into the area and hunted game and gathered mesquite beans along with pinyon pine nuts. Because of the wide altitude differential between the valley bottom and the mountain ridges, especially on the west, the Timbisha practiced a vertical migration pattern. Their winter camps were located near water sources in the valley bottoms. As the spring and summer progressed and the weather warmed, grasses and other plant food sources ripened at progressively higher altitudes. November found them at the very top of the mountain ridges where they harvested pine nuts before moving back to the valley bottom for winter.

The California Gold Rush brought the first people of European descent known to visit the immediate area. In December 1849 two groups of California Gold Country-bound travelers with perhaps 100 wagons total stumbled into Death Valley after getting lost on what they thought was a shortcut off the Old Spanish Trail. Called the Bennett-Arcane Party, they were unable to find a pass out of the valley for weeks; they were able to find fresh water at various springs in the area, but were forced to eat several of their oxen to survive. They used the wood of their wagons to cook the meat and make jerky. The place where they did this is today referred to as "Burned Wagons Camp" and is located near the sand dunes.

After abandoning their wagons, they eventually were able to hike out of the valley. Just after leaving the valley, one of the women in the group turned and said, "Goodbye Death Valley," giving the valley they endured its name. Included in the party was William Lewis Manly whose autobiographical book "Death Valley in '49" detailed this trek and popularized the area (geologists later named the prehistoric lake that once filled the valley after him).

The ores that are most famously associated with the area were also the easiest to collect and the most profitable: evaporite deposits such as salts, borate, and talc. Borax was found by Rosie and Aaron Winters near The Ranch at Death Valley (then called Greenland) in 1881. Later that same year, the Eagle Borax Works became Death Valley's first commercial borax operation. William Tell Coleman built the Harmony Borax Works plant and began to process ore in late 1883 or early 1884, continuing until 1888. This mining and smelting company produced borax to make soap and for industrial uses. The end product was shipped out of the valley to the Mojave railhead in 10-ton-capacity wagons pulled by "twenty-mule teams" that were actually teams of 18 mules and two horses each.

The teams averaged two miles (3 km) an hour and required about 30 days to complete a round trip. The trade name "20-Mule Team Borax" was established by Francis Marion Smith's Pacific Coast Borax Company after Smith acquired Coleman's borax holdings in 1890. A memorable advertising campaign used the wagon's image to promote the Boraxo brand of granular hand soap and the Death Valley Days radio and television programs. In 1914, the Death Valley Railroad was built to serve mining operations on the east side of the valley. Mining continued after the collapse of Coleman's empire, and by the late 1920s the area was the world's number one source of borax. Some four to six million years old, the Furnace Creek Formation is the primary source of borate minerals gathered from Death Valley's playas.

Other visitors stayed to prospect for and mine deposits of copper, gold, lead, and silver. These sporadic mining ventures were hampered by their remote location and the harsh desert environment. In December 1903, two men from Ballarat were prospecting for silver. One was an out-of-work Irish miner named Jack Keane and the other was a one-eyed Basque butcher named Domingo Etcharren. Quite by accident, Keane discovered an immense ledge of free-milling gold by the duo's work site and named the claim the Keane Wonder Mine. This started a minor and short-lived gold rush into the area. The Keane Wonder Mine, along with mines at Rhyolite, Skidoo and Harrisburg, were the only ones to extract enough metal ore to make them worthwhile. Outright shams such as Leadfield also occurred, but most ventures quickly ended after a short series of prospecting mines failed to yield evidence of significant ore (these mines now dot the entire area and are a significant hazard to anyone who enters them). The boom towns which sprang up around these mines flourished during the 1900s (decade) but soon declined after the Panic of 1907.

The first documented tourist facilities in Death Valley were a set of tent houses built in the 1920s where Stovepipe Wells is now located. People flocked to resorts built around natural springs thought to have curative and restorative properties. In 1927, Pacific Coast Borax turned the crew quarters of its Furnace Creek Ranch into a resort, creating the Furnace Creek Inn and resort. The spring at Furnace Creek was harnessed to develop the resort, and as the water was diverted, the surrounding marshes and wetlands started to shrink.

Soon the valley was a popular winter destination. Other facilities started off as private getaways but were later opened to the public. Most notable among these was Death Valley Ranch, better known as Scotty's Castle. This large ranch home built in the Spanish Revival style became a hotel in the late 1930s and, largely because of the fame of Death Valley Scotty, a tourist attraction. Death Valley Scotty, whose real name was Walter Scott, was a gold miner who pretended to be owner of "his castle", which he claimed to have built with profits from his gold mine. Neither claim was true, but the real owner, Chicago millionaire Albert Mussey Johnson, encouraged the myth. When asked by reporters what his connection was to Walter Scott's castle, Johnson replied that he was Mr. Scott's banker.

President Herbert Hoover proclaimed a national monument in and around Death Valley on February 11, 1933, setting aside almost two million acres (8,000 km) of southeastern California and small parts of southwesternmost Nevada.

Twelve companies worked in Death Valley using Civilian Conservation Corps workers during the Great Depression and on into the early 1940s. They built barracks, graded of roads, installed water and telephone lines, and erected a total of 76 buildings. Trails in the Panamint Range were built to points of scenic interest, and an adobe village, laundry and trading post were constructed for Shoshone Native Americans. Five campgrounds, restrooms, an airplane landing field and picnic facilities were also built.

Creation of the monument resulted in a temporary closing of the lands to prospecting and mining. However, Death Valley was quickly reopened to mining by Congressional action in June of the same year. As improvements in mining technology allowed lower grades of ore to be processed, and new heavy equipment allowed greater amounts of rock to be moved, mining in Death Valley changed. Gone were the days of the "single-blanket, jackass prospector" long associated with the romantic west. Open pit and strip mines scarred the landscape as international mining corporations bought claims in highly visible areas of the national monument. The public outcry that ensued led to greater protection for all national park and monument areas in the United States.
In 1976, Congress passed the Mining in the Parks Act, which closed Death Valley National Monument to the filing of new mining claims, banned open-pit mining and required the National Park Service to examine the validity of tens of thousands of pre-1976 mining claims. Mining was allowed to resume on a limited basis in 1980 with stricter environmental standards.

The park's Resources Management Division monitors mining within park boundaries and continues to review the status of 19 patented mining claim groups and less than 10 unpatented mining claims, while ensuring that federal guidelines are followed and the park's resources are protected. In 2005, the Billie Mine, an underground borax mine located along the road to Dante's View, closed, ending mining in the park.

Death Valley National Monument was designated a biosphere reserve in 1984. On October 31, 1994, the monument was expanded by 1.3 million acres (5,300 km) and re-designated as a national park, via congressional passage of the California Desert Protection Act (Public Law 103-433). Consequently, the elevated status for Death Valley made it the largest national park in the contiguous United States. Many of the larger cities and towns within the boundary of the regional ground water flow system that the park and its plants and animals rely upon are experiencing some of the fastest growth rates of any place in the United States. Notable examples within a radius of Death Valley National Park include Las Vegas and Pahrump, Nevada. In the case of Las Vegas, the local Chamber of Commerce estimates that 6,000 people are moving to the city every month. Between 1985 and 1995, the population of the Las Vegas Valley increased from 550,700 to 1,138,800.
In 1977, parts of Death Valley were used by director George Lucas as a filming location for "Star Wars", providing the setting for the fictional planet Tatooine.

The park has a diverse and complex geologic history. Since its formation, the area that comprises the park has experienced at least four major periods of extensive volcanism, three or four periods of major sedimentation, and several intervals of major tectonic deformation where the crust has been reshaped. Two periods of glaciation (a series of ice ages) have also had effects on the area, although no glaciers ever existed in the ranges now in the park.

Little is known about the history of the oldest exposed rocks in the area due to extensive metamorphism (alteration of rock by heat and pressure). Radiometric dating gives an age of 1,700 million years for the metamorphism during the Proterozoic. About 1,400 million years ago a mass of granite now in the Panamint Range intruded this complex. Uplift later exposed these rocks to nearly 500 million years of erosion.

The Proterozoic sedimentary formations of the Pahrump Group were deposited on these basement rocks. This occurred following uplift and erosion of any earlier sediments from the Proterozoic basement rocks. The Pahrump is composed of arkose conglomerate (quartz clasts in a concrete-like matrix) and mudstone in its lower part, followed by dolomite from carbonate banks topped by algal mats as stromatolites, and finished with basin-filling sediment derived from the above, including possible glacial till from the hypothesized Snowball Earth glaciation. The very youngest rocks in the Pahrump Group are basaltic lava flows.

A rift opened and subsequently flooded the region as part of the breakup of the supercontinent Rodinia in the Neoproterozoic (by about 755 million years ago) and the creation of the Pacific Ocean. A shoreline similar to the present Atlantic Ocean margin of the United States lay to the east. An algal mat-covered carbonate bank was deposited, forming the Noonday Dolomite. Subsidence of the region occurred as the continental crust thinned and the newly formed Pacific widened, forming the Ibex Formation. An angular unconformity (an uneven gap in the geologic record) followed.

A true ocean basin developed to the west, breaking all the earlier formations along a steep front. A wedge of clastic sediment then began to accumulate at the base of the two underwater precipices, starting the formation of opposing continental shelves. Three formations developed from sediment that accumulated on the wedge. The region's first known fossils of complex life are found in the resulting formations. Notable among these are the Ediacara fauna and trilobites, the evolution of the latter being part of the Cambrian Explosion of life.

The sandy mudflats gave way about 550 million years ago to a carbonate platform (similar to the one around the present-day Bahamas), which lasted for the next 300 million years of Paleozoic time (refer to the middle of the ). Death Valley's position was then within ten or twenty degrees of the Paleozoic equator. Thick beds of carbonate-rich sediments were periodically interrupted by periods of emergence. Although details of geography varied during this immense interval of time, a north-northeasterly trending coastline generally ran from Arizona up through Utah. The resulting eight formations and one group are thick and underlay much of the Cottonwood, Funeral, Grapevine, and Panamint ranges.

In the early-to-mid- Mesozoic the western edge of the North American continent was pushed against the oceanic plate under the Pacific Ocean, creating a subduction zone. A subduction zone is a type of contact between different crustal plates where heavier crust slides below lighter crust. Erupting volcanoes and uplifting mountains were created as a result, and the coastline was pushed to the west. The Sierran Arc started to form to the northwest from heat and pressure generated from subduction, and compressive forces caused thrust faults to develop.

A long period of uplift and erosion was concurrent with and followed the above events, creating a major unconformity, which is a large gap in the geologic record. Sediments worn off the Death Valley region were carried both east and west by wind and water. No Jurassic- to Eocene-aged sedimentary formations exist in the area, except for some possibly Jurassic-age volcanic rocks (see the top of the ).

Erosion over many millions of years created a relatively featureless plain. Thirty-five million years ago, sluggish streams migrated laterally over its surface. Several other similar formations were also laid down.

Basin and Range-associated stretching of large parts of crust below southwestern United States and northwestern Mexico started around 16 million years ago and the region is still spreading. This stretching began to affect the Death and Panamint valleys area by 3 million years ago. Before this, rocks now in the Panamint Range were on top of rocks that would become the Black Mountains and the Cottonwood Mountains. Lateral and vertical transport of these blocks was accomplished by movement on normal faults. Right-lateral movement along strike-slip faults that run parallel to and at the base of the ranges also helped to develop the area. Torsional forces, probably associated with northwesterly movement of the Pacific Plate along the San Andreas Fault (west of the region), is responsible for the lateral movement.

Igneous activity associated with this stretching occurred from 12 million to 4 million years ago. Sedimentation is concentrated in valleys (basins) from material eroded from adjacent ranges. The amount of sediment deposited has roughly kept up with this subsidence, resulting in retention of more or less the same valley floor elevation over time.

Pleistocene ice ages started 2 million years ago, and melt from alpine glaciers on the nearby Sierra Nevada Mountains fed a series of lakes that filled Death and Panamint valleys and surrounding basins (see the top of the ). The lake that filled Death Valley was the last of a chain of lakes fed by the Amargosa and Mojave Rivers, and possibly also the Owens River. The large lake that covered much of Death Valley's floor, which geologists call Lake Manly, started to dry up 10,500 years ago. Saltpans and playas were created as ice age glaciers retreated, thus drastically reducing the lakes' water source. Only faint shorelines are left.

Habitat varies from saltpan at below sea level to the sub-alpine conditions found on the summit of Telescope Peak, which rises to . Vegetation zones include creosote bush, desert holly, and mesquite at the lower elevations and sage up through shadscale, blackbrush, Joshua tree, pinyon-juniper, to limber pine and bristlecone pine woodlands. The saltpan is devoid of vegetation, and the rest of the valley floor and lower slopes have sparse cover, although where water is available, an abundance of vegetation is usually present. 
These zones and the adjacent desert support a variety of wildlife species, including 51 species of native mammals, 307 species of birds, 36 species of reptiles, 3 species of amphibians, and 2 species of native fish.

Small mammals are more numerous than large mammals, such as bighorn sheep, coyotes (), bobcats, kit foxes, cougars, and mule deer. Mule deer are present in the pinyon/juniper associations of the Grapevine, Cottonwood, and Panamint ranges. Bighorn sheep are a rare species of mountain sheep that exist in isolated bands in the Sierra and in Death Valley. These are highly adaptable animals and can eat almost any plant. They have no known predators, but humans and burros compete for habitat.
The ancestors of the Death Valley pupfish swam to the area from the Colorado River via a long-since dried-up system of rivers and lakes (see Lake Manly). They now live in two separate populations: one in Salt Creek and another in Cottonball Marsh. Death Valley is one of the hottest and driest places in North America, yet it is home to over 1,000 species of plants; 23 of which, including the very rare rock lady ("Holmgrenanthe petrophila"), are not found anywhere else.

Adaptation to the dry environment is key. For example, creosote bush and mesquite have tap-root systems that can extend down in order to take advantage of a year-round supply of ground water. The diversity of Death Valley's plant communities results partly from the region's location in a transition zone between the Mojave Desert, the Great Basin Desert and the Sonoran Desert. This location, combined with the great relief found within the park, supports vegetation typical of three biotic life zones: the lower Sonoran, the Canadian, and the arctic/alpine in portions of the Panamint Range. Based on the Munz and Keck (1968) classifications, seven plant communities can be categorized within these life zones, each characterized by dominant vegetation and representative of three vegetation types: scrub, desert woodland, and coniferous forest. Microhabitats further subdivide some communities into zones, especially on the valley floor.
Unlike more typical locations across the Mojave Desert, many of the water-dependent Death Valley habitats possess a diversity of plant and animal species that are not found anywhere else in the world. The existence of these species is due largely to a unique geologic history and the process of evolution that has progressed in habitats that have been isolated from one another since the Pleistocene epoch.

Sightseeing is available by personal automobile, four-wheel drive, bicycle, mountain bike (on established roadways only), and hiking. Riding through the park on motorcycle is also a popular pastime. State Route 190, the Badwater Road, the Scotty's Castle Road, and paved roads to Dante's View and Wildrose provide access to the major scenic viewpoints and historic points of interest. More than of unpaved and four-wheel-drive roads provide access to wilderness hiking, camping, and historical sites. All vehicles must be licensed and street legal. There are hiking trails of varying lengths and difficulties, but most backcountry areas are accessible only by cross-country hiking. There are thousands of hiking possibilities. The normal season for visiting the park is from October 15 to May 15, avoiding summer extremes in temperature. Costumed living history tours of the historic Death Valley Scotty's Castle are conducted for a fee, but , are suspended due to flood damage to the buildings and grounds.

There are nine designated campgrounds within the park, and overnight backcountry camping permits are available at the Visitor Center. Xanterra Parks & Resorts owns and operates a private resort, the Oasis at Death Valley, which comprises two separate and distinct hotels: the Inn at Death Valley is a four-star historic hotel, and the Ranch at Death Valley is a three-star ranch-style property reminiscent of the mining and prospecting days. Death Valley Lodging Company operates the Stovepipe Wells Village motel. Stovepipe Wells Village is the only authorized concession operations located in Death Valley National Park. There are a few motels near entrances to the park, in Shoshone, Death Valley Junction, Beatty, Nevada, and Panamint Springs.

The visitor center is located in the Furnace Creek resort area on State Route 190. A 12-minute introductory slide program is shown every 30 minutes. During the winter season—November through April—rangers offer interpretive tours and a wide variety of walks, talks, and slide presentations about Death Valley cultural and natural history. The visitor center has displays dealing with the park's geology, climate, wildlife and natural history. There are also specific sections dealing with the human history and pioneer experience. The Death Valley Natural History Association maintains a bookstore specifically geared to the natural and cultural history of the park.

The northeast corner of Saline Valley has several developed hot spring pools. The pools can be accessed by driving on the unpaved Saline Valley Road for several hours, or by flying a personal aircraft to the Chicken Strip—an uncharted airstrip a short walk from the springs.

Death Valley National Park is a popular location for stargazing as it has one of the darkest night skies in the United States. Despite its remote location, air quality and night visibility are threatened by civilization. In particular, light pollution is introduced by nearby Las Vegas. The darkest skies are, in general, located in the northwest of the park. The northwestern area of the park, including sites such as Ubehebe Crater, is a Bortle class 1 or "excellent dark sky" site. The Andromeda Galaxy and the Triangulum Galaxy are visible to the unaided eye under these conditions, and the Milky Way casts shadows; optical phenomenon such as zodiacal light or "false dawn" and gegenschein are also visible to the unaided eye under these conditions. Most southern regions of the park are Bortle class 2 or "average dark sky" sites.




</doc>
<doc id="46852" url="https://en.wikipedia.org/wiki?curid=46852" title="George I of Great Britain">
George I of Great Britain

George I (George Louis; ; 28 May 1660 – 11 June 1727) was King of Great Britain and Ireland from 1 August 1714 and ruler of the Duchy and Electorate of Brunswick-Lüneburg (Hanover) in the Holy Roman Empire from 1698 until his death in 1727.

George was born in Hanover and inherited the titles and lands of the Duchy of Brunswick-Lüneburg from his father and uncles. A succession of European wars expanded his German domains during his lifetime, and in 1708 he was ratified as prince-elector of Hanover. At the age of 54, after the death of his second cousin Anne, Queen of Great Britain, George ascended the British throne as the first monarch of the House of Hanover. Although over 50 Roman Catholics were closer to Anne by primogeniture, the Act of Settlement 1701 prohibited Catholics from inheriting the British throne; George was Anne's closest living Protestant relative. In reaction, Jacobites attempted to depose George and replace him with Anne's Catholic half-brother, James Francis Edward Stuart, but their attempts failed.

During George's reign, the powers of the monarchy diminished and Britain began a transition to the modern system of cabinet government led by a prime minister. Towards the end of his reign, actual political power was held by Robert Walpole, now recognised as Britain's first "de facto" prime minister. George died of a stroke on a trip to his native Hanover, where he was buried. He was the last British monarch to be buried outside the United Kingdom.

George was born on 28 May 1660 in the city of Hanover in the Duchy of Brunswick-Lüneburg in the Holy Roman Empire. He was the eldest son of Ernest Augustus, Duke of Brunswick-Lüneburg, and his wife, Sophia of the Palatinate. Sophia was the granddaughter of King James I of England through her mother, Elizabeth of Bohemia.

For the first year of his life, George was the only heir to the German territories of his father and three childless uncles. George's brother, Frederick Augustus, was born in 1661, and the two boys (known as "Görgen" and "Gustchen" by the family) were brought up together. Their mother was absent for almost a year (1664–65) during a long convalescent holiday in Italy, but corresponded regularly with her sons' governess and took a great interest in their upbringing, even more so upon her return. Sophia bore Ernest Augustus another four sons and a daughter. In her letters, Sophia describes George as a responsible, conscientious child who set an example to his younger brothers and sisters.

By 1675 George's eldest uncle had died without issue, but his remaining two uncles had married, putting George's inheritance in jeopardy as his uncles' estates might pass to their own sons, should they have had any, instead of to George. George's father took him hunting and riding, and introduced him to military matters; mindful of his uncertain future, Ernest Augustus took the fifteen-year-old George on campaign in the Franco-Dutch War with the deliberate purpose of testing and training his son in battle.

In 1679 another uncle died unexpectedly without sons, and Ernest Augustus became reigning Duke of Calenberg-Göttingen, with his capital at Hanover. George's surviving uncle, George William of Celle, had married his mistress in order to legitimise his only daughter, Sophia Dorothea, but looked unlikely to have any further children. Under Salic law, where inheritance of territory was restricted to the male line, the succession of George and his brothers to the territories of their father and uncle now seemed secure. In 1682, the family agreed to adopt the principle of primogeniture, meaning George would inherit all the territory and not have to share it with his brothers.

The same year, George married his first cousin, Sophia Dorothea of Celle, thereby securing additional incomes that would have been outside Salic laws. The marriage of state was arranged primarily as it ensured a healthy annual income and assisted the eventual unification of Hanover and Celle. His mother was at first against the marriage because she looked down on Sophia Dorothea's mother (who was not of royal birth), and because she was concerned by Sophia Dorothea's legitimated status. She was eventually won over by the advantages inherent in the marriage.

In 1683, George and his brother, Frederick Augustus, served in the Great Turkish War at the Battle of Vienna, and Sophia Dorothea bore George a son, George Augustus. The following year, Frederick Augustus was informed of the adoption of primogeniture, meaning he would no longer receive part of his father's territory as he had expected. It led to a breach between father and son, and between the brothers, that lasted until Frederick Augustus's death in battle in 1690. With the imminent formation of a single Hanoverian state, and the Hanoverians' continuing contributions to the Empire's wars, Ernest Augustus was made an Elector of the Holy Roman Empire in 1692. George's prospects were now better than ever as the sole heir to his father's electorate and his uncle's duchy.

Sophia Dorothea had a second child, a daughter named after her, in 1687, but there were no other pregnancies. The couple became estranged—George preferred the company of his mistress, Melusine von der Schulenburg, and Sophia Dorothea, meanwhile, had her own romance with the Swedish Count Philip Christoph von Königsmarck. Threatened with the scandal of an elopement, the Hanoverian court, including George's brothers and mother, urged the lovers to desist, but to no avail. According to diplomatic sources from Hanover's enemies, in July 1694 the Swedish count was killed, possibly with the connivance of George, and his body thrown into the river Leine weighted with stones. The murder was claimed to have been committed by four of Ernest Augustus's courtiers, one of whom (Don Nicolò Montalbano) was paid the enormous sum of 150,000 thalers, which was about one hundred times the annual salary of the highest paid minister. Later rumours supposed that Königsmarck was hacked to pieces and buried beneath the Hanover palace floorboards. However, sources in Hanover itself, including Sophia, denied any knowledge of Königsmarck's whereabouts.

George's marriage to Sophia Dorothea was dissolved, not on the grounds that either of them had committed adultery, but on the grounds that Sophia Dorothea had abandoned her husband. With the agreement of her father, George had Sophia Dorothea imprisoned in Ahlden House in her native Celle, where she stayed until she died more than thirty years later. She was denied access to her children and father, forbidden to remarry and only allowed to walk unaccompanied within the mansion courtyard. She was, however, endowed with an income, establishment, and servants, and was allowed to ride in a carriage outside her castle, albeit under supervision. Melusine von der Schulenburg acted as George's hostess openly from 1698 until his death, and they had three daughters together, born in 1692, 1693 and 1701, respectively.

Ernest Augustus died on 23 January 1698, leaving all of his territories to George with the exception of the Prince-Bishopric of Osnabrück, an office he had held since 1661. George thus became Duke of Brunswick-Lüneburg (also known as Hanover, after its capital) as well as Archbannerbearer and a Prince-Elector of the Holy Roman Empire. His court in Hanover was graced by many cultural icons such as the mathematician and philosopher Gottfried Leibniz and the composers George Frideric Händel and Agostino Steffani.

Shortly after George's accession to his paternal duchy, Prince William, Duke of Gloucester, who was second-in-line to the English and Scottish thrones, died. By the terms of the English Act of Settlement 1701, George's mother, Sophia, was designated as the heir to the English throne if the then reigning monarch, William III, and his sister-in-law, Anne, died without surviving issue. The succession was so designed because Sophia was the closest Protestant relative of the British royal family. Fifty-six Catholics with superior hereditary claims were bypassed. The likelihood of any of them converting to Protestantism for the sake of the succession was remote; some had already refused.

In August 1701, George was invested with the Order of the Garter and, within six weeks, the nearest Catholic claimant to the thrones, the former king James II, died. William III died the following March and was succeeded by Anne. Sophia became heiress presumptive to the new Queen of England. Sophia was in her seventy-first year, older than Anne by thirty-five years, but she was very fit and healthy and invested time and energy in securing the succession either for herself or for her son. However, it was George who understood the complexities of English politics and constitutional law, which required further acts in 1705 to naturalise Sophia and her heirs as English subjects, and to detail arrangements for the transfer of power through a Regency Council. In the same year, George's surviving uncle died and he inherited further German dominions: the Principality of Lüneburg-Grubenhagen, centred at Celle.

Shortly after George's accession in Hanover, the War of the Spanish Succession broke out. At issue was the right of Philip, the grandson of King Louis XIV of France, to succeed to the Spanish throne under the terms of King Charles II of Spain's will. The Holy Roman Empire, the United Dutch Provinces, England, Hanover and many other German states opposed Philip's right to succeed because they feared that the French House of Bourbon would become too powerful if it also controlled Spain. As part of the war effort, George invaded his neighbouring state, Brunswick-Wolfenbüttel, which was pro-French, writing out some of the battle orders himself. The invasion succeeded with few lives lost. As a reward, the prior Hanoverian annexation of the Duchy of Saxe-Lauenburg by George's uncle was recognised by the British and Dutch.

In 1706, the Elector of Bavaria was deprived of his offices and titles for siding with Louis against the Empire. The following year, George was invested as an Imperial Field Marshal with command of the imperial army stationed along the Rhine. His tenure was not altogether successful, partly because he was deceived by his ally, the Duke of Marlborough, into a diversionary attack, and partly because Emperor Joseph I appropriated the funds necessary for George's campaign for his own use. Despite this, the German princes thought that he had acquitted himself well. In 1708 they formally confirmed George's position as a Prince-Elector in recognition of, or because of, his service. George did not hold Marlborough's actions against him; he understood they were part of a plan to lure French forces away from the main attack.

In 1709, George resigned as field marshal, never to go on active service again. In 1710, he was granted the dignity of Arch-Treasurer of the Empire, an office formerly held by the Elector Palatine—the absence of the Elector of Bavaria allowed a reshuffling of offices. The death of the Emperor in 1711 threatened to destroy the balance of power in the opposite direction, so the war ended in 1713 with the ratification of the Treaty of Utrecht. Philip was allowed to succeed to the Spanish throne but was removed from the French line of succession, and the Elector of Bavaria was restored.

Though both England and Scotland recognised Anne as their queen, only the English Parliament had settled on Sophia, Electress of Hanover, as the heir presumptive. The Parliament of Scotland (the Estates) had not formally settled the succession question for the Scottish throne. In 1703, the Estates passed a bill declaring that their selection for Queen Anne's successor would not be the same individual as the successor to the English throne, unless England granted full freedom of trade to Scottish merchants in England and its colonies. At first Royal Assent was withheld, but the following year Anne capitulated to the wishes of the Estates and assent was granted to the bill, which became the Act of Security 1704. In response the English Parliament passed measures that threatened to restrict Anglo-Scottish trade and cripple the Scottish economy if the Estates did not agree to the Hanoverian succession. Eventually, in 1707, both Parliaments agreed on an Act of Union, which united England and Scotland into a single political entity, the Kingdom of Great Britain, and established the rules of succession as laid down by the Act of Settlement 1701. The union created the largest free trade area in 18th-century Europe.

Whig politicians believed Parliament had the right to determine the succession, and to bestow it on the nearest Protestant relative of the Queen, while many Tories were more inclined to believe in the hereditary right of the Catholic Stuarts, who were nearer relations. In 1710, George announced that he would succeed in Britain by hereditary right, as the right had been removed from the Stuarts, and he retained it. "This declaration was meant to scotch any Whig interpretation that parliament had given him the kingdom [and] ... convince the Tories that he was no usurper."

George's mother, the Electress Sophia, died on 28 May 1714 at the age of 83. She had collapsed in the gardens at Herrenhausen after rushing to shelter from a shower of rain. George was now Queen Anne's heir presumptive. He swiftly revised the membership of the Regency Council that would take power after Anne's death, as it was known that Anne's health was failing and politicians in Britain were jostling for power. She suffered a stroke, which left her unable to speak, and died on 1 August 1714. The list of regents was opened, the members sworn in, and George was proclaimed King of Great Britain and Ireland. Partly due to contrary winds, which kept him in The Hague awaiting passage, he did not arrive in Britain until 18 September. George was crowned at Westminster Abbey on 20 October. His coronation was accompanied by rioting in over twenty towns in England.

George mainly lived in Great Britain after 1714, though he visited his home in Hanover in 1716, 1719, 1720, 1723 and 1725; in total George spent about one fifth of his reign as king in Germany. A clause in the Act of Settlement that forbade the British monarch from leaving the country without Parliament's permission was unanimously repealed in 1716. During all but the first of the King's absences power was vested in a Regency Council rather than in his son, George Augustus, Prince of Wales.

Within a year of George's accession the Whigs won an overwhelming victory in the general election of 1715. Several members of the defeated Tory Party sympathised with the Jacobites, who sought to replace George with Anne's Catholic half-brother, James Francis Edward Stuart (called "James III and VIII" by his supporters and "the Pretender" by his opponents). Some disgruntled Tories sided with a Jacobite rebellion, which became known as "The Fifteen". James's supporters, led by Lord Mar, an embittered Scottish nobleman who had previously served as a secretary of state, instigated rebellion in Scotland where support for Jacobitism was stronger than in England. "The Fifteen", however, was a dismal failure; Lord Mar's battle plans were poor, and James arrived late with too little money and too few arms. By the end of the year the rebellion had all but collapsed. In February 1716, faced with impending defeat, James and Lord Mar fled to France. After the rebellion was defeated, although there were some executions and forfeitures, George acted to moderate the Government's response, showed leniency, and spent the income from the forfeited estates on schools for Scotland and paying off part of the national debt.

George's distrust of the Tories aided the passing of power to the Whigs. Whig dominance would grow to be so great under George that the Tories would not return to power for another half-century. After the election, the Whig-dominated Parliament passed the Septennial Act 1715, which extended the maximum duration of Parliament to seven years (although it could be dissolved earlier by the Sovereign). Thus Whigs already in power could remain in such a position for a greater period of time.

After his accession in Great Britain, George's relationship with his son (which had always been poor) worsened. George Augustus, Prince of Wales, encouraged opposition to his father's policies, including measures designed to increase religious freedom in Britain and expand Hanover's German territories at the expense of Sweden. In 1717 the birth of a grandson led to a major quarrel between George and the Prince of Wales. The King, supposedly following custom, appointed the Lord Chamberlain, the Duke of Newcastle, as one of the baptismal sponsors of the child. The King was angered when the Prince of Wales, disliking Newcastle, verbally insulted the Duke at the christening, which the Duke misunderstood as a challenge to a duel. The Prince was told to leave the royal residence, St. James's Palace. The Prince's new home, Leicester House, became a meeting place for the King's political opponents. George and his son were later reconciled at the insistence of Robert Walpole and the desire of the Princess of Wales, who had moved out with her husband but missed her children who had been left in the care of the King. However, following the quarrel at the baptism, father and son were never again on cordial terms.

George was active in directing British foreign policy during his early reign. In 1717 he contributed to the creation of the Triple Alliance, an anti-Spanish league composed of Great Britain, France and the Dutch Republic. In 1718 the Holy Roman Empire was added to the body, which became known as the Quadruple Alliance. The subsequent War of the Quadruple Alliance involved the same issue as the War of the Spanish Succession. The Treaty of Utrecht (1713) had recognised the grandson of King Louis XIV of France, Philip, as the King of Spain on the condition that he gave up his rights to succeed to the French throne. Upon the death of Louis XIV in 1715, however, Philip sought to overturn the treaty.

Spain supported a Jacobite-led invasion of Scotland in 1719, but stormy seas allowed only about three hundred Spanish troops to arrive in Scotland. A base was established at Eilean Donan Castle on the west Scottish coast in April, only to be destroyed by British ships a month later. Attempts by the Jacobites to recruit Scottish clansmen yielded a fighting force of only about a thousand men. The Jacobites were poorly equipped and were easily defeated by British artillery at the Battle of Glen Shiel. The clansmen dispersed into the Highlands, and the Spaniards surrendered. The invasion never posed any serious threat to George's government. With the French this time fighting against him in the War, Philip's armies fared poorly. As a result, the Spanish and French thrones remained separate. Simultaneously, Hanover gained from the resolution of the Great Northern War, which had been caused by rivalry between Sweden and Russia for control of the Baltic. The Swedish territories of Bremen and Verden were ceded to Hanover in 1719, with Hanover paying Sweden monetary compensation for the loss of territory.

In Hanover, the King was an absolute monarch. All government expenditure above 50 thalers (between 12 and 13 British pounds), and the appointment of all army officers, all ministers, and even government officials above the level of copyist, was in his personal control. By contrast in Great Britain, George had to govern through Parliament.

In 1715 when the Whigs came to power, George's chief ministers included Sir Robert Walpole, Lord Townshend (Walpole's brother-in-law), Lord Stanhope and Lord Sunderland. In 1717 Lord Townshend was dismissed, and Walpole resigned from the Cabinet over disagreements with their colleagues; Lord Stanhope became supreme in foreign affairs, and Lord Sunderland the same in domestic matters.

Lord Sunderland's power began to wane in 1719. He introduced a Peerage Bill that attempted to limit the size of the House of Lords by restricting new creations. The measure would have solidified Sunderland's control of the House by preventing the creation of opposition peers, but it was defeated after Walpole led the opposition to the bill by delivering what was considered "the most brilliant speech of his career". Walpole and Townshend were reappointed as ministers the following year and a new, supposedly unified, Whig government formed.

Greater problems arose over financial speculation and the management of the national debt. Certain government bonds could not be redeemed without the consent of the bondholder and had been issued when interest rates were high; consequently each bond represented a long-term drain on public finances, as bonds were hardly ever redeemed. In 1719 the South Sea Company proposed to take over £31 million (three fifths) of the British national debt by exchanging government securities for stock in the company. The Company bribed Lord Sunderland, George's mistress Melusine von der Schulenburg, and Lord Stanhope's cousin, Charles Stanhope, who was Secretary of the Treasury, to support their plan. The Company enticed bondholders to convert their high-interest, irredeemable bonds to low-interest, easily tradeable stocks by offering apparently preferential financial gains. Company prices rose rapidly; the shares had cost £128 on 1 January 1720, but were valued at £500 when the conversion scheme opened in May. On 24 June the price reached a peak of £1,050. The company's success led to the speculative flotation of other companies, some of a bogus nature, and the Government, in an attempt to suppress these schemes and with the support of the Company, passed the Bubble Act. With the rise in the market now halted, uncontrolled selling began in August, which caused the stock to plummet to £150 by the end of September. Many individuals—including aristocrats—lost vast sums and some were completely ruined. George, who had been in Hanover since June, returned to London in November—sooner than he wanted or was usual—at the request of the ministry.

The economic crisis, known as the South Sea Bubble, made George and his ministers extremely unpopular. In 1721 Lord Stanhope, though personally innocent, collapsed and died after a stressful debate in the House of Lords, and Lord Sunderland resigned from public office.

Sunderland, however, retained a degree of personal influence with George until his sudden death in 1722 allowed the rise of Sir Robert Walpole. Walpole became "de facto" Prime Minister, although the title was not formally applied to him (officially, he was First Lord of the Treasury and Chancellor of the Exchequer). His management of the South Sea crisis, by rescheduling the debts and arranging some compensation, helped the return to financial stability. Through Walpole's skilful management of Parliament, George managed to avoid direct implication in the Company's fraudulent actions. Claims that George had received free stock as a bribe are not supported by evidence; indeed receipts in the Royal Archives show that he paid for his subscriptions and that he lost money in the crash.

As requested by Walpole, George revived the Order of the Bath in 1725, which enabled Walpole to reward or gain political supporters by offering them the honour. Walpole became extremely powerful and was largely able to appoint ministers of his own choosing. Unlike his predecessor, Queen Anne, George rarely attended meetings of the cabinet; most of his communications were in private, and he only exercised substantial influence with respect to British foreign policy. With the aid of Lord Townshend, he arranged for the ratification by Great Britain, France and Prussia of the Treaty of Hanover, which was designed to counterbalance the Austro-Spanish Treaty of Vienna and protect British trade.

George, although increasingly reliant on Walpole, could still have replaced his ministers at will. Walpole was actually afraid of being removed from office towards the end of George I's reign, but such fears were put to an end when George died during his sixth trip to his native Hanover since his accession as king. He suffered a stroke on the road between Delden and Nordhorn on 9 June 1727, and was taken by carriage to the Prince-Bishop's palace at Osnabrück where he died in the early hours before dawn on 11 June 1727. He was buried in the chapel of Leine Palace in Hanover, but his remains were moved to the chapel at Herrenhausen Gardens after World War II. Leine Palace had burnt out entirely after British aerial bombings and the king's remains, along with his parents', were moved to the 19th-century mausoleum of King Ernest Augustus in the Berggarten.

George was succeeded by his son, George Augustus, who took the throne as George II. It was widely assumed, even by Walpole for a time, that George II planned to remove Walpole from office but was prevented from doing so by his wife, Caroline of Ansbach. However, Walpole commanded a substantial majority in Parliament and George II had little choice but to retain him or risk ministerial instability. In subsequent reigns the power of the prime minister increased further at the expense of the power of the sovereign.

George was ridiculed by his British subjects; some of his contemporaries, such as Lady Mary Wortley Montagu, thought him unintelligent on the grounds that he was wooden in public. Though he was unpopular in Great Britain due to his supposed inability to speak English, such an inability may not have existed later in his reign as documents from that time show that he understood, spoke and wrote English. He certainly spoke fluent German and French, good Latin, and some Italian and Dutch. His treatment of his wife, Sophia Dorothea, became something of a scandal.

The British perceived him as too German, and in the opinion of historian Ragnhild Hatton, wrongly assumed that he had a succession of German mistresses. However, in mainland Europe, he was seen as a progressive ruler supportive of the Enlightenment who permitted his critics to publish without risk of severe censorship, and provided sanctuary to Voltaire when the philosopher was exiled from Paris in 1726. European and British sources agree that George was reserved, temperate and financially prudent; George disliked to be in the public light at social events, avoided the royal box at the opera and often travelled incognito to the house of a friend to play cards. Despite some unpopularity, the Protestant George I was seen by most of his subjects as a better alternative to the Roman Catholic Pretender James. William Makepeace Thackeray indicates such ambivalent feelings as he wrote: 

Writers of the nineteenth century, such as Thackeray, Sir Walter Scott and Lord Mahon, were reliant on biased first-hand accounts published in the previous century such as Lord Hervey's memoirs, and looked back on the Jacobite cause with romantic, even sympathetic, eyes. They in turn, influenced British authors of the first half of the twentieth century such as G. K. Chesterton, who introduced further anti-German and anti-Protestant bias into the interpretation of George's reign. However, in the wake of World War II continental European archives were opened to historians of the later twentieth century and nationalistic anti-German feeling subsided. George's life and reign were re-explored by scholars such as Beattie and Hatton, and his character, abilities and motives re-assessed in a more generous light. John H. Plumb noted that: 

Yet the character of George I remains elusive; he was in turn genial and affectionate in private letters to his daughter, and then dull and awkward in public. Perhaps his own mother summed him up when "explaining to those who regarded him as cold and overserious that he could be jolly, that he took things to heart, that he felt deeply and sincerely and was more sensitive than he cared to show." Whatever his true character, he ascended a precarious throne, and either by political wisdom and guile, or through accident and indifference, he left it secure in the hands of the Hanoverians and of Parliament.


As King his arms were: Quarterly, I, Gules three lions passant guardant in pale Or (for England) impaling Or a lion rampant within a tressure flory-counter-flory Gules (for Scotland); II, Azure three fleurs-de-lis Or (for France); III, Azure a harp Or stringed Argent (for Ireland); IV, tierced per pale and per chevron (for Hanover), I Gules two lions passant guardant Or (for Brunswick), II Or a semy of hearts Gules a lion rampant Azure (for Lüneburg), III Gules a horse courant Argent (for Westphalia), overall an escutcheon Gules charged with the crown of Charlemagne Or (for the dignity of Archtreasurer of the Holy Roman Empire).





</doc>
<doc id="47263" url="https://en.wikipedia.org/wiki?curid=47263" title="243 Ida">
243 Ida

Ida (; minor planet designation: 243 Ida) is an asteroid in the Koronis family of the asteroid belt. It was discovered on 29 September 1884 by Austrian astronomer Johann Palisa at Vienna Observatory and named after a nymph from Greek mythology. Later telescopic observations categorized Ida as an S-type asteroid, the most numerous type in the inner asteroid belt. On 28 August 1993, Ida was visited by the unmanned "Galileo" spacecraft while en route to Jupiter. It was the second asteroid visited by a spacecraft and the first found to have a natural satellite.

Ida's orbit lies between the planets Mars and Jupiter, like all main-belt asteroids. Its orbital period is 4.84 years, and its rotation period is 4.63 hours. Ida has an average diameter of . It is irregularly shaped and elongated, apparently composed of two large objects connected together. Its surface is one of the most heavily cratered in the Solar System, featuring a wide variety of crater sizes and ages.

Ida's moon Dactyl was discovered by mission member Ann Harch in images returned from "Galileo". It was named after the Dactyls, creatures which inhabited Mount Ida in Greek mythology. Dactyl is only in diameter, about 1/20 the size of Ida. Its orbit around Ida could not be determined with much accuracy, but the constraints of possible orbits allowed a rough determination of Ida's density and revealed that it is depleted of metallic minerals. Dactyl and Ida share many characteristics, suggesting a common origin.

The images returned from "Galileo" and the subsequent measurement of Ida's mass provided new insights into the geology of S-type asteroids. Before the "Galileo" flyby, many different theories had been proposed to explain their mineral composition. Determining their composition permits a correlation between meteorites falling to the Earth and their origin in the asteroid belt. Data returned from the flyby pointed to S-type asteroids as the source for the ordinary chondrite meteorites, the most common type found on the Earth's surface.

Ida was discovered on 29 September 1884 by Austrian astronomer Johann Palisa at the Vienna Observatory. It was his 45th asteroid discovery. Ida was named by Moriz von Kuffner, a Viennese brewer and amateur astronomer. In Greek mythology, Ida was a nymph of Crete who raised the god Zeus. Ida was recognized as a member of the Koronis family by Kiyotsugu Hirayama, who proposed in 1918 that the group comprised the remnants of a destroyed precursor body.

Ida's reflection spectrum was measured on 16 September 1980 by astronomers David J. Tholen and Edward F. Tedesco as part of the eight-color asteroid survey (ECAS). Its spectrum matched those of the asteroids in the S-type classification. Many observations of Ida were made in early 1993 by the US Naval Observatory in Flagstaff and the Oak Ridge Observatory. These improved the measurement of Ida's orbit around the Sun and reduced the uncertainty of its position during the "Galileo" flyby from .

Ida was visited in 1993 by the Jupiter-bound space probe "Galileo". Its encounters of the asteroids Gaspra and Ida were secondary to the Jupiter mission. These were selected as targets in response to a new NASA policy directing mission planners to consider asteroid flybys for all spacecraft crossing the belt. No prior missions had attempted such a flyby. "Galileo" was launched into orbit by the Space Shuttle "Atlantis" mission STS-34 on 18 October 1989. Changing "Galileo's" trajectory to approach Ida required that it consume of propellant. Mission planners delayed the decision to attempt a flyby until they were certain that this would leave the spacecraft enough propellant to complete its Jupiter mission.
"Galileo's" trajectory carried it into the asteroid belt twice on its way to Jupiter. During its second crossing, it flew by Ida on 28 August 1993 at a speed of relative to the asteroid. The onboard imager observed Ida from a distance of to its closest approach of . Ida was the second asteroid, after Gaspra, to be imaged by a spacecraft. About 95% of Ida's surface came into view of the probe during the flyby.

Transmission of many Ida images was delayed due to a permanent failure in the spacecraft's high-gain antenna. The first five images were received in September 1993. These comprised a high-resolution mosaic of the asteroid at a resolution of 31–38 m/pixel. The remaining images were sent in February 1994, when the spacecraft's proximity to the Earth allowed higher speed transmissions.

The data returned from the "Galileo" flybys of Gaspra and Ida, and the later "NEAR Shoemaker" asteroid mission, permitted the first study of asteroid geology. Ida's relatively large surface exhibited a diverse range of geological features. The discovery of Ida's moon Dactyl, the first confirmed satellite of an asteroid, provided additional insights into Ida's composition.

Ida is classified as an S-type asteroid based on ground-based spectroscopic measurements. The composition of S-types was uncertain before the "Galileo" flybys, but was interpreted to be either of two minerals found in meteorites that had fallen to the Earth: ordinary chondrite (OC) and stony-iron. Estimates of Ida's density are constrained to less than 3.2 g/cm by the long-term stability of Dactyl's orbit. This all but rules out a stony-iron composition; were Ida made of 5 g/cm iron- and nickel-rich material, it would have to contain more than 40% empty space.

The Galileo images also led to the discovery that space weathering was taking place on Ida, a process which causes older regions to become more red in color over time. The same process affects both Ida and its moon, although Dactyl shows a lesser change. The weathering of Ida's surface revealed another detail about its composition: the reflection spectra of freshly exposed parts of the surface resembled that of OC meteorites, but the older regions matched the spectra of S-type asteroids.
Both of these discoveries—the space weathering effects and the low density—led to a new understanding about the relationship between S-type asteroids and OC meteorites. S-types are the most numerous kind of asteroid in the inner part of the asteroid belt. OC meteorites are, likewise, the most common type of meteorite found on the Earth's surface. The reflection spectra measured by remote observations of S-type asteroids, however, did not match that of OC meteorites. The "Galileo" flyby of Ida found that some S-types, particularly the Koronis family, could be the source of these meteorites.

Ida's mass is between 3.65 and 4.99 × 10 kg. Its gravitational field produces an acceleration of about 0.3 to 1.1 cm/s over its surface. This field is so weak that an astronaut standing on its surface could leap from one end of Ida to the other, and an object moving in excess of could escape the asteroid entirely.
Ida is a distinctly elongated asteroid, with an irregular surface. Ida is 2.35 times as long as it is wide, and a "waist" separates it into two geologically dissimilar halves. This constricted shape is consistent with Ida being made of two large, solid components, with loose debris filling the gap between them. However, no such debris was seen in high-resolution images captured by "Galileo". Although there are a few steep slopes tilting up to about 50° on Ida, the slope generally does not exceed 35°. Ida's irregular shape is responsible for the asteroid's very uneven gravitational field. The surface acceleration is lowest at the extremities because of their high rotational speed. It is also low near the "waist" because the mass of the asteroid is concentrated in the two halves, away from this location.
Ida's surface appears heavily cratered and mostly gray, although minor color variations mark newly formed or uncovered areas. Besides craters, other features are evident, such as grooves, ridges, and protrusions. Ida is covered by a thick layer of regolith, loose debris that obscures the solid rock beneath. The largest, boulder-sized, debris fragments are called "ejecta blocks", several of which have been observed on the surface.

The surface of Ida is covered in a blanket of pulverized rock, called "regolith", about thick. This material is produced in impact events and redistributed across Ida's surface by geological processes. "Galileo" observed evidence of recent downslope regolith movement.

Ida's regolith is composed of the silicate minerals olivine and pyroxene. Its appearance changes over time through a process called space weathering. Because of this process, older regolith appears more red in color compared to freshly exposed material.
About 20 large (40–150 m across) ejecta blocks have been identified, embedded in Ida's regolith. Ejecta blocks constitute the largest pieces of the regolith. Because ejecta blocks are expected to break down quickly by impact events, those present on the surface must have been either formed recently or uncovered by an impact event. Most of them are located within the craters Lascaux and Mammoth, but they may not have been produced there. This area attracts debris due to Ida's irregular gravitational field. Some blocks may have been ejected from the young crater Azzurra on the opposite side of the asteroid.

Several major structures mark Ida's surface. The asteroid appears to be split into two halves, here referred to as "region 1" and "region 2", connected by a "waist". This feature may have been filled in by debris, or blasted out of the asteroid by impacts.

Region 1 of Ida contains two major structures. One is a prominent ridge named "Townsend Dorsum" that stretches 150 degrees around Ida's surface. The other structure is a large indentation named "Vienna Regio".

Ida's region 2 features several sets of grooves, most of which are wide or less and up to long. They are located near, but are not connected with, the craters Mammoth, Lascaux, and Kartchner. Some grooves are related to major impact events, for example a set opposite Vienna Regio.

Ida is one of the most densely cratered bodies yet explored in the Solar System, and impacts have been the primary process shaping its surface. Cratering has reached the saturation point, meaning that new impacts erase evidence of old ones, leaving the total crater count roughly the same. It is covered with craters of all sizes and stages of degradation, and ranging in age from fresh to as old as Ida itself. The oldest may have been formed during the breakup of the Koronis family parent body. The largest crater, Lascaux, is almost across. Region 2 contains nearly all of the craters larger than in diameter, but Region 1 has no large craters at all. Some craters are arranged in chains.

Ida's major craters are named after caves and lava tubes on Earth. The crater Azzurra, for example, is named after a submerged cave on the island of Capri, also known as the "Blue Grotto". Azzurra seems to be the most recent major impact on Ida. The ejecta from this collision is distributed discontinuously over Ida and is responsible for the large-scale color and albedo variations across its surface. An exception to the crater morphology is the fresh, asymmetric Fingal, which has a sharp boundary between the floor and wall on one side. Another significant crater is Afon, which marks Ida's prime meridian.

The craters are simple in structure: bowl-shaped with no flat bottoms and no central peaks. They are distributed evenly around Ida, except for a protrusion north of crater Choukoutien which is smoother and less cratered. The ejecta excavated by impacts is deposited differently on Ida than on planets because of its rapid rotation, low gravity and irregular shape. Ejecta blankets settle asymmetrically around their craters, but fast-moving ejecta that escapes from the asteroid is permanently lost.

Ida was classified as an S-type asteroid based on the similarity of its reflectance spectra with similar asteroids. S-types may share their composition with stony-iron or ordinary chondrite (OC) meteorites. The composition of the interior has not been directly analyzed, but is assumed to be similar to OC material based on observed surface color changes and Ida's bulk density of 2.27–3.10 g/cm. OC meteorites contain varying amounts of the silicates olivine and pyroxene, iron, and feldspar. Olivine and pyroxene were detected on Ida by "Galileo". The mineral content appears to be homogeneous throughout its extent. "Galileo" found minimal variations on the surface, and the asteroid's spin indicates a consistent density. Assuming that its composition is similar to OC meteorites, which range in density from 3.48 to 3.64 g/cm, Ida would have a porosity of 11–42%.

Ida's interior probably contains some amount of impact-fractured rock, called "megaregolith". The megaregolith layer of Ida extends between hundreds of meters below the surface to a few kilometers. Some rock in Ida's core may have been fractured below the large craters Mammoth, Lascaux, and Undara.

Ida is a member of the Koronis family of asteroid-belt asteroids. Ida orbits the Sun at an average distance of , between the orbits of Mars and Jupiter. Ida takes 4.84089 years to complete one orbit.

Ida's rotation period is 4.63 hours, making it one of the fastest rotating asteroids yet discovered. The calculated maximum moment of inertia of a uniformly dense object the same shape as Ida coincides with the spin axis of the asteroid. This suggests that there are no major variations of density within the asteroid. Ida's axis of rotation precesses with a period of 77 thousand years, due to the gravity of the Sun acting upon the nonspherical shape of the asteroid.

Ida originated in the breakup of the roughly diameter Koronis parent body. The progenitor asteroid had partially differentiated, with heavier metals migrating to the core. Ida carried away insignificant amounts of this core material. It is uncertain how long ago the disruption event occurred. According to an analysis of Ida's cratering processes, its surface is more than a billion years old. However, this is inconsistent with the estimated age of the Ida–Dactyl system of less than 100 million years; it is unlikely that Dactyl, due to its small size, could have escaped being destroyed in a major collision for longer. The difference in age estimates may be explained by an increased rate of cratering from the debris of the Koronis parent body's destruction.

Ida has a moon named Dactyl, official designation (243) Ida I Dactyl ( ). It was discovered in images taken by the "Galileo" spacecraft during its flyby in 1993. These images provided the first direct confirmation of an asteroid moon. At the time, it was separated from Ida by a distance of , moving in a prograde orbit. Dactyl is heavily cratered, like Ida, and consists of similar materials. Its origin is uncertain, but evidence from the flyby suggests that it originated as a fragment of the Koronis parent body.

Dactyl was found on 17 February 1994 by "Galileo" mission member Ann Harch, while examining delayed image downloads from the spacecraft. "Galileo" recorded 47 images of Dactyl over an observation period of 5.5 hours in August 1993. The spacecraft was from Ida and from Dactyl when the first image of the moon was captured, 14 minutes before "Galileo" made its closest approach.

Dactyl was initially designated 1993 (243) 1. It was named by the International Astronomical Union in 1994, for the mythological dactyls who inhabited Mount Ida on the island of Crete.

Dactyl is an "egg-shaped" but "remarkably spherical" object measuring 1.6 by 1.4 by 1.2 kilometres (0.99 mi × 0.87 mi × 0.75 mi). It was oriented with its longest axis pointing towards Ida. Like Ida, Dactyl's surface exhibits saturation cratering. It is marked by more than a dozen craters with a diameter greater than , indicating that the moon has suffered many collisions during its history. At least six craters form a linear chain, suggesting that it was caused by locally produced debris, possibly ejected from Ida. Dactyl's craters may contain central peaks, unlike those found on Ida. These features, and Dactyl's spheroidal shape, imply that the moon is gravitationally controlled despite its small size. Like Ida, its average temperature is about .

Dactyl shares many characteristics with Ida. Their albedos and reflection spectra are very similar. The small differences indicate that the space weathering process is less active on Dactyl. Its small size would make the formation of significant amounts of regolith impossible. This contrasts with Ida, which is covered by a deep layer of regolith.

The two largest imaged craters on Dactyl were named Acmon and Celmis, after two of the mythological dactyls. Acmon is the largest crater in the above image, and Celmis is near the bottom, mostly obscured in shadow. The craters are 300 and 200 meters in diameter, respectively.

Dactyl's orbit around Ida is not precisely known. "Galileo" was in the plane of Dactyl's orbit when most of the images were taken, which made determining its exact orbit difficult. Dactyl orbits in the prograde direction and is inclined about 8° to Ida's equator. Based on computer simulations, Dactyl's pericenter must be more than about from Ida for it to remain in a stable orbit. The range of orbits generated by the simulations was narrowed down by the necessity of having the orbits pass through points at which "Galileo" observed Dactyl to be at 16:52:05 UT on 28 August 1993, about from Ida at longitude 85°. On 26 April 1994, the Hubble Space Telescope observed Ida for eight hours and was unable to spot Dactyl. It would have been able to observe it if it were more than about from Ida.

If in a circular orbit at the distance at which it was seen, Dactyl's orbital period would be about 20 hours. Its orbital speed is roughly , "about the speed of a fast run or a slowly thrown baseball".

Dactyl may have originated at the same time as Ida, from the disruption of the Koronis parent body. However, it may have formed more recently, perhaps as ejecta from a large impact on Ida. It is extremely unlikely that it was captured by Ida. Dactyl may have suffered a major impact around 100 million years ago, which reduced its size.


Journal articles

Books

Other



</doc>
<doc id="47264" url="https://en.wikipedia.org/wiki?curid=47264" title="Asteroid belt">
Asteroid belt

The asteroid belt is the circumstellar disc in the Solar System located roughly between the orbits of the planets Mars and Jupiter. It is occupied by numerous irregularly shaped bodies called asteroids or minor planets. The asteroid belt is also termed the main asteroid belt or main belt to distinguish it from other asteroid populations in the Solar System such as near-Earth asteroids and trojan asteroids. About half the mass of the belt is contained in the four largest asteroids: Ceres, Vesta, Pallas, and Hygiea. The total mass of the asteroid belt is approximately 4% that of the Moon, or 22% that of Pluto, and roughly twice that of Pluto's moon Charon (whose diameter is 1200 km).

Ceres, the asteroid belt's only dwarf planet, is about 950 km in diameter, whereas 4 Vesta, 2 Pallas, and 10 Hygiea have mean diameters of less than 600 km. The remaining bodies range down to the size of a dust particle. The asteroid material is so thinly distributed that numerous unmanned spacecraft have traversed it without incident. Nonetheless, collisions between large asteroids do occur, and these can produce an asteroid family whose members have similar orbital characteristics and compositions. Individual asteroids within the asteroid belt are categorized by their spectra, with most falling into three basic groups: carbonaceous (C-type), silicate (S-type), and metal-rich (M-type).

The asteroid belt formed from the primordial solar nebula as a group of planetesimals. Planetesimals are the smaller precursors of the protoplanets. Between Mars and Jupiter, however, gravitational perturbations from Jupiter imbued the protoplanets with too much orbital energy for them to accrete into a planet. Collisions became too violent, and instead of fusing together, the planetesimals and most of the protoplanets shattered. As a result, 99.9% of the asteroid belt's original mass was lost in the first 100 million years of the Solar System's history. Some fragments eventually found their way into the inner Solar System, leading to meteorite impacts with the inner planets. Asteroid orbits continue to be appreciably perturbed whenever their period of revolution about the Sun forms an orbital resonance with Jupiter. At these orbital distances, a Kirkwood gap occurs as they are swept into other orbits.

Classes of small Solar System bodies in other regions are the near-Earth objects, the centaurs, the Kuiper belt objects, the scattered disc objects, the sednoids, and the Oort cloud objects.

On 22 January 2014, ESA scientists reported the detection, for the first definitive time, of water vapor on Ceres, the largest object in the asteroid belt. The detection was made by using the far-infrared abilities of the Herschel Space Observatory. The finding was unexpected because comets, not asteroids, are typically considered to "sprout jets and plumes". According to one of the scientists, "The lines are becoming more and more blurred between comets and asteroids."

In 1596, Johannes Kepler predicted “Between Mars and Jupiter, I place a planet” in his "Mysterium Cosmographicum". While analyzing Tycho Brahe's data, Kepler thought that there was too large a gap between the orbits of Mars and Jupiter.

In an anonymous footnote to his 1766 translation of Charles Bonnet's "Contemplation de la Nature", the astronomer Johann Daniel Titius of Wittenberg noted an apparent pattern in the layout of the planets. If one began a numerical sequence at 0, then included 3, 6, 12, 24, 48, etc., doubling each time, and added four to each number and divided by 10, this produced a remarkably close approximation to the radii of the orbits of the known planets as measured in astronomical units "provided" one allowed for a "missing planet" (equivalent to 24 in the sequence) between the orbits of Mars (12) and Jupiter (48). In his footnote, Titius declared "But should the Lord Architect have left that space empty? Not at all."

When William Herschel discovered Uranus in 1781, the planet's orbit matched the law almost perfectly, leading astronomers to conclude that there had to be a planet between the orbits of Mars and Jupiter.

On January 1, 1801, Giuseppe Piazzi, chair of astronomy at the University of Palermo, Sicily, found a tiny moving object in an orbit with exactly the radius predicted by this pattern. He dubbed it "Ceres", after the Roman goddess of the harvest and patron of Sicily. Piazzi initially believed it to be a comet, but its lack of a coma suggested it was a planet.

Thus, the aforementioned pattern, now known as the Titius–Bode law, predicted the semi-major axes of all eight planets of the time (Mercury, Venus, Earth, Mars, Ceres, Jupiter, Saturn and Uranus).

Fifteen months later, Heinrich Olbers discovered a second object in the same region, Pallas. Unlike the other known planets, Ceres and Pallas remained points of light even under the highest telescope magnifications instead of resolving into discs. Apart from their rapid movement, they appeared indistinguishable from stars.

Accordingly, in 1802, William Herschel suggested they be placed into a separate category, named "asteroids", after the Greek "asteroeides", meaning "star-like". Upon completing a series of observations of Ceres and Pallas, he concluded,

Neither the appellation of planets nor that of comets, can with any propriety of language be given to these two stars ... They resemble small stars so much as hardly to be distinguished from them. From this, their asteroidal appearance, if I take my name, and call them Asteroids; reserving for myself, however, the liberty of changing that name, if another, more expressive of their nature, should occur.
By 1807, further investigation revealed two new objects in the region: Juno and Vesta. The burning of Lilienthal in the Napoleonic wars, where the main body of work had been done, brought this first period of discovery to a close.

Despite Herschel's coinage, for several decades it remained common practice to refer to these objects as planets and to prefix their names with numbers representing their date of discovery: 1 Ceres, 2 Pallas, 3 Juno, 4 Vesta. However, in 1845 astronomers detected a fifth object (5 Astraea) and, shortly thereafter, new objects were found at an accelerating rate. Counting them among the planets became increasingly cumbersome. Eventually, they were dropped from the planet list (as first suggested by Alexander von Humboldt in the early 1850s) and Herschel's choice of nomenclature, "asteroids", gradually came into common use.

The discovery of Neptune in 1846 led to the discrediting of the Titius–Bode law in the eyes of scientists because its orbit was nowhere near the predicted position. To date, there is no scientific explanation for the law, and astronomers' consensus regards it as a coincidence.

The expression "asteroid belt" came into use in the very early 1850s, although it is hard to pinpoint who coined the term. The first English use seems to be in the 1850 translation (by E. C. Otté) of Alexander von Humboldt's "Cosmos": "[...] and the regular appearance, about the 13th of November and the 11th of August, of shooting stars, which probably form part of a belt of asteroids intersecting the Earth's orbit and moving with planetary velocity". Another early appearance occurred in Robert James Mann's "A Guide to the Knowledge of the Heavens": "The orbits of the asteroids are placed in a wide belt of space, extending between the extremes of [...]". The American astronomer Benjamin Peirce seems to have adopted that terminology and to have been one of its promoters.

One hundred asteroids had been located by mid-1868, and in 1891 the introduction of astrophotography by Max Wolf accelerated the rate of discovery still further. A total of 1,000 asteroids had been found by 1921, 10,000 by 1981, and 100,000 by 2000. Modern asteroid survey systems now use automated means to locate new minor planets in ever-increasing quantities.

In 1802, shortly after discovering Pallas, Olbers suggested to Herschel that Ceres and Pallas were fragments of a much larger planet that once occupied the Mars–Jupiter region, this planet having suffered an internal explosion or a cometary impact many million years before. The large amount of energy required to destroy a planet, combined with the belt's low combined mass, which is only about 4% of the mass of the Moon, do not support the hypothesis. Further, the significant chemical differences between the asteroids become difficult to explain if they come from the same planet. As of 2018, a study was released from researchers at the University of Florida that found the asteroid belt was created from the remnants of several ancient planets instead of a singular planet.

A hypothesis to the asteroid belt creation is that in general, in the Solar System, a planetary formation is thought to have occurred via a process comparable to the long-standing nebular hypothesis: a cloud of interstellar dust and gas collapsed under the influence of gravity to form a rotating disc of material that then further condensed to form the Sun and planets. During the first few million years of the Solar System's history, an accretion process of sticky collisions caused the clumping of small particles, which gradually increased in size. Once the clumps reached sufficient mass, they could draw in other bodies through gravitational attraction and become planetesimals. This gravitational accretion led to the formation of the planets.

Planetesimals within the region which would become the asteroid belt were too strongly perturbed by Jupiter's gravity to form a planet. Instead, they continued to orbit the Sun as before, occasionally colliding. In regions where the average velocity of the collisions was too high, the shattering of planetesimals tended to dominate over accretion, preventing the formation of planet-sized bodies. Orbital resonances occurred where the orbital period of an object in the belt formed an integer fraction of the orbital period of Jupiter, perturbing the object into a different orbit; the region lying between the orbits of Mars and Jupiter contains many such orbital resonances. As Jupiter migrated inward following its formation, these resonances would have swept across the asteroid belt, dynamically exciting the region's population and increasing their velocities relative to each other.

During the early history of the Solar System, the asteroids melted to some degree, allowing elements within them to be partially or completely differentiated by mass. Some of the progenitor bodies may even have undergone periods of explosive volcanism and formed magma oceans. However, because of the relatively small size of the bodies, the period of melting was necessarily brief (compared to the much larger planets), and had generally ended about 4.5 billion years ago, in the first tens of millions of years of formation. In August 2007, a study of zircon crystals in an Antarctic meteorite believed to have originated from Vesta suggested that it, and by extension the rest of the asteroid belt, had formed rather quickly, within 10 million years of the Solar System's origin.

The asteroids are not samples of the primordial Solar System. They have undergone considerable evolution since their formation, including internal heating (in the first few tens of millions of years), surface melting from impacts, space weathering from radiation, and bombardment by micrometeorites. Although some scientists refer to the asteroids as residual planetesimals, other scientists consider them distinct.

The current asteroid belt is believed to contain only a small fraction of the mass of the primordial belt. Computer simulations suggest that the original asteroid belt may have contained the mass equivalent to the Earth. Primarily because of gravitational perturbations, most of the material was ejected from the belt within about 1 million years of formation, leaving behind less than 0.1% of the original mass. Since their formation, the size distribution of the asteroid belt has remained relatively stable: there has been no significant increase or decrease in the typical dimensions of the main-belt asteroids.

The 4:1 orbital resonance with Jupiter, at a radius 2.06 AU, can be considered the inner boundary of the asteroid belt. Perturbations by Jupiter send bodies straying there into unstable orbits. Most bodies formed within the radius of this gap were swept up by Mars (which has an aphelion at 1.67 AU) or ejected by its gravitational perturbations in the early history of the Solar System. The Hungaria asteroids lie closer to the Sun than the 4:1 resonance, but are protected from disruption by their high inclination.

When the asteroid belt was first formed, the temperatures at a distance of 2.7 AU from the Sun formed a "snow line" below the freezing point of water. Planetesimals formed beyond this radius were able to accumulate ice.
In 2006 it was announced that a population of comets had been discovered within the asteroid belt beyond the snow line, which may have provided a source of water for Earth's oceans. According to some models, there was insufficient outgassing of water during the Earth's formative period to form the oceans, requiring an external source such as a cometary bombardment.

Contrary to popular imagery, the asteroid belt is mostly empty. The asteroids are spread over such a large volume that it would be improbable to reach an asteroid without aiming carefully. Nonetheless, hundreds of thousands of asteroids are currently known, and the total number ranges in the millions or more, depending on the lower size cutoff. Over 200 asteroids are known to be larger than 100 km, and a survey in the infrared wavelengths has shown that the asteroid belt has between 700,000 and 1.7 million asteroids with a diameter of 1 km or more. The apparent magnitudes of most of the known asteroids are between 11 and 19, with the median at about 16.

The total mass of the asteroid belt is estimated to be between and kilograms, which is just 4% of the mass of the Moon. The four largest objects, Ceres, 4 Vesta, 2 Pallas, and 10 Hygiea, account for half of the belt's total mass, with almost one-third accounted for by Ceres alone.

The current belt consists primarily of three categories of asteroids: C-type or carbonaceous asteroids, S-type or silicate asteroids, and M-type or metallic asteroids.

Carbonaceous asteroids, as their name suggests, are carbon-rich. They dominate the asteroid belt's outer regions. Together they comprise over 75% of the visible asteroids. They are redder in hue than the other asteroids and have a very low albedo. Their surface composition is similar to carbonaceous chondrite meteorites. Chemically, their spectra match the primordial composition of the early Solar System, with only the lighter elements and volatiles removed.

S-type (silicate-rich) asteroids are more common toward the inner region of the belt, within 2.5 AU of the Sun. The spectra of their surfaces reveal the presence of silicates and some metal, but no significant carbonaceous compounds. This indicates that their materials have been significantly modified from their primordial composition, probably through melting and reformation. They have a relatively high albedo and form about 17% of the total asteroid population.

M-type (metal-rich) asteroids form about 10% of the total population; their spectra resemble that of iron-nickel. Some are believed to have formed from the metallic cores of differentiated progenitor bodies that were disrupted through collision. However, there are also some silicate compounds that can produce a similar appearance. For example, the large M-type asteroid 22 Kalliope does not appear to be primarily composed of metal. Within the asteroid belt, the number distribution of M-type asteroids peaks at a semi-major axis of about 2.7 AU. It is not yet clear whether all M-types are compositionally similar, or whether it is a label for several varieties which do not fit neatly into the main C and S classes.

One mystery of the asteroid belt is the relative rarity of V-type or basaltic asteroids. Theories of asteroid formation predict that objects the size of Vesta or larger should form crusts and mantles, which would be composed mainly of basaltic rock, resulting in more than half of all asteroids being composed either of basalt or olivine. Observations, however, suggest that 99 percent of the predicted basaltic material is missing. Until 2001, most basaltic bodies discovered in the asteroid belt were believed to originate from the asteroid Vesta (hence their name V-type). However, the discovery of the asteroid 1459 Magnya revealed a slightly different chemical composition from the other basaltic asteroids discovered until then, suggesting a different origin. This hypothesis was reinforced by the further discovery in 2007 of two asteroids in the outer belt, 7472 Kumakiri and , with a differing basaltic composition that could not have originated from Vesta. These latter two are the only V-type asteroids discovered in the outer belt to date.

The temperature of the asteroid belt varies with the distance from the Sun. For dust particles within the belt, typical temperatures range from 200 K (−73 °C) at 2.2 AU down to 165 K (−108 °C) at 3.2 AU However, due to rotation, the surface temperature of an asteroid can vary considerably as the sides are alternately exposed to solar radiation and then to the stellar background.

Several otherwise unremarkable bodies in the outer belt show cometary activity. Because their orbits cannot be explained through the capture of classical comets, it is thought that many of the outer asteroids may be icy, with the ice occasionally exposed to sublimation through small impacts. Main-belt comets may have been a major source of the Earth's oceans because the deuterium-hydrogen ratio is too low for classical comets to have been the principal source.

Most asteroids within the asteroid belt have orbital eccentricities of less than 0.4, and an inclination of less than 30°. The orbital distribution of the asteroids reaches a maximum at an eccentricity of around 0.07 and an inclination below 4°. Thus although a typical asteroid has a relatively circular orbit and lies near the plane of the ecliptic, some asteroid orbits can be highly eccentric or travel well outside the ecliptic plane.

Sometimes, the term "main belt" is used to refer only to the more compact "core" region where the greatest concentration of bodies is found. This lies between the strong 4:1 and 2:1 Kirkwood gaps at 2.06 and 3.27 AU, and at orbital eccentricities less than roughly 0.33, along with orbital inclinations below about 20°. , this "core" region contained 93% of all discovered and numbered minor planets within the Solar System. The JPL Small-Body Database lists over 670,000 known main belt asteroids.

The semi-major axis of an asteroid is used to describe the dimensions of its orbit around the Sun, and its value determines the minor planet's orbital period. In 1866, Daniel Kirkwood announced the discovery of gaps in the distances of these bodies' orbits from the Sun. They were located in positions where their period of revolution about the Sun was an integer fraction of Jupiter's orbital period. Kirkwood proposed that the gravitational perturbations of the planet led to the removal of asteroids from these orbits.

When the mean orbital period of an asteroid is an integer fraction of the orbital period of Jupiter, a mean-motion resonance with the gas giant is created that is sufficient to perturb an asteroid to new orbital elements. Asteroids that become located in the gap orbits (either primordially because of the migration of Jupiter's orbit, or due to prior perturbations or collisions) are gradually nudged into different, random orbits with a larger or smaller semi-major axis.

The gaps are not seen in a simple snapshot of the locations of the asteroids at any one time because asteroid orbits are elliptical, and many asteroids still cross through the radii corresponding to the gaps. The actual spatial density of asteroids in these gaps does not differ significantly from the neighboring regions.

The main gaps occur at the 3:1, 5:2, 7:3, and 2:1 mean-motion resonances with Jupiter. An asteroid in the 3:1 Kirkwood gap would orbit the Sun three times for each Jovian orbit, for instance. Weaker resonances occur at other semi-major axis values, with fewer asteroids found than nearby. (For example, an 8:3 resonance for asteroids with a semi-major axis of 2.71 AU.)

The main or core population of the asteroid belt is sometimes divided into three zones, based on the most prominent Kirkwood gaps:

The asteroid belt may also be divided into the inner and outer belts, with the inner belt formed by asteroids orbiting nearer to Mars than the 3:1 Kirkwood gap (2.5 AU), and the outer belt formed by those asteroids closer to Jupiter's orbit. (Some authors subdivide the inner and outer belts at the 2:1 resonance gap (3.3 AU), whereas others suggest inner, middle, and outer belts; also see diagram).

The high population of the asteroid belt makes for a very active environment, where collisions between asteroids occur frequently (on astronomical time scales). Collisions between main-belt bodies with a mean radius of 10 km are expected to occur about once every 10 million years. A collision may fragment an asteroid into numerous smaller pieces (leading to the formation of a new asteroid family). Conversely, collisions that occur at low relative speeds may also join two asteroids. After more than 4 billion years of such processes, the members of the asteroid belt now bear little resemblance to the original population.

Along with the asteroid bodies, the asteroid belt also contains bands of dust with particle radii of up to a few hundred micrometres. This fine material is produced, at least in part, from collisions between asteroids, and by the impact of micrometeorites upon the asteroids. Due to the Poynting–Robertson effect, the pressure of solar radiation causes this dust to slowly spiral inward toward the Sun.

The combination of this fine asteroid dust, as well as ejected cometary material, produces the zodiacal light. This faint auroral glow can be viewed at night extending from the direction of the Sun along the plane of the ecliptic. Asteroid particles that produce the visible zodiacal light average about 40 μm in radius. The typical lifetimes of main-belt zodiacal cloud particles are about 700,000 years. Thus, to maintain the bands of dust, new particles must be steadily produced within the asteroid belt. It was once thought that collisions of asteroids form a major component of the zodiacal light. However, computer simulations by Nesvorný and colleagues attributed 85 percent of the zodiacal-light dust to fragmentations of Jupiter-family comets, rather than to comets and collisions between asteroids in the asteroid belt. At most 10 percent of the dust is attributed to the asteroid belt.

Some of the debris from collisions can form meteoroids that enter the Earth's atmosphere. Of the 50,000 meteorites found on Earth to date, 99.8 percent are believed to have originated in the asteroid belt.

In 1918, the Japanese astronomer Kiyotsugu Hirayama noticed that the orbits of some of the asteroids had similar parameters, forming families or groups.

Approximately one-third of the asteroids in the asteroid belt are members of an asteroid family. These share similar orbital elements, such as semi-major axis, eccentricity, and orbital inclination as well as similar spectral features, all of which indicate a common origin in the breakup of a larger body. Graphical displays of these elements, for members of the asteroid belt, show concentrations indicating the presence of an asteroid family. There are about 20 to 30 associations that are almost certainly asteroid families. Additional groupings have been found that are less certain. Asteroid families can be confirmed when the members display common spectral features. Smaller associations of asteroids are called groups or clusters.

Some of the most prominent families in the asteroid belt (in order of increasing semi-major axes) are the Flora, Eunoma, Koronis, Eos, and Themis families. The Flora family, one of the largest with more than 800 known members, may have formed from a collision less than 1 billion years ago.
The largest asteroid to be a true member of a family (as opposed to an interloper in the case of Ceres with the Gefion family) is 4 Vesta. The Vesta family is believed to have formed as the result of a crater-forming impact on Vesta. Likewise, the HED meteorites may also have originated from Vesta as a result of this collision.

Three prominent bands of dust have been found within the asteroid belt. These have similar orbital inclinations as the Eos, Koronis, and Themis asteroid families, and so are possibly associated with those groupings.

The main belt evolution after the Late Heavy Bombardment was very likely affected by the passages of large Centaurs and trans-Neptunian objects (TNOs).
Centaurs and TNOs that reach the inner Solar System can modify the orbits of main belt asteroids, though only if their mass is of the order of for single encounters or, one order less in case of multiple close encounters.
However Centaurs and TNOs are unlikely to have significantly dispersed young asteroid families in the main belt, but they can have perturbed some old asteroid families. Current main belt asteroids that originated as Centaurs or trans-Neptunian objects may lie in the outer belt with short lifetime of less than 4 million years, most likely between 2.8 and 3.2 AU at larger eccentricities than typical of main belt asteroid.

Skirting the inner edge of the belt (ranging between 1.78 and 2.0 AU, with a mean semi-major axis of 1.9 AU) is the Hungaria family of minor planets. They are named after the main member, 434 Hungaria; the group contains at least 52 named asteroids. The Hungaria group is separated from the main body by the 4:1 Kirkwood gap and their orbits have a high inclination. Some members belong to the Mars-crossing category of asteroids, and gravitational perturbations by Mars are likely a factor in reducing the total population of this group.

Another high-inclination group in the inner part of the asteroid belt is the Phocaea family. These are composed primarily of S-type asteroids, whereas the neighboring Hungaria family includes some E-types. The Phocaea family orbit between 2.25 and 2.5 AU from the Sun.

Skirting the outer edge of the asteroid belt is the Cybele group, orbiting between 3.3 and 3.5 AU. These have a 7:4 orbital resonance with Jupiter. The Hilda family orbit between 3.5 and 4.2 AU, and have relatively circular orbits and a stable 3:2 orbital resonance with Jupiter. There are few asteroids beyond 4.2 AU, until Jupiter's orbit. Here the two families of Trojan asteroids can be found, which, at least for objects larger than 1 km, are approximately as numerous as the asteroids of the asteroid belt.

Some asteroid families have formed recently, in astronomical terms. The Karin Cluster apparently formed about 5.7 million years ago from a collision with a progenitor asteroid 33 km in radius. The Veritas family formed about 8.3 million years ago; evidence includes interplanetary dust recovered from ocean sediment.

More recently, the Datura cluster appears to have formed about 530,000 years ago from a collision with a main-belt asteroid. The age estimate is based on the probability of the members having their current orbits, rather than from any physical evidence. However, this cluster may have been a source for some zodiacal dust material. Other recent cluster formations, such as the Iannini cluster ( million years ago), may have provided additional sources of this asteroid dust.

The first spacecraft to traverse the asteroid belt was "Pioneer 10", which entered the region on 16 July 1972. At the time there was some concern that the debris in the belt would pose a hazard to the spacecraft, but it has since been safely traversed by 12 spacecrafts without incident. "Pioneer 11", "Voyagers 1" and "2" and "Ulysses" passed through the belt without imaging any asteroids. "Galileo" imaged 951 Gaspra in 1991 and 243 Ida in 1993, NEAR imaged 253 Mathilde in 1997 and landed on 433 Eros in February 2001, "Cassini" imaged 2685 Masursky in 2000, "Stardust" imaged 5535 Annefrank in 2002, "New Horizons" imaged 132524 APL in 2006, "Rosetta" imaged 2867 Šteins in September 2008 and 21 Lutetia in July 2010, and "Dawn" orbited Vesta between July 2011 and September 2012 and has orbited Ceres since March 2015. On its way to Jupiter, "Juno" traversed the asteroid belt without collecting science data. Due to the low density of materials within the belt, the odds of a probe running into an asteroid are now estimated at less than 1 in 1 billion.

Most belt asteroids imaged to date have come from brief flyby opportunities by probes headed for other targets. Only the "Dawn", NEAR and "Hayabusa" missions have studied asteroids for a protracted period in orbit and at the surface.



</doc>
<doc id="47397" url="https://en.wikipedia.org/wiki?curid=47397" title="Æthelflæd">
Æthelflæd

Æthelflæd, Lady of the Mercians ( 870 – 12 June 918) ruled Mercia in the English Midlands from 911 until her death. She was the eldest daughter of Alfred the Great, king of the Anglo-Saxon kingdom of Wessex, and his wife Ealhswith. Æthelflæd was born around 870 at the height of the Viking invasions of England. By 878, most of England was under Danish Viking rule – East Anglia and Northumbria having been conquered, and Mercia partitioned between the English and the Vikings – but in that year Alfred won a crucial victory at the Battle of Edington. Soon afterwards the English-controlled western half of Mercia came under the rule of Æthelred, Lord of the Mercians, who accepted Alfred's overlordship. Alfred adopted the title King of the English, claiming to rule all English people not living in areas under Viking control. In the mid-880s, Alfred sealed the strategic alliance between the surviving English kingdoms by marrying Æthelflæd to Æthelred.

Æthelred played a major role in fighting off renewed Viking attacks in the 890s, together with Æthelflæd's brother, the future King Edward the Elder. Æthelred and Æthelflæd fortified Worcester, gave generous donations to Mercian churches and built a new minster in Gloucester. Æthelred's health probably declined early in the next decade, after which it is likely that Æthelflæd was mainly responsible for the government of Mercia. Edward had succeeded as King of the Anglo-Saxons in 899, and in 909 he sent a West Saxon and Mercian force to raid the northern Danelaw. They returned with the remains of the royal Northumbrian saint, Oswald, which were translated to the new Gloucester minster. Æthelred died in 911 and Æthelflæd then ruled Mercia as Lady of the Mercians. The accession of a female ruler in Mercia is described by the historian Ian Walker as "one of the most unique events in early medieval history".

Alfred had built a network of fortified burhs and in the 910s Edward and Æthelflæd embarked on a programme of extending them. Among the towns where she built defences were Bridgnorth, Tamworth, Stafford, Warwick, Chirbury and Runcorn. In 917 she sent an army to capture Derby, the first of the Five Boroughs of the Danelaw to fall to the English, a victory described by Tim Clarkson as "her greatest triumph". In 918 Leicester surrendered without a fight. Shortly afterwards the Viking leaders of York offered her their loyalty, but she died on 12June 918 before she could take advantage of the offer, and a few months later Edward completed the conquest of Mercia. Æthelflæd was succeeded by her daughter Ælfwynn, but in December Edward took personal control of Mercia and carried Ælfwynn off to Wessex.

Historians disagree whether Mercia was an independent kingdom under Æthelred and Æthelflæd but they agree that Æthelflæd was a great ruler who played an important part in the conquest of the Danelaw. She was praised by Anglo-Norman chroniclers such as William of Malmesbury, who described her as "a powerful accession to [Edward's] party, the delight of his subjects, the dread of his enemies, a woman of enlarged soul". According to Pauline Stafford, "like ... ElizabethI she became a wonder to later ages". In Nick Higham's view, medieval and modern writers have been so captivated by her that Edward's reputation has suffered unfairly in comparison.

Mercia was the dominant kingdom in southern England in the eighth century and maintained its position until it suffered a decisive defeat by Wessex at the Battle of Ellandun in 825. Thereafter the two kingdoms became allies, which was to be an important factor in English resistance to the Vikings.

In 865 the Viking Great Heathen Army landed in East Anglia and used this as a starting point for an invasion. The East Anglians were forced to buy peace and the following year the Vikings invaded Northumbria, where they appointed a puppet king in 867. They then moved on Mercia, where they spent the winter of 867–868. King Burgred of Mercia was joined by King Æthelred of Wessex and his brother, the future King Alfred, for a combined attack on the Vikings, who refused an engagement; in the end the Mercians bought peace with them. The following year, the Vikings conquered East Anglia. In 874 the Vikings expelled King Burgred and Ceolwulf became the last King of Mercia with their support. In 877 the Vikings partitioned Mercia, taking the eastern regions for themselves and allowing Ceolwulf to keep the western ones. He was described by the "Anglo-Saxon Chronicle" as "a foolish king's thegn" who was a puppet of the Vikings. The historian Ann Williams regards this view as partial and distorted, that he was accepted as a true king by the Mercians and by King Alfred. The situation was transformed the following year when Alfred won a decisive victory over the Danes at the Battle of Edington.

Ceolwulf is not recorded after 879. His successor as the ruler of the English western half of Mercia, Æthelflæd's husband Æthelred, is first seen in 881 when, according to the historian of medieval Wales, Thomas Charles-Edwards, he led an unsuccessful Mercian invasion of the north Welsh Kingdom of Gwynedd. In 883 he made a grant with the consent of King Alfred, thus acknowledging Alfred's lordship. In 886 Alfred occupied the Mercian town of London, which had been in Viking hands. He then received the submission of all English not under Viking control and handed control of London over to Æthelred. In the 890s, Æthelred and Edward, Alfred's son and future successor, fought off more Viking attacks. Alfred died in 899 and Edward's claim to the throne was disputed by Æthelwold, son of Alfred's elder brother. Æthelwold joined forces with the Vikings when he was unable to get sufficient support in Wessex, and his rebellion only ended with his death in battle in December 902.

The most important source for history in this period is the "Anglo-Saxon Chronicle" but Æthelflæd is almost ignored in the standard West Saxon version, in what F. T. Wainwright calls "a conspiracy of silence". He argues that King Edward was anxious not to encourage Mercian separatism and did not wish to publicise his sister's accomplishments, in case she became a symbol of Mercian claims. Brief details of her actions were preserved in a pro-Mercian version of the "Chronicle" known as the "Mercian Register" or the "Annals of Æthelflæd"; although it is now lost, elements were incorporated into several surviving versions of the "Chronicle". The "Register" covers the years 902 to 924, and focuses on Æthelflæd's actions; Edward is hardly mentioned and her husband only twice, on his death and as father of their daughter. Information about Æthelflæd's career is also preserved in the Irish chronicle known as the "Three Fragments". According to Wainwright, it "contains much that is legendary rather than historical. But it also contains, especially for our period, much genuine historical information which seems to have its roots in a contemporary narrative." She was praised by Anglo-Norman chroniclers such as William of Malmesbury and John of Worcester and she has received more attention from historians than any other secular woman in Anglo-Saxon England.

Æthelflæd was born around 870, the oldest child of King Alfred the Great and his Mercian wife, Ealhswith, who was a daughter of Æthelred Mucel, ealdorman of the Gaini, one of the tribes of Mercia. Ealhswith's mother, Eadburh, was a member of the Mercian royal house, probably a descendant of King Coenwulf (796–821). Æthelflæd was thus half-Mercian and the alliance between Wessex and Mercia was sealed by her marriage to Æthelred, Lord of the Mercians. They are mentioned in Alfred's will, which probably dates to the 880s. Æthelflæd, described only as "my eldest daughter", received an estate and 100 mancuses, while Æthelred, the only ealdorman to be mentioned by name, received a sword worth 100 mancuses. Æthelflæd was first recorded as Æthelred's wife in a charter of 887, when he granted two estates to the see of Worcester "with the permission and sign-manual of King Alfred" and the attestors included "Æthelflæd "conjux"". The marriage may have taken place earlier, perhaps when he submitted to Alfred following the recovery of London in 886. Æthelred was much older than Æthelflæd and they had one known child, a daughter called Ælfwynn. Æthelstan, the eldest son of Edward the Elder and future king of England, was brought up in their court and, in the view of Martin Ryan, certainly joined their campaigns against the Vikings.

Æthelred's descent is unknown. Richard Abels describes him as "somewhat of a mysterious character", who may have claimed royal blood and been related to King Alfred's father-in-law, Ealdorman Æthelred Mucel. In the view of Ian Walker: "He was a royal ealdorman whose power base lay in the south-west of Mercia in the former kingdom of the Hwicce around Gloucester". Alex Woolf suggests that he was probably the son of King Burgred of Mercia and King Alfred's sister Æthelswith, although that would mean that the marriage between Æthelflæd and Æthelred was uncanonical, because Rome then forbade marriage between first cousins.

Compared to the rest of England, much of English Mercia —Gloucestershire, Worcestershire, Herefordshire and Shropshire —was unusually stable in the Viking age. It did not suffer major attacks and it did not come under great pressure from Wessex. Mercian scholarship had high prestige at the courts of Alfred and Edward. Worcester was able to preserve considerable intellectual and liturgical continuity and, with Gloucester, became the centre of a Mercian revival under Æthelred and Æthelflæd that extended into the more unstable areas of Staffordshire and Cheshire. Charters show the Mercian leaders supporting the revival by their generosity to monastic communities. In 883 Æthelred granted privileges to Berkeley Abbey and in the 890s he and Æthelflæd issued a charter in favour of the church of Worcester. This was the only occasion in Alfred's lifetime when they are known to have acted jointly; generally Æthelred acted on his own, usually acknowledging the permission of King Alfred. Æthelflæd witnessed charters of Æthelred in 888, 889 and 896. In 901 Æthelflæd and Æthelred gave land and a golden chalice weighing thirty mancuses to the shrine of Saint Mildburg at Much Wenlock church.
At the end of the ninth century, Æthelred and Æthelflæd fortified Worcester, with the permission of King Alfred and at the request of Bishop Werferth, described in the charter as "their friend". They granted the church of Worcester a half share of the rights of lordship over the city, covering land rents and the proceeds of justice, and in return the cathedral community agreed in perpetuity to dedicate a psalm to them three times a day and a mass and thirty psalms every Saturday. As the rights of lordship had previously belonged fully to the church, this represented the beginning of transfer from episcopal to secular control of the city. In 904 Bishop Werferth granted a lease of land in the city to Æthelred and Æthelflæd, to be held for the duration of their lives and that of their daughter Ælfwynn. The land was valuable, including most of the city's usable river frontage, and control of it enabled the Mercian rulers to dominate over and profit from the city.

Æthelred's health probably declined at some stage in the decade after Alfred died in 899, and Æthelflæd may have become the de facto ruler of Mercia by 902. According to the "Three Fragments", the Norse (Norwegian) Vikings were expelled from Dublin and then made an abortive attack on Wales. When this failed they applied to Æthelflæd, her husband being ill, for permission to settle near Chester. Æthelflæd agreed and for some time they were peaceful. The Norse Vikings then joined with the Danes in an attack on Chester, but this failed because Æthelflæd had fortified the town, and she and her husband persuaded the Irish among the attackers to change sides. Other sources confirm that the Norse were driven out of Dublin in 902 and that Æthelflæd fortified Chester in 907. Æthelflæd re-founded Chester as a burh and she is believed to have enhanced its Roman defences by running walls from the north-west and south-east corners of the fort to the River Dee. Simon Ward, who excavated an Anglo-Saxon site in Chester, sees the later prosperity of the town as owing much to the planning of Æthelflæd and Edward. After Æthelflæd's death, Edward encountered fierce resistance to his efforts to consolidate his control of the north-west and he died there in 924, shortly after suppressing a local rebellion.

In 909 Edward sent a West Saxon and Mercian force to the northern Danelaw, where it raided for five weeks. The remains of the royal Northumbrian saint Oswald were seized and taken from his resting place in Bardney Abbey in Lincolnshire to Gloucester. In the late ninth century Gloucester had become a burh with a street plan similar to Winchester, and Æthelred and Æthelflæd had repaired its ancient Roman defences. In 896 a meeting of the Mercian witan was held in the royal hall at Kingsholm, just outside the town. The Mercian rulers built a new minster in Gloucester and, although the building was small, it was embellished on a grand scale, with rich sculpture. It was initially dedicated to St Peter but when Oswald's remains were brought to Gloucester in 909, Æthelflæd had them translated from Bardney to the new minster, which was renamed St Oswald's in his honour. The relics gave the church great prestige as Oswald had been one of the most important founding saints of Anglo-Saxon Christianity as well as a ruling monarch, and the decision to translate his relics to Gloucester shows the importance of the town to Æthelred and Æthelflæd, who were buried in St Oswald's Minster. Simon Keynes describes the town as "the main seat of their power" and Carolyn Heighway believes that the foundation of the church was probably a family and dynastic enterprise, encouraged by Alfred and supported by Edward and Bishop Werferth. Heighway and Michael Hare wrote:

Mercia had a long tradition of venerating royal saints and this was enthusiastically supported by Æthelred and Æthelflæd. Saintly relics were believed to give supernatural legitimacy to rulers' authority, and Æthelflæd was probably responsible for the foundation or re-foundation of Chester Minster and the transfer to it of the remains of the seventh-century Mercian princess Saint Werburgh from Hanbury in Staffordshire. She may also have translated the relics of the martyred Northumbrian prince Ealhmund from Derby to Shrewsbury. In 910 the Danes retaliated against the English attack of the previous year by invading Mercia, raiding as far as Bridgnorth in Shropshire. On their way back they were caught by an English army in Staffordshire and their army was destroyed at the Battle of Tettenhall, opening the way for the recovery of the Danish Midlands and East Anglia over the next decade.

On her husband's death in 911, Æthelflæd became "Myrcna hlædige", "Lady of the Mercians". Ian Walker describes her succession as the only case of a female ruler of a kingdom in Anglo-Saxon history and "one of the most unique events in early medieval history". In Wessex, royal women were not allowed to play any political role; Alfred's wife was not granted the title of queen and was never a witness to charters. In Mercia, Alfred's sister Æthelswith had been the wife of King Burgred of Mercia; she had witnessed charters as queen and had made grants jointly with her husband and in her own name. Æthelflæd benefited from a Mercian tradition of queenly importance, and was able to play a key role in the history of the early tenth century as Lady of the Mercians, which would not have been possible in Wessex.

When Æthelred died, Edward took control of the Mercian towns of London and Oxford and their hinterlands, which Alfred had put under Mercian control. Ian Walker suggests that Æthelflæd accepted this loss of territory in return for recognition by her brother of her position in Mercia. Alfred had constructed a network of fortified burhs in Wessex, and Edward and Æthelflæd now embarked on a programme of extending them to consolidate their defences and provide bases for attacks on the Vikings. According to Frank Stenton, Æthelflæd led Mercian armies on expeditions, which she planned. He commented: "It was through reliance on her guardianship of Mercia that her brother was enabled to begin the forward movement against the southern Danes which is the outstanding feature of his reign".

Æthelflæd had already fortified an unknown location called "Bremesburh" in 910 and in 912 she built defences at Bridgnorth to cover a crossing of the River Severn. In 913 she built forts at Tamworth to guard against the Danes in Leicester, and in Stafford to cover access from the Trent Valley. In 914 a Mercian army drawn from Gloucester and Hereford repelled a Viking invasion from Brittany, and the Iron Age Eddisbury hill fort was repaired to protect against invasion from Northumbria or Cheshire, while Warwick was fortified as further protection against the Leicester Danes. In 915 Chirbury was fortified to guard a route from Wales and Runcorn on the River Mersey. Defences were built before 914 at Hereford, and probably Shrewsbury and two other fortresses, at "Scergeat" and "Weardbyrig", which have not been located.

In 917 invasions by three Viking armies failed as Æthelflæd sent an army which captured Derby and the territory around it. The town was one of the Five Boroughs of the Danelaw, together with Leicester, Lincoln, Nottingham and Stamford. Derby was the first to fall to the English; she lost "four of her thegns who were dear to her" in the battle. Tim Clarkson, who describes Æthelflæd as "renowned as a competent war-leader", regards the victory at Derby as "her greatest triumph". At the end of the year, the East Anglian Danes submitted to Edward. In early 918, Æthelflæd gained possession of Leicester without opposition and most of the local Danish army submitted to her. A few months later, the leading men of Danish-ruled York offered to pledge their loyalty to Æthelflæd, probably to secure her support against Norse raiders from Ireland, but she died on 12 June 918, before she could take advantage of the offer. No similar offer is known to have been made to Edward. According to the "Three Fragments", in 918 Æthelflæd led an army of Scots and Northumbrian English against forces led by the Norse Viking leader Ragnall at the Battle of Corbridge in Northumbria. Historians consider this unlikely, but she may have sent a contingent to the battle. Both sides claimed victory but Ragnall was able to establish himself as ruler of Northumbria. In the "Three Fragments", Æthelflæd also formed a defensive alliance with the Scots and the Strathclyde British, a claim accepted by Clarkson.

Little is known of Æthelflæd's relations with the Welsh. The only recorded event took place in 916, when she sent an expedition to avenge the murder of a Mercian abbot and his companions; her men destroyed the royal crannog of Brycheiniog on Llangorse Lake and captured the queen and thirty-three of her companions. According to a version of the "Anglo-Saxon Chronicle" strongly sympathetic to Edward the Elder, after Æthelflæd's death "the kings among the Welsh, Hywel and Clydog and Idwal, and all the Welsh people sought to have [Edward] as their lord". Hywel Dda was king of Dyfed in south-west Wales, Clydog ap Cadell probably king of Powys in the north-east, and Idwal ab Anarawd king of Gwynedd in the north-west. Gwent in south-east Wales was already under West Saxon lordship but, in the view of Charles-Edwards, this passage shows that the other Welsh kingdoms were under Mercian lordship until Edward took direct power over Mercia.

No coins were issued with the name of Æthelred or Æthelflæd on them, but in the 910s silver pennies were minted in west Mercian towns with unusual ornamental designs on the reverse and this may have reflected Æthelflæd's desire to distinguish specie issued under her control from that of her brother. After her death, west Mercian coin reverses were again the same as those on coins produced in Wessex.

Æthelflæd died at Tamworth on 12June 918 and her body was carried to Gloucester, where she was buried with her husband in their foundation, St Oswald's Minster. According to the "Mercian Register", Æthelflæd was buried in the east porticus. A building suitable for a royal mausoleum has been found by archaeological investigation at the east end of the church and this may have been St Oswald's burial place. Placement next to the saint would have been a prestigious burial location for Æthelred and Æthelflæd. William of Malmesbury wrote that their burial places were found in the "south" porticus during building works in the early twelfth century. He may have been misinformed about the position but it is also possible that the tombs were moved from their prestigious position next to the saint, when the couple became less known over time or when tenth-century kings acted to minimise the honour paid to their Mercian predecessors.

The choice of burial place was symbolic. Victoria Thompson argues that if Æthelflæd had chosen Edward's royal mausoleum in Winchester as the burial place for her husband and herself, that would have emphasised Mercia's subordinate status, whereas a traditional Mercian royal burial place such as Repton would have been a provocative declaration of independence; Gloucester, near the border with Wessex, was a compromise between the two. Martin Ryan sees the foundation as "something like a royal mausoleum, intended to replace the one at Repton (Derbyshire) that had been destroyed by the Vikings". Æthelflæd died a few months too early to see the final conquest of the southern Danelaw by Edward. She was succeeded as Lady of the Mercians by her daughter, Ælfwynn, but in early December 918 Edward deposed her and took Mercia under his control. Many Mercians disliked the subordination of their ancient kingdom to Wessex, and Wainwright describes the Mercian annalist's description of the deposition of Ælfwynn as "heavy with resentment". Edward died in 924 at Farndon in Cheshire a few days after putting down a rebellion by Mercians and Welshmen at Chester.

To the West Saxon version of the "Anglo-Saxon Chronicle", Æthelflæd was merely King Edward's sister, whereas for the "Mercian Register" she was Lady of the Mercians. Irish and Welsh annals described her as a queen and the Annals of Ulster, which ignore the deaths of Alfred and Edward, described her as "famosissima regina Saxonum" (renowned Saxon queen). She was also praised by Anglo-Norman historians such as John of Worcester and William of Malmesbury, who described her as "a powerful accession to [Edward's] party, the delight of his subjects, the dread of his enemies, a woman of enlarged soul". He claimed that she declined to have sex after the birth of her only child because it was "unbecoming of the daughter of a king to give way to a delight which, after a time, produced such painful consequences". According to Nick Higham, "successive medieval and modern writers were quite captivated by her" and her brother's reputation has suffered unfairly in comparison. In the twelfth century, Henry of Huntingdon paid her his own tribute:
Some historians believe that Æthelred and Æthelflæd were independent rulers. In the "Handbook of British Chronology", David Dumville refers to "Q. Æthelflæd" and comments, "The titles given her by all sources ("hlæfdige, regina") imply that she wielded royal power and authority". Alex Woolf concurs and Pauline Stafford describes Æthelflæd as "the last Mercian queen", referred to in charters in such terms as "by the gift of Christ's mercy ruling the government of the Mercians". Stafford argues that Æthelred and Æthelflæd exercised most or all of the powers of a monarch after Alfred's death but it would have been a provocative act formally to claim regality, especially after Æthelwold's rebellion. Stafford sees her as a "warrior queen", "Like ... ElizabethI she became a wonder to later ages." According to Charles Insley,

Wainwright sees Æthelflæd as willingly accepting a subordinate role in a partnership with her brother and agreeing to his plan of unification of Wessex and Mercia under his rule. Wainwright argues that he probably sent his oldest son Æthelstan to be brought up in Mercia, to make him more acceptable to the Mercians as king; Æthelflæd does not appear to have tried to find a husband for her daughter, who must have been nearly thirty by 918. In Wainwright's view, she was ignored in West Saxon sources for fear that recognition of her achievements would encourage Mercian separatism:

Simon Keynes points out that all coins were issued in Edward's name, and while the Mercian rulers were able to issue some charters on their own authority, others acknowledged Edward's lordship. In 903 a Mercian ealdorman "petitioned King Edward, and also Æthelred and Æthelflæd, who then held rulership and power over the race of the Mercians under the aforesaid king". Keynes argues that a new polity was created when Æthelred submitted to Alfred in the 880s, covering Wessex and English (western) Mercia. In Keynes's view, "the conclusion seems inescapable that the Alfredian polity of the kingship 'of the Anglo-Saxons' persisted in the first quarter of the tenth century, and that the Mercians were thus under Edward's rule from the beginning of his reign". Ryan believes that the Mercian rulers "had a considerable but ultimately subordinate share of royal authority".

In Higham's view, Keynes makes a strong case that Edward ruled over an Anglo-Saxon state with a developing administrative and ideological unity but that Æthelflæd and Æthelred did much to encourage a separate Mercian identity, such as establishing cults of Mercian saints at their new burhs, as well as reverence for their great Northumbrian royal saint at Gloucester:

In June 2018, Æthelflæd's funeral was re-enacted in front of a crowd of 10,000 people in Gloucester, as part of a series of living history events marking the 1,100th anniversary of her death.




</doc>
<doc id="47510" url="https://en.wikipedia.org/wiki?curid=47510" title="Cirrus cloud">
Cirrus cloud

Cirrus (cloud classification symbol: Ci) is a genus of atmospheric cloud generally characterized by thin, wispy strands, giving the type its name from the Latin word "cirrus", meaning a ringlet or curling lock of hair. This cloud can form at any altitude between and above sea level. The strands of cloud sometimes appear in tufts of a distinctive form referred to by the common name of "mares' tails".

From the surface of Earth, cirrus typically appears white, or a light
grey in color. It forms when water vapor undergoes deposition at altitudes above in temperate regions and above in tropical regions. It also forms from the outflow of tropical cyclones or the anvils of cumulonimbus clouds. Since cirrus clouds arrive in advance of the frontal system or tropical cyclone, it indicates that weather conditions may soon deteriorate. While it indicates the arrival of precipitation (rain), cirrus clouds only produce fall streaks (falling ice crystals that evaporate before landing on the ground).

Jet stream-powered cirrus can grow long enough to stretch across continents while remaining only a few kilometers deep. When visible light interacts with the ice crystals in cirrus cloud, it produces optical phenomena such as sun dogs and halos. Cirrus is known to raise the temperature of the air beneath the main cloud layer by an average of 10 °C (18 °F). When the individual filaments become so extensive that they are virtually indistinguishable from one another, they form a sheet of high cloud called cirrostratus. Convection at high altitudes can produce another high-based genus called cirrocumulus, a pattern of small cloud tufts that contain droplets of supercooled water.

Cirrus clouds form on other planets, including Mars, Jupiter, Saturn, Uranus, and possibly Neptune. They have even been seen on Titan, one of Saturn's moons. Some of these extraterrestrial cirrus clouds are composed of ammonia or methane ice rather than water ice. The term "cirrus" is also used for certain interstellar clouds composed of sub-micrometer-sized dust grains.

Cirrus clouds range in thickness from to , with an average thickness of . There are, on average, 30 ice crystals per liter (96 ice crystals per gallon), but this ranges from one ice crystal per 10,000 liters (3.7 ice crystals per 10,000 gallons) to 10,000 ice crystals per liter (37,000 ice crystals per gallon), a difference of eight orders of magnitude. The length of each of these ice crystals is usually 0.25 millimeters long, but they range from as short as 0.01 millimeters or as long as several millimeters. The ice crystals in contrails are much smaller than those in naturally occurring cirrus cloud, as they are around 0.001 millimeters to 0.1 millimeters in length. Cirrus can vary in temperature from to .

The ice crystals in cirrus clouds have different shapes in addition to different sizes. Some shapes include solid columns, hollow columns, plates, rosettes, and conglomerations of the various other types. The shape of the ice crystals is determined by the air temperature, atmospheric pressure, and ice supersaturation. Cirrus in temperate regions typically have the shapes segregated by type: the columns and plates tend to be at the top of the cloud, whereas the rosettes and conglomerations tend to be near the base. In the northern Arctic region, cirrus clouds tend to be composed up of only the columns, plates, and conglomerations, and these crystals tend to be at least four times larger than the minimum size. In Antarctica, cirrus are usually composed of only the columns, and these columns are much longer than normal.
Scientists have studied the characteristics of cirrus using several different methods. One, Light Detection and Ranging (LiDAR), gives highly accurate information on the cloud's altitude, length, and width. Balloon-carried hygrometers give information on the humidity of the cirrus cloud but are not accurate enough to measure the depth of the cloud. Radar units give information on the altitudes and thicknesses of cirrus clouds. Another data source is satellite measurements from the Stratospheric Aerosol and Gas Experiment (SAGE) program. These satellites measure where infrared radiation is absorbed in the atmosphere, and if it is absorbed at cirrus altitudes, then it is assumed that there are cirrus clouds in that location. The United States National Aeronautics and Space Administration's (NASA) MODerate resolution Imaging Spectroradiometer (MODIS) also gives information on the cirrus cloud cover by measuring reflected infrared radiation of various specific frequencies during the day. During the night, it determines cirrus cover by detecting the Earth's infrared emissions. The cloud reflects this radiation back to the ground, thus enabling satellites to see the "shadow" it casts into space. Visual observations from aircraft or the ground provide additional information about cirrus clouds.
Based on data taken from the United States using these methods, cirrus cloud cover was found to vary diurnally and seasonally. The researchers found that in the summer, at noon, the cover is the lowest, with an average of 23% of the United States' land area covered by cirrus. Around midnight, the cloud cover increases to around 28%. In winter, the cirrus cloud cover did not vary appreciably from day to night. These percentages include clear days and nights, as well as days and nights with other cloud types, as lack of cirrus cloud cover. When these clouds are present, the typical coverage ranges from 30% to 50%. Based on satellite data, cirrus covers an average of 20% to 25% of the Earth's surface. In the tropical regions, this cloud covers around 70% of the region's surface area.

Cirrus clouds often produce hair-like filaments—similar to the virga produced in liquid–water clouds—called fall streaks, and they are made of heavier ice crystals that fall from the cloud. The sizes and shapes of fall streaks are determined by the wind shear.
Cirrus comes in four distinct species; Cirrus "castellanus", "fibratus", "spissatus", and "uncinus"; which are each divided into four varieties: "intortus", "vertebratus", "radiatus", and "duplicatus". "Cirrus castellanus" is a species that has cumuliform tops caused by high-altitude convection rising up from the main cloud body. "Cirrus fibratus" looks striated and is the most common cirrus species. "Cirrus uncinus" clouds are hooked and are the form that is usually called "mare's tails". Of the varieties, "Cirrus intortus" has an extremely contorted shape, and "cirrus radiatus" has large, radial bands of cirrus clouds that stretch across the sky. Kelvin–Helmholtz waves are a form of cirrus intortus that has been twisted into loops by vertical wind shear.

Cirrus clouds are formed when water vapor undergoes deposition at high altitudes where the atmospheric pressure ranges from 600 mbar at above sea level to 200 mbar at above sea level. These conditions commonly occur at the leading edge of a warm front. Because humidity is low at such high altitudes, this genus-type tends to be very thin. Cirrus clouds are composed of ice crystals that originate from the freezing of super cooled water droplets in regions where air temperature is lower than -20 °C or -30 °C.Cirrus usually occur in fair weather. They are formed when it is high enough to be cold and freeze the water drops into ice. They sometimes may be caused by turbulence and wind shear, or by upper-tropospheric convection. Sometimes they are like blown out ice-crystals spreading from the top of a dying cumulonimbus.

Cirrus forms from tropical cyclones, and is commonly seen fanning out from the eyewalls of hurricanes. A large shield of cirrus and cirrostratus typically accompanies the high altitude outflow of hurricanes or typhoons, and these can make the underlying rain bands—and sometimes even the eye—difficult to detect in satellite photographs.

Thunderstorms can form dense cirrus at their tops. As the cumulonimbus cloud in a thunderstorm grows vertically, the liquid water droplets freeze when the air temperature reaches the freezing point. The anvil cloud takes its shape because the temperature inversion at the tropopause prevents the warm, moist air forming the thunderstorm from rising any higher, thus creating the flat top. In the tropics, these thunderstorms occasionally produce copious amounts of cirrus from their anvils. High-altitude winds commonly push this dense mat out into an anvil shape that stretches downwind as much as several kilometers.

Individual cirrus cloud formations can be the remnants of anvil clouds formed by thunderstorms. In the dissipating stage of a cumulonimbus cloud, when the normal column rising up to the anvil has evaporated or dissipated, the mat of cirrus in the anvil is all that is left.

Contrails are a manmade type of cirrus cloud formed when water vapor from the exhaust of a jet engine condenses on particles, which come from either the surrounding air or the exhaust itself, and freezes, leaving behind a visible trail. The exhaust can also trigger the formation of cirrus by providing ice nuclei when there is an insufficient naturally-occurring supply in the atmosphere. One of the environmental impacts of aviation is that persistent contrails can form into large mats of cirrus, and increased air traffic has been implicated as one possible cause of the increasing frequency and amount of cirrus in Earth's atmosphere.

Cirrus Fibratus clouds appear thin and fibrous looking. Noticeably, they are the most common type of cirrus cloud. They might indicate windy weather, since they are mostly formed by wind shear on higher altitudes.

Cirrus Uncinus are similar, except that they always have a hook or curl on the tip.

Cirrus Spissatus clouds are the highest clouds of the main cloud genera. They may form in the higher tropopause or even at the lower stratosphere. They are dense and opaque, not allowing the light of the sun or moon to pass through. They are more common on the anvils of cumulonimbus clouds.

Cirrus Floccus is derived from Latin, which means "lock of wool" or cirrus with ragged bases. They are not to be confused with cirrocumulus floccus since they are larger than cirrocumulus and mostly are isolated. A precipitation-based supplementary feature virga is mostly visible, which makes it easier to distinguish the difference between cirrocumulus floccus and cirrus floccus.

Cirrus Castellanus is derived from Latin, which means "castle" or round turrets. They indicate that atmospheric instability is occurring on the higher altitudes of the troposphere. They appear as tall clouds that originate from a flat base.

Cirrus clouds are translucent and so have no opacity-based varieties; only one species is opaque, which is cirrus spissatus.

Cirrus Intortus clouds is derived from Latin which means "twisted", or "wound". These clouds appear twisted, or simply, intorted.

Cirrus Vertebratus clouds, resembling the appearance of bones as hinted by the word "vertebratus". They look more like fish bones, with fibrous lines that originate from one which resembles the appearance of fish bones.

Cirrus Radiatus clouds appear as parallel lines that seem to originate from one point and can stretch for hundreds of miles, and they move parallel to the wind shear.

Random, isolated cirrus do not have any particular significance. A large number of cirrus clouds can be a sign of an approaching frontal system or upper air disturbance. This signals a change in weather in the near future, which usually becomes stormier. If the cloud is a cirrus castellanus, there might be instability at the high altitude level. When the clouds deepen and spread, especially when they are of the "cirrus radiatus" variety or "cirrus fibratus" species, this usually indicates an approaching weather front. If it is a warm front, the cirrus clouds spread out into cirrostratus, which then thicken and lower into altocumulus and altostratus. The next set of clouds are the rain-bearing nimbostratus clouds. When cirrus clouds precede a cold front, squall line or multicellular thunderstorm, it is because they are blown off the anvil, and the next to arrive are the cumulonimbus clouds. Kelvin-Helmholtz waves indicate extreme wind shear at high levels.

Within the tropics, 36 hours prior to the center passage of a tropical cyclone, a veil of white cirrus clouds approaches from the direction of the cyclone. In the mid to late 19th century, forecasters used these cirrus veils to predict the arrival of hurricanes. In the early 1870s the president of Belén College in Havana, Cuba, Father Benito Viñes, developed the first hurricane forecasting system, and he mainly used the motion of these clouds in formulating his predictions. He would observe the clouds hourly from 4:00 am to 10:00 pm. After accumulating enough information, Viñes began accurately predicting the paths of hurricanes, and he eventually summarized his observations in his book, "Apuntes Relativos a los Huracanes de las Antilles".

Cirrus clouds cover nothing to 25% of the Earth (up to 70% in the tropics) and have a net heating effect. When they are thin and translucent, the clouds efficiently absorb outgoing infrared radiation while only marginally reflecting the incoming sunlight. When cirrus clouds are thick, they reflect only around 9% of the incoming sunlight, but they prevent almost 50% of the outgoing infrared radiation from escaping, thus raising the temperature of the atmosphere beneath the clouds by an average of 10 °C (18 °F)—a process known as the greenhouse effect. Averaged worldwide, cloud formation results in a temperature loss of 5 °C (9 °F) at the earth's surface, mainly the result of stratocumulus clouds.

As a result of their warming effects when relatively thin, cirrus clouds have been implicated as a potential partial cause of global warming. Scientists have speculated that global warming could cause high thin cloud cover to increase, thereby increasing temperatures and humidity. This, in turn, would increase the cirrus cloud cover, effectively creating a positive feedback circuit. A prediction of this hypothesis is that the cirrus would move higher as the temperatures rose, increasing the volume of air underneath the clouds and the amount of infrared radiation reflected back down to earth. In addition, the hypothesis suggests that the increase in temperature would tend to increase the size of the ice crystals in the cirrus cloud, possibly causing the reflection of solar radiation and the reflection of the Earth's infrared radiation to balance out.

A similar hypothesis put forth by Richard Lindzen is the iris hypothesis in which an increase in tropical sea surface temperatures results in less cirrus clouds and thus more infrared radiation emitted to space.

Cirrus clouds, like cirrostratus clouds, can produce several optical effects, such as halos around the sun and moon. Halos are caused by interaction of the light with hexagonal ice crystals present in the clouds, which, depending on their shape and orientation, can result in a wide variety of white and colored rings, arcs and spots in the sky. Common halo varieties are the 22° halo, sun dogs, the circumzenithal arc and the circumhorizontal arc (also known as fire rainbows). Halos produced by cirrus clouds tend to be more pronounced and colorful than those caused by cirrostratus.

More rarely, cirrus clouds are capable of producing glories, more commonly associated with liquid water-based clouds such as stratus. A glory is a set of concentric, faintly-colored glowing rings that appear around the shadow of the observer, and are best observed from a high viewpoint or from a plane. Cirrus clouds only form glories when the constituent ice crystals are aspherical, and researchers suggest that the ice crystals must be between 0.009 millimeters and 0.015 millimeters in length. 
Cirrus clouds are one of three different genera of high-étage (high-level) clouds. High-étage clouds form at and above in temperate regions. The other two genera, cirrocumulus and cirrostratus, are also high clouds.

In the intermediate range, from to in temperate regions, are the mid-étage clouds. They comprise two or three genera depending on the system of height classification being used: altostratus, altocumulus, and, according to WMO classification, nimbostratus. These clouds are formed from ice crystals, supercooled water droplets, or liquid water droplets.

Low-étage clouds form at less than . The two genera that are strictly low-étage are stratus, and stratocumulus. These clouds are composed of water droplets, except during winter when they are formed of supercooled waterdroplets or ice crystals if the temperature at cloud level is below freezing. Two additional genera usually form in the low altitude range, but may be based at higher levels under conditions of very low humidity. They comprise the genera cumulus, and cumulonimbus, which along with nimbostratus, are often classified separately as clouds of vertical development, especially when their tops are high enough to be composed of super-cooled water droplets or ice crystals.

The altitudes of high-étage clouds like cirrus vary considerably with latitude. In the polar regions, they are at their lowest, with a minimum altitude of only to a maximum of . In tropical regions, they are at their highest, ranging in altitude from about to around . In temperate regions, they range in altitude from to —a variation in contrast to low-étage clouds, which do not appreciably change altitude with latitude.

There are three main genera in the family of high clouds: cirrus, cirrocumulus, and cirrostratus. Cirrostratus clouds commonly produce halos because they are composed almost entirely of ice crystals. Cirrocumulus and cirrostratus are sometimes informally referred to as "cirriform clouds" because of their frequent association with cirrus. They are given the prefix "cirro-", but this refers more to their altitude range than their physical structure. Cirrocumulus in its pure form is actually a high cumuliform genus, and cirrostratus is stratiform, like altostratus and lower based sheet clouds.

Cirrocumulus clouds form in sheets or patches and do not cast shadows. They commonly appear in regular, rippling patterns or in rows of clouds with clear areas between. Cirrocumulus are, like other members of the cumuliform category, formed via convective processes. Significant growth of these patches indicates high-altitude instability and can signal the approach of poorer weather. The ice crystals in the bottoms of cirrocumulus clouds tend to be in the form of hexagonal cylinders. They are not solid, but instead tend to have stepped funnels coming in from the ends. Towards the top of the cloud, these crystals have a tendency to clump together. These clouds do not last long, and they tend to change into cirrus because as the water vapor continues to deposit on the ice crystals, they eventually begin to fall, destroying the upward convection. The cloud then dissipates into cirrus. Cirrocumulus clouds come in four species: "stratiformis", "lenticularis", "castellanus", and "floccus". They are iridescent when the constituent supercooled water droplets are all about the same size.

Cirrostratus clouds can appear as a milky sheen in the sky or as a striated sheet. They are sometimes similar to altostratus and are distinguishable from the latter because the sun or moon is always clearly visible through transparent cirrostratus, in contrast to altostratus which tends to be opaque or translucent. Cirrostratus come in two species, "fibratus" and "nebulosus". The ice crystals in these clouds vary depending upon the height in the cloud. Towards the bottom, at temperatures of around to , the crystals tend to be long, solid, hexagonal columns. Towards the top of the cloud, at temperatures of around to , the predominant crystal types are thick, hexagonal plates and short, solid, hexagonal columns. These clouds commonly produce halos, and sometimes the halo is the only indication that such clouds are present. They are formed by warm, moist air being lifted slowly to a very high altitude. When a warm front approaches, cirrostratus clouds become thicker and descend forming altostratus clouds, and rain usually begins 12 to 24 hours later.

Cirrus clouds have been observed on several other planets. On 18 September 2008, the Martian Lander "Phoenix" took a time-lapse photograph of a group of cirrus clouds moving across the Martian sky using LiDAR. Near the end of its mission, the Phoenix Lander detected more thin clouds close to the north pole of Mars. Over the course of several days, they thickened, lowered, and eventually began snowing. The total precipitation was only a few thousandths of a millimeter. James Whiteway from York University concluded that "precipitation is a component of the [Martian] hydrologic cycle." These clouds formed during the Martian night in two layers, one around above ground and the other at surface level. They lasted through early morning before being burned away by the sun. The crystals in these clouds were formed at a temperature of , and they were shaped roughly like ellipsoids 0.127 millimeters long and 0.042 millimeters wide.

On Jupiter, cirrus clouds are composed of ammonia. When Jupiter's South Equatorial Belt disappeared, one hypothesis put forward by Glenn Orten was that a large quantity of ammonia cirrus clouds had formed above it, hiding it from view. NASA's Cassini probe detected these clouds on Saturn and thin water-ice cirrus on Saturn's moon Titan. Cirrus clouds composed of methane ice exist on Uranus. On Neptune, thin wispy clouds which could possibly be cirrus have been detected over the Great Dark Spot. As on Uranus, these are probably methane crystals.
Interstellar cirrus clouds are composed of tiny dust grains smaller than a micrometer and are therefore not true clouds of this genus which are composed of ice crystals or other frozen liquids. They range from a few light years to dozens of light years across. While they are not technically cirrus clouds, the dust clouds are referred to as "cirrus" because of their similarity to the clouds on Earth. They also emit infrared radiation, similar to the way cirrus clouds on Earth reflect heat being radiated out into space.


Footnotes
Bibliography



</doc>
<doc id="47548" url="https://en.wikipedia.org/wiki?curid=47548" title="Daylight saving time">
Daylight saving time

Daylight saving time (DST), also daylight savings time or daylight time (United States), also summer time (United Kingdom and others), is the practice of advancing clocks during summer months so that evening daylight lasts longer, while sacrificing normal sunrise times. Typically, regions that use daylight saving time adjust clocks forward one hour close to the start of spring and adjust them backward in the autumn to standard time. In effect, DST causes a lost hour of sleep in the spring and an extra hour of sleep in the fall.

George Hudson proposed the idea of daylight saving in 1895. The German Empire and Austria-Hungary organized the first nationwide implementation starting on April 30, 1916. Many countries have used at various times since then, particularly since the 1970s energy crisis. DST is generally not observed near the equator, where sunrise times do not vary enough to justify it. Some countries observe it only in some regions; for example, southern Brazil observes it, while equatorial Brazil does not. Only a minority of the world's population uses DST, because Asia and Africa generally do not observe it.

DST clock shifts sometimes complicate timekeeping and can disrupt travel, billing, record keeping, medical devices, heavy equipment, and sleep patterns. Computer software often adjusts clocks automatically, but policy changes by various jurisdictions of DST dates and timings may be confusing.

Industrialized societies usually follow a clock-based schedule for daily activities that do not change throughout the course of the year. The time of day that individuals begin and end work or school, and the coordination of mass transit, for example, usually remain constant year-round. In contrast, an agrarian society's daily routines for work and personal conduct are more likely governed by the length of daylight hours and by solar time, which change seasonally because of the Earth's axial tilt. North and south of the tropics daylight lasts longer in summer and shorter in winter, with the effect becoming greater the further one moves away from the tropics.

By synchronously resetting all clocks in a region to one hour ahead of standard time, individuals who follow such a year-round schedule will wake an hour earlier than they would have otherwise; they will begin and complete daily work routines an hour earlier, and they will have available to them an extra hour of daylight after their workday activities. However, they will have one less hour of daylight at the start of each day, making the policy less practical during winter.

While the times of sunrise and sunset change at roughly equal rates as the seasons change, proponents of Daylight Saving Time argue that most people prefer a greater increase in daylight hours after the typical "nine to five" workday. Supporters have also argued that DST decreases energy consumption by reducing the need for lighting and heating, but the actual effect on overall energy use is heavily disputed.

The manipulation of time at higher latitudes (for example Iceland, Nunavut, Scandinavia or Alaska) has little impact on daily life, because the length of day and night changes more extremely throughout the seasons (in comparison to other latitudes), and thus sunrise and sunset times are significantly out of phase with standard working hours regardless of manipulations of the clock. DST is also of little use for locations near the equator, because these regions see only a small variation in daylight in the course of the year. The effect also varies according to how far east or west the location is within its time zone, with locations farther east inside the time zone benefiting more from DST than locations farther west in the same time zone.

Ancient civilizations adjusted daily schedules to the sun more flexibly than DST does, often dividing daylight into 12 hours regardless of daytime, so that each daylight hour became progressively longer during spring and shorter during autumn. For example, the Romans kept time with water clocks that had different scales for different months of the year; at Rome's latitude, the third hour from sunrise ("hora tertia") started at 09:02 solar time and lasted 44 minutes at the winter solstice, but at the summer solstice it started at 06:58 and lasted 75 minutes. From the 14th century onwards, equal-length civil hours supplanted unequal ones, so civil time no longer varies by season. Unequal hours are still used in a few traditional settings, such as some monasteries of Mount Athos and all Jewish ceremonies.

Benjamin Franklin published the proverb "early to bed and early to rise makes a man healthy, wealthy, and wise", and he published a letter in the "Journal de Paris" during his time as an American envoy to France (1776–1785) suggesting that Parisians economize on candles by rising earlier to use morning sunlight. This 1784 satire proposed taxing window shutters, rationing candles, and waking the public by ringing church bells and firing cannons at sunrise. Despite common misconception, Franklin did not actually propose DST; 18th-century Europe did not even keep precise schedules. However, this changed as rail transport and communication networks required a standardization of time unknown in Franklin's day.

In 1810, the Spanish National Assembly Cortes of Cádiz issued a regulation that moved certain meeting times forward by one hour from May 1 to September 30 in recognition of seasonal changes, but it did not actually change the clocks. It also acknowledged that private businesses were in the practice of changing their opening hours to suit daylight conditions, but they did so of their own volition.

New Zealand entomologist George Hudson first proposed modern DST. His shift-work job gave him leisure time to collect insects and led him to value after-hours daylight. In 1895, he presented a paper to the Wellington Philosophical Society proposing a two-hour daylight-saving shift, and considerable interest was expressed in Christchurch; he followed up with an 1898 paper. Many publications credit the DST proposal to prominent English builder and outdoorsman William Willett, who independently conceived DST in 1905 during a pre-breakfast ride when he observed how many Londoners slept through a large part of a summer day. Willett also was an avid golfer who disliked cutting short his round at dusk. His solution was to advance the clock during the summer months, and he published the proposal two years later. Liberal Party member of parliament Robert Pearce took up the proposal, introducing the first Daylight Saving Bill to the House of Commons on February 12, 1908. A select committee was set up to examine the issue, but Pearce's bill did not become law and several other bills failed in the following years. Willett lobbied for the proposal in the UK until his death in 1915.

Port Arthur, Ontario was the first city in the world to enact DST on July 1, 1908. This was followed by Orillia, Ontario, introduced by William Sword Frost while mayor from 1911 to 1912. The first states to adopt DST () nationally were those of the German Empire and its World War I ally Austria-Hungary commencing April 30, 1916 as a way to conserve coal during wartime. Britain, most of its allies, and many European neutrals soon followed. Russia and a few other countries waited until the next year, and the United States adopted daylight saving in 1918. Most jurisdictions abandoned daylight saving time in the years after the war ended in 1918, with exceptions including Canada, the UK, France, Ireland, and the United States. However, many places adopted it for periods of time during the following decades, and it became common during World War II. It became widely adopted in America and Europe starting in the 1970s as a result of the 1970s energy crisis. Since then, the world has seen many enactments, adjustments, and repeals.
For specific details, see Daylight saving time by country.

Clock shifts are usually scheduled at, or soon after, midnight and on a weekend to lessen disruption to weekday schedules. A one-hour shift is customary but twenty minute and two hour shifts have been used in the past. In all countries that use daylight saving, the clock is advanced in spring and set back in autumn; the spring change reduces the length of that day and the autumn change increases it. For a midnight shift in spring, a digital display of local time would appear to jump from 11:59:59.9 to 01:00:00.0.

The time at which clocks are to be shifted differs across jurisdictions. The European Union has a coordinated shift, shifting all zones at the same instant, at 01:00 Coordinated Universal Time (UTC), which means that it changes at 02:00 Central European Time (CET) or 03:00 Eastern European Time (EET), the result is that the time differences across European time zone remain constant. North America shifts at 02:00 but at the local time and is consequently uncoordinated so that, for example, Mountain Time is, for one hour, zero hours ahead of Pacific Time instead of one hour ahead in the autumn and two hours instead of one ahead of Pacific Time in the spring.

The dates on which clocks are to be shifted also vary with location and year; consequently, the time differences between regions also vary throughout the year. For example, Central European Time is usually six hours ahead North American Eastern Time, except for a few weeks in March and October/November, while the United Kingdom and mainland Chile could be five hours apart during the northern summer, three hours during the southern summer, and four hours a few weeks per year. Since 1996, European Summer Time has been observed from the last Sunday in March to the last Sunday in October; previously the rules were not uniform across the European Union. Starting in 2007, most of the United States and Canada observe DST from the second Sunday in March to the first Sunday in November, almost two-thirds of the year. Moreover, the beginning and ending dates are roughly reversed between the northern and southern hemispheres because spring and autumn are displaced six months. For example, mainland Chile observes DST from the second Saturday in October to the second Saturday in March, with transitions at local time. In some countries time is governed by regional jurisdictions within the country so that some jurisdictions shift and others do not; this is currently the case in Australia, Brazil, Canada, Mexico, and the United States.

From year to year, the shift dates may change for political and social reasons. The 2007 U.S. change was part of the Energy Policy Act of 2005; previously, from 1987 through 2006, the start and end dates were the first Sunday in April and the last Sunday in October, and Congress retains the right to go back to the previous dates now that an energy-consumption study has been done. Proponents for permanently retaining November as the month for ending DST point to Halloween as a reason to delay the change—to provide extra daylight on October 31. In the past, Australian state jurisdictions not only changed at different local times but sometimes on different dates; for example, in 2008 most DST-observing states shifted clocks forward on October 5 but Western Australia shifted on October 26.

Daylight saving has caused controversy since it began. Winston Churchill argued that it enlarges "the opportunities for the pursuit of health and happiness among the millions of people who live in this country" and pundits have dubbed it "Daylight Slaving Time". Retailing, sports, and tourism interests have historically favored daylight saving, while agricultural and evening entertainment interests have opposed it; its initial adoption was prompted by energy crises and war.

The fate of Willett's 1907 proposal illustrates several political issues. It attracted many supporters, including Arthur Balfour, Churchill, David Lloyd George, Ramsay MacDonald, Edward VII (who used half-hour DST at Sandringham or "Sandringham time"), the managing director of Harrods, and the manager of the National Bank. However, the opposition was stronger, including Prime Minister H. H. Asquith, William Christie (the Astronomer Royal), George Darwin, Napier Shaw (director of the Meteorological Office), many agricultural organizations, and theatre owners. After many hearings, the proposal was narrowly defeated in a parliamentary committee vote in 1909. Willett's allies introduced similar bills every year from 1911 through 1914, to no avail. The U.S. was even more skeptical; Andrew Peters introduced a DST bill to the House of Representatives in May 1909, but it soon died in committee.

Germany led the way by starting DST () during World War I on April 30, 1916 together with its allies to alleviate hardships from wartime coal shortages and air raid blackouts. The political equation changed in other countries; the United Kingdom used DST first on May 21, 1916. U.S. retailing and manufacturing interests led by Pittsburgh industrialist Robert Garland soon began lobbying for DST, but they were opposed by railroads. The U.S.'s 1917 entry to the war overcame objections, and DST was established in 1918.

The war's end swung the pendulum back. Farmers continued to dislike DST, and many countries repealed it after the war. Britain was an exception; it retained DST nationwide but adjusted transition dates over the years for several reasons, including special rules during the 1920s and 1930s to avoid clock shifts on Easter mornings. Now summer time begins annually on the last Sunday in March under a European Community directive, which may be Easter Sunday (as in 2016). The U.S. was more typical; Congress repealed DST after 1919. President Woodrow Wilson was also an avid golfer like Willet, and he vetoed the repeal twice but his second veto was overridden. Only a few U.S. cities retained DST locally, including New York so that its financial exchanges could maintain an hour of arbitrage trading with London, and Chicago and Cleveland to keep pace with New York. Wilson's successor Warren G. Harding opposed DST as a "deception", reasoning that people should instead get up and go to work earlier in the summer. He ordered District of Columbia federal employees to start work at 8 a.m. rather than 9 a.m. during the summer of 1922. Some businesses followed suit, though many others did not; the experiment was not repeated.

Since Germany's adoption in 1916, the world has seen many enactments, adjustments, and repeals of DST, with similar politics involved. The history of time in the United States includes DST during both world wars, but no standardization of peacetime DST until 1966. St. Paul and Minneapolis, Minnesota, were on different times for two weeks in May 1965 when the capital city decided to join most of the nation by starting Daylight Saving Time, while Minneapolis opted to follow the later date set by state law. In the mid-1980s, Clorox and 7-Eleven provided the primary funding for the Daylight Saving Time Coalition behind the 1987 extension to U.S. DST, and both senators from Idaho voted for it based on the premise that fast-food restaurants sell more French fries during DST, which are made from Idaho potatoes.

A referendum on daylight saving was held in Queensland, Australia, in 1992, after a three-year trial of daylight saving. It was defeated with a 54.5% "no" vote, with regional and rural areas strongly opposed, while those in the metropolitan southeast were in favor. In 2005, the Sporting Goods Manufacturers Association and the National Association of Convenience Stores successfully lobbied for the 2007 extension to U.S. DST. In December 2008, the Daylight Saving for South East Queensland (DS4SEQ) political party was officially registered in Queensland, advocating the implementation of a dual-time zone arrangement for daylight saving in South East Queensland, while the rest of the state maintains standard time. DS4SEQ contested the March 2009 Queensland state election with 32 candidates and received one percent of the statewide primary vote, equating to around 2.5% across the 32 electorates contested. After a three-year trial, more than 55% of Western Australians voted against DST in 2009, with rural areas strongly opposed. Queensland Independent member Peter Wellington introduced the Daylight Saving for South East Queensland Referendum Bill 2010 into the Queensland parliament on April 14, 2010, after being approached by the DS4SEQ political party, calling for a referendum at the next state election on the introduction of daylight saving into South East Queensland under a dual-time zone arrangement. The Bill was defeated in the Queensland parliament on June 15, 2011.

In the UK, the Royal Society for the Prevention of Accidents supports a proposal to observe SDST's additional hour year-round, but that is opposed in some industries, such as postal workers and farmers, and particularly by those living in the northern regions of the UK. In some Muslim countries, DST is temporarily abandoned during Ramadan (the month when no food should be eaten between sunrise and sunset), since the DST would delay the evening dinner. Iran maintains DST during Ramadan, but most Muslim countries do not use DST, partially for this reason.

Russia declared in 2011 that it would stay in DST all year long, followed by a similar declaration from Belarus. Russia's plan generated widespread complaints due to the dark of winter time morning, and thus was abandoned in 2014. The country changed its clocks to Standard Time on October 26, 2014 and intends to stay there permanently.

Proponents of DST generally argue that it saves energy, promotes outdoor leisure activity in the evening (in summer), and is therefore good for physical and psychological health, reduces traffic accidents, reduces crime or is good for business. 

Opponents argue that actual energy savings are inconclusive, that DST increases health risks such as heart attack, that DST can disrupt morning activities, and that the act of changing clocks twice a year is economically and socially disruptive and cancels out any benefit. Farmers have tended to oppose DST.

Having a common agreement about the day's layout or schedule has so many advantages that a standard schedule over whole countries or large areas has generally been chosen over efforts in which some people get up earlier and others do not. The advantages of coordination are so great that many people ignore whether DST is in effect by altering their work schedules to coordinate with television broadcasts or daylight. DST is commonly not observed during most of winter, because the days are shorter then; workers may have no sunlit leisure time, and students may need to leave for school in the dark. Since DST is applied to many varying communities, its effects may be very different depending on their culture, light levels, geography, and climate. Because of this variation, it is hard to make generalized conclusions about the effects of the practice. The costs and benefits may differ between places. Some areas may adopt DST simply as a matter of coordination with other areas rather than for any other benefits.

A 2017 meta-analysis of 44 studies found that DST leads to electricity savings of only 0.34% during the days when DST applies. The meta-analysis furthermore found that "electricity savings are larger for countries farther away from the equator, while subtropical regions consume more electricity because of DST." This means that DST may conserve electricity in some countries, such as Canada and the United Kingdom, but be wasteful in other places, such as Mexico, the southern United States, and northern Africa. The savings in electricity may also be offset by extra use of other types of energy, such as heating fuel.

The period of Daylight Saving Time before the longest day is shorter than the period after, in several countries including the United States and Europe. For example, in the U.S. the period of Daylight Saving Time is defined by the Energy Policy Act of 2005. The period for Daylight Saving Time was extended by changing the start date from the first Sunday of April to the second Sunday of March, and the end date from the last Sunday in October to the first Sunday in November.

DST's potential to save energy comes primarily from its effects on residential lighting, which consumes about 3.5% of electricity in the United States and Canada. (For comparison, air conditioning uses 16.5% of energy in the United States.) Delaying the nominal time of sunset and sunrise reduces the use of artificial light in the evening and increases it in the morning. As Franklin's 1784 satire pointed out, lighting costs are reduced if the evening reduction outweighs the morning increase, as in high-latitude summer when most people wake up well after sunrise. An early goal of DST was to reduce evening usage of incandescent lighting, once a primary use of electricity. Although energy conservation remains an important goal, energy usage patterns have greatly changed since then. Electricity use is greatly affected by geography, climate, and economics, so the results of a study conducted in one place may not be relevant to another country or climate.

Several studies have suggested that DST increases motor fuel consumption. The 2008 DOE report found no significant increase in motor gasoline consumption due to the 2007 United States extension of DST.

Those who benefit most from DST are the retailers, sporting goods makers, and other businesses that benefit from extra afternoon sunlight. Having more hours of sunlight in between the end of the typical workday and bedtime induces customers to shop and to participate in outdoor afternoon sports. People are more likely to stop by a store on their way home from work if the sun is still up. In 1984, "Fortune" magazine estimated that a seven-week extension of DST would yield an additional $30 million for 7-Eleven stores, and the National Golf Foundation estimated the extension would increase golf industry revenues $200 million to $300 million. A 1999 study estimated that DST increases the revenue of the European Union's leisure sector by about 3%.

Conversely, DST can harm some farmers, young children, who have difficulty getting enough sleep at night when the evenings are bright, and others whose hours are set by the sun. One reason why farmers oppose DST is that grain is best harvested after dew evaporates, so when field hands arrive and leave earlier in summer, their labor is less valuable. Dairy farmers are another group who complain of the change. Their cows are sensitive to the timing of milking, so delivering milk earlier disrupts their systems. Today some farmers' groups are in favor of DST.

DST also hurts prime-time television broadcast ratings, drive-ins and other theaters.

Changing clocks and DST rules has a direct economic cost, entailing extra work to support remote meetings, computer applications and the like. For example, a 2007 North American rule change cost an estimated $500 million to $1 billion, and Utah State University economist William F. Shughart II has estimated the lost opportunity cost at around US$1.7 billion. Although it has been argued that clock shifts correlate with decreased economic efficiency, and that in 2000 the daylight-saving effect implied an estimated one-day loss of $31 billion on U.S. stock exchanges, the estimated numbers depend on the methodology. The results have been disputed, and the original authors have refuted the points raised by disputers.

In 1975 the United States Department of Transportation (DOT) conservatively identified a 0.7% reduction in traffic fatalities during DST, and estimated the real reduction at 1.5% to 2%, but the 1976 NBS review of the DOT study found no differences in traffic fatalities. In 1995 the Insurance Institute for Highway Safety estimated a reduction of 1.2%, including a 5% reduction in crashes fatal to pedestrians. Others have found similar reductions. Single/Double Summer Time (SDST), a variant where clocks are one hour ahead of the sun in winter and two in summer, has been projected to reduce traffic fatalities by 3% to 4% in the UK, compared to ordinary DST. However, accidents do increase by as much as 11% during the two weeks that follow the end of British Summer Time. It is not clear whether sleep disruption contributes to fatal accidents immediately after the spring clock shifts. A correlation between clock shifts and traffic accidents has been observed in North America and the UK but not in Finland or Sweden. Four reports have found that this effect is smaller than the overall reduction in traffic fatalities. A 2009 U.S. study found that on Mondays after the switch to DST, workers sleep an average of 40 minutes less, and are injured at work more often and more severely.

DST likely reduces some kinds of crime, such as robbery and sexual assault, as fewer potential victims are outdoors after dusk. Artificial outdoor lighting has a marginal and sometimes even contradictory influence on crime and fear of crime.

In several countries, fire safety officials encourage citizens to use the two annual clock shifts as reminders to replace batteries in smoke and carbon monoxide detectors, particularly in autumn, just before the heating and candle season causes an increase in home fires. Similar twice-yearly tasks include reviewing and practicing fire escape and family disaster plans, inspecting vehicle lights, checking storage areas for hazardous materials, reprogramming thermostats, and seasonal vaccinations. Locations without DST can instead use the first days of spring and autumn as reminders.

A 2017 study in the "American Economic Journal: Applied Economics" estimated that "the transition into DST caused over 30 deaths at a social cost of $275 million annually," primarily by increasing sleep deprivation.

DST has mixed effects on health. In societies with fixed work schedules it provides more afternoon sunlight for outdoor exercise. It alters sunlight exposure; whether this is beneficial depends on one's location and daily schedule, as sunlight triggers vitamin D synthesis in the skin, but overexposure can lead to skin cancer. DST may help in depression by causing individuals to rise earlier, but some argue the reverse. The Retinitis Pigmentosa Foundation Fighting Blindness, chaired by blind sports magnate Gordon Gund, successfully lobbied in 1985 and 2005 for U.S. DST extensions. DST shifts are associated with higher rates of ischemic stroke in the first two days after the shift, though not in the week thereafter.

Clock shifts were found to increase the risk of heart attack by 10 percent, and to disrupt sleep and reduce its efficiency. Effects on seasonal adaptation of the circadian rhythm can be severe and last for weeks. A 2008 study found that although male suicide rates rise in the weeks after the spring transition, the relationship weakened greatly after adjusting for season. A 2008 Swedish study found that heart attacks were significantly more common the first three weekdays after the spring transition, and significantly less common the first weekday after the autumn transition. A 2013 review found little evidence that people slept more on the night after the fall DST shift, even though it is often described as allowing people to sleep for an hour longer than normal. The same review stated that the lost hour of sleep resulting from the spring shift appears to result in sleep loss for at least a week afterward. In 2015, two psychologists recommended that DST be abolished, citing its disruptive effects on sleep as one reason for this recommendation.

The government of Kazakhstan cited health complications due to clock shifts as a reason for abolishing DST in 2005. In March 2011, Dmitri Medvedev, president of Russia, claimed that "stress of changing clocks" was the motivation for Russia to stay in DST all year long. Officials at the time talked about an annual increase in suicides.

An unexpected adverse effect of daylight saving time may lie in the fact that an extra part of morning rush hour traffic occurs before dawn and traffic emissions then cause higher air pollution than during daylight hours.

In 2017, researchers at the University of Washington and the University of Virginia reported that judges who experienced sleep deprivation as a result of DST tended to issue longer sentences.

DST's clock shifts have the obvious disadvantage of complexity. People must remember to change their clocks; this can be time-consuming, particularly for mechanical clocks that cannot be moved backward safely. People who work across time zone boundaries need to keep track of multiple DST rules, as not all locations observe DST or observe it the same way. The length of the calendar day becomes variable; it is no longer always 24 hours. Disruption to meetings, travel, broadcasts, billing systems, and records management is common, and can be expensive. During an autumn transition from 02:00 to 01:00, a clock reads times from 01:00:00 through 01:59:59 twice, possibly leading to confusion.

Damage to a German steel facility occurred during a DST transition in 1993, when a computer timing system linked to a radio time synchronization signal allowed molten steel to cool for one hour less than the required duration, resulting in spattering of molten steel when it was poured. Medical devices may generate adverse events that could harm patients, without being obvious to clinicians responsible for care. These problems are compounded when the DST rules themselves change; software developers must test and perhaps modify many programs, and users must install updates and restart applications. Consumers must update devices such as programmable thermostats with the correct DST rules or manually adjust the devices' clocks. A common strategy to resolve these problems in computer systems is to express time using the Coordinated Universal Time (UTC) rather than the local time zone. For example, Unix-based computer systems use the UTC-based Unix time internally.

Some clock-shift problems could be avoided by adjusting clocks continuously or at least more gradually—for example, Willett at first suggested weekly 20-minute transitions—but this would add complexity and has never been implemented.

DST inherits and can magnify the disadvantages of standard time. For example, when reading a sundial, one must compensate for it along with time zone and natural discrepancies. Also, sun-exposure guidelines such as avoiding the sun within two hours of noon become less accurate when DST is in effect.

As explained by Richard Meade in the English Journal of the (American) National Council of Teachers of English, the form "daylight savings time" (with an "s") was already in 1978 much more common than the older form "daylight saving time" in American English ("the change has been virtually accomplished"). Nevertheless, even dictionaries such as Merriam-Webster's, American Heritage, and Oxford, which describe actual usage instead of prescribing outdated usage (and therefore also list the newer form), still list the older form first. This is because the older form is still very common in print and preferred by many editors. ("Although "daylight saving time" is considered correct, "daylight savings time" (with an "s") is commonly used.") The first two words are sometimes hyphenated ("daylight-saving(s) time"). Merriam-Webster's also lists the forms daylight saving (without "time"), daylight savings (without "time"), and daylight time. The Oxford Dictionary of American Usage and Style explains the development and current situation as follows: "Although the singular form "daylight saving time" is the original one, dating from the early 20th century—and is preferred by some usage critics—the plural form is now extremely common in AmE. [...] The rise of "daylight savings time" appears to have resulted from the avoidance of a miscue: when "saving" is used, readers might puzzle momentarily over whether "saving" is a gerund (the saving of daylight) or a participle (the time for saving). [...] Using "savings" as the adjective—as in "savings account" or "savings bond"—makes perfect sense. More than that, it ought to be accepted as the better form."

In Britain, Willett's 1907 proposal used the term "daylight saving", but by 1911 the term "summer time" replaced "daylight saving time" in draft legislation. The same or similar expressions are used in many other languages: "Sommerzeit" in German, "zomertijd" in Dutch, "kesäaika" in Finnish, "horario de verano" or "hora de verano" in Spanish, and "heure d'été" in French.

The name of local time typically changes when DST is observed. American English replaces "standard" with "daylight": for example, "Pacific Standard Time" ("PST") becomes "Pacific Daylight Time" ("PDT"). In the United Kingdom, the standard term for UK time when advanced by one hour is "British Summer Time" (BST), and British English typically inserts "summer" into other time zone names, e.g. "Central European Time" ("CET") becomes "Central European Summer Time" ("CEST").

The North American English mnemonic "spring forward, fall back" (also "spring ahead ...", "spring up ...", and "... fall behind") helps people remember in which direction to shift the clocks.

Changes to DST rules cause problems in existing computer installations. For example, the 2007 change to DST rules in North America required that many computer systems be upgraded, with the greatest impact on e-mail and calendar programs. The upgrades required a significant effort by corporate information technologists.

Some applications standardize on UTC to avoid problems with clock shifts and time zone differences.
Likewise, most modern operating systems internally handle and store all times as UTC and only convert to local time for display.

However, even if UTC is used internally, the systems still require external leap second updates and time zone information to correctly calculate local time as needed. Many systems in use today base their date/time calculations from data derived from the tz database also known as zoneinfo.

The tz database maps a name to the named location's historical and predicted clock shifts. This database is used by many computer software systems, including most Unix-like operating systems, Java, and the Oracle RDBMS; HP's "tztab" database is similar but incompatible. When temporal authorities change DST rules, zoneinfo updates are installed as part of ordinary system maintenance. In Unix-like systems the TZ environment variable specifies the location name, as in codice_1. In many of those systems there is also a system-wide setting that is applied if the TZ environment variable is not set: this setting is controlled by the contents of the file, which is usually a symbolic link or hard link to one of the zoneinfo files. Internal time is stored in timezone-independent epoch time; the TZ is used by each of potentially many simultaneous users and processes to independently localize time display.

Older or stripped-down systems may support only the TZ values required by POSIX, which specify at most one start and end rule explicitly in the value. For example, codice_2 specifies time for the eastern United States starting in 2007. Such a TZ value must be changed whenever DST rules change, and the new value applies to all years, mishandling some older timestamps.

As with zoneinfo, a user of Microsoft Windows configures DST by specifying the name of a location, and the operating system then consults a table of rule sets that must be updated when DST rules change. Procedures for specifying the name and updating the table vary with release. Updates are not issued for older versions of Microsoft Windows. Windows Vista supports at most two start and end rules per time zone setting. In a Canadian location observing DST, a single Vista setting supports both 1987–2006 and post-2006 time stamps, but mishandles some older time stamps. Older Microsoft Windows systems usually store only a single start and end rule for each zone, so that the same Canadian setting reliably supports only post-2006 time stamps.

These limitations have caused problems. For example, before 2005, DST in Israel varied each year and was skipped some years. Windows 95 used rules correct for 1995 only, causing problems in later years. In Windows 98, Microsoft marked Israel as not having DST, forcing Israeli users to shift their computer clocks manually twice a year. The 2005 Israeli Daylight Saving Law established predictable rules using the Jewish calendar but Windows zone files could not represent the rules' dates in a year-independent way. Partial workarounds, which mishandled older time stamps, included manually switching zone files every year and a Microsoft tool that switches zones automatically. In 2013, Israel standardized its daylight saving time according to the Gregorian calendar.

Microsoft Windows keeps the system real-time clock in local time. This causes several problems, including compatibility when multi booting with operating systems that set the clock to UTC, and double-adjusting the clock when multi booting different Windows versions, such as with a rescue boot disk. This approach is a problem even in Windows-only systems: there is no support for per-user timezone settings, only a single system-wide setting. In 2008 Microsoft hinted that future versions of Windows will partially support a Windows registry entry RealTimeIsUniversal that had been introduced many years earlier, when Windows NT supported RISC machines with UTC clocks, but had not been maintained. Since then at least two fixes related to this feature have been published by Microsoft.

The NTFS file system used by recent versions of Windows stores the file with a UTC time stamp, but displays it corrected to local—or seasonal—time. However, the FAT filesystem commonly used on removable devices stores only the local time. Consequently, when a file is copied from the hard disk onto separate media, its time will be set to the current local time. If the time adjustment is changed, the timestamps of the original file and the copy will be different. The same effect can be observed when compressing and uncompressing files with some file archivers. It is the NTFS file that changes seen time. This effect should be kept in mind when trying to determine if a file is a duplicate of another, although there are other methods of comparing files for equality (such as using a checksum algorithm). A ready clue is if the time stamps differ by precisely 1 hour.

A move to "permanent daylight saving time" (staying on summer hours all year with no time shifts) is sometimes advocated and is currently implemented in some jurisdictions such as Argentina, Belarus, Canada (e.g. Saskatchewan), Iceland, Kyrgyzstan, Malaysia, Morocco, Namibia, Singapore, Turkey, Turkmenistan and Uzbekistan. It could be a result of following the timezone of a neighbouring region, political will, or other causes. Advocates cite the same advantages as normal DST without the problems associated with the twice yearly time shifts. However, many remain unconvinced of the benefits, citing the same problems and the relatively late sunrises, particularly in winter, that year-round DST entails.

Russia switched to permanent DST from 2011 to 2014, but the move proved unpopular because of the late sunrises in winter, so the country switched permanently back to standard time in 2014 for the whole Russian Federation. The United Kingdom and Ireland also experimented with year-round summer time between 1968 and 1971, and put clocks forward by an extra hour during World War II.

In the United States, the Florida legislature passed a bill to enact permanent DST; and California, Maine, Massachusetts, New Hampshire, and Rhode Island have introduced proposals or commissions to that effect. Although 26 states have considered making DST permanent, unless Congress changes federal law, states can not implement permanent DST—states can only opt out of DST, not standard time.





</doc>
<doc id="47801" url="https://en.wikipedia.org/wiki?curid=47801" title="H.M.S. Pinafore">
H.M.S. Pinafore

H.M.S. Pinafore; or, The Lass That Loved a Sailor is a comic opera in two acts, with music by Arthur Sullivan and a libretto by W. S. Gilbert. It opened at the Opera Comique in London, on 25 May 1878 and ran for 571 performances, which was the second-longest run of any musical theatre piece up to that time. "H.M.S. Pinafore" was Gilbert and Sullivan's fourth operatic collaboration and their first international sensation.

The story takes place aboard the ship HMS "Pinafore". The captain's daughter, Josephine, is in love with a lower-class sailor, Ralph Rackstraw, although her father intends her to marry Sir Joseph Porter, the First Lord of the Admiralty. She abides by her father's wishes at first, but Sir Joseph's advocacy of the equality of humankind encourages Ralph and Josephine to overturn conventional social order. They declare their love for each other and eventually plan to elope. The captain discovers this plan, but, as in many of the Gilbert and Sullivan operas, a surprise disclosure changes things dramatically near the end of the story.

Drawing on several of his earlier "Bab Ballad" poems, Gilbert imbued this plot with mirth and silliness. The opera's humour focuses on love between members of different social classes and lampoons the British class system in general. "Pinafore" also pokes good-natured fun at patriotism, party politics, the Royal Navy, and the rise of unqualified people to positions of authority. The title of the piece comically applies the name of a garment for girls and women, a pinafore, to the fearsome symbol of a warship.

"Pinafore's" extraordinary popularity in Britain, America and elsewhere was followed by the similar success of a series of Gilbert and Sullivan works, including "The Pirates of Penzance" and "The Mikado". Their works, later known as the Savoy operas, dominated the musical stage on both sides of the Atlantic for more than a decade and continue to be performed today. The structure and style of these operas, particularly "Pinafore", were much copied and contributed significantly to the development of modern musical theatre.

In 1875, Richard D'Oyly Carte, who was then managing the Royalty Theatre for Selina Dolaro, brought Gilbert and Sullivan together to write their second show, a one-act opera entitled "Trial by Jury". This proved a success, and in 1876 D'Oyly Carte assembled a group of financial backers to establish the Comedy Opera Company, which was devoted to the production and promotion of family-friendly English comic opera. With this theatre company, Carte finally had the financial resources, after many failed attempts, to produce a new full-length Gilbert and Sullivan opera. This next opera was "The Sorcerer", which opened in November 1877. It too was successful, running for 178 performances. Sheet music from the show sold well, and street musicians played the melodies.

Instead of writing a piece for production by a theatre proprietor, as was usual in Victorian theatres, Gilbert, Sullivan and Carte produced the show with their own financial support. They were therefore able to choose their own cast of performers, rather than being obliged to use the actors already engaged at the theatre. They chose talented actors, most of whom were not well-known stars and did not command high fees, and to whom they could teach a more naturalistic style of performance than was commonly used at the time. They then tailored their work to the particular abilities of these performers. The skill with which Gilbert and Sullivan used their performers had an effect on the audience; as critic Herman Klein wrote: "we secretly marvelled at the naturalness and ease with which [the Gilbertian quips and absurdities] were said and done. For until then no living soul had seen upon the stage such weird, eccentric, yet intensely human beings. ... [They] conjured into existence a hitherto unknown comic world of sheer delight."
The success of "The Sorcerer" paved the way for another collaboration by Gilbert and Sullivan. Carte agreed on terms for a new opera with the Comedy Opera Company, and Gilbert began work on "H.M.S. Pinafore" before the end of 1877. Gilbert's father had been a naval surgeon, and the nautical theme of the opera appealed to him. He drew on several of his earlier "Bab Ballad" poems (many of which also have nautical themes), including "Captain Reece" (1868) and "General John" (1867). Some of the characters also have prototypes in the ballads: Dick Deadeye is based on a character in "Woman's Gratitude" (1869); an early version of Ralph Rackstraw can be seen in "Joe Go-Lightly" (1867), with its sailor madly in love with the daughter of someone who far outranks him; and Little Buttercup is taken almost wholesale from "The Bumboat Woman's Story" (1870). On 27 December 1877, while Sullivan was on holiday on the French Riviera, Gilbert sent him a plot sketch accompanied by the following note:
Despite Gilbert's disclaimer, audiences, critics and even the Prime Minister identified Sir Joseph Porter with W. H. Smith, a politician who had recently been appointed First Lord of the Admiralty despite having neither military nor nautical experience. Sullivan was delighted with the sketch, and Gilbert read a first draft of the plot to Carte in mid-January.

Following the example of his mentor, T. W. Robertson, Gilbert strove to ensure that the costumes and sets were as realistic as possible. When preparing the sets for "H.M.S. Pinafore", Gilbert and Sullivan visited Portsmouth in April 1878 to inspect ships. Gilbert made sketches of H.M.S. "Victory" and H.M.S. "St Vincent" and created a model set for the carpenters to work from. This was far from standard procedure in Victorian drama, in which naturalism was still a relatively new concept, and in which most authors had very little influence on how their plays and libretti were staged. This attention to detail was typical of Gilbert's stage management and would be repeated in all of his Savoy Operas. Gilbert's focus on visual accuracy provided a "right-side-up for topsy-turvydom", that is, a realistic point of reference that serves to heighten the whimsicality and absurdity of the situations. Sullivan was "in the full swing" of work on the piece by the middle of April 1878. The bright and cheerful music of "Pinafore" was composed during a time when Sullivan suffered from excruciating pain from a kidney stone. The cast began music rehearsals on 24 April, and at the beginning of May 1878, the two collaborators worked closely together at Sullivan's flat to finalise the piece.

In "Pinafore", Gilbert, Sullivan and Carte used several of the principal cast members whom they had assembled for "The Sorcerer". As Gilbert had suggested to Sullivan in December 1877, "Mrs. Cripps [Little Buttercup] will be a capital part for Everard ... Barrington will be a capital captain, and Grossmith a first-rate First Lord." However, Mrs Howard Paul, who had played Lady Sangazure in "The Sorcerer", was declining vocally. She was under contract to play the role of Cousin Hebe in "Pinafore". Gilbert made an effort to write an amusing part for her despite Sullivan's reluctance to use her, but by mid-May 1878, both Gilbert and Sullivan wanted her out of the cast; unhappy with the role, she left. With only a week to go before opening night, Carte hired a concert singer, Jessie Bond, to play Cousin Hebe. Since Bond had little experience as an actress, Gilbert and Sullivan cut the dialogue out of the role, except for a few lines in the last scene, which they turned into recitative. Other new cast members were Emma Howson and George Power in the romantic roles, who were improvements on the romantic soprano and tenor in "The Sorcerer".

Gilbert acted as stage director for his own plays and operas. He sought realism in acting, just as he strove for realistic visual elements. He deprecated self-conscious interaction with the audience and insisted on a style of portrayal in which the characters were never aware of their own absurdity but were coherent internal wholes. Sullivan conducted the music rehearsals. As was to be his usual practice in his later operas, Sullivan left the overture for the last moment, sketching it out and entrusting it to the company's music director, in this case Alfred Cellier, to complete. "Pinafore" opened on 25 May 1878 at the Opera Comique.


The British warship H.M.S. "Pinafore" is at anchor off Portsmouth. The sailors are on the quarterdeck, proudly "cleaning brasswork, splicing rope, etc."

Little Buttercup, a Portsmouth "bumboat woman" (dockside vendor) – who is the "rosiest, roundest, and reddest beauty in all Spithead" – comes on board to sell her wares to the crew. She hints that she may be hiding a dark secret under her "gay and frivolous exterior". Ralph Rackstraw, "the smartest lad in all the fleet", enters, declaring his love for the Captain's daughter, Josephine. His fellow sailors (excepting Dick Deadeye, the grim and ugly realist of the crew) offer their sympathies, but they can give Ralph little hope that his love will ever be returned.
The gentlemanly and popular Captain Corcoran greets his "gallant crew" and compliments them on their politeness, saying that he returns the favour by never ("well, hardly ever") using bad language, such as "a big, big D". After the sailors leave, the Captain confesses to Little Buttercup that Josephine is reluctant to consider a marriage proposal from Sir Joseph Porter, the First Lord of the Admiralty. Buttercup says that she knows how it feels to love in vain. As she leaves, the Captain remarks that she is "a plump and pleasing person". Josephine enters and reveals to her father that she loves a humble sailor in his crew, but she assures him that she is a dutiful daughter and will never reveal her love to this sailor.

Sir Joseph comes on board, accompanied by his "admiring crowd of sisters, cousins and aunts". He recounts how he rose from humble beginnings to be "ruler of the Queen's Navee" through persistence, although he has no naval qualifications. He then delivers a humiliating lesson in etiquette, telling the Captain that he must always say "if you please" after giving an order; for "A British sailor is any man's equal" – excepting Sir Joseph's. Sir Joseph has composed a song to illustrate that point, and he gives a copy of it to Ralph. Shortly afterwards, elated by Sir Joseph's views on equality, Ralph decides that he will declare his love to Josephine. This delights his shipmates, except Dick Deadeye, who contends that "when people have to obey other people's orders, equality's out of the question". Shocked by his words, the other sailors force Dick to listen to Sir Joseph's song before they exit, leaving Ralph alone on deck. Josephine now enters, and Ralph confesses his love in terms surprisingly eloquent for a "common sailor". Josephine is touched, but although she has found Sir Joseph's attentions nauseating, she knows that it is her duty to marry Sir Joseph instead of Ralph. Disguising her true feelings, she "haughtily rejects" Ralph's "proffered love".

Ralph summons his shipmates (Sir Joseph's female relatives also arrive) and tells them that he is bent on suicide. The crew expresses sympathy, except for Dick, who provides a stark counterpoint of dissent. Ralph puts a pistol to his head, but as he is about to pull the trigger, Josephine enters, admitting that she loves him after all. Ralph and Josephine plan to sneak ashore to elope that night. Dick Deadeye warns them to "forbear, nor carry out the scheme", but the joyous ship's company ignores him.

Later that night, under a full moon, Captain Corcoran reviews his concerns: his "kindly crew rebels", his "daughter to a tar is partial", his friends seem to desert him, and Sir Joseph has threatened a court-martial. Little Buttercup offers sympathy. He tells her that, if it were not for the difference in their social standing, he would have returned her affection. She prophesies that things are not all as they seem and that "a change" is in store for him, but he does not understand her cryptic warning.

Sir Joseph enters and complains that Josephine has not yet agreed to marry him. The Captain speculates that she is probably dazzled by his "exalted rank" and that if Sir Joseph can persuade her that "love levels all ranks", she will accept his proposal. They withdraw, and Josephine enters, still feeling guilty about her planned elopement with Ralph and fearful of giving up a life of luxury. When Sir Joseph makes the argument that "love levels all ranks", a delighted Josephine says that she "will hesitate no longer". The Captain and Sir Joseph rejoice, but Josephine is now more determined than ever to marry Ralph.

Dick Deadeye intercepts the Captain and tells him of the lovers' plans to elope. The Captain confronts Ralph and Josephine as they try to leave the ship. The pair declare their love, justifying their actions because "He is an Englishman!" The furious Captain is unmoved and blurts out, "Why, damme, it's too bad!" Sir Joseph and his relatives, who have overheard this oath, are shocked to hear swearing on board a ship, and Sir Joseph orders the Captain confined to his cabin.

When Sir Joseph asks what had provoked the usually polite officer's outburst, Ralph replies that it was his declaration of love for Josephine. Furious in his turn at this revelation, and ignoring Josephine's plea to spare Ralph, Sir Joseph has the sailor "loaded with chains" and taken to the ship's brig. Little Buttercup now comes forward to reveal her long-held secret. Many years ago, when she "practised baby-farming", she had cared for two babies, one "of low condition", the other "a regular patrician". She confesses that she "mixed those children up. ... The wellborn babe was Ralph; your Captain was the other."

Sir Joseph now realises that Ralph should have been the Captain, and the Captain should have been Ralph. He summons both, and they emerge wearing each other's uniforms: Ralph as Captain, in command of the "Pinafore", and Corcoran as a common sailor. Sir Joseph's marriage with Josephine is now "out of the question" in his eyes: "love levels all ranks ... to a considerable extent, but it does not level them as much as that." He hands her to Captain Rackstraw. The former Captain's now-humble social rank leaves him free to marry Buttercup. Sir Joseph settles for his cousin Hebe, and all ends in general rejoicing.





"See discussion of versions, below."

"Includes reprises of several songs, concluding with "For he is an Englishman"."

"Pinafore" opened on 25 May 1878 at the Opera Comique, before an enthusiastic audience, with Sullivan conducting. Soon, however, the piece suffered from weak ticket sales, generally ascribed to a heat wave that made the Opera Comique particularly uncomfortable. The historian Michael Ainger questions this explanation, at least in part, stating that the heat waves in the summer of 1878 were short and transient. By mid-August, Sullivan wrote to his mother that cooler weather had arrived, which was good for the show. In the meantime, the four partners of the Comedy Opera Company lost confidence in the opera's viability and posted closing notices. Carte publicised the piece by presenting a matinee concert performance on 6 July 1878 at the enormous Crystal Palace.

In late August 1878, Sullivan used some of the "Pinafore" music, arranged by his assistant Hamilton Clarke, during several successful promenade concerts at Covent Garden that generated interest and stimulated ticket sales. By September, "Pinafore" was playing to full houses at the Opera Comique. The piano score sold 10,000 copies, and Carte soon sent two additional companies out to tour in the provinces.

Carte, Gilbert and Sullivan now had the financial resources to produce shows themselves, without outside backers. Carte persuaded the author and composer that a business partnership among the three would be to their advantage, and they hatched a plan to separate themselves from the directors of the Comedy Opera Company. The contract between Gilbert and Sullivan and the Comedy Opera Company gave the latter the right to present "Pinafore" for the duration of the initial run. The Opera Comique was obliged to close for drain and sewer repairs, and it was renovated by E. W. Bradwell, from Christmas 1878 to the end of January 1879. Gilbert, Sullivan and Carte believed that this break ended the initial run, and, therefore, ended the company's rights. Carte put the matter beyond doubt by taking a six-month personal lease of the theatre beginning on 1 February 1879, the date of its re-opening, when "Pinafore" resumed. At the end of the six months, Carte planned to give notice to the Comedy Opera Company that its rights in the show and the theatre had ended.

Meanwhile, numerous versions of "Pinafore", unauthorised by its creators, began playing in America with great success, beginning with a production in Boston that opened on 25 November 1878. "Pinafore" became a source of popular quotations on both sides of the Atlantic, such as the exchange:

<poem style="margin-left: 2em;">"What, never?"
"No, never!"
"What, "never?""
"Well, hardly ever!"</poem>
In February 1879, "Pinafore" resumed operations at the Opera Comique. The opera also resumed touring in April, with two companies crisscrossing the British provinces by June, one starring Richard Mansfield as Sir Joseph, the other W. S. Penley in the role. Hoping to join in on the profits to be made in America from "Pinafore", Carte left in June for New York to make arrangements for an "authentic" production there to be rehearsed personally by the author and composer. He arranged to rent a theatre and auditioned chorus members for the American production of "Pinafore" and a new Gilbert and Sullivan opera to be premiered in New York, and for tours.

Sullivan, as had been arranged with Carte and Gilbert, gave notice to the partners of the Comedy Opera Company in early July 1879 that he, Gilbert and Carte would not be renewing the contract to produce "Pinafore" with them and that he would be withdrawing his music from the Comedy Opera Company on 31 July. In return, the Comedy Opera Company gave notice that they intended to play "Pinafore" at another theatre and brought a legal action against Carte and company. They offered the London and touring casts of "Pinafore" more money to play in their production, and although some choristers accepted their offer, only one principal player, Aeneas Joseph Dymott, accepted. They engaged the Imperial Theatre but had no scenery. On 31 July, they sent a group of thugs to seize the scenery and props during Act II of the evening performance at the Opera Comique. Gilbert was away, and Sullivan was recovering from an operation for kidney stones. Stagehands and cast members managed to ward off their backstage attackers and protect the scenery, although the stage manager, Richard Barker, and others, were injured. The cast went on with the show until someone shouted "Fire!" George Grossmith, playing Sir Joseph, went before the curtain to calm the panicked audience. The police arrived to restore order, and the show continued. Gilbert sued to stop the Comedy Opera Company from staging their rival production of "H.M.S. Pinafore". The court permitted the production to go on at the Imperial, beginning on 1 August 1879, and it transferred to the Olympic Theatre in September. Pauline Rita was one of a series of Josephines. The production received good notices and initially sold well but was withdrawn in October after 91 performances. The matter was eventually settled in court, where a judge ruled in Carte's favour about two years later.

After his return to London, Carte formed a new partnership with Gilbert and Sullivan to divide profits equally after the expenses of each of their shows. Meanwhile, "Pinafore" continued to play strongly. On 20 February 1880, "Pinafore" completed its initial run of 571 performances. Only one other work of musical theatre in the world had ever run longer, Robert Planquette's operetta "Les cloches de Corneville".

Approximately 150 unauthorised productions of "Pinafore" sprang up in the United States in 1878 and 1879, and none of these paid royalties to the authors. Gilbert and Sullivan called them "pirated", although the creators did not have any international copyright protection. The first of these productions, opening at the Boston Museum on 25 November 1878, made such a splash that the piece was quickly produced in major cities and on tour by dozens of companies throughout the country. Boston alone saw at least a dozen productions, including a juvenile version described by Louisa May Alcott in her 1879 story, "Jimmy's Cruise in the Pinafore". In New York, different productions of the piece played simultaneously in eight theatres within five blocks of each other and in six theatres in Philadelphia.
These unauthorised performances took many forms, including burlesques, productions with men playing women's roles and vice versa, spoofs, variety acts, Minstrel show versions, all-black and Catholic productions, German, Yiddish and other foreign-language versions, performances on boats or by church choirs, and productions starring casts of children. Few purported to play the opera as written. Sheet music arrangements were popular, there were "Pinafore"-themed dolls and household items, and references to the opera were common in advertising, news and other media. Gilbert, Sullivan and Carte brought lawsuits in the U.S. and tried for many years to control the American performance copyrights over their operas, or at least to claim some royalties, without success. They made a special effort to claim American rights for their next work after "Pinafore", "The Pirates of Penzance", by giving the official premiere in New York.

Gilbert, Sullivan and Carte met by 24 April 1879 to make plans for a production of "Pinafore" in America. Carte travelled to New York in the summer of 1879 and made arrangements with theatre manager John T. Ford to present, at the Fifth Avenue Theatre, the first authorised American production of "Pinafore". In November, Carte returned to America with Gilbert, Sullivan and a company of strong singers, including J. H. Ryley as Sir Joseph, Blanche Roosevelt as Josephine, Alice Barnett as Little Buttercup, Furneaux Cook as Dick Deadeye, Hugh Talbot as Ralph Rackstraw and Jessie Bond as Cousin Hebe. To these, he added some American singers, including Signor Brocolini as Captain Corcoran. Alfred Cellier came to assist Sullivan, while his brother François remained in London to conduct "Pinafore" there.

"Pinafore" opened in New York on 1 December 1879 (with Gilbert onstage in the chorus) and ran for the rest of December. After a reasonably strong first week, audiences quickly fell off, since most New Yorkers had already seen local productions of "Pinafore". This was unexpected and forced Gilbert and Sullivan to race to complete and rehearse their new opera, "The Pirates of Penzance", which premiered with much success on 31 December. Shortly thereafter, Carte sent three touring companies around the United States East Coast and Midwest, playing "Pinafore" alongside "Pirates".

The unauthorised juvenile productions of "Pinafore" were so popular that Carte mounted his own children's version, played at matinees at the Opera Comique beginning on 16 December 1879. François Cellier, who had taken over from his brother as Carte's music director in London, adapted the score for children's voices. Between its two Christmas seasons in London, the children's production went on a provincial tour from 2 August 1880 to 11 December 1880.

Carte's children's production earned enthusiastic reviews from the critic Clement Scott and the other London critics, as well as the audiences, including children. However, Captain Corcoran's curse "Damme!" was uncensored, shocking such prominent audience members as Lewis Carroll, who later wrote: "a bevy of sweet innocent-looking girls sing, with bright and happy looks, the chorus 'He said, Damn me! He said, Damn me!' I cannot find words to convey to the reader the pain I felt in seeing those dear children taught to utter such words to amuse ears grown callous to their ghastly meaning ... How Mr. Gilbert could have stooped to write, or Sir Arthur Sullivan could have prostituted his noble art to set to music, such vile trash, it passes my skill to understand".

After the opera became successful in London, Richard D'Oyly Carte quickly sent touring companies into the British provinces. At least one D'Oyly Carte company, and sometimes as many as three, played "Pinafore" under Carte's aegis every year between 1878 and 1888, including its first London revival in 1887. The opera was then given a rest, returning to the touring repertory between 1894 and 1900 and again for most of the time between 1903 and 1940. Gilbert directed all the revivals during his lifetime, and after his death, the D'Oyly Carte Opera Company had exclusive performing rights to the Savoy operas until 1962. It continued to hew closely to Gilbert's directions throughout that period, as recorded in Gilbert's prompt books, and it also required its licensees to follow them closely.
Until 1908, revivals of the opera were given in contemporary dress, with ladies' costumes executed by couture houses such as Redfern. After that, designers such as Percy Anderson, George Sheringham and Peter Goffin created Victorian costume designs. The 1887 set was designed by Hawes Craven. In the winter of 1940–41, the D'Oyly Carte Opera Company's scenery and costumes for "Pinafore" and three other operas were destroyed by German bombs during World War II. The opera was revived in London in the summer of 1947. It was then included in the D'Oyly Carte repertory in every season from then on, until the company's closure in 1982. The D'Oyly Carte company performed "Pinafore" before Queen Elizabeth II and the royal family at Windsor Castle on 16 June 1977, during the queen's Silver Jubilee year, the first royal command performance of a Gilbert and Sullivan opera since 1891.

The D'Oyly Carte Opera Company did not allow any other professional company to present the Savoy operas in Britain until the copyrights expired at the end of 1961, although it licensed many amateur and school societies to do so, beginning in the 19th century. After 1961, other professional companies mounted productions of the opera in Britain. These have included Tyrone Guthrie's 1960 production from Stratford, Ontario, seen on Broadway in 1960 and in London in 1962 and a New Sadler's Wells Opera Company production first seen on 4 June 1984 at Sadler's Wells Theatre, which was seen also in New York. Scottish Opera, Welsh National Opera and many of the other British opera companies have mounted productions, as did the reconstituted D'Oyly Carte Opera Company between 1990 and its closure in 2003. In recent years, the Carl Rosa Opera Company has produced "Pinafore" several times, including in 2009, and Opera della Luna and other British companies continue to mount the piece.

The extraordinary initial success of "Pinafore" in America was seen first-hand by J. C. Williamson. He soon made arrangements with D'Oyly Carte to present the opera's first authorised production in Australia, opening on 15 November 1879 at the Theatre Royal, Sydney. Thereafter, his opera company played frequent seasons of the work (and the subsequent Savoy operas) until at least 1963. In the U.S., the piece never lost popularity. The Internet Broadway Database links to a non-exhaustive list of 29 productions on Broadway alone. Among the professional repertory companies continuing to present "Pinafore" regularly in the U.S. are Opera a la Carte, based in California, Ohio Light Opera and the New York Gilbert and Sullivan Players, which tours the opera annually and often includes it in its New York seasons. "Pinafore" is still performed around the world by opera companies such as the Royal Theatre, Copenhagen; Australian Opera (and Essgee Entertainment and others in Australia); in Kassel, Germany; and even Samarkand, Uzbekistan.

The following table shows the history of the D'Oyly Carte productions (excluding tours) in Gilbert's lifetime:

The early reviews were mostly favourable. "The Era" wrote:
"The Era" also lavishly praised Emma Howson as Josephine. "The Entr'acte and Limelight" commented that the opera was reminiscent of "Trial by Jury" and "Sorcerer" but found it diverting and called the music "very charming. To hear so-called grand opera imitated through the medium of the most trifling lyrics, is funny". The paper praised Grossmith as Sir Joseph, noting with amusement that he was made up to look like portraits of Horatio Nelson, "and his good introductory song seems levelled at" W. H. Smith. It opined, further, that "He Is an Englishman" is "an excellent satire on the proposition that a man must necessarily be virtuous to be English". It found the piece, as a whole, well presented and predicted that it would have a long run.
Similarly, "The Illustrated London News" concluded that the production was a success and that the plot, though slight, served as a good vehicle for Gilbert's "caustic humour and quaint satire". It found that there was "much to call forth hearty laughter in the occasional satirical hits. ... Dr. Sullivan's music is as lively as the text to which it is set, with here and there a touch of sentimental expression ... The piece is well performed throughout." The "Daily News", "The Globe", "The Times" (which particularly praised Grossmith, Barrington and Everard) and "The Standard" concurred, the last commenting favourably on the chorus acting, which, it said, "adds to the reality of the illusion". "The Times" also noted that the piece was an early attempt at the establishment of a "national musical stage" with a libretto free from risqué French "improprieties" and without the "aid" of Italian and German musical models.

"The Daily Telegraph" and the "Athenaeum", however, greeted the opera with only mixed praise. "The Musical Times" complained that the ongoing collaboration between Gilbert and Sullivan was "detrimental to the art-progress of either" because, although it was popular with audiences, "something higher is demanded for what is understood as 'comic opera'". The paper commented that Sullivan had "the true elements of an artist, which would be successfully developed were a carefully framed libretto presented to him for composition". It concluded, however, by saying how much it enjoyed the opera: "Having thus conscientiously discharged our duties as art-critics, let us at once proceed to say that "H.M.S. Pinafore" is an amusing piece of extravagance, and that the music floats it on merrily to the end". "The Times" and several of the other papers agreed that, while the piece was entertaining, Sullivan was capable of higher art. Only "The Figaro" was actively hostile to the new piece. Upon the publication of the vocal score, a review by "The Academy" joined the chorus of regret that Sullivan had sunk so low as to compose music for "Pinafore" and hoped that he would turn to projects "more worthy of his great ability". This criticism would follow Sullivan throughout his career.

The many unauthorised American productions of 1878–79 were of widely varying quality, and many of them were adaptations of the opera. One of the more "authentic" ones was the production by the Boston Ideal Opera Company, which was first formed to produce "Pinafore". It engaged well-regarded concert singers and opened on 14 April 1879 at the 3,000-seat Boston Theatre. The critics agreed that the company fulfilled its goals of presenting an "ideal" production. The "Boston Journal" reported that the audience was "wrought up by the entertainment to a point of absolute approval". The paper observed that it is a mistake to consider "Pinafore" a burlesque, "for while irresistibly comical it is not "bouffe" and requires to be handled with great care lest its delicate proportions be marred and its subtle quality of humor be lost". The "Journal" described the opera as "classical" in method and wrote that its "most exquisite satire" lay in its "imitation of the absurdities" of grand opera. The company went on to become one of the most successful touring companies in America. The first children's version in Boston became a sensation with both children and adult audiences, extending its run through the summer of 1879. The "Boston Herald" wrote that "the large audience of children and their elders went fairly wild with delight ... shrieks of laughter were repeatedly heard".

When "Pinafore" was first revived in London in 1887, it was already treated as a classic. "The Illustrated London News" observed that the opera had not been updated with new dialogue, jokes and songs, but concluded that this was for the best, as the public would have missed the "time-honoured jokes, such as 'Hardly Ever.' The Savoy has once more got a brilliant success." "The Theatre" concurred, stating that since the opera "has been heard in almost every part of this habitable globe and been enjoyed everywhere, there is not much occasion to descant". It called the revival a "most brilliant" success and predicted another long run.
Reviewing the 1899 revival, "The Athenaeum" managed to praise the piece while joining in the musical establishment's critique of Sullivan. On the one hand, "The "Pinafore" ... sounds fresher than ever. The musical world has become serious – very serious – and it is indeed refreshing to hear a merry, humorous piece, and music, unassuming in character ... it is delicately scored, and in many ways displays ability of a high order". On the other hand, it wrote that if Sullivan had pursued the path of composing more serious music, like his symphony, "he would have produced still higher results; in like manner "Pinafore" set us wondering what the composer would have accomplished with a libretto of somewhat similar kind, but one giving him larger scope for the exercise of his gifts".

In 1911, H. L. Mencken wrote: "No other comic opera ever written – no other stage play, indeed, of any sort – was ever so popular. ... "Pinafore" ... has been given, and with great success, wherever there are theaters – from Moscow to Buenos Aires, from Cape Town to Shanghai; in Madrid, Ottawa and Melbourne; even in Paris, Rome, Vienna and Berlin." After the deaths of Gilbert and Sullivan, the D'Oyly Carte Opera Company retained exclusive rights to perform their operas in Great Britain until 1962, touring throughout Britain for most of the year and, beginning in 1919, often performing in London for a season of about four months. "The Times" gave the company's 1920 London production an enthusiastic review, saying that the audience was "enraptured", and regretting that "Pinafore" would be played for only two weeks. It praised the cast, singling out Leo Sheffield as the Captain, Henry Lytton as Sir Joseph, Elsie Griffin as Josephine, James Hay as Ralph, Bertha Lewis as Little Buttercup and the "splendid" choral tone. It concluded that the opera made a "rollicking climax to the season". Two years later, it gave an even more glowing report of that season's performances, calling Derek Oldham an "ideal hero" as Ralph, noting that Sydney Granville "fairly brought down the house" with his song, that Darrell Fancourt's Deadeye was "an admirably sustained piece of caricature" and that it was a "great pleasure" to hear the returning principals. A 1961 review of the company's "Pinafore" is much the same.

In 1879, J. C. Williamson acquired the exclusive performing rights to "Pinafore" in Australia and New Zealand. His first production earned public and critical acclaim. Williamson played Sir Joseph, and his wife, Maggie Moore played Josephine. Praising the production and all the performers, the "Sydney Morning Herald" noted that the production though "abounding in fun" was dignified and precise, that many numbers were encored and that laughter and applause from the "immense audience ... was liberally bestowed". Williamson's company continued to produce "Pinafore" in Australia, New Zealand and on tour into the 1960s with much success. As Williamson said, "If you need money, then put on G&S". Meanwhile, "Pinafore" continued to garner praise outside Britain. The 1950s Danish version in Copenhagen, for example, was revived repeatedly, playing for well over 100 performances to "packed houses". Translations into German, Yiddish and many other languages, and professional productions in places as remote as Samarkand in Uzbekistan have been successful.

In the U.S., where Gilbert and Sullivan's performance copyright was never in force, "Pinafore" continued to be produced continuously by both professional and amateur companies. "The New York Times", in a 1914 review, called a large-scale production at the 6,000-seat New York Hippodrome a "royal entertainment [that] comes up smiling". The opera had been turned into a "mammoth spectacle" with a chorus of hundreds and the famous Hippodrome tank providing a realistic harbour. Buttercup made her entrance by rowing over to the three-masted "Pinafore", and Dick Deadeye was later thrown overboard with a real splash. The "Times" praised the hearty singing but noted that some subtlety is lost when the dialogue needs to be "shouted". The production took some liberties, including interpolated music from other Sullivan works. The paper concluded, "the mild satire of "Pinafore" is entertaining because it is universal". The same newspaper deemed Winthrop Ames' popular Broadway productions of "Pinafore" in the 1920s and 1930s "spectacular". Modern productions in America continue to be generally well received. "The New York Times" review of The New York Gilbert and Sullivan Players' 2008 season at New York City Center commented, "Gilbert's themes of class inequality, overbearing nationalism and incompetent authorities remain relevant, however absurdly treated. But the lasting appeal of "Pinafore" and its ilk is more a matter of his unmatched linguistic genius and Sullivan's generous supply of addictive melodies."

With the expiry of the copyrights, companies around the world have been free to produce Gilbert and Sullivan works and to adapt them as they please for almost 50 years. Productions of "Pinafore", both amateur and professional, range from the traditional, in the D'Oyly Carte vein, to the broadly adapted, such as that of the very successful Essgee Entertainment (formed by Simon Gallaher) in Australia and Opera della Luna in Britain. Since its original production, "H.M.S. Pinafore" has remained one of Gilbert and Sullivan's most popular comic operas. Productions continue in large numbers around the world. In 2003 alone, The D'Oyly Carte Opera Company rented 224 sets of orchestra parts, mostly for productions of "Pinafore", "Pirates" and "Mikado". This does not take into account other rental companies and the theatre companies that borrow scores or have their own, or that use only one or two pianos instead of an orchestra. Hundreds of productions of "Pinafore" are presented every year worldwide.

Theatre historian John Bush Jones wrote that "Pinafore" has "everything a musical theatregoer could ask for. An engaging and even relatively suspenseful story is populated with varied and well-drawn characters who speak and sing witty, literate, and often outrageously funny dialogue and lyrics [and] has a score that ... has plenty of tunes for the audience to go away humming". Sir George Power, the tenor who created the role of Ralph Rackstraw, opined in later life that the secret of the success of the Savoy operas is the way in which "Sullivan entered into the spirit of Gilbert's topsy-turvy humour, and was pompous when Gilbert was sprightly, or, when Gilbert's satire was keenest and most acid, consciously wallowed in sentiment." Another commentator has suggested that the opera's enduring success lies in its focus on "mirth and silliness". Even the title of the piece is silly, applying the name of a little girl's garment, a pinafore, to the fearsome symbol of a naval warship, which usually bore names like "Victory", "Goliath", "Audacious" and "Minotaur".

Gilbert's biographer Jane Stedman wrote that "Pinafore" is "satirically far more complex" than "The Sorcerer". She commented that Gilbert uses several ideas and themes from his Bab Ballads, including the idea of gentlemanly behaviour of a captain towards his crew from "Captain Reece" (1868) and the exchange of ranks due to exchange at birth from "General John" (1867). Dick Deadeye, based on a character in "Woman's Gratitude" (1869), represents another of Gilbert's favorite (and semi-autobiographical) satiric themes: the misshapen misanthrope whose forbidding "face and form" makes him unpopular although he represents the voice of reason and common sense. Gilbert also borrows from his 1870 opera, "The Gentleman in Black" which includes the device of baby-switching.
Historian H. M. Walbrook wrote in 1921 that "Pinafore" "satirizes the type of nautical drama of which Douglas Jerrold's "Black-Eyed Susan" is a typical instance, and the 'God's Englishman' sort of patriotism which consists in shouting a platitude, striking an attitude, and doing little or nothing to help one's country". G. K. Chesterton agreed that the satire is pointed at the selfishness of "being proud of yourself for being a citizen" of one's country, which requires no virtuous effort of will to resist the "temptations to belong to other nations" but is merely an excuse for pride. In 2005, Australian opera director Stuart Maunder noted the juxtaposition of satire and nationalism in the opera, saying, "they all sing 'He is an Englishman', and you know damn well they're sending it up, but the music is so military ... that you can't help but be swept up in that whole jingoism that is the British Empire." In addition, he argued that the song ties this theme into the main satire of class distinctions in the opera: ""H.M.S. Pinafore" is basically a satire on ... the British love of the class system. ... [O]f course [Ralph] can marry [the Captain's] daughter, because he's British, and therefore he's great'". Jacobs notes that Gilbert is lampooning the tradition of nautical melodrama in which the sailor's "patriotism guarantees his virtue".

One of Gilbert's favourite comic themes is the elevation of an unqualified person to a position of high responsibility. In "The Happy Land" (1873), for example, Gilbert describes a world in which government offices are awarded to the person who has the least qualification to hold each position. In particular, the one who has never heard of a ship is appointed to the cabinet post of First Lord of the Admiralty. In "Pinafore", Gilbert revisits this theme in the character of Sir Joseph, who rises to the same position by "never go[ing] to sea". In later Gilbert and Sullivan operas, the characters Major-General Stanley in "Pirates", and Ko-Ko in "The Mikado", are similarly appointed to high office though lacking the necessary qualifications. Gilbert also pokes fun at party politics, implying that when Sir Joseph "always voted at [his] party's call", he sacrificed his personal integrity. The "commercial middle class" (which was Gilbert's main audience) is treated as satirically as are social climbers and the great unwashed. In addition, the apparent age difference between Ralph and the Captain, even though they were babies nursed together, satirises the variable age of Thaddeus in "The Bohemian Girl". "The Times" wrote, in reviewing the 1929 production, that "Pinafore" was quintessentially Gilbertian in that the absurdities of a "paternal" Captain and the "ethics ... of all romanticism" are accepted "unflinchingly" and taken to their logical conclusion: "It is the reference to actuality that is essential; without it, the absurdity will not stand starkly out".
A theme that pervades the opera is the treatment of love across different social ranks. In the previous Gilbert and Sullivan opera, "The Sorcerer", a love potion causes trouble by inducing the villagers and wedding guests to fall in love with people of different social classes. In "Pinafore", the captain's daughter, Josephine, loves and is loved by a common sailor, but she dutifully tells him, "your proffered love I haughtily reject". He expresses his devotion to her in a poetic and moving speech that ends with "I am a British sailor, and I love you". It finally turns out that he is of a higher rank than she. This is a parody of the Victorian "equality" drama, such as Lord Lytton's "The Lady of Lyons" (1838), where the heroine rejects a virtuous peasant who makes a similarly moving speech, ending with "I am a peasant!" It then turns out that he has become her social superior. Furthermore, in "Pinafore", Sir Joseph assures Josephine that "love levels all ranks". In Tom Taylor's "The Serf", the heroine again loves a worthy peasant who turns out to be of high rank, and she declares happily at the end that "love levels all". In a satire of the libertarian traditions of nautical melodrama, Sir Joseph tells the crew of the Pinafore that they are "any man's equal" (excepting his), and he writes a song for them that glorifies the British sailor. Conversely, he brings the proud captain down a notch by making him "dance a hornpipe on the cabin table". Jones notes that the union between Ralph and Josephine "becomes acceptable only through the absurd second-act revelation of Buttercup's inadvertent switching of the infants" and concludes that Gilbert is a "conservative satirist [who] ultimately advocated preserving the status quo ... [and] set out to show [that] love definitely "does not" level all ranks".

There is a divide among Gilbert and Sullivan scholars as to whether Gilbert is, as Jones argues, a supporter of the status quo whose focus is merely to entertain or, on the other hand, predominantly to satirise and protest "against the follies of his age". The Gilbert scholar Andrew Crowther posits that this disagreement arises from Gilbert's "techniques of inversion – with irony and topsyturvydom", which lead to "the surface meaning of his writings" being "the opposite of their underlying meaning". Crowther argues that Gilbert desires to "celebrate" society's norms while, at the same time, satirising these conventions. In "Pinafore", which established many patterns for the later Savoy operas, Gilbert found a way to express his own conflict that "also had tremendous appeal to the general public". He creates "a highly intelligent parody of nautical melodrama ... [though] controlled by the conventions it mocks". While nautical melodrama exalts the common sailor, in "Pinafore" Gilbert makes the proponent of equality, Sir Joseph, a pompous and misguided member of the ruling class who, hypocritically, cannot apply the idea of equality to himself. The hero, Ralph, is convinced of his equality by Sir Joseph's foolish pronouncements and declares his love for his Captain's daughter, throwing over the accepted "fabric of social order". At this point, Crowther suggests, the logic of Gilbert's satiric argument should result in Ralph's arrest. But to satisfy convention, Gilbert creates an obvious absurdity: the captain and Ralph were switched as babies. By an "accident of birth", Ralph is suddenly an appropriate husband for Josephine, and both the social order and the desire for a romantic happy ending are satisfied at once. Crowther concludes, "We have an opera which uses all the conventions of melodrama and ridicules them; but in the end it is difficult to see which has won out, the conventions or the ridicule." Thus, "Pinafore" found broadbased success by appealing to the intellectual theatregoer seeking satire, the middle-class theatre-goer looking for a comfortable confirmation of the "existing social order" and the working-class audience who saw a satisfying melodramatic victory for the common man.

According to musicologist Arthur Jacobs, Gilbert's plot "admirably sparked off Sullivan's genius". Sullivan embraces the nautical setting; in "We Sail the Ocean Blue", for example, he "presents his twist on a traditional sea shanty". In the Captain's opening song, "I am the Captain of the Pinafore", he admits that his gentlemanliness "never ... well, hardly ever" gives way to swearing at his men, and although he has experience at sea, he "hardly ever" suffers from seasickness. Sullivan "unerringly found the right musical setting for the key phrase 'What never?' ... cunningly sharpened ... through the chromatic touch on the bassoon." Audrey Williamson argued that the music of "Pinafore" is quintessentially English and free of European influences throughout most of the score, from the "glee" for Ralph, the Boatswain and the Carpenter, to "For He Is an Englishman".
The best-known songs from the opera include "I'm called Little Buttercup", a waltz tune introducing the character, which Sullivan repeats in the entr'acte and in the Act II finale to imprint the melody on the mind of the audience; and "A British tar" (a glee for three men describing the ideal sailor), composed by Sir Joseph "to encourage independent thought and action in the lower branches of the service, and to teach the principle that a British sailor is any man's equal, excepting mine". Sullivan's voicing advances the satiric lyric, which mocks the "equality" plays while underlining the hypocrisy of Sir Joseph. Another popular number is Sir Joseph's song "When I was a Lad", recounting the meteoric rise of his career, which bears similarities to that of W. H. Smith, the civilian news entrepreneur who had risen to the position of First Lord of the Admiralty in 1877.

In "Pinafore", Sullivan exploits minor keys for comic effect, for instance in "Kind Captain, I've important information". Further, he achieves a musical surprise when he uses the subdominant minor in "Sorry her lot". The musicologist Gervase Hughes was impressed with the introduction to the opening chorus which includes "a rousing nautical tune ... in a key of no nonsense, C major ... a modulation to the mediant minor, where to our surprise a plaintive oboe gives us the first verse of "Sorry her lot" in 2/4 [time]. After this closes on the local dominant B major the violins (still in 2/4) introduce us to Little Buttercup ... meeting her under these conditions one would hardly expect her to blossom out later as a queen of the waltz." He continues, "the bassoon and basses ... assert vigorously who is the Captain of the Pinafore ... in the improbable key of A flat minor. ... Buttercup makes a last despairing attempt to make herself heard in D flat minor, but the others have never known that such an outlandish key existed. So in a flash they all go back to C major on a good old 6/4".

According to Jacobs, "Ralph, Captain Corcoran, Sir Joseph and Josephine all live in their interactive music (particularly 'Never mind the why and wherefore'), and almost as much musical resource is lavished on two characters parodied from opera or melodrama, Little Buttercup with 'gypsy blood in her veins' and the heavy-treading Dick Deadeye." Jacobs also opined that the leading tone that begins "Never mind the why and wherefore" "serves to emphasize the phrase like a Johann Strauss-ian grace-note". The Sullivan scholar David Russell Hulme noted Sullivan's parody of operatic styles, "particularly the Handelian recitatives and the elopement scene (evocative of so many nocturnal operatic conspiracies), but best of all is the travesty of the patriotic tune in 'For he is an Englishman!'" Buttercup's Act II song, in which she reveals the dark secret of the baby-switching is preceded by a quote from Franz Schubert's "The Erl-King" and also parodies the opera "Il Trovatore". Jacobs notes that Sullivan also adds his own humorous touches to the music by setting commonplace expressions in "Donizettian recitative". But on the serious side, he enhances the moments of true emotional climax, as in Josephine's Act II aria, and added musical interest to concerted numbers by "subtly shifting the rhythms and bar groupings."

During rehearsals for the original production, Gilbert added a ballad for Captain Corcoran in which he urged his daughter to forget the common sailor with whom she is in love, because "at every step, he would commit solecisms that society would never pardon." The ballad was meant to be sung between No. 5 and No. 6 of the current score, but it was cut before opening night. The words survive in the libretto that was deposited with the Lord Chamberlain for licensing. Before 1999, all that was known to survive of Sullivan's setting was a copy of the leader violin part.

In April 1999, Sullivan scholars Bruce I. Miller and Helga J. Perry announced that they had discovered a nearly complete orchestration – lacking only the second violin part – in a private collection of early band parts. These materials, with a conjectural reconstruction of the partially lost vocal lines and second violin part, were later published and professionally recorded. This piece has now been performed a number of times by amateur and professional companies, although it has not become a standard addition to the traditional scores or recordings.

In the licensing copy of the libretto, Sir Joseph's cousin Hebe had lines of dialogue in several scenes in Act II. In the scene that follows No. 14 ("Things are seldom what they seem"), she accompanied Sir Joseph onstage and echoed the First Lord's dissatisfaction with Josephine. After several interruptions, Sir Joseph urged her to be quiet, eliciting the response "Crushed again!" Gilbert would later re-use this passage for Lady Jane in "Patience". Hebe was also assigned several lines of dialogue after No. 18 ("Carefully on tiptoe stealing") and again after No. 19 ("Farewell, my own").

Late in rehearsals for the original production, Jessie Bond assumed the role of Hebe, replacing Mrs Howard Paul. Bond, who at this point in her career was known primarily as a concert singer and had little experience as an actress, did not feel capable of performing dialogue, and these passages were revised to cut Hebe's dialogue. Hebe's cut dialogue is occasionally restored in modern performances.

The dialogue preceding the Act II finale, starting with "Here, take her sir, and mind you treat her kindly", was originally recitative. The music for this passage was printed in the first edition of the vocal score as No. 20a. Shortly after opening night, the recitative was dropped, and the lines thereafter were performed as spoken dialogue. In modern productions, the recitative is occasionally restored in place of the dialogue.

There have been numerous recordings of "Pinafore" since 1907. Ian Bradley counted seventeen recordings of the opera available on CD in 2005.

The 1930 recording is notable for preserving the performances of the D'Oyly Carte Opera Company stars of the era. The 1960 D'Oyly Carte recording, which contains all the dialogue, has been repeatedly praised by reviewers. The 1994 Mackerras recording, featuring grand opera singers in the principal roles, is musically well regarded. The 2000 D'Oyly Carte recording also contains complete dialogue and the first recording of the "lost" ballad for Captain Corcoran, "Reflect, my child", as a bonus track. A 1957 Danish-language recording of the opera is one of the few foreign-language professional recordings of Gilbert and Sullivan.

In 1939, "Pinafore" was chosen by NBC as one of the earliest operas ever broadcast on American television, but no recording is known to have been saved. The 1973 D'Oyly Carte video recording, directed by Michael Heyland, features the company's staging of the period, but some reviewers find it dull. It is, however, one of only three video or film recordings of a Gilbert and Sullivan opera by the D'Oyly Carte Opera Company. In 1982, Brent Walker Productions produced "Pinafore" as part of its series of Gilbert and Sullivan television films. According to discographer Marc Shepherd, the "Pinafore" video "is widely considered one of the worst" in the series. More recent professional productions have been recorded on video by the International Gilbert and Sullivan Festival.


"H.M.S. Pinafore" has been adapted many times. W. S. Gilbert wrote a 1909 children's book called "The Pinafore Picture Book", illustrated by Alice Woodward, which retells the story of "Pinafore", in some cases giving considerable backstory that is not found in the libretto. Many other children's books have since been written retelling the story of "Pinafore" or adapting characters or events from "Pinafore".

Many musical theatre adaptations have been produced since the original opera. Notable examples include a 1945 Broadway musical adapted by George S. Kaufman, called "Hollywood Pinafore", using Sullivan's music. This was revived several times, including in London in 1998. Another 1945 Broadway musical adaptation, "Memphis Bound", was written by Don Walker and starred Bill Robinson and an all-black cast. In 1940, the American Negro Light Opera Association produced the first of several productions set in the Caribbean Sea, "Tropical Pinafore". An early Yiddish adaptation of "Pinafore", called "Der Shirtz" (Yiddish for "apron") was written by Miriam Walowit in 1952 for a Brooklyn, New York Hadassah group, and they recorded 12 of the songs. In the 1970s, Al Grand was inspired by this recording and urged the Gilbert and Sullivan Long Island Light Opera Company to perform these songs. He later translated the missing songs and dialogue, with Bob Tartell, and the show has been toured widely under the name "Der Yiddisher Pinafore". The group have continued to produce this adaptation for over two decades, in which "He is an Englishman" becomes "Er Iz a Guter Yid" ("He is a good Jew").

Essgee Entertainment produced an adapted version of "Pinafore" in 1997 in Australia and New Zealand that has been much revived. Another musical adaptation is "Pinafore! (A Saucy, Sexy, Ship-Shape New Musical)", adapted by Mark Savage. It was first performed at the Celebration Theater in Los Angeles, California on 7 September 2001, directed by Savage, where it ran with great success for nine months. It then played in Chicago and New York in 2003. In this adaptation, only one character is female, and all but one of the male characters are gay. An original cast recording was issued in 2002 by Belva Records. "Pinafore Swing" is a musical with music arranged by Sarah Travis. It premiered at the Watermill Theatre in England in 2004 in a production directed by John Doyle. The adaptation, set in 1944, changes the characters into members of a band entertaining the sailors on a World War II troop ship in the Atlantic. The reduced-size acting cast also serve as the orchestra for the singing roles, and the music is infused with swing rhythms. Numerous productions in recent decades have been set to parody "Star Trek" or "Star Wars".

Among its other influences on popular culture, "Pinafore" had perhaps its most profound influence on the development of musical theatre. According to theatre historian John Kenrick, "Pinafore" "became an international sensation, reshaping the commercial theater in both England and the United States." The music writer Andrew Lamb notes, "The success of "H.M.S. Pinafore" in 1879 established British comic opera alongside French opéra bouffe throughout the English-speaking world". The historian John Bush Jones opines that "Pinafore" and the other Savoy operas demonstrate that musical theatre "can address contemporary social and political issues without sacrificing entertainment value" and that "Pinafore" created the model for a new kind of musical theatre, the "integrated" musical, where "book, lyrics, and music combined to form an integral whole". He adds that its "unprecedented ... popularity fostered an American audience for musical theatre, while the show itself became a model for form, content, and even intention of ... musicals ever since, especially socially relevant musicals." Its popularity also led to the musical theatre adaptations of "Pinafore" described above, musicals in which the story line involves a production of "Pinafore" and other musicals that parody the opera or that use or adapt its music. Other examples include "The Pirates of Pinafore", "The Pinafore Pirates" (which Bradley calls "splendid" and describes in detail in Bradley (2005), pp. 174–75), "Mutiny on the Pinafore", and "H.M.S. Dumbledore" (2004) by Caius Marcius.</ref> The first such parody was a short-lived burlesque presented at the Opera Comique in 1882, called "The Wreck of the Pinafore" by H. Lingard and Luscombe Searelle; the opera's characters are shipwrecked on a desert island. It was described by "The Era" as "chiefly remarkable for its impudence".

The opera's popularity has led to the widespread parody and pastiche of its songs in comedy routines, literature and other media. Many comedians have used "Pinafore" songs for comic and satiric effect. For example, in his comedy album "My Son, the Celebrity", Allan Sherman parodies "When I Was a Lad" from the point of view of a young man who goes to an Ivy League school and then rises to prominence in business. At the end of the song, he "thanks old Yale", "thanks the Lord" and thanks his father, "who is chairman of the board". Literary references to "Pinafore" songs include Harris's attempt to sing "When I Was a Lad" in Jerome K. Jerome's "Three Men in a Boat". Another is found in the story "Runaround" from "I, Robot" by Isaac Asimov, where a robot sings part of "I'm Called Little Buttercup". "Pinafore" and its songs have been performed by rock musicians such as Todd Rundgren, Taj Mahal and Michele Gray Rundgren, who performed "Never Mind the Why and Wherefore" on "Night Music" ("Sunday Night") in 1989.

Political references include a 1996 satiric pastiche of "When I Was a Lad" aimed at Tony Blair by Virginia Bottomley, heritage secretary under John Major. Sporting references include a racehorse named "H.M.S. Pinafore". "Pinafore" songs and images have been used extensively in advertising. According to Jones, ""Pinafore" launched the first media blitz in the United States" beginning in 1879, and recent ads include a television campaign for Terry's Chocolate Orange featuring a pastiche of "When I Was a Lad". "Pinafore"-themed merchandise includes trading cards that were created in the 1880s.

Songs from "Pinafore" have been used to give period flavor to such films as the 1981 historical film "Chariots of Fire", in which the protagonist, Harold Abrahams, and others from Cambridge University, sing "He Is an Englishman". This song also features at the end of the 1983 BBC drama "An Englishman Abroad". In the 2003 movie "Peter Pan", the Darling family sings "When I Was a Lad". In "Wyatt Earp" (1994), the famed lawman meets his future wife when he sees her playing in an early production of "Pinafore". A 1953 biopic, "The Story of Gilbert and Sullivan", uses music from "Pinafore".

Characters also sing songs from "Pinafore" in such popular films as "Raiders of the Lost Ark" (1981) and "" (1998), where Captain Picard and Lt. Commander Worf sing part of "A British Tar" to distract a malfunctioning Lt. Commander Data. "The Good Shepherd" (2006) depicts an all-male version of "Pinafore" at Yale University in 1939; Matt Damons character plays Little Buttercup, singing in falsetto. Judy Garland sings "I Am the Monarch of the Sea" in the 1963 film, "I Could Go On Singing". The soundtrack of the 1992 thriller "The Hand that Rocks the Cradle" prominently features songs and music from "Pinafore", and the father and daughter characters sing "I Am the Captain of the Pinafore" together. An example of a film based on ideas from "Pinafore" is the 1976 animated film by Ronald Searle called "Dick Deadeye, or Duty Done" is based on the character and songs from "Pinafore". In the 1988 drama "Permanent Record", a high school class performs "Pinafore".

Television series that include substantial "Pinafore" references include "The West Wing", for example in the 2000 episode "And It's Surely to Their Credit", where "He Is an Englishman" is used throughout and quoted (or paraphrased) in the episode's title. Among other notable examples of the use of songs from "Pinafore" on television are several popular animated shows. In the "Cape Feare" episode of "The Simpsons", Bart stalls his would-be killer Sideshow Bob with a "final request" that Bob sing him the entire score of "Pinafore". Similarly, the 1993 "HMS Yakko" episode of "Animaniacs" consists of pastiches of songs from "H.M.S. Pinafore" and "The Pirates of Penzance". In a "Family Guy" episode, "The Thin White Line" (2001), Stewie sings a pastiche of "My Gallant Crew". Stewie also sings "I Am the Monarch of the Sea" (including the ladies' part, in falsetto) in "". A 1986 "Mr. Belvedere" episode, "The Play", concerns a production of "H.M.S. Pinafore", and several of the songs are performed. In 1955, NBC broadcast a variety special including a 20-minute compressed jazz version, "H.M.S. Pinafore in Jazz", produced and directed by Max Liebman, starring Perry Como, Buddy Hackett, Kitty Kallen, Bill Hayes, Pat Carroll and Herb Shriner.

The following tables show the most prominent cast members of significant D'Oyly Carte Opera Company productions and tours at various times through to the company's 1982 closure:


Information
Images
Audio


</doc>
<doc id="47878" url="https://en.wikipedia.org/wiki?curid=47878" title="Huntington's disease">
Huntington's disease

Huntington's disease (HD), also known as Huntington's chorea, is an inherited disorder that results in death of brain cells. The earliest symptoms are often subtle problems with mood or mental abilities. A general lack of coordination and an unsteady gait often follow. As the disease advances, uncoordinated, jerky body movements become more apparent. Physical abilities gradually worsen until coordinated movement becomes difficult and the person is unable to talk. Mental abilities generally decline into dementia. The specific symptoms vary somewhat between people. Symptoms usually begin between 30 and 50 years of age, but can start at any age. The disease may develop earlier in life in each successive generation. About eight percent of cases start before the age of 20 years and typically present with symptoms more similar to Parkinson's disease. People with HD often underestimate the degree of their problems.
HD is typically inherited, although up to 10% of cases are due to a new mutation. The disease is caused by an autosomal dominant mutation in either of an individual's two copies of a gene called "Huntingtin". This means a child of an affected person typically has a 50% chance of inheriting the disease. The "Huntingtin" gene provides the genetic information for a protein that is also called "huntingtin". Expansion of CAG (cytosine-adenine-guanine) triplet repeats in the gene coding for the Huntingtin protein results in an abnormal protein, which gradually damages cells in the brain, through mechanisms that are not fully understood. Diagnosis is by genetic testing, which can be carried out at any time, regardless of whether or not symptoms are present. This fact raises several ethical debates: the age at which an individual is considered mature enough to choose testing; whether parents have the right to have their children tested; and managing confidentiality and disclosure of test results.
There is no cure for HD. Full-time care is required in the later stages of the disease. Treatments can relieve some symptoms and in some improve quality of life. The best evidence for treatment of the movement problems is with tetrabenazine. HD affects about 4 to 15 in 100,000 people of European descent. It is rare among Japanese, while the occurrence rate in Africa is unknown. The disease affects men and women equally. Complications such as pneumonia, heart disease, and physical injury from falls reduce life expectancy. Suicide is the cause of death in about 9% of cases. Death typically occurs fifteen to twenty years from when the disease was first detected.
The first likely description of the disease was in 1841 by Charles Oscar Waters. The condition was described in further detail in 1872 by the physician George Huntington, after whom it is named. The genetic basis was discovered in 1993 by an international collaborative effort led by the Hereditary Disease Foundation. Research and support organizations began forming in the late 1960s to increase public awareness, to provide support for individuals and their families, and to promote research. Current research directions include determining the exact mechanism of the disease, improving animal models to aid with research, testing of medications to treat symptoms or slow the progression of the disease, and studying procedures such as stem cell therapy with the goal of repairing damage caused by the disease.

Symptoms of Huntington's disease most commonly become noticeable between the ages of 35 and 44 years, but they can begin at any age from infancy to old age. In the early stages, there are subtle changes in personality, cognition, and physical skills. The physical symptoms are usually the first to be noticed, as cognitive and behavioral symptoms are generally not severe enough to be recognized on their own at the earlier stages. Almost everyone with Huntington's disease eventually exhibits similar physical symptoms, but the onset, progression and extent of cognitive and behavioral symptoms vary significantly between individuals.

The most characteristic initial physical symptoms are jerky, random, and uncontrollable movements called chorea. Chorea may be initially exhibited as general restlessness, small unintentionally initiated or uncompleted motions, lack of coordination, or slowed saccadic eye movements. These minor motor abnormalities usually precede more obvious signs of motor dysfunction by at least three years. The clear appearance of symptoms such as rigidity, writhing motions or abnormal posturing appear as the disorder progresses. These are signs that the system in the brain that is responsible for movement has been affected. Psychomotor functions become increasingly impaired, such that any action that requires muscle control is affected. Common consequences are physical instability, abnormal facial expression, and difficulties chewing, swallowing, and speaking. Eating difficulties commonly cause weight loss and may lead to malnutrition. Sleep disturbances are also associated symptoms. Juvenile HD differs from these symptoms in that it generally progresses faster and chorea is exhibited briefly, if at all, with rigidity being the dominant symptom. Seizures are also a common symptom of this form of HD.

Cognitive abilities are progressively impaired. Especially affected are executive functions, which include planning, cognitive flexibility, abstract thinking, rule acquisition, initiation of appropriate actions, and inhibition of inappropriate actions. As the disease progresses, memory deficits tend to appear. Reported impairments range from short-term memory deficits to long-term memory difficulties, including deficits in episodic (memory of one's life), procedural (memory of the body of how to perform an activity) and working memory. Cognitive problems tend to worsen over time, ultimately leading to dementia. This pattern of deficits has been called a subcortical dementia syndrome to distinguish it from the typical effects of cortical dementias e.g. Alzheimer's disease.

Reported neuropsychiatric manifestations are anxiety, depression, a reduced display of emotions (blunted affect), egocentrism, aggression, and compulsive behavior, the latter of which can cause or worsen addictions, including alcoholism, gambling, and hypersexuality. Difficulties in recognizing other people's negative expressions have also been observed. The prevalence of these symptoms is highly variable between studies, with estimated rates for lifetime prevalence of psychiatric disorders between 33% and 76%. For many sufferers and their families, these symptoms are among the most distressing aspects of the disease, often affecting daily functioning and constituting reason for institutionalization. Suicidal thoughts and suicide attempts are more common than in the general population. Often individuals have reduced awareness of chorea, cognitive and emotional impairments.

Mutant Huntingtin is expressed throughout the body and associated with abnormalities in peripheral tissues that are directly caused by such expression outside the brain. These abnormalities include muscle atrophy, cardiac failure, impaired glucose tolerance, weight loss, osteoporosis, and testicular atrophy.

All humans have two copies of the Huntingtin gene ("HTT"), which codes for the protein Huntingtin (HTT). The gene is also called "HD" and "IT15", which stands for 'interesting transcript 15'. Part of this gene is a repeated section called a trinucleotide repeat, which varies in length between individuals and may change length between generations. If the repeat is present in a healthy gene, a dynamic mutation may increase the repeat count and result in a defective gene. When the length of this repeated section reaches a certain threshold, it produces an altered form of the protein, called mutant Huntingtin protein (mHTT). The differing functions of these proteins are the cause of pathological changes which in turn cause the disease symptoms. The Huntington's disease mutation is genetically dominant and almost fully penetrant: mutation of either of a person's "HTT" alleles causes the disease. It is not inherited according to sex, but the length of the repeated section of the gene and hence its severity can be influenced by the sex of the affected parent.

HD is one of several trinucleotide repeat disorders which are caused by the length of a repeated section of a gene exceeding a normal range. The "HTT" gene is located on the short arm of chromosome 4 at 4p16.3. "HTT" contains a sequence of three DNA bases—cytosine-adenine-guanine (CAG)—repeated multiple times (i.e. ... CAGCAGCAG ...), known as a trinucleotide repeat. CAG is the 3-letter genetic code (codon) for the amino acid glutamine, so a series of them results in the production of a chain of glutamine known as a polyglutamine tract (or polyQ tract), and the repeated part of the gene, the "PolyQ region".

Generally, people have fewer than 36 repeated glutamines in the polyQ region which results in production of the cytoplasmic protein Huntingtin. However, a sequence of 36 or more glutamines results in the production of a protein which has different characteristics. This altered form, called mutant huntingtin (mHTT), increases the decay rate of certain types of neurons. Regions of the brain have differing amounts and reliance on these types of neurons, and are affected accordingly. Generally, the number of CAG repeats is related to how much this process is affected, and accounts for about 60% of the variation of the age of the onset of symptoms. The remaining variation is attributed to environment and other genes that modify the mechanism of HD. 36–39 repeats result in a reduced-penetrance form of the disease, with a much later onset and slower progression of symptoms. In some cases the onset may be so late that symptoms are never noticed. With very large repeat counts, HD has full penetrance and can occur under the age of 20, when it is then referred to as juvenile HD, akinetic-rigid, or Westphal variant HD. This accounts for about 7% of HD carriers.

Huntington's disease has autosomal dominant inheritance, meaning that an affected individual typically inherits one copy of the gene with an expanded trinucleotide repeat (the mutant allele) from an affected parent. Since penetrance of the mutation is very high, those who have a mutated copy of the gene will have the disease. In this type of inheritance pattern, each offspring of an affected individual has a 50% risk of inheriting the mutant allele and therefore being affected with the disorder (see figure). This probability is sex-independent.

Trinucleotide CAG repeats over 28 are unstable during replication, and this instability increases with the number of repeats present. This usually leads to new expansions as generations pass (dynamic mutations) instead of reproducing an exact copy of the trinucleotide repeat. This causes the number of repeats to change in successive generations, such that an unaffected parent with an "intermediate" number of repeats (28–35), or "reduced penetrance" (36–40), may pass on a copy of the gene with an increase in the number of repeats that produces fully penetrant HD. Such increases in the number of repeats (and hence earlier age of onset and severity of disease) in successive generations is known as genetic anticipation. Instability is greater in spermatogenesis than oogenesis; maternally inherited alleles are usually of a similar repeat length, whereas paternally inherited ones have a higher chance of increasing in length. It is rare for Huntington's disease to be caused by a new mutation, where neither parent has over 36 CAG repeats.

In the rare situations where both parents have an expanded HD gene, the risk increases to 75%, and when either parent has two expanded copies, the risk is 100% (all children will be affected). Individuals with both genes affected are rare. For some time HD was thought to be the only disease for which possession of a second mutated gene did not affect symptoms and progression, but it has since been found that it can affect the phenotype and the rate of progression.

The huntingtin protein interacts with over 100 other proteins, and appears to have multiple biological functions. The behavior of this mutated protein is not completely understood, but it is toxic to certain cell types, particularly in the brain. Early damage is most evident in the striatum, but as the disease progresses, other areas of the brain are also more conspicuously affected. Early symptoms are attributable to functions of the striatum and its cortical connections—namely control over movement, mood and higher cognitive function. DNA methylation also appears to be changed in HD.

HTT is expressed in all cells. The highest concentrations are found in the brain and testes, with moderate amounts in the liver, heart, and lungs. The function of HTT in humans is unclear. It interacts with proteins which are involved in transcription, cell signaling, and intracellular transporting. In animals genetically modified to exhibit HD, several functions of HTT have been found. In these animals, HTT is important for embryonic development, as its absence is related to embryonic death. Caspase, an enzyme which plays a role in catalyzing apoptosis, is thought to be activated by the mutated gene through damaging the ubiquitin-protease system. It also acts as an anti-apoptotic agent preventing programmed cell death and controls the production of brain-derived neurotrophic factor, a protein which protects neurons and regulates their creation during neurogenesis. HTT also facilitates vesicular transport and synaptic transmission and controls neuronal gene transcription. If the expression of HTT is increased and more HTT produced, brain cell survival is improved and the effects of mHTT are reduced, whereas when the expression of HTT is reduced, the resulting characteristics are more typical of the presence of mHTT. It is thought that the disease is not caused by inadequate production of HTT, but by an increase in the toxic function of mHTT in the body.

There are multiple cellular changes through which the toxic function of mHTT may manifest and produce the HD pathology. In its mutant (i.e. polyglutamine expanded) form, the protein is more prone to cleavage that creates shorter fragments containing the polyglutamine expansion. These protein fragments have a propensity to undergo misfolding and aggregation, yielding fibrillar aggregates in which non-native polyglutamine β-strands from multiple proteins are bonded together via hydrogen bonds. These aggregates share the same fundamental cross-β amyloid architecture seen in other protein deposition diseases. Over time, the aggregates accumulate to form inclusion bodies within cells, ultimately interfering with neuron function. Neuronal inclusions run indirect interference. Inclusion bodies have been found in both the cell nucleus and cytoplasm. Inclusion bodies in cells of the brain are one of the earliest pathological changes, and some experiments have found that they can be toxic for the cell, but other experiments have shown that they may form as part of the body's defense mechanism and help protect cells.

Several pathways by which mHTT may cause cell death have been identified. These include: effects on chaperone proteins, which help fold proteins and remove misfolded ones; interactions with caspases, which play a role in the process of removing cells; the toxic effects of glutamine on nerve cells; impairment of energy production within cells; and effects on the expression of genes.

An additional theory that explains another way cell function may be disrupted by HD proposes that damage to mitochondria in striatal cells is of central importance (numerous accounts of mitochondrial metabolism deficiency have been found). Mutant Huntingtin protein has been found to play a key role in mitochondrial dysfunction. The impairment of mitochondrial electron transport can result in higher levels of oxidative stress and release of reactive oxygen species.

The interactions of the altered huntingtin protein with numerous proteins in neurons leads to an increased vulnerability of glutamine, which, in large amounts, has been found to be an excitotoxin. Excitotoxins may cause damage to numerous cellular structures. Although glutamine is not found in excessively high amounts, it has been postulated that because of the increased vulnerability, even normal amounts of glutamine can cause excitotoxins to be expressed.

HD affects the whole brain, but certain areas are more vulnerable than others. The most prominent early effects are in a part of the basal ganglia called the neostriatum, which is composed of the caudate nucleus and putamen. Other areas affected include the substantia nigra, layers 3, 5 and 6 of the cerebral cortex, the hippocampus, purkinje cells in the cerebellum, lateral tuberal nuclei of the hypothalamus and parts of the thalamus. These areas are affected according to their structure and the types of neurons they contain, reducing in size as they lose cells. Striatal spiny neurons are the most vulnerable, particularly ones with projections towards the external globus pallidus, with interneurons and spiny cells projecting to the internal pallidum being less affected. HD also causes an abnormal increase in astrocytes and activation of the brain's immune cells, microglia.

The basal ganglia—the part of the brain most prominently affected in early HD—play a key role in movement and behavior control. Their functions are not fully understood, but current theories propose that they are part of the cognitive executive system and the motor circuit. The basal ganglia ordinarily inhibit a large number of circuits that generate specific movements. To initiate a particular movement, the cerebral cortex sends a signal to the basal ganglia that causes the inhibition to be released. Damage to the basal ganglia can cause the release or reinstatement of the inhibitions to be erratic and uncontrolled, which results in an awkward start to motion or motions to be unintentionally initiated, or a motion to be halted before, or beyond, its intended completion. The accumulating damage to this area causes the characteristic erratic movements associated with HD. The spontaneous and erratic physical movements associated with HD are classified as a type of hyperkinetic dysarthria. Because of the basal ganglia's inability to inhibit movements, individuals affected by it will inevitably experience a reduced ability to produce speech and swallow foods and liquids (dysphagia).

CREB-binding protein (CBP), a transcriptional coregulator, is essential for cell function because as a coactivator at a significant number of promoters, it activates the transcription of genes for survival pathways. Furthermore, the amino acids that form CBP include a strip of 18 glutamines. Thus, the glutamines on CBP interact directly with the increased numbers of glutamine on the HTT chain and CBP gets pulled away from its typical location next to the nucleus.<ref name="urlAnalysis of Strand Slippage in DNA Polymerase Expansions of CAG/CTG Triplet Repeats Associated with Neurodegenerative Disease – JBC"></ref> Specifically, CBP contains an acetyltransferase domain to which HTT binds through its polyglutamine-containing domain. Autopsied brains of those who had Huntington's disease also have been found to have incredibly reduced amounts of CBP. In addition, when CBP is overexpressed, polyglutamine-induced death is diminished, further demonstrating that CBP plays an important role in Huntington's disease and neurons in general.

Medical diagnosis of the onset of HD can be made following the appearance of physical symptoms specific to the disease. Genetic testing can be used to confirm a physical diagnosis if there is no family history of HD. Even before the onset of symptoms, genetic testing can confirm if an individual or embryo carries an expanded copy of the trinucleotide repeat in the "HTT" gene that causes the disease. Genetic counseling is available to provide advice and guidance throughout the testing procedure, and on the implications of a confirmed diagnosis. These implications include the impact on an individual's psychology, career, family planning decisions, relatives and relationships. Despite the availability of pre-symptomatic testing, only 5% of those at risk of inheriting HD choose to do so.

A physical examination, sometimes combined with a psychological examination, can determine whether the onset of the disease has begun. Excessive unintentional movements of any part of the body are often the reason for seeking medical consultation. If these are abrupt and have random timing and distribution, they suggest a diagnosis of HD. Cognitive or behavioral symptoms are rarely the first symptoms diagnosed; they are usually only recognized in hindsight or when they develop further. How far the disease has progressed can be measured using the "unified Huntington's disease rating scale", which provides an overall rating system based on motor, behavioral, cognitive, and functional assessments. Medical imaging, such as computerized tomography (CT) and magnetic resonance imaging (MRI), can show atrophy of the caudate nuclei early in the disease, as seen in the illustration to the right, but these changes are not, by themselves, diagnostic of HD. Cerebral atrophy can be seen in the advanced stages of the disease. Functional neuroimaging techniques, such as functional magnetic resonance imaging (fMRI) and positron emission tomography (PET), can show changes in brain activity before the onset of physical symptoms, but they are experimental tools, and are not used clinically.

Because HD follows an autosomal dominant pattern of inheritance, there is a strong motivation for individuals who are at risk of inheriting it to seek a diagnosis. The genetic test for HD consists of a blood test which counts the numbers of CAG repeats in each of the "HTT" alleles. Cutoffs are given as follows:

Testing before the onset of symptoms is a life-changing event and a very personal decision. The main reason given for choosing testing for HD is to aid in career and family decisions. Before 1993 there was not an available test for individuals to learn if they carried the Huntington's gene. At that time surveys indicated that 50–70% of at-risk individuals would have been interested in receiving testing, but since predictive testing has been offered far fewer choose to be tested. Over 95% of individuals at risk of inheriting HD do not proceed with testing, mostly because there is no treatment. A key issue is the anxiety an individual experiences about not knowing whether they will eventually develop HD, compared to the impact of a positive result. Irrespective of the result, stress levels have been found to be lower two years after being tested, but the risk of suicide is increased after a positive test result. Individuals found to have not inherited the disorder may experience survivor guilt with regard to family members who are affected. Other factors taken into account when considering testing include the possibility of discrimination and the implications of a positive result, which usually means a parent has an affected gene and that the individual's siblings will be at risk of inheriting it. In one study genetic discrimination was found in 46% of individuals at risk for Huntington's disease. It occurred at higher rates within personal relationships than health insurance or employment relations. Genetic counseling in HD can provide information, advice and support for initial decision-making, and then, if chosen, throughout all stages of the testing process. Because of the implications of this test, patients who wish to undergo testing must complete three counseling sessions which provide information about Huntington's.

Counseling and guidelines on the use of genetic testing for HD have become models for other genetic disorders, such as autosomal dominant cerebellar ataxias. Presymptomatic testing for HD has also influenced testing for other illnesses with genetic variants such as polycystic kidney disease, familial Alzheimer's disease and breast cancer. The European Molecular Genetics Quality Network have published yearly external quality assessment scheme for molecular genetic testing for this disease and have developed best practice guidelines for genetic testing for HD to assist in testing and reporting of results.

Embryos produced using in vitro fertilization may be genetically tested for HD using preimplantation genetic diagnosis (PGD). This technique, where one or two cells are extracted from a typically 4- to 8-cell embryo and then tested for the genetic abnormality, can then be used to ensure embryos affected with HD genes are not implanted, and therefore any offspring will not inherit the disease. Some forms of preimplantation genetic diagnosis—non-disclosure or exclusion testing—allow at-risk people to have HD-free offspring "without" revealing their own parental genotype, giving no information about whether they themselves are destined to develop HD. In exclusion testing, the embryos' DNA is compared with that of the parents and grandparents to avoid inheritance of the chromosomal region containing the HD gene from the affected grandparent. In non-disclosure testing, only disease-free embryos are replaced in the uterus while the parental genotype and hence parental risk for HD are never disclosed.

It is also possible to obtain a prenatal diagnosis for an embryo or fetus in the womb, using fetal genetic material acquired through chorionic villus sampling. An amniocentesis can be performed if the pregnancy is further along, within 14–18 weeks. This procedure looks at the amniotic fluid surrounding the baby for indicators of the HD mutation. This, too, can be paired with exclusion testing to avoid disclosure of parental genotype. Prenatal testing can be done when a parent has been diagnosed with HD, when they have had genetic testing showing the expansion of the HTT gene, or when they have a 50% chance of inheriting the disease. The parents can be counseled on their options, which include termination of pregnancy, and on the difficulties of a child with the identified gene.

In addition, in at-risk pregnancies due to an affected male partner, non-invasive prenatal diagnosis can be performed by analyzing cell-free fetal DNA in a blood sample taken from the mother (via venipuncture) between six and twelve weeks of pregnancy. It has no procedure-related risk of miscarriage (excepting via needle contamination).

About 99% of HD diagnoses based on the typical symptoms and a family history of the disease are confirmed by genetic testing to have the expanded trinucleotide repeat that causes HD. Most of the remaining are called HD-like (HDL) syndromes. The cause of most HDL diseases is unknown, but those with known causes are due to mutations in the prion protein gene (HDL1), the junctophilin 3 gene (HDL2), a recessively inherited unknown gene (HDL3—only found in two families and poorly understood), and the gene encoding the TATA box-binding protein (SCA17, sometimes called HDL4). Other autosomal dominant diseases that can be misdiagnosed as HD are dentatorubral-pallidoluysian atrophy and neuroferritinopathy. There are also autosomal recessive disorders that resemble sporadic cases of HD. These include chorea acanthocytosis and pantothenate kinase-associated neurodegeneration. One X-linked disorder of this type is McLeod syndrome.

There is no cure for HD, but there are treatments available to reduce the severity of some of its symptoms. For many of these treatments, evidence to confirm their effectiveness in treating symptoms of HD specifically are incomplete. As the disease progresses the ability to care for oneself declines, and carefully managed multidisciplinary caregiving becomes increasingly necessary. Although there have been relatively few studies of exercises and therapies that help rehabilitate cognitive symptoms of HD, there is some evidence for the usefulness of physical therapy, occupational therapy, and speech therapy. An association between caffeine intake and earlier age of onset in Huntington's disease has been found but, since this finding was based on retrospective questionnaire data rather than a blinded, randomized trial or case-control study, this work is a poor basis for guiding lifestyle decisions.

Weight loss and eating difficulties due to dysphagia and other muscle discoordination are common, making nutrition management increasingly important as the disease advances. Thickening agents can be added to liquids as thicker fluids are easier and safer to swallow. Reminding the affected person to eat slowly and to take smaller pieces of food into the mouth may also be of use to prevent choking. If eating becomes too hazardous or uncomfortable, the option of using a percutaneous endoscopic gastrostomy is available. This is a feeding tube, permanently attached through the abdomen into the stomach, which reduces the risk of aspirating food and provides better nutritional management. Assessment and management by speech-language pathologists with experience in Huntington's disease is recommended.

People with Huntington's disease may see a physical therapist for non-invasive and non-medication-based ways of managing the physical symptoms. Physical therapists may implement fall risk assessment and prevention, as well as strengthening, stretching, and cardiovascular exercises. Walking aids may be prescribed as appropriate. Physical therapists also prescribe breathing exercises and airway clearance techniques with the development of respiratory problems. Consensus guidelines on physiotherapy in Huntington's disease have been produced by the European HD Network. Goals of early rehabilitation interventions are prevention of loss of function. Participation in rehabilitation programs during early to middle stage of the disease may be beneficial as it translates into long term maintenance of motor and functional performance. Rehabilitation during the late stage aims to compensate for motor and functional losses. For long-term independent management, the therapist may develop home exercise programs for appropriate people.

Additionally, an increasing number of people with Huntington's disease are turning to palliative care, which aims to improve quality of life through the treatment of the symptoms and stress of serious illness, in addition to their other treatments.

Tetrabenazine was approved in 2000 for treatment of chorea in Huntington's disease in the EU, and in 2008 in the US. Other drugs that help to reduce chorea include neuroleptics and benzodiazepines. Compounds such as amantadine or remacemide are still under investigation but have shown preliminary positive results. Hypokinesia and rigidity, especially in juvenile cases, can be treated with antiparkinsonian drugs, and myoclonic hyperkinesia can be treated with valproic acid.

Psychiatric symptoms can be treated with medications similar to those used in the general population. Selective serotonin reuptake inhibitors and mirtazapine have been recommended for depression, while atypical antipsychotic drugs are recommended for psychosis and behavioral problems. Specialist neuropsychiatric input is recommended as people may require long-term treatment with multiple medications in combination.

The families of individuals, and society at large, who have inherited or are at risk of inheriting HD have generations of experience of HD, but may be unaware of recent breakthroughs in understanding the disease, and of the availability of genetic testing. Genetic counseling benefits these individuals by updating their knowledge, seeking to dispel any unfounded beliefs that they may have, and helping them consider their future options and plans. Also covered is information concerning family planning choices, care management, and other considerations.

The length of the trinucleotide repeat accounts for 60% of the variation in the age symptoms appear and the rate they progress. A longer repeat results in an earlier age of onset and a faster progression of symptoms. Individuals with more than sixty repeats often develop the disease before age 20, while those with fewer than 40 repeats may not ever develop noticeable symptoms. The remaining variation is due to environmental factors and other genes that influence the mechanism of the disease.

Life expectancy in HD is generally around 20 years following the onset of visible symptoms. Most life-threatening complications result from muscle coordination and, to a lesser extent, behavioral changes induced by declining cognitive function. The largest risk is pneumonia, which causes death in one third of those with HD. As the ability to synchronize movements deteriorates, difficulty clearing the lungs and an increased risk of aspirating food or drink both increase the risk of contracting pneumonia. The second greatest risk is heart disease, which causes almost a quarter of fatalities of those with HD. Suicide is the third greatest cause of fatalities, with 7.3% of those with HD taking their own lives and up to 27% attempting to do so. It is unclear to what extent suicidal thoughts are influenced by behavioral symptoms, as they signify sufferers' desires to avoid the later stages of the disease. Other associated risks include choking, physical injury from falls, and malnutrition.

The late onset of Huntington's disease means it does not usually affect reproduction. The worldwide prevalence of HD is 5–10 cases per 100,000 persons, but varies greatly geographically as a result of ethnicity, local migration and past immigration patterns. Prevalence is similar for men and women. The rate of occurrence is highest in peoples of Western European descent, averaging around 7 per 100,000 people, and is lower in the rest of the world; e.g., one per million people of Asian and African descent. A 2013 epidemiological study of the prevalence of Huntington's disease in the UK between 1990 and 2010 found that the average prevalence for the UK was 12.3 per 100,000. Additionally, some localized areas have a much higher prevalence than their regional average. One of the highest incidences is in the isolated populations of the Lake Maracaibo region of Venezuela, where HD affects up to 700 per 100,000 persons. Other areas of high localization have been found in Tasmania and specific regions of Scotland, Wales and Sweden. Increased prevalence in some cases occurs due to a local founder effect, a historical migration of carriers into an area of geographic isolation. Some of these carriers have been traced back hundreds of years using genealogical studies. Genetic haplotypes can also give clues for the geographic variations of prevalence. Iceland, on the contrary, has a rather low prevalence of 1 per 100,000, despite the fact that Icelanders as a people are descended of the early Germanic tribes of Scandinavia which also gave rise to the Swedes; all cases with the exception of one going back nearly two centuries having derived from the offspring of a couple living early in the 19th century. Finland, as well, has a low incidence of only 2.2 per 100,000 people.

Until the discovery of a genetic test, statistics could only include clinical diagnosis based on physical symptoms and a family history of HD, excluding those who died of other causes before diagnosis. These cases can now be included in statistics; and, as the test becomes more widely available, estimates of the prevalence and incidence of the disorder are likely to increase.

Although Huntington's has been recognized as a disorder since at least the Middle Ages, the cause has been unknown until fairly recently. Huntington's was given different names throughout this history as understanding of the disease changed. Originally called simply 'chorea' for the jerky dancelike movements associated with the disease, HD has also been called "hereditary chorea" and "chronic progressive chorea". The first definite mention of HD was in a letter by Charles Oscar Waters, published in the first edition of Robley Dunglison's "Practice of Medicine" in 1842. Waters described "a form of chorea, vulgarly called magrums", including accurate descriptions of the chorea, its progression, and the strong heredity of the disease. In 1846 Charles Gorman observed how higher prevalence seemed to occur in localized regions. Independently of Gorman and Waters, both students of Dunglison at Jefferson Medical College in Philadelphia, Johan Christian Lund also produced an early description in 1860. He specifically noted that in Setesdalen, a secluded mountain valley in Norway, there was a high prevalence of dementia associated with a pattern of jerking movement disorders that ran in families.

The first thorough description of the disease was by George Huntington in 1872. Examining the combined medical history of several generations of a family exhibiting similar symptoms, he realized their conditions must be linked; he presented his detailed and accurate definition of the disease as his first paper. Huntington described the exact pattern of inheritance of autosomal dominant disease years before the rediscovery by scientists of Mendelian inheritance."Of its hereditary nature. When either or both the parents have shown manifestations of the disease ..., one or more of the offspring almost invariably suffer from the disease ... But if by any chance these children go through life without it, the thread is broken and the grandchildren and great-grandchildren of the original shakers may rest assured that they are free from the disease.". Sir William Osler was interested in the disorder and chorea in general, and was impressed with Huntington's paper, stating that "In the history of medicine, there are few instances in which a disease has been more accurately, more graphically or more briefly described." Osler's continued interest in HD, combined with his influence in the field of medicine, helped to rapidly spread awareness and knowledge of the disorder throughout the medical community. Great interest was shown by scientists in Europe, including Louis Théophile Joseph Landouzy, Désiré-Magloire Bourneville, Camillo Golgi, and Joseph Jules Dejerine, and until the end of the century, much of the research into HD was European in origin. By the end of the 19th century, research and reports on HD had been published in many countries and the disease was recognized as a worldwide condition.

During the rediscovery of Mendelian inheritance at the turn of the 20th century, HD was used tentatively as an example of autosomal dominant inheritance. The English biologist William Bateson used the pedigrees of affected families to establish that HD had an autosomal dominant inheritance pattern. The strong inheritance pattern prompted several researchers, including Smith Ely Jelliffe, to attempt to trace and connect family members of previous studies. Jelliffe collected information from across New York and published several articles regarding the genealogy of HD in New England. Jelliffe's research roused the interest of his college friend, Charles Davenport, who commissioned Elizabeth Muncey to produce the first field study on the East Coast of the United States of families with HD and to construct their pedigrees. Davenport used this information to document the variable age of onset and range of symptoms of HD; he claimed that most cases of HD in the USA could be traced back to a handful of individuals. This research was further embellished in 1932 by P. R. Vessie, who popularized the idea that three brothers who left England in 1630 bound for Boston were the progenitors of HD in the USA. The claim that the earliest progenitors had been established and eugenic bias of Muncey's, Davenport's, and Vessie's work contributed to misunderstandings and prejudice about HD. Muncey and Davenport also popularized the idea that in the past some HD sufferers may have been thought to be possessed by spirits or victims of witchcraft, and were sometimes shunned or exiled by society. This idea has not been proven. Researchers have found contrary evidence; for instance, the community of the family studied by George Huntington openly accommodated those who exhibited symptoms of HD.

The search for the cause of this condition was enhanced considerably in 1968, when the Hereditary Disease Foundation (HDF) was created by Milton Wexler, a psychoanalyst based in Los Angeles, California, whose wife Leonore Sabin had been diagnosed earlier that year with Huntington's disease. The three brothers of Wexler's wife also suffered from this disease. The foundation was involved in the recruitment of over 100 scientists in the Huntington's Disease Collaborative Research Project who over a 10-year period worked to locate the responsible gene.

Thanks to the HDF, the ongoing US-Venezuela Huntington's Disease Collaborative Research Project was started in 1979, and reported a major breakthrough in 1983 with the discovery of the approximate location of a causal gene. This was the result of an extensive study focusing on the populations of two isolated Venezuelan villages, Barranquitas and Lagunetas, where there was an unusually high prevalence of the disease. It involved over 18,000 people—mostly from a single extended family.

Among other innovations, the project developed DNA-marking methods which were an important step in making the Human Genome Project possible. In 1993, the research group isolated the precise causal gene at 4p16.3, making this the first autosomal disease locus found using genetic linkage analysis.

In the same time frame, key discoveries concerning the mechanisms of the disorder were being made, including the findings by Anita Harding's research group on the effects of the gene's length.

Modelling the disease in various types of animals, such as the transgenic mouse developed in 1996, enabled larger scale experiments. As these animals have faster metabolisms and much shorter lifespans than humans, results from experiments are received sooner, speeding research. The 1997 discovery that mHTT fragments misfold led to the discovery of the nuclear inclusions they cause. These advances have led to increasingly extensive research into the proteins involved with the disease, potential drug treatments, care methods, and the gene itself.

The condition was formerly called 'Huntington's chorea' but this term has been replaced by 'Huntington's disease' because not all patients develop chorea and due to the importance of cognitive and behavioral problems.

Huntington's disease, particularly the application of the genetic test for the disease, has raised several ethical issues. The issues for genetic testing include defining how mature an individual should be before being considered eligible for testing, ensuring the confidentiality of results, and whether companies should be allowed to use test results for decisions on employment, life insurance or other financial matters. There was controversy when Charles Davenport proposed in 1910 that compulsory sterilization and immigration control be used for people with certain diseases, including HD, as part of the eugenics movement. In vitro fertilization has some issues regarding its use of embryos. Some HD research has ethical issues due to its use of animal testing and embryonic stem cells.

The development of an accurate diagnostic test for Huntington's disease has caused social, legal, and ethical concerns over access to and use of a person's results.
Many guidelines and testing procedures have strict procedures for disclosure and confidentiality to allow individuals to decide when and how to receive their results and also to whom the results are made available. Financial institutions and businesses are faced with the question of whether to use genetic test results when assessing an individual, such as for life insurance or employment. The United Kingdom's insurance companies have agreed with the Department of Health and Social Care that until 2017 customers need not disclose predictive genetics tests to them, but this agreement explicitly excludes the government-approved test for Huntington's when writing policies with a value over . As with other untreatable genetic conditions with a later onset, it is ethically questionable to perform pre-symptomatic testing on a child or adolescent, as there would be no medical benefit for that individual. There is consensus for testing only individuals who are considered cognitively mature, although there is a counter-argument that parents have a right to make the decision on their child's behalf. With the lack of an effective treatment, testing a person under legal age who is not judged to be competent is considered unethical in most cases.

There are ethical concerns related to prenatal genetic testing or preimplantation genetic diagnosis to ensure a child is not born with a given disease. For example, prenatal testing raises the issue of selective abortion, a choice considered unacceptable by some. As it is a dominant disease, there are difficulties in situations in which a parent does not want to know his or her own diagnosis. This would require parts of the process to be kept secret from the parent.

In 1968, after experiencing HD in his wife's family, Dr. Milton Wexler was inspired to start the Hereditary Disease Foundation (HDF), with the aim of curing genetic illnesses by coordinating and supporting research. The foundation and Wexler's daughter, Nancy Wexler, were key parts of the research team in Venezuela which discovered the HD gene.

At roughly the same time as the HDF formed, Marjorie Guthrie helped to found the Committee to Combat Huntington's Disease (now the Huntington's Disease Society of America), after her husband Woody Guthrie died from complications of HD.

Since then, support and research organizations have formed in many countries around the world and have helped to increase public awareness of HD. A number of these collaborate in umbrella organizations, like the International Huntington Association and the European HD network. Many support organizations hold an annual HD awareness event, some of which have been endorsed by their respective governments. For example, 6 June is designated "National Huntington's Disease Awareness Day" by the US Senate.

The largest funder of Huntington's disease research globally, in terms of financial expenditure, is the CHDI Foundation, a US non-profit biomedical foundation that aims to "rapidly discover and develop drugs that delay or slow Huntington's disease". CHDI was formerly known as the High Q Foundation. In 2006, it spent $50 million on Huntington's disease research. CHDI collaborates with many academic and commercial laboratories globally and engages in oversight and management of research projects as well as funding. Many organizations exist to support and inform those affected by HD.

Research into the mechanism of HD has focused on identifying the functioning of HTT, how mHTT differs or interferes with it, and the brain pathology that the disease produces. Research is conducted using "in vitro" methods, animal models and human volunteers. Animal models are critical for understanding the fundamental mechanisms causing the disease and for supporting the early stages of drug development. Animals with chemically induced brain injury exhibit HD-like symptoms and were initially used, but they did not mimic the progressive features of the disease. The identification of the causative gene has enabled the development of many transgenic animal models including nematode worms, "Drosophila" fruit flies, mice, rats, sheep, pigs and monkeys that express mutant huntingtin and develop progressive neurodegeneration and HD-like symptoms.

Research is being conducted on many different approaches to prevent Huntington's disease or slow its progression. Disease-modifying strategies can be broadly grouped into three categories: reducing the level of the mutant huntingtin protein (including gene splicing and gene silencing); approaches aimed at improving neuronal survival by reducing the harm caused by the protein to specific cellular pathways and mechanisms (including protein homeostasis and histone deacetylase inhibition); and strategies to replace lost neurons. In addition, novel therapies to improve brain functioning are under development; these seek to produce symptomatic rather than disease-modifying therapies, and include phosphodiesterase inhibitors.

Gene silencing aims to reduce the production of the mutant protein, since HD is caused by a single dominant gene encoding a toxic protein. Gene silencing experiments in mouse models have shown that when the expression of mHTT is reduced, symptoms improve. Safety of non-allele specific RNAi and ASO gene silencing has now been demonstrated in mice and the large, human-like brains of primates. Allele-specific silencing attempts to silence mutant HTT while leaving wild-type HTT untouched. One way of accomplishing this is to identify polymorphisms present on only one allele and produce gene silencing drugs that target polymorphisms in only the mutant allele. The first 'gene silencing' trial involving human HD patients began in 2015, testing the safety of IONIS-HTTRx, produced by Ionis Pharmaceuticals and led by UCL Institute of Neurology. Mutant huntingtin was detected and quantified for the first time in cerebrospinal fluid from Huntington's disease mutation-carriers in 2015 using a novel 'single-molecule counting' immunoassay, providing a direct way to assess whether huntingtin-lowering treatments are achieving the desired effect. Similarly, gene splicing techniques are being looked at to try to repair a genome with the erroneous gene that causes HD, using tools such as CRISPR/Cas9.

Among the approaches aimed at improving cell survival in the presence of mutant huntingtin are correction of transcriptional regulation using histone deacetylase inhibitors, modulating aggregation of huntingtin, improving metabolism and mitochondrial function and restoring function of synapses.

Stem cell therapy is the replacement of damaged neurons by transplantation of stem cells into affected regions of the brain. Experiments have yielded mixed results using this technique in animal models and preliminary human clinical trials. Whatever their future therapeutic potential, stem cells are already a valuable tool for studying Huntington's disease in the laboratory.

Several clinical trials of new experimental treatments are underway and planned in Huntington's disease.

Compounds that have failed to prevent or slow progression of Huntington's disease in human trials include remacemide, coenzyme Q10, riluzole, creatine, minocycline, ethyl-EPA, phenylbutyrate and dimebon.




</doc>
<doc id="47923" url="https://en.wikipedia.org/wiki?curid=47923" title="Queen Victoria">
Queen Victoria

Victoria (Alexandrina Victoria; 24 May 1819 – 22 January 1901) was Queen of the United Kingdom of Great Britain and Ireland from 20 June 1837 until her death. On 1 May 1876, she adopted the additional title of Empress of India.

Victoria was the daughter of Prince Edward, Duke of Kent and Strathearn, the fourth son of King George III. Both the Duke and the King died in 1820, and Victoria was raised under close supervision by her mother, Princess Victoria of Saxe-Coburg-Saalfeld. She inherited the throne at the age of 18, after her father's three elder brothers had all died, leaving no surviving legitimate children. The United Kingdom was already an established constitutional monarchy, in which the sovereign held relatively little direct political power. Privately, Victoria attempted to influence government policy and ministerial appointments; publicly, she became a national icon who was identified with strict standards of personal morality.

Victoria married her first cousin Prince Albert of Saxe-Coburg and Gotha in 1840. Their nine children married into royal and noble families across the continent, tying them together and earning her the sobriquet "the grandmother of Europe". After Albert's death in 1861, Victoria plunged into deep mourning and avoided public appearances. As a result of her seclusion, republicanism temporarily gained strength, but in the latter half of her reign, her popularity recovered. Her Golden and Diamond Jubilees were times of public celebration.

Her reign of 63 years and seven months was longer than that of any of her predecessors and is known as the Victorian era. It was a period of industrial, cultural, political, scientific, and military change within the United Kingdom, and was marked by a great expansion of the British Empire. She was the last British monarch of the House of Hanover. Her son and successor, Edward VII, initiated the House of Saxe-Coburg and Gotha, the line of his father.

Victoria's father was Prince Edward, Duke of Kent and Strathearn, the fourth son of the reigning King of the United Kingdom, George III. Until 1817, Edward's niece, Princess Charlotte of Wales, was the only legitimate grandchild of George III. Her death in 1817 precipitated a succession crisis that brought pressure on the Duke of Kent and his unmarried brothers to marry and have children. In 1818 he married Princess Victoria of Saxe-Coburg-Saalfeld, a widowed German princess with two children—Carl (1804–1856) and Feodora (1807–1872)—by her first marriage to the Prince of Leiningen. Her brother Leopold was Princess Charlotte's widower. The Duke and Duchess of Kent's only child, Victoria, was born at 4.15 a.m. on 24May 1819 at Kensington Palace in London.

Victoria was christened privately by the Archbishop of Canterbury, Charles Manners-Sutton, on 24June 1819 in the Cupola Room at Kensington Palace. She was baptised "Alexandrina" after one of her godparents, Emperor Alexander I of Russia, and "Victoria", after her mother. Additional names proposed by her parents—Georgina (or Georgiana), Charlotte, and Augusta—were dropped on the instructions of Kent's eldest brother, George, the Prince Regent.

At birth, Victoria was fifth in the line of succession after the four eldest sons of GeorgeIII: George, the Prince Regent (later GeorgeIV); Frederick, the Duke of York; William, the Duke of Clarence (later WilliamIV); and Victoria's father, Edward, the Duke of Kent. The Prince Regent had no surviving children, and the Duke of York had no children; further, both were estranged from their wives, who were both past child-bearing age, so the two eldest brothers were unlikely to have any further children. The Duke of Clarence and the Duke of Kent married on the same day in 1818, but both of Clarence's legitimate daughters (born in 1819 and 1820) died as infants. Victoria's father died in January 1820, when Victoria was less than a year old. A week later her grandfather died and was succeeded by his eldest son, GeorgeIV. The Duke of York died in 1827. When GeorgeIV died in 1830, he was succeeded by his next surviving brother, WilliamIV, and Victoria became heir presumptive. The Regency Act 1830 made special provision for Victoria's mother to act as regent in case William died while Victoria was still a minor. King William distrusted the Duchess's capacity to be regent, and in 1836 he declared in her presence that he wanted to live until Victoria's 18th birthday, so that a regency could be avoided.

Victoria later described her childhood as "rather melancholy". Her mother was extremely protective, and Victoria was raised largely isolated from other children under the so-called "Kensington System", an elaborate set of rules and protocols devised by the Duchess and her ambitious and domineering comptroller, Sir John Conroy, who was rumoured to be the Duchess's lover. The system prevented the princess from meeting people whom her mother and Conroy deemed undesirable (including most of her father's family), and was designed to render her weak and dependent upon them. The Duchess avoided the court because she was scandalised by the presence of King William's illegitimate children. Victoria shared a bedroom with her mother every night, studied with private tutors to a regular timetable, and spent her play-hours with her dolls and her King Charles Spaniel, Dash. Her lessons included French, German, Italian, and Latin, but she spoke only English at home.
In 1830, the Duchess of Kent and Conroy took Victoria across the centre of England to visit the Malvern Hills, stopping at towns and great country houses along the way. Similar journeys to other parts of England and Wales were taken in 1832, 1833, 1834 and 1835. To the King's annoyance, Victoria was enthusiastically welcomed in each of the stops. William compared the journeys to royal progresses and was concerned that they portrayed Victoria as his rival rather than his heir presumptive. Victoria disliked the trips; the constant round of public appearances made her tired and ill, and there was little time for her to rest. She objected on the grounds of the King's disapproval, but her mother dismissed his complaints as motivated by jealousy and forced Victoria to continue the tours. At Ramsgate in October 1835, Victoria contracted a severe fever, which Conroy initially dismissed as a childish pretence. While Victoria was ill, Conroy and the Duchess unsuccessfully badgered her to make Conroy her private secretary. As a teenager, Victoria resisted persistent attempts by her mother and Conroy to appoint him to her staff. Once queen, she banned him from her presence, but he remained in her mother's household.

By 1836, the Duchess's brother, Leopold, who had been King of the Belgians since 1831, hoped to marry his niece to his nephew, Prince Albert of Saxe-Coburg and Gotha. Leopold, Victoria's mother, and Albert's father (Ernest I, Duke of Saxe-Coburg and Gotha) were siblings. Leopold arranged for Victoria's mother to invite her Coburg relatives to visit her in May 1836, with the purpose of introducing Victoria to Albert. William IV, however, disapproved of any match with the Coburgs, and instead favoured the suit of Prince Alexander of the Netherlands, second son of the Prince of Orange. Victoria was aware of the various matrimonial plans and critically appraised a parade of eligible princes. According to her diary, she enjoyed Albert's company from the beginning. After the visit she wrote, "[Albert] is extremely handsome; his hair is about the same colour as mine; his eyes are large and blue, and he has a beautiful nose and a very sweet mouth with fine teeth; but the charm of his countenance is his expression, which is most delightful." Alexander, on the other hand, she described as "very plain".

Victoria wrote to her uncle Leopold, whom Victoria considered her "best and kindest adviser", to thank him "for the prospect of "great" happiness you have contributed to give me, in the person of dear Albert ... He possesses every quality that could be desired to render me perfectly happy. He is so sensible, so kind, and so good, and so amiable too. He has besides the most pleasing and delightful exterior and appearance you can possibly see." However at 17, Victoria, though interested in Albert, was not yet ready to marry. The parties did not undertake a formal engagement, but assumed that the match would take place in due time.

Victoria turned 18 on 24 May 1837, and a regency was avoided. Less than a month later, on 20 June 1837, William IV died at the age of 71, and Victoria became Queen of the United Kingdom. In her diary she wrote, "I was awoke at 6 o'clock by Mamma, who told me the Archbishop of Canterbury and Lord Conyngham were here and wished to see me. I got out of bed and went into my sitting-room (only in my dressing gown) and "alone", and saw them. Lord Conyngham then acquainted me that my poor Uncle, the King, was no more, and had expired at 12 minutes past 2 this morning, and consequently that "I" am "Queen"." Official documents prepared on the first day of her reign described her as Alexandrina Victoria, but the first name was withdrawn at her own wish and not used again.

Since 1714, Britain had shared a monarch with Hanover in Germany, but under Salic law women were excluded from the Hanoverian succession. While Victoria inherited all the British Dominions, her father's younger brother, her unpopular uncle the Duke of Cumberland, became King of Hanover. He was her heir presumptive while she was childless.

At the time of Victoria's accession, the government was led by the Whig prime minister Lord Melbourne. The Prime Minister at once became a powerful influence on the politically inexperienced Queen, who relied on him for advice. Charles Greville supposed that the widowed and childless Melbourne was "passionately fond of her as he might be of his daughter if he had one", and Victoria probably saw him as a father figure. Her coronation took place on 28 June 1838 at Westminster Abbey. Over 400,000 visitors came to London for the celebrations. She became the first sovereign to take up residence at Buckingham Palace and inherited the revenues of the duchies of Lancaster and Cornwall as well as being granted a civil list allowance of £385,000 per year. Financially prudent, she paid off her father's debts.

At the start of her reign Victoria was popular, but her reputation suffered in an 1839 court intrigue when one of her mother's ladies-in-waiting, Lady Flora Hastings, developed an abdominal growth that was widely rumoured to be an out-of-wedlock pregnancy by Sir John Conroy. Victoria believed the rumours. She hated Conroy, and despised "that odious Lady Flora", because she had conspired with Conroy and the Duchess of Kent in the Kensington System. At first, Lady Flora refused to submit to an intimate medical examination, until in mid-February she eventually agreed, and was found to be a virgin. Conroy, the Hastings family, and the opposition Tories organised a press campaign implicating the Queen in the spreading of false rumours about Lady Flora. When Lady Flora died in July, the post-mortem revealed a large tumour on her liver that had distended her abdomen. At public appearances, Victoria was hissed and jeered as "Mrs. Melbourne".

In 1839, Melbourne resigned after Radicals and Tories (both of whom Victoria detested) voted against a bill to suspend the constitution of Jamaica. The bill removed political power from plantation owners who were resisting measures associated with the abolition of slavery. The Queen commissioned a Tory, Sir Robert Peel, to form a new ministry. At the time, it was customary for the prime minister to appoint members of the Royal Household, who were usually his political allies and their spouses. Many of the Queen's ladies of the bedchamber were wives of Whigs, and Peel expected to replace them with wives of Tories. In what became known as the bedchamber crisis, Victoria, advised by Melbourne, objected to their removal. Peel refused to govern under the restrictions imposed by the Queen, and consequently resigned his commission, allowing Melbourne to return to office.

Though Victoria was now queen, as an unmarried young woman she was required by social convention to live with her mother, despite their differences over the Kensington System and her mother's continued reliance on Conroy. Her mother was consigned to a remote apartment in Buckingham Palace, and Victoria often refused to see her. When Victoria complained to Melbourne that her mother's close proximity promised "torment for many years", Melbourne sympathised but said it could be avoided by marriage, which Victoria called a "schocking alternative". Victoria showed interest in Albert's education for the future role he would have to play as her husband, but she resisted attempts to rush her into wedlock.

Victoria continued to praise Albert following his second visit in October 1839. Albert and Victoria felt mutual affection and the Queen proposed to him on 15 October 1839, just five days after he had arrived at Windsor. They were married on 10 February 1840, in the Chapel Royal of St James's Palace, London. Victoria was love-struck. She spent the evening after their wedding lying down with a headache, but wrote ecstatically in her diary:

Albert became an important political adviser as well as the Queen's companion, replacing Lord Melbourne as the dominant influential figure in the first half of her life. Victoria's mother was evicted from the palace, to Ingestre House in Belgrave Square. After the death of Victoria's aunt, Princess Augusta, in 1840, Victoria's mother was given both Clarence and Frogmore Houses. Through Albert's mediation, relations between mother and daughter slowly improved.

During Victoria's first pregnancy in 1840, in the first few months of the marriage, 18-year-old Edward Oxford attempted to assassinate her while she was riding in a carriage with Prince Albert on her way to visit her mother. Oxford fired twice, but either both bullets missed or, as he later claimed, the guns had no shot. He was tried for high treason, found not guilty on the grounds of insanity, committed to an insane asylum indefinitely, and later sent to live in Australia. In the immediate aftermath of the attack, Victoria's popularity soared, mitigating residual discontent over the Hastings affair and the bedchamber crisis. Her daughter, also named Victoria, was born on 21 November 1840. The Queen hated being pregnant, viewed breast-feeding with disgust, and thought newborn babies were ugly. Nevertheless, over the following seventeen years, she and Albert had a further eight children: Albert Edward (b. 1841), Alice (b. 1843), Alfred (b. 1844), Helena (b. 1846), Louise (b. 1848), Arthur (b. 1850), Leopold (b. 1853) and Beatrice (b. 1857).

Victoria's household was largely run by her childhood governess, Baroness Louise Lehzen from Hanover. Lehzen had been a formative influence on Victoria and had supported her against the Kensington System. Albert, however, thought that Lehzen was incompetent and that her mismanagement threatened his daughter's health. After a furious row between Victoria and Albert over the issue, Lehzen was pensioned off in 1842, and Victoria's close relationship with her ended.

On 29 May 1842, Victoria was riding in a carriage along The Mall, London, when John Francis aimed a pistol at her, but the gun did not fire. The assailant escaped; however the following day, Victoria drove the same route, though faster and with a greater escort, in a deliberate attempt to provoke Francis to take a second aim and catch him in the act. As expected, Francis shot at her, but he was seized by plainclothes policemen, and convicted of high treason. On 3 July, two days after Francis's death sentence was commuted to transportation for life, John William Bean also tried to fire a pistol at the Queen, but it was loaded only with paper and tobacco and had too little charge. Edward Oxford felt that the attempts were encouraged by his acquittal in 1840. Bean was sentenced to 18 months in jail. In a similar attack in 1849, unemployed Irishman William Hamilton fired a powder-filled pistol at Victoria's carriage as it passed along Constitution Hill, London. In 1850, the Queen did sustain injury when she was assaulted by a possibly insane ex-army officer, Robert Pate. As Victoria was riding in a carriage, Pate struck her with his cane, crushing her bonnet and bruising her forehead. Both Hamilton and Pate were sentenced to seven years' transportation.

Melbourne's support in the House of Commons weakened through the early years of Victoria's reign, and in the 1841 general election the Whigs were defeated. Peel became prime minister, and the ladies of the bedchamber most associated with the Whigs were replaced.
In 1845, Ireland was hit by a potato blight. In the next four years, over a million Irish people died and another million emigrated in what became known as the Great Famine. In Ireland, Victoria was labelled "The Famine Queen". In January 1847 she personally donated £2,000 (equivalent to between £178,000 and £6.5 million in 2016) to the British Relief Association, more than any other individual famine relief donor, and also supported the Maynooth Grant to a Roman Catholic seminary in Ireland, despite Protestant opposition. The story that she donated only £5 in aid to the Irish, and on the same day gave the same amount to Battersea Dogs Home, was a myth generated towards the end of the 19th century.

By 1846, Peel's ministry faced a crisis involving the repeal of the Corn Laws. Many Tories—by then known also as Conservatives—were opposed to the repeal, but Peel, some Tories (the "Peelites"), most Whigs and Victoria supported it. Peel resigned in 1846, after the repeal narrowly passed, and was replaced by Lord John Russell.
Internationally, Victoria took a keen interest in the improvement of relations between France and Britain. She made and hosted several visits between the British royal family and the House of Orleans, who were related by marriage through the Coburgs. In 1843 and 1845, she and Albert stayed with King Louis Philippe I at château d'Eu in Normandy; she was the first British or English monarch to visit a French monarch since the meeting of Henry VIII of England and Francis I of France on the Field of the Cloth of Gold in 1520. When Louis Philippe made a reciprocal trip in 1844, he became the first French king to visit a British sovereign. Louis Philippe was deposed in the revolutions of 1848, and fled to exile in England. At the height of a revolutionary scare in the United Kingdom in April 1848, Victoria and her family left London for the greater safety of Osborne House, a private estate on the Isle of Wight that they had purchased in 1845 and redeveloped. Demonstrations by Chartists and Irish nationalists failed to attract widespread support, and the scare died down without any major disturbances. Victoria's first visit to Ireland in 1849 was a public relations success, but it had no lasting impact or effect on the growth of Irish nationalism.

Russell's ministry, though Whig, was not favoured by the Queen. She found particularly offensive the Foreign Secretary, Lord Palmerston, who often acted without consulting the Cabinet, the Prime Minister, or the Queen. Victoria complained to Russell that Palmerston sent official dispatches to foreign leaders without her knowledge, but Palmerston was retained in office and continued to act on his own initiative, despite her repeated remonstrances. It was only in 1851 that Palmerston was removed after he announced the British government's approval of President Louis-Napoleon Bonaparte's coup in France without consulting the Prime Minister. The following year, President Bonaparte was declared Emperor Napoleon III, by which time Russell's administration had been replaced by a short-lived minority government led by Lord Derby.

In 1853, Victoria gave birth to her eighth child, Leopold, with the aid of the new anaesthetic, chloroform. Victoria was so impressed by the relief it gave from the pain of childbirth that she used it again in 1857 at the birth of her ninth and final child, Beatrice, despite opposition from members of the clergy, who considered it against biblical teaching, and members of the medical profession, who thought it dangerous. Victoria may have suffered from postnatal depression after many of her pregnancies. Letters from Albert to Victoria intermittently complain of her loss of self-control. For example, about a month after Leopold's birth Albert complained in a letter to Victoria about her "continuance of hysterics" over a "miserable trifle".

In early 1855, the government of Lord Aberdeen, who had replaced Derby, fell amidst recriminations over the poor management of British troops in the Crimean War. Victoria approached both Derby and Russell to form a ministry, but neither had sufficient support, and Victoria was forced to appoint Palmerston as prime minister.

Napoleon III, since the Crimean War Britain's closest ally, visited London in April 1855, and from 17 to 28 August the same year Victoria and Albert returned the visit. Napoleon III met the couple at Boulogne and accompanied them to Paris. They visited the Exposition Universelle (a successor to Albert's 1851 brainchild the Great Exhibition) and Napoleon I's tomb at Les Invalides (to which his remains had only been returned in 1840), and were guests of honour at a 1,200-guest ball at the Palace of Versailles.

On 14 January 1858, an Italian refugee from Britain called Felice Orsini attempted to assassinate Napoleon III with a bomb made in England. The ensuing diplomatic crisis destabilised the government, and Palmerston resigned. Derby was reinstated as prime minister. Victoria and Albert attended the opening of a new basin at the French military port of Cherbourg on 5 August 1858, in an attempt by Napoleon III to reassure Britain that his military preparations were directed elsewhere. On her return Victoria wrote to Derby reprimanding him for the poor state of the Royal Navy in comparison to the French one. Derby's ministry did not last long, and in June 1859 Victoria recalled Palmerston to office.

Eleven days after Orsini's assassination attempt in France, Victoria's eldest daughter married Prince Frederick William of Prussia in London. They had been betrothed since September 1855, when Princess Victoria was 14 years old; the marriage was delayed by the Queen and Prince Albert until the bride was 17. The Queen and Albert hoped that their daughter and son-in-law would be a liberalising influence in the enlarging Prussian state. Victoria felt "sick at heart" to see her daughter leave England for Germany; "It really makes me shudder", she wrote to Princess Victoria in one of her frequent letters, "when I look round to all your sweet, happy, unconscious sisters, and think I must give them up too – one by one." Almost exactly a year later, Princess Victoria gave birth to the Queen's first grandchild, Wilhelm, who would become the last German Emperor.

In March 1861, Victoria's mother died, with Victoria at her side. Through reading her mother's papers, Victoria discovered that her mother had loved her deeply; she was heart-broken, and blamed Conroy and Lehzen for "wickedly" estranging her from her mother. To relieve his wife during her intense and deep grief, Albert took on most of her duties, despite being ill himself with chronic stomach trouble. In August, Victoria and Albert visited their son, Edward, Prince of Wales, who was attending army manoeuvres near Dublin, and spent a few days holidaying in Killarney. In November, Albert was made aware of gossip that his son had slept with an actress in Ireland. Appalled, Albert travelled to Cambridge, where his son was studying, to confront him. By the beginning of December, Albert was very unwell. He was diagnosed with typhoid fever by William Jenner, and died on 14 December 1861. Victoria was devastated. She blamed her husband's death on worry over the Prince of Wales's philandering. He had been "killed by that dreadful business", she said. She entered a state of mourning and wore black for the remainder of her life. She avoided public appearances, and rarely set foot in London in the following years. Her seclusion earned her the nickname "widow of Windsor". Her weight increased through comfort eating, which further reinforced her aversion to public appearances.

Victoria's self-imposed isolation from the public diminished the popularity of the monarchy, and encouraged the growth of the republican movement. She did undertake her official government duties, yet chose to remain secluded in her royal residences—Windsor Castle, Osborne House, and the private estate in Scotland that she and Albert had acquired in 1847, Balmoral Castle. In March 1864 a protester stuck a notice on the railings of Buckingham Palace that announced "these commanding premises to be let or sold in consequence of the late occupant's declining business". Her uncle Leopold wrote to her advising her to appear in public. She agreed to visit the gardens of the Royal Horticultural Society at Kensington and take a drive through London in an open carriage.

Through the 1860s, Victoria relied increasingly on a manservant from Scotland, John Brown. Slanderous rumours of a romantic connection and even a secret marriage appeared in print, and the Queen was referred to as "Mrs. Brown". The story of their relationship was the subject of the 1997 movie "Mrs. Brown". A painting by Sir Edwin Henry Landseer depicting the Queen with Brown was exhibited at the Royal Academy, and Victoria published a book, "Leaves from the Journal of Our Life in the Highlands", which featured Brown prominently and in which the Queen praised him highly.

Palmerston died in 1865, and after a brief ministry led by Russell, Derby returned to power. In 1866, Victoria attended the State Opening of Parliament for the first time since Albert's death. The following year she supported the passing of the Reform Act 1867 which doubled the electorate by extending the franchise to many urban working men, though she was not in favour of votes for women. Derby resigned in 1868, to be replaced by Benjamin Disraeli, who charmed Victoria. "Everyone likes flattery," he said, "and when you come to royalty you should lay it on with a trowel." With the phrase "we authors, Ma'am", he complimented her. Disraeli's ministry only lasted a matter of months, and at the end of the year his Liberal rival, William Ewart Gladstone, was appointed prime minister. Victoria found Gladstone's demeanour far less appealing; he spoke to her, she is thought to have complained, as though she were "a public meeting rather than a woman".

In 1870 republican sentiment in Britain, fed by the Queen's seclusion, was boosted after the establishment of the Third French Republic. A republican rally in Trafalgar Square demanded Victoria's removal, and Radical MPs spoke against her. In August and September 1871, she was seriously ill with an abscess in her arm, which Joseph Lister successfully lanced and treated with his new antiseptic carbolic acid spray. In late November 1871, at the height of the republican movement, the Prince of Wales contracted typhoid fever, the disease that was believed to have killed his father, and Victoria was fearful her son would die. As the tenth anniversary of her husband's death approached, her son's condition grew no better, and Victoria's distress continued. To general rejoicing, he recovered. Mother and son attended a public parade through London and a grand service of thanksgiving in St Paul's Cathedral on 27 February 1872, and republican feeling subsided.

On the last day of February 1872, two days after the thanksgiving service, 17-year-old Arthur O'Connor, a great-nephew of Irish MP Feargus O'Connor, waved an unloaded pistol at Victoria's open carriage just after she had arrived at Buckingham Palace. Brown, who was attending the Queen, grabbed him and O'Connor was later sentenced to 12 months' imprisonment, and a birching. As a result of the incident, Victoria's popularity recovered further.

After the Indian Rebellion of 1857, the British East India Company, which had ruled much of India, was dissolved, and Britain's possessions and protectorates on the Indian subcontinent were formally incorporated into the British Empire. The Queen had a relatively balanced view of the conflict, and condemned atrocities on both sides. She wrote of "her feelings of horror and regret at the result of this bloody civil war", and insisted, urged on by Albert, that an official proclamation announcing the transfer of power from the company to the state "should breathe feelings of generosity, benevolence and religious toleration". At her behest, a reference threatening the "undermining of native religions and customs" was replaced by a passage guaranteeing religious freedom.

In the 1874 general election, Disraeli was returned to power. He passed the Public Worship Regulation Act 1874, which removed Catholic rituals from the Anglican liturgy and which Victoria strongly supported. She preferred short, simple services, and personally considered herself more aligned with the presbyterian Church of Scotland than the episcopal Church of England. Disraeli also pushed the Royal Titles Act 1876 through Parliament, so that Victoria took the title "Empress of India" from 1 May 1876. The new title was proclaimed at the Delhi Durbar of 1 January 1877.

On 14 December 1878, the anniversary of Albert's death, Victoria's second daughter Alice, who had married Louis of Hesse, died of diphtheria in Darmstadt. Victoria noted the coincidence of the dates as "almost incredible and most mysterious". In May 1879, she became a great-grandmother (on the birth of Princess Feodora of Saxe-Meiningen) and passed her "poor old 60th birthday". She felt "aged" by "the loss of my beloved child".

Between April 1877 and February 1878, she threatened five times to abdicate while pressuring Disraeli to act against Russia during the Russo-Turkish War, but her threats had no impact on the events or their conclusion with the Congress of Berlin. Disraeli's expansionist foreign policy, which Victoria endorsed, led to conflicts such as the Anglo-Zulu War and the Second Anglo-Afghan War. "If "we" are to "maintain" our position as a "first-rate" Power", she wrote, "we must ... be "Prepared" for "attacks" and "wars", "somewhere" or "other", CONTINUALLY." Victoria saw the expansion of the British Empire as civilising and benign, protecting native peoples from more aggressive powers or cruel rulers: "It is not in our custom to annexe countries", she said, "unless we are obliged & forced to do so." To Victoria's dismay, Disraeli lost the 1880 general election, and Gladstone returned as prime minister. When Disraeli died the following year, she was blinded by "fast falling tears", and erected a memorial tablet "placed by his grateful Sovereign and Friend, Victoria R.I."

On 2 March 1882, Roderick Maclean, a disgruntled poet apparently offended by Victoria's refusal to accept one of his poems, shot at the Queen as her carriage left Windsor railway station. Two schoolboys from Eton College struck him with their umbrellas, until he was hustled away by a policeman. Victoria was outraged when he was found not guilty by reason of insanity, but was so pleased by the many expressions of loyalty after the attack that she said it was "worth being shot at—to see how much one is loved".

On 17 March 1883, she fell down some stairs at Windsor, which left her lame until July; she never fully recovered and was plagued with rheumatism thereafter. Brown died 10 days after her accident, and to the consternation of her private secretary, Sir Henry Ponsonby, Victoria began work on a eulogistic biography of Brown. Ponsonby and Randall Davidson, Dean of Windsor, who had both seen early drafts, advised Victoria against publication, on the grounds that it would stoke the rumours of a love affair. The manuscript was destroyed. In early 1884, Victoria did publish "More Leaves from a Journal of a Life in the Highlands", a sequel to her earlier book, which she dedicated to her "devoted personal attendant and faithful friend John Brown". On the day after the first anniversary of Brown's death, Victoria was informed by telegram that her youngest son, Leopold, had died in Cannes. He was "the dearest of my dear sons", she lamented. The following month, Victoria's youngest child, Beatrice, met and fell in love with Prince Henry of Battenberg at the wedding of Victoria's granddaughter Princess Victoria of Hesse and by Rhine to Henry's brother Prince Louis of Battenberg. Beatrice and Henry planned to marry, but Victoria opposed the match at first, wishing to keep Beatrice at home to act as her companion. After a year, she was won around to the marriage by Henry and Beatrice's promise to remain living with and attending her.
Victoria was pleased when Gladstone resigned in 1885 after his budget was defeated. She thought his government was "the worst I have ever had", and blamed him for the death of General Gordon at Khartoum. Gladstone was replaced by Lord Salisbury. Salisbury's government only lasted a few months, however, and Victoria was forced to recall Gladstone, whom she referred to as a "half crazy & really in many ways ridiculous old man". Gladstone attempted to pass a bill granting Ireland home rule, but to Victoria's glee it was defeated. In the ensuing election, Gladstone's party lost to Salisbury's and the government switched hands again.

In 1887, the British Empire celebrated Victoria's Golden Jubilee. Victoria marked the fiftieth anniversary of her accession on 20 June with a banquet to which 50 kings and princes were invited. The following day, she participated in a procession and attended a thanksgiving service in Westminster Abbey. By this time, Victoria was once again extremely popular. Two days later on 23 June, she engaged two Indian Muslims as waiters, one of whom was Abdul Karim. He was soon promoted to "Munshi": teaching her Urdu (known as Hindustani) and acting as a clerk. Her family and retainers were appalled, and accused Abdul Karim of spying for the Muslim Patriotic League, and biasing the Queen against the Hindus. Equerry Frederick Ponsonby (the son of Sir Henry) discovered that the Munshi had lied about his parentage, and reported to Lord Elgin, Viceroy of India, "the Munshi occupies very much the same position as John Brown used to do." Victoria dismissed their complaints as racial prejudice. Abdul Karim remained in her service until he returned to India with a pension, on her death.

Victoria's eldest daughter became Empress consort of Germany in 1888, but she was widowed within the year, and Victoria's grandchild Wilhelm became German Emperor as Wilhelm II. Under Wilhelm, Victoria and Albert's hopes of a liberal Germany were not fulfilled. He believed in autocracy. Victoria thought he had "little heart or "Zartgefühl" [tact] – and ... his conscience & intelligence have been completely wharped ".

Gladstone returned to power after the 1892 general election; he was 82 years old. Victoria objected when Gladstone proposed appointing the Radical MP Henry Labouchère to the Cabinet, so Gladstone agreed not to appoint him. In 1894, Gladstone retired and, without consulting the outgoing prime minister, Victoria appointed Lord Rosebery as prime minister. His government was weak, and the following year Lord Salisbury replaced him. Salisbury remained prime minister for the remainder of Victoria's reign.

On 23 September 1896, Victoria surpassed her grandfather George III as the longest-reigning monarch in British history. The Queen requested that any special celebrations be delayed until 1897, to coincide with her Diamond Jubilee, which was made a festival of the British Empire at the suggestion of the Colonial Secretary, Joseph Chamberlain. The prime ministers of all the self-governing Dominions were invited to London for the festivities. One reason for including the prime ministers of the Dominions and excluding foreign heads of state was to avoid having to invite Victoria's grandson, Wilhelm II of Germany, who, it was feared, might cause trouble at the event.

The Queen's Diamond Jubilee procession on 22 June 1897 followed a route six miles long through London and included troops from all over the empire. The procession paused for an open-air service of thanksgiving held outside St Paul's Cathedral, throughout which Victoria sat in her open carriage, to avoid her having to climb the steps to enter the building. The celebration was marked by vast crowds of spectators and great outpourings of affection for the 78-year-old Queen.

Victoria visited mainland Europe regularly for holidays. In 1889, during a stay in Biarritz, she became the first reigning monarch from Britain to set foot in Spain when she crossed the border for a brief visit. By April 1900, the Boer War was so unpopular in mainland Europe that her annual trip to France seemed inadvisable. Instead, the Queen went to Ireland for the first time since 1861, in part to acknowledge the contribution of Irish regiments to the South African war.

In July 1900, Victoria’s second son Alfred ("Affie") died. "Oh, God! My poor darling Affie gone too", she wrote in her journal. "It is a horrible year, nothing but sadness & horrors of one kind & another."

Following a custom she maintained throughout her widowhood, Victoria spent the Christmas of 1900 at Osborne House on the Isle of Wight. Rheumatism in her legs had rendered her lame, and her eyesight was clouded by cataracts. Through early January, she felt "weak and unwell", and by mid-January she was "drowsy ... dazed, [and] confused". She died on Tuesday 22 January 1901, at half past six in the evening, at the age of 81. Her son and successor, King Edward VII, and her eldest grandson, Emperor Wilhelm II, were at her deathbed. Her favourite pet Pomeranian, Turi, was laid upon her deathbed as a last request.

In 1897, Victoria had written instructions for her funeral, which was to be military as befitting a soldier's daughter and the head of the army, and white instead of black. On 25 January, Edward, Wilhelm and Prince Arthur, Duke of Connaught, helped lift her body into the coffin. She was dressed in a white dress and her wedding veil. An array of mementos commemorating her extended family, friends and servants were laid in the coffin with her, at her request, by her doctor and dressers. One of Albert's dressing gowns was placed by her side, with a plaster cast of his hand, while a lock of John Brown's hair, along with a picture of him, was placed in her left hand concealed from the view of the family by a carefully positioned bunch of flowers. Items of jewellery placed on Victoria included the wedding ring of John Brown's mother, given to her by Brown in 1883. Her funeral was held on Saturday 2 February, in St George's Chapel, Windsor Castle, and after two days of lying-in-state, she was interred beside Prince Albert in Frogmore Mausoleum at Windsor Great Park.

With a reign of 63 years, seven months and two days, Victoria was the longest-reigning British monarch and the longest-reigning queen regnant in world history until her great-great-granddaughter Elizabeth II surpassed her on 9 September 2015. She was the last monarch of Britain from the House of Hanover. Her son and successor Edward VII belonged to her husband's House of Saxe-Coburg and Gotha.

According to one of her biographers, Giles St Aubyn, Victoria wrote an average of 2,500 words a day during her adult life. From July 1832 until just before her death, she kept a detailed journal, which eventually encompassed 122 volumes. After Victoria's death, her youngest daughter, Princess Beatrice, was appointed her literary executor. Beatrice transcribed and edited the diaries covering Victoria's accession onwards, and burned the originals in the process. Despite this destruction, much of the diaries still exist. In addition to Beatrice's edited copy, Lord Esher transcribed the volumes from 1832 to 1861 before Beatrice destroyed them. Part of Victoria's extensive correspondence has been published in volumes edited by A. C. Benson, Hector Bolitho, George Earle Buckle, Lord Esher, Roger Fulford, and Richard Hough among others.

Victoria was physically unprepossessing—she was stout, dowdy and only about five feet tall—but she succeeded in projecting a grand image. She experienced unpopularity during the first years of her widowhood, but was well liked during the 1880s and 1890s, when she embodied the empire as a benevolent matriarchal figure. Only after the release of her diary and letters did the extent of her political influence become known to the wider public. Biographies of Victoria written before much of the primary material became available, such as Lytton Strachey's "Queen Victoria" of 1921, are now considered out of date. The biographies written by Elizabeth Longford and Cecil Woodham-Smith, in 1964 and 1972 respectively, are still widely admired. They, and others, conclude that as a person Victoria was emotional, obstinate, honest, and straight-talking. Contrary to popular belief, her staff and family recorded that Victoria "was immensely amused and roared with laughter" on many occasions.

Through Victoria's reign, the gradual establishment of a modern constitutional monarchy in Britain continued. Reforms of the voting system increased the power of the House of Commons at the expense of the House of Lords and the monarch. In 1867, Walter Bagehot wrote that the monarch only retained "the right to be consulted, the right to encourage, and the right to warn". As Victoria's monarchy became more symbolic than political, it placed a strong emphasis on morality and family values, in contrast to the sexual, financial and personal scandals that had been associated with previous members of the House of Hanover and which had discredited the monarchy. The concept of the "family monarchy", with which the burgeoning middle classes could identify, was solidified.
Victoria's links with Europe's royal families earned her the nickname "the grandmother of Europe". Victoria and Albert had 42 grandchildren, of whom 34 survived to adulthood. Their living descendants include Elizabeth II; Prince Philip, Duke of Edinburgh; Harald V of Norway; Carl XVI Gustaf of Sweden; Margrethe II of Denmark; and Felipe VI of Spain.

Victoria's youngest son, Leopold, was affected by the blood-clotting disease haemophilia B and at least two of her five daughters, Alice and Beatrice, were carriers. Royal haemophiliacs descended from Victoria included her great-grandsons, Alexei Nikolaevich, Tsarevich of Russia, Alfonso, Prince of Asturias, and Infante Gonzalo of Spain. The presence of the disease in Victoria's descendants, but not in her ancestors, led to modern speculation that her true father was not the Duke of Kent, but a haemophiliac. There is no documentary evidence of a haemophiliac in connection with Victoria's mother, and as male carriers always suffer the disease, even if such a man had existed he would have been seriously ill. It is more likely that the mutation arose spontaneously because Victoria's father was over 50 at the time of her conception and haemophilia arises more frequently in the children of older fathers. Spontaneous mutations account for about a third of cases.

Around the world, places and memorials are dedicated to her, especially in the Commonwealth nations. Places named after her include Africa's largest lake, Victoria Falls, the capitals of British Columbia (Victoria) and Saskatchewan (Regina), and two Australian states (Victoria and Queensland).

The Victoria Cross was introduced in 1856 to reward acts of valour during the Crimean War, and it remains the highest British, Canadian, Australian, and New Zealand award for bravery. Victoria Day is a Canadian statutory holiday and a local public holiday in parts of Scotland celebrated on the last Monday before or on 24 May (Queen Victoria's birthday).


At the end of her reign, the Queen's full style and title were: "Her Majesty Victoria, by the Grace of God, of the United Kingdom of Great Britain and Ireland Queen, Defender of the Faith, Empress of India."


As Sovereign, Victoria used the royal coat of arms of the United Kingdom. Before her accession, she received no grant of arms. As she could not succeed to the throne of Hanover, her arms did not carry the Hanoverian symbols that were used by her immediate predecessors. Her arms have been borne by all of her successors on the throne.

Outside Scotland, the blazon for the shield—also used on the Royal Standard—is: Quarterly: I and IV, Gules, three lions passant guardant in pale Or (for England); II, Or, a lion rampant within a double tressure flory-counter-flory Gules (for Scotland); III, Azure, a harp Or stringed Argent (for Ireland). In Scotland, the first and fourth quarters are occupied by the Scottish lion, and the second by the English lions. The crests, mottoes, and supporters also differ in and outside Scotland.



</doc>
<doc id="47974" url="https://en.wikipedia.org/wiki?curid=47974" title="Dr. No (novel)">
Dr. No (novel)

Dr. No is the sixth novel by the English author Ian Fleming to feature his British Secret Service agent James Bond. Fleming wrote the novel in early 1957 at his Goldeneye estate in Jamaica. It was first published in the United Kingdom by Jonathan Cape on 31 March 1958. The novel centres on Bond's investigation into the disappearance in Jamaica of two fellow MI6 operatives. He establishes that they had been investigating Doctor No, a Chinese operator of a guano mine on the fictional Caribbean island of Crab Key. Bond travels to the island and meets Honeychile Rider and later Doctor No.

The novel began as a 1956 screenplay for the producer Henry Morgenthau III for a proposed television show entitled "Commander Jamaica". When those plans foundered, Fleming adapted the ideas as the basis for a novel, provisionally titled "The Wound Man". The book's eponymous villain was influenced by Sax Rohmer's Fu Manchu stories.

"Dr. No" was the first of Fleming's novels to face widespread negative criticism in Britain; Paul Johnson of the "New Statesman" dismissed the book as one of "Sex, Snobbery and Sadism". When released on the American market it was received more favourably. "Dr. No" was serialised in the "Daily Express", first in an abridged story form and later as a comic strip. The story was adapted in 1962 as the first film in the Bond series, with Sean Connery in the lead role; in 2008 BBC Radio 4 broadcast a version, with Toby Stephens as Bond.

After recovering from serious poisoning inflicted by the SMERSH agent Rosa Klebb (in "From Russia, with Love") the MI6 agent James Bond is sent by his superior, M, on an undemanding mission to the British Colony of Jamaica. He is instructed to investigate the disappearance of Commander John Strangways, the head of MI6's Station J in Kingston, and his secretary. Bond is briefed that Strangways had been investigating the activities of Doctor Julius No, a reclusive Chinese-German who lives on the fictional island of Crab Key and runs a guano mine. The island has a colony of roseate spoonbills at one end while local rumour is that a vicious dragon also lives there. The spoonbills are protected by the American National Audubon Society, two of whose representatives died when their plane crashed on No's airstrip.

On his arrival in Jamaica, Bond soon realises that he is being watched. His hotel room is searched, a basket of poisoned fruit is delivered to the room —supposedly a gift from the colonial governor—and a deadly centipede is placed in his bed while he is sleeping. With the help of an old friend, Quarrel, Bond surreptitiously visits Crab Key to establish whether there is a connection between No and the disappearance of the MI6 personnel. Bond and Quarrel meet Honeychile Rider, who is there to collect valuable shells. Bond and Rider are captured by No's men after Quarrel is burned to death by the doctor's "dragon"—a flamethrowing, armoured swamp buggy designed to keep away trespassers. Bond and Rider are taken to a luxurious facility carved into the mountain.

No tells Bond that he is working with the Russians and has built an elaborate underground facility from which he can sabotage US test missiles launched from Cape Canaveral. He had previously been a member of a Chinese tong, but after he stole a large amount of money from their treasury, he was captured by the organisation. The tong's leaders had No's hands cut off as a warning to others, and then shot. Because No's heart was on the right side of his body, the bullet missed it and he survived.

Interested in the ability of the human body to withstand and survive pain, No forces Bond to navigate his way through an obstacle course constructed in the facility's ventilation system. Bond is kept under observation as he suffers electric shocks, burns and an encounter with large poisonous spiders. Bond's ordeal ends in a fight with a captive giant squid, which he defeats by using improvised weapons. After his escape he encounters Rider, who has been pegged out to be eaten by crabs; they had ignored her and she managed to escape.

Bond kills No by taking over the guano-loading machine at the docks and diverting the flow of guano to bury him alive. Bond and Rider then escape from No's complex in the "dragon" buggy, sail back to Jamaica and notify the colonial authorities.

In June 1956 the author Ian Fleming began a collaboration with the producer Henry Morgenthau III on a planned television series, "Commander Jamaica", which was to feature the Caribbean-based character James Gunn. When the project foundered, and Fleming could not fashion a new plot for his next Bond novel, he used the idea as the basis for "Dr. No". By January 1957 he had published four Bond novels in successive years from 1953—"Casino Royale", "Live and Let Die", "Moonraker" and "Diamonds Are Forever". A fifth, "From Russia, with Love", was being edited and prepared for production. That month Fleming travelled to his Goldeneye estate in Jamaica to write "Dr. No". He followed his usual practice, which he later outlined in "Books and Bookmen" magazine: "I write for about three hours in the morning ... and I do another hour's work between six and seven in the evening. I never correct anything and I never go back to see what I have written ... By following my formula, you write 2,000 words a day." By the time he returned to London in late February, he had completed a 206-page first draft, which he initially titled "The Wound Man".

Although Fleming did not date the event within his novels, John Griswold and Henry Chancellor—both of whom wrote books for Ian Fleming Publications—have identified different timelines based on events and situations within the novel series as a whole. Chancellor put the events of "Dr. No" in 1956; Griswold is more precise, and considers the story to have taken place in February and March of that year.

As with his previous four novels, Fleming came up with the concept of the front cover design; he considered Honeychile Rider to have a Venus-like quality when introduced in the book and wanted this echoed on the cover. When Fleming commissioned Pat Marriott to illustrate the cover, he instructed that she be shown on a "Venus elegans" shell.

Prior to the release of "Dr. No"—and unconnected with the book itself—Bernard Bergonzi, in the March 1958 issue of "Twentieth Century", attacked Fleming's work, saying that it contained "a strongly marked streak of voyeurism and sado-masochism" and that the books showed "the total lack of any ethical frame of reference". The article also compared Fleming unfavourably to John Buchan and Raymond Chandler in both moral and literary measures. The writer Simon Raven, while appreciating Bergonzi had produced a "quiet and well-argued article", thought that the critic's conclusion was naïve, and asked "Since when has it been remarkable in a work of entertainment that it should lack a specific 'ethical frame of reference'?" Raven continued, saying Fleming "by reason of his cool and analytical intelligence, his informed use of technical facts, his plausibility, sense of pace, brilliant descriptive powers and superb imagination, provides sheer entertainment such as I, who must read many novels, am seldom lucky enough to find".

In March 1956 Fleming and his friend Ivar Bryce accompanied Robert Cushman Murphy (of the American Museum of Natural History) and Arthur Stannard Vernay (of the Flamingo Protection Society) on a trip to a flamingo colony on Great Inagua in the south of the Bahamas. The colony was of dense mangrove swamp and salt flats, home to flamingos, egrets and roseate spoonbills; the location inspired Crab Key. Much of the travel overland on Great Inagua was by a swamp vehicle, a Land Rover fitted with over-large tyres that became the model for the "dragon" used in the story.

Fleming's inspiration for the Doctor No character was Sax Rohmer's villain Dr Fu Manchu, who featured in books Fleming had read and enjoyed in earlier years. Aspects of the plot were influenced by Rohmer's work, and Winder observes that the use of the centipede was "a straight steal" from a Fu Manchu novel; other devices from Rohmer's novels included Doctor No's secret lair and the use of the mad scientist trope.

As he had done in his previous novels, Fleming borrowed names from his friends and associates to use in his book; Ivar Bryce's housekeeper, May Maxwell, became Bond's Scottish "treasure" May. One of Fleming's neighbours in Jamaica, and later his lover, was Blanche Blackwell: Fleming named the guano-collecting ship in "Dr. No" as "Blanche". His friend Patricia Wilder found that her nickname of Honey Chile was used for the novel's main female character, and John Fox-Strangways—a friend from the gentlemen's club White's—saw part of his surname being used for the name of the MI6 station chief in Jamaica. Fleming also used the physical descriptions of people he knew; Quarrel, who previously appeared in the novel "Live and Let Die", was based on a Jamaican fisherman who often took Fleming shark fishing.

In "Dr. No", for the first time in the Bond novels, there is friction between Bond and M, brought about because Bond was nearly killed by the SMERSH agent Rosa Klebb in "From Russia, with Love". M orders Bond to use a new gun and sends him on a holiday assignment, which Bond resents. The writer Raymond Benson—who later wrote a series of Bond novels—sees M at his most authoritarian in "Dr. No", punishing Bond both in terms of stripping him of his gun and then sending him on what both Bond and M considered at first to be a "soft" assignment.

Honeychile Rider is one of three women in the Bond canon who have been scarred by rape. This follows a pattern where the women Bond comes across are somehow different to the norm, although Black points out that this gives Bond an opportunity to help and save both Rider and the others. Other female characters in the Bond series have flaws, and Rider has a broken nose—the result of the rape she suffered. The cultural historians Janet Woollacott and Tony Bennett, in their analysis of the roles of women in the Bond novels, consider that Rider is "not archetypically feminine", but is "constructed according to the formula 'equal but yet subordinate'." Rider is described in the book as having buttocks like a boy, which brought a response from Fleming's friend Noël Coward that "I was also slightly shocked by the lascivious announcement that Honeychile's bottom was like a boy's. I know that we are all becoming more broadminded nowadays, but really old chap what "could" you have been thinking of?"
Fleming's villain was physically disfigured, similar to many of Bond's later adversaries; No is tall, with steel pincers for hands and has dextrocardia. Bond describes him as "a giant venomous worm wrapped in grey tin-foil". Benson considers that No is "a wickedly successful villain", the best since Hugo Drax in "Moonraker", while "Time" thought No to be "one of the less forgettable characters in modern fiction".

Quarrel was Fleming's idealised concept of a black person, and the character was based on his genuine liking for Jamaicans, whom he saw as "full of goodwill and cheerfulness and humour". The relationship between Bond and Quarrel was based on a presumption of Bond's superiority. Fleming described the relationship as "that of a Scots laird with his head stalker; authority was unspoken and there was no room for servility". Winder considers the scenes with Quarrel to be "embarrassingly patronising but nonetheless hypnotic".

In "From Russia, with Love" Fleming experimented with an unusual narrative structure that saw Bond's entry into the story delayed until chapter eleven. For "Dr. No" he returned to the conventional form with which he felt comfortable—that of the thriller writers of the early 20th century. As a result, the story's villain is closer to the intellectual "gentleman crook" of the golden age of detective fiction, and the novel's focus is on action at the expense of character development and depth of plot.

Benson describes the "Fleming Sweep" as taking the reader from one chapter to another using "hooks" at the end of chapters to heighten tension and pull the reader onto the next. He feels that the "Fleming Sweep briskly propels the plot" of "Dr. No" through chapters that are longer than in previous Bond novels; the cultural historian Jeremy Black also likes "Dr. No"s pacing, despite considering it inconsistent in places. Winder believes that the novel's plotting is chaotic, although he still feels the book "can be read over and over again with immense pleasure".
Fleming used known brand names and everyday details to produce a sense of realism, which the writer Kingsley Amis calls "the Fleming effect". Amis describes "the imaginative use of information, whereby the pervading fantastic nature of Bond's world ... [is] bolted down to some sort of reality, or at least counter-balanced." The journalist and writer Matthew Parker sees the novel as "the most fantastical, gothic and melodramatic; and at times frankly, even knowingly, over the top", while Black considers the fantastic element of Doctor No's underground lair to be a "weak" and "bizarre" part of the story. When the writer Raymond Chandler reviewed the novel, he thought "that the long sensational business which is the heart of the book not only borders on fantasy. It plunges in with both feet. Ian Fleming's impetuous imagination has no rules." Writing in 1963, Fleming acknowledged his plots were "fantastical while often being based in truth. They go wildly beyond the probable but not, I think, beyond the possible".

Two main themes run through "Dr. No": the meaning of power; and the concept of friendship and loyalty. Bond talks about the meaning of power with several villains in the series. His conversation with Doctor No reveals that the latter believes it can only be secured through the privacy required to maintain the sovereignty of his island. No quotes Carl von Clausewitz's first principle—about having a secure base from which to operate—in support of his argument. According to Panek, in his examination of 20th century British spy novels, "Dr. No" "shows a shift towards emphasizing the intellect and organizing power of the individual", as opposed to a group or nation. Black considers that although it is American assets that are under threat from the Soviet Union, it is British power, through the British agent, that concludes the issue. This is reinforced at the end of the book, when a modern British warship bearing British soldiers is despatched to the island. In Black and Parker's views, the display of British power, with no assistance from America, portrayed the British Empire as an enduring force.

The concept of friendship and loyalty is the second major theme. The relationship between Bond and Quarrel, the Cayman Islander, is mutually felt. According to Lindner, Quarrel is "an indispensable ally" who had assisted Bond in "Live and Let Die". Benson sees no racial discrimination in the relationship between the two men and acknowledges that Bond feels genuine remorse and sadness at Quarrel's death.

"Dr. No" was released on 31 March 1958 in the UK as a hardcover edition by the publishers Jonathan Cape. A paperback edition was issued by Pan Books in February 1960; over 115,000 copies were sold that year. The first American edition was published in June 1958 by Macmillan under the name "Doctor No". The largest boost in sales of the novel came in 1962 with the release of the film adaptation. In the seven months after the picture's release, 1.5 million copies of the book were sold. In 1964 the novel was serialised in "France-Soir" for the French market, which led to increased sales of Bond works in that country; 480,000 French-language copies of the six Bond novels were sold that year. Since its initial publication the book has been issued in numerous hardback and paperback editions, translated into several languages and has never been out of print.

For the first time in the Bond series, Fleming encountered harsh criticism. The most virulent came from Paul Johnson of the "New Statesman", who opened his review, "Sex, Snobbery and Sadism", with: "I have just finished what is, without doubt, the nastiest book I have ever read". He went on to say that "by the time I was a third of the way through, I had to suppress a strong impulse to throw the thing away". Although he recognised that Bond represented "a social phenomenon of some importance", he saw this as a negative element, as the phenomenon concerned "three basic ingredients in "Dr. No", all unhealthy, all thoroughly English: the sadism of a schoolboy bully, the mechanical, two-dimensional sex-longings of a frustrated adolescent, and the crude, snob-cravings of a suburban adult". Johnson saw no positives in "Dr. No", saying that "Mr Fleming has no literary skill, the construction of the book is chaotic, and entire incidents and situations are inserted, and then forgotten, in a haphazard manner."

Maurice Richardson, of "The Observer", considered the novel "the usual sado-masochistic free-for-all, plus octopuses". The unnamed critic in "The Manchester Guardian" referred to Johnson's "sex, snobbery and sadism" complaint. They highlighted the "sinister ... cult of luxury for its own sake", with Bond's enjoyment of branded and bespoke products, but disagreed with part of Johnson's summary that the novel was a sign of moral decay; rather, "we should be grateful to Mr. Fleming for providing a conveniently accessible safety-valve for the boiling sensibility of modern man." This reviewer also conceded that while "the casualties take place on a somewhat narrower front than usual, they are heavy". In April 1958, Fleming wrote to "The Manchester Guardian" in defence of his work, referring to both that paper's review of "Dr. No" and the article in "The Twentieth Century". Fleming partly accepted the criticism concerning the exclusivity of Bond's objects, such as cigarettes and food, but defended it on the basis that "I had to fit Bond out with some theatrical props". These included his cocktail, ("The Vesper") and Bond's diet. Fleming called these devices "vulgar foibles" which he was saddled with, although maybe, he suggested, "Bond's luxury meals are simply saying 'no' to toad-in-the-hole and tele-bickies."

Writing in "The Times Literary Supplement", Philip Stead was more generous to "Dr. No". Despite thinking that Fleming was offering "too opulent a feast" with the book, Stead argued that Fleming managed to pull this off, where "a less accomplished writer ... would never have got away with this story." Raymond Chandler reviewed the novel for "The Sunday Times" and praised as "masterly" Fleming's depiction of colonial Kingston in the first chapter. Chandler admired Fleming's writing, which had "an acute sense of pace. ... You don't have to work at Ian Fleming. He does the work for you."

The reviewer for "Time" acknowledged the critical storm around Fleming and "Dr. No", but was broadly welcoming of the book, writing that while "not all readers will agree that "Dr. No" ... is magnificent writing, ... pages of it, at least, qualify for Ezra Pound's classic comment on "Tropic of Cancer": 'At last, an unprintable book that is readable'." In "The New York Times", Anthony Boucher—described by Fleming's biographer John Pearson as "throughout an avid anti-Bond and an anti-Fleming man"—was again damning of Fleming's work, saying "it's harder than ever to see why an ardent coterie so admires Ian Fleming's tales". Benson described Boucher's critique as "true to form" and "a tirade" as Boucher concluded his review by saying: "it is 80,000 words long, with enough plot for 8,000 and enough originality for 800."

Glendy Culligan of "The Washington Post" described the novel as a "thin little whodunit which rocked the British Empire and shook the English Establishment", adding "Bully for it!" Culligan admitted that "Confidentially though, we enjoyed "Dr. No", and if this be sick, sick, sick, gentlemen, make the most of it." James Sandoe in his book review for "The New York Herald Tribune" was very positive about "Dr. No" and thought that it was "the most artfully bold, dizzyingly poised thriller of the decade. You'd much better read it than read about it."

The writer Simon Winder believes that because Fleming was writing about Jamaica, the result was "perhaps the most attractive of all the Bond books—the most relaxed, the most fiendish, the most confident". According to the literary analyst LeRoy L. Panek, in his examination of 20th century British spy novels, Fleming knew his outdated view of Jamaica would soon be overtaken by events—as evidenced by the novel's description of how the Queen's Club would be lost during independence struggles. According to the cultural historian Michael Denning, this acknowledgement of the end-of-empire leads to a "sense of doom" that is the result of "a shadow of real history hanging over the stories".

"Dr. No" was serialised in "The Daily Express" from 19 March to 1 April 1958. In 1960 the novel was adapted as a daily comic strip in the paper and was syndicated worldwide. The strip, which ran from May to October, was written by Peter O'Donnell and illustrated by John McLusky. It was reprinted in 2005 by Titan Books as part of the "Dr. No" anthology that also includes "Diamonds Are Forever" and "From Russia, with Love". In 1962 the American men's magazine "Stag" serialised the story, renaming it as "Nude Girl of Nightmare Key".

The film "Dr. No" was released in 1962, produced by Albert R. Broccoli and Harry Saltzman, and directed by Terence Young. It was the first Bond film in the Eon Productions series; Sean Connery portrayed Bond, with Joseph Wiseman as Doctor No and Ursula Andress as Honeychile Rider. Although the story follows the same general storyline, there are some changes: the film shows No to be an operative of the fictional crime organisation SPECTRE and his island fortress is nuclear-powered; No is killed not by the mountain of guano, but by drowning in reactor coolant. The novel was dramatised for BBC Radio 4 in May 2008. The actor Toby Stephens played Bond, while No was played by David Suchet.




</doc>
<doc id="48064" url="https://en.wikipedia.org/wiki?curid=48064" title="Sesame Street">
Sesame Street

Sesame Street is an American educational children's television series that combines live action, sketch comedy, animation and puppetry. It is produced by Sesame Workshop (known as the Children's Television Workshop (CTW) until June 2000) and was created by Joan Ganz Cooney and Lloyd Morrisett. The program is known for its images communicated through the use of Jim Henson's Muppets, and includes short films, with humor and cultural references. The series premiered on November 10, 1969, to positive reviews, some controversy, and high viewership; it has aired on the U.S.'s national public television provider PBS since its debut, with its first run moving to premium channel HBO on January 16, 2016.

The format of "Sesame Street" consists of a combination of commercial television production elements and techniques which have evolved to reflect the changes in American culture and the audience's viewing habits. With the creation of "Sesame Street", producers and writers of a children's television show used, for the first time, educational goals and a curriculum to shape its content. It was also the first time a show's educational effects were formally studied. The show, therefore, has undergone significant changes in its history as adjustments to the format and content have been made to reflect change sources to the curriculum.

Shortly after creating "Sesame Street", its producers developed what came to be called the "CTW model" (after the production company's previous name), a system of television show planning, production, and evaluation based on collaborations between producers, writers, educators, and researchers. The show was initially funded by government and private foundations but has become somewhat self-supporting due to revenues from licensing arrangements, international sales, and other media. By 2006, there were independently produced versions, or "co-productions", of "Sesame Street" broadcast in twenty countries. In 2001, there were over 120 million viewers of various international versions of "Sesame Street", and by the show's 40th anniversary in 2009, it was broadcast in more than 140 countries.

"Sesame Street" was by then the fifteenth-highest-rated children's television show in the United States. A 1996 survey found that 95% of all American preschoolers had watched the show by the time they were three years old. In 2018, it was estimated that 86 million Americans had watched the series as children. As of 2018, "Sesame Street" has won 189 Emmy Awards and 11 Grammy Awards, more than any other children's show.

"Sesame Street" was conceived in 1966 during discussions between television producer Joan Ganz Cooney and Carnegie Foundation vice president Lloyd Morrisett. Their goal was to create a children's television show that would "master the addictive qualities of television and do something good with them", such as helping young children prepare for school. After two years of research, the newly formed Children's Television Workshop (CTW) received a combined grant of US$8 million ($ million in dollars) from the Carnegie Foundation, the Ford Foundation, the Corporation for Public Broadcasting and the U.S. Federal Government to create and produce a new children's television show. The program premiered on public television stations on November 10, 1969. It was the first preschool educational television program to base its contents and production values on laboratory and formative research. Initial responses to the show included adulatory reviews, some controversy, and high ratings. By its 50th anniversary in 2019, there were over 150 versions of "Sesame Street", produced in 70 languages. As of 2006, 20 international versions had been produced.

According to writer Michael Davis, by the mid-1970s "Sesame Street"the show had become "an American institution". The cast and crew expanded during this time, with emphasis on the hiring of women crew members and the addition of minorities to the cast. The show's success continued into the 1980s. In 1981, when the federal government withdrew its funding, CTW turned to, and expanded, other revenue sources, including its magazine division, book royalties, product licensing, and foreign broadcast income. "Sesame Street"s curriculum has expanded to include more affective topics such as relationships, ethics, and emotions. Many of the show's storylines were taken from the experiences of its writing staff, cast, and crew, most notably, the 1982 death of Will Lee—who played Mr. Hooper—and the marriage of Luis and Maria in 1988.

By the end of the 1990s, "Sesame Street" faced societal and economic challenges, including changes in viewing habits of young children, competition from other shows, the development of cable television, and a drop in ratings. After the turn of the 21st century, "Sesame Street" made major structural changes. For example, starting in 2002, its format became more narrative and included ongoing storylines. After its thirtieth anniversary in 1999, due to the popularity of the Muppet Elmo the show also incorporated a popular segment known as "Elmo's World". Upon its fortieth anniversary in 2009, the show received a Lifetime Achievement Emmy at the 36th Daytime Emmy Awards.

On August 13, 2015, as part of a five-year programming and development deal, Sesame Workshop announced that first-run episodes of "Sesame Street" would move to premium television service HBO beginning with season 46, which premiered on January 16, 2016. HBO holds first-run rights to all newer episodes of the series, after which they will air on PBS member stations following a nine-month exclusivity window, with no charge to the stations. The agreement also gives HBO exclusive rights to stream past and future "Sesame Street" episodes on HBO Go and HBO Now, assuming those rights from Amazon Video and Netflix. On August 14 Sesame Workshop announced that it would phase out its in-house subscription streaming service, Sesame Go, as a standalone service, remaining in operation, likely with its offerings reduced to a slate content available free of charge or serving as a portal for "Sesame Street"s website. The deal came in the wake of cutbacks that had affected the series in recent years, the changing viewer habits of American children in the previous ten years, and Sesame Workshop's dependence upon revenue from DVD sales.

In April 2017, " Sesame Street" introduced Julia, a new Muppet who has autism, performed by Stacey Gordon, who has a son on the autism spectrum.

From its first episode, "Sesame Street" has structured its format by using "a strong visual style, fast-moving action, humor, and music," as well as animation and live-action short films. When "Sesame Street" premiered, most researchers believed that young children did not have long attention spans, therefore the new show's producers were concerned that an hour-long show would not hold their audience's attention. At first, the show's "street scenes"—the action taking place on its set—consisted of character-driven interactions and were not written as ongoing stories. Instead, they consisted of individual, curriculum-based segments which were interrupted by "inserts" consisting of puppet sketches, short films, and animations. This structure allowed the producers to use a mixture of styles and characters, and to vary the show's pace. By season 20, research had shown that children were able to follow a story, and the street scenes, while still interspersed with other segments, became evolving storylines.

Upon recommendations by child psychologists, the producers initially decided that the show's human actors and Muppets would not interact because they were concerned it would confuse young children. When the CTW tested the appeal of the new show, they found that although children paid attention to the shows during the Muppet segments, their interest was lost during the "Street" segments. The producers requested that Henson and his team create Muppets such as Big Bird and Oscar the Grouch to interact with the human actors, and the Street segments were re-shot. "Sesame Street"s format remained intact until the 2000s, when the changing audience required that producers move to a more narrative format. In 1998, the popular "Elmo's World", a 15-minute-long segment hosted by the Muppet Elmo, was created. Starting in 2014, during the show's 45th season, the producers introduced a half-hour version of the program. The new version, which originally complemented the full-hour series, and was both broadcast weekday afternoons and streamed on the Internet. The half-hour version of the show became the standard with the 46th season.

Author Malcolm Gladwell said that ""Sesame Street" was built around a single, breakthrough insight: that if you can hold the attention of children, you can educate them". Gerald S. Lesser, the CTW's first advisory board chair, went even further, saying that the effective use of television as an educational tool needed to capture, focus, and sustain children's attention. "Sesame Street" was the first children's show to structure each episode, and the segments within them, to capture children's attention, and to make, as Gladwell put it, "small but critical adjustments" to keep it. According to CTW researchers Rosemarie Truglio and Shalom Fisch, "Sesame Street" was one of the few children's television programs to utilize a detailed and comprehensive educational curriculum, garnered from formative and summative research.

The creators of "Sesame Street" and their researchers formulated both cognitive and affective goals for the show. Initially, they focused on cognitive goals, while addressing affective goals indirectly, in the belief that doing so would increase children's self-esteem and feelings of competency. One of their primary goals was preparing very young children for school, especially children from low-income families, using modeling, repetition, and humor to fulfill these goals. They made changes in the show's content to increase their viewers' attention and to increase its appeal, and encouraged "co-viewing" to entice older children and parents to watch the show by including more sophisticated humor, cultural references, and celebrity guest appearances.

After "Sesame Street"s first season, its critics forced its producers and researchers to address more overtly such affective goals as social competence, tolerance of diversity, and nonaggressive ways of resolving conflict. These issues were addressed through interpersonal disputes among its Street characters. During the 1980s, the show incorporated the real-life experiences of the show's cast and crew, including the death of Will Lee (Mr. Hooper) and the pregnancy of Sonia Manzano (Maria) to address affective concerns. In later seasons, "Sesame Street" addressed real-life disasters such as the September 11 terrorist attacks and Hurricane Katrina.

The show's goals for outreach were addressed through a series of programs that first focused on promotion and then, after the first season, on the development of educational materials used in preschool settings. Innovative programs were developed because their target audience, children and their families in low-income, inner-city homes, did not traditionally watch educational programs on television and because traditional methods of promotion and advertising were not effective with these groups.

As a result of Cooney's initial proposal in 1968, the Carnegie Institute awarded her an $1 million grant to create a new children's television program and establish the CTW, renamed in June 2000 to Sesame Workshop (SW). Cooney and Morrisett procured additional multimillion-dollar grants from the U.S. federal government, The Arthur Vining Davis Foundations, CPB, and the Ford Foundation. Davis reported that Cooney and Morrisett decided that if they did not procure full funding from the beginning, they would drop the idea of producing the show. As Lesser reported, funds gained from a combination of government agencies and private foundations protected them from the economic pressures experienced by commercial broadcast television networks, but created challenges in procuring future funding.

After "Sesame Street"s initial success, its producers began to think about its survival beyond its development and first season and decided to explore other funding sources. From the first season, they understood that the source of their funding, which they considered "seed" money, would need to be replaced. The 1970s were marked by conflicts between the CTW and the federal government; in 1978, the U.S. Department of Education refused to deliver a $2 million check until the last day of CTW's fiscal year. As a result, the CTW decided to depend upon licensing arrangements with toy companies and other manufacturers, publishing, and international sales for their funding.

In 1998, the CTW accepted corporate sponsorship to raise funds for "Sesame Street" and other projects. For the first time, they allowed short advertisements by indoor playground manufacturer Discovery Zone, their first corporate sponsor, to air before and after each episode. Consumer advocate Ralph Nader, who had previously appeared on "Sesame Street", called for a boycott of the show, saying that the CTW was "exploiting impressionable children". While first-run episodes on HBO do not have underwriting due to its status as a pay-TV network, repeats on PBS continue to have corporate underwriting.

Producer Joan Ganz Cooney has stated, "Without research, there would be no "Sesame Street"". In 1967, when Cooney and her team began to plan the show's development, combining research with television production was, as she put it, "positively heretical". Shortly after creating "Sesame Street", its producers began to develop what came to be called "the CTW model", a system of planning, production, and evaluation that did not fully emerge until the end of the show's first season. According to Morrow, the CTW model consisted of four parts: "the interaction of receptive television producers and child science experts, the creation of a specific and age-appropriate curriculum, research to shape the program directly, and independent measurement of viewers' learning".

Cooney credited the show's high standard in research procedures to Harvard professors Gerald S. Lesser, whom the CTW hired to design the show's educational objectives, and Edward L. Palmer, who was responsible for conducting the show's formative research and for bridging the gap between the show's producers and researchers. The CTW conducted research in two ways: in-house formative research that informed and improved production, and independent summative evaluations, conducted by the Educational Testing Service (ETS) during the show's first two seasons, which measuring its educational effectiveness. Cooney stated, "From the beginning, we—the planners of the project—designed the show as an experimental research project with educational advisers, researchers, and television producers collaborating as equal partners". Cooney also described the collaboration as an "arranged marriage".

"Sesame Street" has used many writers in its long history. As Dave Connell, one of "Sesame Street"s original producers, has stated, it was difficult to find adults who could identify a preschooler's interest level. Fifteen writers a year worked on the show's scripts, but very few lasted longer than one season. Norman Stiles, head writer in 1987, reported that most writers would "burn out" after writing about a dozen scripts. According to Gikow, "Sesame Street" went against the convention of hiring teachers to write for the show, as most educational television programs did at the time. Instead, Cooney and the producers felt that it would be easier to teach writers how to interpret curriculum than to teach educators how to write comedy. As Stone stated, "Writing for children is not so easy". Long-time writer Tony Geiss agreed, stating in 2009, "It's not an easy show to write. You have to know the characters and the format and how to teach and be funny at the same time, which is a big, ambidextrous stunt".

The show's research team developed an annotated document, or "Writer's Notebook", which served as a bridge between the show's curriculum goals and script development. The notebook was a compilation of programming ideas designed to teach specific curriculum points, provided extended definitions of curriculum goals, and assisted the writers and producers in translating the goals into televised material. Suggestions in the notebook were free of references to specific characters and contexts on the show so that they could be implemented as openly and flexibly as possible.

The research team, in a series of meetings with the writers, also developed "a curriculum sheet" that described the show's goals and priorities for each season. After receiving the curriculum focus and goals for the season, the writers met to discuss ideas and story arcs for the characters, and an "assignment sheet" was created that suggested how much time was allotted for each goal and topic. When a script was completed, the show's research team analyzed it to ensure that the goals were met. Then each production department met to determine what each episode needed in terms of costumes, lights, and sets. The writers were present during the show's taping, which for the first twenty-four years of the show took place in Manhattan, and after 1992, at the Kaufman Astoria Studios in Queens to make last-minute revisions when necessary.

Early in their history "Sesame Street" and the CTW began to look for alternative funding sources and turned to creating products and writing licensing agreements. They became, as Cooney put it, "a multiple-media institution". In 1970, the CTW created a "non-broadcast" division responsible for creating and publishing books and "Sesame Street Magazine". They decided that all materials their licensing program created would "underscore and amplify" the show's curriculum. In 2004, over 68% of "Sesame Street"s revenue came from licenses and products such as toys and clothing. By 2008, the "Sesame Street" Muppets accounted for between $15 million and $17 million per year in licensing and merchandising fees, split between the Sesame Workshop and The Jim Henson Company.

Jim Henson, the creator of the Muppets, owned the trademarks to those characters, and was reluctant to market them at first. He agreed when the CTW promised that the profits from toys, books, computer games, and other products were to be used exclusively to fund the CTW and its outreach efforts. Even though Cooney and the CTW had very little experience with marketing, they demanded complete control over all products and product decisions. Any product line associated with the show had to be educational and inexpensive, and could not be advertised during the show's airings. As Davis reported, "Cooney stressed restraint, prudence, and caution" in their marketing and licensing efforts.

Director Jon Stone, talking about the music of "Sesame Street", said: "There was no other sound like it on television". For the first time in children's television, the show's songs fulfilled a specific purpose and supported its curriculum. In order to attract the best composers and lyricists, the CTW allowed songwriters like "Sesame Street"s first musical director Joe Raposo to retain the rights to the songs they wrote, which earned them lucrative profits and helped the show sustain public interest. By 1991, "Sesame Street" and its songwriters had received eight Grammys.

"Sesame Street" used animations and short films commissioned from outside studios, interspersed throughout each episode, to help teach their viewers basic concepts like numbers and letters. Jim Henson was one of the many producers to create short films for the show. Shortly after "Sesame Street" debuted in the United States, the CTW was approached independently by producers from several countries to produce versions of the show at home. These versions came to be called "co-productions". By 2001 there were over 120 million viewers of all international versions of "Sesame Street", and in 2006, there were twenty co-productions around the world. By the show's 40th anniversary in 2009, "Sesame Street" was broadcast in more than 140 countries. In 2005, Doreen Carvajal of "The New York Times" reported that income from the co-productions and international licensing accounted for $96 million.

Shortly after the CTW was created in 1968, Joan Ganz Cooney was named its first executive director. She was one of the first female executives in American television. Her appointment was called "one of the most important television developments of the decade". She assembled a team of producers, all of whom had previously worked on "Captain Kangaroo". Jon Stone was responsible for writing, casting, and format; Dave Connell took over animation; and Sam Gibbon served as the show's chief liaison between the production staff and the research team. Cameraman Frankie Biondo worked on "Sesame Street" from its first episode.

Jim Henson and the Muppets' involvement in "Sesame Street" began when he and Cooney met at one of the curriculum planning seminars in Boston. Author Christopher Finch reported that Stone, who had worked with Henson previously, felt that if they could not bring him on board, they should "make do without puppets". Henson was initially reluctant, but he agreed to join "Sesame Street" to meet his own social goals. He also agreed to waive his performance fee for full ownership of the "Sesame Street" Muppets and to split any revenue they generated with the CTW. As Morrow stated, Henson's puppets were a crucial part of the show's popularity and it brought Henson national attention. Davis reported that Henson was able to take "arcane academic goals" and translate them to "effective and pleasurable viewing". In early research, the Muppet segments of the show scored high, and more Muppets were added during the first few seasons. Morrow reported that the Muppets were effective teaching tools because children easily recognized them, they were stereotypical and predictable, and they appealed to adults and older siblings.

Although the producers decided against depending upon a single host for "Sesame Street", instead casting a group of ethnically diverse actors, they realized that a children's television program needed to have, as Lesser put it, "a variety of distinctive and reliable personalities", both human and Muppet. Jon Stone, whose goal was to cast white actors in the minority, was responsible for hiring the show's first cast. He did not audition actors until Spring 1969, a few weeks before the five test shows were due to be filmed. Stone videotaped the auditions, and Ed Palmer took them out into the field to test children's reactions. The actors who received the "most enthusiastic thumbs up" were cast. For example, Loretta Long was chosen to play Susan when the children who saw her audition stood up and sang along with her rendition of "I'm a Little Teapot". As Stone said, casting was the only aspect of the show that was "just completely haphazard". Most of the cast and crew found jobs on "Sesame Street" through personal relationships with Stone and the other producers.

According to the CTW's research, children preferred watching and listening to other children more than to puppets and adults, so they included children in many scenes. Dave Connell insisted that no child actors be used, so these children were non-professionals, unscripted, and spontaneous. Many of their reactions were unpredictable and difficult to control, but the adult cast learned to handle the children's spontaneity flexibly, even when it resulted in departures from the planned script or lesson. CTW research also revealed that the children's hesitations and on-air mistakes served as models for viewers. According to Morrow, this resulted in the show having a "fresh quality", especially in its early years. Children were also used in the voice-over commentaries of most of the live-action films the CTW produced.

When "Sesame Street" premiered in 1969, it aired on only 67.6% of American televisions, but it earned a 3.3 Nielsen rating, which totaled 1.9 million households. By the show's tenth anniversary in 1979, nine million American children under the age of 6 were watching "Sesame Street" daily. According to a 1993 survey conducted by the U.S. Department of Education, out of the show's 6.6 million viewers, 2.4 million kindergartners regularly watched it. 77% of preschoolers watched it once a week, and 86% of kindergartners and first- and second-grade students had watched it once a week before starting school. The show reached most young children in almost all demographic groups.

The show's ratings significantly decreased in the early 1990s, due to changes in children's viewing habits and in the television marketplace. The producers responded by making large-scale structural changes to the show. By 2006, "Sesame Street" had become "the most widely viewed children's television show in the world", with 20 international independent versions and broadcasts in over 120 countries. A 1996 survey found that 95% of all American preschoolers had watched the show by the time they were three years old. In 2008, it was estimated that 77 million Americans had watched the series as children. By the show's 40th anniversary in 2009, it was ranked the fifteenth-most-popular children's show on television.

As of 2001, there were over 1,000 research studies regarding "Sesame Street"s efficacy, impact, and effect on American culture. The CTW solicited the Educational Testing Service (ETS) to conduct summative research on the show. ETS's two "landmark" summative evaluations, conducted in 1970 and 1971, demonstrated that the show had a significant educational impact on its viewers. These studies have been cited in other studies of the effects of television on young children. Additional studies conducted throughout "Sesame Street"s history demonstrated that the show continued to have a positive effect on its young viewers.

Lesser believed that "Sesame Street" research "may have conferred a new respectability upon the studies of the effects of visual media upon children". He also believed that the show had the same effect on the prestige of producing shows for children in the television industry. Historian Robert Morrow, in his book "Sesame Street and the Reform of Children's Television", which chronicled the show's influence on children's television and on the television industry as a whole, reported that many critics of commercial television saw "Sesame Street" as a "straightforward illustration for reform". Les Brown, a writer for "Variety", saw in "Sesame Street" "a hope for a more substantial future" for television.

Morrow reported that the networks responded by creating more high-quality television programs, but that many critics saw them as "appeasement gestures". According to Morrow, despite the CTW Model's effectiveness in creating a popular show, commercial television "made only a limited effort to emulate CTW's methods", and did not use a curriculum or evaluate what children learned from them. By the mid-1970s commercial television had abandoned their experiments with creating better children's programming. Other critics hoped that "Sesame Street", with its depiction of a functioning, multicultural community, would nurture racial tolerance in its young viewers. It was not until the mid-1990s that another children's television educational program, "Blue's Clues", used the CTW's methods to create and modify their content. The creators of "Blue's Clues" were influenced by "Sesame Street", but wanted to use research conducted in the 30 years since its debut. Angela Santomero, one of its producers, said, "We wanted to learn from "Sesame Street" and take it one step further".

Critic Richard Roeper said that perhaps one of the strongest indicators of the influence of "Sesame Street" has been the enduring rumors and urban legends surrounding the show and its characters, especially those concerning Bert and Ernie. One popular rumor points to Bert and Ernie being gay, as revealed by Mark Saltzman, one of the show's writers. In response, Sesame Street firmly denies the allegation.

"Sesame Street" was praised from its debut in 1969. "Newsday" reported that several newspapers and magazines had written "glowing" reports about the CTW and Cooney. The press overwhelmingly praised the new show; several popular magazines and niche magazines lauded it. In 1970, "Sesame Street" won twenty awards, including a Peabody Award, three Emmys, an award from the Public Relations Society of America, a Clio, and a Prix Jeunesse. By 1995, the show had won two Peabody Awards and four Parents' Choice Awards. In addition, it was the subject of retrospectives at the Smithsonian Institution and the Museum of Modern Art.

"Sesame Street" was not without its detractors, however. The state commission in Mississippi, where Henson was from, operated the state's PBS member station; in May 1970 it voted to not air "Sesame Street" because of its "highly [racially] integrated cast of children" which "the commission members felt ... Mississippi was not yet ready for". According to "", Lesser's account of the development and early years of "Sesame Street", there was little criticism of the show in the months following its premiere, but it increased at the end of its first season and beginning of the second season. Historian Robert W. Morrow speculated that much of the early criticism, which he called "surprisingly intense", stemmed from cultural and historical reasons in regards to, as he put it, "the place of children in American society and the controversies about television's effects on them".

According to Morrow, the "most important" studies finding negative effects of "Sesame Street" were conducted by educator Herbert A. Sprigle and psychologist Thomas D. Cook during its first two seasons. Social scientist and Head Start founder Urie Bronfenbrenner criticized the show for being too wholesome. Psychologist Leon Eisenberg saw "Sesame Street"s urban setting as "superficial" and having little to do with the problems confronted by the inner-city child. Head Start director Edward Zigler was probably "Sesame Street"s most vocal critic in the show's early years.

In spite of their commitment to multiculturalism, the CTW experienced conflicts with the leadership of minority groups, especially Latino groups and feminists, who objected to "Sesame Street"s depiction of Latinos and women. The CTW took steps to address their objections. By 1971, the CTW hired Hispanic actors, production staff, and researchers, and by the mid-1970s, Morrow reported that "the show included Chicano and Puerto Rican cast members, films about Mexican holidays and foods, and cartoons that taught Spanish words". As "The New York Times" has stated, creating strong female characters "that make kids laugh, but not...as female stereotypes" has been a challenge for the producers of "Sesame Street". According to Morrow, change regarding how women and girls were depicted on "Sesame Street" occurred slowly. As more female Muppets performers like Camille Bonora, Fran Brill, Pam Arciero, Carmen Osbahr, Stephanie D'Abruzzo, Jennifer Barnhart, and Leslie Carrara-Rudolph were hired and trained, stronger female characters like Rosita and Abby Cadabby were created.
In 2002, "Sesame Street" was ranked No. 27 on TV Guide's 50 Greatest TV Shows of All Time. It also won another Peabody Award in 2009 for sesamestreet.org. In 2013, TV Guide ranked the series No. 30 on its list of the 60 Best Series. As of 2018, "Sesame Street" has received 189 Emmy Awards, more than any other television series.



</doc>
<doc id="48068" url="https://en.wikipedia.org/wiki?curid=48068" title="Maurice Ravel">
Maurice Ravel

Joseph Maurice Ravel (; ; 7 March 1875 – 28 December 1937) was a French composer, pianist and conductor. He is often associated with impressionism along with his elder contemporary Claude Debussy, although both composers rejected the term. In the 1920s and 1930s Ravel was internationally regarded as France's greatest living composer.

Born to a music-loving family, Ravel attended France's premier music college, the Paris Conservatoire; he was not well regarded by its conservative establishment, whose biased treatment of him caused a scandal. After leaving the conservatoire, Ravel found his own way as a composer, developing a style of great clarity, incorporating elements of baroque, neoclassicism and, in his later works, jazz. He liked to experiment with musical form, as in his best-known work, "Boléro" (1928), in which repetition takes the place of development. He made some orchestral arrangements of other composers' music, of which his 1922 version of Mussorgsky's "Pictures at an Exhibition" is the best known.

As a slow and painstaking worker, Ravel composed fewer pieces than many of his contemporaries. Among his works to enter the repertoire are pieces for piano, chamber music, two piano concertos, ballet music, two operas and eight song cycles; he wrote no symphonies or church music. Many of his works exist in two versions: first, a piano score and later an orchestration. Some of his piano music, such as "Gaspard de la nuit" (1908), is exceptionally difficult to play, and his complex orchestral works such as "Daphnis et Chloé" (1912) require skilful balance in performance.

Ravel was among the first composers to recognise the potential of recording to bring their music to a wider public. From the 1920s, despite limited technique as a pianist or conductor, he took part in recordings of several of his works; others were made under his supervision.

Ravel was born in the Basque town of Ciboure, France, near Biarritz, from the Spanish border. His father, Pierre-Joseph Ravel, was an educated and successful engineer, inventor and manufacturer, born in Versoix near the Franco-Swiss border. His mother, Marie, "née" Delouart, was Basque but had grown up in Madrid. In 19th-century terms, Joseph had married beneath his status – Marie was illegitimate and barely literate – but the marriage was a happy one. Some of Joseph's inventions were successful, including an early internal combustion engine and a notorious circus machine, the "Whirlwind of Death", an automotive loop-the-loop that was a major attraction until a fatal accident at Barnum and Bailey's Circus in 1903.

Both Ravel's parents were Roman Catholics; Marie was also something of a free-thinker, a trait inherited by her elder son, who was always politically and socially progressive in outlook in adult life. He was baptised in the Ciboure parish church six days after he was born. The family moved to Paris three months later, and there a younger son, Édouard, was born. (He was close to his father, whom he eventually followed into the engineering profession.) Maurice was particularly devoted to their mother; her Basque-Spanish heritage was a strong influence on his life and music. Among his earliest memories were folk songs she sang to him. The household was not rich, but the family was comfortable, and the two boys had happy childhoods.

Ravel senior delighted in taking his sons to factories to see the latest mechanical devices, but he also had a keen interest in music and culture in general. In later life, Ravel recalled, "Throughout my childhood I was sensitive to music. My father, much better educated in this art than most amateurs are, knew how to develop my taste and to stimulate my enthusiasm at an early age." There is no record that Ravel received any formal general schooling in his early years; his biographer Roger Nichols suggests that the boy may have been chiefly educated by his father.

When he was seven, Ravel started piano lessons with Henry Ghys, a friend of Emmanuel Chabrier; five years later, in 1887, he began studying harmony, counterpoint and composition with Charles-René, a pupil of Léo Delibes. Without being anything of a child prodigy, he was a highly musical boy. Charles-René found that Ravel's conception of music was natural to him "and not, as in the case of so many others, the result of effort". Ravel's earliest known compositions date from this period: variations on a chorale by Schumann, variations on a theme by Grieg and a single movement of a piano sonata. They survive only in fragmentary form.

In 1888 Ravel met the young pianist Ricardo Viñes, who became not only a lifelong friend, but also one of the foremost interpreters of his works, and an important link between Ravel and Spanish music. The two shared an appreciation of Wagner, Russian music, and the writings of Poe, Baudelaire, and Mallarmé. At the Exposition Universelle in Paris in 1889, Ravel was much struck by the new Russian works conducted by Nikolai Rimsky-Korsakov. This music had a lasting effect on both Ravel and his older contemporary Claude Debussy, as did the exotic sound of the Javanese gamelan, also heard during the Exposition.

Émile Decombes took over as Ravel's piano teacher in 1889; in the same year Ravel gave his earliest public performance. Aged fourteen, he took part in a concert at the Salle Érard along with other pupils of Decombes, including Reynaldo Hahn and Alfred Cortot.

With the encouragement of his parents, Ravel applied for entry to France's most important musical college, the Conservatoire de Paris. In November 1889, playing music by Chopin, he passed the examination for admission to the preparatory piano class run by Eugène Anthiome. Ravel won the first prize in the Conservatoire's piano competition in 1891, but otherwise he did not stand out as a student. Nevertheless, these years were a time of considerable advance in his development as a composer. The musicologist Arbie Orenstein writes that for Ravel the 1890s were a period "of immense growth... from adolescence to maturity." 
In 1891 Ravel progressed to the classes of Charles-Wilfrid de Bériot, for piano, and Émile Pessard, for harmony. He made solid, unspectacular progress, with particular encouragement from Bériot but, in the words of the musical scholar Barbara L. Kelly, he "was only teachable on his own terms". His later teacher Gabriel Fauré understood this, but it was not generally acceptable to the conservative faculty of the Conservatoire of the 1890s. Ravel was expelled in 1895, having won no more prizes. His earliest works to survive in full are from these student days: "Sérénade grotesque", for piano, and "Ballade de la Reine morte d'aimer", a "mélodie" setting a poem by Roland de Marès (both 1893).

Ravel was never so assiduous a student of the piano as his colleagues such as Viñes and Cortot were. It was plain that as a pianist he would never match them, and his overriding ambition was to be a composer. From this point he concentrated on composition. His works from the period include the songs "Un grand sommeil noir" and "D'Anne jouant de l'espinette" to words by Paul Verlaine and Clément Marot, and the piano pieces "Menuet antique" and "Habanera" (for four-hands), the latter eventually incorporated into the "Rapsodie espagnole". At around this time, Joseph Ravel introduced his son to Erik Satie, who was earning a living as a café pianist. Ravel was one of the first musicians – Debussy was another – who recognised Satie's originality and talent. Satie's constant experiments in musical form were an inspiration to Ravel, who counted them "of inestimable value".
In 1897 Ravel was readmitted to the Conservatoire, studying composition with Fauré, and taking private lessons in counterpoint with André Gedalge. Both these teachers, particularly Fauré, regarded him highly and were key influences on his development as a composer. As Ravel's course progressed, Fauré reported "a distinct gain in maturity... engaging wealth of imagination". Ravel's standing at the Conservatoire was nevertheless undermined by the hostility of the Director, Théodore Dubois, who deplored the young man's musically and politically progressive outlook. Consequently, according to a fellow-student, Michel-Dimitri Calvocoressi, he was "a marked man, against whom all weapons were good". He wrote some substantial works while studying with Fauré, including the overture "Shéhérazade" and a violin sonata, but he won no prizes, and therefore was expelled again in 1900. As a former student he was allowed to attend Fauré's classes as a non-participating "auditeur" until finally abandoning the Conservatoire in 1903.

In 1899 Ravel composed his first piece to become widely known, though it made little impact initially: "Pavane pour une infante défunte" ("Pavane for a dead princess"). It was originally a solo piano work, commissioned by the Princesse de Polignac. In 1897 he conducted the first performance of the "Shéhérazade" overture, which had a mixed reception, with boos mingling with applause from the audience, and unflattering reviews from the critics. One described the piece as "a jolting debut: a clumsy plagiarism of the Russian School" and called Ravel a "mediocrely gifted debutant... who will perhaps become something if not someone in about ten years, if he works hard." Another critic, Pierre Lalo, thought that Ravel showed talent, but was too indebted to Debussy and should instead emulate Beethoven. Over the succeeding decades Lalo became Ravel's most implacable critic.

From the start of his career, Ravel appeared calmly indifferent to blame or praise. Those who knew him well believed that this was no pose but wholly genuine. The only opinion of his music that he truly valued was his own, perfectionist and severely self-critical. At twenty years of age he was, in the words of the biographer Burnett James, "self-possessed, a little aloof, intellectually biased, given to mild banter." He dressed like a dandy and was meticulous about his appearance and demeanour. Orenstein comments that, short in stature, light in frame, and bony in features, Ravel had the "appearance of a well-dressed jockey", whose large head seemed suitably matched to his formidable intellect. During the late 1890s and into the early years of the next century, Ravel was bearded in the fashion of the day; from his mid-thirties he was clean-shaven.

Around 1900, Ravel and a number of innovative young artists, poets, critics, and musicians joined together in an informal group; they came to be known as Les Apaches ("The Hooligans"), a name coined by Viñes to represent their status as "artistic outcasts". They met regularly until the beginning of the First World War, and members stimulated one another with intellectual argument and performances of their works. The membership of the group was fluid, and at various times included Igor Stravinsky and Manuel de Falla as well as their French friends.

Among the enthusiasms of the Apaches was the music of Debussy. Ravel, twelve years his junior, had known Debussy slightly since the 1890s, and their friendship, though never close, continued for more than ten years. In 1902 André Messager conducted the premiere of Debussy's opera" Pelléas et Mélisande" at the Opéra-Comique. It divided musical opinion. Dubois unavailingly forbade Conservatoire students to attend, and the conductor's friend and former teacher Camille Saint-Saëns was prominent among those who detested the piece. The Apaches were loud in their support. The first run of the opera consisted of fourteen performances: Ravel attended all of them.
Debussy was widely held to be an impressionist composer – a label he intensely disliked. Many music lovers began to apply the same term to Ravel, and the works of the two composers were frequently taken as part of a single genre. Ravel thought that Debussy was indeed an impressionist but that he himself was not. Orenstein comments that Debussy was more spontaneous and casual in his composing while Ravel was more attentive to form and craftsmanship. Ravel wrote that Debussy's "genius was obviously one of great individuality, creating its own laws, constantly in evolution, expressing itself freely, yet always faithful to French tradition. For Debussy, the musician and the man, I have had profound admiration, but by nature I am different from Debussy... I think I have always personally followed a direction opposed to that of [his] symbolism". During the first years of the new century Ravel's new works included the piano piece "Jeux d'eau" (1901), the String Quartet and the orchestral song cycle "Shéhérazade" (both 1903). Commentators have noted some Debussian touches in some parts of these works. Nichols calls the quartet "at once homage to and exorcism of Debussy's influence".

The two composers ceased to be on friendly terms in the middle of the first decade of the 1900s, for musical and possibly personal reasons. Their admirers began to form factions, with adherents of one composer denigrating the other. Disputes arose about the chronology of the composers' works and who influenced whom. Prominent in the anti-Ravel camp was Lalo, who wrote, "Where M. Debussy is all sensitivity, M. Ravel is all insensitivity, borrowing without hesitation not only technique but the sensitivity of other people." The public tension led to personal estrangement. Ravel said, "It's probably better for us, after all, to be on frigid terms for illogical reasons." Nichols suggests an additional reason for the rift. In 1904 Debussy left his wife and went to live with the singer Emma Bardac. Ravel, together with his close friend and confidante Misia Edwards and the opera star Lucienne Bréval, contributed to a modest regular income for the deserted Lilly Debussy, a fact that Nichols suggests may have rankled with her husband.

During the first years of the new century, Ravel made five attempts to win France's most prestigious prize for young composers, the Prix de Rome, past winners of which included Berlioz, Gounod, Bizet, Massenet and Debussy. In 1900 Ravel was eliminated in the first round; in 1901 he won the second prize for the competition. In 1902 and 1903 he won nothing: according to the musicologist Paul Landormy, the judges suspected Ravel of making fun of them by submitting cantatas so academic as to seem like parodies. In 1905 Ravel, by now thirty, competed for the last time, inadvertently causing a "furore". He was eliminated in the first round, which even critics unsympathetic to his music, including Lalo, denounced as unjustifiable. The press's indignation grew when it emerged that the senior professor at the Conservatoire, Charles Lenepveu, was on the jury, and only his students were selected for the final round; his insistence that this was pure coincidence was not well received. "L'affaire Ravel" became a national scandal, leading to the early retirement of Dubois and his replacement by Fauré, appointed by the government to carry out a radical reorganisation of the Conservatoire.

Among those taking a close interest in the controversy was Alfred Edwards, owner and editor of "Le Matin", for which Lalo wrote. Edwards was married to Ravel's friend Misia; the couple took Ravel on a seven-week Rhine cruise on their yacht in June and July 1905, the first time he had travelled abroad.

By the latter part of the 1900s Ravel had established a pattern of writing works for piano and subsequently arranging them for full orchestra. He was in general a slow and painstaking worker, and reworking his earlier piano compositions enabled him to increase the number of pieces published and performed. There appears to have been no mercenary motive for this; Ravel was known for his indifference to financial matters. The pieces that began as piano compositions and were then given orchestral dress were "Pavane pour une infante défunte" (orchestrated 1910), "Une barque sur l'océan" (1906, from the 1905 piano suite "Miroirs"), the Habanera section of "Rapsodie espagnole" (1907–08), "Ma mère l'Oye" (1908–10, orchestrated 1911), "Valses nobles et sentimentales" (1911, orchestrated 1912), "Alborada del gracioso" (from "Miroirs", orchestrated 1918) and "Le tombeau de Couperin" (1914–17, orchestrated 1919).
Ravel was not by inclination a teacher, but he gave lessons to a few young musicians he felt could benefit from them. Manuel Rosenthal was one, and records that Ravel was a very demanding teacher when he thought his pupil had talent. Like his own teacher, Fauré, he was concerned that his pupils should find their own individual voices and not be excessively influenced by established masters. He warned Rosenthal that it was impossible to learn from studying Debussy's music: "Only Debussy could have written it and made it sound like only Debussy can sound." When George Gershwin asked him for lessons in the 1920s, Ravel, after serious consideration, refused, on the grounds that they "would probably cause him to write bad Ravel and lose his great gift of melody and spontaneity". The best known composer who studied with Ravel was probably Ralph Vaughan Williams, who was his pupil for three months in 1907–08. Vaughan Williams recalled that Ravel helped him escape from "the heavy contrapuntal Teutonic manner... "Complexe mais pas compliqué" was his motto."

Vaughan Williams's recollections throw some light on Ravel's private life, about which the latter's reserved and secretive personality has led to much speculation. Vaughan Williams, Rosenthal and Marguerite Long have all recorded that Ravel frequented brothels. Long attributed this to his self-consciousness about his diminutive stature, and consequent lack of confidence with women. By other accounts, none of them first-hand, Ravel was in love with Misia Edwards, or wanted to marry the violinist Hélène Jourdan-Morhange. Rosenthal records and discounts contemporary speculation that Ravel, a lifelong bachelor, may have been homosexual. Such speculation recurred in a 2000 life of Ravel by Benjamin Ivry; subsequent studies have concluded that Ravel's sexuality and personal life remain a mystery.

Ravel's first concert outside France was in 1909. As the guest of the Vaughan Williamses, he visited London, where he played for the Société des Concerts Français, gaining favourable reviews and enhancing his growing international reputation.

The Société Nationale de Musique, founded in 1871 to promote the music of rising French composers, had been dominated since the mid-1880s by a conservative faction led by Vincent d'Indy. Ravel, together with several other former pupils of Fauré, set up a new, modernist organisation, the Société Musicale Indépendente, with Fauré as its president. The new society's inaugural concert took place on 20 April 1910; the seven items on the programme included premieres of Fauré's song cycle "La chanson d'Ève", Debussy's piano suite "D'un cahier d'esquisses", Zoltán Kodály's "Six pièces pour piano", and the original piano duet version of Ravel's " Ma mère l'Oye". The performers included Fauré, Florent Schmitt, Ernest Bloch, Pierre Monteux and, in the Debussy work, Ravel. Kelly considers it a sign of Ravel's new influence that the society featured Satie's music in a concert in January 1911.

The first of Ravel's two operas, the one-act comedy "L'heure espagnole" was premiered in 1911. The work had been completed in 1907, but the manager of the Opéra-Comique, Albert Carré, repeatedly deferred its presentation. He was concerned that its plot – a bedroom farce – would be badly received by the ultra-respectable mothers and daughters who were an important part of the Opéra-Comique's audience. The piece was only modestly successful at its first production, and it was not until the 1920s that it became popular.
In 1912 Ravel had three ballets premiered. The first, to the orchestrated and expanded version of "Ma mère l'Oye", opened at the Théâtre des Arts in January. The reviews were excellent: the "Mercure de France" called the score "absolutely ravishing, a masterwork in miniature". The music rapidly entered the concert repertoire; it was played at the Queen's Hall, London, within weeks of the Paris premiere, and was repeated at the Proms later in the same year. "The Times" praised "the enchantment of the work ... the effect of mirage, by which something quite real seems to float on nothing." New York audiences heard the work in the same year. Ravel's second ballet of 1912 was "Adélaïde ou le langage des fleurs", danced to the score of "Valses nobles et sentimentales", which opened at the Châtelet in April. "Daphnis et Chloé" opened at the same theatre in June. This was his largest-scale orchestral work, and took him immense trouble and several years to complete.

"Daphnis et Chloé" was commissioned in or about 1909 by the impresario Sergei Diaghilev for his company, the Ballets Russes. Ravel began work with Diaghilev's choreographer, Michel Fokine, and designer, Léon Bakst. Fokine had a reputation for his modern approach to dance, with individual numbers replaced by continuous music. This appealed to Ravel, and after discussing the action in great detail with Fokine, Ravel began composing the music. There were frequent disagreements between the collaborators, and the premiere was under-rehearsed because of the late completion of the work. It had an unenthusiastic reception and was quickly withdrawn, although it was revived successfully a year later in Monte Carlo and London. The effort to complete the ballet took its toll on Ravel's health; neurasthenia obliged him to rest for several months after the premiere.

Ravel composed little during 1913. He collaborated with Stravinsky on a performing version of Mussorgsky's unfinished opera "Khovanshchina", and his own works were the "Trois poèmes de Mallarmé" for soprano and chamber ensemble, and two short piano pieces, "À la manière de Borodine" and "À la manière de Chabrier". In 1913, together with Debussy, Ravel was among the musicians present at the dress rehearsal of "The Rite of Spring". Stravinsky later said that Ravel was the only person who immediately understood the music. Ravel predicted that the premiere of the "Rite" would be seen as an event of historic importance equal to that of "Pelléas et Mélisande".

When Germany invaded France in 1914, Ravel tried to join the French Air Force. He considered his small stature and light weight ideal for an aviator, but was rejected because of his age and a minor heart complaint. After several unsuccessful attempts to enlist, Ravel finally joined the Thirteenth Artillery Regiment as a lorry driver in March 1915, when he was forty. Stravinsky expressed admiration for his friend's courage: "at his age and with his name he could have had an easier place, or done nothing". Some of Ravel's duties put him in mortal danger, driving munitions at night under heavy German bombardment. At the same time his peace of mind was undermined by his mother's failing health. His own health also deteriorated; he suffered from insomnia and digestive problems, underwent a bowel operation following amoebic dysentery in September 1916, and had frostbite in his feet the following winter.

During the war, the Ligue Nationale pour la Defense de la Musique Française was formed by Saint-Saëns, Dubois, d'Indy and others, campaigning for a ban on the performance of contemporary German music. Ravel declined to join, telling the committee of the league in 1916, "It would be dangerous for French composers to ignore systematically the productions of their foreign colleagues, and thus form themselves into a sort of national coterie: our musical art, which is so rich at the present time, would soon degenerate, becoming isolated in banal formulas." The league responded by banning Ravel's music from its concerts.

Ravel's mother died in January 1917, and he fell into a "horrible despair", compounding the distress he felt at the suffering endured by the people of his country during the war. He composed few works in the war years. The Piano Trio was almost complete when the conflict began, and the most substantial of his wartime works is "Le tombeau de Couperin", composed between 1914 and 1917. The suite celebrates the tradition of François Couperin, the 18th-century French composer; each movement is dedicated to a friend of Ravel's who died in the war.

After the war, those close to Ravel recognised that he had lost much of his physical and mental stamina. As the musicologist Stephen Zank puts it, "Ravel's emotional equilibrium, so hard won in the previous decade, had been seriously compromised". His output, never large, became smaller. Nonetheless, after the death of Debussy in 1918, he was generally seen, in France and abroad, as the leading French composer of the era. Fauré wrote to him, "I am happier than you can imagine about the solid position which you occupy and which you have acquired so brilliantly and so rapidly. It is a source of joy and pride for your old professor." Ravel was offered the Legion of Honour in 1920, and although he declined the decoration, he was viewed by the new generation of composers typified by Satie's protégés Les Six as an establishment figure. Satie had turned against him, and commented, "Ravel refuses the Légion d'honneur, but all his music accepts it." Despite this attack, Ravel continued to admire Satie's early music, and always acknowledged the older man's influence on his own development. Ravel took a benign view of Les Six, promoting their music, and defending it against journalistic attacks. He regarded their reaction against his works as natural, and preferable to their copying his style. Through the Société Musicale Indépendente, he was able to encourage them and composers from other countries. The Société presented concerts of recent works by American composers including Aaron Copland, Virgil Thomson and George Antheil and by Vaughan Williams and his English colleagues Arnold Bax and Cyril Scott.
Orenstein and Zank both comment that, although Ravel's post-war output was small, averaging only one composition a year, it included some of his finest works. In 1920 he completed "La valse", in response to a commission from Diaghilev. He had worked on it intermittently for some years, planning a concert piece, "a sort of apotheosis of the Viennese waltz, mingled with, in my mind, the impression of a fantastic, fatal whirling". It was rejected by Diaghilev, who said, "It's a masterpiece, but it's not a ballet. It's the portrait of a ballet". Ravel heard Diaghilev's verdict without protest or argument, left, and had no further dealings with him. Nichols comments that Ravel had the satisfaction of seeing the ballet staged twice by other managements before Diaghilev died. A ballet danced to the orchestral version of "Le tombeau de Couperin" was given at the Théâtre des Champs-Elysées in November 1920, and the premiere of "La valse" followed in December. The following year "Daphnis et Chloé" and " L'heure espagnole" were successfully revived at the Paris Opéra.

In the post-war era there was a reaction against the large-scale music of composers such as Gustav Mahler and Richard Strauss. Stravinsky, whose "Rite of Spring" was written for a huge orchestra, began to work on a much smaller scale. His 1923 ballet score "Les noces" is composed for voices and twenty-one instruments. Ravel did not like the work (his opinion caused a cooling in Stravinsky's friendship with him) but he was in sympathy with the fashion for "dépouillement" – the "stripping away" of pre-war extravagance to reveal the essentials. Many of his works from the 1920s are noticeably sparer in texture than earlier pieces. Other influences on him in this period were jazz and atonality. Jazz was popular in Parisian cafés, and French composers such as Darius Milhaud incorporated elements of it in their work. Ravel commented that he preferred jazz to grand opera, and its influence is heard in his later music. Arnold Schönberg's abandonment of conventional tonality also had echoes in some of Ravel's music such as the "Chansons madécasses" (1926), which Ravel doubted he could have written without the example of "Pierrot Lunaire". His other major works from the 1920s include the orchestral arrangement of Mussorgsky's piano suite "Pictures at an Exhibition" (1922), the opera "L'enfant et les sortilèges" to a libretto by Colette (1926), "Tzigane" (1924) and the Violin Sonata (1927).

Finding city life fatiguing, Ravel moved to the countryside. In May 1921 he took up residence at Le Belvédère, a small house on the fringe of Montfort-l'Amaury, west of Paris, in the Yvelines département. Looked after by a devoted housekeeper, Mme Revelot, he lived there for the rest of his life. At Le Belvédère Ravel composed and gardened, when not performing in Paris or abroad. His touring schedule increased considerably in the 1920s, with concerts in Britain, Sweden, Denmark, the US, Canada, Spain, Austria and Italy.

The last composition Ravel completed in the 1920s, "Boléro", became his most famous. He was commissioned to provide a score for Ida Rubinstein's ballet company, and having been unable to secure the rights to orchestrate Albéniz's "Iberia", he decided on "an experiment in a very special and limited direction ... a piece lasting seventeen minutes and consisting wholly of orchestral tissue without music." Ravel continued that the work was "one long, very gradual crescendo. There are no contrasts, and there is practically no invention except the plan and the manner of the execution. The themes are altogether impersonal". He was astonished, and not wholly pleased, that it became a mass success. When one elderly member of the audience at the Opéra shouted "Rubbish!" at the premiere, he remarked, "That old lady got the message!" The work was popularised by the conductor Arturo Toscanini, and has been recorded several hundred times. Ravel commented to Arthur Honegger, one of Les Six, "I've written only one masterpiece – "Boléro". Unfortunately there's no music in it."

At the beginning of the 1930s, Ravel was working on two piano concertos. He completed the Piano Concerto in D major for the Left Hand first. It was commissioned by the Austrian pianist Paul Wittgenstein, who had lost his right arm during the war. Ravel was stimulated by the technical challenges of the project: "In a work of this kind, it is essential to give the impression of a texture no thinner than that of a part written for both hands." Ravel, not proficient enough to perform the work with only his left hand, demonstrated it with both hands. Wittgenstein was initially disappointed by the piece, but after long study he became fascinated by it and ranked it as a great work. In January 1932 he premiered it in Vienna to instant acclaim, and performed it in Paris with Ravel conducting the following year. The critic Henry Prunières wrote, "From the opening measures, we are plunged into a world in which Ravel has but rarely introduced us."

The Piano Concerto in G major was completed a year later. After the premiere in January 1932 there was high praise for the soloist, Marguerite Long, and for Ravel's score, though not for his conducting. Long, the dedicatee, played the concerto in more than twenty European cities, with the composer conducting; they planned to record it together, but at the sessions Ravel confined himself to supervising proceedings and Pedro de Freitas Branco conducted.
In October 1932, Ravel suffered a blow to the head in a taxi accident. The injury was not thought serious at the time, but in a study for the "British Medical Journal" in 1988 the neurologist R. A. Henson concludes that it may have exacerbated an existing cerebral condition. As early as 1927 close friends had been concerned at Ravel's growing absent-mindedness, and within a year of the accident he started to experience symptoms suggesting aphasia. Before the accident he had begun work on music for a film, "Don Quixote" (1933), but he was unable to meet the production schedule, and Jacques Ibert wrote most of the score. Ravel completed three songs for baritone and orchestra intended for the film; they were published as "Don Quichotte à Dulcinée". The manuscript orchestral score is in Ravel's hand, but Lucien Garban and Manuel Rosenthal helped in transcription. Ravel composed no more after this. The exact nature of his illness is unknown. Experts have ruled out the possibility of a tumour, and have variously suggested frontotemporal dementia, Alzheimer's disease and Creutzfeldt–Jakob disease. Though no longer able to write music or perform, Ravel remained physically and socially active until his last months. Henson notes that Ravel preserved most or all his auditory imagery and could still hear music in his head.

In 1937, Ravel began to suffer pain from his condition, and was examined by Clovis Vincent, a well-known Paris neurosurgeon. Vincent advised surgical treatment. He thought a tumour unlikely, and expected to find ventricular dilatation that surgery might prevent from progressing. Ravel's brother Edouard accepted this advice; as Henson comments, the patient was in no state to express a considered view. After the operation there seemed to be an improvement in his condition, but it was short-lived, and he soon lapsed into a coma. He died on 28 December, at the age of 62.

On 30 December 1937, Ravel was interred next to his parents in a granite tomb at Levallois-Perret cemetery, in north-west Paris. He was an atheist and there was no religious ceremony.

Marcel Marnat's catalogue of Ravel's complete works lists eighty-five works, including many incomplete or abandoned. Though that total is small in comparison with the output of his major contemporaries, it is nevertheless inflated by Ravel's frequent practice of writing works for piano and later rewriting them as independent pieces for orchestra. The performable body of works numbers about sixty; slightly more than half are instrumental. Ravel's music includes pieces for piano, chamber music, two piano concerti, ballet music, opera, and song cycles. He wrote no symphonies or church works.

Ravel drew on many generations of French composers from Couperin and Rameau to Fauré and the more recent innovations of Satie and Debussy. Foreign influences include Mozart, Schubert, Liszt and Chopin. He considered himself in many ways a classicist, often using traditional structures and forms, such as the ternary, to present his new melodic and rhythmic content and innovative harmonies. The influence of jazz on his later music is heard within conventional classical structures in the Piano Concerto and the Violin Sonata.
Ravel placed high importance on melody, telling Vaughan Williams that there is "an implied melodic outline in all vital music". His themes are frequently modal instead of using the familiar major or minor scales. As a result, there are few leading notes in his output. Chords of the ninth and eleventh and unresolved appoggiaturas, such as those in the "Valses nobles et sentimentales", are characteristic of Ravel's harmonic language.

Dance forms appealed to Ravel, most famously the bolero and pavane, but also the minuet, forlane, rigaudon, waltz, czardas, habanera and passacaglia. National and regional consciousness was important to him, and although a planned concerto on Basque themes never materialised, his works include allusions to Hebraic, Greek, Hungarian and gypsy themes. He wrote several short pieces paying tribute to composers he admired – Borodin, Chabrier, Fauré and Haydn, interpreting their characteristics in a Ravellian style. Another important influence was literary rather than musical: Ravel said that he learnt from Poe that "true art is a perfect balance between pure intellect and emotion", with the corollary that a piece of music should be a perfectly balanced entity with no irrelevant material allowed to intrude.

Ravel completed two operas, and worked on three others. The unrealised three were "Olympia", "La cloche engloutie" and "Jeanne d'Arc". "Olympia" was to be based on Hoffmann's "The Sandman"; he made sketches for it in 1898–99, but did not progress far. "La cloche engloutie" after Hauptmann's "The Sunken Bell" occupied him intermittently from 1906 to 1912, Ravel destroyed the sketches for both these works, except for a ""Symphonie horlogère"" which he incorporated into the opening of "L'heure espagnole". The third unrealised project was an operatic version of Joseph Delteil's 1925 novel about Joan of Arc. It was to be a large-scale, full-length work for the Paris Opéra, but Ravel's final illness prevented him from writing it.

Ravel's first completed opera was "L'heure espagnole" (premiered in 1911), described as a "comédie musicale". It is among the works set in or illustrating Spain that Ravel wrote throughout his career. Nichols comments that the essential Spanish colouring gave Ravel a reason for virtuoso use of the modern orchestra, which the composer considered "perfectly designed for underlining and exaggerating comic effects". Edward Burlingame Hill found Ravel's vocal writing particularly skilful in the work, "giving the singers something besides recitative without hampering the action", and "commenting orchestrally upon the dramatic situations and the sentiments of the actors without diverting attention from the stage." Some find the characters artificial and the piece lacking in humanity. The critic David Murray writes that the score "glows with the famous Ravel "tendresse"".

The second opera, also in one act, is "L'enfant et les sortilèges" (1926), a "fantaisie lyrique" to a libretto by Colette. She and Ravel had planned the story as a ballet, but at the composer's suggestion Colette turned it into an opera libretto. It is more uncompromisingly modern in its musical style than "L'heure espagnole", and the jazz elements and bitonality of much of the work upset many Parisian opera-goers. Ravel was once again accused of artificiality and lack of human emotion, but Nichols finds "profoundly serious feeling at the heart of this vivid and entertaining work". The score presents an impression of simplicity, disguising intricate links between themes, with, in Murray's phrase, "extraordinary and bewitching sounds from the orchestra pit throughout".

Although one-act operas are generally staged less often than full-length ones, Ravel's are produced regularly in France and abroad.

A substantial proportion of Ravel's output was vocal. His early works in that sphere include cantatas written for his unsuccessful attempts at the Prix de Rome. His other vocal music from that period shows Debussy's influence, in what Kelly describes as "a static, recitative-like vocal style", prominent piano parts and rhythmic flexibility. By 1906 Ravel was taking even further than Debussy the natural, sometimes colloquial, setting of the French language in "Histoires naturelles". The same technique is highlighted in "Trois poèmes de Mallarmé" (1913); Debussy set two of the three poems at the same time as Ravel, and the former's word-setting is noticeably more formal than the latter's, in which syllables are often elided. In the cycles "Shéhérazade" and "Chansons madécasses", Ravel gives vent to his taste for the exotic, even the sensual, in both the vocal line and the accompaniment.

Ravel's songs often draw on vernacular styles, using elements of many folk traditions in such works as "Cinq mélodies populaires grecques", "Deux mélodies hébraïques" and "Chants populaires". Among the poets on whose lyrics he drew were Marot, Léon-Paul Fargue, Leconte de Lisle and Verlaine. For three songs dating from 1914–15, he wrote his own texts.

Although Ravel wrote for mixed choirs and male solo voices, he is chiefly associated, in his songs, with the soprano and mezzo-soprano voices. Even when setting lyrics clearly narrated by a man, he often favoured a female voice, and he seems to have preferred his best-known cycle, "Shéhérazade", to be sung by a woman, although a tenor voice is a permitted alternative in the score.

During his lifetime it was above all as a master of orchestration that Ravel was famous. He minutely studied the ability of each orchestral instrument to determine its potential, putting its individual colour and timbre to maximum use. The critic Alexis Roland-Manuel wrote, "In reality he is, with Stravinsky, the one man in the world who best knows the weight of a trombone-note, the harmonics of a 'cello or a "pp" tam-tam in the relationships of one orchestral group to another."
For all Ravel's orchestral mastery, only four of his works were conceived as concert works for symphony orchestra: "Rapsodie espagnole", "La valse" and the two concertos. All the other orchestral works were written either for the stage, as in "Daphnis et Chloé", or as a reworking of piano pieces, "Alborada del gracioso" and "Une barque sur l'ocean", ("Miroirs"), "Valses nobles et sentimentales," " Ma mère l'Oye", "Tzigane" (originally for violin and piano) and "Le tombeau de Couperin." In the orchestral versions, the instrumentation generally clarifies the harmonic language of the score and brings sharpness to classical dance rhythms. Occasionally, as in the "Alborada del gracioso", critics have found the later orchestral version less persuasive than the sharp-edged piano original.

In some of his scores from the 1920s, including "Daphnis et Chloé", Ravel frequently divides his upper strings, having them play in six to eight parts while the woodwind are required to play with extreme agility. His writing for the brass ranges from softly muted to triple-forte outbursts at climactic points. In the 1930s he tended to simplify his orchestral textures. The lighter tone of the G major Piano Concerto follows the models of Mozart and Saint-Saëns, alongside use of jazz-like themes. The critics Edward Sackville-West and Desmond Shawe-Taylor comment that in the slow movement, "one of the most beautiful tunes Ravel ever invented", the composer "can truly be said to join hands with Mozart". The most popular of Ravel's orchestral works, "Boléro" (1928), was conceived several years before its completion; in 1924 he said that he was contemplating "a symphonic poem without a subject, where the whole interest will be in the rhythm".

Ravel made orchestral versions of piano works by Schumann, Chabrier, Debussy and Mussorgsky's piano suite "Pictures at an Exhibition". Orchestral versions of the last by Mikhail Tushmalov, Sir Henry Wood and Leo Funtek predated Ravel's 1922 version, and many more have been made since, but Ravel's remains the best known. Kelly remarks on its "dazzling array of instrumental colour", and a contemporary reviewer commented on how, in dealing with another composer's music, Ravel had produced an orchestral sound wholly unlike his own.

Although Ravel wrote fewer than thirty works for the piano, they exemplify his range; Orenstein remarks that the composer keeps his personal touch "from the striking simplicity of "Ma mère l'Oye" to the transcendental virtuosity of "Gaspard de la nuit"." Ravel's earliest major work for piano, "Jeux d'eau" (1901), is frequently cited as evidence that he evolved his style independently of Debussy, whose major works for piano all came later. When writing for solo piano, Ravel rarely aimed at the intimate chamber effect characteristic of Debussy, but sought a Lisztian virtuosity. The authors of "The Record Guide" consider that works such as "Gaspard de la Nuit" and "Miroirs" have a beauty and originality with a deeper inspiration "in the harmonic and melodic genius of Ravel himself."
Most of Ravel's piano music is extremely difficult to play, and presents pianists with a balance of technical and artistic challenges. Writing of the piano music the critic Andrew Clark commented in 2013, "A successful Ravel interpretation is a finely balanced thing. It involves subtle musicianship, a feeling for pianistic colour and the sort of lightly worn virtuosity that masks the advanced technical challenges he makes in "Alborada del gracioso"... and the two outer movements of "Gaspard de la nuit". Too much temperament, and the music loses its classical shape; too little, and it sounds pale." This balance caused a breach between the composer and Viñes, who said that if he observed the nuances and speeds Ravel stipulated in "Gaspard de la nuit", "Le gibet" would "bore the audience to death". Some pianists continue to attract criticism for over-interpreting Ravel's piano writing.

Ravel's regard for his predecessors is heard in several of his piano works; "Menuet sur le nom de Haydn" (1909), "À la manière de Borodine" (1912), "À la manière de Chabrier" (1913) and "Le tombeau de Couperin" all incorporate elements of the named composers interpreted in a characteristically Ravellian manner. Clark comments that those piano works which Ravel later orchestrated are overshadowed by the revised versions: "Listen to "Le tombeau de Couperin" and the complete ballet music for "Ma mère L'Oye" in the classic recordings conducted by André Cluytens, and the piano versions never sound quite the same again."

Apart from a one-movement sonata for violin and piano dating from 1899, unpublished in the composer's lifetime, Ravel wrote seven chamber works. The earliest is the String Quartet (1902–03), dedicated to Fauré, and showing the influence of Debussy's quartet of ten years earlier. Like the Debussy, it differs from the more monumental quartets of the established French school of Franck and his followers, with more succinct melodies, fluently interchanged, in flexible tempos and varieties of instrumental colour. The Introduction and Allegro for harp, flute, clarinet, and string quartet (1905) was composed very quickly by Ravel's standards. It is an ethereal piece in the vein of the "Pavane pour une infante défunte". Ravel also worked at unusual speed on the Piano Trio (1914) to complete it before joining the French Army. It contains Basque, Baroque and far Eastern influences, and shows Ravel's growing technical skill, dealing with the difficulties of balancing the percussive piano with the sustained sound of the violin and cello, "blending the two disparate elements in a musical language that is unmistakably his own," in the words of the commentator Keith Anderson.

Ravel's four chamber works composed after the First World War are the Sonata for Violin and Cello (1920–22), the "Berceuse sur le nom de Gabriel Fauré" for violin and piano (1922), the chamber original of "Tzigane" for violin and piano (1924) and finally the Violin Sonata (1923–27). The two middle works are respectively an affectionate tribute to Ravel's teacher, and a virtuoso display piece for the violinist Jelly d'Arányi. The Violin and Cello Sonata is a departure from the rich textures and harmonies of the pre-war Piano Trio: the composer said that it marked a turning point in his career, with thinness of texture pushed to the extreme and harmonic charm renounced in favour of pure melody. His last chamber work, the Violin Sonata (sometimes called the Second after the posthumous publication of his student sonata), is a frequently dissonant work. Ravel said that the violin and piano are "essentially incompatible" instruments, and that his Sonata reveals their incompatibility. Sackville-West and Shawe-Taylor consider the post-war sonatas "rather laboured and unsatisfactory", and neither work has matched the popularity of Ravel's pre-war chamber works.

Ravel's interpretations of some of his piano works were captured on piano roll between 1914 and 1928, although some rolls supposedly played by him may have been made under his supervision by Robert Casadesus, a better pianist. Transfers of the rolls have been released on compact disc. In 1913 there was a gramophone recording of "Jeux d'eau" played by Mark Hambourg, and by the early 1920s there were discs featuring the "Pavane pour une infante défunte" and "Ondine", and movements from the String Quartet, "Le tombeau de Couperin" and "Ma mère l'Oye". Ravel was among the first composers who recognised the potential of recording to bring their music to a wider public, and throughout the 1920s there was a steady stream of recordings of his works, some of which featured the composer as pianist or conductor. A 1932 recording of the G major Piano Concerto was advertised as "Conducted by the composer", although he had in fact supervised the sessions while a more proficient conductor took the baton. Recordings for which Ravel actually was the conductor included a "Boléro" in 1930, and a sound film of a 1933 performance of the D major concerto with Wittgenstein as soloist.

Ravel declined not only the Légion d'honneur, but all state honours from France, refusing to let his name go forward for election to the Institut de France. He accepted foreign awards, including honorary membership of the Royal Philharmonic Society in 1921, the Belgian Ordre de Léopold in 1926, and an honorary doctorate from the University of Oxford in 1928.

After Ravel's death, his brother and legatee, Edouard, turned the composer's house at Montfort-l'Amaury into a museum, leaving it substantially as Ravel had known it. the maison-musée de Maurice Ravel remains open for guided tours.

In his later years, Edouard Ravel declared his intention to leave the bulk of the composer's estate to the city of Paris for the endowment of a Nobel Prize in music, but evidently changed his mind. After his death in 1960, the estate passed through several hands. Despite the substantial royalties paid for performing Ravel's music, the news magazine "Le Point" reported in 2000 that it was unclear who the beneficiaries were. The British newspaper "The Guardian" reported in 2001 that no money from royalties had been forthcoming for the maintenance of the Ravel museum at Montfort-l'Amaury, which was in a poor state of repair.





</doc>
<doc id="48083" url="https://en.wikipedia.org/wiki?curid=48083" title="Sesame Workshop">
Sesame Workshop

Sesame Workshop (SW), formerly the Children's Television Workshop (CTW), is an American nonprofit organization which has been responsible for the production of several educational children's programs—including its first and best-known, "Sesame Street"—that have been televised internationally. Television producer Joan Ganz Cooney and foundation executive Lloyd Morrisett developed the idea to form an organization to produce "Sesame Street", a television series which would help children, especially those from low-income families, prepare for school. They spent two years, from 1966 to 1968, researching, developing, and raising money for the new series. Cooney was named as the Workshop's first executive director, which was termed "one of the most important television developments of the decade".

"Sesame Street" premiered as a series on National Educational Television (NET) in the United States on November 10, 1969, and moved to NET's successor, the Public Broadcasting Service (PBS), in late 1970. The Workshop was formally incorporated in 1970. Gerald S. Lesser and Edward L. Palmer were hired to perform research for the series; they were responsible for developing a system of planning, production, and evaluation, and the interaction between television producers and educators, later termed the "CTW model". They also hired a staff of producers and writers. After the initial success of "Sesame Street", they began to plan for its continued survival, which included procuring additional sources of funding and creating other television series. The early 1980s were a challenging period for the Workshop; difficulty finding audiences for their other productions and a series of bad investments harmed the organization until licensing agreements stabilized its revenues by 1985.

After "Sesame Street"s initial success, the CTW began to think about its survival beyond the development and first season of the show, since their funding sources were composed of organizations and institutions that tended to start projects, not sustain them. Government funding ended by 1981, so the CTW developed other activities, including unsuccessful ventures into adult programs, the publications of books and music, international co-productions, interactive media and new technologies, licensing arrangements, and programs for preschools. By 2005, income from the CTW's international co-productions of the series was $96 million. By 2008, the "Sesame Street" Muppets accounted for $15–17 million per year in licensing and merchandising fees. Cooney resigned as CEO during 1990; David Britt was named as her replacement. 

On June 5, 2000, the CTW changed its name to Sesame Workshop to better represent its activities beyond television, and Gary Knell became CEO. H. Melvin Ming replaced Knell during 2011. During 2014, Ming was succeeded by Jeffrey D. Dunn.

During the late 1960s, 97% of all American households owned a television set, and preschool children watched an average of 27 hours of television per week. Early childhood educational research at the time had shown that when children were prepared to succeed in school, they earned better grades and learned more effectively. Children from low-income families, however, had fewer resources than children from higher-income families to prepare them for school. Research had shown that children from low-income, minority backgrounds tested "substantially lower" than middle-class children in school-related skills, and that they continued to have educational deficits throughout school. The topic of developmental psychology had grown during this period, and scientists were beginning to understand that changes of early childhood education could increase children's cognitive growth.

During the winter of 1966, Joan Ganz Cooney hosted what she called "a little dinner party" at her apartment near Gramercy Park. Attending were her husband Tim Cooney, her boss Lewis Freedman, and Lloyd and Mary Morrisett, whom the Cooneys knew socially. Cooney was a producer of documentary films at New York public television station WNDT (now WNET), and won an Emmy for a documentary about poverty in America. Lloyd Morrisett was a vice-president at Carnegie Corporation, and was responsible for funding educational research, but had been frustrated in his efforts because they were unable to reach the large numbers of children in need of early education and intervention. Cooney was committed to using television to change society, and Morrisett was interested in using television to "reach greater numbers of needy kids". The conversation during the party, which according to writer Michael Davis was the start of a five-decade long professional relationship between Cooney and Morrisett, turned to the possibilities of using television to educate young children. A week later, Cooney and Freedman met with Morrisett at the office of Carnegie Corporation to discuss doing a feasibility study for creating an educational television program for preschoolers. Cooney was chosen to perform the study.

During the summer of 1967, Cooney took a leave of absence from WNDT, and funded by Carnegie Corporation, traveled the U.S. and Canada interviewing experts in child development, education, and television. She reported her findings in a fifty-five-page document entitled "The Potential Uses of Television in Preschool Education". The report described what the new series, which became "Sesame Street", would be like and proposed the creation of a company that managed its production, which eventually became known as the Children's Television Workshop (CTW).

For the next two years, Cooney and Morrisett researched and developed the new show, acquiring $8 million funding for "Sesame Street", and establishing the CTW. Due to her professional experience, Cooney always assumed the show's natural network would be PBS. Morrisett was amenable to broadcast it by commercial stations, but all three major networks rejected the idea. Davis, considering "Sesame Street"s licensing income years later, termed their decision "a billion-dollar blunder". Morrisett was responsible for fund acquisition, and was so successful at it that writer Lee D. Mitgang later said that it "defied conventional media wisdom". Cooney was responsible for the show's creative development, and for hiring the production and research staff for the CTW. The Carnegie Corporation provided their initial $1 million grant, and Morrisett, using his contacts, procured additional multimillion-dollar grants from the U.S. federal government, the Arthur Vining Davis Foundations, the Corporation for Public Broadcasting, and the Ford Foundation. Morrisett's friend Harold Howe, who was the commissioner for the U.S. Department of Education, promised $4 million, half of the new organization's budget. The Carnegie Corporation donated an additional $1 million. Mitgang stated, "Had Morrisett been any less effective in lining up financial support, Cooney's report likely would have become just another long-forgotten foundation idea". Funds gained from a combination of government agencies and private foundations protected them from the economic problems experienced by commercial networks, but caused difficulty for procuring future funding.

Cooney's proposal included using in-house formative research that would inform and improve production, and independent summative evaluations to test the show's effect on its young viewers' learning. During 1967, Morrisett recruited Harvard University professor Gerald S. Lesser, whom he had met while they were both psychology students at Yale, to help develop and lead the Workshop's research department. During 1972, the Markle Foundation donated $72,000 to Harvard to form the Center for Research in Children's Television, which served as a research agency for the CTW. Harvard produced about 20 major research studies about "Sesame Street" and its effect on young children. Lesser also served as the first chairman of the Workshop's advisory board, a position he held until his retirement in 1997. According to Lesser, the CTW's advisory board was unusual because instead of rubber-stamping the Workshop's decisions like most boards for other children's television shows, it contributed significantly to the series' design and implementation. Lesser reported in "", his 1974 book about the beginnings of "Sesame Street" and the Children's Television Workshop, that about 8—10% of the Workshop's initial budget was spent on research.

CTW's summative research was done by the Workshop's first research director, Edward L. Palmer, whom they met at the curriculum seminars Lesser conducted in Boston during the summer of 1967. During the summer of 1968, Palmer began to create educational goals, define the Workshop's research activities, and hire his research team. Lesser and Palmer were the only scientists in the U.S. studying the interaction of children and television at the time. They were responsible for developing a system of planning, production, and evaluation, and the interaction between television producers and educators, later called the "CTW model". Cooney observed of the CTW model: "From the beginning, we—the planners of the project—designed the show as an experimental research project with educational advisers, researchers, and television producers collaborating as equal partners". She described the collaboration as an "arranged marriage".

The CTW devoted 8% of its initial budget to outreach and publicity. In what television historian Robert W. Morrow called "an extensive campaign" that Lesser stated "would demand at least as much ingenuity as production and research", the Workshop promoted the show with educators, the broadcast industry, and the show's target audience, which consisted of inner-city children and their families. They hired Evelyn Payne Davis from the Urban League, whom Michael Davis called "remarkable, unsinkable, and indispensable", as the Workshop's first Vice President of Community Relations and manager of the Workshop's Community Educational Services (CES) division. Bob Hatch was hired to publicize their new series, both before its premiere and to take advantage of the media attention concerning "Sesame Street" during its first year of production.

According to Davis, despite her involvement with the project's initial research and development, Cooney's installment as CTW's executive director was questionable due to her lack of executive experience, untested financial management skills, and lack of experience with children's television and education. Davis also speculated that sexism was involved, stating, "Doubters also questioned whether a woman could gain the full confidence of a quorum of men from the federal government and two elite philanthropies, institutions whose wealth exceeded the gross national product of entire countries". At first, Cooney did not fight for the position. However she had the help of her husband and Morrisett, and the project's investors soon realized they could not begin without her. She was eventually named to the post during February 1968. As one of the first female executives in American television, her appointment was termed "one of the most important television developments of the decade". The formation of the Children Television Workshop was announced at a press conference at the Waldorf-Astoria Hotel in New York City on 20 May 1968.

After her appointment, Cooney hired Bob Davidson as her assistant; he was responsible for making agreements with approximately 180 public television stations to broadcast the new series. She assembled a team of producers: Jon Stone was responsible for writing, casting, and format; David Connell assumed control of animation and volume production; and Samuel Gibbon served as the show's chief liaison between the production staff and the research team. Stone, Connell, and Gibbon had worked on another children's show, "Captain Kangaroo", together. Cooney later said about "Sesame Street"s original team of producers, "collectively, we were a genius". CTW's first children's show, "Sesame Street", premiered on 10 November 1969. The CTW was not incorporated until 1970 because its creators wanted to see if the series was a success before they hired lawyers and accountants. Morrisett served as the first chairperson of CTW's board of trustees, a job he had for 28 years.

During the second season of "Sesame Street", to capitalize on the momentum the Workshop was enjoying and the attention it received from the press, the Workshop created its second series, "The Electric Company", during 1971. Morrisett used the same fund-acquisition techniques as he had used for "Sesame Street". "The Electric Company" stopped production in 1977, but continued in re-runs until 1985; it eventually became one of the most widely used TV shows in American classrooms and was revived in 2009. Starting during early 1970s, the Workshop ventured into adult programming, but found that it was difficult to make their programs accessible to all socio-economic groups. During 1971, it produced a medical program for adults termed "Feelin' Good", hosted by Dick Cavett, which was broadcast until 1974. According to writer Cary O'Dell, the show "lacked a clear direction and never found a large audience". During 1977, the Workshop broadcast an adult drama called "Best of Families", which was set in New York City around the turn of the 20th century. However, it lasted for only six or seven episodes and helped the Workshop decide to emphasize children's programs only.

Throughout the 1970s, the CTW's main non-television efforts changed from promotion to the development of educational materials for preschool settings. Early efforts included mobile viewing units that broadcast the show in the inner cities, in Appalachia, in Native American communities, and in migrant worker camps. During the early 1980s, the CTW created the Preschool Education Program (PEP), whose goal was to assist preschools, by combining television viewing, books, hands-on activities, and other media, in using the series as an educational resource. The Workshop also provided materials to non-English speaking children and adults. Starting during 2006, the Workshop expanded its programs by creating a series of PBS specials and DVDs largely concerning how military deployment affects the families of soldiers. Other efforts by the Workshop concerned families of prisoners, health and wellness, and safety.

According to Cooney and O'Dell, the 1980s were a problematic period for the Workshop. Other than "Sesame Street", many of its productions were not successful. "3-2-1 Contact" premiered during 1980, and were broadcast in various forms until 1988. The CTW found that finding funding for this series and other science-oriented series like "Square One Television", which was broadcast from 1987 to 1992, was easy because the National Science Foundation and other foundations were interested in funding science education. A series of poor investments in video games, motion picture production, theme parks, and other business ventures hurt the organization financially. Cooney brought in Bill Whaley during the late 1970s to work on their licensing agreements, but he was unable to compensate for the CTW's losses until 1986, when licensing revenues stabilized and its portfolio investments increased.

Cooney resigned as chairman and chief executive officer of the CTW during 1990, when she was replaced by David Britt, who was her "chief lieutenant in the executive ranks through the mid-1990s" and whom Cooney termed her "right-hand for many years". Britt had worked for her at the CTW since 1975 and had served as its president and chief operating officer since 1988. At that time, Cooney became chairman of the Workshop's executive board, which managed its businesses and licensing, and became more involved with the organization's creative efforts.

The Workshop had a reorganization during 1995, and dismissed about 12 percent of its staff. During 1998, for the first time in the series' history, they accepted funds from corporations for "Sesame Street" and its other programs, a policy criticized by consumer advocate Ralph Nader. The Workshop defended the acceptance of corporate sponsorship, stating that it compensated for a decrease of government subsidies and financial assistance by PBS. Also during 1998, the Workshop invested $25 million in the cable channel Noggin, initiated during 1999 by the Workshop and Viacom's Nickelodeon. During 2000, the profit the CTW earned from the deal, along with its 1998 revenue caused partly by the "Tickle Me Elmo" craze, enabled the CTW to purchase The Jim Henson Company's rights to the "Sesame Street" Muppets from the German media company EM.TV, which had acquired Henson earlier that year. The transaction, valued at $180 million, also included a small interest Henson had in the Noggin cable channel. Gary Knell stated, "Everyone, most especially the puppeteers, were thrilled that we were able to bring them home. It protected "Sesame Street" and allowed our international expansion to continue. Owning these characters has allowed us to maximize their potential. We are now in control of our own destiny".

The CTW changed its name to Sesame Workshop (SW) on June 5, 2000 (television); and on May 7, 2001 (home media), to better represent its non-television activities and interactive media. The website www.ctw.org changed its domain name to www.sesameworkshop.org on June 5, 2000. Also during 2000, Gary Knell succeeded Britt as president and CEO of the Workshop; according to Davis, he "presided over an especially fertile period in the nonprofit's history". Knell was instrumental in the creation of the cable channel Universal Kids (formerly Sprout TV network) during 2005. Sprout (launched as PBS Kids Sprout) was founded as a partnership between the Workshop, Comcast, PBS, and HIT Entertainment, all of whom contributed programming to the new network. After seven years as a partner, the Workshop divested its stake in Sprout during December 2012.

During 2007, the Sesame Workshop founded The Joan Ganz Cooney Center, an independent, non-profit organization that studies how to improve children's literacy by using and developing digital technologies "grounded in detailed educational curriculum", just as was done during the development of "Sesame Street". During 2009, the SW launched a website with a library of free video clips and free podcasts from throughout the show's history.

The 2008–2009 recession, which resulted in budget reductions for many nonprofit arts organizations, severely affected the SW; during 2009, it had to dismiss 20% of its staff. Despite earning about $100 million from licensing revenue, royalties, and foundation and government funding during 2012, the Workshop's total revenue was down 15% and its operating loss doubled to $24.3 million. During 2013, it responded by dismissing 10% of its staff, saying that it was necessary to "strategically focus" their resources because of "today's rapidly changing digital environment". During 2011, Knell left the SW to become the chief executive of National Public Radio NPR; H. Melvin Ming was named as his replacement. Ming had been chief financial officer since 1999 and its chief operating officer since 2002.

During 2014, H. Melvin Ming retired and was succeeded by former HIT Entertainment and Nickelodeon executive Jeffery D. Dunn. Dunn's appointment was the first time someone not affiliated with the SW became its manager, although he had associations with the organization previously. As of December 2014, the senior management at the SW consisted of: Dr. Lewis Bernstein, Executive Vice President and director of Education Research and Outreach; Terry Fitzpatrick, who was Executive Vice President and responsible for content distribution; Myung Kang-Huenke, Executive Vice President and General Counsel and Secretary; Daryl Mintz, Chief Financial Officer; Sherrie Westin, Executive Vice President and Chief Marketing Officer; and Michael H. Levine, Executive Director of the Joan Ganz Cooney Center. The organization's board of trustees included, among others: its chair, Vincent A. Mai, who was also chairman of AEA Investors, Inc.; Cooney, Morrisett, and Dunn.

After "Sesame Street"s initial success, the CTW began to think about its survival beyond the development and first season of the show, since its funding sources were composed of organizations and institutions that tended to start projects, not sustain them. Although the organization was what Cooney termed "the darling of the federal government for a brief period of two or three years", its first ten years of existence was marked by conflicts between the two; during 1978, the US Department of Education refused to deliver a $2 million check until the last day of the CTW's fiscal year. According to Davis, the federal government was opposed to funding public television, but the Workshop used Cooney's prestige and fame, and the fact that there would be "great public outcry" if the series was de-funded, to withstand the government's attacks on PBS. Eventually, the CTW got its own line item in the federal budget, but by 1981, government funding for "Sesame Street" had been terminated.

For the first time, a public broadcasting series had the potential to earn a great deal of money. Immediately after its premiere, "Sesame Street "gained attention from marketers, so the Workshop explored sources such as licensing arrangements, publishing, and international sales, and became, as Cooney envisioned, a "multiple media institution". Licensing became the foundation of, as writer Louise Gikow stated, the Sesame Workshop endowment, which had the potential to fund the organization and future productions and projects. Muppet creator Jim Henson owned the trademarks to the Muppet characters: he was reluctant to market them at first, but agreed when the CTW promised that the profits from toys, books, and other products were to be used exclusively to fund the CTW. The producers demanded complete control of all products and product decisions throughout its history; any product line associated with the series had to be educational, inexpensive, and not advertised during broadcastings of "Sesame Street". As Davis reported, "Cooney stressed restraint, prudence, and caution" in their marketing and licensing efforts. During the early 1970s, the CTW negotiated with the company Random House to establish and manage a non-broadcast materials division. Random House and the CTW named Christopher Cerf to assist the CTW in publishing books and other materials that emphasized the series' curriculum.

Soon after the premiere of "Sesame Street", producers, educators, and officials of other nations began requesting that a version of the series be broadcast in their countries. CBS executive Michael Dann was required to quit his job at that network due to a change of corporate policy preceding the so-called "rural purge"; upon his ouster, he became vice-president of the CTW and Cooney's assistant. Dann then began developing foreign versions of "Sesame Street" by arranging what were eventually termed co-productions, or independent programs with their own sets, characters, and curriculum goals. By 2009, "Sesame Street" had expanded into 140 countries; "The New York Times" reported during 2005 that income from the CTW's international co-productions of the series was $96 million. By 2008, the "Sesame Street" Muppets accounted for between $15 million and $17 million per year in licensing and merchandising fees, divided between the Workshop and Henson Associates.

During 1970, the CTW established a department managing the development of "nonbroadcast" materials based upon "Sesame Street". The Workshop decided that all materials its licensing program created would "underscore and amplify" the series' curriculum. Coloring books, for example, were prohibited because the Workshop felt they would restrict children's imaginations. The CTW published "Sesame Street Magazine" during 1970, which incorporated the show's curriculum goals in a magazine format. As with the series, research was performed for the magazine, initially by CTW's research department for a year and a half, and then by the Magazine Research Group during 1975.

Working with Random House editor Jason Epstein, the CTW hired Christopher Cerf to manage "Sesame Street"s book publishing program. During the division's first year, Cerf earned $900,000 for the CTW. He quit to become more involved with writing and composing music for the series, and was replaced eventually by Bill Whaley. Ann Kearns, vice president of licensing for the CTW during 2000, stated that Whaley was responsible for expanding the licensing to other products, and for creating a licensing model used by other children's seriess. As of 2001, there were more than 600 books available in the "Sesame Street" library, and as researcher Renee Cherow-O'Leary stated, "the print materials produced by CTW have been an enduring part of the legacy of Sesame Street". In one of these books, for example, the death of the "Sesame Street" character Mr. Hooper was featured in a book entitled "I'll Miss You, Mr. Hooper", published soon after the series featured it during 1983.

According to director Jon Stone, the music of "Sesame Street" was unlike any other children's program on television. For the first time, the show's songs fulfilled a specific purpose and was related to its curriculum. Cooney observed in her initial report that children had an "affinity for commercial jingles", so many of the show's songs were like television advertisements.

To attract the best composers and lyricists, and to encourage them to compose more music for the series, the CTW allowed songwriters to retain the rights to the songs they wrote. For the first time in children's television, the writers earned lucrative profits, which as Davis reported, "helped the show sustain the level of public interest in the show". Scriptwriters often wrote their own lyrics to accompany their scripts. Songwriters of note were Joe Raposo, Jeff Moss, Christopher Cerf, Tony Geiss, and Norman Stiles. Many of the songs written for "Sesame Street" have become what writer David Borgenicht termed "timeless classics". These songs included the "Sesame Street Theme" (known also as "Sunny Day"), "I Love Trash", "Rubber Duckie", "Bein' Green", and "Sing". Many "Sesame Street" songs were recorded by well-known artists such as Barbra Streisand, Lena Horne, Dizzy Gillespie, Paul Simon, and Jose Feliciano.

The series' first album, "Sesame Street Book & Record", recorded during 1970, was a major success and won a Grammy Award. " Entertainment Weekly" reported that by 1991, "Sesame Street" had received eight Grammys. According to Gikow, Raposo won three Emmys and four Grammys for his work for the series.

Soon after "Sesame Street" debuted in the USA, the CTW was asked independently by producers from several countries to produce versions of the series in their countries. Cooney remarked, "To be frank, I was really surprised, because we thought we were creating the quintessential American show. We thought the Muppets were quintessentially American, and it turns out they're the most international characters ever created". She hired former CBS executive Mike Dann, who quit commercial television to become her assistant, as a CTW vice-president. One of Dann's tasks was to manage offers to produce versions of "Sesame Street" in other countries. In response to Dann's appointment, television critic Marvin Kitman said, "After [Dann] sells ["Sesame Street"] in Russia and Czechoslovakia, he might try Mississippi, where it is considered too controversial for educational TV". This was a reference to the May 1970 decision by the state's PBS station to not air the series. By summer 1970, Dann had made the first international agreements for what the CTW came to term "co-productions".

The earliest international versions were what CTW vice-president Charlotte Cole and her colleagues termed "fairly simple", consisting of dubbed versions of the series with local language voice-overs and instructional cutaways. Dubbed versions of the series continued to be produced if the country's needs and resources warranted it. Eventually, a variant of the CTW model was used to create and produce independently produced preschool television series in other countries. By 2006, there were twenty co-productions. During 2001, there were more than 120 million viewers of all international versions of "Sesame Street", and by the show's 40th anniversary during 2009, they were seen in more than 140 countries. During 2005, Doreen Carvajal of "The New York Times" reported that income from the co-productions and international licensing accounted for $96 million. As Cole and her colleagues reported during 2000, "Children's Television Workshop (CTW) can be regarded as the single largest informal educator of young children in the world".

Ten years after the premiere of "Sesame Street", the CTW began experimenting with new technologies. During 1979, it began to plan the development of a theme park, Sesame Place, which opened during 1980 in Langhorne, Pennsylvania. Three international parks, "Parque Plaza Sesamo" in Monterrey, Mexico since 1995, Universal Studios Japan, and "Vila Sesamo" Kids' Land in Brazil were later built. One of the park's features was a computer gallery, which was developed by a small in-house team and included 55 computer programs. The team evolved into the Children's Computer Workshop (CCW) during 1982, which was disbanded and became the Interactive Technologies division of the CTW during the late 1980s. As "Sesame Street" researcher Shalom M. Fisch stated, no television series could be as interactive as computer games, even "participatory" shows like "Blue's Clues" or the "Sesame Street" segment "Elmo's World". The CTW has chosen to take advantage of the contingent feedback inherent in interactive computer games by developing and creating educational software based upon the television series' content and curriculum.

During 2008, a new "research-driven" website was created; it had 18 million downloads in one month. Also during 2008, the Sesame Workshop began to offer clips and full-length episodes on the websites Hulu, YouTube, and iTunes, where "Word on the Street" segments became the most popular webcast. During 2010, the Workshop began offering eBooks through the series' website, including a free rotating selection of five titles. Their selection of eBooks came in a variety of formats, some of which were interactive, and covered nineteen topics, including letters, numbers, counting, colors, and cultural appreciation.




</doc>
<doc id="48419" url="https://en.wikipedia.org/wiki?curid=48419" title="Mary of Teck">
Mary of Teck

Mary of Teck (Victoria Mary Augusta Louise Olga Pauline Claudine Agnes; 26 May 1867 – 24 March 1953) was Queen of the United Kingdom and the British Dominions and Empress of India as the wife of King George V.

Although technically a princess of Teck, in the Kingdom of Württemberg, she was born and raised in England. Her parents were Francis, Duke of Teck, who was of German extraction, and Princess Mary Adelaide of Cambridge, who was a granddaughter of King George III. She was informally known as "May", after her birth month. 

At the age of 24, she was betrothed to her second cousin once removed Prince Albert Victor, Duke of Clarence and Avondale, the eldest son of the Prince of Wales, but six weeks after the announcement of the engagement, he died unexpectedly during an influenza pandemic. The following year, she became engaged to Albert Victor's next surviving brother, George, who subsequently became king. Before her husband's accession, she was successively Duchess of York, Duchess of Cornwall, and Princess of Wales.

As queen consort from 1910, she supported her husband through the First World War, his ill health, and major political changes arising from the aftermath of the war. After George's death in 1936, she became queen mother when her eldest son, Edward VIII, ascended the throne, but to her dismay, he abdicated later the same year in order to marry twice-divorced American socialite Wallis Simpson. She supported her second son, George VI, until his death in 1952. She died the following year, during the reign of her granddaughter Elizabeth II, who had not yet been crowned.

Princess Victoria Mary ("May") of Teck was born on 26 May 1867 at Kensington Palace, London, in the same room where Queen Victoria, her first cousin once removed, was born 48 years and two days earlier. Queen Victoria came to visit the baby, writing that she was "a very fine one, with pretty little features and a quantity of hair". May would become the first queen consort born in England since Catherine Parr. Her father was Prince Francis, Duke of Teck, the son of Duke Alexander of Württemberg by his morganatic wife, Countess Claudine Rhédey von Kis-Rhéde (created Countess von Hohenstein in the Austrian Empire). Her mother was Princess Mary Adelaide of Cambridge, a granddaughter of King George III and the third child and younger daughter of Prince Adolphus, Duke of Cambridge, and Princess Augusta of Hesse-Kassel.

She was baptised in the Chapel Royal of Kensington Palace on 27 July 1867 by Charles Thomas Longley, Archbishop of Canterbury. From an early age, she was known to her family, friends and the public by the diminutive name of "May", after her birth month. 

May's upbringing was "merry but fairly strict". She was the eldest of four children, the only daughter, and "learned to exercise her native discretion, firmness, and tact" by resolving her three younger brothers' petty boyhood squabbles. They played with their cousins, the children of the Prince of Wales, who were similar in age. She grew up at Kensington Palace and White Lodge, in Richmond Park, which was granted by Queen Victoria on permanent loan, and was educated at home by her mother and governess (as were her brothers until they were sent to boarding schools). The Duchess of Teck spent an unusually long time with her children for a lady of her time and class, and enlisted May in various charitable endeavours, which included visiting the tenements of the poor.

Although May was a great-grandchild of George III, she was only a minor member of the British royal family. Her father, the Duke of Teck, had no inheritance or wealth and carried the lower royal style of Serene Highness because his parents' marriage was morganatic. The Duchess of Teck was granted a parliamentary annuity of £5,000 and received about £4,000 a year from her mother, the Duchess of Cambridge, but she donated lavishly to dozens of charities. Prince Francis was deeply in debt and moved his family abroad with a small staff in 1883, in order to economise. They travelled throughout Europe, visiting their various relations. They stayed in Florence, Italy, for a time, where May enjoyed visiting the art galleries, churches, and museums. She was fluent in English, German, and French.

In 1885, the family returned to London and lived for some time in Chester Square. May was close to her mother, and acted as an unofficial secretary, helping to organise parties and social events. She was also close to her aunt, the Grand Duchess of Mecklenburg-Strelitz, and wrote to her every week. During the First World War, the Crown Princess of Sweden helped pass letters from May to her aunt, who lived in enemy territory in Germany until her death in 1916.

In 1886, Princess May was a debutante in her first season and introduced at court. Her status as the only unmarried British princess who was not descended from Queen Victoria made her a suitable candidate for the royal family's most eligible bachelor, Prince Albert Victor, Duke of Clarence and Avondale, her second cousin once removed and the eldest son of the Prince of Wales.

In December 1891, May and Albert Victor were engaged. The choice of May as bride for the Duke owed much to Queen Victoria's fondness for her, as well as to her strong character and sense of duty. However, Albert Victor died six weeks later, in a recurrence of the worldwide 1889–90 influenza pandemic, before the date was fixed for their wedding.

Albert Victor's brother, Prince George, Duke of York, now second in line to the throne, evidently became close to May during their shared period of mourning, and Queen Victoria still favoured May as a suitable candidate to marry a future king. The public was also anxious that the Duke of York should marry and settle the succession. In May 1893, George proposed, and May accepted. They were soon deeply in love, and their marriage was a success. George wrote to May every day they were apart and, unlike his father, never took a mistress.

May married Prince George, Duke of York, in London on 6 July 1893 at the Chapel Royal, St James's Palace. The new Duke and Duchess of York lived in York Cottage on the Sandringham Estate in Norfolk, and in apartments in St James's Palace. York Cottage was a modest house for royalty, but it was a favourite of George, who liked a relatively simple life. They had six children: Edward, Albert, Mary, Henry, George, and John.

The children were put into the care of a nanny, as was usual in upper-class families at the time. The first nanny was dismissed for insolence and the second for abusing the children. This second woman, anxious to suggest that the children preferred her to anyone else, would pinch Edward and Albert whenever they were about to be presented to their parents so that they would start crying and be speedily returned to her. On discovery, she was replaced by her effective and much-loved assistant, Charlotte Bill.

Sometimes, Mary and George appear to have been distant parents. At first, they failed to notice the nanny's abuse of the young Princes Edward and Albert, and their youngest son, Prince John, was housed in a private farm on the Sandringham Estate, in Bill's care, perhaps to hide his epilepsy from the public. However, despite Mary's austere public image and her strait-laced private life, she was a caring mother in many respects, revealing a fun-loving and frivolous side to her children and teaching them history and music. 

Edward wrote fondly of his mother in his memoirs: "Her soft voice, her cultivated mind, the cosy room overflowing with personal treasures were all inseparable ingredients of the happiness associated with this last hour of a child's day ... Such was my mother's pride in her children that everything that happened to each one was of the utmost importance to her. With the birth of each new child, Mama started an album in which she painstakingly recorded each progressive stage of our childhood". He expressed a less charitable view, however, in private letters to his wife after his mother's death: "My sadness was mixed with incredulity that any mother could have been so hard and cruel towards her eldest son for so many years and yet so demanding at the end without relenting a scrap. I'm afraid the fluids in her veins have always been as icy cold as they are now in death."

As Duke and Duchess of York, George and May carried out a variety of public duties. In 1897, she became the patron of the London Needlework Guild in succession to her mother. The guild, initially established as The London Guild in 1882, was renamed several times and was named after May between 1914 and 2010. Samples of her own embroidery range from chair seats to tea cosies.
On 22 January 1901, Queen Victoria died, and May's father-in-law ascended the throne. For most of the rest of that year, George and May were known as the "Duke and Duchess of Cornwall and York". For eight months they toured the British Empire, visiting Gibraltar, Malta, Egypt, Ceylon, Singapore, Australia, New Zealand, Mauritius, South Africa and Canada. No royal had undertaken such an ambitious tour before. She broke down in tears at the thought of leaving her children, who were to be left in the care of their grandparents, for such a long time.

On 9 November 1901, nine days after arriving back in Britain and on the King's sixtieth birthday, George was created Prince of Wales. The family moved their London residence from St James's Palace to Marlborough House. As Princess of Wales, May accompanied her husband on trips to Austria-Hungary and Württemberg in 1904. The following year, she gave birth to her last child, John. It was a difficult labour, and although she recovered quickly, her newborn son suffered respiratory problems.

From October 1905 the Prince and Princess of Wales undertook another eight-month tour, this time of India, and the children were once again left in the care of their grandparents. They passed through Egypt both ways and on the way back stopped in Greece. The tour was almost immediately followed by a trip to Spain for the wedding of King Alfonso XIII to Victoria Eugenie of Battenberg, at which the bride and groom narrowly avoided assassination. Only a week after returning to Britain, May and George went to Norway for the coronation of George's brother-in-law and sister, King Haakon VII and Queen Maud.

On 6 May 1910, Edward VII died. Mary's husband ascended the throne and she became queen consort. When her husband asked her to drop one of her two official names, Victoria Mary, she chose to be called Mary, preferring not to be known by the same style as her husband's grandmother, Queen Victoria. Queen Mary was crowned with the King on 22 June 1911 at Westminster Abbey. Later in the year, the new King and Queen travelled to India for the Delhi Durbar held on 12 December 1911, and toured the sub-continent as Emperor and Empress of India, returning to Britain in February. 

The beginning of Mary's period as consort brought her into conflict with her mother-in-law, Queen Alexandra. Although the two were on friendly terms, Alexandra could be stubborn; she demanded precedence over Mary at the funeral of Edward VII, was slow in leaving Buckingham Palace, and kept some of the royal jewels that should have been passed to the new queen.

During the First World War, Queen Mary instituted an austerity drive at the palace, where she rationed food, and visited wounded and dying servicemen in hospital, which caused her great emotional strain. After three years of war against Germany, and with anti-German feeling in Britain running high, the Russian Imperial Family, which had been deposed by a revolutionary government, was refused asylum, possibly in part because the Tsar's wife was German-born. News of the Tsar's abdication provided a boost to those in Britain who wished to replace their own monarchy with a republic. The war ended in 1918 with the defeat of Germany and the abdication and exile of the Kaiser.
Two months after the end of the war, Queen Mary's youngest son, John, died at the age of thirteen. She described her shock and sorrow in her diary and letters, extracts of which were published after her death: "our poor darling little Johnnie had passed away suddenly ... The first break in the family circle is hard to bear but people have been so kind & sympathetic & this has helped us [the King and me] much." 

Her staunch support of her husband continued during the latter half of his reign. She advised him on speeches and used her extensive knowledge of history and royalty to advise him on matters affecting his position. He appreciated her discretion, intelligence, and judgement. She maintained an air of self-assured calm throughout all her public engagements in the years after the war, a period marked by civil unrest over social conditions, Irish independence, and Indian nationalism.

In the late 1920s, George V became increasingly ill with lung problems, exacerbated by his heavy smoking. Queen Mary paid particular attention to his care. During his illness in 1928, one of his doctors, Sir Farquhar Buzzard, was asked who had saved the King's life. He replied, "The Queen". In 1935, King George V and Queen Mary celebrated their silver jubilee, with celebrations taking place throughout the British Empire. In his jubilee speech, George paid public tribute to his wife, having told his speechwriter, "Put that paragraph at the very end. I cannot trust myself to speak of the Queen when I think of all I owe her."

George V died on 20 January 1936, after his physician, Lord Dawson of Penn, gave him an injection of morphine and cocaine that may have hastened his death. Queen Mary's eldest son ascended the throne as Edward VIII. She was now the queen mother, though she did not use that style, and was instead known as "Her Majesty Queen Mary".

Within the year, Edward caused a constitutional crisis by announcing his desire to marry his twice-divorced American mistress, Wallis Simpson. Mary disapproved of divorce, which was against the teaching of the Anglican church, and thought Simpson wholly unsuitable to be the wife of a king. After receiving advice from the Prime Minister of the United Kingdom, Stanley Baldwin, as well as the Dominion governments, that he could not remain king and marry Simpson, Edward abdicated. 

Though loyal and supportive of her son, Mary could not comprehend why Edward would neglect his royal duties in favour of his personal feelings. Simpson had been presented formally to both King George V and Queen Mary at court, but Mary later refused to meet her either in public or privately. She saw it as her duty to provide moral support for her second son, the reserved and stammering Prince Albert, Duke of York, who ascended the throne on Edward's abdication, taking the name George VI. When Mary attended the coronation, she became the first British dowager queen to do so. Edward's abdication did not lessen her love for him, but she never wavered in her disapproval of his actions.

Mary took an interest in the upbringing of her granddaughters, Princesses Elizabeth and Margaret, and took them on various excursions in London, to art galleries and museums. (The princesses' own parents thought it unnecessary for them to be taxed with any demanding educational regime.)

During the Second World War, George VI wished his mother to be evacuated from London. Although she was reluctant, she decided to live at Badminton House, Gloucestershire, with her niece, Mary Somerset, Duchess of Beaufort, the daughter of her brother Lord Cambridge. Her personal belongings were transported from London in seventy pieces of luggage. Her household, which comprised fifty-five servants, occupied most of the house, except for the Duke and Duchess's private suites, until after the war. The only people to complain about the arrangements were the royal servants, who found the house too small, though Queen Mary annoyed her niece by having the ancient ivy torn from the walls as she considered it unattractive and a hazard. From Badminton, in support of the war effort, she visited troops and factories and directed the gathering of scrap materials. She was known to offer lifts to soldiers she spotted on the roads. In 1942, her youngest surviving son, Prince George, Duke of Kent, was killed in an air crash while on active service. Mary finally returned to Marlborough House in June 1945, after the war in Europe had resulted in the defeat of Nazi Germany.

Mary was an eager collector of objects and pictures with a royal connection. She paid above-market estimates when purchasing jewels from the estate of Dowager Empress Marie of Russia and paid almost three times the estimate when buying the family's Cambridge Emeralds from Lady Kilmorey, the mistress of her late brother Prince Francis. In 1924, the famous architect Sir Edwin Lutyens created Queen Mary's Dolls' House for her collection of miniature pieces. Indeed, she has sometimes been criticised for her aggressive acquisition of "objets d'art" for the Royal Collection. On several occasions, she would express to hosts, or others, that she admired something they had in their possession, in the expectation that the owner would be willing to donate it. Her extensive knowledge of, and research into, the Royal Collection helped in identifying artefacts and artwork that had gone astray over the years. The royal family had lent out many objects over previous generations. Once she had identified unreturned items through old inventories, she would write to the holders, requesting that they be returned. In addition to being an avid collector, Mary was also generous in giving gifts of jewellery, such as presenting her ladies-in-waiting with rings on the occasion of their engagement.

In 1952, King George VI died, the third of Queen Mary's children to predecease her; her eldest granddaughter, Princess Elizabeth, ascended the throne as Queen Elizabeth II. The death of a third child profoundly affected her. Mary remarked to Princess Marie Louise: "I have lost three sons through death, but I have never been privileged to be there to say a last farewell to them."

Mary died on 24 March 1953 in her sleep at the age of 85, ten weeks before her granddaughter's coronation. Mary let it be known that, in the event of her death, the coronation was not to be postponed. Her remains lay in state at Westminster Hall, where large numbers of mourners filed past her coffin. She is buried beside her husband in the nave of St George's Chapel, Windsor Castle.

Sir Henry "Chips" Channon wrote that she was "above politics ... magnificent, humorous, worldly, in fact nearly sublime, though cold and hard. But what a grand Queen."

The ocean liner ; the Royal Navy battlecruiser, , which was destroyed at the Battle of Jutland in 1916; Queen Mary University of London; Queen Mary Reservoir in Surrey, United Kingdom; Queen Mary College, Lahore; Queen Mary's Hospital, Roehampton; Queen Mary Hospital, Hong Kong; Queen Mary's Peak, the highest mountain in Tristan da Cunha; Queen Mary Land in Antarctica; and Queen Mary's College in Chennai, India, are named in her honour.

Actresses who have portrayed Queen Mary include Dame Wendy Hiller (on the London stage in "Crown Matrimonial"), Greer Garson (in the television production of "Crown Matrimonial"), Judy Loe (in "Edward the Seventh"), Dame Flora Robson (in "A King's Story"), Dame Peggy Ashcroft (in "Edward & Mrs. Simpson"), Phyllis Calvert (in "The Woman He Loved"), Gaye Brown (in "All the King's Men"), Miranda Richardson (in "The Lost Prince"), Margaret Tyzack (in "Wallis & Edward"), Claire Bloom (in "The King's Speech"), Judy Parfitt (in W.E.), Valerie Dane (in Downton Abbey), and Dame Eileen Atkins (in "Bertie and Elizabeth" and "The Crown").


Queen Mary's arms were the royal coat of arms of the United Kingdom impaled with her family arms – the arms of her grandfather, Prince Adolphus, Duke of Cambridge, in the 1st and 4th quarters, and the arms of her father, Prince Francis, Duke of Teck, in the 2nd and 3rd quarters. The shield is surmounted by the imperial crown, and supported by the crowned lion of England and "a stag Proper" as in the arms of Württemberg.





</doc>
<doc id="48571" url="https://en.wikipedia.org/wiki?curid=48571" title="Æthelwulf, King of Wessex">
Æthelwulf, King of Wessex

Æthelwulf (; Old English for "Noble Wolf"; died 13 January 858) was King of Wessex from 839 to 858. In 825, his father, King Egbert, defeated King Beornwulf of Mercia, ending a long Mercian dominance over Anglo-Saxon England south of the Humber. Egbert sent Æthelwulf with an army to Kent, where he expelled the Mercian sub-king and was himself appointed sub-king. After 830, Egbert maintained good relations with Mercia, and this was continued by Æthelwulf when he became king in 839, the first son to succeed his father as West Saxon king since 641.

The Vikings were not a major threat to Wessex during Æthelwulf's reign. In 843, he was defeated in a battle against the Vikings at Carhampton in Somerset, but he achieved a major victory at the Battle of Aclea in 851. In 853 he joined a successful Mercian expedition to Wales to restore the traditional Mercian hegemony, and in the same year his daughter Æthelswith married King Burgred of Mercia. In 855 Æthelwulf went on pilgrimage to Rome. In preparation he gave a "decimation", donating a tenth of his personal property to his subjects; he appointed his eldest surviving son Æthelbald to act as King of Wessex in his absence, and his next son Æthelberht to rule Kent and the south-east. Æthelwulf spent a year in Rome, and on his way back he married Judith, the daughter of the West Frankish King Charles the Bald.

When Æthelwulf returned to England, Æthelbald refused to surrender the West Saxon throne, and Æthelwulf agreed to divide the kingdom, taking the east and leaving the west in Æthelbald's hands. On Æthelwulf's death in 858 he left Wessex to Æthelbald and Kent to Æthelberht, but Æthelbald's death only two years later led to the reunification of the kingdom.

In the 20th century Æthelwulf's reputation among historians was poor: he was seen as excessively pious and impractical, and his pilgrimage was viewed as a desertion of his duties. Historians in the 21st century see him very differently, as a king who consolidated and extended the power of his dynasty, commanded respect on the continent, and dealt more effectively than most of his contemporaries with Viking attacks. He is regarded as one of the most successful West Saxon kings, who laid the foundations for the success of his son, Alfred the Great.

At the beginning of the 9th century, England was almost completely under the control of the Anglo-Saxons, with Mercia and Wessex the most important southern kingdoms. Mercia was dominant until the 820s, and it exercised overlordship over East Anglia and Kent, but Wessex was able to maintain its independence from its more powerful neighbour. Offa, King of Mercia from 757 to 796, was the dominant figure of the second half of the 8th century. King Beorhtric of Wessex (786–802), married Offa's daughter in 789. Beorhtric and Offa drove Æthelwulf's father Egbert into exile, and he spent several years at the court of Charlemagne in Francia. Egbert was the son of Ealhmund, who had briefly been King of Kent in 784. Following Offa's death, King Coenwulf of Mercia (796–821) maintained Mercian dominance, but it is uncertain whether Beorhtric ever accepted political subordination, and when he died in 802 Egbert became king, perhaps with the support of Charlemagne. For two hundred years three kindreds had fought for the West Saxon throne, and no son had followed his father as king. Egbert's best claim was that he was the great-great-grandson of Ingild, brother of King Ine (688–726), and in 802 it would have seemed very unlikely that he would establish a lasting dynasty.

Almost nothing is recorded of the first twenty years of Egbert's reign, apart from campaigns against the Cornish in the 810s. The historian Richard Abels argues that the silence of the "Anglo-Saxon Chronicle" was probably intentional, concealing Egbert's purge of Beorhtric's magnates and suppression of rival royal lines. Relations between Mercian kings and their Kentish subjects were distant. Kentish ealdormen did not attend the court of King Coenwulf, who quarrelled with Archbishop Wulfred of Canterbury (805–832) over the control of Kentish monasteries; Coenwulf's primary concern seems to have been to gain access to the wealth of Kent. His successors Ceolwulf I (821–23) and Beornwulf (823–26) restored relations with Archbishop Wulfred, and Beornwulf appointed a sub-king of Kent, Baldred.

England had suffered Viking raids in the late 8th century, but no attacks are recorded between 794 and 835, when the Isle of Sheppey in Kent was ravaged. In 836 Egbert was defeated by the Vikings at Carhampton in Somerset, but in 838 he was victorious over an alliance of Cornishmen and Vikings at the Battle of Hingston Down, reducing Cornwall to the status of a client kingdom.

Æthelwulf was the son of Egbert, King of Wessex from 802 to 839. His mother's name is unknown, and he had no recorded siblings. He is known to have had two wives in succession, and so far as is known, Osburh, the senior of the two, was the mother of all his children. She was the daughter of Oslac, described by Asser, biographer of their son Alfred the Great, as "King Æthelwulf's famous butler", a man who was descended from Jutes who had ruled the Isle of Wight. Æthelwulf had six known children. His eldest son, Æthelstan, was old enough to be appointed King of Kent in 839, so he must have been born by the early 820s, and he died in the early 850s. The second son, Æthelbald, is first recorded as a charter witness in 841, and if, like Alfred, he began to attest when he was around six, he would have been born around 835; he was King of Wessex from 858 to 860. Æthelwulf's third son, Æthelberht, was probably born around 839 and was king from 860 to 865. The only daughter, Æthelswith, married Burgred, King of Mercia, in 853. The other two sons were much younger: Æthelred was born around 848 and was king from 865 to 871, and Alfred was born around 849 and was king from 871 to 899. In 856 Æthelwulf married Judith, daughter of Charles the Bald, King of West Francia and future Holy Roman Emperor, and his wife Ermentrude. Osburh had probably died, although it is possible that she had been repudiated. There were no children from Æthelwulf's marriage to Judith, and after his death she married his eldest surviving son and successor, Æthelbald.

Æthelwulf was first recorded in 825, when Egbert won the crucial Battle of Ellandun in Wiltshire against King Beornwulf of Mercia, ending the long Mercian ascendancy over southern England. Egbert followed it up by sending Æthelwulf with Eahlstan, Bishop of Sherborne, and Wulfheard, Ealdorman of Hampshire, with a large army into Kent to expel sub-king Baldred. Æthelwulf was descended from kings of Kent, and he was sub-king of Kent, and of Surrey, Sussex and Essex, which were then included in the sub-kingdom, until he inherited the throne of Wessex in 839. His sub-kingship is recorded in charters, in some of which King Egbert acted with his son's permission, such as a grant in 838 to Bishop Beornmod of Rochester, and Æthelwulf himself issued a charter as King of Kent in the same year. Unlike their Mercian predecessors, who alienated the Kentish people by ruling from a distance, Æthelwulf and his father successfully cultivated local support by governing through Kentish ealdormen and promoting their interests. In Abels' view, Egbert and Æthelwulf rewarded their friends and purged Mercian supporters. Historians take differing views on the attitude of the new regime to the Kentish church. At Canterbury in 828 Egbert granted privileges to the bishopric of Rochester, and according to the historian of Anglo-Saxon England Simon Keynes, Egbert and Æthelwulf took steps to secure the support of Archbishop Wulfred. However, the medievalist Nicholas Brooks argues that Wulfred's Mercian origin and connections proved a liability. Æthelwulf seized an estate in East Malling from the Canterbury church on the ground that it had only been granted by Baldred when he was in flight from the West Saxon forces; the issue of archiepiscopal coinage was suspended for several years; and the only estate Wulfred was granted after 825 he received from King Wiglaf of Mercia.

In 829 Egbert conquered Mercia, only for Wiglaf to recover his kingdom a year later. The scholar D. P. Kirby sees Wiglaf's restoration in 830 as a dramatic reversal for Egbert, which was probably followed by his loss of control of the London mint and the Mercian recovery of Essex and Berkshire, and the historian Heather Edwards states that his "immense conquest could not be maintained". However, in the view of Keynes:

In 838 King Egbert held an assembly at Kingston in Surrey, where Æthelwulf may have been consecrated as king by the archbishop. Egbert restored the East Malling estate to Wulfred's successor as Archbishop of Canterbury, Ceolnoth, in return for a promise of "firm and unbroken friendship" for himself and Æthelwulf and their heirs, and the same condition is specified in a grant to the see of Winchester. Egbert thus ensured support for Æthelwulf, who became the first son to succeed his father as West Saxon king since 641. At the same meeting Kentish monasteries chose Æthelwulf as their lord, and he undertook that, after his death, they would have freedom to elect their heads. Wulfred had devoted his archiepiscopate to fighting against secular power over Kentish monasteries, but Ceolnoth now surrendered effective control to Æthelwulf, whose offer of freedom from control after his death was unlikely to be honoured by his successors. Kentish ecclesiastics and laymen now looked for protection against Viking attacks to West Saxon rather than Mercian royal power. 

Egbert's conquests brought him wealth far greater than his predecessors had enjoyed, and enabled him to purchase the support which secured the West Saxon throne for his descendants. The stability brought by the dynastic succession of Egbert and Æthelwulf led to an expansion of commercial and agrarian resources, and to an expansion of royal income. The wealth of the West Saxon kings was also increased by the agreement in 838–39 with Archbishop Ceolnoth for the previously independent West Saxon minsters to accept the king as their secular lord in return for his protection. However, there was no certainty that the hegemony of Wessex would prove more permanent than that of Mercia.

When Æthelwulf succeeded to the throne of Wessex in 839, his experience as sub-king of Kent had given him valuable training in kingship, and he in turn made his own sons sub-kings. According to the "Anglo-Saxon Chronicle", on his accession "he gave to his son Æthelstan the kingdom of the people of Kent, and the kingdom of the East Saxons [Essex] and of the people of Surrey and of the South Saxons [Sussex]". However, Æthelwulf did not give Æthelstan the same power as his father had given him, and although Æthelstan attested his father's charters as king, he does not appear to have been given the power to issue his own charters. Æthelwulf exercised authority in the south-east and made regular visits there. He governed Wessex and Kent as separate spheres, and assemblies in each kingdom were only attended by the nobility of that country. The historian Janet Nelson says that "Æthelwulf ran a Carolingian-style family firm of plural realms, held together by his own authority as father-king, and by the consent of distinct élites." He maintained his father's policy of governing Kent through ealdormen appointed from the local nobility and advancing their interests, but gave less support to the church. In 843 Æthelwulf granted ten hides at Little Chart to Æthelmod, the brother of the leading Kentish ealdorman Ealhere, and Æthelmod succeeded to the post on his brother's death in 853. In 844 Æthelwulf granted land at Horton in Kent to Ealdorman Eadred, with permission to transfer parts of it to local landowners; in a culture of reciprocity, this created a network of mutual friendships and obligations between the beneficiaries and the king. Archbishops of Canterbury were firmly in the West Saxon king's sphere. His ealdormen enjoyed a high status, and were sometimes placed higher than the king's sons in lists of witnesses to charters. His reign is the first for which there is evidence of royal priests, and Malmesbury Abbey regarded him as an important benefactor, who is said to have been the donor of a shrine for the relics of Saint Aldhelm.

After 830, Egbert had followed a policy of maintaining good relations with Mercia, and this was continued by Æthelwulf when he became king. London was traditionally a Mercian town, but in the 830s it was under West Saxon control; soon after Æthelwulf's accession it reverted to Mercian control. King Wiglaf of Mercia died in 839 and his successor, Berhtwulf, revived the Mercian mint in London; the two kingdoms appear to have struck a joint issue in the mid-840s, possibly indicating West Saxon help in reviving Mercian coinage, and showing the friendly relations between the two powers. Berkshire was still Mercian in 844, but by 849 it was part of Wessex, as Alfred was born in that year at the West Saxon royal estate in Wantage, then in Berkshire. However, the local Mercian ealdorman, also called Æthelwulf, retained his position under the West Saxon kings. Berhtwulf died in 852 and cooperation with Wessex continued under Burgred, his successor as King of Mercia, who married Æthelwulf's daughter Æthelswith in 853. In the same year Æthelwulf assisted Burgred in a successful attack on Wales to restore the traditional Mercian hegemony over the Welsh.

In 9th-century Mercia and Kent, royal charters were produced by religious houses, each with its own style, but in Wessex there was a single royal diplomatic tradition, probably by a single agency acting for the king. This may have originated in Egbert's reign, and it becomes clear in the 840s, when Æthelwulf had a Frankish secretary called Felix. There were strong contacts between the West Saxon and Carolingian courts. The Annals of St Bertin took particular interest in Viking attacks on Britain, and in 852 Lupus, the Abbot of Ferrières and a protégé of Charles the Bald, wrote to Æthelwulf congratulating him on his victory over the Vikings and requesting a gift of lead to cover his church roof. Lupus also wrote to his "most beloved friend" Felix, asking him to manage the transport of the lead. Unlike Canterbury and the south-east, Wessex did not see a sharp decline in the standard of Latin in charters in the mid-9th century, and this may have been partly due to Felix and his continental contacts. Lupus thought that Felix had great influence over the King. Charters were mainly issued from royal estates in counties which were the heartland of ancient Wessex, namely Hampshire, Somerset, Wiltshire and Dorset, with a few in Kent.

An ancient division between east and west Wessex continued to be important in the 9th century; the boundary was Selwood Forest on the borders of Somerset, Dorset and Wiltshire. The two bishoprics of Wessex were Selborne in the west and Winchester in the east. Æthelwulf's family connections seem to have been west of Selwood, but his patronage was concentrated further east, particularly on Winchester, where his father was buried, and where he appointed Swithun to succeed Helmstan as bishop in 852–853. However, he made a grant of land in Somerset to his leading ealdorman, Eanwulf, and on 26 December 846 he granted a large estate to himself in South Hams in west Devon. He thus changed it from royal demesne, which he was obliged to pass on to his successor as king, to bookland, which could be transferred as the owner pleased, so he could make land grants to followers to improve security in a frontier zone.

Viking raids increased in the early 840s on both sides of the English Channel, and in 843 Æthelwulf was defeated by the companies of 35 Danish ships at Carhampton in Somerset. In 850 sub-king Æthelstan and Ealdorman Ealhhere of Kent won a naval victory over a large Viking fleet off Sandwich in Kent, capturing nine ships and driving off the rest. Æthelwulf granted Ealhhere a large estate in Kent, but Æthelstan is not heard of again, and probably died soon afterwards. The following year the "Anglo-Saxon Chronicle" records five different attacks on southern England. A Danish fleet of 350 Viking ships took London and Canterbury, and when King Berhtwulf of Mercia went to their relief he was defeated. The Vikings then moved on to Surrey, where they were defeated by Æthelwulf and his son Æthelbald at the Battle of Aclea. According to the "Anglo-Saxon Chronicle" the West Saxon levies "there made the greatest slaughter of a heathen that we have heard tell of up to the present day". The "Chronicle" frequently reported victories during Æthelwulf's reign won by levies led by ealdormen, unlike the 870s when royal command was emphasised, reflecting a more consensual style of leadership in the earlier period.

In 850 a Danish army wintered on Thanet, and in 853 ealdormen Ealhhere of Kent and Huda of Surrey were killed in a battle against the Vikings, also on Thanet. In 855 Danish Vikings stayed over the winter on Sheppey, before carrying on their pillaging of eastern England. However, during Æthelwulf's reign Viking attacks were contained and did not present a major threat.

The silver penny was almost the only coin used in middle and later Anglo-Saxon England. Æthelwulf's coinage came from a main mint in Canterbury and a secondary one at Rochester; both had been used by Egbert for his own coinage after he gained control of Kent. During Æthelwulf's reign, there were four main phases of the coinage distinguishable at both mints, though they are not exactly parallel and it is uncertain when the transitions took place. The first issue at Canterbury carried a design known as "Saxoniorum", which had been used by Egbert for one of his own issues. This was replaced by a portrait design in about 843, which can be subdivided further; the earliest coins have cruder designs than the later ones. At the Rochester mint the sequence was reversed, with an initial portrait design replaced, also in about 843, by a non-portrait design carrying a cross-and-wedges pattern on the obverse.

In about 848 both mints switched to a common design known as Dor¯b¯/Cant – the characters "Dor¯b¯" on the obverse of these coins indicate either "Dorobernia" (Canterbury) or "Dorobrevia" (Rochester), and "Cant", referring to Kent, appeared on the reverse. It is possible that the Canterbury mint continued to produce portrait coins at the same time. The Canterbury issue seems to have been ended in 850–851 by Viking raids, though it is possible that Rochester was spared, and the issue may have continued there. The final issue, again at both mints, was introduced in about 852; it has an inscribed cross on the reverse and a portrait on the obverse. Æthelwulf's coinage became debased by the end of his reign, and though the problem became worse after his death it is possible that the debasement prompted the changes in coin type from as early as 850.

Æthelwulf's first Rochester coinage may have begun when he was still sub-king of Kent, under Egbert. A hoard of coins deposited at the beginning of Æthelwulf's reign in about 840, found in the Middle Temple in London, contained 22 coins from Rochester and two from Canterbury of the first issue of each mint. Some numismatists argue that the high proportion of Rochester coins means that the issue must have commenced before Egbert's death, but an alternative explanation is that whoever hoarded the coins simply happened to have access to more Rochester coins. No coins were issued by Æthelwulf's sons during his reign.

Ceolnoth, Archbishop of Canterbury throughout Æthelwulf's reign, also minted coins of his own at Canterbury: there were three different portrait designs, thought to be contemporary with each of the first three of Æthelwulf's Canterbury issues. These were followed by an inscribed cross design that was uniform with Æthelwulf's final coinage. At Rochester, Bishop Beornmod produced only one issue, a cross-and-wedges design which was contemporary with Æthelwulf's "Saxoniorum" issue.

In the view of the numismatists Philip Grierson and Mark Blackburn, the mints of Wessex, Mercia and East Anglia were not greatly affected by changes in political control: "the remarkable continuity of moneyers which can be seen at each of these mints suggests that the actual mint organisation was largely independent of the royal administration and was founded in the stable trading communities of each city".

The early 20th-century historian W. H. Stevenson observed that: "Few things in our early history have led to so much discussion" as Æthelwulf's Decimation Charters; a hundred years later the charter expert Susan Kelly described them as "one of the most controversial groups of Anglo-Saxon diplomas". Both Asser and the "Anglo-Saxon Chronicle" say that Æthelwulf gave a decimation, in 855, shortly before leaving on pilgrimage to Rome. According to the "Chronicle" "King Æthelwulf conveyed by charter the tenth part of his land throughout all his kingdom to the praise of God and to his own eternal salvation". However, Asser states that "Æthelwulf, the esteemed king, freed the tenth part of his whole kingdom from royal service and tribute, and as an everlasting inheritance he made it over on the cross of Christ to the triune God, for the redemption of his soul and those of his predecessors." According to Keynes, Asser's version may just be a "loose translation" of the "Chronicle", and his implication that Æthelwulf released a tenth of all land from secular burdens was probably not intended. All land could be regarded as the king's land, so the "Chronicle" reference to "his land" does not necessarily refer to royal property, and since the booking of land – conveying it by charter – was always regarded as a pious act, Asser's statement that he made it over to God does not necessarily mean that the charters were in favour of the church.

The Decimation Charters are divided by Susan Kelly into four groups:


None of the charters are original, and Stevenson dismissed all of them as fraudulent apart from the Kentish one of 855. Stevenson saw the decimation as a donation of royal demesne to churches and laymen, with those grants which were made to laymen being on the understanding that there would be reversion to a religious institution. Up to the 1990s, his view on the authenticity of the charters was generally accepted by scholars, with the exception of the historian H. P. R. Finberg, who argued in 1964 that most are based on authentic diplomas. Finberg coined the terms the 'First Decimation' of 844, which he saw as the removal of public dues on a tenth of all bookland, and the 'Second Decimation' of 854, the donation of a tenth of "the private domain of the royal house" to the churches. He considered it unlikely that the First Decimation had been carried into effect, probably due to the threat from the Vikings. Finberg's terminology has been adopted, but his defence of the First Decimation generally rejected. In 1994, Keynes defended the Wilton charters in group 2, and his arguments have been widely accepted.

Historians have been divided on how to interpret the Second Decimation, and in 1994 Keynes described it as "one of the most perplexing problems" in the study of 9th-century charters. He set out three alternatives:


Some scholars, for example Frank Stenton, author of the standard history of Anglo-Saxon England, along with Keynes and Abels, see the Second Decimation as a donation of royal demesne. In Abels' view Æthelwulf sought loyalty from the aristocracy and church during the king's forthcoming absence from Wessex, and displayed a sense of dynastic insecurity also evident in his father's generosity towards the Kentish church in 838, and in an "avid attention" in this period to compiling and revising royal genealogies. Keynes suggests that "Æthelwulf's purpose was presumably to earn divine assistance in his struggles against the Vikings", and the mid-20th-century historian Eric John observes that "a lifetime of medieval studies teaches one that an early medieval king was never so political as when he was on his knees". The view that the decimation was a donation of the king's own personal estate is supported by the Anglo-Saxonist Alfred P. Smyth, who argues that these were the only lands the king was entitled to alienate by book. The historian Martin Ryan prefers the view that Æthelwulf freed a tenth part of land owned by laymen from secular obligations, who could now endow churches under their own patronage. Ryan sees it as part of a campaign of religious devotion. According to the historian David Pratt, it "is best interpreted as a strategic 'tax cut', designed to encourage cooperation in defensive measures through a partial remission of royal dues". Nelson states that the decimation took place in two phases, in Wessex in 854 and Kent in 855, reflecting that they remained separate kingdoms.

Kelly argues that most charters were based on genuine originals, including the First Decimation of 844. She says: "Commentators have been unkind [and] the 844 version has not been given the benefit of the doubt". In her view Æthelwulf then gave a 10% tax reduction on bookland, and ten years later he took the more generous step of "a widespread distribution of royal lands". Unlike Finberg, she believes that both decimations were carried out, although the second one may not have been completed due to opposition from Æthelwulf's son Æthelbald. She thinks that the grants of bookland to laymen in the Second Decimation were unconditional, not with reversion to religious houses as Stevenson had argued. However, Keynes is not convinced by Kelly's arguments, and thinks that the First Decimation charters were 11th or early 12th century fabrications.

In the early 850s Æthelwulf went on pilgrimage to Rome. According to Abels: "Æthelwulf was at the height of his power and prestige. It was a propitious time for the West Saxon king to claim a place of honour among the kings and emperors of christendom." His eldest surviving sons Æthelbald and Æthelberht were then adults, while Æthelred and Alfred were still young children. In 853 Æthelwulf sent his younger sons to Rome, perhaps accompanying envoys in connection with his own forthcoming visit. Alfred, and possibly Æthelred as well, were invested with the "belt of consulship". Æthelred's part in the journey is only known from a contemporary record in the "liber vitae" of San Salvatore, Brescia, as later records such as the "Anglo-Saxon Chronicle" were only interested in recording the honour paid to Alfred. Abels sees the embassy as paving the way for Æthelwulf's pilgrimage, and the presence of Alfred, his youngest and therefore most expendable son, as a gesture of goodwill to the papacy; confirmation by Pope Leo IV made Alfred his spiritual son, and thus created a spiritual link between the two "fathers". Kirby argues that the journey may indicate that Alfred was intended for the church, while Nelson on the contrary sees Æthelwulf's purpose as affirming his younger sons' throneworthiness, thus protecting them against being tonsured by their elder brothers, which would have rendered them ineligible for kingship.

Æthelwulf set out for Rome in the spring of 855, accompanied by Alfred and a large retinue. The King left Wessex in the care of his oldest surviving son, Æthelbald, and the sub-kingdom of Kent to the rule of Æthelberht, and thereby confirmed that they were to succeed to the two kingdoms. On the way the party stayed with Charles the Bald in Francia, where there were the usual banquets and exchange of gifts. Æthelwulf stayed a year in Rome, and his gifts to the Diocese of Rome included a gold crown weighing , two gold goblets, a sword bound with gold, four silver-gilt bowls, two silk tunics and two gold-interwoven veils. He also gave gold to the clergy and leading men and silver to the people of Rome. According to the historian Joanna Story, his gifts rivalled those of Carolingian donors and the Byzantine emperor and "were clearly chosen to reflect the personal generosity and spiritual wealth of the West Saxon king; here was no Germanic 'hillbilly' from the backwoods of the Christian world but, rather, a sophisticated, wealthy and utterly contemporary monarch". According to the 12th-century chronicler William of Malmesbury, he helped to pay for the restoration of the Saxon quarter, which had recently been destroyed by fire, for English pilgrims.

The pilgrimage puzzles historians and Kelly comments that "it is extraordinary that an early medieval king could consider his position safe enough to abandon his kingdom in a time of extreme crisis". She suggests that Æthelwulf may have been motivated by a personal religious impulse. Ryan sees it as an attempt to placate the divine wrath displayed by Viking attacks, whereas Nelson thinks he aimed to enhance his prestige in dealing with the demands of his adult sons. In Kirby's view:

On his way back from Rome Æthelwulf again stayed with King Charles the Bald, and may have joined him on a campaign against a Viking warband. On 1 October 856 Æthelwulf married Charles's daughter, Judith, aged 12 or 13, at Verberie. The marriage was considered extraordinary by contemporaries and by modern historians. Carolingian princesses rarely married and were usually sent to nunneries, and it was almost unknown for them to marry foreigners. Judith was crowned queen and anointed by Hincmar, Archbishop of Rheims. Although empresses had been anointed before, this is the first definitely known anointing of a Carolingian queen. In addition West Saxon custom, described by Asser as "perverse and detestable", was that the wife of a king of Wessex could not be called queen or sit on the throne with her husband – she was just the king's wife.

Æthelwulf returned to Wessex to face a revolt by Æthelbald, who attempted to prevent his father from recovering his throne. Historians give varying explanations for both the rebellion and the marriage. In Nelson's view, Æthelwulf's marriage to Judith added the West Saxon king to the family of kings and princely allies which Charles was creating. Charles was under attack both from Vikings and from a rising among his own nobility, and Æthelwulf had great prestige due to his victories over the Vikings; some historians such as Kirby and Pauline Stafford see the marriage as sealing an anti-Viking alliance. The marriage gave Æthelwulf a share in Carolingian prestige, and Kirby describes the anointing of Judith as "a charismatic sanctification which enhanced her status, blessed her womb and conferred additional throne-worthiness on her male offspring." These marks of a special status implied that a son of hers would succeed to at least part of Æthelwulf's kingdom, and explain Æthelbald's decision to rebel. The historian Michael Enright denies that an anti-Viking alliance between two such distant kingdoms could serve any useful purpose, and argues that the marriage was Æthelwulf's response to news that his son was planning to rebel; his son by an anointed Carolingian queen would be in a strong position to succeed as king of Wessex instead of the rebellious Æthelbald. Abels suggests that Æthelwulf sought Judith's hand because he needed her father's money and support to overcome his son's rebellion, but Kirby and Smyth argue that it is extremely unlikely that Charles the Bald would have agreed to marry his daughter to a ruler who was known to be in serious political difficulty. Æthelbald may also have acted out of resentment at the loss of patrimony he suffered as a result of the decimation.

Æthelbald's rebellion was supported by Ealhstan, Bishop of Sherborne, and Eanwulf, ealdorman of Somerset, even though they appear to have been two of the king's most trusted advisers. According to Asser, the plot was concerted "in the western part of Selwood", and western nobles may have backed Æthelbald because they resented the patronage Æthelwulf gave to eastern Wessex. Asser also stated that Æthelwulf agreed to give up the western part of his kingdom in order to avoid a civil war. Some historians such as Keynes and Abels think that his rule was then confined to the south-east, while others such as Kirby think it is more likely that it was Wessex itself which was divided, with Æthelbald keeping Wessex west of Selwood, Æthelwulf holding the centre and east, and Æthelberht keeping the south-east. Æthelwulf insisted that Judith should sit beside him on the throne until the end of his life, and according to Asser this was "without any disagreement or dissatisfaction on the part of his nobles".
King Æthelwulf's ring was found in a cart rut in Laverstock in Wiltshire in about August 1780 by one William Petty, who sold it to a silversmith in Salisbury. The silversmith sold it to the Earl of Radnor, and the earl's son, William, donated it to the British Museum in 1829. The ring, together with a similar ring of Æthelwulf's daughter Æthelswith, is one of two key examples of nielloed 9th-century metalwork. They appear to represent the emergence of a "court style" of West Saxon metalwork, characterised by an unusual Christian iconography, such as a pair of peacocks at the Fountain of Life on the Æthelwulf ring, associated with Christian immortality. The ring is inscribed "Æthelwulf Rex", firmly associating it with the King, and the inscription forms part of the design, so it cannot have been added later. Many of its features are typical of 9th-century metalwork, such as the design of two birds, beaded and speckled borders, and a saltire with arrow-like terminals on the back. It was probably manufactured in Wessex, but was typical of the uniformity of animal ornament in England in the 9th century. In the view of Leslie Webster, an expert on medieval art: "Its fine Trewhiddle style ornament would certainly fit a mid ninth-century date." In Nelson's view, "it was surely made to be a gift from this royal lord to a brawny follower: the sign of a successful ninth-century kingship". The art historian David Wilson sees it as a survival of the pagan tradition of the generous king as the "ring-giver".

Æthelwulf's will has not survived, but Alfred's has and it provides some information about his father's intentions. The kingdom was to be divided between the two oldest surviving sons, with Æthelbald getting Wessex and Æthelberht getting Kent and the south-east. The survivor of Æthelbald, Æthelred and Alfred was to inherit their father's bookland – his personal property as opposed to the royal lands which went with the kingship – and Abels and Yorke argue that this probably means that the survivor was to inherit the throne of Wessex as well. Other historians disagree. Nelson states that the provision regarding the personal property had nothing to do with the kingship, and Kirby comments: "Such an arrangement would have led to fratricidal strife. With three older brothers, Alfred's chances of reaching adulthood would, one feels, have been minimal." Æthelwulf's moveable wealth, such as gold and silver, was to be divided between "children, nobles and the needs of the king's soul". For the latter, he left one tenth of his hereditary land to be set aside to feed the poor, and he ordered that three hundred mancuses be sent to Rome each year, one hundred to be spent on lighting the lamps in St Peter's at Easter, one hundred for the lights of St Paul's, and one hundred for the pope.

Æthelwulf died on 13 January 858. According to the Annals of St Neots, he was buried at Steyning in Sussex, but his body was later transferred to Winchester, probably by Alfred. Æthelwulf was succeeded by Æthelbald in Wessex and Æthelberht in Kent and the south-east. The prestige conferred by a Frankish marriage was so great that Æthelbald then wedded his step-mother Judith, to Asser's retrospective horror; he described the marriage as a "great disgrace", and "against God's prohibition and Christian dignity". When Æthelbald died only two years later, Æthelberht became King of Wessex as well as Kent, and Æthelwulf's intention of dividing his kingdoms between his sons was thus set aside. In the view of Yorke and Abels this was because Æthelred and Alfred were too young to rule, and Æthelberht agreed in return that his younger brothers would inherit the whole kingdom on his death, whereas Kirby and Nelson think that Æthelberht just became the trustee for his younger brothers' share of the bookland.

After Æthelbald's death Judith sold her possessions and returned to her father, but two years later she eloped with Baldwin, Count of Flanders. In the 890s their son, also called Baldwin, married Æthelwulf's granddaughter Ælfthryth.

Æthelwulf's reputation among historians was poor in the twentieth century. In 1935, the historian R. H. Hodgkin attributed his pilgrimage to Rome to "the unpractical piety which had led him to desert his kingdom at a time of great danger", and described his marriage to Judith as "the folly of a man senile before his time". To Stenton in the 1960s he was "a religious and unambitious man, for whom engagement in war and politics was an unwelcome consequence of rank". One dissenter was Finberg, who in 1964 described him as "a king whose valour in war and princely munificence recalled the figures of the heroic age", but in 1979 Enright said: "More than anything else he appears to have been an impractical religious enthusiast." Early medieval writers, especially Asser, emphasise his religiosity and his preference for consensus, seen in the concessions made to avert a civil war on his return from Rome. In Story's view "his legacy has been clouded by accusations of excessive piety which (to modern sensibilities at least) has seemed at odds with the demands of early medieval kingship". In 839 an unnamed Anglo-Saxon king wrote to the Holy Roman Emperor Louis the Pious asking for permission to travel through his territory on the way to Rome, and relating an English priest's dream which foretold disaster unless Christians abandoned their sins. This is now believed to have been an unrealised project of Egbert at the end of his life, but it was formerly attributed to Æthelwulf, and seen as exhibiting what Story calls his reputation for "dramatic piety", and irresponsibility for planning to abandon his kingdom at the beginning of his reign.

In the twenty-first century he is seen very differently by historians. Æthelwulf is not listed in the index of Peter Hunter Blair's "An Introduction to Anglo-Saxon England", first published in 1956, but in a new introduction to the 2003 edition Keynes listed him among people "who have not always been accorded the attention they might be thought to deserve ... for it was he, more than any other, who secured the political fortune of his people in the ninth century, and who opened up channels of communication which led through Frankish realms and across the Alps to Rome". According to Story: "Æthelwulf acquired and cultivated a reputation both in Francia and Rome which is unparalleled in the sources since the height of Offa's and Coenwulf's power at the turn of the ninth century".

Nelson describes him as "one of the great underrated among Anglo-Saxons", and complains that she was only allowed 2,500 words for him in the Oxford Dictionary of National Biography, compared with 15,000 for Edward II and 35,000 for Elizabeth I. She says:


</doc>
<doc id="48585" url="https://en.wikipedia.org/wiki?curid=48585" title="Æthelbald, King of Wessex">
Æthelbald, King of Wessex

Æthelbald, King of Wessex (died 860) was the second of five sons of King Æthelwulf of Wessex. In 850 Æthelbald's elder brother Æthelstan defeated the Vikings in the first recorded sea battle in English history, but he is not recorded afterwards and probably died in the early 850s. The next year Æthelwulf and Æthelbald inflicted another defeat on the Vikings at the Battle of Aclea. In 855 Æthelwulf went on pilgrimage to Rome and he appointed Æthelbald king of Wessex, while Æthelberht, the next oldest son, became King of Kent, which had been conquered by Wessex thirty years earlier. When Æthelwulf returned to England in 856, Æthelbald refused to give up the crown. Most historians believe that Æthelbald continued to be king of Wessex while Æthelberht gave up Kent to his father, but some scholars think that Wessex itself was divided, with Æthelbald ruling the west and his father the east, while Æthelberht kept Kent. When Æthelwulf died, in 858 Æthelbald continued as (or became again) king of Wessex and his brother resumed (or carried on) his kingship of Kent.

On his way back from Rome, Æthelwulf stayed for several months with Charles the Bald, King of the Franks and married Charles' twelve-year-old daughter, Judith. After Æthelwulf's death Æthelbald married his stepmother, to the later horror of Asser, the biographer of his youngest brother, Alfred the Great. Asser denounced the union as being "against God's prohibition and Christian dignity, and also contrary to the practice of all pagans", but the marriage does not appear to have been condemned at the time. Æthelbald and Æthelberht appear to have been on good terms: when Æthelbald died in 860 Æthelberht became king of both Wessex and Kent, and they were never again divided.

When Æthelbald's grandfather Ecgberht became king of Wessex in 802, it would have seemed very unlikely that he would establish a lasting dynasty. For two hundred years, three families had fought for the West Saxon throne, and no son had followed his father as king. Ecgberht's nearest connection to a king of Wessex was as a great-great-grandson of Ingild, brother of King Ine (688–726), but he was believed to be a paternal descendant of Cerdic, the founder of the West Saxon dynasty, which made him an ætheling, a prince who had a legitimate claim to the throne. But in the ninth and tenth centuries Ecgberht's line controlled the kingdom, and all kings were sons of kings.

At the beginning of the ninth century, England was almost wholly under the control of the Anglo-Saxons, and the Midland kingdom of Mercia dominated southern England. In 825 Ecgberht decisively defeated the Mercians at the Battle of Ellendun, ending Mercian supremacy. The two kingdoms became allies, which was important in the resistance to Viking attacks. In 835 the Isle of Sheppey in Kent was ravaged. In 836 Ecgberht was defeated by the Vikings at Carhampton in Somerset, but in 838 he was victorious over an alliance of Cornishmen and Vikings at the Battle of Hingston Down, reducing Cornwall to the status of a client kingdom. He died in the following year and was succeeded by his son Æthelwulf, who appointed his eldest son Æthelstan as sub-king of Kent, Essex, Surrey and Sussex, in the same year.

Æthelbald was the second son of King Æthelwulf and probably of his first wife Osburh, who was the mother of Alfred the Great. As Æthelstan was old enough to be appointed king ten years before Alfred was born in 849, and Æthelbald took part in battle in 851, some historians argue that it is more likely that the elder children were born to an unrecorded earlier wife. Æthelstan died before his father, but Æthelbald and his three younger brothers were successively kings of Wessex: Æthelbald reigned from 855 to 860, Æthelberht reigned from 860 to 865, Æthelred I reigned from 865 to 871 and Alfred the Great reigned from 871 to 899. Æthelbald is first recorded when he witnessed a charter of his father (S 290) in 840 as "filius regis" (the king's son). He attested with the same designation in the 840s, to S 300 in 850 as "dux filius regis" and in the early 850s as "dux" (ealdorman). In 850 his elder brother Æthelstan defeated a Danish fleet off Sandwich in the first recorded naval battle in English history, but he is not recorded thereafter, and probably died soon afterwards. In 851 Æthelwulf and Æthelbald defeated the Vikings at the Battle of Aclea and, according to the "Anglo-Saxon Chronicle", "we have never heard of a greater slaughter of them, in any region, on any one day, before or since". At Easter in 854 Æthelbald and his younger brother Æthelberht attested charters as "dux", and in 855 their father went on pilgrimage to Rome and appointed Æthelbald as king of Wessex while Æthelberht became king of Kent, Essex, Surrey and Sussex.

Æthelwulf spent a year in Rome. On his way back he stayed for several months with Charles the Bald, King of the West Franks, and married Charles' twelve-year-old daughter Judith; the bishop of Rheims ceremonially consecrated her and Æthelwulf conferred the title of queen on her. Æthelwulf returned with his new wife in October 856, and according to Alfred the Great's biographer, Bishop Asser, during his absence a plot was hatched to prevent the king's return and keep Æthelbald on the throne. Asser regarded it as "a terrible crime: expelling the king from his own kingdom; but God did not allow it to happen, nor would the nobles of the whole Saxon land have any part in it". Asser stated that a great many men said that the initiative for "this wretched incident, unheard of in all previous ages" came from Æthelbald's chief counsellors, Eahlstan, Bishop of Sherborne and Eanwulf, Ealdorman of Somerset, who had been two of Æthelwulf's most senior advisers, while many blamed Æthelbald himself.

Historians give varying explanations for both the marriage and the rebellion. D. P. Kirby and Pauline Stafford see the match as sealing an anti-Viking alliance. Another factor was that Judith was a great-granddaughter of Charlemagne, and union with her gave Æthelwulf a share in Carolingian prestige. Kirby describes her anointing as "a charismatic sanctification which enhanced her status, blessed her womb and conferred additional throne-worthiness on her male offspring." These marks of a special status implied that a son of hers would succeed to at least part of Æthelwulf's kingdom, and explain Æthelbald's decision to rebel. He may also have feared that he would be disadvantaged if his father returned to rule Wessex while his brother kept Kent. Michael Enright argues that an alliance against the Vikings between such distant territories would have served no useful purpose. He sees the marriage as following Æthelbald's rebellion and being a response to it, intending that a son of Judith would displace Æthelbald as successor to the throne. Janet Nelson goes further, seeing Æthelwulf's pilgrimage as intended from the start to enhance his prestige to assist him in facing down filial resentments. Kirby and Sean Miller argue that it is unlikely that Charles would have agreed to his daughter being taken to a country in a state of civil war, so Æthelbald's revolt was probably a response to the marriage, which threatened to produce sons who had a stronger claim to the throne than he had. Richard Abels argues that Æthelbald probably hoped that his rule would be permanent: "All knew the dangers that attended a pilgrimage to Rome and were aware of the possibility that Æthelwulf would not return. His departure to Rome all but invited the prowling of hungry æthelings." Charles may have agreed to the marriage because he was under attack both from Vikings and from a rising among his own nobility, and Æthelwulf had great prestige due to his victories over the Vikings. The marriage added the West Saxon king to the network of royal and princely allies that Charles was creating.

Rivalry between east and west Wessex may have also been a factor in the dispute. The ancient Selwood Forest marked the boundary between the bishoprics of Sherborne in the west and Winchester in the east. In the eighth century, the connections of Ecgberht's family were with the west, but in the early ninth century, the family became close to the clergy of Winchester, who helped them to establish an exclusive hold on the throne for their royal branch. According to Asser, the plot to rob Æthelwulf of his throne was concocted in "the western part of Selwood", and Æthelbald's chief supporters, Eahlstan and Eanwulf, were western magnates who probably resented the favour shown by Æthelwulf to the eastern Winchester diocese, and to Swithun, who was appointed by Æthelwulf as Bishop of Winchester in 852. Æthelbald's patronage was mainly directed at Sherborne.
Asser is the sole source for the dispute between Æthelwulf and Æthelbald, which is not mentioned in the "Anglo-Saxon Chronicle", and according to Asser when Æthelwulf returned to England he agreed to divide the kingdom to avoid a civil war. Most historians state that Æthelbald kept Wessex while Æthelberht agreed to surrender the south-eastern kingdoms of Kent, Essex, Surrey and Sussex to Æthelwulf, although Simon Keynes thinks that Æthelwulf kept a degree of sovereignty. Some historians argue that it is more likely that Wessex itself was divided, with Æthelbald keeping his power base west of Selwood, Æthelwulf taking the east and Æthelberht keeping Kent. Pauline Stafford and D. P. Kirby point out that Asser implies that Judith became queen of the West Saxons in 856. Sean Miller observes that Asser complained that the "son ruled where by rightful judgment the father should have done; for the western part of the Saxon land has always been more important than the eastern", and since Kent had only been conquered thirty years previously, it did not make sense to speak of it as having always been a less important part of the kingdom.

According to Asser, at the end of his life, Æthelwulf directed that his kingdom should be divided between his two eldest sons, and this was carried out when he died on 13 January 858. Æthelbald then continued (or resumed) as king of Wessex, while Æthelberht resumed (or kept) the kingship of Kent and the south-east. Æthelwulf left a bequest to Æthelbald, Æthelred and Alfred, with the provision that whoever lived the longest was to inherit the whole; this is seen by some historians as leaving the kingship of Wessex to the survivor, but other historians dispute this and it may have been intended to provide for the younger sons. Judith's charisma as a Carolingian princess was so great that rather than lose the prestige of the connection Æthelbald then married her. The "Anglo-Saxon Chronicle" ignores the marriage, perhaps because mentioning such a prestigious connection of Alfred's older brother would have detracted from its focus on the achievements of Alfred himself. Æthelbald's marriage to his widowed stepmother was subsequently condemned by Asser as "against God's prohibition and Christian dignity, and also contrary to the practice of all pagans", although it does not appear to have aroused opposition at the time. The Frankish "Annals of St Bertin" reported the marriage without comment, and stated that when she returned to her father after Æthelbald's death, Judith was treated "with all the honour due to a queen". To her father's fury, soon afterwards she eloped with Baldwin, Count of Flanders, and their son Baldwin II married Alfred's daughter Ælfthryth.

Little is known of Æthelbald's reign and only two of his charters survive. S 1274 dated 858 is a grant by Swithun of an episcopal estate at Farnham to the king for his lifetime, and in Barbara Yorke's view it is an example of Æthelbald's confiscations of the bishop of Winchester's estates for his own use. S 326 dated 860 is a grant by Æthelbald of fourteen hides at Teffont in Wiltshire to a thegn called Osmund. Both are attested by Judith, an indication of her high status as ninth-century West Saxon kings' wives were not normally given the rank of queen and almost never witnessed charters. The marriage and attestations are evidence that Æthelbald intended the succession to pass to his own son, not his brothers. S 326 is also attested by King Æthelberht, suggesting that he was on good terms with his brother. S 1274 is the earliest surviving West Saxon charter to require a contribution to fortification work, and Nelson suggests that Judith's entourage may have been responsible for the innovation. A few years later Charles the Bald began a programme of rebuilding town walls and building new fortresses in West Francia.
No coins are known to have been issued in the name of Æthelbald. The main mints in southern England were both in Kent, at Canterbury and Rochester. They minted coins in the name of Æthelwulf until 858 and then in the name of Æthelberht. There was one mint in Wessex, probably at Southampton or Winchester, but it operated at a minimal level in the mid-ninth century and only three coins from it between 839 and 871 are known, two of Æthelwulf and one of Æthelred I, all produced by the same moneyer. The fact that the Kentish mints produced coins only for Æthelberht between 858 and 860 is evidence that Æthelbald was not his brother's overlord. Three coins of Æthelbald were regarded as genuine in the late nineteenth century, but in the 1900s they were found to be forgeries.

Æthelbald died in 860 and the "Anglo-Saxon Chronicle" gives him a reign of five years, dating the start to 855 when Æthelwulf left for Rome. Both Asser and the "Annals of St Neots" give Æthelbald a rule of two and a half years, and the "Annals" adds that he also ruled for two and a half years jointly with his father. Most modern historians date his reign as 855 to 860, but some as 858 to 860. Only the year of his death is known, but as his father died in January 858 and he ruled for two and a half years thereafter, he probably died in about July 860. He was buried at Sherborne in Dorset and he is not known to have had any children.

He was succeeded by Æthelberht, who re-united Wessex and Kent under his rule. It is not clear whether the division between Wessex and Kent had been intended to be permanent, but if so Æthelbald's early death allowed Æthelberht to reverse the division and Kent and the south-east were thereafter treated as an integral part of Wessex.

In the 890s, Bishop Asser gave the only surviving contemporary assessment of Æthelbald. Asser, who was hostile to him both because of his revolt against his father and because of his uncanonical marriage, described him as "iniquitous and grasping" and his reign as "two and a half lawless years", adding that many people attributed the rebellion "solely to arrogance on the part of King Æthelbald, because he was grasping in this affair and many other wrongdoings". Post-Conquest clerical chroniclers adopted Asser's views. William of Malmesbury wrote that "Æthelbald, who was worthless and disloyal to his father, defiled his father's marriage-bed, for after his father's death he sank so low as to marry his stepmother Judith." According to John of Worcester, "Æthelbald, in defiance of God's prohibition and Christian dignity, and even against all pagan customs, climbed into his father's marriage-bed, married Judith, daughter of Charles, king of the Franks, and held the government of the kingdom of the West Saxons without restraint for two and half years after his father's death". Roger of Wendover condemned Æthelbald in similar terms, but claimed that in 859 he repented of his error, put aside Judith and ruled thereafter "in peace and righteousness". The exception was Henry of Huntingdon, who stated that Æthelbald and Æthelberht, "young men of superlative natural quality, possessed their kingdoms very prosperously as long as they each lived. When Æthelbald, King of Wessex, had held his kingdom peacefully for five years, he was carried off by a premature death. All England lamented King Æthelbald's youth and there was great sorrow over him. And they buried him at Sherborne. After this England was conscious of what it had lost in him."

Robert Howard Hodgkin also adopted Asser's views in his 1935 "History of the Anglo-Saxons", but later historians have been more circumspect. Frank Stenton in "Anglo-Saxon England" does not give any opinion on Æthelbald, and observes that his marriage to Judith does not appear to have aroused any scandal among the churchmen of her country, while Sean Miller in his "Dictionary of National Biography" article on Æthelbald says that very little is known of his reign after his marriage, but he appears to have been on good terms with Æthelberht.



</doc>
<doc id="48587" url="https://en.wikipedia.org/wiki?curid=48587" title="Æthelberht, King of Wessex">
Æthelberht, King of Wessex

Æthelberht (or Ethelbert or Aethelberht) was the King of Wessex from 860 until his death in 865. He was the third son of King Æthelwulf and his first wife, Osburh. Æthelberht was first recorded as a witness to a charter in 854. The following year Æthelwulf went on pilgrimage to Rome and appointed his oldest surviving son, Æthelbald, as king of Wessex while Æthelberht became king of the recently conquered territory of Kent. Æthelberht may have surrendered his position to his father when he returned from pilgrimage, but resumed (or kept) the south-eastern kingship when his father died in 858. 

When Æthelbald died in 860, Æthelberht united both their territories under his rule. He did not appoint a sub-king and Wessex and Kent were fully united for the first time. He appears to have been on good terms with his younger brothers, the future kings Æthelred I and Alfred the Great. The kingdom came under attack from Viking raids during his reign, but these were minor compared with the invasions after his death. Æthelberht died in the autumn of 865 and was buried next to his brother Æthelbald at Sherborne Abbey in Dorset. He was succeeded by Æthelred.

When Æthelberht's grandfather Ecgberht became king of Wessex in 802, it must have appeared very unlikely that he would establish a lasting dynasty. For two hundred years, three families had fought for the West Saxon throne, and no son had followed his father as king. Ecgberht's nearest connection to a previous king of Wessex was as a great-great-grandson of Ingild, brother of King Ine (688–726), but he was believed to be a paternal descendant of Cerdic, the founder of the West Saxon dynasty, which made him an ætheling, a prince who had a legitimate claim to the throne. But in the ninth and tenth centuries Ecgberht's line controlled the kingdom, and all æthelings were sons of kings.

At the beginning of the ninth century, England was almost wholly under the control of the Anglo-Saxons. The Midland kingdom of Mercia dominated southern England, but their supremacy came to an end in 825 when they were decisively defeated by Ecgberht at the Battle of Ellendun. The two kingdoms became allies, which was important in the resistance to Viking attacks. In the same year Ecgberht sent his son Æthelwulf to conquer the Mercian sub-kingdom of Kent (the area of the modern county plus Essex, Surrey and Sussex) and appointed him sub-king. In 835 the Isle of Sheppey was ravaged by Vikings and in the following year they defeated Ecgberht at Carhampton in Somerset, but in 838 he was victorious over an alliance of Cornishmen and Vikings at the Battle of Hingston Down, reducing Cornwall to the status of a client kingdom. He died in 839 and was succeeded by Æthelwulf, who appointed his eldest son Æthelstan as sub-king of Kent. Æthelwulf and Ecgberht may not have intended a permanent union between Wessex and Kent as they both appointed sons as sub-kings and charters in Wessex were attested (witnessed) by West Saxon magnates, while Kentish charters were witnessed by the Kentish elite; both kings kept overall control and the sub-kings were not allowed to issue their own coinage.

Viking raids increased in the early 840s on both sides of the English Channel, and in 843 Æthelwulf was defeated by the companies of 35 Danish ships at Carhampton. In 850 Æthelstan defeated a Danish fleet off Sandwich in the first recorded naval battle in English history. In 851 Æthelwulf and his second son Æthelbald defeated the Vikings at the Battle of Aclea and, according to the "Anglo-Saxon Chronicle", "there made the greatest slaughter of a heathen raiding-army that we have heard tell of up to this present day, and there took the victory".

Charters provide the major source for Æthelberht's life and narrative accounts are very limited. The "Anglo-Saxon Chronicle" only mentions two events in his reign and these are also the only incidents related in Asser's biography of his younger brother Alfred the Great, which is mainly based on the "Chronicle" for the mid-tenth century.

Æthelberht was the third of five sons of Æthelwulf and his first wife Osburh, who died around 855. Æthelstan died in the early 850s, but the four younger brothers were successively kings of Wessex: Æthelbald from 855 to 860, Æthelberht from 860 to 865, Æthelred I from 865 to 871 and Alfred the Great from 871 to 899. Æthelberht had one sister, Æthelswith, who married King Burgred of Mercia in 853.

Æthelberht was first recorded when he attested charters in 854. In the following year Æthelwulf went on pilgrimage to Rome after appointing his eldest surviving son, Æthelbald, under-king of Wessex and Æthelberht under-king of Kent, Essex, Sussex and Surrey, appointments which suggest that his sons were to succeed to the separate kingdoms whether or not he returned to England. Æthelberht attested charters as "dux" (ealdorman) in 854 and king in 855. In 856, Æthelwulf returned to England with a new wife, Judith, daughter of Charles the Bald, king of the West Franks. Æthelbald, with the support of Eahlstan, Bishop of Sherborne, and Eanwulf, Ealdorman of Somerset, refused to give up his kingship of Wessex. Æthelwulf compromised to avoid a civil war, but historians disagree how the kingdom was divided. According to Asser, Æthelwulf was assigned the "eastern districts", and most historians assume that Æthelbald kept Wessex while Æthelberht gave up the Kent to his father; some others believe that Wessex itself was divided, with Æthelbald ruling the west and Æthelwulf the east, and Æthelberht retaining Kent.

Æthelwulf confirmed that he intended a permanent division of his kingdom as he recommended that on his death Æthelbald should be king of Wessex and Æthelberht king of Kent. This proposal was carried out when Æthelwulf died in 858. According to the "Anglo-Saxon Chronicle": "And then Æthelwulf's two sons succeeded to the kingdom: Æthelbald to the kingdom of Wessex, and Æthelberht to the kingdom of the inhabitants of Kent and to the kingdom of Essex and to Surrey and to the kingdom of Sussex". Æthelbald was later condemned by Alfred the Great's biographer, Asser, both for his rebellion against his father and because he married his father's widow, but he appears to have been on good terms with Æthelberht. In 858 Æthelbald issued a charter (S 1274) relating to land in Surrey, and thus in his brother's territory, and a charter he issued in 860 (S 326) was witnessed by Æthelberht and Judith.

Æthelberht appears to have made significant changes in personnel as a Kentish charter of 858 (S 328) was witnessed by twenty-one thegns, out of whom fourteen did not witness a surviving charter of his father. They include Eastmund, who Æthelberht later appointed ealdorman of Kent. The charter is regarded by historians as important because it clarifies the obligations of folkland. 

The separation of Wessex and Kent was soon reversed as Æthelbald died childless in 860 and Æthelberht succeeded to the whole kingdom of Wessex and Kent. Æthelred and Alfred may have been intended to succeed in Wessex, but they were too young as the preference was for adults as kings, especially when Wessex was under threat from the Vikings. During Æthelberht's rule over the whole kingdom, Wessex and its recent south-eastern conquests became a united kingdom for the first time. Unlike his father and grandfather, Æthelberht did not appoint another member of his family as under-king of Kent. A Kentish charter issued in the first year of his reign (S 327) was the first to include a full complement both of West Saxon and Kentish attesters, although he then returned to locally attested charters. The historian Simon Keynes sees this charter as 

According to the "Anglo-Saxon Chronicle", Æthelberht reigned "in good harmony and in great peace" and "in peace, love and honour". He appears to have been on good terms with his younger brothers and in a charter of 861 (S 330) he granted land to St Augustine's, Canterbury in return for the abbot's continuing loyalty to him, Æthelred and Alfred. Some historians believe that the three brothers agreed that each would succeed to the throne in turn. In two charters in 862 and 863 (S 335 and S 336) Æthelred makes grants as king of the West Saxons and Æthelberht is not mentioned. In Keynes's view, Æthelberht may have delegated some power in Wessex, perhaps in his own absence. However, a charter of Æthelberht dated December 863 (S 333) is attested by Æthelred and Alfred as "filius regis" (king's son). Æthelberht granted immunity from royal and judicial services to Sherborne church in honour of the souls of his father Æthelwulf and his brother Æthelbald. Unlike most charters, which were in Latin, this one is in Old English, and historians disagree whether this reflects a trend towards greater use of the vernacular as better suited to recording legal documents or support for Alfred's later claim that knowledge of Latin had declined disastrously when he came to the throne in 871.

Æthelberht's reign began and ended with raids by the Vikings. In 860 a Viking army sailed from the Somme to England and sacked Winchester, but they were then defeated by the men of Hampshire and Berkshire. Probably in the autumn of 864, another Viking army camped on Thanet and were promised money in return for peace, but they broke their promise and ravaged eastern Kent. These attacks were minor compared with events after Æthelberht's death, when the Vikings almost conquered England.

In the late eighth and ninth centuries the only denomination of coin produced in southern England was the silver penny. Coins were minted in an unidentified town in Wessex itself, but activity in the mid-ninth century was minimal and no Wessex coins of Æthelberht are known. Kent had mints at Canterbury and Rochester and they produced coins in the name of Æthelwulf until 858 and Æthelberht thereafter. The lack of coins in the name of Æthelbald is evidence that he did not have any status of overlordship over Æthelberht. In the early ninth century the quality of the inscription and the bust of the king on coins declined, but it revived on the Inscribed Cross penny at the end of Æthelwulf's reign and this continued under Æthelberht's, which also saw the introduction of the rare Floreate Cross design in about 862. There was a considerable increase in the number of moneyers: twelve struck Inscribed Cross coins in Æthelwulf's reign and fifty in Æthelberht's. This may have been due to a recoinage starting at the end of Æthelwulf's reign and continuing in Æthelberht's, when old coins were called in and melted down to make new ones. The silver content of his Inscribed Cross issue fell to below 50% and one penny minted in Canterbury has only 30%, but a Floreate Cross coin has 84%, perhaps indicating that it was an intended as a recoinage with higher fineness. There was also increasing standardisation of design in the coinage, reflecting greater royal control over currency and minting in the middle of the ninth century.
Æthelberht died of unknown causes in the autumn of 865. He was buried at Sherborne Abbey in Dorset beside his brother Æthelbald but the tombs had been lost by the sixteenth century. He had no known children and was succeeded by his brother Æthelred.

According to Asser, who based his account of events before 887 mainly on the "Anglo-Saxon Chronicle": "So after governing in peace, love and honour for five years, Æthelberht went the way of all flesh, to the great sorrow of his people; and he lies buried honourably beside his brother, at Sherborne." Asser's view was followed by post-Conquest historians. John of Worcester copied Asser's words, while William of Malmesbury described him as "a vigorous but kindly ruler". The 20th-century historian Alfred Smyth points out that the "Anglo-Saxon Chronicle", which was first written in Alfred the Great's reign, only recorded two events in Æthelberht's reign, the attacks on Winchester and eastern Kent, and does not associate the king personally with either of them. Smyth argues that this reflected an agenda by Alfred's propagandists to downplay the achievements of his brothers to enhance the reputation of Alfred himself.



</doc>
<doc id="48596" url="https://en.wikipedia.org/wiki?curid=48596" title="Douglas MacArthur">
Douglas MacArthur

Douglas MacArthur (January 26, 1880April 5, 1964) was an American five-star general and Field Marshal of the Philippine Army. He was Chief of Staff of the United States Army during the 1930s and played a prominent role in the Pacific theater during World War II. He received the Medal of Honor for his service in the Philippines Campaign, which made him and his father Arthur MacArthur Jr. the first father and son to be awarded the medal. He was one of only five to rise to the rank of General of the Army in the US Army, and the only one conferred the rank of field marshal in the Philippine Army.

Raised in a military family in the American Old West, MacArthur was valedictorian at the West Texas Military Academy, and First Captain at the United States Military Academy at West Point, where he graduated top of the class of 1903. During the 1914 United States occupation of Veracruz, he conducted a reconnaissance mission, for which he was nominated for the Medal of Honor. In 1917, he was promoted from major to colonel and became chief of staff of the 42nd (Rainbow) Division. In the fighting on the Western Front during World War I, he rose to the rank of brigadier general, was again nominated for a Medal of Honor, and was awarded the Distinguished Service Cross twice and the Silver Star seven times.

From 1919 to 1922, MacArthur served as Superintendent of the U.S. Military Academy at West Point, where he attempted a series of reforms. His next assignment was in the Philippines, where in 1924 he was instrumental in quelling the Philippine Scout Mutiny. In 1925, he became the Army's youngest major general. He served on the court-martial of Brigadier General Billy Mitchell and was president of the American Olympic Committee during the 1928 Summer Olympics in Amsterdam. In 1930, he became Chief of Staff of the United States Army. As such, he was involved in the expulsion of the Bonus Army protesters from Washington, D.C. in 1932, and the establishment and organization of the Civilian Conservation Corps. He retired from the US Army in 1937 to become Military Advisor to the Commonwealth Government of the Philippines.

MacArthur was recalled to active duty in 1941 as commander of United States Army Forces in the Far East. A series of disasters followed, starting with the destruction of his air forces on 8 December 1941 and the Japanese invasion of the Philippines. MacArthur's forces were soon compelled to withdraw to Bataan, where they held out until May 1942. In March 1942, MacArthur, his family and his staff left nearby Corregidor Island in PT boats and escaped to Australia, where MacArthur became Supreme Commander, Southwest Pacific Area. Upon his arrival, MacArthur gave a speech in which he famously promised "I shall return" to the Philippines. After more than two years of fighting in the Pacific, he fulfilled that promise. For his defense of the Philippines, MacArthur was awarded the Medal of Honor. He officially accepted the Surrender of Japan on 2 September 1945 aboard the , which was anchored in Tokyo Bay, and he oversaw the occupation of Japan from 1945 to 1951. As the effective ruler of Japan, he oversaw sweeping economic, political and social changes. He led the United Nations Command in the Korean War with initial success; however, the controversial invasion of North Korea provoked Chinese intervention. Following a series of major defeats, he was removed from command by President Harry S. Truman on 11 April 1951. He later became chairman of the board of Remington Rand.

A military brat, Douglas MacArthur was born 26 January 1880, at Little Rock Barracks, Little Rock, Arkansas, to Arthur MacArthur, Jr., a U.S. Army captain, and his wife, Mary Pinkney Hardy MacArthur (nicknamed "Pinky"). Arthur, Jr. was the son of Scottish-born jurist and politician Arthur MacArthur, Sr., Arthur would later receive the Medal of Honor for his actions with the Union Army in the Battle of Missionary Ridge during the American Civil War, and be promoted to the rank of lieutenant general. Pinkney came from a prominent Norfolk, Virginia, family. Two of her brothers had fought for the South in the Civil War, and refused to attend her wedding. Arthur and Pinky had three sons, of whom Douglas was the youngest, following Arthur III, born on 1 August 1876, and Malcolm, born on 17 October 1878. The family lived on a succession of Army posts in the American Old West. Conditions were primitive, and Malcolm died of measles in 1883. In his memoir, "Reminiscences", MacArthur wrote "I learned to ride and shoot even before I could read or write—indeed, almost before I could walk and talk."
MacArthur's time on the frontier ended in July 1889 when the family moved to Washington, D.C., where he attended the Force Public School. His father was posted to San Antonio, Texas, in September 1893. While there MacArthur attended the West Texas Military Academy, where he was awarded the gold medal for "scholarship and deportment". He also participated on the school tennis team, and played quarterback on the school football team and shortstop on its baseball team. He was named valedictorian, with a final year average of 97.33 out of 100. MacArthur's father and grandfather unsuccessfully sought to secure Douglas a presidential appointment to the United States Military Academy at West Point, first from President Grover Cleveland and then from President William McKinley. After these two rejections, he was given coaching and private tutoring by Milwaukee high school teacher Gertrude Hull. He then passed the examination for an appointment from Congressman Theobald Otjen, scoring 93.3 on the test. He later wrote: "It was a lesson I never forgot. Preparedness is the key to success and victory."

MacArthur entered West Point on 13 June 1899, and his mother also moved there, to a suite at Craney's Hotel, which overlooked the grounds of the Academy. Hazing was widespread at West Point at this time, and MacArthur and his classmate Ulysses S. Grant III were singled out for special attention by southern cadets as sons of generals with mothers living at Craney's. When Cadet Oscar Booz left West Point after being hazed and subsequently died of tuberculosis, there was a congressional inquiry. MacArthur was called to appear before a special Congressional committee in 1901, where he testified against cadets implicated in hazing, but downplayed his own hazing even though the other cadets gave the full story to the committee. Congress subsequently outlawed acts "of a harassing, tyrannical, abusive, shameful, insulting or humiliating nature", although hazing continued. MacArthur was a corporal in Company B in his second year, a first sergeant in Company A in his third year and First Captain in his final year. He played left field for the baseball team and academically earned 2424.12 merits out of a possible 2470.00 or 98.14, which was the third highest score ever recorded. He graduated first in his 93-man class on 11 June 1903. At the time it was customary for the top-ranking cadets to be commissioned into the United States Army Corps of Engineers, so MacArthur was commissioned as a second lieutenant in that corps.

MacArthur spent his graduation furlough with his parents at Fort Mason, California, where his father, now a major general, was serving as commander of the Department of the Pacific. Afterward, he joined the 3rd Engineer Battalion, which departed for the Philippines in October 1903. MacArthur was sent to Iloilo, where he supervised the construction of a wharf at Camp Jossman. He went on to conduct surveys at Tacloban City, Calbayog City and Cebu City. In November 1903, while working on Guimaras, he was ambushed by a pair of Filipino brigands or guerrillas; he shot and killed both with his pistol. He was promoted to first lieutenant in Manila in April 1904. In October 1904, his tour of duty was cut short when he contracted malaria and dhobi itch during a survey on Bataan. He returned to San Francisco, where he was assigned to the California Debris Commission. In July 1905, he became chief engineer of the Division of the Pacific.

In October 1905, MacArthur received orders to proceed to Tokyo for appointment as aide-de-camp to his father. A man who knew the MacArthurs at this time wrote that: "Arthur MacArthur was the most flamboyantly egotistical man I had ever seen, until I met his son." They inspected Japanese military bases at Nagasaki, Kobe and Kyoto, then headed to India via Shanghai, Hong Kong, Java and Singapore, reaching Calcutta in January 1906. In India, they visited Madras, Tuticorin, Quetta, Karachi, the Northwest Frontier and the Khyber Pass. They then sailed to China via Bangkok and Saigon, and toured Canton, Tsingtao, Peking, Tientsin, Hankow and Shanghai before returning to Japan in June. The next month they returned to the United States, where Arthur MacArthur resumed his duties at Fort Mason, still with Douglas as his aide. In September, Douglas received orders to report to the 2nd Engineer Battalion at the Washington Barracks and enroll in the Engineer School. While there he also served as "an aide to assist at White House functions" at the request of President Theodore Roosevelt.

In August 1907, MacArthur was sent to the engineer district office in Milwaukee, where his parents were living. In April 1908, he was posted to Fort Leavenworth, where he was given his first command, Company K, 3rd Engineer Battalion. He became battalion adjutant in 1909 and then engineer officer at Fort Leavenworth in 1910. MacArthur was promoted to captain in February 1911 and was appointed as head of the Military Engineering Department and the Field Engineer School. He participated in exercises at San Antonio, Texas, with the Maneuver Division in 1911 and served in Panama on detached duty in January and February 1912. The sudden death of their father on 5 September 1912 brought Douglas and his brother Arthur back to Milwaukee to care for their mother, whose health had deteriorated. MacArthur requested a transfer to Washington, D.C. so his mother could be near Johns Hopkins Hospital. Army Chief of Staff, Major General Leonard Wood, took up the matter with Secretary of War Henry L. Stimson, who arranged for MacArthur to be posted to the Office of the Chief of Staff in 1912.

On 21 April 1914, President Woodrow Wilson ordered the occupation of Veracruz. MacArthur joined the headquarters staff that was sent to the area, arriving on 1 May 1914. He realized that the logistic support of an advance from Veracruz would require the use of the railroad. Finding plenty of railroad cars in Veracruz but no locomotives, MacArthur set out to verify a report that there were a number of locomotives in Alvarado, Veracruz. For $150 in gold, he acquired a handcar and the services of three Mexicans, whom he disarmed. MacArthur and his party located five engines in Alvarado, two of which were only switchers, but the other three locomotives were exactly what was required. On the way back to Veracruz, his party was set upon by five armed men. The party made a run for it and outdistanced all but two of the armed men, whom MacArthur shot. Soon after, they were attacked by a group of about fifteen horsemen. MacArthur took three bullet holes in his clothes but was unharmed. One of his companions was lightly wounded before the horsemen finally decided to retire after MacArthur shot four of them. Further on, the party was attacked a third time by three mounted men. MacArthur received another bullet hole in his shirt, but his men, using their handcar, managed to outrun all but one of their attackers. MacArthur shot both that man and his horse, and the party had to remove the horse's carcass from the track before proceeding.

A fellow officer wrote to Wood recommending that MacArthur's name be put forward for the Medal of Honor. Wood did so, and Chief of Staff Hugh L. Scott convened a board to consider the award. The board questioned "the advisability of this enterprise having been undertaken without the knowledge of the commanding general on the ground". This was Brigadier General Frederick Funston, a Medal of Honor recipient himself, who considered awarding the medal to MacArthur "entirely appropriate and justifiable". However the board feared that "to bestow the award recommended might encourage any other staff officer, under similar conditions, to ignore the local commander, possibly interfering with the latter's plans"; consequently, MacArthur received no award at all.

MacArthur returned to the War Department, where he was promoted to major on 11 December 1915. In June 1916, he was assigned as head of the Bureau of Information at the office of the Secretary of War, Newton D. Baker. MacArthur has since been regarded as the Army's first press officer. Following the declaration of war on Germany on 6 April 1917, Baker and MacArthur secured an agreement from President Wilson for the use of the National Guard on the Western Front. MacArthur suggested sending first a division organized from units of different states, so as to avoid the appearance of favoritism toward any particular state. Baker approved the creation of this formation, which became the 42nd ("Rainbow") Division, and appointed Major General William A. Mann, the head of the National Guard Bureau, as its commander; MacArthur was its chief of staff, with the rank of colonel. At MacArthur's request, this commission was in the infantry rather than the engineers.

The 42nd Division was assembled in August and September 1917 at Camp Mills, New York, where its training emphasized open-field combat rather than trench warfare. It sailed in a convoy from Hoboken, New Jersey, for France on 18 October 1917. On 19 December, Mann was replaced as division commander by Major General Charles T. Menoher.

The 42nd Division entered the line in the quiet Lunéville sector in February 1918. On 26 February, MacArthur and Captain Thomas T. Handy accompanied a French trench raid in which MacArthur assisted in the capture of a number of German prisoners. The commander of the French VII Corps, Major General Georges de Bazelaire, decorated MacArthur with the "Croix de Guerre". Menoher recommended MacArthur for a Silver Star, which he later received. The Silver Star Medal was not instituted until 8 August 1932, but small Silver Citation Stars were authorized to be worn on the campaign ribbons of those cited in orders for gallantry, similar to the British mention in despatches. When the Silver Star Medal was instituted, it was retroactively awarded to those who had been awarded Silver Citation Stars. On 9 March, the 42nd Division launched three raids of its own on German trenches in the Salient du Feys. MacArthur accompanied a company of the 168th Infantry. This time, his leadership was rewarded with the Distinguished Service Cross. A few days later, MacArthur, who was strict about his men carrying their gas masks but often neglected to bring his own, was gassed. He recovered in time to show Secretary Baker around the area on 19 March.

MacArthur was promoted to brigadier general on 26 June. In late June, the 42nd Division was shifted to Châlons-en-Champagne to oppose the impending German Champagne-Marne Offensive. "Général d'Armée" Henri Gouraud of the French Fourth Army elected to meet the attack with a defense in depth, holding the front line area as thinly as possible and meeting the German attack on his second line of defense. His plan succeeded, and MacArthur was awarded a second Silver Star. The 42nd Division participated in the subsequent Allied counter-offensive, and MacArthur was awarded a third Silver Star on 29 July. Two days later, Menoher relieved Brigadier General Robert A. Brown of the 84th Infantry Brigade of his command, and replaced him with MacArthur. Hearing reports that the enemy had withdrawn, MacArthur went forward on 2 August to see for himself. He later wrote: 

MacArthur reported back to Menoher and Lieutenant General Hunter Liggett that the Germans had indeed withdrawn, and was awarded a fourth Silver Star. He was also awarded a second "Croix de guerre" and made a "commandeur" of the "Légion d'honneur".

The 42nd Division earned a few weeks rest, returning to the line for the Battle of Saint-Mihiel on 12 September 1918. The Allied advance proceeded rapidly and MacArthur was awarded a fifth Silver Star for his leadership of the 84th Infantry Brigade. He received a sixth Silver Star for his participation in a raid on the night of 25–26 September. The 42nd Division was relieved on the night of 30 September and moved to the Argonne sector where it relieved the 1st Division on the night of 11 October. On a reconnaissance the next day, MacArthur was gassed again, earning a second Wound Chevron.
The 42nd Division's participation in the Meuse-Argonne Offensive began on 14 October when it attacked with both brigades. That evening, a conference was called to discuss the attack, during which Charles Pelot Summerall, commander of the First Infantry Division and V Corps, telephoned and demanded that Châtillon be taken by 18:00 the next evening. An aerial photograph had been obtained that showed a gap in the German barbed wire to the northeast of Châtillon. Lieutenant Colonel Walter E. Bare—the commander of the 167th Infantry—proposed an attack from that direction, where the defenses seemed least imposing, covered by a machine-gun barrage. MacArthur adopted this plan. He was wounded, but not severely, while verifying the existence of the gap in the barbed wire.

Summerall nominated MacArthur for the Medal of Honor and promotion to major general, but he received neither. Instead he was awarded a second Distinguished Service Cross. The 42nd Division returned to the line for the last time on the night of 4–5 November 1918. In the final advance on Sedan. MacArthur later wrote that this operation "narrowly missed being one of the great tragedies of American history". An order to disregard unit boundaries led to units crossing into each other's zones. In the resulting chaos, MacArthur was taken prisoner by men of the 1st Division, who mistook him for a German general. His performance in the attack on the Meuse heights led to his being awarded a seventh Silver Star. On 10 November, a day before the armistice that ended the fighting, MacArthur was appointed commander of the 42nd Division. For his service as chief of staff and commander of the 84th Infantry Brigade, he was awarded the Distinguished Service Medal.

His period in command was brief, for on 22 November he, like other brigadier generals, was replaced, and returned to the 84th Infantry Brigade. The 42nd Division was chosen to participate in the occupation of the Rhineland, occupying the Ahrweiler district. In April 1919, they entrained for Brest and Saint-Nazaire, where they boarded ships to return to the United States. MacArthur traveled on the ocean liner , which reached New York on 25 April 1919.

In 1919, MacArthur became Superintendent of the U.S. Military Academy at West Point, which Chief of Staff Peyton March felt had become out of date in many respects and was much in need of reform. Accepting the post allowed MacArthur to retain his rank of brigadier general, instead of being reduced to his substantive rank of major like many of his contemporaries. When MacArthur moved into the superintendent's house with his mother in June 1919, he became the youngest superintendent since Sylvanus Thayer in 1817. However, whereas Thayer had faced opposition from outside the Army, MacArthur had to overcome resistance from graduates and the academic board.
MacArthur's vision of what was required of an officer came not just from his recent experience of combat in France but also from that of the occupation of the Rhineland in Germany. The military government of the Rhineland had required the Army to deal with political, economic and social problems but he had found that many West Point graduates had little or no knowledge of fields outside of the military sciences. During the war, West Point had been reduced to an officer candidate school, with five classes graduated in two years. Cadet and staff morale was low and hazing "at an all-time peak of viciousness". MacArthur's first change turned out to be the easiest. Congress had set the length of the course at three years. MacArthur was able to get the four-year course restored.

During the debate over the length of the course, "The New York Times" brought up the issue of the cloistered and undemocratic nature of student life at West Point. Also, starting with Harvard University in 1869, civilian universities had begun grading students on academic performance alone, but West Point had retained the old "whole man" concept of education. MacArthur sought to modernize the system, expanding the concept of military character to include bearing, leadership, efficiency and athletic performance. He formalized the hitherto unwritten Cadet Honor Code in 1922 when he formed the Cadet Honor Committee to review alleged code violations. Elected by the cadets themselves, it had no authority to punish, but acted as a kind of grand jury, reporting offenses to the commandant. MacArthur attempted to end hazing by using officers rather than upperclassmen to train the plebes.

Instead of the traditional summer camp at Fort Clinton, MacArthur had the cadets trained to use modern weapons by regular army sergeants at Fort Dix; they then marched back to West Point with full packs. He attempted to modernize the curriculum by adding liberal arts, government and economics courses, but encountered strong resistance from the Academic Board. In Military Art classes, the study of the campaigns of the American Civil War was replaced with the study of those of World War I. In History class, more emphasis was placed on the Far East. MacArthur expanded the sports program, increasing the number of intramural sports and requiring all cadets to participate. He allowed upper class cadets to leave the reservation, and sanctioned a cadet newspaper, "The Brag", forerunner of today's "West Pointer". He also permitted cadets to travel to watch their football team play, and gave them an allowance of $5 ($ in modern dollars) a month. Professors and alumni alike protested these radical moves. Most of MacArthur's West Point reforms were soon discarded but, in the ensuing years, his ideas became accepted and his innovations were gradually restored.

MacArthur became romantically involved with socialite and multi-millionaire heiress Louise Cromwell Brooks. They were married at her family's villa in Palm Beach, Florida on 14 February 1922. Rumors circulated that General Pershing, who had also courted Louise, had threatened to exile them to the Philippines if they were married. Pershing denied this as "all damn poppycock". In October 1922, MacArthur left West Point and sailed to the Philippines with Louise and her two children, Walter and Louise, to assume command of the Military District of Manila. MacArthur was fond of the children, and spent much of his free time with them.

The revolts in the Philippines had been suppressed, the islands were peaceful now, and in the wake of the Washington Naval Treaty, the garrison was being reduced. MacArthur's friendships with Filipinos like Manuel Quezon offended some people. "The old idea of colonial exploitation", he later conceded, "still had its vigorous supporters." In February and March 1923 MacArthur returned to Washington to see his mother, who was ill from a heart ailment. She recovered, but it was the last time he saw his brother Arthur, who died suddenly from appendicitis in December 1923. In June 1923, MacArthur assumed command of the 23rd Infantry Brigade of the Philippine Division. On 7 July 1924, he was informed that a mutiny had broken out amongst the Philippine Scouts over grievances concerning pay and allowances. Over 200 were arrested and there were fears of an insurrection. MacArthur was able to calm the situation, but his subsequent efforts to improve the salaries of Filipino troops were frustrated by financial stringency and racial prejudice. On 17 January 1925, at the age of 44, he was promoted, becoming the Army's youngest major general.

Returning to the U.S., MacArthur took command of the IV Corps Area, based at Fort McPherson in Atlanta, Georgia, on 2 May 1925. However, he encountered southern prejudice because he was the son of a Union Army officer, and requested to be relieved. A few months later, he assumed command of the III Corps area, based at Fort McHenry in Baltimore, Maryland, which allowed MacArthur and Louise to move to her Rainbow Hill estate near Garrison, Maryland. However, this relocation also led to what he later described as "one of the most distasteful orders I ever received": a direction to serve on the court-martial of Brigadier General Billy Mitchell. MacArthur was the youngest of the thirteen judges, none of whom had aviation experience. Three of them, including Summerall, the president of the court, were removed when defense challenges revealed bias against Mitchell. Despite MacArthur's claim that he had voted to acquit, Mitchell was found guilty as charged and convicted. MacArthur felt "that a senior officer should not be silenced for being at variance with his superiors in rank and with accepted doctrine".

In 1927, MacArthur and Louise separated, and she moved to New York City. In August that year, William C. Prout—the president of the American Olympic Committee—died suddenly and the committee elected MacArthur as their new president. His main task was to prepare the U.S. team for the 1928 Summer Olympics in Amsterdam. MacArthur saw the team as representatives of the United States, and its task was to win medals. "We have not come 3,000 miles", he told them, "just to lose gracefully." The Americans had a successful meet, winning the most medals and setting various records. Upon returning to the U.S., MacArthur received orders to assume command of the Philippine Department. In 1929, while he was in Manila, Louise obtained a divorce, ostensibly on the grounds of "failure to provide". In view of Louise's great wealth, William Manchester described this legal fiction as "preposterous".

By 1930, MacArthur was 50 and still the youngest and best known of the U.S. Army's major generals. He left the Philippines on 19 September 1930 and for a brief time was in command of the IX Corps Area in San Francisco. On 21 November, he was sworn in as Chief of Staff of the United States Army, with the rank of general. While in Washington, he would ride home each day to have lunch with his mother. At his desk, he would wear a Japanese ceremonial kimono, cool himself with an oriental fan, and smoke cigarettes in a jeweled cigarette holder. In the evenings, he liked to read military history books. About this time, he began referring to himself as "MacArthur". He had already hired a public relations staff to promote his image with the American public, together with a set of ideas he was known to favor, namely: a belief that America needed a strongman leader to deal with the possibility that Communists might lead all of the great masses of unemployed into a revolution; that America's destiny was in the Asia-Pacific region; and a strong hostility to the British Empire. One contemporary described MacArthur as the greatest actor to ever serve as a U.S Army general while another wrote that MacArthur had a court rather than a staff.

The onset of the Great Depression forced Congress to make cuts in the Army's personnel and budget. Some 53 bases were closed, but MacArthur managed to prevent attempts to reduce the number of regular officers from 12,000 to 10,000. MacArthur's main programs included the development of new mobilization plans. He grouped the nine corps areas together under four armies, which were charged with responsibility for training and frontier defense. He also negotiated the MacArthur-Pratt agreement with the Chief of Naval Operations, Admiral William V. Pratt. This was the first of a series of inter-service agreements over the following decades that defined the responsibilities of the different services with respect to aviation. This agreement placed coastal air defense under the Army. In March 1935, MacArthur activated a centralized air command, General Headquarters Air Force, under Major General Frank M. Andrews.
One of MacArthur's most controversial acts came in 1932, when the "Bonus Army" of veterans converged on Washington. He sent tents and camp equipment to the demonstrators, along with mobile kitchens, until an outburst in Congress caused the kitchens to be withdrawn. MacArthur was concerned that the demonstration had been taken over by communists and pacifists but the General Staff's intelligence division reported that only three of the march's 26 key leaders were communists. MacArthur went over contingency plans for civil disorder in the capital. Mechanized equipment was brought to Fort Myer, where anti-riot training was conducted.

On 28 July 1932, in a clash with the District police, two veterans were shot, and later died. President Herbert Hoover ordered MacArthur to "surround the affected area and clear it without delay". MacArthur brought up troops and tanks and, against the advice of Major Dwight D. Eisenhower, decided to accompany the troops, although he was not in charge of the operation. The troops advanced with bayonets and sabers drawn under a shower of bricks and rocks, but no shots were fired. In less than four hours, they cleared the Bonus Army's campground using tear gas. The gas canisters started a number of fires, causing the only death during the riots. While not as violent as other anti-riot operations, it was nevertheless a public relations disaster. However, the defeat of the "Bonus Army" while unpopular with the American people at large, did make MacArthur into the hero of the more right-wing elements in the Republican Party who believed that the general had saved America from a communist revolution in 1932.
In 1934, MacArthur sued journalists Drew Pearson and Robert S. Allen for defamation after they described his treatment of the Bonus marchers as "unwarranted, unnecessary, insubordinate, harsh and brutal". In turn, they threatened to call Isabel Rosario Cooper as a witness. MacArthur had met Isabel, a Eurasian woman, while in the Philippines, and she had become his mistress. MacArthur was forced to settle out of court, secretly paying Pearson $15,000.

In the 1932 presidential election, Herbert Hoover was defeated by Franklin D. Roosevelt. MacArthur and Roosevelt had worked together before World War I and had remained friends despite their political differences. MacArthur supported the New Deal through the Army's operation of the Civilian Conservation Corps. He ensured that detailed plans were drawn up for its employment and decentralized its administration to the corps areas, which became an important factor in the program's success. MacArthur's support for a strong military, and his public criticism of pacifism and isolationism, made him unpopular with the Roosevelt administration.

Perhaps the most incendiary exchange between Roosevelt and MacArthur occurred over an administration proposal to cut 51% of the Army's budget. In response, MacArthur lectured Roosevelt that "when we lost the next war, and an American boy, lying in the mud with an enemy bayonet through his belly and an enemy foot on his dying throat, spat out his last curse, I wanted the name not to be MacArthur, but Roosevelt". In response, Roosevelt yelled, "you must not talk that way to the President!" MacArthur offered to resign, but Roosevelt refused his request, and MacArthur then staggered out of the White House and vomited on the front steps.

In spite of such exchanges, MacArthur was extended an extra year as chief of staff, and ended his tour in October 1935. For his service as chief of staff, he was awarded a second Distinguished Service Medal. He was retroactively awarded two Purple Hearts for his World War I service, a decoration that he authorized in 1932 based loosely on the defunct Military Badge of Merit. MacArthur also insisted on being the first recipient of the Purple Heart, which he had engraved with "#1".

When the Commonwealth of the Philippines achieved semi-independent status in 1935, President of the Philippines Manuel Quezon asked MacArthur to supervise the creation of a Philippine Army. Quezon and MacArthur had been personal friends since the latter's father had been Governor-General of the Philippines, 35 years earlier. With President Roosevelt's approval, MacArthur accepted the assignment. It was agreed that MacArthur would receive the rank of field marshal, with its salary and allowances, in addition to his major general's salary as Military Advisor to the Commonwealth Government of the Philippines. It would be his fifth tour in the Far East. MacArthur sailed from San Francisco on the in October 1935, accompanied by his mother and sister-in-law. He brought Eisenhower and Major James B. Ord along as his assistants. Another passenger on the "President Hoover" was Jean Marie Faircloth, an unmarried 37-year-old socialite. Over the next two years, MacArthur and Faircloth were frequently seen together. His mother became gravely ill during the voyage and died in Manila on 3 December 1935.
President Quezon officially conferred the title of field marshal on MacArthur in a ceremony at Malacañan Palace on 24 August 1936, and presented him with a gold baton and a unique uniform. The Philippine Army was formed from conscription. Training was conducted by a regular cadre, and the Philippine Military Academy was created along the lines of West Point to train officers. MacArthur and Eisenhower found that few of the training camps had been constructed and the first group of 20,000 trainees did not report until early 1937. Equipment and weapons were "more or less obsolete" American cast offs, and the budget was completely inadequate. MacArthur's requests for equipment fell on deaf ears, although MacArthur and his naval advisor, Lieutenant Colonel Sidney L. Huff, persuaded the Navy to initiate the development of the PT boat. Much hope was placed in the Philippine Army Air Corps, but the first squadron was not organized until 1939.

MacArthur married Jean Faircloth in a civil ceremony on 30 April 1937. Their marriage produced a son, Arthur MacArthur IV, who was born in Manila on 21 February 1938. On 31 December 1937, MacArthur officially retired from the Army. He ceased to represent the U.S. as military adviser to the government, but remained as Quezon's adviser in a civilian capacity. Eisenhower returned to the U.S., and was replaced as MacArthur's chief of staff by Lieutenant Colonel Richard K. Sutherland, while Richard J. Marshall became deputy chief of staff.

On 26 July 1941, Roosevelt federalized the Philippine Army, recalled MacArthur to active duty in the U.S. Army as a major general, and named him commander of U.S. Army Forces in the Far East (USAFFE). MacArthur was promoted to lieutenant general the following day, and then to general on 20 December. On 31 July 1941, the Philippine Department had 22,000 troops assigned, 12,000 of whom were Philippine Scouts. The main component was the Philippine Division, under the command of Major General Jonathan M. Wainwright. The initial American plan for the defense of the Philippines called for the main body of the troops to retreat to the Bataan peninsula in Manila Bay to hold out against the Japanese until a relief force could arrive. MacArthur changed this plan to one of attempting to hold all of Luzon and using B-17 Flying Fortresses to sink Japanese ships that approached the islands. MacArthur persuaded the decision-makers in Washington that his plans represented the best deterrent to prevent Japan from choosing war and of winning a war if worse did come to worse.

Between July and December 1941, the garrison received 8,500 reinforcements. After years of parsimony, much equipment was shipped. By November, a backlog of 1,100,000 shipping tons of equipment intended for the Philippines had accumulated in U.S. ports and depots awaiting vessels. In addition, the Navy intercept station in the islands, known as Station CAST, had an ultra secret Purple cipher machine, which decrypted Japanese diplomatic messages, and partial codebooks for the latest JN-25 naval code. Station CAST sent MacArthur its entire output, via Sutherland, the only officer on his staff authorized to see it.

At 03:30 local time on 8 December 1941 (about 09:00 on 7 December in Hawaii), Sutherland learned of the attack on Pearl Harbor and informed MacArthur. At 05:30, the Chief of Staff of the U.S. Army, General George Marshall, ordered MacArthur to execute the existing war plan, Rainbow Five. MacArthur did nothing. On three occasions, the commander of the Far East Air Force, Major General Lewis H. Brereton, requested permission to attack Japanese bases in Formosa, in accordance with prewar intentions, but was denied by Sutherland. Not until 11:00 did Brereton speak with MacArthur about it, and obtained permission. MacArthur later denied having the conversation. At 12:30, nine hours after the attack on Pearl Harbor, aircraft of Japan's 11th Air Fleet achieved complete tactical surprise when they attacked Clark Field and the nearby fighter base at Iba Field, and destroyed or disabled 18 of Far East Air Force's 35 B-17s, 53 of its 107 P-40s, three P-35s, and more than 25 other aircraft. Most were destroyed on the ground. Substantial damage was done to the bases, and casualties totaled 80 killed and 150 wounded. What was left of the Far East Air Force was all but destroyed over the next few days.
MacArthur attempted to slow the Japanese advance with an initial defense against the Japanese landings. MacArthur's plan for holding all of Luzon against the Japanese collapsed as it spread out the American-Filipino forces too thin. However, he reconsidered his confidence in the ability of his Filipino troops after the Japanese landing force made a rapid advance after landing at Lingayen Gulf on 21 December, and ordered a retreat to Bataan. Within two days of the Japanese landing at Lingayen Gulf, MacArthur had reverted to pre-July 1941 plan of attempting to hold only Bataan while waiting for a relief force to come. Most of the American and some of the Filipino troops were able to retreat back to Baatan, but without most of their supplies, which were abandoned in the confusion. Manila was declared an open city at midnight on 24 December, without any consultation with Admiral Thomas C. Hart, commanding the Asiatic Fleet, forcing the Navy to destroy considerable amounts of valuable materiel.

On the evening of 24 December, MacArthur moved his headquarters to the island fortress of Corregidor in Manila Bay arriving at 21:30, with his headquarters reporting to Washington as being open on the 25th. A series of air raids by the Japanese destroyed all the exposed structures on the island and USAFFE headquarters was moved into the Malinta Tunnel. Later, most of the headquarters moved to Bataan, leaving only the nucleus with MacArthur. The troops on Bataan knew that they had been written off but continued to fight. Some blamed Roosevelt and MacArthur for their predicament. A ballad sung to the tune of "The Battle Hymn of the Republic" called him "Dugout Doug". However, most clung to the belief that somehow MacArthur "would reach down and pull something out of his hat".

On 1 January 1942, MacArthur accepted $500,000 from President Quezon of the Philippines as payment for his pre-war service. MacArthur's staff members also received payments: $75,000 for Sutherland, $45,000 for Richard Marshall, and $20,000 for Huff. Eisenhower—after being appointed Supreme Commander Allied Expeditionary Force (AEF)—was also offered money by Quezon, but declined. These payments were known only to a few in Manila and Washington, including President Roosevelt and Secretary of War Henry L. Stimson, until they were made public by historian Carol Petillo in 1979. While the payments had been fully legal, the revelation tarnished MacArthur's reputation.

In February 1942, as Japanese forces tightened their grip on the Philippines, President Roosevelt ordered MacArthur to relocate to Australia. On the night of 12 March 1942, MacArthur and a select group that included his wife Jean, son Arthur, and Arthur's Cantonese "amah", Ah Cheu, fled Corregidor. MacArthur and his party reached Del Monte Airfield on Mindanao, where B-17s picked them up, and flew them to Australia. His famous speech, in which he said, "I came through and I shall return", was first made on Terowie railway station in South Australia, on 20 March. Washington asked MacArthur to amend his promise to "We shall return". He ignored the request.

Bataan surrendered on 9 April, and Corregidor on 6 May. George Marshall decided that MacArthur would be awarded the Medal of Honor, a decoration for which he had twice previously been nominated, "to offset any propaganda by the enemy directed at his leaving his command". Eisenhower pointed out that MacArthur had not actually performed any acts of valor as required by law, but Marshall cited the 1927 award of the medal to Charles Lindbergh as a precedent. Special legislation had been passed to authorize Lindbergh's medal, but while similar legislation was introduced authorizing the medal for MacArthur by Congressmen J. Parnell Thomas and James E. Van Zandt, Marshall felt strongly that a serving general should receive the medal from the President and the War Department, expressing that the recognition "would mean more" if the gallantry criteria were not waived by a bill of relief.

Marshall ordered Sutherland to recommend the award, and authored the citation himself. Ironically, this also meant that it violated the governing statute, as it could only be considered lawful so long as material requirements were waived by Congress, such as the unmet requirement to perform conspicuous gallantry "above and beyond the call of duty." Marshall admitted the defect to the Secretary of War, acknowledging that "there is no specific act of General MacArthur's to justify the award of the Medal of Honor under a literal interpretation of the statutes." Similarly, when the Army's Adjutant General reviewed the case in 1945, he determined that "authority for [MacArthur's] award is questionable under strict interpretation of regulations."

MacArthur had been nominated for the award twice before and understood that it was for leadership and not gallantry. He expressed the sentiment that "this award was intended not so much for me personally as it is a recognition of the indomitable courage of the gallant army which it was my honor to command". Arthur and Douglas MacArthur thus became the first father and son to be awarded the Medal of Honor. They remained the only pair until 2001, when Theodore Roosevelt was posthumously awarded for his service during the Spanish–American War, Theodore Roosevelt, Jr. having received one posthumously for his service during World War II. MacArthur's citation, written by Marshall, read:
As the symbol of the forces resisting the Japanese, MacArthur received many other accolades. The Native American tribes of the Southwest chose him as a "Chief of Chiefs", which he acknowledged as from "my oldest friends, the companions of my boyhood days on the Western frontier". He was touched when he was named Father of the Year for 1942, and wrote to the National Father's Day Committee that:

On 18 April 1942, MacArthur was appointed Supreme Commander of Allied Forces in the Southwest Pacific Area (SWPA). Lieutenant General George Brett became Commander, Allied Air Forces, and Vice Admiral Herbert F. Leary became Commander, Allied Naval Forces. Since the bulk of land forces in the theater were Australian, George Marshall insisted an Australian be appointed as Commander, Allied Land Forces, and the job went to General Sir Thomas Blamey. Although predominantly Australian and American, MacArthur's command also included small numbers of personnel from the Netherlands East Indies, the United Kingdom, and other countries.

MacArthur established a close relationship with the Prime Minister of Australia, John Curtin, and was probably the second most-powerful person in the country after the prime minister, although many Australians resented MacArthur as a foreign general who had been imposed upon them. MacArthur had little confidence in Brett's abilities as commander of Allied Air Forces, and in August 1942 selected Major General George C. Kenney to replace him. Kenney's application of air power in support of Blamey's troops would prove crucial.
The staff of MacArthur's General Headquarters (GHQ) was built around the nucleus that had escaped from the Philippines with him, who became known as the "Bataan Gang". Though Roosevelt and George Marshall pressed for Dutch and Australian officers to be assigned to GHQ, the heads of all the staff divisions were American and such officers of other nationalities as were assigned served under them. Initially located in Melbourne, GHQ moved to Brisbane—the northernmost city in Australia with the necessary communications facilities—in July 1942, occupying the Australian Mutual Provident Society building (renamed after the war as MacArthur Chambers).

MacArthur formed his own signals intelligence organization, known as the Central Bureau, from Australian intelligence units and American cryptanalysts who had escaped from the Philippines. This unit forwarded Ultra information to Willoughby for analysis. After a press release revealed details of the Japanese naval dispositions during the Battle of the Coral Sea, at which a Japanese attempt to capture Port Moresby was turned back, Roosevelt ordered that censorship be imposed in Australia, and the Advisory War Council granted GHQ censorship authority over the Australian press. Australian newspapers were restricted to what was reported in the daily GHQ communiqué. Veteran correspondents considered the communiqués, which MacArthur drafted personally, "a total farce" and "Alice-in-Wonderland information handed out at high level".

Anticipating that the Japanese would strike at Port Moresby again, the garrison was strengthened and MacArthur ordered the establishment of new bases at Merauke and Milne Bay to cover its flanks. The Battle of Midway in June 1942 led to consideration of a limited offensive in the Pacific. MacArthur's proposal for an attack on the Japanese base at Rabaul met with objections from the Navy, which favored a less ambitious approach, and objected to an Army general being in command of what would be an amphibious operation. The resulting compromise called for a three-stage advance. The first stage, the seizure of the Tulagi area, would be conducted by the Pacific Ocean Areas, under Admiral Chester W. Nimitz. The later stages would be under MacArthur's command.
The Japanese struck first, landing at Buna in July, and at Milne Bay in August. The Australians repulsed the Japanese at Milne Bay, but a series of defeats in the Kokoda Track campaign had a depressing effect back in Australia. On 30 August, MacArthur radioed Washington that unless action was taken, New Guinea Force would be overwhelmed. He sent Blamey to Port Moresby to take personal command. Having committed all available Australian troops, MacArthur decided to send American forces. The 32nd Infantry Division, a poorly trained National Guard division, was selected. A series of embarrassing reverses in the Battle of Buna–Gona led to outspoken criticism of the American troops by the Australians. MacArthur then ordered Lieutenant General Robert L. Eichelberger to assume command of the Americans, and "take Buna, or not come back alive".

MacArthur moved the advanced echelon of GHQ to Port Moresby on 6 November 1942. After Buna finally fell on 3 January 1943, MacArthur awarded the Distinguished Service Cross to twelve officers for "precise execution of operations". This use of the country's second highest award aroused resentment, because while some, like Eichelberger and George Alan Vasey, had fought in the field, others, like Sutherland and Willoughby, had not. For his part, MacArthur was awarded his third Distinguished Service Medal, and the Australian government had him appointed an honorary Knight Grand Cross of the British Order of the Bath.

At the Pacific Military Conference in March 1943, the Joint Chiefs of Staff approved MacArthur's plan for Operation Cartwheel, the advance on Rabaul. MacArthur explained his strategy:

In New Guinea, a country without roads, large-scale transportation of men and materiel would have to be accomplished by aircraft or ships. A multi-pronged approach was employed to solve this problem. Disassembled landing craft were shipped to Australia, where they were assembled in Cairns. The range of these small landing craft was to be greatly extended by the landing ships of the VII Amphibious Force, which began arriving in late 1942, and formed part of the newly formed Seventh Fleet. Since the Seventh Fleet had no aircraft carriers, the range of naval operations was limited by that of the fighter aircraft of the Fifth Air Force.

Lieutenant General Walter Krueger's Sixth Army headquarters arrived in SWPA in early 1943 but MacArthur had only three American divisions, and they were tired and depleted from the fighting at Battle of Buna–Gona and Battle of Guadalcanal. As a result, "it became obvious that any military offensive in the South-West Pacific in 1943 would have to be carried out mainly by the Australian Army". The offensive began with the landing at Lae by the Australian 9th Division on 4 September 1943. The next day, MacArthur watched the landing at Nadzab by paratroops of the 503rd Parachute Infantry. His B-17 made the trip on three engines because one failed soon after leaving Port Moresby, but he insisted that it fly on to Nadzab. For this, he was awarded the Air Medal.

The Australian 7th and 9th Divisions converged on Lae, which fell on 16 September. MacArthur advanced his timetable, and ordered the 7th to capture Kaiapit and Dumpu, while the 9th mounted an amphibious assault on Finschhafen. Here, the offensive bogged down, partly because MacArthur had based his decision to assault Finschhafen on Willoughby's assessment that there were only 350 Japanese defenders at Finschhafen, when in fact there were nearly 5,000. A furious battle ensued.

In early November, MacArthur's plan for a westward advance along the coast of New Guinea to the Philippines was incorporated into plans for the war against Japan. Three months later, airmen reported no signs of enemy activity in the Admiralty Islands. Although Willoughby did not agree that the islands had been evacuated, MacArthur ordered an amphibious landing there, commencing the Admiralty Islands campaign. He accompanied the assault force aboard the light cruiser , the flagship of Vice Admiral Thomas C. Kinkaid, the new commander of the Seventh Fleet, and came ashore seven hours after the first wave of landing craft, for which he was awarded the Bronze Star. It took six weeks of fierce fighting before the 1st Cavalry Division captured the islands.

MacArthur had one of the most powerful PR machines of any Allied general during the war, which made him into an extremely popular war hero with the American people. In late 1943–early 1944, there was a serious effort by the conservative faction in the Republican Party centered in the Midwest to have MacArthur seek the Republican nomination to be the candidate for the presidency in the 1944 election, as they regarded the two men most likely to win the Republican nomination, namely Wendell Willkie and Governor Thomas E. Dewey of New York, as too liberal. For a time, MacArthur, who had long seen himself as a potential president, was in the words of the U.S historian Gerhard Weinberg "very interested" in running as the Republican candidate in 1944. However, MacArthur's vow to "return" to the Philippines had not been fulfilled in early 1944 and he decided not to run for president until he had liberated the Philippines.

Furthermore, Weinberg had argued that it is probable that Roosevelt, who knew of the "enormous gratuity" MacArthur had accepted from Quezon in 1942, had used his knowledge of this transaction to blackmail MacArthur into not running for president. Finally, despite the best efforts of the conservative Republicans to put MacArthur's name on the ballot, on April 4, 1944, Governor Dewey won such a convincing victory in the Wisconsin primary (regarded as a significant victory given that the Midwest was a stronghold of the conservative Republicans opposed to Dewey) as to ensure that he would win the Republican nomination to be the GOP's candidate for president in 1944.

MacArthur now bypassed the Japanese forces at Hansa Bay and Wewak, and assaulted Hollandia and Aitape, which Willoughby reported to be lightly defended based on intelligence gathered in the Battle of Sio. MacArthur's bold thrust by going 600 miles up the coast had surprised and confused the Japanese high command, who had not anticipated that MacArthur would take such risks. Although they were out of range of the Fifth Air Force's fighters based in the Ramu Valley, the timing of the operation allowed the aircraft carriers of Nimitz's Pacific Fleet to provide air support. Though risky, the operation turned out to be another success. MacArthur caught the Japanese off balance and cut off Lieutenant General Hatazō Adachi's Japanese XVIII Army in the Wewak area. Because the Japanese were not expecting an attack, the garrison was weak, and Allied casualties were correspondingly light. However, the terrain turned out to be less suitable for airbase development than first thought, forcing MacArthur to seek better locations further west. While bypassing Japanese forces had great tactical merit, it had the strategic drawback of tying up Allied troops to contain them. Moreover, Adachi was far from beaten, which he demonstrated in the Battle of Driniumor River.

In July 1944, President Roosevelt summoned MacArthur to meet with him in Hawaii "to determine the phase of action against Japan". Nimitz made the case for attacking Formosa. MacArthur stressed America's moral obligation to liberate the Philippines. In September, Admiral William Halsey, Jr.'s carriers made a series of air strikes on the Philippines. Opposition was feeble and Halsey concluded, incorrectly, that Leyte was "wide open" and possibly undefended, and recommended that projected operations be skipped in favor of an assault on Leyte.

On 20 October 1944, troops of Krueger's Sixth Army landed on Leyte, while MacArthur watched from the light cruiser . That afternoon he arrived off the beach. The advance had not progressed far; snipers were still active and the area was under sporadic mortar fire. When his whaleboat grounded in knee-deep water, MacArthur requested a landing craft, but the beachmaster was too busy to grant his request. MacArthur was compelled to wade ashore. In his prepared speech, he said:
Since Leyte was out of range of Kenney's land-based aircraft, MacArthur was dependent on carrier aircraft. Japanese air activity soon increased, with raids on Tacloban, where MacArthur decided to establish his headquarters, and on the fleet offshore. MacArthur enjoyed staying on "Nashville"s bridge during air raids, although several bombs landed close by, and two nearby cruisers were hit. Over the next few days, the Japanese counterattacked in the Battle of Leyte Gulf, resulting in a near-disaster that MacArthur attributed to the command being divided between himself and Nimitz. Nor did the campaign ashore proceed smoothly. Heavy monsoonal rains disrupted the airbase construction program. Carrier aircraft proved to be no substitute for land-based aircraft, and the lack of air cover permitted the Japanese to pour troops into Leyte. Adverse weather and tough Japanese resistance slowed the American advance, resulting in a protracted campaign.

By the end of December, Krueger's headquarters estimated that 5,000 Japanese remained on Leyte, and on 26 December MacArthur issued a communiqué announcing that "the campaign can now be regarded as closed except for minor mopping up". Yet Eichelberger's Eighth Army killed another 27,000 Japanese on Leyte before the campaign ended in May 1945. On 18 December 1944, MacArthur was promoted to the new five-star rank of General of the Army, placing him in the company of Marshall, Eisenhower, Henry "Hap" Arnold, the only four men to achieve the rank in World War II. Including Omar Bradley, MacArthur was one of only five men to achieve the title of General of the Army since the 5 August 1888 death of Philip Sheridan, and he was one of only five American officers to hold the rank as a five-star general. MacArthur was senior to all but Marshall. The rank was created by an Act of Congress when Public Law was passed on 14 December 1944, as a temporary rank, subject to reversion to permanent rank six months after the end of the war. The temporary rank was then declared permanent 23 March 1946 by Public Law 333 of the 79th Congress, which also awarded full pay and allowances in the grade to those on the retired list.

MacArthur's next move was the invasion of Mindoro, where there were good potential airfield sites. Willoughby estimated, correctly as it turned out, that the island had only about 1,000 Japanese defenders. The problem this time was getting there. Kinkaid balked at sending escort carriers into the restricted waters of the Sulu Sea, and Kenney could not guarantee land based air cover. The operation was clearly hazardous, and MacArthur's staff talked him out of accompanying the invasion on "Nashville". As the invasion force entered the Sulu Sea, a "kamikaze" struck "Nashville", killing 133 people and wounding 190 more. Australian and American engineers had three airstrips in operation within two weeks, but the resupply convoys were repeatedly attacked by "kamikazes". During this time, MacArthur quarreled with Sutherland, notorious for his abrasiveness, over the latter's mistress, Captain Elaine Clark. MacArthur had instructed Sutherland not to be bring Clark to Leyte, due to a personal undertaking to Curtin that Australian women on the GHQ staff would not be taken to the Philippines, but Sutherland had brought her along anyway.
The way was now clear for the invasion of Luzon. This time, based on different interpretations of the same intelligence data, Willoughby estimated the strength of General Tomoyuki Yamashita's forces on Luzon at 137,000, while Sixth Army estimated it at 234,000. MacArthur's response was "Bunk!". He felt that even Willoughby's estimate was too high. "Audacity, calculated risk, and a clear strategic aim were MacArthur's attributes", and he disregarded the estimates. In fact, they were too low; Yamashita had more than 287,000 troops on Luzon. This time, MacArthur traveled aboard the light cruiser , watching as the ship was nearly hit by a bomb and torpedoes fired by midget submarines. His communiqué read: "The decisive battle for the liberation of the Philippines and the control of the Southwest Pacific is at hand. General MacArthur is in personal command at the front and landed with his assault troops."

MacArthur's primary concern was the capture of the port of Manila and the airbase at Clark Field, which were required to support future operations. He urged his commanders on. On 25 January 1945, he moved his advanced headquarters forward to Hacienda Luisita, closer to the front than Krueger's. He ordered the 1st Cavalry Division to conduct a rapid advance on Manila. It reached the northern outskirts of Manila on 3 February, but, unknown to the Americans, Rear Admiral Sanji Iwabuchi had decided to defend Manila to the death. The Battle of Manila raged for the next three weeks. To spare the civilian population, MacArthur prohibited the use of air strikes, but thousands of civilians died in the crossfire or Japanese massacres. He also refused to restrict the traffic of civilians who clogged the roads in and out of Manila, placing humanitarian concerns above military ones except in emergencies. For his part in the capture of Manila, MacArthur was awarded his third Distinguished Service Cross.

After taking Manila, MacArthur installed one of his Filipino friends, Manuel Roxas—who also happened to be one of the few people who knew about the huge sum of money Quezon had given MacArthur in 1942—into a position of power that ensured Roxas was to become the next Filipino president. Roxas had been a leading Japanese collaborator serving in the puppet government of José Laurel, but MacArthur claimed that Roxas had secretly been an American agent all the long. About MacArthur's claim that Roxas was really part of the resistance, the American historian Gerhard Weinberg wrote that "...evidence to this effect has yet to surface", and that by favoring the Japanese collaborator Roxas, MacArthur ensured there was no serious effort to address the issue of Filipino collaboration with the Japanese after the war.

After the Battle of Manila, MacArthur turned his attention to Yamashita, who had retreated into the mountains of central and northern Luzon. Yamashita chose to fight a defensive campaign, being pushed back slowly by Krueger, and was still holding out at the time the war ended, much to MacArthur's intense annoyance as he had wished to liberate the entire Philippines before the war ended. On 2 September 1945, Yamashita (who had a hard time believing that the Emperor had ordered Japan to sign an armistice) came down from the mountains to surrender with some 100,000 of his men.

Although MacArthur had no specific directive to do so, and the fighting on Luzon was far from over, he committed his forces to liberate the remainder of the Philippines. In the GHQ communiqué on 5 July, he announced that the Philippines had been liberated and all operations ended, although Yamashita still held out in northern Luzon. Starting in May 1945, MacArthur used his Australian troops in the invasion of Borneo. He accompanied the assault on Labuan, and visited the troops ashore. While returning to GHQ in Manila, he visited Davao, where he told Eichelberger that no more than 4,000 Japanese remained alive on Mindanao. A few months later, six times that number surrendered. In July 1945, he was awarded his fourth Distinguished Service Medal.

As part of preparations for Operation Downfall, the invasion of Japan, MacArthur became commander in chief U.S. Army Forces Pacific (AFPAC) in April 1945, assuming command of all Army and Army Air Force units in the Pacific except the Twentieth Air Force. At the same time, Nimitz became commander of all naval forces. Command in the Pacific therefore remained divided. During his planning of the invasion of Japan, MacArthur stressed to the decision-makers in Washington that it was essential to have the Soviet Union enter the war as he argued it was crucial to have the Red Army tie down the Kwantung army in Manchuria. The invasion was pre-empted by the surrender of Japan in August 1945. On 2 September MacArthur accepted the formal Japanese surrender aboard the battleship , thus ending hostilities in World War II. In recognition of his role as a maritime strategist, the U.S. Navy awarded him the Navy Distinguished Service Medal.

On 29 August 1945, MacArthur was ordered to exercise authority through the Japanese government machinery, including the Emperor Hirohito. MacArthur's headquarters was located in the Dai Ichi Life Insurance Building in Tokyo. Unlike in Germany, where the Allies had in May 1945 abolished the German state, the Americans chose to allow the Japanese state to continue to exist, albeit under their ultimate control. Unlike Germany, there was a certain partnership between the occupiers and occupied as MacArthur decided to rule Japan via the Emperor and most of the rest of the Japanese elite. The Emperor was a living god to the Japanese people, and MacArthur found that ruling via the Emperor made his job in running Japan much easier than it otherwise would have been.
MacArthur took the view that a few "militarist" extremists had "hijacked" Japan starting in 1931 with the Mukden Incident, the Emperor was a pro-Western "moderate" who had been powerless to stop the militarists, and thus bore no responsibility for any of the war crimes committed by the Japanese between 1931 and 1945. The American historian Herbert P. Bix described the relationship between the general and the Emperor as: "the Allied commander would use the Emperor, and the Emperor would cooperate in being used. Their relationship became one of expediency and mutual protection, of more political benefit to Hirohito than to MacArthur because Hirohito had more to lose–the entire panoply of symbolic, legitimizing properties of the imperial throne".

At the same time, MacArthur undermined the imperial mystique when his staff released the famous picture of his first meeting with the Emperor, the impact of which on the Japanese public was electric as the Japanese people for the first time saw the Emperor as a mere man overshadowed by the much taller MacArthur instead of the living god he had always been portrayed as. Up to 1945, the Emperor had been a remote, mysterious figure to his people, rarely seen in public and always silent, whose photographs were always taken from a certain angle to make him look taller and more impressive than he really was. No Japanese photographer would have taken such a photo of the Emperor being overshadowed by MacArthur. The Japanese government immediately banned the photo of the Emperor with MacArthur on the grounds that it damaged the imperial mystique, but MacArthur rescinded the ban and ordered all of the Japanese newspapers to print it. The photo was intended as a message to the Emperor about who was going to be the senior partner in their relationship.

As he needed the Emperor, MacArthur protected him from any effort to hold accountable for his actions, and allowed him to issue statements that incorrectly portrayed the emerging democratic post-war era as a continuation of the Meiji era reforms. MacArthur did not allow any investigations of the Emperor, and instead in October 1945 ordered his staff "in the interests of peaceful occupation and rehabilitation of Japan, prevention of revolution and communism, all facts surrounding the execution of the declaration of war and subsequent position of the Emperor which tend to show fraud, menace or duress be marshalled". In January 1946, MacArthur reported to Washington that the Emperor could not be indicted for war crimes on the grounds: 

To protect the Emperor from being indicted, MacArthur had one of his staff, Brigadier General Bonner Fellers tell the "genrō" Admiral Mitsumasa Yonai on 6 March 1946:

From the viewpoint of both sides, having one especially evil figure in the form of General Hideki Tojo, on whom everything that went wrong could be blamed, was most politically convenient. At a second meeting on 22 March 1946, Fellers told Yonai: 

MacArthur's attempts to shield the Emperor from indictment and to have all the blame taken by Tojo were successful, which as Herbert P. Bix commented, "...had a lasting and profoundly distorting impact on the Japanese understanding of the lost war".

MacArthur was responsible for confirming and enforcing the sentences for war crimes handed down by the International Military Tribunal for the Far East. In late 1945, Allied military commissions in various cities of the Orient tried 5,700 Japanese, Taiwanese and Koreans for war crimes. About 4,300 were convicted, almost 1,000 sentenced to death, and hundreds given life imprisonment. The charges arose from incidents that included the Rape of Nanking, the Bataan Death March and Manila massacre. The trial in Manila of Yamashita was criticized because he was hanged for Iwabuchi's Manila massacre, which he had not ordered and of which he was probably unaware. Iwabuchi had killed himself as the battle for Manila was ending.

MacArthur gave immunity to Shiro Ishii and other members of the bacteriological research units in exchange for germ warfare data based on human experimentation. He also exempted the Emperor and all members of the imperial family implicated in war crimes, including princes such as Chichibu, Asaka, Takeda, Higashikuni and Fushimi, from criminal prosecutions. MacArthur confirmed that the emperor's abdication would not be necessary. In doing so, he ignored the advice of many members of the imperial family and Japanese intellectuals who publicly called for the abdication of the Emperor and the implementation of a regency.

As Supreme Commander for the Allied Powers (SCAP) in Japan, MacArthur and his staff helped Japan rebuild itself, eradicate militarism and ultra-nationalism, promote political civil liberties, institute democratic government, and chart a new course that ultimately made Japan one of the world's leading industrial powers. The U.S. was firmly in control of Japan to oversee its reconstruction, and MacArthur was effectively the interim leader of Japan from 1945 until 1948. In 1946, MacArthur's staff drafted a new constitution that renounced war and stripped the Emperor of his military authority. The constitution—which became effective on 3 May 1947—instituted a parliamentary system of government, under which the Emperor acted only on the advice of his ministers. It included the famous Article 9, which outlawed belligerency as an instrument of state policy and the maintenance of a standing army. The constitution also enfranchised women, guaranteed fundamental human rights, outlawed racial discrimination, strengthened the powers of Parliament and the Cabinet, and decentralized the police and local government.

A major land reform was also conducted, led by Wolf Ladejinsky of MacArthur's SCAP staff. Between 1947 and 1949, approximately , or 38% of Japan's cultivated land, was purchased from the landlords under the government's reform program, and was resold to the farmers who worked them. By 1950, 89% of all agricultural land was owner-operated and only 11% was tenant-operated. MacArthur's efforts to encourage trade union membership met with phenomenal success, and by 1947, 48% of the non-agricultural workforce was unionized. Some of MacArthur's reforms were rescinded in 1948 when his unilateral control of Japan was ended by the increased involvement of the State Department. During the Occupation, SCAP successfully, if not entirely, abolished many of the financial coalitions known as the Zaibatsu, which had previously monopolized industry. Eventually, looser industrial groupings known as "Keiretsu" evolved. The reforms alarmed many in the U.S. Departments of Defense and State, who believed they conflicted with the prospect of Japan and its industrial capacity as a bulwark against the spread of communism in Asia.

In 1948, MacArthur made a bid to win the Republican nomination to be the GOP candidate for president, which was the most serious of several efforts he made over the years. MacArthur's status as one of America's most popular war heroes together with his reputation as the statesman who had "transformed" Japan gave him a strong basis for running for president, but MacArthur's lack of connections within the GOP were a major handicap. MacArthur's strongest supporters came from the quasi-isolationist, Midwestern wing of the Republicans and embraced men such as Brigadier General Hanford MacNider, Philip La Follette, and Brigadier General Robert E. Wood, a diverse collection of "Old Right" and Progressive Republicans only united by a belief that the U.S. was too much involved in Europe for its own good. MacArthur declined to campaign for the presidency himself, but he privately encouraged his supporters to put his name on the ballot. MacArthur had always stated he would retire when a peace treaty was signed with Japan, and his push in the fall of 1947 to have the U.S sign a peace treaty with Japan was intended to allow him to retire on a high note, and thus campaign for the presidency. For the same reasons, Truman subverted MacArthur's efforts to have peace treaty signed in 1947, saying that more time was needed before the U.S could formally make peace with Japan.

Without a peace treaty, MacArthur decided not to resign while at the same time writing letters to Wood saying he would be more than happy to accept the Republican nomination if it were offered to him. In late 1947 and early 1948, MacArthur received several Republican grandees in Tokyo. On 9 March 1948 MacArthur issued a press statement declaring his interest in being the Republican candidate for president, saying he would be honored if the Republican Party were to nominate him, but would not resign from the Army to campaign for the presidency. The press statement had been forced by Wood, who told MacArthur that it was impossible to campaign for a man who was not officially running for president, and that MacArthur could either declare his candidacy or see Wood cease campaigning for him. MacArthur's supporters made a major effort to win the Wisconsin Republican primary held on 6 April 1948. MacArthur's refusal to campaign badly hurt his chances and it was won to everybody's surprise by Harold Stassen. The defeat in Wisconsin followed by defeat in Nebraska effectively ended MacArthur's chances of winning the Republican nomination, but MacArthur refused to withdraw his name until the 1948 Republican National Convention which was won by Governor Thomas Dewey of New York.

In an address to Congress on 19 April 1951, MacArthur declared: 

MacArthur handed over power to the Japanese government in 1949, but remained in Japan until relieved by President Harry S. Truman on 11 April 1951. The San Francisco Peace Treaty, signed on 8 September 1951, marked the end of the Allied occupation, and when it went into effect on 28 April 1952, Japan was once again an independent state. The Japanese subsequently gave him the nickname "Gaijin Shogun" ("foreign military ruler") but not until around the time of his death in 1964.
On 25 June 1950, North Korea invaded South Korea, starting the Korean War. The United Nations Security Council passed Resolution 82, which authorized a United Nations (UN) force to assist South Korea. The UN empowered the American government to select a commander, and the Joint Chiefs of Staff unanimously recommended MacArthur. He therefore became Commander-in-Chief of the United Nations Command (UNCOM), while remaining SCAP in Japan and Commander of the USAFFE. All South Korean forces were also placed under his command. As they retreated before the North Korean onslaught, MacArthur received permission to commit U.S. ground forces. All the first units to arrive could do was trade men and ground for time, falling back to the Pusan Perimeter. By the end of August, the crisis subsided. North Korean attacks on the perimeter had tapered off. While the North Korean force numbered 88,000 troops, Lieutenant General Walton Walker's Eighth Army now numbered 180,000, and he had more tanks and artillery pieces.
In 1949, the Chairman of the Joint Chiefs of Staff, General of the Army Omar Bradley, had predicted that "large scale combined amphibious operations ... will never occur again", but by July 1950, MacArthur was planning just such an operation. MacArthur compared his plan with that of General James Wolfe at the Battle of the Plains of Abraham, and brushed aside the problems of tides, hydrography and terrain. In September, despite lingering concerns from superiors, MacArthur's soldiers and marines made a successful landing at Inchon, deep behind North Korean lines. Launched with naval and close air support, the landing outflanked the North Koreans, recaptured Seoul and forced them to retreat northward in disarray. Visiting the battlefield on 17 September, MacArthur surveyed six T-34 tanks that had been knocked out by Marines, ignoring sniper fire around him, except to note that the North Korean marksmen were poorly trained.

On 11 September, Truman issued orders for an advance beyond the 38th parallel into North Korea. MacArthur now planned another amphibious assault, on Wonsan on the east coast, but it fell to South Korean troops before the 1st Marine Division could reach it by sea. In October, MacArthur met with Truman at the Wake Island Conference, with Truman emulating Roosevelt's wartime meeting with MacArthur in Hawaii. The president awarded MacArthur his fifth Distinguished Service Medal. Briefly questioned about the Chinese threat, MacArthur dismissed it, saying that he hoped to be able to withdraw the Eighth Army to Japan by Christmas, and to release a division for service in Europe in January. He regarded the possibility of Soviet intervention as a more serious threat.

A month later, things had changed. The enemy were engaged by the UN forces at the Battle of Unsan in late October, which demonstrated the presence of Chinese soldiers in Korea and rendered significant losses to the American and other UN troops. Nevertheless, Willoughby downplayed the evidence about Chinese intervention in the war. He estimated that up to 71,000 Chinese soldiers were in the country, while the true number was closer to 300,000. He was not alone in this miscalculation. On 24 November, the Central Intelligence Agency reported to Truman that while there could be as many as 200,000 Chinese troops in Korea, "there is no evidence that the Chinese Communists plan major offensive operations."

That day, MacArthur flew to Walker's headquarters and he later wrote: MacArthur flew over the front line himself in his Douglas C-54 Skymaster but saw no signs of a Chinese build up and therefore decided to wait before ordering an advance or withdrawal. Evidence of the Chinese activity was hidden to MacArthur: the Chinese Army traveled at night and dug in during the day. For his reconnaissance efforts, MacArthur was nonetheless awarded the Distinguished Flying Cross and honorary combat pilot's wings.

The next day, 25 November 1950, Walker's Eighth Army was attacked by the Chinese Army and soon the UN forces were in retreat. MacArthur provided the Chief of Staff, General J. Lawton Collins with a series of nine successive withdrawal lines. On 23 December, Walker was killed when his jeep collided with a truck, and was replaced by Lieutenant General Matthew Ridgway, whom MacArthur had selected in case of such an eventuality. Ridgway noted that MacArthur's "prestige, which had gained an extraordinary luster after Inch'on, was badly tarnished. His credibility suffered in the unforeseen outcome of the November offensive ..."

Collins discussed the possible use of nuclear weapons in Korea with MacArthur in December, and later asked him for a list of targets in the Soviet Union in case it entered the war. MacArthur testified before the Congress in 1951 that he had never recommended the use of nuclear weapons. He did at one point consider a plan to cut off North Korea with radioactive poisons; he did not recommend it at the time, although he later broached the matter with Eisenhower, then president-elect, in 1952. In 1954, in an interview published after his death, he stated he had wanted to drop atomic bombs on enemy bases, but in 1960, he challenged a statement by Truman that he had advocated using atomic bombs. Truman issued a retraction, stating that he had no evidence of the claim; it was merely his personal opinion.

In April 1951, the Joint Chiefs of Staff drafted orders for MacArthur authorizing nuclear attacks on Manchuria and the Shantung Peninsula if the Chinese launched airstrikes originating from there against his forces. The next day Truman met with the chairman of the United States Atomic Energy Commission, Gordon Dean, and arranged for the transfer of nine Mark 4 nuclear bombs to military control. Dean was apprehensive about delegating the decision on how they should be used to MacArthur, who lacked expert technical knowledge of the weapons and their effects. The Joint Chiefs were not entirely comfortable about giving them to MacArthur either, for fear that he might prematurely carry out his orders. Instead, they decided that the nuclear strike force would report to the Strategic Air Command.

Within weeks of the Chinese attack, MacArthur was forced to retreat from North Korea. Seoul fell in January 1951, and both Truman and MacArthur were forced to contemplate the prospect of abandoning Korea entirely. European countries did not share MacArthur's world view, distrusted his judgment, and were afraid that he might use his stature and influence with the American public to re-focus American policy away from Europe and towards Asia. They were concerned that this might lead to a major war with China, possibly involving nuclear weapons. Since in February 1950 the Soviet Union and China had signed a defensive alliance committing each to go to war if the other party was attacked, the possibility that an American attack on China would cause World War III was considered to be very real at the time. In a visit to the United States in December 1950, the British prime minister, Clement Attlee, had raised the fears of the British and other European governments that "General MacArthur was running the show".

Under Ridgway's command, the Eighth Army pressed north again in January. He inflicted heavy casualties on the Chinese, recaptured Seoul in March 1951, and pushed on to the 38th Parallel. With the improved military situation, Truman now saw the opportunity to offer a negotiated peace but, on 24 March, MacArthur called upon China to admit that it had been defeated, simultaneously challenging both the Chinese and his own superiors. Truman's proposed announcement was shelved.

On 5 April, Representative Joseph William Martin, Jr., the Republican leader in the House of Representatives, read aloud on the floor of the House a letter from MacArthur critical of Truman's Europe-first policy and limited-war strategy. The letter concluded with:
In March 1951 secret United States intercepts of diplomatic dispatches disclosed clandestine conversations in which General MacArthur expressed confidence to the Tokyo embassies of Spain and Portugal that he would succeed in expanding the Korean War into a full-scale conflict with the Chinese Communists. When the intercepts came to the attention of President Truman, he was enraged to learn that MacArthur was not only trying to increase public support for his position on conducting the war, but had secretly informed foreign governments that he planned to initiate actions that were counter to United States policy. The President was unable to act immediately since he could not afford to reveal the existence of the intercepts and because of MacArthur's popularity with the public and political support in Congress. However, following the release on April 5 by Representative Martin of MacArthur's letter, Truman concluded he could relieve MacArthur of his commands without incurring unacceptable political damage.

Truman summoned Secretary of Defense George Marshall, Chairman of the Joint Chiefs Omar Bradley, Secretary of State Dean Acheson and Averell Harriman to discuss what to do about MacArthur. They concurred MacArthur should be relieved of his command, but made no recommendation to do so. Although they felt that it was correct "from a purely military point of view", they were aware that there were important political considerations as well. Truman and Acheson agreed that MacArthur was insubordinate, but the Joint Chiefs avoided any suggestion of this. Insubordination was a military offense, and MacArthur could have requested a public court martial similar to that of Billy Mitchell. The outcome of such a trial was uncertain, and it might well have found him not guilty and ordered his reinstatement. The Joint Chiefs agreed that there was "little evidence that General MacArthur had ever failed to carry out a direct order of the Joint Chiefs, or acted in opposition to an order". "In point of fact", Bradley insisted, "MacArthur had stretched but not legally violated any JCS directives. He had violated the President's 6 December directive [not to make public statements on policy matters], relayed to him by the JCS, but this did not constitute violation of a JCS order." Truman ordered MacArthur's relief by Ridgway, and the order went out on 10 April with Bradley's signature.

In a 3 December 1973 article in "Time" magazine, Truman was quoted as saying in the early 1960s:
The relief of the famous general by the unpopular politician for communicating with Congress led to a constitutional crisis, and a storm of public controversy. Polls showed that the majority of the public disapproved of the decision to relieve MacArthur. By February 1952, almost nine months later, Truman's approval rating had fallen to 22 percent. , that remains the lowest Gallup Poll approval rating recorded by any serving president. As the increasingly unpopular war in Korea dragged on, Truman's administration was beset with a series of corruption scandals, and he eventually decided not to run for re-election. Beginning on 3 May 1951, a Joint Senate Committee—chaired by Democrat Richard Russell, Jr.—investigated MacArthur's removal. It concluded that "the removal of General MacArthur was within the constitutional powers of the President but the circumstances were a shock to national pride".

A day after his arrival in San Francisco from Korea on 18 April 1951, MacArthur had flown with his family to Washington, D.C. where he was scheduled to address a joint session of Congress. It was his and Jean's first visit to the continental United States since 1937, when they had been married; Arthur IV, now aged 13, had never been to the U.S. And, on April 19, 1951, MacArthur made his last official appearance in a farewell address to the U.S. Congress presenting and defending his side of his disagreement with Truman over the conduct of the Korean War. During his speech, he was interrupted by fifty ovations. MacArthur ended the address saying:
MacArthur received public adulation, which aroused expectations that he would run for president, but he was not a candidate. MacArthur carried out a speaking tour in 1951–52 attacking the Truman administration for "appeasement in Asia" and for mismanaging the economy. Initially attracting large crowds, by early 1952 MacArthur's speeches were attracting smaller and smaller numbers of people as many complained that MacArthur seemed more interested in settling scores with Truman and praising himself than in offering up a constructive vision for the nation. MacArthur felt uncomfortable campaigning for the Republican nomination, and hoped that at the Republican convention, a deadlock would ensue between Senator Robert Taft and General Eisenhower, which would end with the GOP nominating him as the best compromise. MacArthur's unwillingness to campaign for the presidency seriously hurt his ability to win the nomination. In the end, MacArthur endorsed Senator Robert A. Taft, and was keynote speaker at the 1952 Republican National Convention. Taft lost the nomination to Eisenhower, who went on to win the 1952 election by a landslide. Once elected, Eisenhower consulted with MacArthur about ending the war in Korea.
Douglas and Jean MacArthur spent their last years together in the penthouse of the Waldorf Towers, a part of the Waldorf-Astoria Hotel. He was elected chairman of the board of Remington Rand. In that year, he earned a salary of $68,000 (equivalent to $612,000 in 2016), in addition to $20,000 pay and allowances as a General of the Army. The Waldorf became the setting for an annual birthday party on 26 January thrown by the general's former deputy chief engineer, Major General Leif J. Sverdrup. At the 1960 celebration for MacArthur's 80th birthday, many of his friends were startled by the general's obviously deteriorating health. The next day, he collapsed and was rushed into surgery at St. Luke's Hospital to control a severely swollen prostate.

After his recovery, MacArthur methodically began to carry out the closing acts of his life. He visited the White House for a final reunion with Eisenhower. In 1961, he made a "sentimental journey" to the Philippines, where he was decorated by President Carlos P. Garcia with the Philippine Legion of Honor. MacArthur also accepted a $900,000 (equivalent to $7.25 million in 2016) advance from Henry Luce for the rights to his memoirs, and wrote the volume that would eventually be published as "Reminiscences". Sections began to appear in serialized form in "Life magazine" in the months before his death.

President John F. Kennedy solicited MacArthur's counsel in 1961. The first of two meetings was held shortly after the Bay of Pigs Invasion. MacArthur was extremely critical of the military advice given to Kennedy, and cautioned the young President to avoid a U.S. military build-up in Vietnam, pointing out that domestic problems should be given a much greater priority. Shortly before his death, MacArthur gave similar advice to President Lyndon B. Johnson.

In 1962, West Point honored the increasingly frail MacArthur with the Sylvanus Thayer Award for outstanding service to the nation, which had gone to Eisenhower the year before. MacArthur's speech to the cadets in accepting the award had as its theme "Duty, Honor, Country": 

In 1963, President Kennedy asked MacArthur to help mediate a dispute between the National Collegiate Athletic Association and the Amateur Athletic Union over control of amateur sports in the country. The dispute threatened to derail the participation of the United States in the 1964 Summer Olympics. His presence helped to broker a deal, and participation in the games went on as planned.

Douglas MacArthur died at Walter Reed Army Medical Center on 5 April 1964, of biliary cirrhosis. Kennedy had authorized a state funeral before his own death in 1963, and Johnson confirmed the directive, ordering that MacArthur be buried "with all the honor a grateful nation can bestow on a departed hero". On 7 April his body was taken to New York City, where it lay in an open casket at the Seventh Regiment Armory for about 12 hours. That night it was taken on a funeral train to Union Station and transported by a funeral procession to the Capitol, where it lay in state at the United States Capitol rotunda. An estimated 150,000 people filed by the bier.

MacArthur had requested to be buried in Norfolk, Virginia, where his mother had been born and where his parents had married. Accordingly, on 11 April, his funeral service was held in St Paul's Episcopal Church in Norfolk and his body was finally laid to rest in the rotunda of the Douglas MacArthur Memorial (the former Norfolk City Hall and later courthouse).

In 1960, the mayor of Norfolk had proposed using funds raised by public contribution to remodel the old Norfolk City Hall as a memorial to General MacArthur and as a repository for his papers, decorations, and mementos he had accepted. Restored and remodeled, the MacArthur Memorial contains nine museum galleries whose contents reflect the general's 50 years of military service. At the heart of the memorial is a rotunda. In its center lies a sunken circular crypt with two marble sarcophagi, one for MacArthur, the other for Jean, who continued to live in the Waldorf Towers until her own death in 2000.

The MacArthur Chambers in Brisbane, Australia, hosts the MacArthur Museum on the 8th floor where MacArthur had his office.
MacArthur has a contested legacy. In the Philippines in 1942, he suffered a defeat that Gavin Long described as "the greatest in the history of American foreign wars". Despite this, "in a fragile period of the American psyche when the general American public, still stunned by the shock of Pearl Harbor and uncertain what lay ahead in Europe, desperately needed a hero, they wholeheartedly embraced Douglas MacArthur—good press copy that he was. There simply were no other choices that came close to matching his mystique, not to mention his evocative lone-wolf stand—something that has always resonated with Americans."

MacArthur's concept of the role of the soldier as encompassing a broad spectrum of roles that included civil affairs, quelling riots and low-level conflict, was dismissed by the majority of officers who had fought in Europe during World War II, and afterwards saw the Army's role as fighting the Soviet Union. Unlike them, in his victories in New Guinea in 1944, the Philippines in 1945 and Korea in 1950, he fought outnumbered, and relied on maneuver and surprise for success. The American Sinologist John Fairbank called MacArthur "our greatest soldier".

On the other hand, Truman once remarked that he did not understand how the US Army could "produce men such as Robert E. Lee, John J. Pershing, Eisenhower and Bradley and at the same time produce Custers, Pattons and MacArthur". His relief of MacArthur cast a long shadow over American civil-military relations for decades. When Lyndon Johnson met with William Westmoreland in Honolulu in 1966, he told him: "General, I have a lot riding on you. I hope you don't pull a MacArthur on me." MacArthur's relief "left a lasting current of popular sentiment that in matters of war and peace, the military really knows best", a philosophy which became known as "MacArthurism".

MacArthur remains a controversial and enigmatic figure. He has been portrayed as a reactionary, although he was in many respects ahead of his time. He championed a progressive approach to the reconstruction of Japanese society, arguing that all occupations ultimately ended badly for the occupier and the occupied. He was often out of step with his contemporaries, such as in 1941 when he contended that Nazi Germany could not defeat the Soviet Union, when he argued that North Korea and China were no mere Soviet puppets, and throughout his career in his insistence that the future lay in the Far East. As such, MacArthur implicitly rejected White American contemporary notions of their own racial superiority. He always treated Filipino and Japanese leaders with respect as equals. At the same time, his Victorian sensibilities recoiled at leveling Manila with aerial bombing, an attitude the hardened World War II generation regarded as old fashioned. When asked about MacArthur, Field Marshal Sir Thomas Blamey once said, "The best and the worst things you hear about him are both true."

During his lifetime, MacArthur earned over 100 military decorations from the U.S. and other countries including the Medal of Honor, the French "Légion d'honneur" and "Croix de guerre", the Order of the Crown of Italy, the Order of Orange-Nassau from the Netherlands, the Honorary Knight Grand Cross of the Order of the Bath from Australia, and the Order of the Rising Sun with Paulownia Flowers, Grand Cordon from Japan.

MacArthur was enormously popular with the American public. Streets, public works, and children were named after him. Even a dance step was named after him. In 1955, his promotion to General of the Armies was proposed in Congress, but the proposal was shelved.

Since 1987 the General Douglas MacArthur Leadership Awards are presented annually by the United States Army on behalf of the General Douglas MacArthur Foundation to recognize company grade officers (lieutenants and captains) and junior warrant officers (warrant officer one and chief warrant officer two) who have demonstrated the attributes of "duty, honor, country" in their professional lives and in service to their communities.

The General Douglas MacArthur Foundation presents the MacArthur Cadet Awards in recognition of outstanding cadets within the Association of Military Colleges and Schools of the United States. The MacArthur Award is presented annually to seniors at these military schools. The award is designed to encourage cadets to emulate the leadership qualities shown by General Douglas MacArthur, as a student at West Texas Military Institute and the U.S. Military Academy. Approximately 40 schools are authorized to provide the award to its top cadet each year.

The MacArthur Leadership Award at the Royal Military College of Canada in Kingston, Ontario is awarded to the graduating officer cadet who demonstrates outstanding leadership performance based on the credo of Duty-Honor-Country and potential for future military service.

Several actors have portrayed MacArthur on-screen.




</doc>
<doc id="48664" url="https://en.wikipedia.org/wiki?curid=48664" title="Yosemite National Park">
Yosemite National Park

Yosemite National Park ( ) is an American national park located in the western Sierra Nevada of Central California, bounded on the southeast by Sierra National Forest and on the northwest by Stanislaus National Forest. The park is managed by the National Park Service and covers an area of and sits in four counties: centered in Tuolumne and Mariposa, extending north and east to Mono and south to Madera County. Designated a World Heritage site in 1984, Yosemite is internationally recognized for its granite cliffs, waterfalls, clear streams, giant sequoia groves, lakes, mountains, meadows, glaciers, and biological diversity. Almost 95% of the park is designated wilderness.

On average, about 4 million people visit Yosemite each year, and most spend the majority of their time in the of Yosemite Valley. The park set a visitation record in 2016, surpassing 5 million visitors for the first time in its history. Yosemite was central to the development of the national park idea. Galen Clark and others lobbied to protect Yosemite Valley from development, ultimately leading to President Abraham Lincoln's signing the Yosemite Grant in 1864. John Muir led a successful movement to have Congress establish a larger national park by 1890, one which encompassed the valley and its surrounding mountains and forests, paving the way for the National Park System.

Yosemite is one of the largest and least fragmented habitat blocks in the Sierra Nevada, and the park supports a diversity of plants and animals. The park has an elevation range from and contains five major vegetation zones: chaparral and oak woodland, lower montane forest, upper montane forest, subalpine zone, and alpine. Of California's 7,000 plant species, about 50% occur in the Sierra Nevada and more than 20% are within Yosemite. The park contains suitable habitat for more than 160 rare plants, with rare local geologic formations and unique soils characterizing the restricted ranges many of these plants occupy.

The geology of the Yosemite area is characterized by granitic rocks and remnants of older rock. About 10 million years ago, the Sierra Nevada was uplifted and then tilted to form its relatively gentle western slopes and the more dramatic eastern slopes. The uplift increased the steepness of stream and river beds, resulting in the formation of deep, narrow canyons. About one million years ago, snow and ice accumulated, forming glaciers at the higher alpine meadows that moved down the river valleys. Ice thickness in Yosemite Valley may have reached during the early glacial episode. The downslope movement of the ice masses cut and sculpted the U-shaped valley that attracts so many visitors to its scenic vistas today.

The name "Yosemite" (meaning "killer" in Miwok) originally referred to the name of a renegade tribe which was driven out of the area (and possibly annihilated) by the Mariposa Battalion. Previously, the area had been called "Ahwahnee" ("big mouth") by indigenous people.

Yosemite Valley has been inhabited for nearly 3,000 years, although humans may have first visited the area as long as 8,000 to 10,000 years ago. The indigenous natives called themselves the Ahwahnechee, meaning "dwellers in Ahwahnee." They are related to the Northern Paiute and Mono tribes. Many tribes visited the area to trade, including nearby Central Sierra Miwoks, who lived along the drainage area of the Tuolumne and Stanislaus Rivers. A major trading route went over Mono Pass and through Bloody Canyon to Mono Lake, just to the east of the Yosemite area. Vegetation and game in the region were similar to that present today; acorns were a staple to their diet, as well as other seeds and plants, salmon and deer.

The California Gold Rush in the mid-19th century dramatically increased travel by European-Americans in the area, causing competition for resources between the regional Paiute and Miwok and the miners and hangers on. In 1851 as part of the Mariposa Wars intended to suppress Native American resistance, United States Army Major Jim Savage led the Mariposa Battalion into the west end of Yosemite Valley. He was pursuing forces of around 200 Ahwahneechee led by Chief Tenaya.

Accounts from this battalion were the first well-documented reports of ethnic Europeans entering Yosemite Valley. Attached to Savage's unit was Dr. Lafayette Bunnell, the company physician, who later wrote about his awestruck impressions of the valley in "The Discovery of the Yosemite". Bunnell is credited with naming Yosemite Valley, based on his interviews with Chief Tenaya. Bunnell wrote that Chief Tenaya was the founder of the Ah-wah-nee colony. The Miwok, a neighboring tribe, and most white settlers considered the Ahwahneechee to be especially violent because of their frequent territorial disputes. The Miwok term for the Pai-Ute band was "yohhe'meti," meaning "they are killers". Correspondence and articles written by members of the battalion helped to popularize the natural wonders of the Yosemite Valley and the surrounding area.
Chief Tenaya and his Ahwahneechee were eventually captured and their village burned; they were removed to a reservation near Fresno, California. The chief and some others were later allowed to return to Yosemite Valley. In the spring of 1852 they attacked a group of eight gold miners, and then moved east to flee law enforcement. Near Mono Lake, they took refuge with the nearby Mono tribe of Paiute. They stole horses from their hosts and moved away, but the Mono Paiutes tracked down and killed many of the Ahwahneechee, including Chief Tenaya. The Mono Paiute took the survivors as captives back to Mono Lake and absorbed them into the Mono Lake Paiute tribe.

After these wars, a number of Native Americans continued to live within the boundaries of Yosemite. A number of Indians supported the growing tourism industry by working as laborers or maids. Later, Indians became part of the tourism industry itself by selling baskets or performing for tourists.
A reconstructed "Indian Village of Ahwahnee" has been erected behind the Yosemite Museum, located next to the Yosemite Valley Visitor Center.

In 1855, entrepreneur James Mason Hutchings, artist Thomas Ayres and two others were the first to tour the area. Hutchings and Ayres were responsible for much of the earliest publicity about Yosemite, writing articles and special magazine issues about the Valley. Ayres' style in art was highly detailed with exaggerated angularity. His works and written accounts were distributed nationally, and an art exhibition of his drawings was held in New York City. Hutchings' publicity efforts between 1855 and 1860 led to an increase in tourism to Yosemite.

Wawona was an Indian encampment in what is now the southwestern part of the park. Settler Galen Clark discovered the Mariposa Grove of giant sequoia in Wawona in 1857. He had simple lodgings built, and roads to the area. In 1879, the Wawona Hotel was built to serve tourists visiting Mariposa Grove. As tourism increased, so did the number of trails and hotels developed by people intending to build on the trade.

The Wawona Tree, also known as the Tunnel Tree, was a famous giant sequoia that stood in the Mariposa Grove. It was tall, and was in circumference. When a carriage-wide tunnel was cut through the tree in 1881, it became even more popular as a tourist photo attraction. Everything from horse-drawn carriages in the late 19th century, to automobiles in the first part of the 20th century, traveled the road which passed through that tree. The Wawona Tree fell in 1969 under a heavy load of snow. It was estimated to have been 2,300 years old.

Yosemite's first concession was established in 1884 when John Degnan and his wife established a bakery and store. In 1916, the National Park Service granted a 20-year concession to the Desmond Park Service Company. It bought out or built hotels, stores, camps, a dairy, a garage, and other park services. Desmond changed its name to the Yosemite National Park Company in December 1917 and was reorganized in 1920.

The Curry Company had been started in 1899 by David and Jennie Curry to provide concessions in the park. They also founded Camp Curry, formerly known as Curry Village, now known as Half Dome Village. The Currys lobbied reluctant park supervisors to allow expansion of concession operations and development in the area.

Administrators in the National Park Service felt that limiting the number of concessionaires in each national park would be more financially sound. The Curry Company and its rival, the Yosemite National Park Company, were forced to merge in 1925 to form the Yosemite Park & Curry Company (YP&CC). The company built the Ahwahnee Hotel in 1927.

Concerned by the effects of commercial interests, prominent citizens including Galen Clark and Senator John Conness advocated for protection of the area. A park bill was prepared with the assistance of the General Land Office in the Interior Department. The bill passed both houses of the 38th United States Congress, and was signed by President Abraham Lincoln on June 30, 1864, creating the Yosemite Grant. This is the first instance of park land being set aside specifically for preservation and public use by action of the U.S. federal government, and set a precedent for the 1872 creation of Yellowstone as the first national park. Yosemite Valley and the Mariposa Grove were ceded to California as a state park, and a board of commissioners was proclaimed two years later.

Galen Clark was appointed by the commission as the Grant's first guardian, but neither Clark nor the commissioners had the authority to evict homesteaders (which included Hutchings). The issue was not settled until 1872 when the homesteader land holdings were invalidated by the U.S. Supreme Court. Clark and the reigning commissioners were ousted in 1880, this dispute also reaching the Supreme Court in 1880. The two Supreme Court decisions affecting management of the Yosemite Grant are considered important precedents in land management law. Hutchings became the new park guardian.

Access to the park by tourists improved in the early years of the park, and conditions in the Valley were made more hospitable. Tourism significantly increased after the First Transcontinental Railroad was completed in 1869, but the long horseback ride to reach the area was a deterrent. Three stagecoach roads were built in the mid-1870s to provide better access for the growing number of visitors to Yosemite Valley.

John Muir was a Scottish-born American naturalist and explorer. It was because of Muir that many National Parks were left untouched, such as Yosemite Valley National Park. One of the most significant camping trips Muir took was in 1903 with then president Theodore Roosevelt. This trip persuaded Roosevelt to return "Yosemite Valley and Mariposa Grove to federal protection as part of Yosemite National Park".

John Muir wrote articles popularizing the area and increasing scientific interest in it. Muir was one of the first to theorize that the major landforms in Yosemite Valley were created by large alpine glaciers, bucking established scientists such as Josiah Whitney, who regarded Muir as an amateur. Muir wrote scientific papers on the area's biology. Landscape architect Frederick Law Olmsted emphasized the importance of conservation of Yosemite Valley.

Overgrazing of meadows (especially by sheep), logging of giant sequoia, and other damage caused Muir to become an advocate for further protection. Muir convinced prominent guests of the importance of putting the area under federal protection; one such guest was Robert Underwood Johnson, editor of "Century Magazine". Muir and Johnson lobbied Congress for the Act that created Yosemite National Park on October 1, 1890. The State of California, however, retained control of Yosemite Valley and Mariposa Grove. Muir also helped persuade local officials to virtually eliminate grazing from the Yosemite high country.

The newly created national park came under the jurisdiction of the United States Army's Troop I of the 4th Cavalry on May 19, 1891, which set up camp in Wawona with Captain Abram Epperson Wood as acting superintendent. By the late 1890s, sheep grazing was no longer a problem, and the Army made other improvements. The cavalry could not intervene to ease the worsening condition of Yosemite Valley and Mariposa Grove. The cavalry left another legacy in the park, the ranger hat. From 1899 to 1913, cavalry regiments of the Western Department, including the all Black 9th Cavalry (known as the "Buffalo Soldiers") and the 1st Cavalry, stationed two troops at Yosemite and brought with them the trooper's campaign hat with its distinctive Montana Peak we recognize today as the "ranger hat." This peak had been formed into the trooper's stetson by veterans of the 1898 Spanish–American War to better shed tropical rain.
Muir and his Sierra Club continued to lobby the government and influential people for the creation of a unified Yosemite National Park. In May 1903, President Theodore Roosevelt camped with Muir near Glacier Point for three days. On that trip, Muir convinced Roosevelt to take control of Yosemite Valley and Mariposa Grove away from California and return it to the federal government. In 1906, Roosevelt signed a bill that did precisely that.

The National Park Service was formed in 1916, and Yosemite was transferred to that agency's jurisdiction. Tuolumne Meadows Lodge, Tioga Pass Road, and campgrounds at Tenaya and Merced lakes were also completed in 1916. Automobiles started to enter the park in ever-increasing numbers following the construction of all-weather highways to the park. The Yosemite Museum was founded in 1926 through the efforts of Ansel Franklin Hall.In the 1920s, the museum featured Native Americans practicing traditional crafts, and many of the Sierra Miwok continued to live in Yosemite Valley until they were evicted from Yosemite in the 1960s.

In 1903, a dam in the northern portion of the park was proposed. Located in the Hetch Hetchy Valley, its purpose was to provide water and hydroelectric power to San Francisco. Muir and the Sierra Club opposed the project, while others, including Gifford Pinchot, supported it. In 1913, the U.S. Congress authorized the O'Shaughnessy Dam through passage of the Raker Act.
In the late 1920s a bid for Yosemite for the 1932 Winter Olympics was put forward. Ultimately, the 1932 Winter Olympics were awarded to Lake Placid, New York. In 1937, conservationist Rosalie Edge, head of the Emergency Conservation Committee (ECC), successfully lobbied Congress to purchase about 8,000 acres of old-growth sugar pines on the perimeter of Yosemite National Park that were to be logged.

More recently, preservationists persuaded Congress to designate , or about 89% of the park, as the Yosemite Wilderness—a highly protected wilderness area. The Park Service has reduced artificial inducements to visit the park, such as the "Firefall", in which red-hot embers were pushed off a cliff near Glacier Point at night. Traffic congestion in Yosemite Valley during the summer months has become a concern. Two electric buses commenced service in September 1995. The buses are quiet and do not emit pollutants. Eventually, all the buses in Yosemite will be electric.

In 2016, The Trust for Public Land purchased Ackerson Meadow, a 400-acre tract on the western edge of Yosemite National Park, for $2.3 million in order to preserve habitat and protect the area from development. Ackerson Meadow was originally included in the proposed 1890 park boundary but never acquired by the federal government. On September 7, 2016, the National Park Service accepted the donation of the land, making the meadow the largest addition to Yosemite since 1949.

Yosemite National Park is located in the central Sierra Nevada of California. Three wilderness areas are adjacent to Yosemite: the Ansel Adams Wilderness to the southeast, the Hoover Wilderness to the northeast, and the Emigrant Wilderness to the north.

The park is roughly the size of the U.S. state of Rhode Island and contains thousands of lakes and ponds, of streams, of hiking trails, and of roads. Two federally designated Wild and Scenic Rivers, the Merced and the Tuolumne, begin within Yosemite's borders and flow westward through the Sierra foothills, into the Central Valley of California. On average, about 4 million people visit the park each year, with most visitor use concentrated in the seven-square-mile (18 km) area of Yosemite Valley.

Almost all of the landforms in the Yosemite area are cut from the granitic rock of the Sierra Nevada Batholith (a batholith is a large mass of intrusive igneous rock that formed deep below the surface). About 5% of the park's landforms (mostly in its eastern margin near Mount Dana) are metamorphosed volcanic and sedimentary rocks. These rocks are called "roof pendants" because they were once the roof of the underlying granitic rock.

Erosion acting upon different types of uplift-created joint and fracture systems is responsible for creating the valleys, canyons, domes, and other features we see today. These joints and fracture systems do not move, and are therefore not faults. Spacing between joints is controlled by the amount of silica in the granite and granodiorite rocks; more silica tends to create a more resistant rock, resulting in larger spaces between joints and fractures.

Pillars and columns, such as Washington Column and Lost Arrow, are created by cross joints. Erosion acting on master joints is responsible for creating valleys and later canyons. The single most erosive force over the last few million years has been large alpine glaciers, which have turned the previously V-shaped river-cut valleys into U-shaped glacial-cut canyons (such as Yosemite Valley and Hetch Hetchy Valley). Exfoliation (caused by the tendency of crystals in plutonic rocks to expand at the surface) acting on granitic rock with widely spaced joints is responsible for creating domes such as Half Dome and North Dome and inset arches like Royal Arches.

Yosemite Valley represents only one percent of the park area, but this is where most visitors arrive and stay. The Tunnel View is the first view of the Valley for many visitors and is extensively photographed. El Capitan, a prominent granite cliff that looms over Yosemite Valley, is one of the most popular rock climbing destinations in the world because of its diverse range of climbing routes in addition to its year-round accessibility. Granite domes such as Sentinel Dome and Half Dome rise , respectively, above the valley floor. In the park are many domes.

The high country of Yosemite contains beautiful areas such as Tuolumne Meadows, Dana Meadows, the Clark Range, the Cathedral Range, and the Kuna Crest. The Sierra crest and the Pacific Crest Trail run through Yosemite, with peaks of red metamorphic rock, such as Mount Dana and Mount Gibbs, and granite peaks, such as Mount Conness. Mount Lyell is the highest point in the park, standing at . The Lyell Glacier is the largest glacier in Yosemite National Park and is one of the few remaining in the Sierra Nevada today.

The park has three groves of ancient giant sequoia ("Sequoiadendron giganteum") trees; the Mariposa Grove (200 trees), the Tuolumne Grove (25 trees), and the Merced Grove (20 trees). This species grows larger in volume than any other and is one of the tallest and longest-lived.

The Tuolumne and Merced River systems originate along the crest of the Sierra Nevada in the park and have carved river canyons deep. The Tuolumne River drains the entire northern portion of the park, an area of approximately . The Merced River begins in the park's southern peaks, primarily the Cathedral and Clark Ranges, and drains an area of approximately .

Hydrologic processes, including glaciation, flooding, and fluvial geomorphic response, have been fundamental in creating landforms in the park. The park also contains approximately 3,200 lakes (greater than 100 m), two reservoirs, and of streams, all of which help form these two large watersheds. Wetlands in Yosemite occur in valley bottoms throughout the park, and are often hydrologically linked to nearby lakes and rivers through seasonal flooding and groundwater movement. Meadow habitats, distributed at elevations from in the park, are generally wetlands, as are the riparian habitats found on the banks of Yosemite's numerous streams and rivers.
Yosemite is famous for its high concentration of waterfalls in a small area. Numerous sheer drops, glacial steps and hanging valleys in the park provide many places for waterfalls to exist, especially during April, May, and June (the snowmelt season). Located in Yosemite Valley, the Yosemite Falls is the highest in North America at . Also in Yosemite Valley is the much lower volume Ribbon Falls, which has the highest single vertical drop, . Perhaps the most prominent of the Yosemite Valley waterfalls is Bridalveil Fall, which is the waterfall seen from the Tunnel View viewpoint at the east end of the Wawona Tunnel. Wapama Falls in Hetch Hetchy Valley is another notable waterfall. Hundreds of ephemeral waterfalls also exist in the park.

All glaciers in the park are relatively small glaciers that occupy areas that are in almost permanent shade, such as north- and northeast-facing cirques. Lyell Glacier is the largest glacier in Yosemite (the Palisades Glaciers are the largest in the Sierra Nevada) and covers . None of the Yosemite glaciers are a remnant of the much, much larger Ice Age alpine glaciers responsible for sculpting the Yosemite landscape. Instead, they were formed during one of the neoglacial episodes that have occurred since the thawing of the Ice Age (such as the Little Ice Age). Climate change has reduced the number and size of glaciers around the world. Many Yosemite glaciers, including Merced Glacier, which was discovered by John Muir in 1871 and bolstered his glacial origins theory of the Yosemite area, have disappeared and most of the others have lost up to 75% of their surface area.

Yosemite has a Mediterranean climate (Köppen climate classification "Csa"), meaning most precipitation falls during the mild winter, and the other seasons are nearly dry (less than 3% of precipitation falls during the long, hot summers). Because of orographic lift, precipitation increases with elevation up to where it slowly decreases to the crest. Precipitation amounts vary from at elevation to at . Snow does not typically persist on the ground until November in the high country. It accumulates all winter and into March or early April.

Mean daily temperatures range from to at Tuolumne Meadows at . At the Wawona Entrance (elevation ), mean daily temperature ranges from . At the lower elevations below , temperatures are hotter; the mean daily high temperature at Yosemite Valley (elevation ) varies from . At elevations above , the hot, dry summer temperatures are moderated by frequent summer thunderstorms, along with snow that can persist into July. The combination of dry vegetation, low relative humidity, and thunderstorms results in frequent lightning-caused fires as well.

At the park headquarters, with an elevation of , January averages , while July averages , though in summer the nights are much cooler than the hot days. There are an average of 39.5 days with highs of or higher and an average of 97.9 nights with freezing temperatures. Freezing temperatures have been recorded in every month of the year. The record high temperature was on July 20, 1915, while the record low temperature was on January 2, 1924 and on January 21, 1937. Average annual precipitation is nearly , falling on 65 days. The wettest year was 1983 with and the driest year was 1976 with . The most precipitation in one month was in December 1955 and the most in one day was on December 23, 1955. Average annual snowfall is . The snowiest year was 1967 with . The most snow in one month was in January 1993.

The area of the park was astride a passive continental margin during the Precambrian and early Paleozoic. Sediment was derived from continental sources and was deposited in shallow water. These rocks have since been metamorphosed.

Heat generated from the Farallon Plate subducting below the North American Plate led to the creation of an island arc of volcanoes on the west coast of proto-North America between the late Devonian and Permian periods. Later volcanism in the Jurassic intruded and covered these rocks in what may have been magmatic activity associated with the early stages of the creation of the Sierra Nevada Batholith. 95% of these rocks were eventually removed by uplifted-accelerated erosion.

The first phase of regional plutonism started 210 million years ago in the late Triassic and continued throughout the Jurassic to about 150 million years before present (BP). Around the same time, the Nevadan orogeny built the Nevadan mountain range (also called the Ancestral Sierra Nevada) to a height of . This was directly part of the creation of the Sierra Nevada Batholith, and the resulting rocks were mostly granitic in composition and emplaced about below the surface. The second major pluton emplacement phase lasted from about 120 million to 80 million years ago during the Cretaceous. This was part of the Sevier orogeny.

Starting 20 million years ago (in the Cenozoic) and lasting until 5 million years ago, a now-extinct extension of Cascade Range volcanoes erupted, bringing large amounts of igneous material in the area. These igneous deposits blanketed the region north of the Yosemite region. Volcanic activity persisted past 5 million years BP east of the current park borders in the Mono Lake and Long Valley areas.

Starting 10 million years ago, vertical movement along the Sierra fault started to uplift the Sierra Nevada. Subsequent tilting of the Sierra block and the resulting accelerated uplift of the Sierra Nevada increased the gradient of western-flowing streams. The streams consequently ran faster and thus cut their valleys more quickly. Additional uplift occurred when major faults developed to the east, especially the creation of Owens Valley from Basin and Range-associated extensional forces. Uplift of the Sierra accelerated again about two million years ago during the Pleistocene.

The uplifting and increased erosion exposed granitic rocks in the area to surface pressures, resulting in exfoliation (responsible for the rounded shape of the many domes in the park) and mass wasting following the numerous fracture joint planes (cracks; especially vertical ones) in the now solidified plutons. Pleistocene glaciers further accelerated this process and the larger ones transported the resulting talus and till from valley floors.

Numerous vertical joint planes controlled where and how fast erosion took place. Most of these long, linear and very deep cracks trend northeast or northwest and form parallel, often regularly spaced sets. They were created by uplift-associated pressure release and by the unloading of overlying rock via erosion.

A series of glaciations further modified the region starting about 2 to 3 million years ago and ending sometime around 10,000 BP. At least four major glaciations have occurred in the Sierra Nevada, locally called the Sherwin (also called the pre-Tahoe), Tahoe, Tenaya, and Tioga. The Sherwin glaciers were the largest, filling Yosemite and other valleys, while later stages produced much smaller glaciers. A Sherwin-age glacier was almost surely responsible for the major excavation and shaping of Yosemite Valley and other canyons in the area.

Glacial systems reached depths of up to and left their marks in the Yosemite area. The longest glacier in the Yosemite area ran down the Grand Canyon of the Tuolumne River for , passing well beyond Hetch Hetchy Valley. Merced Glacier flowed out of Yosemite Valley and into the Merced River Gorge. Lee Vining Glacier carved Lee Vining Canyon and emptied into Lake Russel (the much-enlarged ice age version of Mono Lake). Only the highest peaks, such as Mount Dana and Mount Conness, were not covered by glaciers. Retreating glaciers often left recessional moraines that impounded lakes such as the long Lake Yosemite (a shallow lake that periodically covered much of the floor of Yosemite Valley).

With its scrubby sun-baked chaparral, stately groves of pine, fir, and sequoia, and expanses of alpine woodlands and meadows, Yosemite National Park preserves a Sierra Nevada landscape as it prevailed before Euro-American settlement. In contrast to surrounding lands, which have been significantly altered by logging, the park still contains some of old-growth forest. Taken together, the park's varied habitats support over 250 species of vertebrates, which include fish, amphibians, reptiles, birds, and mammals.

Much of Yosemite's western boundary has habitats dominated by mixed coniferous forests of ponderosa pine, sugar pine, incense cedar, white fir, Douglas fir, and a few stands of giant sequoia, interspersed by areas of black oak and canyon live oak. A relatively high diversity of wildlife species is supported by these habitats, because of relatively mild, lower-elevation climate and the mixture of habitat types and plant species. Wildlife species typically found in these habitats include black bear, coyote, raccoon, mountain kingsnake, Gilbert's skink, white-headed woodpecker, bobcat, river otter, gray fox, red fox, brown creeper, two species of skunk, cougar, spotted owl, and a wide variety of bat species.

Going higher in elevation, the coniferous forests become purer stands of red fir, western white pine, Jeffrey pine, lodgepole pine, and the occasional foxtail pine. Fewer wildlife species tend to be found in these habitats, because of their higher elevation and lower complexity. Species likely to be found include golden-mantled ground squirrel, chickaree, fisher, Steller's jay, hermit thrush, and northern goshawk. Reptiles are not common, but include rubber boa, western fence lizard, and northern alligator lizard.
As the landscape rises, trees become smaller and more sparse, with stands broken by areas of exposed granite. These include lodgepole pine, whitebark pine, and mountain hemlock that, at highest elevations, give way to vast expanses of granite as treeline is reached. The climate in these habitats is harsh and the growing season is short, but species such as pika, yellow-bellied marmot, white-tailed jackrabbit, Clark's nutcracker, and black rosy finch are adapted to these conditions. Also, the treeless alpine habitats are the areas favored by Sierra Nevada bighorn sheep. This species, however, is now found in the Yosemite area only around Tioga Pass, where a small, reintroduced population exists.

At a variety of elevations, meadows provide important, productive habitat for wildlife. Animals come to feed on the green grasses and use the flowing and standing water found in many meadows. Predators, in turn, are attracted to these areas. The interface between meadow and forest is also favored by many animal species because of the proximity of open areas for foraging and cover for protection. Species that are highly dependent upon meadow habitat include great grey owl, willow flycatcher, Yosemite toad, and mountain beaver.

The black bears of Yosemite were once famous for breaking into parked cars to steal food. They were also an encouraged tourist sight for many years at the park's garbage dumps, where bears congregated to eat park visitors' garbage and tourists gathered to photograph the bears. Increasing encounters between bears and humans and increasing damage to property led to an aggressive campaign to discourage bears from relying on human food or interacting with people and their property. The open-air dumps were closed; all trash receptacles were replaced with bear-proof receptacles; all campgrounds were equipped with bear-proof food lockers so that people would not leave food in their vehicles, which were easy targets for the powerful and resourceful bears. Because bears who show aggression towards people usually are eventually destroyed, park personnel have continued to come up with innovative ways to have bears associate humans and their property with unpleasant experiences, such as being hit with rubber bullets. Today, about 30 bears a year are captured and ear-tagged and their DNA is sampled so that, when bear damage occurs, rangers can ascertain which bear is causing the problem.

Despite the richness of high-quality habitats in Yosemite, the brown bear, California condor, and least Bell's vireo have become extinct in the park within historical time, and another 37 species currently have special status under either California or federal endangered species legislation. The most serious current threats to Yosemite's wildlife and the ecosystems they occupy include loss of a natural fire regime, exotic species, air pollution, habitat fragmentation, and climate change. On a more local basis, factors such as road kills and the availability of human food have affected some wildlife species.
Yosemite National Park has documented more than 130 non-native plant species within park boundaries. These non-native plants were introduced into Yosemite following the migration of early Euro-American settlers in the late 1850s. Natural and human-caused disturbances, such as wildland fires and construction activities, have contributed to a rapid increase in the spread of non-native plants. A number of these species aggressively invade and displace the native plant communities, resulting in impacts on the park's resources. Non-native plants can bring about significant changes in park ecosystems by altering the native plant communities and the processes that support them. Some non-native species may cause an increase in the fire frequency of an area or increase the available nitrogen in the soil that may allow more non-native plants to become established. Many non-native species, such as yellow star thistle ("Centaurea solstitialis"), are able to produce a long tap root that allows them to out-compete the native plants for available water.

Bull thistle ("Cirsium vulgare"), common mullein ("Verbascum thapsus"), and Klamath weed ("Hypericum perforatum") have been identified as noxious pests in Yosemite since the 1940s. Additional species that have been recognized more recently as aggressive and requiring control are yellow star thistle ("Centaurea solstitialis"), sweet clover ("Melilot" spp.), Himalayan blackberry ("Rubus armeniacus"), cut-leaved blackberry ("Rubus laciniatus") and large periwinkle ("Vinca major").

Increasing ozone pollution is causing tissue damage to the massive giant sequoia trees in the park, making them more vulnerable to insect infestation and disease. Since the cones of these trees require fire-touched soil to germinate, historic fire suppression has reduced these trees' ability to reproduce. The current policy of setting prescribed fires is expected to help the germination issue.

Forest fires seasonally clear the park of dead vegetation, making way for new growth. These fires damage the income generated by tourism. The Rim Fire in 2013 destroyed nearly $2 billion in assets and revenue, though natural woodland assets are renewable, and closed off much of the park to tourists. This fire was the third largest on record, and burned nearly 500 acres of wild habitat.

During late July and early August, 2018, sections of the park, including the Valley, were temporarily closed due to the Ferguson Fire at its western boundary. The closing was the largest in almost thirty years at the park.

Yosemite Valley is open year-round and numerous activities are available through the National Park Service, Yosemite Conservancy, and Aramark at Yosemite, including nature walks, photography and art classes, stargazing programs, tours, bike rentals, rafting, mule and horseback rides, and rock climbing classes. Many people enjoy short walks and longer hikes to waterfalls in Yosemite Valley, or walks among giant sequoias in the Mariposa, Tuolumne, or Merced Groves. Others like to drive or take a tour bus to Glacier Point (summer–fall) to see views of Yosemite Valley and the high country, or drive along the scenic Tioga Road to Tuolumne Meadows (May–October) and go for a walk or hike.

Most park visitors stay just for the day, and visit only those locations within Yosemite Valley that are easily accessible by automobile. There is a US$25-30 per automobile user fee to enter the park, depending on the season. Traffic congestion in the valley is a serious problem during peak season, in summer. A free shuttle bus system operates year-round in the valley, and park rangers encourage people to use this system since parking within the valley during the summer is often nearly impossible to find.

In addition to exploring the natural features of the park, visitors can also learn about the natural and cultural history of Yosemite Valley at a number of facilities in the valley: the Yosemite Valley Visitor Center, the adjoining Yosemite Museum, and the Nature Center at Happy Isles. There are also two National Historic Landmarks: the Sierra Club's LeConte Memorial Lodge (Yosemite's first public visitor center), and the Ahwahnee Hotel. Camp 4 was added to the National Register of Historic Places in 2003.

In the winter, it is snowed in, but the area of Tuolumne Meadows has a great deal of hiking, rock climbing, and mountain climbing.

Over of trails are available to hikers—everything from an easy stroll to a challenging mountain hike, or an overnight backpack trip. One of the most popular trails leads to the summit of Half Dome and requires an advance permit from Memorial Day weekend in late May, to Columbus Day in early October. A maximum of 300 hikers, selected by lottery, are permitted to advance beyond the base of the subdome each day, including 225 day hikers and 75 backpackers.

The park can be divided into five sections for the day-user—Yosemite Valley, Wawona/Mariposa Grove/Glacier Point, Tuolumne Meadows, Hetch Hetchy, and Crane Flat/White Wolf. Numerous books describe park trails, and free information is available from the National Park Service in Yosemite. Park rangers encourage visitors to experience portions of the park in addition to Yosemite Valley.

Between late spring and early fall, much of the park can be accessed for multiple-day backpacking trips. All overnight trips into the back country require a wilderness permit and most require approved bear-resistant food storage.

While some locations in Yosemite require hiking, other locations can be reached via automobile transportation. Driving locations also allow guests to observe the night sky in locations other than their campsite or lodge. All of the roads in Yosemite are scenic, but the most famous is the Tioga Road, typically open from late May or early June through November.

As an alternative to driving, bicycles are allowed on the roads. However, bicycles are allowed off-road on only of paved trails in Yosemite Valley itself; mountain biking is not allowed.

Rock climbing is an important part of Yosemite. Camp 4, a walk-in campground in Yosemite Valley, was instrumental in the development of rock climbing as a sport, and is listed on the National Register of Historic Places. Climbers can generally be spotted in the snow-free months on anything from ten-foot-high (3 m) boulders to the face of El Capitan. Classes on rock climbing are offered by numerous groups.

Yosemite Valley is open all year, although some roads within the park close in winter. Downhill skiing is available at the Badger Pass Ski Area—the oldest downhill skiing area in California, offering downhill skiing from mid-December through early April. Much of the park is open to cross-country skiing and snowshoeing, with several backcountry ski huts open for use. Wilderness permits are required for backcountry overnight ski trips.

The Bracebridge dinner is an annual holiday event, held since 1927 at the Ahwahnee Hotel, inspired by Washington Irving's descriptions of Squire Bracebridge and English Christmas traditions of the 18th century in his "Sketch Book". Between 1929 and 1973, the show was organized by Ansel Adams.

Bicycle rentals are available in Yosemite Valley spring through fall. Over of paved bike paths are available in Yosemite Valley. In addition, bicyclists can ride on regular roads. Helmets are required by law for children under 18 years of age. Off-trail riding and mountain biking are not permitted in Yosemite National Park.

Water activities are plentiful during warmer months. Rafting can be done through the Yosemite Valley on the Merced River. There are also swimming pools available at Yosemite Lodge and Curry Village.
In 2010, Yosemite National Park was honored with its own quarter under the America the Beautiful Quarters program.

The opening scenes of "" (1989) were filmed in Yosemite National Park. Films such as "The Last of the Mohicans" (1920) and "Maverick" (1994) have also been shot here.




</doc>
<doc id="48918" url="https://en.wikipedia.org/wiki?curid=48918" title="Alexandra of Denmark">
Alexandra of Denmark

Alexandra of Denmark (Alexandra Caroline Marie Charlotte Louise Julia; 1 December 1844 – 20 November 1925) was Queen of the United Kingdom and the British Dominions and Empress of India as the wife of King Edward VII.

Her family had been relatively obscure until 1852, when her father, Prince Christian of Schleswig-Holstein-Sonderburg-Glücksburg, was chosen with the consent of the major European powers to succeed his distant cousin, Frederick VII, to the Danish throne. At the age of sixteen, she was chosen as the future wife of Albert Edward, Prince of Wales, the heir apparent of Queen Victoria. They married eighteen months later in 1863, the same year her father became king of Denmark as Christian IX and her brother was appointed to the vacant Greek throne as George I. She was Princess of Wales from 1863 to 1901, the longest anyone has ever held that title, and became generally popular; her style of dress and bearing were copied by fashion-conscious women. Largely excluded from wielding any political power, she unsuccessfully attempted to sway the opinion of British ministers and her husband's family to favour Greek and Danish interests. Her public duties were restricted to uncontroversial involvement in charitable work.

On the death of Queen Victoria in 1901, Albert Edward became king-emperor as Edward VII, with Alexandra as queen-empress. She held the status until Edward's death in 1910. She greatly distrusted her nephew, German Emperor Wilhelm II, and supported her son George V during the First World War, in which Britain and its allies fought Germany.

Princess Alexandra Caroline Marie Charlotte Louise Julia, or "Alix", as her immediate family knew her, was born at the Yellow Palace, an 18th-century town house at 18 Amaliegade, right next to the Amalienborg Palace complex in Copenhagen. Her father was Prince Christian of Schleswig-Holstein-Sonderburg-Glücksburg and her mother was Princess Louise of Hesse-Kassel. Although she was of royal blood, her family lived a comparatively normal life. They did not possess great wealth; her father's income from an army commission was about £800 per year and their house was a rent-free grace and favour property. Occasionally, Hans Christian Andersen was invited to call and tell the children stories before bedtime.

In 1848, King Christian VIII of Denmark died and his only son Frederick ascended the throne. Frederick was childless, had been through two unsuccessful marriages, and was assumed to be infertile. A succession crisis arose as Frederick ruled in both Denmark and Schleswig-Holstein, and the succession rules of each territory differed. In Holstein, the Salic law prevented inheritance through the female line, whereas no such restrictions applied in Denmark. Holstein, being predominantly German, proclaimed independence and called in the aid of Prussia. In 1852, the major European powers called a conference in London to discuss the Danish succession. An uneasy peace was agreed, which included the provision that Prince Christian of Schleswig-Holstein-Sonderburg-Glücksburg would be Frederick's heir in all his dominions and the prior claims of others (who included Christian's own mother-in-law, brother-in-law and wife) were surrendered.

Prince Christian was given the title Prince of Denmark and his family moved into a new official residence, Bernstorff Palace. Although the family's status had risen, there was little or no increase in their income and they did not participate in court life at Copenhagen as they refused to meet Frederick's third wife and former mistress, Louise Rasmussen, because she had an illegitimate child by a previous lover. Alexandra shared a draughty attic bedroom with her sister, Dagmar (later Empress of Russia), made her own clothes and waited at table along with her sisters. Alexandra and Dagmar were given swimming lessons by the Swedish pioneer of women's swimming, Nancy Edberg. At Bernstorff, Alexandra grew into a young woman; she was taught English by the English chaplain at Copenhagen and was confirmed in Christiansborg Palace. She was devout throughout her life, and followed High Church practice.

Queen Victoria and her husband, Prince Albert, were already concerned with finding a bride for their son and heir, Albert Edward, the Prince of Wales. They enlisted the aid of their daughter, Crown Princess Victoria of Prussia, in seeking a suitable candidate. Alexandra was not their first choice, since the Danes were at loggerheads with the Prussians over the Schleswig-Holstein Question and most of the British royal family's relations were German. Eventually, after rejecting other possibilities, they settled on her as "the only one to be chosen".

On 24 September 1861, Crown Princess Victoria introduced her brother Albert Edward to Alexandra at Speyer. Almost a year later on 9 September 1862 (after his affair with Nellie Clifden and the death of his father) Albert Edward proposed to Alexandra at the Royal Castle of Laeken, the home of his great-uncle, King Leopold I of Belgium.

A few months later, Alexandra travelled from Denmark to Britain aboard the royal yacht "Victoria and Albert II" and arrived in Gravesend, Kent, on 7 March 1863. Sir Arthur Sullivan composed music for her arrival and Poet Laureate Alfred, Lord Tennyson, wrote an ode in Alexandra's honour:

Thomas Longley, the Archbishop of Canterbury, married the couple on 10 March 1863 at St George's Chapel, Windsor Castle. The choice of venue was criticised widely. As the ceremony took place outside London, the press complained that large public crowds would not be able to view the spectacle. Prospective guests thought it awkward to get to and, as the venue was small, some people who had expected invitations were disappointed. The Danes were dismayed because only Alexandra's closest relations were invited. The British court was still in mourning for Prince Albert, so ladies were restricted to wearing grey, lilac or mauve. As the couple left Windsor for their honeymoon at Osborne House on the Isle of Wight, they were cheered by the schoolboys of neighbouring Eton College, including Lord Randolph Churchill.

By the end of the following year, Alexandra's father had ascended the throne of Denmark, her brother George had become King of the Hellenes, her sister Dagmar was engaged to the Tsesarevich of Russia, and Alexandra had given birth to her first child. Her father's accession gave rise to further conflict over the fate of Schleswig-Holstein. The German Confederation successfully invaded Denmark, reducing the area of Denmark by two-fifths. To the great irritation of Queen Victoria and the Crown Princess of Prussia, Alexandra and Albert Edward supported the Danish side in the war. The Prussian conquest of former Danish lands heightened Alexandra's profound dislike of the Germans, a feeling which stayed with her for the rest of her life.

Alexandra's first child, Albert Victor, was born two months premature in early 1864. Alexandra showed devotion to her children: "She was in her glory when she could run up to the nursery, put on a flannel apron, wash the children herself and see them asleep in their little beds." Albert Edward and Alexandra had six children in total: Albert Victor, George, Louise, Victoria, Maud, and John. All of Alexandra's children were apparently born prematurely; biographer Richard Hough thought Alexandra deliberately misled Queen Victoria as to her probable delivery dates, as she did not want the queen to be present at their births. During the birth of her third child in 1867, the added complication of a bout of rheumatic fever threatened Alexandra's life, and left her with a permanent limp.

In public, Alexandra was dignified and charming; in private, affectionate and jolly. She enjoyed many social activities, including dancing and ice-skating, and was an expert horsewoman and tandem driver. She also enjoyed hunting, to the dismay of Queen Victoria, who asked her to stop, but without success. Even after the birth of her first child, she continued to socialise much as before, which led to some friction between the queen and the young couple, exacerbated by Alexandra's loathing of Prussians and the queen's partiality towards them.

Albert Edward and Alexandra visited Ireland in April 1868. After her illness the previous year, she had only just begun to walk again without the aid of two walking sticks, and was already pregnant with her fourth child. The royal couple undertook a six-month tour taking in Austria, Egypt and Greece over 1868 and 1869, which included visits to her brother King George I of Greece, to the Crimean battlefields and, for her only, to the harem of the Khedive Ismail. In Turkey she became the first woman to sit down to dinner with the Sultan (Abdülâziz).

The Waleses made Sandringham House their preferred residence, with Marlborough House their London base. Biographers agree that their marriage was in many ways a happy one; however, some have asserted that Albert Edward did not give his wife as much attention as she would have liked and that they gradually became estranged, until his attack of typhoid fever, the disease which was believed to have killed his father, in late 1871 brought about a reconciliation. This is disputed by others, who point out Alexandra's frequent pregnancies throughout this period and use family letters to deny the existence of any serious rift. Nevertheless, the prince was severely criticised from many quarters of society for his apparent lack of interest in her very serious illness with rheumatic fever. Throughout their marriage Albert Edward continued to keep company with other women, including the actress Lillie Langtry, Daisy Greville, Countess of Warwick, humanitarian Agnes Keyser, and society matron Alice Keppel. Alexandra knew about most of these relationships, and later permitted Alice Keppel to visit her husband as he lay dying. Alexandra herself remained faithful throughout her marriage.

An increasing degree of deafness, caused by hereditary otosclerosis, led to Alexandra's social isolation; she spent more time at home with her children and pets. Her sixth and final pregnancy ended tragically when her infant son died only a day after his birth. Despite Alexandra's pleas for privacy, Queen Victoria insisted on announcing a period of court mourning, which led unsympathetic elements of the press to describe the birth as "a wretched abortion" and the funeral arrangements as "sickening mummery", even though the infant was not buried in state with other members of the royal family at Windsor, but in strict privacy in the churchyard at Sandringham, where he had lived out his brief life.

For eight months over 1875–76, the Prince of Wales was absent from Britain on a tour of India, but to her dismay Alexandra was left behind. The prince had planned an all-male group and intended to spend much of the time hunting and shooting. During the prince's tour, one of his friends who was travelling with him, Lord Aylesford, was told by his wife that she was going to leave him for another man: Lord Blandford, who was himself married. Aylesford was appalled and decided to seek a divorce. Meanwhile, Lord Blandford's brother, Lord Randolph Churchill, persuaded the lovers against an elopement. Now concerned by the threat of divorce, Lady Aylesford sought to dissuade her husband from proceeding but Lord Aylesford was adamant and refused to reconsider. In an attempt to pressure Lord Aylesford to drop his divorce suit, Lady Aylesford and Lord Randolph Churchill called on Alexandra and told her that if the divorce was to proceed they would subpoena her husband as a witness and implicate him in the scandal. Distressed at their threats, and following the advice of Sir William Knollys and the Duchess of Teck, Alexandra informed the queen, who then wrote to the Prince of Wales. The prince was incensed. Eventually, the Blandfords and the Aylesfords both separated privately. Although Lord Randolph Churchill later apologised, for years afterwards the Prince of Wales refused to speak to or see him.

Alexandra spent the spring of 1877 in Greece recuperating from a period of ill health and visiting her brother King George of Greece. During the Russo-Turkish War, Alexandra was clearly partial against Turkey and towards Russia, where her sister was married to the Tsarevitch, and she lobbied for a revision of the border between Greece and Turkey in favour of the Greeks. Alexandra and her two sons spent the next three years largely parted from each other's company as the boys were sent on a worldwide cruise as part of their naval and general education. The farewell was very tearful and, as shown by her regular letters, she missed them dreadfully. In 1881, Alexandra and Albert Edward travelled to Saint Petersburg after the assassination of Alexander II of Russia, both to represent Britain and so that Alexandra could provide comfort to her sister, who was now the tsarina.

Alexandra undertook many public duties; in the words of Queen Victoria, "to spare me the strain and fatigue of functions. She opens bazaars, attends concerts, visits hospitals in my place ... she not only never complains, but endeavours to prove that she has enjoyed what to another would be a tiresome duty." She took a particular interest in the London Hospital, visiting it regularly. Joseph Merrick, the so-called "Elephant Man", was one of the patients whom she met. Crowds usually cheered Alexandra rapturously, but during a visit to Ireland in 1885, she suffered a rare moment of public hostility when visiting the City of Cork, a hotbed of Irish nationalism. She and her husband were booed by a crowd of two to three thousand people brandishing sticks and black flags. She smiled her way through the ordeal, which the British press still portrayed in a positive light, describing the crowds as "enthusiastic". As part of the same visit, she received a Doctorate in Music from Trinity College, Dublin.

The death of her eldest son, Prince Albert Victor, Duke of Clarence and Avondale, in 1892 was a serious blow to Alexandra. His room and possessions were kept exactly as he had left them, much as those of Prince Albert were left after his death in 1861. She said, "I have buried my angel and with him my happiness." Surviving letters between Alexandra and her children indicate that they were mutually devoted. In 1894, her brother-in-law Alexander III of Russia died and her nephew Nicholas II of Russia became Tsar. Alexandra's widowed sister, the Dowager Empress, leant heavily on her for support; Alexandra slept, prayed, and stayed beside her sister for the next two weeks until Alexander's burial.

With the death of her mother-in-law, Queen Victoria, in 1901, Alexandra became queen-empress consort to the new king. Just two months later, her son George and daughter-in-law Mary left on an extensive tour of the empire, leaving their young children in the care of Alexandra and Edward, who doted on their grandchildren. On George's return, preparations for Edward and Alexandra's coronation in Westminster Abbey were well in hand but just a few days before the scheduled coronation in June 1902 the king became seriously ill with appendicitis. Alexandra deputised for him at a military parade, and attended the Royal Ascot races without him, in an attempt to prevent public alarm. Eventually, the coronation had to be postponed and Edward had an operation performed by Frederick Treves of the London Hospital to drain the infected appendix. After his recovery, Alexandra and Edward were crowned together in August: he by the Archbishop of Canterbury, Frederick Temple, and she by the Archbishop of York, William Dalrymple Maclagan.

Despite being queen, Alexandra's duties changed little, and she kept many of the same retainers. Alexandra's Woman of the Bedchamber, Charlotte Knollys, the daughter of Sir William Knollys, served Alexandra loyally for many years. On 10 December 1903, Knollys woke to find her bedroom full of smoke. She roused Alexandra and shepherded her to safety. In the words of Grand Duchess Augusta of Mecklenburg-Strelitz, "We must give credit to old Charlotte for "really" saving [Alexandra's] life."

Alexandra again looked after her grandchildren when George and Mary went on a second tour, this time to British India, over the winter of 1905–06. Her father, King Christian IX of Denmark, died that January. Eager to retain their family links, both to each other and to Denmark, in 1907 Alexandra and her sister, the Dowager Empress of Russia, purchased a villa north of Copenhagen, Hvidøre, as a private getaway.

Alexandra was denied access to the king's briefing papers and excluded from some of his foreign tours to prevent her meddling in diplomatic matters. She was deeply distrustful of Germans, and invariably opposed anything that favoured German expansion or interests. For example, in 1890 Alexandra wrote a memorandum, distributed to senior British ministers and military personnel, warning against the planned exchange of the British North Sea island of Heligoland for the German colony of Zanzibar, pointing out Heligoland's strategic significance and that it could be used either by Germany to launch an attack, or by Britain to contain German aggression. Despite this, the exchange went ahead anyway. The Germans fortified the island and, in the words of Robert Ensor and as Alexandra had predicted, it "became the keystone of Germany's maritime position for offence as well as for defence". The "Frankfurter Zeitung" was outspoken in its condemnation of Alexandra and her sister, the Dowager Empress of Russia, saying that the pair were "the centre of the international anti-German conspiracy". She despised and distrusted her nephew, German Emperor Wilhelm II, calling him in 1900 "inwardly our enemy".

In 1910, Alexandra became the first queen consort to visit the British House of Commons during a debate. In a remarkable departure from precedent, for two hours she sat in the Ladies' Gallery overlooking the chamber while the Parliament Bill, to remove the right of the House of Lords to veto legislation, was debated. Privately, Alexandra disagreed with the bill. Shortly afterwards, she left to visit her brother, King George I of Greece, in Corfu. While there, she received news that King Edward was seriously ill. Alexandra returned at once and arrived just the day before her husband died. In his last hours, she personally administered oxygen from a gas cylinder to help him breathe. She told Frederick Ponsonby, "I feel as if I had been turned into stone, unable to cry, unable to grasp the meaning of it all." Later that year she moved out of Buckingham Palace to Marlborough House, but she retained possession of Sandringham. The new king, Alexandra's son George, soon faced a decision over the Parliament Bill. Despite her personal views, Alexandra supported her son's reluctant agreement to Prime Minister H. H. Asquith's request to create sufficient Liberal peers after a general election if the Lords continued to block the legislation.

From Edward's death, Alexandra was queen mother, being a dowager queen and the mother of the reigning monarch. She did not attend her son's coronation in 1911 since it was not customary for a crowned queen to attend the coronation of another king or queen, but otherwise continued the public side of her life, devoting time to her charitable causes. One such cause included Alexandra Rose Day, where artificial roses made by people with disabilities were sold in aid of hospitals by women volunteers. During the First World War, the custom of hanging the banners of foreign princes invested with Britain's highest order of knighthood, the Order of the Garter, in St George's Chapel, Windsor Castle, came under criticism, as the German members of the Order were fighting against Britain. Alexandra joined calls to "have down those hateful German banners". Driven by public opinion, but against his own wishes, the king had the banners removed but to Alexandra's dismay he had down not only "those vile Prussian banners" but also those of her Hessian relations who were, in her opinion, "simply soldiers or vassals under that brutal German Emperor's orders". On 17 September 1916, she was at Sandringham during a Zeppelin air raid, but far worse was to befall other members of her family. In Russia, her nephew Tsar Nicholas II was overthrown and he, his wife and their children were killed by revolutionaries. Her sister the Dowager Empress was rescued from Russia in 1919 by and brought to England, where she lived for some time with Alexandra.

Alexandra retained a youthful appearance into her senior years, but during the war her age caught up with her. She took to wearing elaborate veils and heavy makeup, which was described by gossips as having her face "enamelled". She made no more trips abroad, and suffered increasing ill health. In 1920, a blood vessel in her eye burst, leaving her with temporary partial blindness. Towards the end of her life, her memory and speech became impaired. She died on 20 November 1925 at Sandringham after suffering a heart attack, and was buried in an elaborate tomb next to her husband in St George's Chapel, Windsor Castle.

The Queen Alexandra Memorial by Alfred Gilbert was unveiled on Alexandra Rose Day 8 June 1932 at Marlborough Gate, London. An ode in her memory, "So many true princesses who have gone", composed by the then Master of the King's Musick Sir Edward Elgar to words by the Poet Laureate John Masefield, was sung at the unveiling and conducted by the composer.

Alexandra was highly popular with the British public. After she married the Prince of Wales in 1863, a new park and "People's Palace", a public exhibition and arts centre under construction in north London, were renamed the Alexandra Palace and park to commemorate her. There are at least sixty-seven roads and streets in the Greater London area alone called Alexandra Road, Alexandra Avenue, Alexandra Gardens, Alexandra Close or Alexandra Street, all named after her. Unlike her husband and mother-in-law, she was not castigated by the press. Funds that she helped to collect were used to buy a river launch, called "Alexandra", to ferry the wounded during the Sudan campaign, and to fit out a hospital ship, named "The Princess of Wales", to bring back wounded from the Boer War. During the Boer War, Queen Alexandra's Imperial Military Nursing Service, later renamed Queen Alexandra's Royal Army Nursing Corps, was founded under Royal Warrant.

Alexandra had little understanding of money. The management of her finances was left in the hands of her loyal comptroller, Sir Dighton Probyn VC, who undertook a similar role for her husband. In the words of her grandson, Edward VIII (later the Duke of Windsor), "Her generosity was a source of embarrassment to her financial advisers. Whenever she received a letter soliciting money, a cheque would be sent by the next post, regardless of the authenticity of the mendicant and without having the case investigated." Though she was not always extravagant (she had her old stockings darned for re-use and her old dresses were recycled as furniture covers), she would dismiss protests about her heavy spending with a wave of a hand or by claiming that she had not heard.

She hid a small scar on her neck, which was probably the result of a childhood operation, by wearing choker necklaces and high necklines, setting fashions which were adopted for fifty years. Alexandra's effect on fashion was so profound that society ladies even copied her limping gait, after her serious illness in 1867 left her with a stiff leg. This came to be known as the "Alexandra limp". She used predominantly the London fashion houses; her favourite was Redfern's, but she shopped occasionally at Doucet and Fromont of Paris.

Queen Alexandra has been portrayed on television by Deborah Grant and Helen Ryan in "Edward the Seventh", Ann Firbank in "Lillie", Maggie Smith in "All the King's Men", and Bibi Andersson in "The Lost Prince". She was portrayed in film by Helen Ryan again in the 1980 film "The Elephant Man", Sara Stewart in the 1997 film "Mrs Brown", and Julia Blake in the 1999 film "Passion". In a 1980 stage play by Royce Ryton, "Motherdear", she was portrayed by Margaret Lockwood in her last acting role.


In 1901, she became the first woman since 1488 to be made a Lady of the Garter. Other honours she held included Member First Class of the Royal Order of Victoria and Albert, Lady of the Imperial Order of the Crown of India, and Lady of Justice of the Order of St. John of Jerusalem. On 1 January 1918, she was appointed a Dame Grand Cross of the Order of the British Empire.

Among foreign honours received by Queen Alexandra was the Japanese Order of the Precious Crown, delivered to her on behalf of Emperor Meiji by Prince Komatsu Akihito when he visited the United Kingdom in June 1902 to attend the coronation. At the same time she also received the Order of Nishan-i-Sadakat from the Sultan of the Ottoman Empire, despatched to London by a special messenger together with their coronation representatives.

Queen Alexandra's arms upon the accession of her husband in 1901 were the royal coat of arms of the United Kingdom impaled with the arms of her father, the King of Denmark. The shield is surmounted by the imperial crown, and supported by the crowned lion of England and a wild man or savage from the Danish royal arms.





</doc>
<doc id="48927" url="https://en.wikipedia.org/wiki?curid=48927" title="Camille Saint-Saëns">
Camille Saint-Saëns

Charles-Camille Saint-Saëns (; 9 October 183516 December 1921) was a French composer, organist, conductor and pianist of the Romantic era. His best-known works include Introduction and Rondo Capriccioso (1863), the Second Piano Concerto (1868), the First Cello Concerto (1872), "Danse macabre" (1874), the opera "Samson and Delilah" (1877), the Third Violin Concerto (1880), the Third ("Organ") Symphony (1886) and "The Carnival of the Animals" (1886).

Saint-Saëns was a musical prodigy; he made his concert debut at the age of ten. After studying at the Paris Conservatoire he followed a conventional career as a church organist, first at Saint-Merri, Paris and, from 1858, La Madeleine, the official church of the French Empire. After leaving the post twenty years later, he was a successful freelance pianist and composer, in demand in Europe and the Americas.

As a young man, Saint-Saëns was enthusiastic for the most modern music of the day, particularly that of Schumann, Liszt and Wagner, although his own compositions were generally within a conventional classical tradition. He was a scholar of musical history, and remained committed to the structures worked out by earlier French composers. This brought him into conflict in his later years with composers of the impressionist and dodecaphonic schools of music; although there were neoclassical elements in his music, foreshadowing works by Stravinsky and Les Six, he was often regarded as a reactionary in the decades around the time of his death.

Saint-Saëns held only one teaching post, at the École de Musique Classique et Religieuse in Paris, and remained there for less than five years. It was nevertheless important in the development of French music: his students included Gabriel Fauré, among whose own later pupils was Maurice Ravel. Both of them were strongly influenced by Saint-Saëns, whom they revered as a genius.

Saint-Saëns was born in Paris, the only child of Jacques-Joseph-Victor Saint-Saëns (1798–1835), an official in the French Ministry of the Interior, and Françoise-Clémence, "née" Collin. Victor Saint-Saëns was of Norman ancestry, and his wife was from an Haute-Marne family; their son, born in the Rue du Jardinet in the 6th arrondissement of Paris, and baptised at the nearby church of Saint-Sulpice, always considered himself a true Parisian. Less than two months after the christening, Victor Saint-Saëns died of consumption on the first anniversary of his marriage. The young Camille was taken to the country for the sake of his health, and for two years lived with a nurse at Corbeil, to the south of Paris.
When Saint-Saëns was brought back to Paris he lived with his mother and her widowed aunt, Charlotte Masson. Before he was three years old he displayed perfect pitch and enjoyed picking out tunes on the piano. His great-aunt taught him the basics of pianism, and when he was seven he became a pupil of Camille-Marie Stamaty, a former pupil of Friedrich Kalkbrenner. Stamaty required his students to play while resting their forearms on a bar situated in front of the keyboard, so that all the pianist's power came from the hands and fingers rather than the arms, which, Saint-Saëns later wrote, was good training. Clémence Saint-Saëns, well aware of her son's precocious talent, did not wish him to become famous too young. The music critic Harold C. Schonberg wrote of Saint-Saëns in 1969, "It is not generally realized that he was the most remarkable child prodigy in history, and that includes Mozart." The boy gave occasional performances for small audiences from the age of five, but it was not until he was ten that he made his official public debut, at the Salle Pleyel, in a programme that included Mozart's Piano Concerto in B (K450), and Beethoven's Third Piano Concerto. Through Stamaty's influence, Saint-Saëns was introduced to the composition professor Pierre Maleden and the organ teacher Alexandre Pierre François Boëly. From the latter he acquired a lifelong love of the music of Bach, which was then little known in France.

As a schoolboy Saint-Saëns was outstanding in many subjects. In addition to his musical prowess, he distinguished himself in the study of French literature, Latin and Greek, divinity, and mathematics. His interests included philosophy, archaeology and astronomy, of which, particularly the last, he remained a talented amateur in later life.
In 1848, at the age of thirteen, Saint-Saëns was admitted to the Paris Conservatoire, France's foremost music academy. The director, Daniel Auber, had succeeded Luigi Cherubini in 1842, and brought a more relaxed regime than that of his martinet predecessor, though the curriculum remained conservative. Students, even outstanding pianists like Saint-Saëns, were encouraged to specialise in organ studies, because a career as a church organist was seen to offer more opportunities than that of a solo pianist. His organ professor was François Benoist, whom Saint-Saëns considered a mediocre organist but a first-rate teacher; his pupils included Adolphe Adam, César Franck, Charles Alkan, Louis Lefébure-Wély and Georges Bizet. In 1851 Saint-Saëns won the Conservatoire's top prize for organists, and in the same year he began formal composition studies. His professor was a protégé of Cherubini, Fromental Halévy, whose pupils included Charles Gounod and Bizet.

Saint-Saëns's student compositions included a symphony in A major (1850) and a choral piece, "Les Djinns" (1850), after an eponymous poem by Victor Hugo. He competed for France's premier musical award, the Prix de Rome, in 1852 but was unsuccessful. Auber believed that the prize should have gone to Saint-Saëns, considering him to have more promise than the winner, Léonce Cohen, who made little mark during the rest of his career. In the same year Saint-Saëns had greater success in a competition organised by the Société Sainte-Cécile, Paris, with his "Ode à Sainte-Cécile", for which the judges unanimously voted him the first prize. The first piece the composer acknowledged as a mature work and gave an opus number was "Trois Morceaux" for harmonium (1852).

On leaving the Conservatoire in 1853, Saint-Saëns accepted the post of organist at the ancient Parisian church of Saint-Merri near the Hôtel de Ville. The parish was substantial, with 26,000 parishioners; in a typical year there were more than two hundred weddings, the organist's fees from which, together with fees for funerals and his modest basic stipend, gave Saint-Saëns a comfortable income. The organ, the work of François-Henri Clicquot, had been badly damaged in the aftermath of the French Revolution and imperfectly restored. The instrument was adequate for church services but not for the ambitious recitals that many high-profile Parisian churches offered. With enough spare time to pursue his career as a pianist and composer, Saint-Saëns composed what became his opus 2, the Symphony in E (1853). This work, with military fanfares and augmented brass and percussion sections, caught the mood of the times in the wake of the popular rise to power of Napoleon III and the restoration of the French Empire. The work brought the composer another first prize from the Société Sainte-Cécile.

Among the musicians who were quick to spot Saint-Saëns's talent were the composers Gioachino Rossini, Hector Berlioz and Franz Liszt, and the influential singer Pauline Viardot, who all encouraged him in his career. In early 1858 Saint-Saëns moved from Saint-Merri to the high-profile post of organist of La Madeleine, the official church of the Empire; Liszt heard him playing there and declared him the greatest organist in the world.

Although in later life he had a reputation for outspoken musical conservatism, in the 1850s Saint-Saëns supported and promoted the most modern music of the day, including that of Liszt, Robert Schumann and Richard Wagner. Unlike many French composers of his own and the next generation, Saint-Saëns, for all his enthusiasm for and knowledge of Wagner's operas, was not influenced by him in his own compositions. He commented, "I admire deeply the works of Richard Wagner in spite of their bizarre character. They are superior and powerful, and that is sufficient for me. But I am not, I have never been, and I shall never be of the Wagnerian religion."

In 1861 Saint-Saëns accepted his only post as a teacher, at the École de Musique Classique et Religieuse, Paris, which Louis Niedermeyer had established in 1853 to train first-rate organists and choirmasters for the churches of France. Niedermeyer himself was professor of piano; when he died in March 1861, Saint-Saëns was appointed to take charge of piano studies. He scandalised some of his more austere colleagues by introducing his students to contemporary music, including that of Schumann, Liszt and Wagner. His best-known pupil, Gabriel Fauré, recalled in old age:

Saint-Saëns further enlivened the academic regime by writing, and composing incidental music for, a one-act farce performed by the students (including André Messager). He conceived his best-known piece, "The Carnival of the Animals", with his students in mind, but did not finish composing it until 1886, more than twenty years after he left the Niedermeyer school.

In 1864 Saint-Saëns caused some surprise by competing a second time for the Prix de Rome. Many in musical circles were puzzled by his decision to enter the competition again, now that he was establishing a reputation as a soloist and composer. He was once more unsuccessful. Berlioz, one of the judges, wrote:

According to the musical scholar Jean Gallois, it was apropos of this episode that Berlioz made his well-known "bon mot" about Saint-Saëns, "He knows everything, but lacks inexperience" ("Il sait tout, mais il manque d'inexpérience"). The winner, Victor Sieg, had a career no more notable than that of the 1852 winner, but Saint-Saëns's biographer Brian Rees speculates that the judges may "have been seeking signs of genius in the midst of tentative effort and error, and considered that Saint-Saëns had reached his summit of proficiency". The suggestion that Saint-Saëns was more proficient than inspired dogged his career and posthumous reputation. He himself wrote, "Art is intended to create beauty and character. Feeling only comes afterwards and art can very well do without it. In fact, it is very much better off when it does." The biographer Jessica Duchen writes that he was "a troubled man who preferred not to betray the darker side of his soul". The critic and composer Jeremy Nicholas observes that this reticence has led many to underrate the music; he quotes such slighting remarks as "Saint-Saëns is the only great composer who wasn't a genius", and "Bad music well written".
While teaching at the Niedermeyer school Saint-Saëns put less of his energy into composing and performing, but after he left in 1865 he pursued both aspects of his career with vigour. In 1867 his cantata "Les noces de Prométhée" beat more than a hundred other entries to win the composition prize of the Grande Fête Internationale in Paris, for which the jury included Auber, Berlioz, Gounod, Rossini and Giuseppe Verdi. In 1868 he premiered the first of his orchestral works to gain a permanent place in the repertoire, his Second Piano Concerto. Playing this and other works he became a noted figure in the musical life of Paris and other cities in France and abroad during the 1860s.

In 1870, concerned at the dominance of German music and the lack of opportunity for young French composers to have their works played, Saint-Saëns and Romain Bussine, professor of singing at the Conservatoire, discussed the founding of a society to promote new French music. Before they could take the proposal further, the Franco-Prussian War broke out. Saint-Saëns served in the National Guard during the war. During the brief but bloody Paris Commune that followed, his superior at the Madeleine, the Abbé Deguerry, was murdered by rebels; Saint-Saëns was fortunate to escape to temporary exile in England where he arrived in May 1871. With the help of George Grove and others he supported himself while there, giving recitals. Returning to Paris in the same year, he found that anti-German sentiments had considerably enhanced support for the idea of a pro-French musical society. The Société Nationale de Musique, with its motto, ""Ars Gallica"", had been established in February 1871, with Bussine as president, Saint-Saëns as vice-president and Henri Duparc, Fauré, Franck and Jules Massenet among its founder-members.
As an admirer of Liszt's innovative symphonic poems, Saint-Saëns enthusiastically adopted the form; his first "poème symphonique" was "Le Rouet d'Omphale" (1871), premiered at a concert of the Sociéte Nationale in January 1872. In the same year, after more than a decade of intermittent work on operatic scores, Saint-Saëns finally had one of his operas staged. "La princesse jaune" ("The Yellow Princess"), a one-act, light romantic piece, was given at the Opéra-Comique, Paris in June. It ran for five performances.

Throughout the 1860s and early 1870s, Saint-Saëns had continued to live a bachelor existence, sharing a large fourth-floor flat in the Rue du Faubourg Saint-Honoré with his mother. In 1875, he surprised many by marrying. The groom was approaching forty and his bride was nineteen; she was Marie-Laure Truffot, the sister of one of the composer's pupils. The marriage was not a success. In the words of the biographer Sabina Teller Ratner, "Saint-Saëns's mother disapproved, and her son was difficult to live with". Saint-Saëns and his wife moved to the Rue Monsieur-le-Prince, in the Latin Quarter; his mother moved with them. The couple had two sons, both of whom died in infancy. In 1878, the elder, André, aged two, fell from a window of the flat and was killed; the younger, Jean-François, died of pneumonia six weeks later, aged six months. Saint-Saëns and Marie-Laure continued to live together for three years, but he blamed her for André's accident; the double blow of their loss effectively destroyed the marriage.
For a French composer of the 19th century, opera was seen as the most important type of music. Saint-Saëns's younger contemporary and rival, Massenet, was beginning to gain a reputation as an operatic composer, but Saint-Saëns, with only the short and unsuccessful "La princesse jaune" staged, had made no mark in that sphere. In February 1877, he finally had a full-length opera staged. His four-act "drame lyricque", "Le timbre d'argent" ("The Silver Bell"), to Jules Barbier's and Michel Carré's libretto, reminiscent of the Faust legend, had been in rehearsal in 1870, but the outbreak of war halted the production. The work was eventually presented by the Théâtre Lyrique company of Paris; it ran for eighteen performances.

The dedicatee of the opera, Albert Libon, died three months after the premiere, leaving Saint-Saëns a large legacy "To free him from the slavery of the organ of the Madeleine and to enable him to devote himself entirely to composition". Saint-Saëns, unaware of the imminent bequest, had resigned his position shortly before his friend died. He was not a conventional Christian, and found religious dogma increasingly irksome; he had become tired of the clerical authorities' interference and musical insensitivity; and he wanted to be free to accept more engagements as a piano soloist in other cities. After this he never played the organ professionally in a church service, and rarely played the instrument at all. He composed a "Messe de Requiem" in memory of his friend, which was performed at Saint-Sulpice to mark the first anniversary of Libon's death; Charles-Marie Widor played the organ and Saint-Saëns conducted.

In December 1877, Saint-Saëns had a more solid operatic success, with "Samson et Dalila", his one opera to gain and keep a place in the international repertoire. Because of its biblical subject, the composer had met many obstacles to its presentation in France, and through Liszt's influence the premiere was given at Weimar in a German translation. Although the work eventually became an international success it was not staged at the Paris Opéra until 1892.

Saint-Saëns was a keen traveller. From the 1870s until the end of his life he made 179 trips to 27 countries. His professional engagements took him most often to Germany and England; for holidays, and to avoid Parisian winters which affected his weak chest, he favoured Algiers and various places in Egypt.

Saint-Saëns was elected to the Institut de France in 1881, at his second attempt, having to his chagrin been beaten by Massenet in 1878. In July of that year he and his wife went to the Auvergnat spa town of La Bourboule for a holiday. On 28 July he disappeared from their hotel, and a few days later his wife received a letter from him to say that he would not be returning. They never saw each other again. Marie Saint-Saëns returned to her family, and lived until 1950, dying near Bordeaux at the age of ninety-five. Saint-Saëns did not divorce his wife and remarry, nor did he form any later intimate relationship with a woman. Rees comments that although there is no firm evidence, some biographers believe that Saint-Saëns was more attracted to his own sex than to women. After the death of his children and collapse of his marriage, Saint-Saëns increasingly found a surrogate family in Fauré and his wife, Marie, and their two sons, to whom he was a much-loved honorary uncle. Marie told him, "For us you are one of the family, and we mention your name ceaselessly here."
In the 1880s Saint-Saëns continued to seek success in the opera house, an undertaking made the more difficult by an entrenched belief among influential members of the musical establishment that it was unthinkable that a pianist, organist and symphonist could write a good opera. He had two operas staged during the decade, the first being "Henry VIII" (1883) commissioned by the Paris Opéra. Although the libretto was not of his choosing, Saint-Saëns, normally a fluent, even facile composer, worked at the score with unusual diligence to capture a convincing air of 16th-century England. The work was a success, and was frequently revived during the composer's lifetime. When it was produced at Covent Garden in 1898, "The Era" commented that though French librettists generally "make a pretty hash of British history", this piece was "not altogether contemptible as an opera story".

The open-mindedness of the Société Nationale had hardened by the mid-1880s into a dogmatic adherence to Wagnerian methods favoured by Franck's pupils, led by Vincent d'Indy. They had begun to dominate the organisation and sought to abandon its ""Ars Gallica"" ethos of commitment to French works. Bussine and Saint-Saëns found this unacceptable, and resigned in 1886. Having long pressed the merits of Wagner on a sometimes sceptical French public, Saint-Saëns was now becoming worried that the German's music was having an excessive impact on young French composers. His increasing caution towards Wagner developed in later years into stronger hostility, directed as much at Wagner's political nationalism as at his music.

By the 1880s Saint-Saëns was an established favourite with audiences in England, where he was widely regarded as the greatest living French composer. In 1886 the Philharmonic Society of London commissioned what became one of his most popular and respected works, the Third ("Organ") Symphony. It was premiered in London at a concert in which Saint-Saëns appeared as conductor of the symphony and as soloist in Beethoven's Fourth Piano Concerto, conducted by Sir Arthur Sullivan. The success of the symphony in London was considerable, but was surpassed by the ecstatic welcome the work received at its Paris premiere early the following year. Later in 1887 Saint-Saëns's "drame lyrique" "Proserpine" opened at the Opéra-Comique. It was well received and seemed to be heading for a substantial run when the theatre burnt down within weeks of the premiere and the production was lost.

In December 1888 Saint-Saëns's mother died. He felt her loss deeply, and was plunged into depression and insomnia, even contemplating suicide. He left Paris and stayed in Algiers, where he recuperated until May 1889, walking and reading but unable to compose.

During the 1890s Saint-Saëns spent much time on holiday, travelling overseas, composing less and performing more infrequently than before. A planned visit to perform in Chicago fell through in 1893. He wrote one opera, the comedy "Phryné" (1893), and together with Paul Dukas helped to complete "Frédégonde" (1895) an opera left unfinished by Ernest Guiraud, who died in 1892. "Phryné" was well received, and prompted calls for more comic operas at the Opéra-Comique, which had latterly been favouring grand opera. His few choral and orchestral works from the 1890s are mostly short; the major concert pieces from the decade were the single movement fantasia "Africa" (1891) and his Fifth ("Egyptian") Piano Concerto, which he premiered at a concert in 1896 marking the fiftieth anniversary of his début at the Salle Pleyel in 1846. Before playing the concerto he read out a short poem he had written for the event, praising his mother's tutelage and his public's long support.

Among the concerts that Saint-Saëns undertook during the decade was one at Cambridge in June 1893, when he, Bruch and Tchaikovsky performed at an event presented by Charles Villiers Stanford for the Cambridge University Musical Society, marking the award of honorary degrees to all three visitors. Saint-Saëns greatly enjoyed the visit, and even spoke approvingly of the college chapel services: "The demands of English religion are not excessive. The services are very short, and consist chiefly of listening to good music extremely well sung, for the English are excellent choristers". His mutual regard for British choirs continued for the rest of his life, and one of his last large-scale works, the oratorio "The Promised Land", was composed for the Three Choirs Festival of 1913.

In 1900, after ten years without a permanent home in Paris, Saint-Saëns took a flat in the rue de Courcelles, not far from his old residence in the rue du Faubourg Saint-Honoré. This remained his home for the rest of his life. He continued to travel abroad frequently, but increasingly often to give concerts rather than as a tourist. He revisited London, where he was always a welcome visitor, went to Berlin, where until the First World War, he was greeted with honour, and travelled in Italy, Spain, Monaco and provincial France. In 1906 and 1909 he made highly successful tours of the US, as a pianist and conductor. In New York on his second visit he premiered his "Praise ye the Lord" for double choir, orchestra and organ, which he composed for the occasion.

Despite his growing reputation as a musical reactionary, Saint-Saëns was, according to Gallois, probably the only French musician who travelled to Munich to hear the premiere of Mahler's Eighth Symphony in 1910. Nonetheless, by the 20th century Saint-Saëns had lost much of his enthusiasm for modernism in music. Though he strove to conceal it from Fauré, he did not understand or like the latter's opera "Pénélope" (1913), of which he was the dedicatee. In 1917 Francis Poulenc, at the beginning of his career as a composer, was dismissive when Ravel praised Saint-Saëns as a genius. By this time, various strands of new music were emerging with which Saint-Saëns had little in common. His classical instincts for form put him at odds with what seemed to him the shapelessness and structure of the musical impressionists, led by Debussy. Nor did the theories of Arnold Schönberg's dodecaphony commend themselves to Saint-Saëns:

Holding such conservative views, Saint-Saëns was out of sympathy – and out of fashion – with the Parisian musical scene of the early 20th century, fascinated as it was with novelty. It is often said that he walked out, scandalised, from the premiere of Vaslav Nijinsky and Igor Stravinsky's ballet "The Rite of Spring" in 1913. In fact, according to Stravinsky, Saint-Saëns was not present on that occasion, but at the first concert performance of the piece the following year he expressed the firm view that Stravinsky was insane.

When a group of French musicians led by Saint-Saëns tried to organise a boycott of German music during the First World War, Fauré and Messager dissociated themselves from the idea, though the disagreement did not affect their friendship with their old teacher. They were privately concerned that their friend was in danger of looking foolish with his excess of patriotism, and his growing tendency to denounce in public the works of rising young composers, as in his condemnation of Debussy's "En blanc et noir" (1915): "We must at all costs bar the door of the Institut against a man capable of such atrocities; they should be put next to the cubist pictures." His determination to block Debussy's candidacy for election to the Institut was successful, and caused bitter resentment from the younger composer's supporters. Saint-Saëns's response to the neoclassicism of Les Six was equally uncompromising: of Darius Milhaud's polytonal symphonic suite "Protée" (1919) he commented, "fortunately, there are still lunatic asylums in France".
Saint-Saëns gave what he intended to be his farewell concert as a pianist in Paris in 1913, but his retirement was soon in abeyance as a result of the war, during which he gave many performances in France and elsewhere, raising money for war charities. These activities took him across the Atlantic, despite the danger from German warships.

In November 1921, Saint-Saëns gave a recital at the Institut for a large invited audience; it was remarked that his playing was as vivid and precise as ever, and that his personal bearing was admirable for a man of eighty-six. He left Paris a month later for Algiers, with the intention of wintering there, as he had long been accustomed to do. While there, he died without warning of a heart attack on 16 December 1921. His body was taken back to Paris, and after a state funeral at the Madeleine he was buried at the Cimetière de Montparnasse. Heavily veiled, in an inconspicuous place among the mourners from France's political and artistic élite, was his widow, Marie-Laure, whom he had last seen in 1881.

In the early years of the 20th century, the anonymous author of the article on Saint-Saëns in "Grove's Dictionary of Music and Musicians" wrote:

Although a keen modernist in his youth, Saint-Saëns was always deeply aware of the great masters of the past. In a profile of him written to mark his eightieth birthday, the critic DCParker wrote, "That Saint-Saëns knows Rameau... Bach and Handel, Haydn and Mozart, must be manifest to all who are familiar with his writings. His love for the classical giants and his sympathy with them form, so to speak, the foundation of his art."

Less attracted than some of his French contemporaries to the continuous stream of music popularised by Wagner, Saint-Saëns often favoured self-contained melodies. Though they are frequently, in Ratner's phrase, "supple and pliable", more often than not they are constructed in three- or four-bar sections, and the "phrase pattern AABB is characteristic". An occasional tendency to neoclassicism, influenced by his study of French baroque music, is in contrast with the colourful orchestral music more widely identified with him. "Grove" observes that he makes his effects more by characterful harmony and rhythms than by extravagant scoring. In both of those areas of his craft he was normally content with the familiar. Rhythmically, he inclined to standard double, triple or compound metres (although "Grove" points to a 5/4 passage in the Piano Trio and another in 7/4 in the Polonaise for two pianos). From his time at the Conservatoire he was a master of counterpoint; contrapuntal passages crop up, seemingly naturally, in many of his works.

The authors of the 1955 "The Record Guide", Edward Sackville-West and Desmond Shawe-Taylor write that Saint-Saëns's brilliant musicianship was "instrumental in drawing the attention of French musicians to the fact that that there are other forms of music besides opera." In the 2001 edition of "Grove's Dictionary", Ratner and Daniel Fallon, analysing Saint-Saëns's orchestral music rate the unnumbered Symphony in A (c.1850) as the most ambitious of the composer's juvenilia. Of the works of his maturity, the First Symphony (1853) is a serious and large-scale work, in which the influence of Schumann is detectable. The "Urbs Roma" Symphony (1856) in some ways represents a backward step, being less deftly orchestrated, and "thick and heavy" in its effect. Ratner and Fallon praise the Second Symphony (1859) as a fine example of orchestral economy and structural cohesion, with passages that show the composer's mastery of fugal writing. The best known of the symphonies is the Third (1886) which, unusually, has prominent parts for piano and organ. It opens in C minor and ends in C major with a stately chorale tune. The four movements are clearly divided into two pairs, a practice Saint-Saëns used elsewhere, notably in the Fourth Piano Concerto (1875) and the First Violin Sonata (1885). The work is dedicated to the memory of Liszt, and uses a recurring "motif" treated in a Lisztian style of thematic transformation.
Saint-Saëns's four symphonic poems follow the model of those by Liszt, though, in Sackville-West's and Shawe-Taylor's view, without the "vulgar blatancy" to which the earlier composer was prone. The most popular of the four is "Danse macabre" (1874) depicting skeletons dancing at midnight. Saint-Saëns generally achieved his orchestral effects by deft harmonisation rather than exotic instrumentation, but in this piece he featured the xylophone prominently, representing the rattling bones of the dancers. "Le Rouet d'Omphale" (1870) was composed soon after the horrors of the Commune, but its lightness and delicate orchestration give no hint of recent tragedies. Rees rates "Phaëton" (1873) as the finest of the symphonic poems, belying the composer's professed indifference to melody, and inspired in its depiction of the mythical hero and his fate. A critic at the time of the premiere took a different view, hearing in the piece "the noise of a hack coming down from Montmartre" rather than the galloping fiery horses of Greek legend that inspired the piece. The last of the four symphonic poems, "La jeunesse d'Hercule" ("Hercules's Youth", 1877) was the most ambitious of the four, which, Harding suggests, is why it is the least successful. In the judgment of the critic Roger Nichols these orchestral works, which combine striking melodies, strength of construction and memorable orchestration "set new standards for French music and were an inspiration to such young composers as Ravel".

Saint-Saëns wrote a one-act ballet, "Javot" (1896), the score for the film "L'assassinat du duc de Guise" (1908), and incidental music to a dozen plays between 1850 and 1916. Three of these scores were for revivals of classics by Molière and Racine, for which Saint-Saëns's deep knowledge of French baroque scores was reflected in his scores, in which he incorporated music by Lully and Charpentier.

Saint-Saëns was the first major French composer to write piano concertos. His First, in D (1858), in conventional three-movement form, is not well known, but the Second, in G minor (1868) is one of his most popular works. The composer experimented with form in this piece, replacing the customary sonata form first movement with a more discursive structure, opening with a solemn cadenza. The scherzo second movement and "presto" finale are in such contrast with the opening that the pianist Zygmunt Stojowski commented that the work "begins like Bach and ends like Offenbach". The Third Piano Concerto, in E (1869) has another high-spirited finale, but the earlier movements are more classical, the texture clear, with graceful melodic lines. The Fourth, in C minor (1875) is probably the composer's best-known piano concerto after the Second. It is in two movements, each comprising two identifiable sub-sections, and maintains a thematic unity not found in the composer's other piano concertos. According to some sources it was this piece that so impressed Gounod that he dubbed Saint-Saëns "the Beethoven of France" (other sources base that distinction on the Third Symphony). The Fifth and last piano concerto, in F major, was written in 1896, more than twenty years after its predecessor. The work is known as the "Egyptian" concerto; it was written while the composer was wintering in Luxor, and incorporates a tune he heard Nile boatmen singing.

The First Cello Concerto, in A minor (1872) is a serious although animated work, in a single continuous movement with an unusually turbulent first section. It is among the most popular concertos in the cello repertory, much favoured by Pablo Casals and later players. The Second, in D minor (1902), like the Fourth Piano Concerto, consists of two movements each subdivided into two distinct sections. It is more purely virtuosic than its predecessor: Saint-Saëns commented to Fauré that it would never be as popular as the First because it was too difficult. There are three violin concertos; the first to be composed dates from 1858 but was not published until 1879, as the composer's Second, in C major. The First, in A, was also completed in 1858. It is a short work, its single 314-bar movement lasting less than a quarter of an hour. The Second, in conventional three-movement concerto form, is twice as long as the First, and is the least popular of the three: the thematic catalogue of the composer's works lists only three performances in his lifetime. The Third, in B minor, written for Pablo de Sarasate, is technically challenging for the soloist, although the virtuoso passages are balanced by intervals of pastoral serenity. It is by some margin the most popular of the three violin concertos, but Saint-Saëns's best-known concertante work for violin and orchestra is probably the Introduction and Rondo Capriccioso, in A minor, Op. 28, a single-movement piece, also written for Sarasate, dating from 1863. It changes from a wistful opening to a swaggering main theme, described as faintly sinister by the critic Gerald Larner, who goes on, "After a multi-stopped cadenza ... the solo violin makes a breathless sprint through the coda to the happy ending in A major".

Discounting his collaboration with Dukas in the completion of Guiraud's unfinished "Frédégonde", Saint-Saëns wrote twelve operas, two of which are "opéras comiques". During the composer's lifetime his "Henry VIII" became a repertory piece; since his death only "Samson et Dalila" has been regularly staged, although according to Schonberg, "Ascanio" (1890) is considered by experts to be a much finer work. The critic Ronald Crichton writes that for all his experience and musical skill, Saint-Saëns "lacked the 'nose' of the theatre animal granted, for example, to Massenet who in other forms of music was his inferior". In a 2005 study, the musical scholar Steven Huebner contrasts the two composers: "Saint-Saëns obviously had no time for Massenet's histrionics". Saint-Saëns's biographer James Harding comments that it is regrettable that the composer did not attempt more works of a light-hearted nature, on the lines of "La princesse jaune", which Harding describes as like Sullivan "with a light French touch".

Although most of Saint-Saëns's operas have remained neglected, Crichton rates them as important in the history of French opera, as "a bridge between Meyerbeer and the serious French operas of the early 1890s". In his view, the operatic scores of Saint-Saëns have, in general, the strengths and weaknesses of the rest of his music – "lucid Mozartian transparency, greater care for form than for content... There is a certain emotional dryness; invention is sometimes thin, but the workmanship is impeccable." Stylistically, Saint-Saëns drew on a range of models. From Meyerbeer he drew the effective use of the chorus in the action of a piece; for "Henry VIII" he included Tudor music he had researched in London; in "La princesse jaune" he used an oriental pentatonic scale; from Wagner he derived the use of leitmotifs, which, like Massenet, he used sparingly. Huebner observes that Saint-Saëns was more conventional than Massenet so far as through composition is concerned, more often favouring discrete arias and ensembles, with less variety of tempo within individual numbers. In a survey of recorded opera Alan Blyth writes that Saint-Saëns "certainly learned much from Handel, Gluck, Berlioz, the Verdi of "Aida", and Wagner, but from these excellent models he forged his own style."

From the age of six and for the rest of his life Saint-Saëns composed "mélodies", writing more than 140. He regarded his songs as thoroughly and typically French, denying any influence from Schubert or other German composers of "Lieder". Unlike his protégé Fauré, or his rival Massenet, he was not drawn to the song cycle, writing only two during his long career – "Mélodies persanes" ("Persian Songs", 1870) and "Le Cendre rouge" ("The Red Ash Tree", 1914, dedicated to Fauré). The poet whose works he set most often was Victor Hugo; others included Alphonse de Lamartine, Pierre Corneille, Amable Tastu, and, in eight songs, Saint-Saëns himself: among his many non-musical talents he was an amateur poet. He was highly sensitive to word setting, and told the young composer Lili Boulanger that to write songs effectively musical talent was not enough: "you must study the French language in depth; it is indispensable." Most of the "mélodies" are written for piano accompaniment, but a few, including "Le lever du soleil sur le Nil" ("Sunrise over the Nile", 1898) and "Hymne à la paix" ("Hymn to Peace", 1919), are for voice and orchestra. His settings, and chosen verses, are generally traditional in form, contrasting with the free verse and less structured forms of a later generation of French composers, including Debussy.

Saint-Saëns composed more than sixty sacred vocal works, ranging from motets to masses and oratorios. Among the larger-scale compositions are the Requiem (1878) and the oratorios "Le déluge" (1875) and "The Promised Land" (1913) with an English text by Herman Klein. He was proud of his connection with British choirs, commenting, "One likes to be appreciated in the home, "par excellence", of oratorio." He wrote a smaller number of secular choral works, some for unaccompanied choir, some with piano accompaniment and some with full orchestra. In his choral works, Saint-Saëns drew heavily on tradition, feeling that his models should be Handel, Mendelssohn and other earlier masters of the genre. In Klein's view, this approach was old-fashioned, and the familiarity of Saint-Saëns's treatment of the oratorio form impeded his success in it.

Nichols comments that, although as a famous pianist Saint-Saëns wrote for the piano throughout his life, "this part of his oeuvre has made curiously little mark". Nichols excepts the "Étude en forme de valse" (1912), which he observes still attracts pianists eager to display their left-hand technique. Although Saint-Saëns was dubbed "the French Beethoven", and his Variations on a Theme of Beethoven in E (1874) is his most extended work for unaccompanied piano, he did not emulate his predecessor in composing piano sonatas. He is not known even to have contemplated writing one. There are sets of bagatelles (1855), études (two sets – 1899 and 1912) and fugues (1920), but in general Saint-Saëns's works for the piano are single short pieces. In addition to established forms such as the song without words (1871) and the mazurka (1862, 1871 and 1882) popularised by Mendelssohn and Chopin, respectively, he wrote descriptive pieces such as "Souvenir d'Italie" (1887), "Les cloches du soir" ("Evening bells", 1889) and "Souvenir d'Ismaïlia" (1895).
Unlike his pupil, Fauré, whose long career as a reluctant organist left no legacy of works for the instrument, Saint-Saëns published a modest number of pieces for organ solo. Some of them were written for use in church services – "Offertoire" (1853), "Bénédiction nuptiale" (1859), "Communion" (1859) and others. After he left the Madeleine in 1877 Saint-Saëns wrote ten more pieces for organ, mostly for concert use, including two sets of preludes and fugues (1894 and 1898). Some of the earlier works were written to be played on either the harmonium or the organ, and a few were primarily intended for the former.

Saint-Saëns wrote more than forty chamber works between the 1840s and his last years. One of the first of his major works in the genre was the Piano Quintet (1855). It is a straightforward, confident piece, in a conventional structure with lively outer movements and a central movement containing two slow themes, one chorale-like and the other "cantabile". The Septet (1880), for the unusual combination of trumpet, two violins, viola, cello, double bass and piano, is a neoclassical work that draws on 17th-century French dance forms. At the time of its composition Saint-Saëns was preparing new editions of the works of baroque composers including Rameau and Lully.

In Ratner's view, the most important of Saint-Saëns's chamber works are the sonatas: two for violin, two for cello, and one each for oboe, clarinet and bassoon, all seven with piano accompaniment. The First Violin Sonata dates from 1885, and is rated by "Grove's Dictionary" as one of the composer's best and most characteristic compositions. The Second (1896) signals a stylistic change in Saint-Saëns's work, with a lighter, clearer sound for the piano, characteristic of his music from then onwards. The First Cello Sonata (1872) was written after the death of the composer's great-aunt, who had taught him to play the piano more than thirty years earlier. It is a serious work, in which the main melodic material is sustained by the cello over a virtuoso piano accompaniment. Fauré called it the only cello sonata from any country to be of any importance. The Second (1905) is in four movements, and has the unusual feature of a theme and variations as its scherzo.
The woodwind sonatas are among the composer's last works. Ratner writes of them, "The spare, evocative, classical lines, haunting melodies, and superb formal structures underline these beacons of the neoclassical movement." Gallois comments that the Oboe Sonata begins like a conventional classical sonata, with an andantino theme; the central section has rich and colourful harmonies, and the molto allegro finale is full of delicacy, humour and charm with a form of tarantella. For Gallois the Clarinet Sonata is the most important of the three: he calls it "a masterpiece full of impishness, elegance and discreet lyricism" amounting to "a summary of the rest". The work contrasts a "doleful threnody" in the slow movement with the finale, which "pirouettes in 4/4 time", in a style reminiscent of the 18th century. The same commentator calls the Bassoon Sonata "a model of transparency, vitality and lightness", containing humorous touches but also moments of peaceful contemplation.

The composer's most famous work, "The Carnival of the Animals" (1887), although far from a typical chamber piece, is written for eleven players, and is considered by "Grove's Dictionary" to be part of Saint-Saëns's chamber output. "Grove" rates it as "his most brilliant comic work, parodying Offenbach, Berlioz, Mendelssohn, Rossini, his own "Danse macabre" and several popular tunes". He forbade performances of it during his lifetime, concerned that its frivolity would damage his reputation as a serious composer.

Saint-Saëns was a pioneer in recorded music. In June 1904 The Gramophone Company of London sent its producer Fred Gaisberg to Paris to record Saint-Saëns as accompanist to the mezzo-soprano Meyriane Héglon in arias from "Ascanio" and "Samson et Dalila", and as soloist in his own piano music, including an arrangement of sections of the Second Piano Concerto (without orchestra). Saint-Saëns made more recordings for the company in 1919.

In the early days of the LP record, Saint-Saëns's works were patchily represented on disc. "The Record Guide" (1955) lists one recording apiece of the Third Symphony, Second Piano Concerto and First Cello Concerto, alongside several versions of "Danse Macabre", "The Carnival of the Animals", the Introduction and Rondo Capriccioso and other short orchestral works. In the latter part of the 20th century and the early 21st, many more of the composer's works were released on LP and later CD and DVD. The 2008 "Penguin Guide to Recorded Classical Music" contains ten pages of listings of Saint-Saëns works, including all the concertos, symphonies, symphonic poems, sonatas and quartets. Also listed are an early Mass, collections of organ music, and choral songs. A recording of twenty-seven of Saint-Saëns's "mélodies" was released in 1997.

With the exception of "Samson et Dalila" the operas have been sparsely represented on disc. A recording of "Henry VIII" was issued on CD and DVD in 1992. "Hélène" was released on CD in 2008. There are several recordings of "Samson et Dalilah", under conductors including Sir Colin Davis, Georges Prêtre, Daniel Barenboim and Myung-Whun Chung.

Saint-Saëns was made a Chevalier of the Legion of Honour in 1867 and promoted to Officier in 1884, and Grand Croix in 1913. Foreign honours included the British Royal Victorian Order (CVO) in 1902, and honorary doctorates from the universities of Cambridge (1893) and Oxford (1907).

In its obituary notice, "The Times" commented:
In a short poem, "Mea culpa", published in 1890 Saint-Saëns accused himself of lack of decadence, and commented approvingly on the excessive enthusiasms of youth, lamenting that such things were not for him. An English commentator quoted the poem in 1910, observing, "His sympathies are with the young in their desire to push forward, because he has not forgotten his own youth when he championed the progressive ideals of the day." The composer sought a balance between innovation and traditional form. The critic Henry Colles, wrote, a few days after the composer's death:
"Grove" concludes its article on Saint-Saëns with the observation that although his works are remarkably consistent, "it cannot be said that he evolved a distinctive musical style. Rather, he defended the French tradition that threatened to be engulfed by Wagnerian influences and created the environment that nourished his successors".

Since the composer's death writers sympathetic to his music have expressed regret that he is known by the musical public for only a handful of his scores such as "The Carnival of the Animals", the Second Piano Concerto, the Organ Symphony, "Samson et Dalila", "Danse macabre" and the Introduction and Rondo Capriccioso. Among his large output, Nicholas singles out the Requiem, the Christmas Oratorio, the ballet "Javotte", the Piano Quartet, the Septet for trumpet, piano and strings, and the First Violin Sonata as neglected masterpieces. In 2004, the cellist Steven Isserlis said, "Saint-Saens is exactly the sort of composer who needs a festival to himself ... there are Masses, all of which are interesting. I've played all his cello music and there isn't one bad piece. His works are rewarding in every way. And he's an endlessly fascinating figure."




</doc>
<doc id="48951" url="https://en.wikipedia.org/wiki?curid=48951" title="Empress Matilda">
Empress Matilda

Empress Matilda (c. 7 February 110210 September 1167), also known as the Empress Maude, was one of the claimants to the English throne during the civil war known as the Anarchy. The daughter of King Henry I of England, she moved to Germany as a child when she married the future Holy Roman Emperor Henry V. She travelled with her husband into Italy in 1116, was controversially crowned in St. Peter's Basilica, and acted as the imperial regent in Italy. Matilda and Henry had no children, and when Henry died in 1125, the crown was claimed by Lothair II, one of his political enemies.

Meanwhile, Matilda's younger brother, William Adelin, died in the "White Ship" disaster of 1120, leaving England facing a potential succession crisis. On Emperor Henry V's death, Matilda was recalled to Normandy by her father, who arranged for her to marry Geoffrey of Anjou to form an alliance to protect his southern borders. Henry I had no further legitimate children and nominated Matilda as his heir, making his court swear an oath of loyalty to her and her successors, but the decision was not popular in the Anglo-Norman court. Henry died in 1135, but Matilda and Geoffrey faced opposition from the Norman barons and were unable to pursue their claims. The throne was instead taken by Matilda's cousin Stephen of Blois, who enjoyed the backing of the English Church. Stephen took steps to solidify his new regime but faced threats both from neighbouring powers and from opponents within his kingdom.

In 1139, Matilda crossed to England to take the kingdom by force, supported by her half-brother, Robert of Gloucester, and her uncle, King David I of Scotland, while Geoffrey focused on conquering Normandy. Matilda's forces captured Stephen at the Battle of Lincoln in 1141, but the Empress's attempt to be crowned at Westminster collapsed in the face of bitter opposition from the London crowds. As a result of this retreat, Matilda was never formally declared Queen of England, and was instead titled the Lady of the English. Robert was captured following the Rout of Winchester in 1141, and Matilda agreed to exchange him for Stephen. Matilda became trapped in Oxford Castle by Stephen's forces that winter, and was forced to escape across the frozen River Isis at night to avoid capture. The war degenerated into a stalemate, with Matilda controlling much of the south-west of England, and Stephen the south-east and the Midlands. Large parts of the rest of the country were in the hands of local, independent barons.

Matilda returned to Normandy, now in the hands of her husband, in 1148, leaving her eldest son to continue the campaign in England; he eventually succeeded to the throne as Henry II in 1154. She settled her court near Rouen and for the rest of her life concerned herself with the administration of Normandy, acting on Henry's behalf when necessary. Particularly in the early years of her son's reign, she provided political advice and attempted to mediate during the Becket controversy. She worked extensively with the Church, founding Cistercian monasteries, and was known for her piety. She was buried under the high altar at Bec Abbey after her death in 1167.

Matilda was born to Henry I, King of England and Duke of Normandy, and his first wife, Matilda of Scotland, possibly around 7 February 1102 at Sutton Courtenay in Oxfordshire. Henry was the youngest son of William the Conqueror, who had invaded England in 1066, creating an empire stretching into Wales. The invasion had created an Anglo-Norman elite, many with estates spread across both sides of the English Channel. These barons typically had close links to the kingdom of France, which was then a loose collection of counties and smaller polities, under only the minimal control of the king. Her mother Matilda was the daughter of King Malcolm III of Scotland, a member of the West Saxon royal family, and a descendant of Alfred the Great. For Henry, marrying Matilda of Scotland had given his reign increased legitimacy, and for her it had been an opportunity for high status and power in England.

Matilda had a younger, legitimate brother, William Adelin, and her father's relationships with numerous mistresses resulted in around 22 illegitimate siblings. Little is known about Matilda's earliest life, but she probably stayed with her mother, was taught to read, and was educated in religious morals. Among the nobles at her mother's court were her uncle David, later the King of Scotland, and aspiring nobles such as her half-brother Robert of Gloucester, her cousin Stephen of Blois and Brian Fitz Count. In 1108 Henry left Matilda and her brother in the care of Anselm, the Archbishop of Canterbury, while he travelled to Normandy; Anselm was a favoured cleric of Matilda's mother. There is no detailed description of Matilda's appearance; contemporaries described Matilda as being very beautiful, but this may have simply reflected the conventional practice among the chroniclers.

In late 1108 or early 1109, Henry V, then the King of the Romans, sent envoys to Normandy proposing that Matilda marry him, and wrote separately to her mother on the same matter. The match was attractive to the English king: his daughter would be marrying into one of the most prestigious dynasties in Europe, reaffirming his own, slightly questionable, status as the youngest son of a new royal house, and gaining him an ally in dealing with France. In return, Henry V would receive a dowry of 10,000 marks, which he needed to fund an expedition to Rome for his coronation as the Holy Roman Emperor. The final details of the deal were negotiated at Westminster in June 1109 and, as a result of her changing status, Matilda attended a royal council for the first time that October. She left England in February 1110 to make her way to Germany.

The couple met at Liège before travelling to Utrecht where, on 10 April, they became officially betrothed. On 25 July Matilda was crowned Queen of the Romans in a ceremony at Mainz. There was a considerable age gap between the couple, as Matilda was only eight years old while Henry was 24. After the betrothal she was placed into the custody of Bruno, the Archbishop of Trier, who was tasked with educating her in German culture, manners and government. In January 1114 Matilda was ready to be married to Henry, and their wedding was held at the city of Worms amid extravagant celebrations. Matilda now entered public life in Germany, complete with her own household.

Political conflict broke out across the Empire shortly after the marriage, triggered when Henry arrested his Chancellor Adalbert and various other German princes. Rebellions followed, accompanied by opposition from within the Church, which played an important part in administering the Empire, and this led to the formal excommunication of the Emperor by Pope Paschal II. Henry and Matilda marched over the Alps into Italy in early 1116, intent on settling matters permanently with the Pope. Matilda was now playing a full part in the imperial government, sponsoring royal grants, dealing with petitioners and taking part in ceremonial occasions. The rest of the year was spent establishing control of northern Italy, and in early 1117 the pair advanced on Rome itself.

Paschal fled when Henry and Matilda arrived, and in his absence the papal envoy Maurice Bourdin, later the Antipope Gregory VIII, crowned the pair at St. Peter's Basilica, probably that Easter and certainly by Pentecost. Matilda used these ceremonies to claim the title of the Empress of the Holy Roman Empire. The Empire was governed by elected monarchs who, like Henry V, had been selected by the major nobles to become the King of the Romans. These kings typically hoped to be subsequently crowned by the Pope as the Holy Roman Emperor, but this could not be guaranteed. Henry V had coerced the Pope into crowning him in 1111, but Matilda's own status was less clear. As a result of her marriage she was clearly the legitimate Queen of the Romans, a title that she used on her seal and charters, but it was uncertain if she had a legitimate claim to the title of empress.

Both Bourdin's status and the ceremonies themselves were deeply ambiguous. Strictly speaking, the ceremonies were not imperial coronations but instead were formal "crown-wearing" occasions, among the few times in the year when the rulers would wear their crowns in court. Bourdin had also been excommunicated by the time he conducted the second ceremony, and he was later to be deposed and imprisoned for life by the Pope. Nonetheless, Matilda maintained that she had been officially crowned as the empress in Rome. The titles of emperor and empress were not always consistently used in this period, and in any case her use of the title became widely accepted. Matilda chose not to dispute Anglo-Norman chroniclers who later incorrectly recorded that the Pope himself had crowned her in Rome.

In 1118, Henry returned north over the Alps into Germany to suppress fresh rebellions, leaving Matilda as his regent to govern Italy. There are few records of her rule over the next two years, but she probably gained considerable practical experience of government. In 1119, she returned north to meet Henry in Lotharingia. Her husband was occupied in finding a compromise with the Pope, who had excommunicated him. In 1122, Henry and probably Matilda were at the Council of Worms. The council settled the long-running dispute with the Church when Henry gave up his rights to invest bishops with their episcopal regalia. Matilda attempted to visit her father in England that year, but the journey was blocked by Charles I, Count of Flanders, whose territory she would have needed to pass through. Historian Marjorie Chibnall argues Matilda had intended to discuss the inheritance of the English crown on this journey.

Matilda and Henry remained childless, but neither party was considered to be infertile and contemporary chroniclers blamed their situation on the Emperor and his sins against the Church. In early 1122, the couple travelled down the Rhine together as Henry continued to suppress the ongoing political unrest, but by now he was suffering from cancer. His condition worsened and he died on 23 May 1125 in Utrecht, leaving Matilda in the protection of their nephew Frederick, the heir to his estates. Before his death, he left the imperial insignia in the control of Matilda, but it is unclear what instructions he gave her about the future of the Empire, which faced another leadership election. Archbishop Adalbert subsequently convinced Matilda that she should give him the insignia, and the Archbishop led the electoral process which appointed Lothair of Supplinburg, a former enemy of Henry, as the new King of the Romans.

Now aged 23, Matilda had only limited options as to how she might spend the rest of her life. Being childless, she could not exercise a role as an imperial regent, which left her with the choice of either becoming a nun or remarrying. Some offers of marriage started to arrive from German princes, but she chose to return to Normandy. She does not appear to have expected to return to Germany, as she gave up her estates within the Empire and departed with her personal collection of jewels, her own imperial regalia, two of Henry's crowns, and the valuable relic of the Hand of St James the Apostle.

In 1120, the English political landscape had changed dramatically after the "White Ship" disaster. Around three hundred passengers – including Matilda's brother William Adelin and many other senior nobles – embarked one night on the "White Ship" to travel from Barfleur in Normandy across to England. The vessel foundered just outside the harbour, possibly as a result of overcrowding or excessive drinking by the ship's master and crew, and all but two of the passengers died. William Adelin was among the casualties.

With William dead, the succession to the English throne was thrown into doubt. Rules of succession were uncertain in western Europe at the time; in some parts of France, male primogeniture was becoming more popular, in which the eldest son would inherit a title. It was also traditional for the King of France to crown his successor while he was still alive, making the intended line of succession relatively clear. This was not the case in England, where the best a noble could do was to identify what Professor Eleanor Searle has termed a pool of legitimate heirs, leaving them to challenge and dispute the inheritance after his death. The problem was further complicated by the sequence of unstable Anglo-Norman successions over the previous sixty years. William the Conqueror had invaded England, his sons William Rufus and Robert Curthose had fought a war between them to establish their inheritance, and Henry had only acquired control of Normandy by force. There had been no peaceful, uncontested successions.

Initially, Henry put his hopes in fathering another son. William and Matilda's mother—Matilda of Scotland—had died in 1118, and so Henry took a new wife, Adeliza of Louvain. Henry and Adeliza did not conceive any children, and the future of the dynasty appeared at risk. Henry may have begun to look among his nephews for a possible heir. He may have considered his sister Adela's son Stephen of Blois as a possible option and, perhaps in preparation for this, he arranged a beneficial marriage for Stephen to Matilda's wealthy maternal cousin and namesake the Countess of Boulogne. Theobald of Blois, his close ally, possibly also felt that he was in favour with Henry. William Clito, the only son of Robert Curthose, was King Louis VI of France's preferred choice, but William was in open rebellion against Henry and was therefore unsuitable. Henry might have also considered his own illegitimate son, Robert of Gloucester, as a possible candidate, but English tradition and custom would have looked unfavourably on this. Henry's plans shifted when Empress Matilda's husband, Emperor Henry, died in 1125.

Matilda returned to Normandy in 1125 and spent about a year at the royal court, where her father Henry was still hoping that his second marriage would generate a male heir. In the event that this failed to happen, Matilda was now Henry's preferred choice, and he declared that she was to be his rightful successor if he should die without a male heir. The Anglo-Norman barons were gathered together at Westminster on Christmas 1126, where they swore in January to recognise Matilda and any future legitimate heir she might have.

Henry began to formally look for a new husband for Matilda in early 1127 and received various offers from princes within the Empire. His preference was to use Matilda's marriage to secure the southern borders of Normandy by marrying her to Geoffrey of Anjou, the eldest son of Fulk, the Count of Anjou. Henry's control of Normandy had faced numerous challenges since he had conquered it in 1106, and the latest threat came from his nephew William Clito, the new Count of Flanders, who enjoyed the support of the French King. It was essential to Henry that he did not also face a threat from the south as well as the east of Normandy. William Adelin had married Fulk's daughter Matilda, which would have cemented an alliance between Henry and Anjou, but the "White Ship" disaster put an end to this. Henry and Fulk argued over the fate of the marriage dowry, and this had encouraged Fulk to turn to support William Clito instead. Henry's solution was now to negotiate the marriage of Matilda to Geoffrey, recreating the former alliance.

Matilda appears to have been unimpressed by this plan. She felt that marrying the son of a count diminished her imperial status and was probably also unhappy about marrying someone so much younger than she was; Matilda was 25 and Geoffrey was only 13. Hildebert, the Archbishop of Tours, eventually intervened to persuade her to go along with the engagement. Matilda finally agreed, and she travelled to Rouen in May 1127 with Robert of Gloucester and Brian Fitz Count where she was formally betrothed to Geoffrey. Over the course of the next year, Fulk decided to depart for Jerusalem, where he hoped to become king, leaving his possessions to Geoffrey. Henry knighted his future son-in-law, and Matilda and Geoffrey were married a week later on 17 June 1128 in Le Mans by the bishops of Le Mans and Séez. Fulk finally left Anjou for Jerusalem in 1129, declaring Geoffrey the Count of Anjou and Maine.

The marriage proved difficult, as the couple did not particularly like each other. There was a further dispute over Matilda's dowry; she was granted various castles in Normandy by Henry, but it was not specified when the couple would actually take possession of them. It is also unknown whether Henry intended Geoffrey to have any future claim on England or Normandy, and he was probably keeping Geoffrey's status deliberately uncertain. Soon after the marriage, Matilda left Geoffrey and returned to Normandy. Henry appears to have blamed Geoffrey for the separation, but the couple were finally reconciled in 1131. Henry summoned Matilda from Normandy, and she arrived in England that August. It was decided that Matilda would return to Geoffrey at a meeting of the King's great council in September. The council also gave another collective oath of allegiance to recognise her as Henry's heir.

Matilda gave birth to her first son in March 1133 at Le Mans, the future Henry II. Henry was delighted by the news and came to see her at Rouen. At Pentecost 1134, son Geoffrey was born in Rouen, but the childbirth was extremely difficult and Matilda appeared close to death. She made arrangements for her will and argued with her father about where she should be buried. Matilda preferred Bec Abbey, but Henry wanted her to be interred at Rouen Cathedral. Matilda recovered, and Henry was overjoyed by the birth of his second grandson, possibly insisting on another round of oaths from his nobility.

From then on, relations became increasingly strained between Matilda and Henry. The couple suspected that they lacked genuine support in England for their claim to the throne, and proposed in 1135 that the King should hand over the royal castles in Normandy to Matilda and should insist that the Norman nobility immediately swear allegiance to her. This would have given the couple a much more powerful position after Henry's death, but the King angrily refused, probably out of a concern that Geoffrey would try to seize power in Normandy while he was still alive. A fresh rebellion broke out in southern Normandy, and Geoffrey and Matilda intervened militarily on behalf of the rebels.

In the middle of this confrontation, Henry unexpectedly fell ill and died near Lyons-la-Forêt. It is uncertain what, if anything, Henry said about the succession before his death. Contemporary chronicler accounts were coloured by subsequent events. Sources favourable to Matilda suggested that Henry had reaffirmed his intent to grant all his lands to his daughter, while hostile chroniclers argued that Henry had renounced his former plans and had apologised for having forced the barons to swear an oath of allegiance to her.

When news began to spread of Henry I's death, Matilda and Geoffrey were in Anjou, supporting the rebels in their campaign against the royal army, which included a number of Matilda's supporters such as Robert of Gloucester. Many of these barons had taken an oath to stay in Normandy until the late king was properly buried, which prevented them from returning to England. Nonetheless, Geoffrey and Matilda took the opportunity to march into southern Normandy and seize a number of key castles around Argentan that had formed Matilda's disputed dowry. They then stopped, unable to advance further, pillaging the countryside and facing increased resistance from the Norman nobility and a rebellion in Anjou itself. Matilda was by now also pregnant with her third son, William; opinions vary among historians as to what extent this affected her military plans.

Meanwhile, news of Henry's death had reached Stephen of Blois, conveniently placed in Boulogne, and he left for England, accompanied by his military household. Robert of Gloucester had garrisoned the ports of Dover and Canterbury and some accounts suggest that they refused Stephen access when he first arrived. Nonetheless Stephen reached the edge of London by 8 December and over the next week he began to seize power in England. The crowds in London proclaimed Stephen the new monarch, believing that he would grant the city new rights and privileges in return, and his brother, Henry of Blois, the Bishop of Winchester, delivered the support of the Church to Stephen. Stephen had sworn to support Matilda in 1127, but Henry convincingly argued that the late King had been wrong to insist that his court take the oath, and suggested that the King had changed his mind on his deathbed. Stephen's coronation was held a week later at Westminster Abbey on 26 December.

Following the news that Stephen was gathering support in England, the Norman nobility had gathered at Le Neubourg to discuss declaring his elder brother Theobald king. The Normans argued that the count, as the eldest grandson of William the Conqueror, had the most valid claim over the kingdom and the Duchy, and was certainly preferable to Matilda. Their discussions were interrupted by the sudden news from England that Stephen's coronation was to occur the next day. Theobald's support immediately ebbed away, as the barons were not prepared to support the division of England and Normandy by opposing Stephen.

Matilda gave birth to her third son William on 22 July 1136 at Argentan, and she then operated out of the border region for the next three years, establishing her household knights on estates around the area. Matilda may have asked Ulger, the Bishop of Angers, to garner support for her claim with the Pope in Rome, but if she did, Ulger was unsuccessful. Geoffrey invaded Normandy in early 1136 and, after a temporary truce, invaded again later the same year, raiding and burning estates rather than trying to hold the territory. Stephen returned to the Duchy in 1137, where he met with Louis VI and Theobald to agree to an informal alliance against Geoffrey and Matilda, to counter the growing Angevin power in the region. Stephen formed an army to retake Matilda's Argentan castles, but frictions between his Flemish mercenary forces and the local Norman barons resulted in a battle between the two halves of his army. The Norman forces then deserted the King, forcing Stephen to give up his campaign. Stephen agreed to another truce with Geoffrey, promising to pay him 2,000 marks a year in exchange for peace along the Norman borders.

In England, Stephen's reign started off well, with lavish gatherings of the royal court that saw the King give out grants of land and favours to his supporters. Stephen received the support of Pope Innocent II, thanks in part to the testimony of Louis VI and Theobald. Troubles rapidly began to emerge. Matilda's uncle, David I of Scotland, invaded the north of England on the news of Henry's death, taking Carlisle, Newcastle and other key strongholds. Stephen rapidly marched north with an army and met David at Durham, where a temporary compromise was agreed. South Wales rose in rebellion, and by 1137 Stephen was forced to abandon attempts to suppress the revolt. Stephen put down two revolts in the south-west led by Baldwin de Redvers and Robert of Bampton; Baldwin was released after his capture and travelled to Normandy, where he became a vocal critic of the King.

Matilda's half-brother, Robert of Gloucester, was one of the most powerful Anglo-Norman barons, controlling estates in Normandy as well as the Earldom of Gloucester. In 1138, he rebelled against Stephen, starting the descent into civil war in England. Robert renounced his fealty to the King and declared his support for Matilda, which triggered a major regional rebellion in Kent and across the south-west of England, although he himself remained in Normandy. Matilda had not been particularly active in asserting her claims to the throne since 1135 and in many ways it was Robert who took the initiative in declaring war in 1138. In France, Geoffrey took advantage of the situation by re-invading Normandy. David of Scotland also invaded the north of England once again, announcing that he was supporting the claim of Matilda to the throne, pushing south into Yorkshire.

Stephen responded quickly to the revolts and invasions, paying most attention to England rather than to Normandy. His wife Matilda was sent to Kent with ships and resources from Boulogne, with the task of retaking the key port of Dover, under Robert's control. A small number of Stephen's household knights were sent north to help the fight against the Scots, where David's forces were defeated later that year at the Battle of the Standard. Despite this victory, however, David still occupied most of the north. Stephen himself went west in an attempt to regain control of Gloucestershire, first striking north into the Welsh Marches, taking Hereford and Shrewsbury, before heading south to Bath. The town of Bristol itself proved too strong for him, and Stephen contented himself with raiding and pillaging the surrounding area. The rebels appear to have expected Robert to intervene with support, but he remained in Normandy throughout the year, trying to persuade the Empress Matilda to invade England herself. Dover finally surrendered to the Queen's forces later in the year.

By 1139, an invasion of England by Robert and Matilda appeared imminent. Geoffrey and Matilda had secured much of Normandy and, together with Robert, spent the beginning of the year mobilising forces for a cross-Channel expedition. Matilda also appealed to the papacy at the start of the year; her representative, Bishop Ulger, put forward her legal claim to the English throne on the grounds of her hereditary right and the oaths sworn by the barons. Arnulf of Lisieux led Stephen's case, arguing that because Matilda's mother had really been a nun, her claim to the throne was illegitimate. The Pope declined to reverse his earlier support for Stephen, but from Matilda's perspective the case usefully established that Stephen's claim was disputed.

Empress Matilda's invasion finally began at the end of the summer of 1139. Baldwin de Redvers crossed over from Normandy to Wareham in August in an initial attempt to capture a port to receive Matilda's invading army, but Stephen's forces forced him to retreat into the south-west. The following month, the Empress was invited by her stepmother, Queen Adeliza, to land at Arundel instead, and on 30 September Robert of Gloucester and Matilda arrived in England with a force of 140 knights. Matilda stayed at Arundel Castle, while Robert marched north-west to Wallingford and Bristol, hoping to raise support for the rebellion and to link up with Miles of Gloucester, who took the opportunity to renounce his fealty to the King and declare for Matilda.

Stephen responded by promptly moving south, besieging Arundel and trapping Matilda inside the castle. Stephen then agreed to a truce proposed by his brother, Henry of Blois; the full details of the agreement are not known, but the results were that Matilda and her household of knights were released from the siege and escorted to the south-west of England, where they were reunited with Robert of Gloucester. The reasons for Matilda's release remain unclear. Stephen may have thought it was in his own best interests to release the Empress and concentrate instead on attacking Robert, seeing Robert, rather than Matilda, as his main opponent at this point in the conflict. Arundel Castle was also considered almost impregnable, and Stephen may have been worried that he risked tying down his army in the south whilst Robert roamed freely in the west. Another theory is that Stephen released Matilda out of a sense of chivalry; Stephen had a generous, courteous personality and women were not normally expected to be targeted in Anglo-Norman warfare.

After staying for a period in Robert's stronghold of Bristol, Matilda established her court in nearby Gloucester, still safely in the south-west but far enough away for her to remain independent of her half-brother. Although there had been only a few new defections to her cause, Matilda still controlled a compact block of territory stretching out from Gloucester and Bristol south into Wiltshire, west into the Welsh Marches and east through the Thames Valley as far as Oxford and Wallingford, threatening London. Her influence extended down into Devon and Cornwall, and north through Herefordshire, but her authority in these areas remained limited.

She faced a counterattack from Stephen, who started by attacking Wallingford Castle which controlled the Thames corridor; it was held by Brian Fitz Count and Stephen found it too well defended. Stephen continued into Wiltshire to attack Trowbridge, taking the castles of South Cerney and Malmesbury en route. In response, Miles marched east, attacking Stephen's rearguard forces at Wallingford and threatening an advance on London. Stephen was forced to give up his western campaign, returning east to stabilise the situation and protect his capital.

At the start of 1140, Nigel, the Bishop of Ely, joined Matilda's faction. Hoping to seize East Anglia, he established his base of operations in the Isle of Ely, then surrounded by protective fenland. Nigel faced a rapid response from Stephen, who made a surprise attack on the isle, forcing the Bishop to flee to Gloucester. Robert of Gloucester's men retook some of the territory that Stephen had taken in his 1139 campaign. In an effort to negotiate a truce, Henry of Blois held a peace conference at Bath, at which Matilda was represented by Robert. The conference collapsed after Henry and the clergy insisted that they should set the terms of any peace deal, which Stephen's representatives found unacceptable.

Matilda's fortunes changed dramatically for the better at the start of 1141. Ranulf of Chester, a powerful northern magnate, had fallen out with the King over the winter and Stephen had placed his castle in Lincoln under siege. In response, Robert of Gloucester and Ranulf advanced on Stephen's position with a larger force, resulting in the Battle of Lincoln on 2 February 1141. The King commanded the centre of his army, with Alan of Brittany on his right and William of Aumale on his left. Robert and Ranulf's forces had a superiority in cavalry and Stephen dismounted many of his own knights to form a solid infantry block. After an initial success in which William's forces destroyed the Angevins' Welsh infantry, the battle went well for Matilda's forces. Robert and Ranulf's cavalry encircled Stephen's centre, and the King found himself surrounded by the Angevin army. After much fighting, Robert's soldiers finally overwhelmed Stephen and he was taken away from the field in custody.

Matilda received Stephen in person at her court in Gloucester, before having him moved to Bristol Castle, traditionally used for holding high-status prisoners. Matilda now began to take the necessary steps to have herself crowned queen in his place, which would require the agreement of the Church and her coronation at Westminster. Stephen's brother Henry summoned a council at Winchester before Easter in his capacity as papal legate to consider the clergy's view. Matilda had made a private deal with Henry that he would deliver the support of the Church in exchange for being granted control over Church affairs. Henry handed over the royal treasury to her, which proved to be rather depleted except for Stephen's crown, and he excommunicated many of her enemies who refused to switch sides. Archbishop Theobald of Canterbury was unwilling to declare Matilda queen so rapidly, however, and a delegation of clergy and nobles, headed by Theobald, travelled to Bristol to see Stephen, who agreed that, given the situation, he was prepared to release his subjects from their oath of fealty to him.

The clergy gathered again in Winchester after Easter and declared Matilda the "Lady of England and Normandy" as a precursor to her coronation. Although Matilda's own followers attended the event, few other major nobles seem to have attended and the delegation from London procrastinated. Stephen's wife, Queen Matilda, wrote to complain and demand her husband's release. Nonetheless, Matilda then advanced to London to arrange her coronation in June, where her position became precarious. Despite securing the support of Geoffrey de Mandeville, who controlled the Tower of London, forces loyal to Stephen and Queen Matilda remained close to the city and the citizens were fearful about welcoming the Empress. On 24 June, shortly before the planned coronation, the city rose up against the Empress and Geoffrey de Mandeville; Matilda and her followers fled just in time, making a chaotic retreat back to Oxford.

Meanwhile, Geoffrey of Anjou invaded Normandy again and, in the absence of Waleran of Beaumont, who was still fighting in England, Geoffrey took all the Duchy south of the River Seine and east of the Risle. No help was forthcoming from Stephen's brother Theobald this time either, who appears to have been preoccupied with his own problems with France—the new French king, Louis VII, had rejected his father's regional alliance, improving relations with Anjou and taking a more bellicose line with Theobald, which would result in war the following year. Geoffrey's success in Normandy and Stephen's weakness in England began to influence the loyalty of many Anglo-Norman barons, who feared losing their lands in England to Robert and the Empress, and their possessions in Normandy to Geoffrey. Many started to leave Stephen's faction. His friend and advisor Waleran was one of those who decided to defect in mid-1141, crossing into Normandy to secure his ancestral possessions by allying himself with the Angevins, and bringing Worcestershire into the Empress's camp. Waleran's twin brother, Robert of Leicester, effectively withdrew from fighting in the conflict at the same time. Other supporters of the Empress were restored in their former strongholds, such as Bishop Nigel of Ely, and still others received new earldoms in the west of England. The royal control over the minting of coins broke down, leading to coins being struck by local barons and bishops across the country.

Matilda's position was transformed by her defeat at the Rout of Winchester. Her alliance with Henry of Blois proved short-lived and they soon fell out over political patronage and ecclesiastical policy; the Bishop transferred his support back to Stephen's cause. In response, in July Matilda and Robert of Gloucester besieged Henry of Blois in his episcopal castle at Winchester, using the royal castle in the city as the base for their operations. Stephen's wife, Queen Matilda, had kept his cause alive in the south-east of England, and the Queen, backed by her lieutenant William of Ypres and reinforced with fresh troops from London, took the opportunity to advance on Winchester. Their forces encircled Matilda's army. Matilda decided to escape from the city with Fitz Count and Reginald of Cornwall, while the rest of her army delayed the royal forces. In the subsequent battle the Empress's forces were defeated and Robert of Gloucester himself was taken prisoner during the retreat, although Matilda herself escaped, exhausted, to her fortress at Devizes.

With both Stephen and Robert held prisoner, negotiations were held to try to come to agreement on a long-term peace settlement, but Queen Matilda was unwilling to offer any compromise to the Empress, and Robert refused to accept any offer to encourage him to change sides to Stephen. Instead, in November the two sides simply exchanged the two leaders, Stephen returning to his queen, and Robert to the Empress in Oxford. Henry held another church council, which reversed its previous decision and reaffirmed Stephen's legitimacy to rule, and a fresh coronation of Stephen and Matilda occurred at Christmas 1141. Stephen travelled north to raise new forces and to successfully persuade Ranulf of Chester to change sides once again. Stephen then spent the summer attacking some of the new Angevin castles built the previous year, including Cirencester, Bampton and Wareham.

During the summer of 1142 Robert returned to Normandy to assist Geoffrey with operations against some of Stephen's remaining followers there, before returning in the autumn. Matilda came under increased pressure from Stephen's forces and was surrounded at Oxford. Oxford was a secure town, protected by walls and the River Isis, but Stephen led a sudden attack across the river, leading the charge and swimming part of the way. Once on the other side, the King and his men stormed into the town, trapping Matilda in the castle. Oxford Castle was a powerful fortress and, rather than storming it, Stephen decided to settle down for a long siege. Just before Christmas, Matilda sneaked out of the castle with a handful of knights (probably via a postern gate), crossed the icy river on foot and made her escape past the royal army to safety at Wallingford, leaving the castle garrison free to surrender the next day.

In the aftermath of the retreat from Winchester, Matilda rebuilt her court at Devizes Castle, a former property of the Bishop of Salisbury that had been confiscated by Stephen. She established her household knights on the surrounding estates, supported by Flemish mercenaries, ruling through the network of local sheriffs and other officials. Many of those that had lost lands in the regions held by the King travelled west to take up patronage from Matilda. Backed by the pragmatic Robert of Gloucester, Matilda was content to engage in a drawn-out struggle, and the war soon entered a stalemate.

At first, the balance of power appeared to move slightly in Matilda's favour. Robert of Gloucester besieged Stephen in 1143 at Wilton Castle, an assembly point for royal forces in Herefordshire. Stephen attempted to break out and escape, resulting in the Battle of Wilton. Once again, the Angevin cavalry proved too strong, and for a moment it appeared that Stephen might be captured for a second time, before finally managing to escape. Later in the year Geoffrey de Mandeville, the Earl of Essex, rose up in rebellion against Stephen in East Anglia. Geoffrey based himself from the Isle of Ely and began a military campaign against Cambridge, with the intention of progressing south towards London. Ranulf of Chester revolted once again in the summer of 1144.
Meanwhile, Geoffrey of Anjou finished securing his hold on southern Normandy, and in January 1144 he advanced into Rouen, the capital of the Duchy, concluding his campaign. Louis VII recognised him as Duke of Normandy shortly after.

Despite these successes, Matilda was unable to consolidate her position. Miles of Gloucester, one of the most talented of her military commanders, had died while hunting over the previous Christmas. Geoffrey de Mandeville's rebellion against Stephen in the east ended with his death in September 1144 during an attack on Burwell Castle. As a result, Stephen made progress against Matilda's forces in the west in 1145, recapturing Faringdon Castle in Oxfordshire. Matilda authorised Reginald, the Earl of Cornwall, to attempt fresh peace negotiations, but neither side was prepared to compromise.

The character of the conflict in England gradually began to shift; by the late 1140s, the major fighting in the war was over, giving way to an intractable stalemate, with only the occasional outbreak of fresh fighting. Several of Matilda's key supporters died: in 1147 Robert of Gloucester died peacefully, and Brian Fitz Count gradually withdrew from public life, probably eventually joining a monastery; by 1151 he was dead. Many of Matilda's other followers joined the Second Crusade when it was announced in 1145, leaving the region for several years. Some of the Anglo-Norman barons made individual peace agreements with each other to secure their lands and war gains, and many were not keen to pursue any further conflict.

Matilda's eldest son Henry slowly began to assume a leading role in the conflict. He had remained in France when the Empress first left for England. He crossed over to England in 1142, before returning to Anjou in 1144. Geoffrey of Anjou expected Henry to become the King of England and began to involve him in the government of the family lands. In 1147, Henry intervened in England with a small mercenary army but the expedition failed, not least because Henry lacked the funds to pay his men. Henry asked his mother for money, but she refused, stating that she had none available. In the end Stephen himself ended up paying off Henry's mercenaries, allowing him to return home safely; his reasons for doing so remain unclear.

Matilda decided to return to Normandy in 1148, partially due to her difficulties with the Church. The Empress had occupied the strategically essential Devizes Castle in 1142, maintaining her court there, but legally it still belonged to Josceline de Bohon, the Bishop of Salisbury, and in late 1146 Pope Eugene III intervened to support his claims, threatening Matilda with excommunication if she did not return it. Matilda first played for time, then left for Normandy in early 1148, leaving the castle to Henry, who then procrastinated over its return for many years. Matilda re-established her court in Rouen, where she met with her sons and husband and probably made arrangements for her future life in Normandy, and for Henry's next expedition to England. Matilda chose to live in the priory of Notre Dame du Pré, situated just south of Rouen, where she lived in personal quarters attached to the priory and in a nearby palace built by Henry.

Matilda increasingly devoted her efforts to the administration of Normandy, rather than the war in England. Geoffrey sent the Bishop of Thérouanne to Rome in 1148 to campaign for Henry's right to the English throne, and opinion within the English Church gradually shifted in Henry's favour. Matilda and Geoffrey made peace with Louis VII, who in return supported Henry's rights to Normandy. Geoffrey died unexpectedly in 1151, and Henry claimed the family lands. Henry returned to England once again at the start of 1153 with a small army, winning the support of some of the major regional barons. Neither side's army was keen to fight, however, and the Church brokered a truce; a permanent peace followed, under which Henry recognised Stephen as king, but became Stephen's adopted son and successor. Meanwhile, Normandy faced considerable disorder and the threat of baronial revolt, which Matilda was unable to totally suppress. Stephen died the next year, and Henry assumed the throne; his coronation used the grander of the two imperial crowns that Matilda had brought back from Germany in 1125. Once Henry had been crowned, the troubles facing Matilda in Normandy died away.

Matilda spent the rest of her life in Normandy, often acting as Henry's representative and presiding over the government of the Duchy. Early on, Matilda and her son issued charters in England and Normandy in their joint names, dealing with the various land claims that had arisen during the wars. Particularly in the initial years of his reign, the King drew on her for advice on policy matters. Matilda was involved in attempts to mediate between Henry and his Chancellor Thomas Becket when the two men fell out in the 1160s. Matilda had originally cautioned against the appointment, but when the Prior of Mont St Jacques asked her for a private interview on Becket's behalf to seek her views, she provided a moderate perspective on the problem. Matilda explained that she disagreed with Henry's attempts to codify English customs, which Becket was opposed to, but also condemned poor administration in the English Church and Becket's own headstrong behaviour.

Matilda helped to deal with several diplomatic crises. The first of these involved the Hand of St James, the relic which Matilda had brought back with her from Germany many years before. Frederick I, the Holy Roman Emperor, considered the hand to be part of the imperial regalia and requested that Henry return it to Germany. Matilda and Henry were equally insistent that it should remain at Reading Abbey, where it had become a popular attraction for visiting pilgrims. Frederick was bought off with an alternative set of expensive gifts from England, including a huge, luxurious tent, probably chosen by Matilda, which Frederick used for court events in Italy. She was also approached by Louis VII of France, in 1164, and helped to defuse a growing diplomatic row over the handling of Crusading funds.

In her old age Matilda paid increasing attention to Church affairs and her personal faith, although she remained involved in governing Normandy throughout her life. Matilda appears to have had particular fondness for her youngest son William. She opposed Henry's proposal in 1155 to invade Ireland and give the lands to William, however, possibly on the grounds that the project was impractical, and instead William received large grants of land in England. Matilda was more easy-going in her later life than in her youth, but the chronicler of Mont St Jacques, who met her during this period, still felt that she appeared to be "of the stock of tyrants".

Matilda died on 10 September 1167, and her remaining wealth was given to the Church. She was buried under the high altar at the abbey of Bec-Hellouin in a service led by Rotrou, the Archbishop of Rouen. Her tomb's epitaph included the lines "Great by birth, greater by marriage, greatest in her offspring: here lies Matilda, the daughter, wife, and mother of Henry", which became a famous phrase among her contemporaries. This tomb was damaged in a fire in 1263 and later restored in 1282, before finally being destroyed by an English army in 1421. In 1684 the Congregation of St. Maur identified some of her remaining bones and reburied them at Bec-Hellouin in a new coffin. Her remains were lost again after the destruction of Bec-Hellouin's church by Napoleon, but were found once more in 1846 and this time reburied at Rouen Cathedral, where they remain.

In the Holy Roman Empire, the young Matilda's court included knights, chaplains and ladies-in-waiting, although, unlike some queens of the period, she did not have her own personal chancellor to run her household, instead using the imperial chancellor. When acting as regent in Italy, she found the local rulers were prepared to accept a female ruler. Her Italian administration included the Italian chancellor, backed by experienced administrators. She was not called upon to make any major decisions, instead dealing with smaller matters and acting as the symbolic representative of her absent husband, meeting with and helping to negotiate with magnates and clergy.

On her return from Germany to Normandy and Anjou, she styled herself as empress and the daughter of King Henry. During the civil war for England, her status was uncertain. The Anglo-Saxon queens of England had exercised considerable formal power, but this tradition had diminished under the Normans: at most their queens ruled temporarily as regents on their husbands' behalf when they were away travelling, rather than in their own right. Initially between 1139 and 1141 Matilda referred to herself as acting as a "feme sole", "a woman acting alone", highlighting her autonomy and independence from her husband Geoffrey. She had an imperial great seal created, which was round like the seal of a king – queens used an oval seal – but which showed Matilda enthroned as an empress and titled as the Queen of the Romans. The seal did not show her on horseback, however, as a male ruler would have been depicted. Since she was never crowned at Westminster, during the rest of the war she appears to have used her title of Lady of the English, rather than that of the Queen of England, although some contemporaries referred to her by the royal title.

Matilda presented herself as continuing the English tradition of centralised royal government, and attempted to maintain a government in England parallel to Stephen's, including a royal household and a chancellor. Matilda gathered revenues from the royal estates in the counties under her control, particularly in her core territories where the sheriffs were loyal to her cause. She appointed earls to rival those created by Stephen. She was unable to operate a system of royal law courts, however, and her administrative resources were extremely limited, although some of her clerks went on to become bishops in Normandy. Matilda issued two types of coins in her name during her time in England, which were used in the west of England and Wales. The first were initially minted in Oxford during her stay there, and the design was then adopted by her mints at Bristol, Cardiff and Wareham after her victory at the Battle of Lincoln. A second design was minted at Bristol and Cardiff during the 1140s.

On returning to Normandy for the last time in 1148, Matilda ceased to use the title Lady of the English, simply styling herself as empress again; she never adopted the title of Countess of Anjou. Matilda's household became smaller, and often merged with Henry's own court when the two were co-located in Rouen. She continued to play a special role in the government of the area around Argentan, where she held feudal rights from the grants made at the time of her second marriage.

It is unclear how strong Matilda's personal piety was, although contemporaries praised her lifelong preference to be buried at the monastic site of Bec rather than the grander but more worldly Rouen, and believed her to have substantial, underlying religious beliefs. Like other members of the Anglo-Norman nobility, she bestowed considerable patronage on the Church. Early on in her life, she preferred the well-established Benedictine monastery of Cluny alongside some of the newer Augustinian orders, such as the Victorines and Premonstratensians. As part of this patronage, she re-founded the abbey of Notre-Dame-du-Vœu near Cherbourg.

As time went by, Matilda directed more of her attention to the Cistercian order. This order was very fashionable in England and Normandy during the period, and was dedicated to the Virgin Mary, a figure of particular importance to Matilda. She had close links to the Cistercian Mortemer Abbey in Normandy, and drew on the house for a supply of monks when she supported the foundation of nearby La Valasse. She encouraged the Cistercians to build at Mortemer on a grand scale, with guest houses to accommodate a range of visitors of all ranks, and may have played a part in selecting the paintings for the monastic chapels.

Contemporary chroniclers in England, France, Germany and Italy documented many aspects of Matilda's life, although the only biography of her, apparently written by Arnulf of Lisieux, has been lost. The chroniclers took a range of perspectives on her. In Germany, the chroniclers praised Matilda extensively and her reputation as the "good Matilda" remained positive. During the years of the Anarchy, works such as the "Gesta Stephani" took a much more negative tone, praising Stephen and condemning Matilda. Once Henry II assumed the throne, the tone of the chroniclers towards Matilda became more positive. Legends spread in the years after Matilda's death, including the suggestion that her first husband, Henry, had not died but had in fact secretly become a hermit – making Matilda's second marriage illegitimate – and a tale that Matilda had an affair with Stephen, resulting in the conception of Henry II.

Tudor scholars were interested in Matilda's right of succession. According to 16th century standards, Matilda had a clear right to the English throne, and academics therefore struggled to explain why Matilda had acquiesced to her son Henry's kingship at the end of the war, rather than ruling directly herself. By the 18th century, historians such as David Hume had a much better understanding of the irregular nature of 12th century law and custom and this question became less relevant. By the 19th century, the archival sources on Matilda's life, including charters, foundation histories, and letters, were being uncovered and analysed. Historians Kate Norgate, Sir James Ramsay and J. H. Round used these to produce new, richer accounts of Matilda and the civil war; Ramsay's account, using the "Gesta Stephani", was not complimentary, while Norgate, drawing on French sources, was more neutral in tone. The German academic Oskar Rössler's 1897 biography drew heavily on German charters, not extensively used by Anglophone historians.

Matilda has attracted relatively little attention from modern English academics, being treated as a marginal figure in comparison to other contemporaries, particularly her rival Stephen, in contrast to the work carried out by German scholars on her time in the Empire. Popular, but not always accurate, biographies were written by the Earl of Onslow in 1939 and Nesta Pain in 1978, but the only major academic biography in English remains Marjorie Chibnall's 1991 work. Interpretations of Matilda's character have shifted over time, but there is, as Chibnall describes, a "general agreement that she was either proud or at least keenly conscious of the high status of an empress". Like both Henry I and Henry II, Matilda had a certain autocratic grandeur, which was combined with a firm moral belief in her cause; ultimately however she was limited by the political conventions of the 12th century. The treatment of Matilda by modern historians has been challenged by feminist scholars, including Fiona Tolhurst, who believe some traditional assumptions about her role and personality show gender bias. In this interpretation, Matilda has been unfairly criticised for showing qualities that have been considered praiseworthy when seen in her male contemporaries.

The civil war years of Matilda's life have been the subject of historical fiction. Matilda, Stephen and their supporters feature in Ellis Peters's historical detective series about Brother Cadfael, set between 1137 and 1145. Peters paints the Empress as proud and aloof, in contrast to Stephen, a tolerant man and a reasonable ruler. Matilda's martial reputation may also have contributed to Alfred, Lord Tennyson's decision to entitle his 1855 battle poem "Maud".

Matilda's family tree:



</doc>
<doc id="49123" url="https://en.wikipedia.org/wiki?curid=49123" title="Phoenix (constellation)">
Phoenix (constellation)

Phoenix is a minor constellation in the southern sky. Named after the mythical phoenix, it was first depicted on a celestial atlas by Johann Bayer in his 1603 "Uranometria". The French explorer and astronomer Nicolas Louis de Lacaille charted the brighter stars and gave their Bayer designations in 1756. The constellation stretches from roughly −39° to −57° declination, and from 23.5h to 2.5h of right ascension. The constellations Phoenix, Grus, Pavo and Tucana, are known as the Southern Birds.

The brightest star, Alpha Phoenicis, is named Ankaa, an Arabic word meaning 'the Phoenix'. It is an orange giant of apparent magnitude 2.4. Next is Beta Phoenicis, actually a binary system composed of two yellow giants with a combined apparent magnitude of 3.3. Nu Phoenicis has a dust disk, while the constellation has ten star systems with known planets and the recently discovered galaxy clusters El Gordo and the Phoenix Cluster—located 7.2 and 5.7 billion light years away respectively, two of the largest objects in the visible universe. Phoenix is the radiant of two annual meteor showers: the Phoenicids in December, and the July Phoenicids.

Phoenix was the largest of the twelve constellations established by Petrus Plancius from the observations of Pieter Dirkszoon Keyser and Frederick de Houtman. It first appeared on a 35-cm diameter celestial globe published in 1597 (or 1598) in Amsterdam by Plancius with Jodocus Hondius. The first depiction of this constellation in a celestial atlas was in Johann Bayer's "Uranometria" of 1603. De Houtman included it in his southern star catalog the same year under the Dutch name "Den voghel Fenicx", "The Bird Phoenix", symbolising the phoenix of classical mythology. One name of the brightest star Alpha Phoenicis—Ankaa—is derived from the Arabic العنقاء "al-‘anqā’" "the phoenix", and was coined sometime after 1800 in relation to the constellation.

Celestial historian Richard Allen noted that unlike the other constellations introduced by Plancius and La Caille, Phoenix has actual precedent in ancient astronomy, as the Arabs saw this formation as representing young ostriches, "Al Ri'āl", or as a griffin or eagle. In addition, the same group of stars was sometimes imagined by the Arabs as a boat, "Al Zaurak", on the nearby river Eridanus. He observed, "the introduction of a Phoenix into modern astronomy was, in a measure, by adoption rather than by invention."

The Chinese incorporated Phoenix's brightest star, Ankaa (Alpha Phoenicis), and stars from the adjacent constellation Sculptor to depict "Bakui", a net for catching birds. Phoenix and the neighbouring constellation of Grus together were seen by Julius Schiller as portraying Aaron the High Priest. These two constellations, along with nearby Pavo and Tucana, are called the Southern Birds.

Phoenix is a small constellation bordered by Fornax and Sculptor to the north, Grus to the west, Tucana to the south, touching on the corner of Hydrus to the south, and Eridanus to the east and southeast. The bright star Achernar is nearby. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'Phe'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of 10 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between −39.31° and −57.84°. This means it remains below the horizon to anyone living north of the 40th parallel in the Northern Hemisphere, and remains low in the sky for anyone living north of the equator. It is most visible from locations such as Australia and South Africa during late Southern Hemisphere spring. Most of the constellation lies within, and can be located by, forming a triangle of the bright stars Achernar, Fomalhaut and Beta Ceti—Ankaa lies roughly in the centre of this.

A curved line of stars comprising Alpha, Kappa, Mu, Beta, Nu and Gamma Phoenicis was seen as a boat by the ancient Arabs. French explorer and astronomer Nicolas Louis de Lacaille charted and designated 27 stars with the Bayer designations Alpha through to Omega in 1756. Of these, he labelled two stars close together Lambda, and assigned Omicron, Psi and Omega to three stars, which subsequent astronomers such as Benjamin Gould felt were too dim to warrant their letters. A different star was subsequently labelled Psi Phoenicis, while the other two designations fell out of use.

Ankaa is the brightest star in the constellation. It is an orange giant of apparent visual magnitude 2.37 and spectral type K0.5IIIb, 77 light years distant from Earth and orbited by a secondary object about which little is known. Lying close by Ankaa is Kappa Phoenicis, a main sequence star of spectral type A5IVn and apparent magnitude 3.90. Located centrally in the asterism, Beta Phoenicis is the second brightest star in the constellation and another binary star. Together the stars, both yellow giants of spectral type G8, shine with an apparent magnitude of 3.31, though the components are of individual apparent magnitudes of 4.0 and 4.1 and orbit each other every 168 years. Zeta Phoenicis or "Wurren" is an Algol-type eclipsing binary, with an apparent magnitude fluctuating between 3.9 and 4.4 with a period of around 1.7 days (40 hours); its dimming results from the component two blue-white B-type stars, which orbit and block out each other from Earth. The two stars are 0.05 AU from each other, while a third star is around 600 AU away from the pair, and has an orbital period exceeding 5000 years. The system is around 300 light years distant. In 1976, researchers Clausen, Gyldenkerne, and Grønbech calculated that a nearby 8th magnitude star is a fourth member of the system.

Gamma Phoenicis is a red giant of spectral type M0IIIa and varies between magnitudes 3.39 and 3.49. It lies 235 light years away. Psi Phoenicis is another red giant, this time of spectral type M4III, and has an apparent magnitude that ranges between 4.3 and 4.5 over a period of around 30 days. Lying 340 light years away, it has around 85 times the diameter, but only 85% of the mass, of our sun. W Phoenicis is a Mira variable, ranging from magnitude 8.1 to 14.4 over 333.95 days. A red giant, its spectrum ranges between M5e and M6e. Located 6.5 degrees west of Ankaa is SX Phoenicis, a variable star which ranges from magnitude 7.1 to 7.5 over a period of a mere 79 minutes. Its spectral type varies between A2 and F4. It gives its name to a group of stars known as SX Phoenicis variables. Rho and BD Phoenicis are Delta Scuti variables—short period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. Rho is spectral type F2III, and ranges between magnitudes 5.20 and 5.26 over a period of 2.85 hours. BD is of spectral type A1V, and ranges between magnitudes 5.90 and 5.94.

Nu Phoenicis is a yellow-white main sequence star of spectral type F9V and magnitude 4.96. Lying some 49 light years distant, it is around 1.2 times as massive as our sun, and likely to be surrounded by a disk of dust. It is the closest star in the constellation that is visible with the unaided eye. Gliese 915 is a white dwarf only 26 light years away. It is of magnitude 13.05, too faint to be seen with the naked eye. White dwarfs are extremely dense stars compacted into a volume the size of the Earth. With around 85% of the mass of the Sun, Gliese 915 has a surface gravity of 10 (2.45 · 10) cm·s, or approximately 250,000 of Earth's.

Ten stars have been found to have planets to date, and four planetary systems have been discovered with the SuperWASP project. HD 142 is a yellow giant that has an apparent magnitude of 5.7, and has a planet (HD 142 b)1.36 times the mass of Jupiter which orbits every 328 days. HD 2039 is a yellow subgiant with an apparent magnitude of 9.0 around 330 light years away which has a planet (HD 2039 b) six times the mass of Jupiter. WASP-18 is a star of magnitude 9.29 which was discovered to have a hot Jupiter-like planet (WASP-18b) taking less than a day to orbit the star. The planet is suspected to be causing WASP-18 to appear older than it really is. WASP-4 and WASP-5 are solar-type yellow stars around 1000 light years distant and of 13th magnitude, each with a single planet larger than Jupiter. WASP-29 is an orange dwarf of spectral type K4V and visual magnitude 11.3, which has a planetary companion of similar size and mass to Saturn. The planet completes an orbit every 3.9 days.

WISE J003231.09-494651.4 and WISE J001505.87-461517.6 are two brown dwarfs discovered by the Wide-field Infrared Survey Explorer, and are 63 and 49 light years away respectively. Initially hypothesised before they were belatedly discovered, brown dwarfs are objects more massive than planets, but which are of insufficient mass for hydrogen fusion characteristic of stars to occur. Many are being found by sky surveys.

Phoenix contains HE0107-5240, possibly one of the oldest stars yet discovered. It has around 1/200,000 the metallicity that the Sun has and hence must have formed very early in the history of the universe. With a visual magnitude of 15.17, it is around 10,000 times dimmer than the faintest stars visible to the naked eye and is 36000 light years distant.

The constellation does not lie on the galactic plane of the Milky Way, and there are no prominent star clusters. NGC 625 is a dwarf irregular galaxy of apparent magnitude 11.0 and lying some 12.7 million light years distant. Only 24000 light years in diameter, it is an outlying member of the Sculptor Group. NGC 625 is thought to have been involved in a collision and is experiencing a burst of active star formation. NGC 37 is a lenticular galaxy of apparent magnitude 14.66. It is approximately 42 kiloparsecs (137,000 light-years) in diameter and about 12.9 billion years old. Robert's Quartet (composed of the irregular galaxy NGC 87, and three spiral galaxies NGC 88, NGC 89 and NGC 92) is a group of four galaxies located around 160 million light-years away which are in the process of colliding and merging. They are within a circle of radius of 1.6 arcmin, corresponding to about 75,000 light-years. Located in the galaxy ESO 243-49 is HLX-1, an intermediate-mass black hole—the first one of its kind identified. It is thought to be a remnant of a dwarf galaxy that was absorbed in a collision with ESO 243-49. Before its discovery, this class of black hole was only hypothesized.

Lying within the bounds of the constellation is the gigantic Phoenix cluster, which is around 7.3 million light years wide and 5.7 billion light years away, making it one of the most massive galaxy clusters. It was first discovered in 2010, and the central galaxy is producing an estimated 740 new stars a year. Larger still is El Gordo, or officially ACT-CL J0102-4915, whose discovery was announced in 2012. Located around 7.2 billion light years away, it is composed of two subclusters in the process of colliding, resulting in the spewing out of hot gas, seen in X-rays and infrared images.

Phoenix is the radiant of two annual meteor showers. The Phoenicids, also known as the December Phoenicids, were first observed on 3 December 1887. The shower was particularly intense in December 1956, and is thought related to the breakup of the short-period comet 289P/Blanpain. It peaks around 4–5 December, though is not seen every year. A very minor meteor shower peaks around July 14 with around one meteor an hour, though meteors can be seen anytime from July 3 to 18; this shower is referred to as the July Phoenicids.


</doc>
<doc id="49241" url="https://en.wikipedia.org/wiki?curid=49241" title="Gustav Holst">
Gustav Holst

Gustav Theodore Holst (born Gustavus Theodore von Holst; 21 September 1874 – 25 May 1934) was an English composer, arranger and teacher. Best known for his orchestral suite "The Planets", he composed a large number of other works across a range of genres, although none achieved comparable success. His distinctive compositional style was the product of many influences, Richard Wagner and Richard Strauss being most crucial early in his development. The subsequent inspiration of the English folksong revival of the early 20th century, and the example of such rising modern composers as Maurice Ravel, led Holst to develop and refine an individual style.

There were professional musicians in the previous three generations of Holst's family and it was clear from his early years that he would follow the same calling. He hoped to become a pianist, but was prevented by neuritis in his right arm. Despite his father's reservations, he pursued a career as a composer, studying at the Royal College of Music under Charles Villiers Stanford. Unable to support himself by his compositions, he played the trombone professionally and later became a teacher—a great one, according to his colleague Ralph Vaughan Williams. Among other teaching activities he built up a strong tradition of performance at Morley College, where he served as musical director from 1907 until 1924, and pioneered music education for women at St Paul's Girls' School, where he taught from 1905 until his death in 1934. He was the founder of a series of Whitsun music festivals, which ran from 1916 for the remainder of his life.

Holst's works were played frequently in the early years of the 20th century, but it was not until the international success of "The Planets" in the years immediately after the First World War that he became a well-known figure. A shy man, he did not welcome this fame, and preferred to be left in peace to compose and teach. In his later years his uncompromising, personal style of composition struck many music lovers as too austere, and his brief popularity declined. Nevertheless, he was a significant influence on a number of younger English composers, including Edmund Rubbra, Michael Tippett and Benjamin Britten. Apart from "The Planets" and a handful of other works, his music was generally neglected until the 1980s, when recordings of much of his output became available.

Holst was born in Cheltenham, Gloucestershire, the elder of the two children of Adolph von Holst, a professional musician, and his wife, Clara Cox, "née" Lediard. She was of mostly British descent, daughter of a respected Cirencester solicitor; the Holst side of the family was of mixed Swedish, Latvian and German ancestry, with at least one professional musician in each of the previous three generations.

One of Holst's great-grandfathers, Matthias Holst, born in Riga, Latvia, was of German origin; he served as composer and harp-teacher to the Imperial Russian Court in St Petersburg. Matthias's son Gustavus, who moved to England with his parents as a child in 1802, was a composer of salon-style music and a well-known harp teacher. He appropriated the aristocratic prefix "von" and added it to the family name in the hope of gaining enhanced prestige and attracting pupils.

Holst's father, Adolph von Holst, became organist and choirmaster at All Saints' Church, Cheltenham; he also taught, and gave piano recitals. His wife, Clara, a former pupil, was a talented singer and pianist. They had two sons; Gustav's younger brother, Emil Gottfried, became known as Ernest Cossart, a successful actor in the West End, New York and Hollywood. Clara died in February 1882, and the family moved to another house in Cheltenham, where Adolph recruited his sister Nina to help raise the boys. Gustav recognised her devotion to the family and dedicated several of his early compositions to her. In 1885 Adolph married Mary Thorley Stone, another of his pupils. They had two sons, Matthias (known as "Max") and Evelyn ("Thorley"). Mary von Holst was absorbed in theosophy and not greatly interested in domestic matters. All four of Adolph's sons were subject to what one biographer calls "benign neglect", and Gustav in particular was "not overburdened with attention or understanding, with a weak sight and a weak chest, both neglected—he was 'miserable and scared'."

Holst was taught to play the piano and the violin; he enjoyed the former but hated the latter. At the age of twelve he took up the trombone at Adolph's suggestion, thinking that playing a brass instrument might improve his asthma. Holst was educated at Cheltenham Grammar School between 1886 and 1891. He started composing in or about 1886; inspired by Macaulay's poem "" he began, but soon abandoned, an ambitious setting of the work for chorus and orchestra. His early compositions included piano pieces, organ voluntaries, songs, anthems and a symphony (from 1892). His main influences at this stage were Mendelssohn, Chopin, Grieg and above all Sullivan.

Adolph tried to steer his son away from composition, hoping that he would have a career as a pianist. Holst was oversensitive and miserable. His eyes were weak, but no one realized that he needed to wear spectacles. Holst's health played a decisive part in his musical future; he had never been strong, and in addition to his asthma and poor eyesight he suffered from neuritis, which made playing the piano difficult. He said that the affected arm was "like a jelly overcharged with electricity".

After Holst left school in 1891, Adolph paid for him to spend four months in Oxford studying counterpoint with George Frederick Sims, organist of Merton College. On his return, Holst obtained his first professional appointment, aged seventeen, as organist and choirmaster at Wyck Rissington, Gloucestershire. The post brought with it the conductorship of the Bourton-on-the-Water Choral Society, which offered no extra remuneration but provided valuable experience that enabled him to hone his conducting skills. In November 1891 Holst gave what was perhaps his first public performance as a pianist; he and his father played the Brahms "Hungarian Dances" at a concert in Cheltenham. The programme for the event gives his name as "Gustav" rather than "Gustavus"; he was called by the shorter version from his early years.

In 1892 Holst wrote the music for an operetta in the style of Gilbert and Sullivan, "Lansdown Castle, or The Sorcerer of Tewkesbury". The piece was performed at Cheltenham Corn Exchange in February 1893; it was well received and its success encouraged him to persevere with composing. He applied for a scholarship at the Royal College of Music (RCM) in London, but the composition scholarship for that year was won by Samuel Coleridge-Taylor. Holst was accepted as a non-scholarship student, and Adolph borrowed £100 to cover the first year's expenses. Holst left Cheltenham for London in May 1893. Money was tight, and partly from frugality and partly from his own inclination he became a vegetarian and a teetotaller. Two years later he was finally granted a scholarship, which slightly eased his financial difficulties, but he retained his austere personal regime.

Holst's professors at the RCM were Frederick Sharpe (piano), William Stephenson Hoyte (organ), George Case (trombone), Georges Jacobi (instrumentation) and the director of the college, Hubert Parry (history). After preliminary lessons with W. S. Rockstro and Frederick Bridge, Holst was granted his wish to study composition with Charles Villiers Stanford.

To support himself during his studies Holst played the trombone professionally, at seaside resorts in the summer and in London theatres in the winter. His daughter and biographer, Imogen Holst, records that from his fees as a player "he was able to afford the necessities of life: board and lodging, manuscript paper, and tickets for standing room in the gallery at Covent Garden Opera House on Wagner evenings". He secured an occasional engagement in symphony concerts, playing in 1897 under the baton of Richard Strauss at the Queen's Hall.

Like many musicians of his generation, Holst came under Wagner's spell. He had recoiled from the music of "Götterdämmerung" when he heard it at Covent Garden in 1892, but encouraged by his friend and fellow-student Fritz Hart he persevered and quickly became an ardent Wagnerite. Wagner supplanted Sullivan as the main influence on his music, and for some time, as Imogen put it, "ill-assimilated wisps of "Tristan" inserted themselves on nearly every page of his own songs and overtures." Stanford admired some of Wagner's works, and had in his earlier years been influenced by him, but Holst's sub-Wagnerian compositions met with his disapprobation: "It won't do, me boy; it won't do". Holst respected Stanford, describing him to a fellow-pupil, Herbert Howells, as "the one man who could get any one of us out of a technical mess", but he found that his fellow students, rather than the faculty members, had the greater influence on his development.

In 1895, shortly after celebrating his twenty-first birthday, Holst met Ralph Vaughan Williams, who became a lifelong friend and had more influence on Holst's music than anybody else. Stanford emphasised the need for his students to be self-critical, but Holst and Vaughan Williams became one another's chief critics; each would play his latest composition to the other while still working on it. Vaughan Williams later observed, "What one really learns from an Academy or College is not so much from one's official teachers as from one's fellow-students ... [we discussed] every subject under the sun from the lowest note of the double bassoon to the philosophy of "Jude the Obscure". In 1949 he wrote of their relationship, "Holst declared that his music was influenced by that of his friend: the converse is certainly true."

The year 1895 was also the bicentenary of Henry Purcell, which was marked by various performances including Stanford conducting "Dido and Aeneas" at the Lyceum Theatre; the work profoundly impressed Holst, who over twenty years later confessed to a friend that his search for "the (or a) musical idiom of the English language" had been inspired "unconsciously" by "hearing the recits in Purcell's "Dido"".

Another early influence was William Morris. In Vaughan Williams's words, "It was now that Holst discovered the feeling of unity with his fellow men which made him afterwards a great teacher. A sense of comradeship rather than political conviction led him, while still a student, to join the Kelmscott House Socialist Club in Hammersmith." At Kelmscott House, Morris's home, Holst attended lectures by his host and Bernard Shaw. His own socialism was moderate in character, but he enjoyed the club for its good company and his admiration of Morris as a man. His ideals were influenced by Morris's but had a different emphasis. Morris had written, "I do not want art for a few any more than education for a few, or freedom for a few. I want all persons to be educated according to their capacity, not according to the amount of money which their parents happen to have". Holst said, "'Aristocracy in art'—art is not for all but only for the chosen few—but the only way to find those few is to bring art to everyone—then the artists have a sort of masonic signal by which they recognise each other in the crowd." He was invited to conduct the Hammersmith Socialist Choir, teaching them madrigals by Thomas Morley, choruses by Purcell, and works by Mozart, Wagner and himself. One of his choristers was (Emily) Isobel Harrison (1876–1969), a beautiful soprano two years his junior. He fell in love with her; she was at first unimpressed by him, but she came round and they were engaged, though with no immediate prospect of marriage given Holst's tiny income.

In 1898 the RCM offered Holst a further year's scholarship, but he felt that he had learned as much as he could there and that it was time, as he put it, to "learn by doing". Some of his compositions were published and performed; the previous year "The Times" had praised his song "Light Leaves Whisper", "a moderately elaborate composition in six parts, treated with a good deal of expression and poetic feeling".

Occasional successes notwithstanding, Holst found that "man cannot live by composition alone"; he took posts as organist at various London churches, and continued playing the trombone in theatre orchestras. In 1898 he was appointed first trombonist and "répétiteur" with the Carl Rosa Opera Company and toured with the Scottish Orchestra. Though a capable rather than a virtuoso player he won the praise of the leading conductor Hans Richter, for whom he played at Covent Garden. His salary was only just enough to live on, and he supplemented it by playing in a popular orchestra called the "White Viennese Band", conducted by Stanislas Wurm.

Holst enjoyed playing for Wurm, and learned much from him about drawing rubato from players. Nevertheless, longing to devote his time to composing, Holst found the necessity of playing for "the Worm" or any other light orchestra "a wicked and loathsome waste of time". Vaughan Williams did not altogether agree with his friend about this; he admitted that some of the music was "trashy" but thought it had been useful to Holst nonetheless: "To start with, the very worst a trombonist has to put up with is as nothing compared to what a church organist has to endure; and secondly, Holst is above all an orchestral composer, and that sure touch which distinguishes his orchestral writing is due largely to the fact that he has been an orchestral player; he has learnt his art, both technically and in substance, not at second hand from text books and models, but from actual live experience."

With a modest income secured, Holst was able to marry Isobel; the ceremony was at Fulham Register Office on 22 June 1901. Their marriage lasted until his death; there was one child, Imogen, born in 1907. In 1902 Dan Godfrey and the Bournemouth Municipal Orchestra premiered Holst's symphony "The Cotswolds" (Op. 8), the slow movement of which is a lament for William Morris who had died in October 1896, three years before Holst began work on the piece. In 1903 Adolph von Holst died, leaving a small legacy. Holst and his wife decided, as Imogen later put it, that "as they were always hard up the only thing to do was to spend it all at once on a holiday in Germany".

While in Germany, Holst reappraised his professional life, and in 1903 he decided to abandon orchestral playing to concentrate on composition. His earnings as a composer were too little to live on, and two years later he accepted the offer of a teaching post at James Allen's Girls' School, Dulwich, which he held until 1921. He also taught at the Passmore Edwards Settlement, where among other innovations he gave the British premieres of two Bach cantatas. The two teaching posts for which he is probably best known were director of music at St Paul's Girls' School, Hammersmith, from 1905 until his death, and director of music at Morley College from 1907 to 1924.

Vaughan Williams wrote of the former establishment: "Here he did away with the childish sentimentality which schoolgirls were supposed to appreciate and substituted Bach and Vittoria; a splendid background for immature minds." Several of Holst's pupils at St Paul's went on to distinguished careers, including the soprano Joan Cross, and the oboist and cor anglais player Helen Gaskell.

Of Holst's impact on Morley College, Vaughan Williams wrote: "[A] bad tradition had to be broken down. The results were at first discouraging, but soon a new spirit appeared and the music of Morley College, together with its offshoot the 'Whitsuntide festival' ... became a force to be reckoned with". Before Holst's appointment, Morley College had not treated music very seriously (Vaughan Williams's "bad tradition"), and at first Holst's exacting demands drove many students away. He persevered, and gradually built up a class of dedicated music-lovers.

According to the composer Edmund Rubbra, who studied under him in the early 1920s, Holst was "a teacher who often came to lessons weighted, not with the learning of Prout and Stainer, but with a miniature score of "Petrushka" or the then recently published Mass in G minor of Vaughan Williams". He never sought to impose his own ideas on his composition pupils. Rubbra recalled that he would divine a student's difficulties and gently guide him to finding the solution for himself. "I do not recall that Holst added one single note of his own to anything I wrote, but he would suggest—if I agreed!—that, given such and such a phrase, the following one would be better if it took such and such a course; if I did not see this, the point would not be insisted upon ... He frequently took away [because of] his abhorrence of unessentials."
As a composer Holst was frequently inspired by literature. He set poetry by Thomas Hardy and Robert Bridges and, a particular influence, Walt Whitman, whose words he set in "Dirge for Two Veterans" and "The Mystic Trumpeter" (1904). He wrote an orchestral "Walt Whitman Overture" in 1899. While on tour with the Carl Rosa company Holst had read some of Max Müller's books, which inspired in him a keen interest in Sanskrit texts, particularly the Rig Veda hymns. He found the existing English versions of the texts unconvincing, and decided to make his own translations, despite his lack of skills as a linguist. He enrolled in 1909 at University College, London, to study the language.

Imogen commented on his translations: "He was not a poet, and there are occasions when his verses seem naïve. But they never sound vague or slovenly, for he had set himself the task of finding words that would be 'clear and dignified' and that would 'lead the listener into another world'". His settings of translations of Sanskrit texts included "Sita" (1899–1906), a three-act opera based on an episode in the "Ramayana" (which he eventually entered for a competition for English opera set by the Milan music publisher Tito Ricordi); "Savitri" (1908), a chamber opera based on a tale from the "Mahabharata"; four groups of "Hymns from the Rig Veda" (1908–14); and two texts originally by Kālidāsa: "Two Eastern Pictures" (1909–10) and "The Cloud Messenger" (1913).

Towards the end of the nineteenth century, British musical circles had experienced a new interest in national folk music. Some composers, such as Sullivan and Elgar, remained indifferent, but Parry, Stanford, Stainer and Alexander Mackenzie were founding members of the Folk-Song Society. Parry considered that by recovering English folk song, English composers would find an authentic national voice; he commented, "in true folk-songs there is no sham, no got-up glitter, and no vulgarity". Vaughan Williams was an early and enthusiastic convert to this cause, going round the English countryside collecting and noting down folk songs. These had an influence on Holst. Though not as passionate on the subject as his friend, he incorporated a number of folk melodies in his own compositions and made several arrangements of folk songs collected by others. The "Somerset Rhapsody" (1906–07), was written at the suggestion of the folk-song collector Cecil Sharp and made use of tunes that Sharp had noted down. Holst described its performance at the Queen's Hall in 1910 as "my first real success". A few years later Holst became excited by another musical renaissance—the rediscovery of English madrigal composers. Weelkes was his favourite of all the Tudor composers, but Byrd also meant much to him.
Holst was a keen rambler. He walked extensively in England, Italy, France and Algeria. In 1908 he travelled to Algeria on medical advice as a treatment for asthma and the depression that he suffered after his opera "Sita" failed to win the Ricordi prize. This trip inspired the suite "Beni Mora", which incorporated music he heard in the Algerian streets. Vaughan Williams wrote of this exotic work, "if it had been played in Paris rather than London it would have given its composer a European reputation, and played in Italy would probably have caused a riot."

In June 1911 Holst and his Morley College students gave the first performance since the seventeenth century of Purcell's "The Fairy-Queen". The full score had been lost soon after Purcell's death in 1695, and had only recently been found. Twenty-eight Morley students copied out the complete vocal and orchestral parts. There were 1,500 pages of music and it took the students almost eighteen months to copy them out in their spare time. A concert performance of the work was given at The Old Vic, preceded by an introductory talk by Vaughan Williams. "The Times" praised Holst and his forces for "a most interesting and artistic performance of this very important work".

After this success, Holst was disappointed the following year by the lukewarm reception of his choral work "The Cloud Messenger". He again went travelling, accepting an invitation from H. Balfour Gardiner to join him and the brothers Clifford and Arnold Bax in Spain. During this holiday Clifford Bax introduced Holst to astrology, an interest that later inspired his suite "The Planets". Holst cast his friends' horoscopes for the rest of his life and referred to astrology as his "pet vice".

In 1913, St Paul's Girls' School opened a new music wing, and Holst composed "St Paul's Suite" for the occasion. The new building contained a sound-proof room, handsomely equipped, where he could work undisturbed. Holst and his family moved to a house in Brook Green, very close to the school. For the previous six years they had lived in a pretty house overlooking the Thames at Barnes, but the river air, frequently foggy, affected his breathing. For use at weekends and during school holidays, Holst and his wife bought a cottage in Thaxted, Essex, surrounded by mediaeval buildings and ample rambling opportunities. In 1917 they moved to a house in the centre of the town, where they stayed until 1925.
At Thaxted, Holst became friendly with the Rev Conrad Noel, known as the "Red Vicar", who supported the Independent Labour Party and espoused many causes unpopular with conservative opinion. Noel also encouraged the revival of folk-dancing and processionals as part of church ceremonies, innovations which caused controversy among traditionally-minded churchgoers. Holst became an occasional organist and choirmaster at Thaxted Parish Church; he also developed an interest in bell-ringing. He started an annual music festival at Whitsuntide in 1916; students from Morley College and St Paul's Girls' School performed together with local participants.

Holst's "a cappella" carol, "This Have I Done For My True Love", was dedicated to Noel in recognition of his interest in the ancient origins of religion (the composer always referred to the work as "The Dancing Day"). It received its first performance during the Third Whitsun Festival at Thaxted in May 1918. During that festival, Noel, a staunch supporter of Russia's October Revolution, demanded in a Saturday message during the service that there should be a greater political commitment from those who participated in the church activities; his claim that several of Holst's pupils (implicitly those from St Paul's Girls' School) were merely "camp followers" caused offence. Holst, anxious to protect his students from being embroiled in ecclesiastical conflict, moved the Whitsun Festival to Dulwich, though he himself continued to help with the Thaxted choir and to play the church organ on occasion.

At the outbreak of the First World War, Holst tried to enlist but was rejected as unfit for military service. He felt frustrated that he could not contribute to the war effort. His wife became a volunteer ambulance driver; Vaughan Williams went on active service to France as did Holst's brother Emil; Holst's friends the composers George Butterworth and Cecil Coles were killed in battle. He continued to teach and compose; he worked on "The Planets" and prepared his chamber opera "Savitri" for performance. It was first given in December 1916 by students of the London School of Opera at the Wellington Hall in St John's Wood. It attracted no attention at the time from the main newspapers, though when professionally staged five years later it was greeted as "a perfect little masterpiece." In 1917 he wrote "The Hymn of Jesus" for chorus and orchestra, a work which remained unperformed until after the war.

In 1918, as the war neared its end, Holst finally had the prospect of a job that offered him the chance to serve. The music section of the YMCA's education department needed volunteers to work with British troops stationed in Europe awaiting demobilisation. Morley College and St Paul's Girls' School offered him a year's leave of absence, but there remained one obstacle: the YMCA felt that his surname looked too German to be acceptable in such a role. He formally changed "von Holst" to "Holst" by deed poll in September 1918. He was appointed as the YMCA's musical organiser for the Near East, based in Salonica.
Holst was given a spectacular send-off. The conductor Adrian Boult recalled, "Just before the Armistice, Gustav Holst burst into my office: 'Adrian, the YMCA are sending me to Salonica quite soon and Balfour Gardiner, bless his heart, has given me a parting present consisting of the Queen's Hall, full of the Queen's Hall Orchestra for the whole of a Sunday morning. So we're going to do "The Planets", and you've got to conduct'." There was a burst of activity to get things ready in time. The girls at St Paul's helped to copy out the orchestral parts, and the women of Morley and the St Paul's girls learned the choral part in the last movement.

The performance was given on 29 September to an invited audience including Sir Henry Wood and most of the professional musicians in London. Five months later, when Holst was in Greece, Boult introduced "The Planets" to the general public, at a concert in February 1919; Holst sent him a long letter full of suggestions, but failed to convince him that the suite should be played in full. The conductor believed that about half an hour of such radically new music was all the public could absorb at first hearing, and he gave only five of the seven movements on that occasion.

Holst enjoyed his time in Salonica, from where he was able to visit Athens, which greatly impressed him. His musical duties were wide-ranging, and even obliged him on occasion to play the violin in the local orchestra: "it was great fun, but I fear I was not of much use". He returned to England in June 1919.

On his return from Greece, Holst resumed his teaching and composing. In addition to his existing work he accepted a lectureship in composition at the University of Reading and joined Vaughan Williams in teaching composition at their "alma mater" the RCM. Inspired by Adrian Boult's conducting classes at the RCM, Holst tried to further pioneer music education for women by proposing to the High Mistress of St Paul's Girls' School that he should invite Boult to give classes at the school: "It would be glorious if the SPGS turned out the only women conductors in the world!" In his soundproof room at SPGS he composed the "Ode to Death", a setting of a poem by Whitman, which according to Vaughan Williams is considered by many to be Holst's most beautiful choral work.
Holst, in his forties, suddenly found himself in demand. The New York Philharmonic and Chicago Symphony Orchestra vied to be the first to play "The Planets" in the US. The success of that work was followed in 1920 by an enthusiastic reception for "The Hymn of Jesus", described in "The Observer" as "one of the most brilliant and one of the most sincere pieces of choral and orchestral expression heard for some years." "The Times" called it "undoubtedly the most strikingly original choral work which has been produced in this country for many years."

To his surprise and dismay Holst was becoming famous. Celebrity was something wholly foreign to his nature. As the music scholar Byron Adams puts it, "he struggled for the rest of his life to extricate himself from the web of garish publicity, public incomprehension and professional envy woven about him by this unsought-for success." He turned down honours and awards proffered to him, and refused to grant interviews or sign autographs.

Holst's comic opera "The Perfect Fool" (1923) was widely seen as a satire of "Parsifal", though Holst firmly denied it. The piece, with Maggie Teyte in the leading soprano role and Eugene Goossens conducting, was enthusiastically received at its premiere in the Royal Opera House. At a concert in Reading in 1923, Holst slipped and fell, suffering concussion. He seemed to make a good recovery, and he felt up to accepting an invitation to the US, lecturing and conducting at the University of Michigan. After he returned he found himself more and more in demand, to conduct, prepare his earlier works for publication, and, as before, to teach. The strain caused by these demands on him was too great; on doctor's orders he cancelled all professional engagements during 1924, and retreated to Thaxted. In 1925 he resumed his work at St Paul's Girls' School, but did not return to any of his other posts.

Holst's productivity as a composer benefited almost at once from his release from other work. His works from this period include the "Choral Symphony" to words by Keats (a "Second Choral Symphony" to words by George Meredith exists only in fragments). A short Shakespearian opera, "At the Boar's Head", followed; neither had the immediate popular appeal of "A Moorside Suite" for brass band of 1928.

In 1927 Holst was commissioned by the New York Symphony Orchestra to write a symphony. Instead, he wrote an orchestral piece "Egdon Heath", inspired by Thomas Hardy's Wessex. It was first performed in February 1928, a month after Hardy's death, at a memorial concert. By this time the public's brief enthusiasm for everything Holstian was waning, and the piece was not well received in New York. Olin Downes in "The New York Times" opined that "the new score seemed long and undistinguished". The day after the American performance, Holst conducted the City of Birmingham Orchestra in the British premiere. "The Times" acknowledged the bleakness of the work but allowed that it matched Hardy's grim view of the world: ""Egdon Heath" is not likely to be popular, but it says what the composer wants to say, whether we like it or not, and truth is one aspect of duty." Holst had been distressed by hostile reviews of some of his earlier works, but he was indifferent to critical opinion of "Egdon Heath", which he regarded as, in Adams's phrase, his "most perfectly realized composition".

Towards the end of his life Holst wrote the "Choral Fantasia" (1930) and he was commissioned by the BBC to write a piece for military band; the resulting prelude and scherzo "Hammersmith" was a tribute to the place where he had spent most of his life. The composer and critic Colin Matthews considers the work "as uncompromising in its way as "Egdon Heath", discovering, in the words of Imogen Holst, 'in the middle of an over-crowded London ... the same tranquillity that he had found in the solitude of Egdon Heath'". The work was unlucky in being premiered at a concert that also featured the London premiere of Walton's "Belshazzar's Feast", by which it was somewhat overshadowed.

Holst wrote a score for a British film, "The Bells" (1931), and was amused to be recruited as an extra in a crowd scene. Both film and score are now lost. He wrote a "jazz band piece" that Imogen later arranged for orchestra as "Capriccio". Having composed operas throughout his life with varying success, Holst found for his last opera, "The Wandering Scholar", what Matthews calls "the right medium for his oblique sense of humour, writing with economy and directness".

Harvard University offered Holst a lectureship for the first six months of 1932. Arriving via New York he was pleased to be reunited with his brother, Emil, whose acting career under the name of Ernest Cossart had taken him to Broadway; but Holst was dismayed by the continual attentions of press interviewers and photographers. He enjoyed his time at Harvard, but was taken ill while there: a duodenal ulcer prostrated him for some weeks. He returned to England, joined briefly by his brother for a holiday together in the Cotswolds. His health declined, and he withdrew further from musical activities. One of his last efforts was to guide the young players of the St Paul's Girls' School orchestra through one of his final compositions, the "Brook Green Suite", in March 1934.

Holst died in London on 25 May 1934, at the age of 59, of heart failure following an operation on his ulcer. His ashes were interred at Chichester Cathedral in Sussex, close to the memorial to Thomas Weelkes, his favourite Tudor composer. Bishop George Bell gave the memorial oration at the funeral, and Vaughan Williams conducted music by Holst and himself.

Holst's absorption of folksong, not only in the melodic sense but in terms of its simplicity and economy of expression, helped to develop a style that many of his contemporaries, even admirers, found austere and cerebral. This is contrary to the popular identification of Holst with "The Planets", which Matthews believes has masked his status as a composer of genuine originality. Against charges of coldness in the music, Imogen cites Holst's characteristic "sweeping modal tunes mov[ing] reassuringly above the steps of a descending bass", while Michael Kennedy points to the 12 Humbert Wolfe settings of 1929, and the 12 Welsh folksong settings for unaccompanied chorus of 1930–31, as works of true warmth.

Many of the characteristics that Holst employed — unconventional time signatures, rising and falling scales, ostinato, bitonality and occasional polytonality — set him apart from other English composers. Vaughan Williams remarked that Holst always said in his music what he wished to say, directly and concisely; "He was not afraid of being obvious when the occasion demanded, nor did he hesitate to be remote when remoteness expressed his purpose". Kennedy has surmised that Holst's economy of style was in part a product of the composer's poor health: "the effort of writing it down compelled an artistic economy which some felt was carried too far". However, as an experienced instrumentalist and orchestra member, Holst understood music from the standpoint of his players and made sure that, however challenging, their parts were always practicable. According to his pupil Jane Joseph, Holst fostered in performance "a spirit of practical comradeship ... none could know better than he the boredom possible to a professional player, and the music that rendered boredom impossible".

Although Holst wrote a large number of works—particularly songs—during his student days and early adulthood, almost everything he wrote before 1904 he later classified as derivative "early horrors". Nevertheless, the composer and critic Colin Matthews recognises even in these apprentice works an "instinctive orchestral flair". Of the few pieces from this period which demonstrate some originality, Matthews pinpoints the G minor String Trio of 1894 (unperformed until 1974) as the first underivative work produced by Holst. Matthews and Imogen Holst each highlight the "Elegy" movement in "The Cotswold Symphony" (1899–1900) as among the more accomplished of the apprentice works, and Imogen discerns glimpses of her father's real self in the 1899 "Suite de ballet" and the "Ave Maria" of 1900. She and Matthews have asserted that Holst found his genuine voice in his setting of Whitman's verses, "The Mystic Trumpeter" (1904), in which the trumpet calls that characterise Mars in "The Planets" are briefly anticipated. In this work, Holst first employs the technique of bitonality—the use of two keys simultaneously.

At the beginning of the 20th century, according to Matthews, it appeared that Holst might follow Schoenberg into late Romanticism. Instead, as Holst recognised afterwards, his encounter with Purcell's "Dido and Aeneas" prompted his searching for a "musical idiom of the English language"; the folksong revival became a further catalyst for Holst to seek inspiration from other sources during the first decade or so of the new century.

Holst's interest in Indian mythology, shared by many of his contemporaries, first became musically evident in the opera "Sita" (1901–06). During the opera's long gestation, Holst worked on other Indian-themed pieces. These included "Maya" (1901) for violin and piano, regarded by the composer and writer Raymond Head as "an insipid salon-piece whose musical language is dangerously close to Stephen Adams". Then, through Vaughan Williams, Holst discovered and became an admirer of the music of Ravel, whom he considered a "model of purity" on the level with Haydn, another composer he greatly admired.

The combined influence of Ravel, Hindu spiritualism and English folk tunes enabled Holst to get beyond the once all-consuming influences of Wagner and Richard Strauss and to forge his own style. Imogen Holst has acknowledged Holst's own suggestion (written to Vaughan Williams): "[O]ne ought to follow Wagner until he leads you to fresh things". She notes that although much of his grand opera, "Sita", is "'good old Wagnerian bawling' ... towards the end a change comes over the music, and the beautifully calm phrases of the hidden chorus representing the Voice of the Earth are in Holst's own language."

According to Rubbra, the publication in 1911 of Holst's Rig Veda Hymns was a landmark event in the composer's development: "Before this, Holst's music had, indeed, shown the clarity of utterance which has always been his characteristic, but harmonically there was little to single him out as an important figure in modern music." Dickinson describes these vedic settings as pictorial rather than religious; although the quality is variable the sacred texts clearly "touched vital springs in the composer's imagination". While the music of Holst's Indian verse settings remained generally western in character, in some of the vedic settings he experimented with Indian "raga" (scales).

The chamber opera "Savitri" (1908) is written for three solo voices, a small hidden female chorus, and an instrumental combination of two flutes, a cor anglais and a double string quartet. The music critic John Warrack comments on the "extraordinary expressive subtlety" with which Holst deploys the sparse forces: "... [T]he two unaccompanied vocal lines opening the work skilfully convey the relationship between Death, steadily advancing through the forest, and Savitri, her frightened answers fluttering round him, unable to escape his harmonic pull." Head describes the work as unique in its time for its compact intimacy, and considers it Holst's most successful attempt to end the domination of Wagnerian chromaticism in his music. Dickinson considers it a significant step, "not towards opera, but towards an idiomatic pursuit of [Holst's] vision". Of the Kālidāsa texts, Dickinson dismisses "The Cloud Messenger" (1910–12) as an "accumulation of desultory incidents, opportunistic dramatic episodes and ecstatic outpourings" which illustrate the composer's creative confusion during that period; the "Two Eastern Pictures" (1911), in Dickinson's view, provide "a more memorable final impression of Kālidāsa".

Holst's settings of Indian texts formed only a part of his compositional output in the period 1900 to 1914. A highly significant factor in his musical development was the English folksong revival, evident in the orchestral suite "A Somerset Rhapsody" (1906–07), a work that was originally to be based around eleven folksong themes; this was later reduced to four. Observing the work's kinship with Vaughan Williams's "Norfolk Rhapsody", Dickinson remarks that, with its firm overall structure, Holst's composition "rises beyond the level of ... a song-selection". Imogen acknowledges that Holst's discovery of English folksongs "transformed his orchestral writing", and that the composition of "A Somerset Rhapsody" did much to banish the chromaticisms that had dominated his early compositions. In the "Two Songs without Words" of 1906, Holst showed that he could create his own original music using the folk idiom. An orchestral folksong fantasy "Songs of the West", also written in 1906, was withdrawn by the composer and never published, although it emerged in the 1980s in the form of an arrangement for wind band by James Curnow.

In the years before the First World War, Holst composed in a variety of genres. Matthews considers the evocation of a North African town in the "Beni Mora" suite of 1908 the composer's most individual work to that date; the third movement gives a preview of minimalism in its constant repetition of a four-bar theme. Holst wrote two suites for military band, in E flat (1909) and F major (1911) respectively, the first of which became and remains a brass-band staple. This piece, a highly original and substantial musical work, was a signal departure from what Short describes as "the usual transcriptions and operatic selections which pervaded the band repertoire". Also in 1911 he wrote "Hecuba's Lament", a setting of Gilbert Murray's translation from Euripides built on a seven-beat refrain designed, says Dickinson, to represent Hecuba's defiance of divine wrath. In 1912 Holst composed two psalm settings, in which he experimented with plainsong; the same year saw the enduringly popular "St Paul's Suite" (a "gay but retrogressive" piece according to Dickinson), and the failure of his large scale orchestral work "Phantastes".

Holst conceived the idea of "The Planets" in 1913, partly as a result of his interest in astrology, and also from his determination, despite the failure of "Phantastes", to produce a large-scale orchestral work. The chosen format may have been influenced by Schoenberg's "Fünf Orchesterstücke", and shares something of the aesthetic, Matthews suggests, of Debussy's "Nocturnes" or "La mer". Holst began composing "The Planets" in 1914; the movements appeared not quite in their final sequence; "Mars" was the first to be written, followed by "Venus" and "Jupiter". "Saturn", "Uranus" and "Neptune" were all composed during 1915, and "Mercury" was completed in 1916.

Each planet is represented with a distinct character; Dickinson observes that "no planet borrows colour from another". In "Mars", a persistent, uneven rhythmic cell consisting of five beats, combined with trumpet calls and harmonic dissonance provides battle music which Short asserts is unique in its expression of violence and sheer terror, "... Holst's intention being to portray the reality of warfare rather than to glorify deeds of heroism". In "Venus", Holst incorporated music from an abandoned vocal work, "A Vigil of Pentecost", to provide the opening; the prevalent mood within the movement is of peaceful resignation and nostalgia. "Mercury" is dominated by uneven metres and rapid changes of theme, to represent the speedy flight of the winged messenger. "Jupiter" is renowned for its central melody, "Thaxted", in Dickinson's view "a fantastic relaxation in which many retain a far from sneaking delight". Dickinson and other critics have decried the later use of the tune in the patriotic hymn "I Vow to Thee, My Country"—despite Holst's full complicity.

For "Saturn", Holst again used a previously-composed vocal piece, "Dirge and Hymeneal", as the basis for the movement, where repeated chords represent the relentless approach of old age. "Uranus", which follows, has elements of Berlioz's "Symphonie fantastique" and Dukas's "The Sorcerer's Apprentice", in its depiction of the magician who "disappears in a whiff of smoke as the sonic impetus of the movement diminishes from fff to ppp in the space of a few bars". "Neptune", the final movement, concludes with a wordless female chorus gradually receding, an effect which Warrack likens to "unresolved timelessness ... never ending, since space does not end, but drifting away into eternal silence". Apart from his concession with "I Vow to Thee..."', Holst insisted on the unity of the whole work, and opposed the performance of individual movements. Nevertheless, Imogen wrote that the piece had "suffered from being quoted in snippets as background music".

During and after the composition of "The Planets", Holst wrote or arranged numerous vocal and choral works, many of them for the wartime Thaxted Whitsun Festivals, 1916–18. They include the "Six Choral Folksongs" of 1916, based on West Country tunes, of which "Swansea Town", with its "sophisticated tone", is deemed by Dickinson to be the most memorable. Holst downplayed such music as "a limited form of art" in which "mannerisms are almost inevitable"; the composer Alan Gibbs, however, believes Holst's set at least equal to Vaughan Williams's "Five English Folk Songs" of 1913.

Holst's first major work after "The Planets" was the "Hymn of Jesus", completed in 1917. The words are from a Gnostic text, the apocryphal Acts of St John, using a translation from the Greek which Holst prepared with assistance from Clifford Bax and Jane Joseph. Head comments on the innovative character of the "Hymn": "At a stroke Holst had cast aside the Victorian and Edwardian sentimental oratorio, and created the precursor of the kind of works that John Tavener, for example, was to write in the 1970s". Matthews has written that the "Hymn"s "ecstatic" quality is matched in English music "perhaps only by Tippett's "The Vision of Saint Augustine""; the musical elements include plainsong, two choirs distanced from each other to emphasise dialogue, dance episodes and "explosive chordal dislocations".

In the "Ode to Death" (1918–19), the quiet, resigned mood is seen by Matthews as an "abrupt volte-face" after the life-enhancing spirituality of the "Hymn". Warrack refers to its aloof tranquillity; Imogen Holst believed the "Ode" expressed Holst's private attitude to death. The piece has rarely been performed since its premiere in 1922, although the composer Ernest Walker thought it was Holst's finest work to that date.

The influential critic Ernest Newman considered "The Perfect Fool" "the best of modern British operas", but its unusually short length (about an hour) and parodic, whimsical nature—described by "The Times" as "a brilliant puzzle"—put it outside the operatic mainstream. Only the ballet music from the opera, which "The Times" called "the most brilliant thing in a work glittering with brilliant moments", has been regularly performed since 1923. Holst's libretto attracted much criticism, although Edwin Evans remarked on the rare treat in opera of being able to hear the words being sung.

Before his enforced rest in 1924, Holst demonstrated a new interest in counterpoint, in his "Fugal Overture" of 1922 for full orchestra and the neo-classical" Fugal Concerto" of 1923, for flute, oboe and strings. In his final decade he mixed song settings and minor pieces with major works and occasional new departures; the 1925 "Terzetto" for flute, violin and oboe, each instrument playing in a different key, is cited by Imogen as Holst's only successful chamber work. Of the "Choral Symphony" completed in 1924, Matthews writes that, after several movements of real quality, the finale is a rambling anticlimax. Holst's penultimate opera, "At the Boar's Head" (1924), is based on tavern scenes from Shakespeare's "Henry IV, Parts 1" and "2". The music, which is largely derived from old English melodies gleaned from Cecil Sharp and other collections, has pace and verve; the contemporary critic Harvey Grace discounted the lack of originality, a facet which he said "can be shown no less convincingly by a composer's handling of material than by its invention".

"Egdon Heath" (1927) was Holst's first major orchestral work after "The Planets". Matthews summarises the music as "elusive and unpredictable [with] three main elements: a pulseless wandering melody [for strings], a sad brass processional, and restless music for strings and oboe." The mysterious dance towards the end is, says Matthews, "the strangest moment in a strange work". Richard Greene in "Music & Letters" describes the piece as "a larghetto dance in a siciliano rhythm with a simple, stepwise, rocking melody", but lacking the power of "The Planets" and, at times, monotonous to the listener. A more popular success was "A Moorside Suite" for brass band, written as a test piece for the National Brass Band Festival championships of 1928. While written within the traditions of north-country brass-band music, the suite, Short says, bears Holst's unmistakable imprint, "from the skipping 6/8 of the opening Scherzo, to the vigorous melodic fourths of the concluding March, the intervening Nocturne bearing a family resemblance to the slow-moving procession of "Saturn"". 'A Moorside Suite' has undergone major revisionism in the article 'Symphony Within: rehearing Holst's 'A Moorside Suite' by Stephen Arthur Allen in the Winter 2017 edition of 'The Musical Times'. As with 'Egdon Heath' – commissioned as a symphony – the article reveals the symphonic nature of this brass-band work.

After this, Holst tackled his final attempt at opera in a cheerful vein, with "The Wandering Scholar" (1929–30), to a text by Clifford Bax. Imogen refers to the music as "Holst at his best in a scherzando (playful) frame of mind"; Vaughan Williams commented on the lively, folksy rhythms: "Do you think there's a "little" bit too much 6/8 in the opera?" Short observes that the opening motif makes several reappearances without being identified with a particular character, but imposes musical unity on the work.

Holst composed few large-scale works in his final years. "A Choral Fantasia" of 1930 was written for the Three Choirs Festival at Gloucester; beginning and ending with a soprano soloist, the work, also involving chorus, strings, brass and percussion, includes a substantial organ solo which, says Imogen Holst, "knows something of the 'colossal and mysterious' loneliness of "Egdon Heath"". Apart from his final uncompleted symphony, Holst's remaining works were for small forces; the eight "Canons" of 1932 were dedicated to his pupils, though in Imogen's view that they present a formidable challenge to the most professional of singers. The "Brook Green Suite" (1932), written for the orchestra of St Paul's School, was a late companion piece to the "St Paul's Suite". The "Lyric Movement" for viola and small orchestra (1933) was written for Lionel Tertis. Quiet and contemplative, and requiring little virtuosity from the soloist, the piece was slow to gain popularity among violists. Robin Hull, in "Penguin Music Magazine", praised the work's "clear beauty—impossible to mistake for the art of any other composer"; in Dickinson's view, however, it remains "a frail creation". Holst's final composition, the orchestral scherzo movement of a projected symphony, contains features characteristic of much of Holst's earlier music—"a summing up of Holst's orchestral art", according to Short. Dickinson suggests that the somewhat casual collection of material in the work gives little indication of the symphony that might have been written.

Holst made some recordings, conducting his own music. For the Columbia company he recorded "Beni Mora", the "Marching Song" and the complete "Planets" with the London Symphony Orchestra (LSO) in 1922, using the acoustic process. The limitations of early recording prevented the gradual fade-out of women's voices at the end of "Neptune", and the lower strings had to be replaced by a tuba to obtain an effective bass sound. With an anonymous string orchestra Holst recorded the "St Paul's Suite" and "Country Song" in 1925. Columbia's main rival, HMV, issued recordings of some of the same repertoire, with an unnamed orchestra conducted by Albert Coates. When electrical recording came in, with dramatically improved recording quality, Holst and the LSO re-recorded "The Planets" for Columbia in 1926.

In the early LP era little of Holst's music was available on disc. Only six of his works are listed in the 1955 issue of "The Record Guide": "The Planets" (recordings under Boult on HMV and Nixa, and another under Sir Malcolm Sargent on Decca); the "Perfect Fool" ballet music; the "St Paul's Suite"; and three short choral pieces. In the stereo LP and CD eras numerous recordings of "The Planets" were issued, performed by orchestras and conductors from round the world. By the early years of the 21st century most of the major and many of the minor orchestral and choral works had been issued on disc. The 2008 issue of "The Penguin Guide to Recorded Classical Music" contained seven pages of listings of Holst's works on CD. Of the operas, "Savitri", "The Wandering Scholar", and "At the Boar's Head" have been recorded.

Warrack emphasises that Holst acquired an instinctive understanding—perhaps more so than any English composer—of the importance of folksong. In it he found "a new concept not only of how melody might be organized, but of what the implications were for the development of a mature artistic language". Holst did not found or lead a school of composition; nevertheless, he exercised influences over both contemporaries and successors. According to Short, Vaughan Williams described Holst as "the greatest influence on my music", although Matthews asserts that each influenced the other equally. Among later composers, Michael Tippett is acknowledged by Short as Holst's "most significant artistic successor", both in terms of compositional style and because Tippett, who succeeded Holst as director of music at Morley College, maintained the spirit of Holst's music there. Of an early encounter with Holst, Tippett later wrote: "Holst seemed to look right inside me, with an acute spiritual vision". Kennedy observes that "a new generation of listeners ... recognized in Holst the fount of much that they admired in the music of Britten and Tippett". Holst's pupil Edmund Rubbra acknowledged how he and other younger English composers had adopted Holst's economy of style: "With what enthusiasm did we pare down our music to the very bone".

Short cites other English composers who are in debt to Holst, in particular William Walton and Benjamin Britten, and suggests that Holst's influence may have been felt further afield. Above all, Short recognises Holst as a composer for the people, who believed it was a composer's duty to provide music for practical purposes—festivals, celebrations, ceremonies, Christmas carols or simple hymn tunes. Thus, says Short, "many people who may never have heard any of [Holst's] major works ... have nevertheless derived great pleasure from hearing or singing such small masterpieces as the carol 'In the Bleak Midwinter'".

On 27 September 2009, after a weekend of concerts at Chichester Cathedral in memory of Holst, a new memorial was unveiled to mark the 75th anniversary of the composer's death. It is inscribed with words from the text of "The Hymn of Jesus": "The heavenly spheres make music for us". In April 2011 a BBC television documentary, "Holst: In the Bleak Midwinter", charted Holst's life with particular reference to his support for socialism and the cause of working people.

Notes

References



</doc>
