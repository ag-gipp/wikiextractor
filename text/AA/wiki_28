<doc id="251489" url="https://en.wikipedia.org/wiki?curid=251489" title="Ironclad warship">
Ironclad warship

An ironclad is a steam-propelled warship protected by iron or steel armor plates used in the early part of the second half of the 19th century. The ironclad was developed as a result of the vulnerability of wooden warships to explosive or incendiary shells. The first ironclad battleship, , was launched by the French Navy in November 1859. The British Admiralty had been considering armored warships since 1856 and prepared a draft design for an armored corvette in 1857; in early 1859 the Royal Navy started building two iron-hulled armored frigates, and by 1861 had made the decision to move to an all-armored battle fleet. After the first clashes of ironclads (both with wooden ships and with one another) took place in 1862 during the American Civil War, it became clear that the ironclad had replaced the unarmored ship of the line as the most powerful warship afloat. This type of ship would come to be very successful in the American Civil War.

Ironclads were designed for several roles, including as high seas battleships, coastal defense ships, and long-range cruisers. The rapid development of warship design in the late 19th century transformed the ironclad from a wooden-hulled vessel that carried sails to supplement its steam engines into the steel-built, turreted battleships and cruisers familiar in the 20th century. This change was pushed forward by the development of heavier naval guns (the ironclads of the 1880s carried some of the heaviest guns ever mounted at sea at the time), more sophisticated steam engines, and advances in metallurgy which made steel shipbuilding possible.

The quick pace of change meant that many ships were obsolete as soon as they were finished, and that naval tactics were in a state of flux. Many ironclads were built to make use of the ram or the torpedo, which a number of naval designers considered the important weapons of naval combat. There is no clear end to the ironclad period, but towards the end of the 1890s the term "ironclad" dropped out of use. New ships were increasingly constructed to a standard pattern and designated battleships or armored cruisers.

The ironclad became technically feasible and tactically necessary because of developments in shipbuilding in the first half of the 19th century. According to naval historian J. Richard Hill: "The (ironclad) had three chief characteristics: a metal-skinned hull, steam propulsion and a main armament of guns capable of firing explosive shells. It is only when all three characteristics are present that a fighting ship can properly be called an ironclad." Each of these developments was introduced separately in the decade before the first ironclads.

In the 18th and early 19th centuries fleets had relied on two types of major warship, the ship of the line and the frigate. The first major change to these types was the introduction of steam power for propulsion. While paddle steamer warships had been used from the 1830s onwards, steam propulsion only became suitable for major warships after the adoption of the screw propeller in the 1840s.

Steam-powered screw frigates were built in the mid-1840s, and at the end of the decade the French Navy introduced steam power to its line of battle. The desire for change came from the ambition of Napoleon III to gain greater influence in Europe, which required a challenge to the British at sea. The first purpose-built steam battleship was the 90-gun in 1850. "Napoléon" was armed as a conventional ship-of-the-line, but her steam engines could give her a speed of 12 knots (22 km/h), regardless of the wind conditions: a potentially decisive advantage in a naval engagement.

The introduction of the steam ship-of-the-line led to a building competition between France and Britain. Eight sister ships to "Napoléon" were built in France over a period of ten years, but the United Kingdom soon managed to take the lead in production. Altogether, France built ten new wooden steam battleships and converted 28 from older ships of the line, while the United Kingdom built 18 and converted 41.

The era of the wooden steam ship-of-the-line was brief, because of new, more powerful naval guns. In the 1820s and 1830s, warships began to mount increasingly heavy guns, replacing 18- and 24-pounder guns with 32-pounders on sailing ships-of-the-line and introducing 68-pounders on steamers. Then, the first shell guns firing explosive shells were introduced following their development by the French Général Henri-Joseph Paixhans, and by the 1840s were part of the standard armament for naval powers including the French Navy, Royal Navy, Imperial Russian Navy and United States Navy. It is often held that the power of explosive shells to smash wooden hulls, as demonstrated by the Russian destruction of an Ottoman squadron at the Battle of Sinop, spelled the end of the wooden-hulled warship. The more practical threat to wooden ships was from conventional cannon firing red-hot shot, which could lodge in the hull of a wooden ship and cause a fire or ammunition explosion. Some navies even experimented with hollow shot filled with molten metal for extra incendiary power.

The use of iron instead of wood as the primary material of ships' hulls began in the 1830s; the first "warship" with an iron hull was the gunboat "Nemesis", built by Jonathan Laird of Birkenhead for the East India Company in 1839. There followed, also from Laird, the first full-blown warships with metal hulls, the 1842 steam frigates "Guadelupe" and "Montezuma" for the Mexican navy. But a thin iron skin, while not being susceptible to fire or lethal splintering like wood, was not the same thing as providing iron "armor" calculated to stop enemy gunfire.

In 1843, the United States Navy launched its first iron warship, USS "Michigan", on the Great Lakes. This pioneering iron-hulled, steam-powered ship served for 70 years in the relatively peaceful region.

Following the demonstration of the power of explosive shells against wooden ships at the Battle of Sinop, and fearing that his own ships would be vulnerable to the Paixhans guns of Russian fortifications in the Crimean War, Emperor Napoleon III ordered the development of light-draft floating batteries, equipped with heavy guns and protected by heavy armor. Experiments made during the first half of 1854 proved highly satisfactory, and on 17 July 1854, the French communicated to the British Government that a solution had been found to make gun-proof vessels and that plans would be communicated. After tests in September 1854, the British Admiralty agreed to build five armored floating batteries on the French plans, establishing the important Thames and Millwall Iron Works within the docks.
The French floating batteries were deployed in 1855 as a supplement to the wooden steam battle fleet in the Crimean War. The role of the battery was to assist unarmored mortar and gunboats bombarding shore fortifications. The French used three of their ironclad batteries ("Lave", "Tonnante" and "Dévastation") in 1855 against the defenses at the Battle of Kinburn on the Black Sea, where they were effective against Russian shore defences. They would later be used again during the Italian war in the Adriatic in 1859. The British floating batteries and arrived too late to participate to the action at Kinburn. The British planned to use theirs in the Baltic Sea against the well-fortified naval base at Kronstadt.

The batteries have a claim to the title of the first ironclad warships but they were capable of only 4 knots (7 km/h) under their own power: they operated under their own power at the Battle of Kinburn, but had to be towed for long range transit. They were also arguably marginal to the work of the navy. The brief success of the floating ironclad batteries convinced France to begin work on armored warships for their battlefleet.

By the end of the 1850s it was clear that France was unable to match British building of steam warships, and to regain the strategic initiative a dramatic change was required. The result was the first ocean-going ironclad, , begun in 1857 and launched in 1859.

"Gloire"s wooden hull was modelled on that of a steam ship of the line, reduced to one deck, sheathed in iron plates 4.5 inches (110 mm) thick. She was propelled by a steam engine, driving a single screw propeller for a speed of 13 knots (24 km/h). She was armed with thirty-six rifled guns. France proceeded to construct 16 ironclad warships, including two more sister ships to "Gloire", and the only two-decked broadside ironclads ever built, and .

The Royal Navy had not been keen to sacrifice its advantage in steam ships of the line, but was determined that the first British ironclad would outmatch the French ships in every respect, particularly speed. A fast ship would have the advantage of being able to choose a range of engagement which could make her invulnerable to enemy fire. The British specification was more a large, powerful frigate than a ship-of-the-line. The requirement for speed meant a very long vessel, which had to be built from iron. The result was the construction of two s; and . The ships had a successful design, though there were necessarily compromises between 'sea-keeping', strategic range and armor protection; their weapons were more effective than that of "Gloire", and with the largest set of steam engines yet fitted to a ship they could steam at 14.3 knots (26.5 km/h). Yet the "Gloire" and her sisters had full iron-armor protection along the waterline and the battery itself. "Warrior" and "Black Prince" (but also the smaller "Defence" and "Resistance") were obliged to concentrate their armor in a central "citadel" or "armoured box", leaving many main deck guns and the fore and aft sections of the vessel unprotected. The use of iron in the construction of "Warrior "also came with some drawbacks; iron hulls required more regular and intensive repairs than wooden hulls, and iron was more susceptible to fouling by marine life.

By 1862, navies across Europe had adopted ironclads. Britain and France each had sixteen either completed or under construction, though the British vessels were larger. Austria, Italy, Russia, and Spain were also building ironclads. However, the first battles using the new ironclad ships involved neither Britain nor France, and involved ships markedly different from the broadside-firing, masted designs of "Gloire" and "Warrior". The use of ironclads by both sides in the American Civil War, and the clash of the Italian and Austrian fleets at the Battle of Lissa, had an important influence on the development of ironclad design.

The first use of ironclads in action came in the U.S. Civil War. The U.S. Navy at the time the war broke out had no ironclads, its most powerful ships being six unarmored steam-powered frigates. Since the bulk of the Navy remained loyal to the Union, the Confederacy sought to gain advantage in the naval conflict by acquiring modern armored ships. In May 1861, the Confederate Congress appropriated $2 million for the purchase of ironclads from overseas, and in July and August 1861 the Confederacy started work on construction and converting wooden ships.

On 12 October 1861, the became the first ironclad to enter combat, when she fought Union warships on the Mississippi during the Battle of the Head of Passes. She had been converted from a commercial vessel in New Orleans for river and coastal fighting. In February 1862, the larger joined the Confederate Navy, having been rebuilt at Norfolk. Constructed on the hull of , "Virginia" originally was a conventional warship made of wood, but she was converted into an iron-covered casemate ironclad gunship, when she entered the Confederate navy. By this time, the Union had completed seven ironclad gunboats of the , and was about to complete the , an innovative design proposed by the Swedish inventor John Ericsson. The Union was also building a large armored frigate, the , and the smaller .

The first battle between ironclads happened on 9 March 1862, as the armored "Monitor" was deployed to protect the Union's wooden fleet from the ironclad ram "Virginia" and other Confederate warships. In this engagement, the second day of the Battle of Hampton Roads, the two ironclads repeatedly tried to ram one another while shells bounced off their armor. The battle attracted attention worldwide, making it clear that the wooden warship was now out of date, with the ironclads destroying them easily.

The Civil War saw more ironclads built by both sides, and they played an increasing role in the naval war alongside the unarmored warships, commerce raiders and blockade runners. The Union built a large fleet of fifty monitors modeled on their namesake. The Confederacy built ships designed as smaller versions of "Virginia", many of which saw action, but their attempts to buy ironclads overseas were frustrated as European nations confiscated ships being built for the Confederacy – especially in Russia, the only country to openly support the Union through the war. Only CSS "Stonewall" was completed, and she arrived in American waters just in time for the end of the war.

Through the remainder of the war, ironclads saw action in the Union's attacks on Confederate ports. Seven Union monitors, including , as well as two other ironclads, the ironclad frigate "New Ironsides" and a light-draft , participated in the failed attack on Charleston; one was sunk. Two small ironclads, and participated in the defence of the harbor. For the later attack at Mobile Bay, the Union assembled four monitors as well as 11 wooden ships, facing the , the Confederacy's most powerful ironclad and the gunboats , , .

On the western front, the Union built a formidable force of river ironclads, beginning with several converted riverboats and then contracting engineer James Eads of St. Louis, Missouri to build the City-class ironclads. These excellent ships were built with twin engines and a central paddle wheel, all protected by an armored casement. They had a shallow draft, allowing them to journey up smaller tributaries, and were very well suited for river operations. Eads also produced monitors for use on the rivers, the first two of which differed from the ocean-going monitors in that they contained a paddle wheel (the and ). 

The Union ironclads played an important role in the Mississippi and tributaries by providing tremendous fire upon Confederate forts, installations and vessels with relative impunity to enemy fire. They were not as heavily armored as the ocean-going monitors of the Union, but they were adequate for their intended use. More Western Flotilla Union ironclads were sunk by torpedoes (mines) than by enemy fire, and the most damaging fire for the Union ironclads was from shore installations, not Confederate vessels.

The first fleet battle, and the first ocean battle, involving ironclad warships was the Battle of Lissa in 1866. Waged between the Austrian and Italian navies, the battle pitted combined fleets of wooden frigates and corvettes and ironclad warships on both sides in the largest naval battle between the battles of Navarino and Tsushima.

The Italian fleet consisted of 12 ironclads and a similar number of wooden warships, escorting transports which carried troops intending to land on the Adriatic island of Lissa. Among the Italian ironclads were seven broadside ironclad frigates, four smaller ironclads, and the newly built  – a double-turretted ram. Opposing them, the Austrian navy had seven ironclad frigates.

The Austrians believed their ships to have less effective guns than their enemy, so decided to engage the Italians at close range and ram them. The Austrian fleet formed into an arrowhead formation with the ironclads in the first line, charging at the Italian ironclad squadron. In the melée which followed both sides were frustrated by the lack of damage inflicted by guns, and by the difficulty of ramming—nonetheless, the effective ramming attack being made by the Austrian flagship against the Italian attracted great attention in following years.

The superior Italian fleet lost its two ironclads, and , while the Austrian unarmored screw two-decker remarkably survived close actions with four Italian ironclads. The battle ensured the popularity of the ram as a weapon in European ironclads for many years, and the victory won by Austria established it as the predominant naval power in the Adriatic.

The battles of the American Civil War and at Lissa were very influential on the designs and tactics of the ironclad fleets that followed. In particular, it taught a generation of naval officers the lesson that ramming was the best way to sink enemy ironclads.

The adoption of iron armor meant that the traditional naval armament of dozens of light cannon became useless, since their shot would bounce off an armored hull. To penetrate armor, increasingly heavy guns were mounted on ships; nevertheless, the view that ramming was the only way to sink an ironclad became widespread. The increasing size and weight of guns also meant a movement away from the ships mounting many guns broadside, in the manner of a ship-of-the-line, towards a handful of guns in turrets for all-round fire.

 From the 1860s to the 1880s many naval designers believed that the development of the ironclad meant that the ram was again the most important weapon in naval warfare. With steam power freeing ships from the wind, and armor making them invulnerable to shellfire, the ram seemed to offer the opportunity to strike a decisive blow.

The scant damage inflicted by the guns of "Monitor" and "Virginia" at Battle of Hampton Roads and the spectacular but lucky success of the Austrian flagship SMS "Erzherzog Ferdinand Max" sinking the Italian "Re d'Italia" at Lissa gave strength to the ramming craze. From the early 1870s to early 1880s most British naval officers thought that guns were about to be replaced as the main naval armament by the ram. Those who noted the tiny number of ships that had actually been sunk by ramming struggled to be heard.

The revival of ramming had a significant effect on naval tactics. Since the 17th century the predominant tactic of naval warfare had been the line of battle, where a fleet formed a long line to give it the best fire from its broadside guns. This tactic was totally unsuited to ramming, and the ram threw fleet tactics into disarray. The question of how an ironclad fleet should deploy in battle to make best use of the ram was never tested in battle, and if it had been, combat might have shown that rams could only be used against ships which were already stopped dead in the water.

The ram finally fell out of favour in the 1880s, as the same effect could be achieved with a torpedo, with less vulnerability to quick-firing guns.

The armament of ironclads tended to become concentrated in a small number of powerful guns capable of penetrating the armor of enemy ships at range; calibre and weight of guns increased markedly to achieve greater penetration. Throughout the ironclad era navies also grappled with the complexities of rifled versus smoothbore guns and breech-loading versus muzzle-loading.

Breech-loading guns seemed to offer important advantages. A breech-loader could be reloaded without moving the gun, a lengthy process particularly if the gun then needed to be re-aimed. The "Warrior"s Armstrong guns also had the virtue of being lighter than an equivalent smoothbore and, because of their rifling, more accurate. Nonetheless, the design was rejected because of problems which plagued breech-loaders for decades.

The weakness of the breech-loader was the obvious problem of sealing the breech. All guns are powered by the explosive conversion of a solid propellant into gas. This explosion propels the shot or shell out of the front of the gun, but also imposes great stresses on the gun-barrel. If the breech—which experiences some of the greatest forces in the gun—is not entirely secure, then there is a risk that either gas will discharge through the breech or that the breech will break. This in turn reduces the muzzle velocity of the weapon and can also endanger the gun crew. "Warrior"s Armstrong guns suffered from both problems; the shells were unable to penetrate the 4.5 in (118 mm) armor of "Gloire", while sometimes the screw which closed the breech flew backwards out of the gun on firing. Similar problems were experienced with the breech-loading guns which became standard in the French and German navies.

These problems influenced the British to equip ships with muzzle-loading weapons of increasing power until the 1880s. After a brief introduction of 100-pounder or 9.5-inch (240 mm) smoothbore Somerset Gun, which weighed 6.5 tons (6.6 t), the Admiralty introduced 7-inch (178 mm) rifled guns, weighing 7 tons. These were followed by a series of increasingly mammoth weapons—guns weighing 12, 25, 25, 38 and finally 81 tons, with calibre increasing from 8-inch (203 mm) to 16-inch (406 mm).

The decision to retain muzzle-loaders until the 1880s has been criticised by historians. However, at least until the late 1870s, the British muzzle-loaders had superior performance in terms of both range and rate of fire than the French and Prussian breech-loaders, which suffered from the same problems as had the first Armstrong guns.

From 1875 onwards, the balance between breech- and muzzle-loading changed. Captain de Bange invented a method of reliably sealing a breech, adopted by the French in 1873. Just as compellingly, the growing size of naval guns made muzzle-loading much more complicated. With guns of such size there was no prospect of hauling in the gun for re-loading, or even re-loading by hand, and complicated hydraulic systems were required for re-loading the gun outside the turret without exposing the crew to enemy fire. In 1882, the 81-ton, 16-inch (406 mm) guns of fired only once every 11 minutes while bombarding Alexandria during the Urabi Revolt. The 100-ton, 450 mm (17.72 inch) guns of could each fire a round every 15 minutes.

In the Royal Navy, the switch to breech-loaders was finally made in 1879; as well as the significant advantages in terms of performance, opinion was swayed by an explosion on board caused by a gun being double-loaded, a problem which could only happen with a muzzle-loading gun.

The calibre and weight of guns could only increase so far. The larger the gun, the slower it would be to load, the greater the stresses on the ship's hull, and the less the stability of the ship. The size of the gun peaked in the 1880s, with some of the heaviest calibres of gun ever used at sea. carried two 16.25-inch (413 mm) breech-loading guns, each weighing 110 tons—no British battleship would ever carry guns as large. The Italian 450 mm (17.72 inch) guns would be larger than any gun fitted to a battleship until the 18.1-inch (460 mm) armament of the Japanese of World War II. One consideration which became more acute was that even from the original Armstrong models, following the Crimean War, range and hitting power far exceeded simple accuracy, especially at sea where the slightest roll or pitch of the vessel as 'floating weapons-platform' could negate the advantage of rifling. American ordnance experts accordingly preferred smoothbore monsters whose round shot could at least 'skip' along the surface of the water. Actual effective combat ranges, they had learned during the Civil War, were comparable to those in the Age of Sail—though a vessel could now be smashed to pieces in only a few rounds. Smoke and the general chaos of battle only added to the problem. As a result, many naval engagements in the 'Age of the Ironclad' were still fought at ranges within easy eyesight of their targets, and well below the maximum reach of their ships' guns.

Another method of increasing firepower was to vary the projectile fired or the nature of the propellant. Early ironclads used black powder, which expanded rapidly after combustion; this meant cannons had relatively short barrels, to prevent the barrel itself slowing the shell. The sharpness of the black powder explosion also meant that guns were subjected to extreme stress. One important step was to press the powder into pellets, allowing a slower, more controlled explosion and a longer barrel. A further step forward was the introduction of chemically different brown powder which combusted more slowly again. It also put less stress on the insides of the barrel, allowing guns to last longer and to be manufactured to tighter tolerances.

The development of smokeless powder, based on nitroglycerine or nitrocellulose, by the French inventor Paul Vielle in 1884 was a further step allowing smaller charges of propellant with longer barrels. The guns of the pre-Dreadnought battleships of the 1890s tended to be smaller in calibre compared to the ships of the 1880s, most often 12 in (305 mm), but progressively grew in length of barrel, making use of improved propellants to gain greater muzzle velocity.

The nature of the projectiles also changed during the ironclad period. Initially, the best armor-piercing projectile was a solid cast-iron shot. Later, shot of chilled iron, a harder iron alloy, gave better armor-piercing qualities. Eventually the armor-piercing shell was developed.

The first British, French and Russian ironclads, in a logical development of warship design from the long preceding era of wooden ships of the line, carried their weapons in a single line along their sides and so were called "broadside ironclads". Both and were examples of this type. Because their armor was so heavy, they could only carry a single row of guns along the main deck on each side rather than a row on each deck.

A significant number of broadside ironclads was built in the 1860s, principally in Britain and France, but in smaller numbers by other powers including Italy, Austria, Russia and the United States. The advantages of mounting guns on both broadsides was that the ship could engage more than one adversary at a time, and the rigging did not impede the field of fire.

Broadside armament also had disadvantages, which became more serious as ironclad technology developed. Heavier guns to penetrate ever-thicker armor meant that fewer guns could be carried. Furthermore, the adoption of ramming as an important tactic meant the need for ahead and all-round fire. These problems led to broadside designs being superseded by designs that gave greater all-round fire, which included central-battery, turret, and barbette designs.

There were two main design alternatives to the broadside. In one design, the guns were placed in an armored casemate amidships: this arrangement was called the 'box-battery' or 'centre-battery'. In the other, the guns could be placed on a rotating platform to give them a broad field of fire; when fully armored, this arrangement was called a turret and when partially armored or unarmored, a barbette.

The centre-battery was the simpler and, during the 1860s and 1870s, the more popular method. Concentrating guns amidships meant the ship could be shorter and handier than a broadside type. The first full-scale centre-battery ship was of 1865; the French laid down centre-battery ironclads in 1865 which were not completed until 1870. Centre-battery ships often, but not always, had a recessed freeboard enabling some of their guns to fire directly ahead.

The turret was first used in naval combat on the USS "Monitor" in 1862, with a type of turret designed by the Swedish engineer John Ericsson. A competing turret design was proposed by the British inventor Cowper Coles with a prototype of this installed on HMS "Trusty" in 1861 for testing and evaluation purposes. Ericsson's turret turned on a central spindle, and Coles's turned on a ring of bearings. Turrets offered the maximum arc of fire from the guns, but there were significant problems with their use in the 1860s. The fire arc of a turret would be considerably limited by masts and rigging, so they were unsuited to use on the earlier ocean-going ironclads. The second problem was that turrets were extremely heavy. Ericsson was able to offer the heaviest possible turret (guns and armor protection) by deliberately designing a ship with very low freeboard. The weight thus saved from having a high broadside above the waterline was diverted to actual guns and armor. Low freeboard, however, also meant a smaller hull and therefore a smaller capacity for coal storage—and therefore range of the vessel. In many respects, the turreted, low-freeboard "Monitor" and the broadside sailer HMS "Warrior" represented two opposite extremes in what an 'Ironclad' was all about. The most dramatic attempt to compromise these two extremes, or 'squaring this circle', was designed by Captain Cowper Phipps Coles: HMS "Captain", a dangerously low freeboard turret ship which nevertheless carried a full rig of sail, and which subsequently capsized not long after her launch in 1870. Her half-sister was restricted to firing from her turrets only on the port and starboard beams. The third Royal Navy ship to combine turrets and masts was of 1876, which carried two turrets on either side of the centre-line, allowing both to fire fore, aft and broadside.

A lighter alternative to the turret, particularly popular with the French navy, was the barbette. These were fixed armored towers which held a gun on a turntable. The crew was sheltered from direct fire, but vulnerable to plunging fire, for instance from shore emplacements. The barbette was lighter than the turret, needing less machinery and no roof armor—though nevertheless some barbettes were stripped of their armor plate to reduce the top-weight of their ships. The barbette became widely adopted in the 1880s, and with the addition of an armored 'gun-house', transformed into the turrets of the pre-Dreadnought battleships.

The ironclad age saw the development of explosive torpedoes as naval weapons, which helped complicate the design and tactics of ironclad fleets. The first torpedoes were static mines, used extensively in the American Civil War. That conflict also saw the development of the spar torpedo, an explosive charge pushed against the hull of a warship by a small boat. For the first time, a large warship faced a serious threat from a smaller one—and given the relative inefficiency of shellfire against ironclads, the threat from the spar torpedo was taken seriously. The U.S. Navy converted four of its monitors to become turretless armored spar-torpedo vessels while under construction in 1864–5, but these vessels never saw action. Another proposal, the towed or 'Harvey' torpedo, involved an explosive on a line or outrigger; either to deter a ship from ramming or to make a torpedo attack by a boat less suicidal.

A more practical and influential weapon was the self-propelled or Whitehead torpedo. Invented in 1868 and deployed in the 1870s, the Whitehead torpedo formed part of the armament of ironclads of the 1880s like HMS "Inflexible" and the Italian "Caio Duilio" and . The ironclad's vulnerability to the torpedo was a key part of the critique of armored warships made by the Jeune Ecole school of naval thought; it appeared that any ship armored enough to prevent destruction by gunfire would be slow enough to be easily caught by torpedo. In practice, however, the Jeune Ecole was only briefly influential and the torpedo formed part of the confusing mixture of weapons possessed by ironclads.

The first ironclads were built on wooden or iron hulls, and protected by wrought iron armor backed by thick wooden planking. Ironclads were still being built with wooden hulls into the 1870s.

Using iron construction for warships offered advantages for the engineering of the hull. However, unarmored iron had many military disadvantages, and offered technical problems which kept wooden hulls in use for many years, particularly for long-range cruising warships.

Iron ships had first been proposed for military use in the 1820s. In the 1830s and 1840s, France, Britain and the United States had all experimented with iron-hulled but unarmored gunboats and frigates. However, the iron-hulled frigate was abandoned by the end of the 1840s, because iron hulls were more vulnerable to solid shot; iron was more brittle than wood, and iron frames more likely to fall out of shape than wood.

The unsuitability of unarmored iron for warship hulls meant that iron was only adopted as a building material for battleships when protected by armor. However, iron gave the naval architect many advantages. Iron allowed larger ships and more flexible design, for instance the use of watertight bulkheads on the lower decks. "Warrior", built of iron, was longer and faster than the wooden-hulled "Gloire". Iron could be produced to order and used immediately, in contrast to the need to give wood a long period of seasoning. And, given the large quantities of wood required to build a steam warship and the falling cost of iron, iron hulls were increasingly cost-effective. The main reason for the French use of wooden hulls for the ironclad fleet built in the 1860s was that the French iron industry could not supply enough, and the main reason why Britain built its handful of wooden-hulled ironclads was to make best use of hulls already started and wood already bought.

Wooden hulls continued to be used for long-range and smaller ironclads, because iron nevertheless had a significant disadvantage. Iron hulls suffered quick fouling by marine life, slowing the ships down—manageable for a European battlefleet close to dry docks, but a difficulty for long-range ships. The only solution was to sheath the iron hull first in wood and then in copper, a laborious and expensive process which made wooden construction remain attractive. Iron and wood were to some extent interchangeable: the Japanese and ordered in 1875 were sister-ships, but one was built of iron and the other of composite construction.

After 1872, steel started to be introduced as a material for construction. Compared to iron, steel allows for greater structural strength for a lower weight. The French Navy led the way with the use of steel in its fleet, starting with the , laid down in 1873 and launched in 1876. "Redoutable" nonetheless had wrought iron armor plate, and part of her exterior hull was iron rather than steel.

Even though Britain led the world in steel production, the Royal Navy was slow to adopt steel warships. The Bessemer process for steel manufacture produced too many imperfections for large-scale use on ships. French manufacturers used the Siemens-Martin process to produce adequate steel, but British technology lagged behind. The first all-steel warships built by the Royal Navy were the dispatch vessels "Iris" and "Mercury", laid down in 1875 and 1876.

Iron-built ships used wood as part of their protection scheme. HMS "Warrior" was protected by 4.5 in (114 mm) of wrought iron backed by 15 in (381 mm) of teak, the strongest shipbuilding wood. The wood played two roles, preventing spalling and also preventing the shock of a hit damaging the structure of the ship. Later, wood and iron were combined in 'sandwich' armor, for instance in .

Steel was also an obvious material for armor. It was tested in the 1860s, but the steel of the time was too brittle and disintegrated when struck by shells. Steel became practical to use when a way was found to fuse steel onto wrought iron plates, giving a form of compound armor. This compound armor was used by the British in ships built from the late 1870s, first for turret armor (starting with HMS "Inflexible") and then for all armor (starting with of 1882). The French and German navies adopted the innovation almost immediately, with licenses being given for the use of the 'Wilson System' of producing fused armor.

The first ironclads to have all-steel armor were the Italian and . Though the ships were laid down in 1873 their armor was not purchased from France until 1877. The French navy decided in 1880 to adopt compound armor for its fleet, but found it limited in supply, so from 1884 the French navy was using steel armor. Britain stuck to compound armor until 1889.

The ultimate ironclad armor was case hardened nickel-steel. In 1890, the U.S. Navy tested steel armor hardened by the Harvey process and found it superior to compound armor. For several years 'Harvey steel' was the state of the art, produced in the U.S., France, Germany, Britain, Austria and Italy. In 1894, the German firm Krupp developed gas cementing, which further hardened steel armor. The German , laid down in 1895, was the first ship to benefit from the new 'Krupp armor' and the new armor was quickly adopted; the Royal Navy using it from , laid down in 1896. By 1901 almost all new battleships used Krupp armor, though the U.S. continued to use Harvey armor alongside until the end of the decade.

The equivalent strengths of the different armor plates was as follows: 15 in (381 mm) of wrought iron was equivalent to 12 in (305 mm) of either plain steel or compound iron and steel armor, and to 7.75 in (197 mm) of Harvey armor or 5.75 in (146 mm) of Krupp armor.

Ironclad construction also prefigured the later debate in battleship design between tapering and 'all-or-nothing' armor design. "Warrior" was only semi-armored, and could have been disabled by hits on the bow and stern. As the thickness of armor grew to protect ships from the increasingly heavy guns, the area of the ship which could be fully protected diminished. "Inflexible"s armor protection was largely limited to the central citadel amidships, protecting boilers and engines, turrets and magazines, and little else. An ingenious arrangement of cork-filled compartments and watertight bulkheads was intended to keep her stable and afloat in the event of heavy damage to her un-armored sections.

The first ocean-going ironclads carried masts and sails like their wooden predecessors, and these features were only gradually abandoned. Early steam engines were inefficient; the wooden steam fleet of the Royal Navy could only carry "5 to 9 days coal", and the situation was similar with the early ironclads. "Warrior" also illustrates two design features which aided hybrid propulsion; she had retractable screws to reduce drag while under sail (though in practice the steam engine was run at a low throttle), and a telescopic funnel which could be folded down to the deck level.
Ships designed for coastal warfare, like the floating batteries of the Crimea, or and her sisters, dispensed with masts from the beginning. The British , started in 1869, was the first large, ocean-going ironclad to dispense with masts. Her principal role was for combat in the English Channel and other European waters; while her coal supplies gave her enough range to cross the Atlantic, she would have had little endurance on the other side of the ocean. The "Devastation" and the similar ships commissioned by the British and Russian navies in the 1870s were the exception rather than the rule. Most ironclads of the 1870s retained masts, and only the Italian navy, which during that decade was focused on short-range operations in the Adriatic, built consistently mastless ironclads.

During the 1860s, steam engines improved with the adoption of double-expansion steam engines, which used 30–40% less coal than earlier models. The Royal Navy decided to switch to the double-expansion engine in 1871, and by 1875 they were widespread. However, this development alone was not enough to herald the end of the mast. Whether this was due to a conservative desire to retain sails, or was a rational response to the operational and strategic situation, is a matter of debate. A steam-only fleet would require a network of coaling stations worldwide, which would need to be fortified at great expense to stop them falling into enemy hands. Just as significantly, because of unsolved problems with the technology of the boilers which provided steam for the engines, the performance of double-expansion engines was rarely as good in practice as it was in theory.
During the 1870s the distinction grew between 'first-class ironclads' or 'battleships' on the one hand, and 'cruising ironclads' designed for long-range work on the other. The demands on first-class ironclads for very heavy armor and armament meant increasing displacement, which reduced speed under sail; and the fashion for turrets and barbettes made a sailing rig increasingly inconvenient. , launched in 1876 but not commissioned until 1881, was the last British battleship to carry masts, and these were widely seen as a mistake. The start of the 1880s saw the end of sailing rig on ironclad battleships.

Sails persisted on 'cruising ironclads' for much longer. During the 1860s, the French navy had produced the and es as small, long-range ironclads as overseas cruisers and the British had responded with ships like of 1870. The Russian ship , laid down in 1870 and completed in 1875, was a model of a fast, long-range ironclad which was likely to be able to outrun and outfight ships like "Swiftsure". Even the later , often described as the first British armored cruiser, would have been too slow to outrun "General-Admiral". While "Shannon" was the last British ship with a retractable propellor, later armored cruisers of the 1870s retained sailing rig, sacrificing speed under steam in consequence. It took until 1881 for the Royal Navy to lay down a long-range armored warship capable of catching enemy commerce raiders, , which was completed in 1888. While sailing rigs were obsolescent for all purposes by the end of the 1880s, rigged ships were in service until the early years of the 20th century.

The final evolution of ironclad propulsion was the adoption of the triple-expansion steam engine, a further refinement which was first adopted in , laid down in 1885 and commissioned in 1891. Many ships also used a forced draught to get additional power from their engines, and this system was widely used until the introduction of the steam turbine in the mid-1900s (decade).

While ironclads spread rapidly in navies worldwide, there were few pitched naval battles involving ironclads. Most European nations settled differences on land, and the Royal Navy struggled to maintain a deterrent parity with at least France, while providing suitable protection to Britain's commerce and colonial outposts worldwide. Ironclads remained, for the British Royal Navy, a matter of defending the British Isles first and projecting power abroad second. Those naval engagements of the latter half of the 19th century which involved ironclads normally involved colonial actions or clashes between second-rate naval powers. But these encounters were often enough to convince British policy-makers of the increasing hazards of strictly naval foreign intervention, from Hampton Roads in the American Civil War to the hardening combined defences of naval arsenals such as Kronstadt and Cherbourg.

There were many types of ironclads:

The United Kingdom possessed the largest navy in the world for the whole of the ironclad period. The Royal Navy was the second to adopt ironclad warships, and it applied them worldwide in their whole range of roles. In the age of sail, the British strategy for war depended on the Royal Navy mounting a blockade of the ports of the enemy. Because of the limited endurance of steamships, this was no longer possible, so the British at times considered the risk-laden plan of engaging an enemy fleet in harbor as soon as war broke out. To this end, the Royal Navy developed a series of 'coast-defence battleships', starting with the "Devastation" class. These 'breastwork monitors' were markedly different from the other high-seas ironclads of the period and were an important precursor of the modern battleship. As long-range monitors they could reach Bermuda unescorted, for example. However, they were still armed with only four heavy guns and were as vulnerable to mines and obstructions (and enemy monitors) as the original monitors of the Union Navy proved to be during the Civil War. The British prepared for an overwhelming mortar bombardment of Kronstadt by the close of the Crimean War, but never considered running the smoke-ridden, shallow-water gauntlet straight to St. Petersburg with ironclads. Likewise, monitors proved acutely unable to 'overwhelm' enemy fortifications single-handed during the American conflict, though their low-profile and heavy armor protection made them ideal for running gauntlets. Mines and obstructions, however, negated these advantages—a problem the British Admiralty frequently acknowledged but never countered throughout the period. The British never laid down enough "Devastation"-class 'battleships' to instantly overwhelm Cherbourg, Kronstadt or even New York City with gunfire. Although throughout the 1860s and 1870s the Royal Navy was still in many respects superior to its potential rivals, by the early 1880s widespread concern about the threat from France and Germany culminated in the Naval Defence Act, which promulgated the idea of a 'two-power standard', that Britain should possess as many ships as the next two navies combined. This standard provoked aggressive shipbuilding in the 1880s and 1890s.

British ships did not participate in any major wars in the ironclad period. The Royal Navy's ironclads only saw action as part of colonial battles or one-sided engagements like the bombardment of Alexandria in 1882. Defending British interests against Ahmed 'Urabi's Egyptian revolt, a British fleet opened fire on the fortifications around the port of Alexandria. A mixture of centre-battery and turret ships bombarded Egyptian positions for most of a day, forcing the Egyptians to retreat; return fire from Egyptian guns was heavy at first, but inflicted little damage, killing only five British sailors. Few Egyptian guns were actually dismounted, on the other hand, and the fortifications themselves were typically left intact. Had the Egyptians actually utilised the heavy mortars that were at their disposal, they might have quickly turned the tide, for the attacking British ironclads found it easy (for accuracy's sake) to simply anchor whilst firing—perfect targets for high-angle fire upon their thinly armored topdecks.

The French navy built the first ironclad to try to gain a strategic advantage over the British, but were consistently out-built by the British. Despite taking the lead with a number of innovations like breech-loading weapons and steel construction, the French navy could never match the size of the Royal Navy. In the 1870s, the construction of ironclads ceased for a while in France as the Jeune Ecole school of naval thought took prominence, suggesting that torpedo boats and unarmored cruisers would be the future of warships. Like the British, the French navy saw little action with its ironclads; the French blockade of Germany in the Franco-Prussian War was ineffective, as the war was settled entirely on land.

Russia built a number of ironclads, generally copies of British or French designs. Nonetheless, there were real innovations from Russia; the first true type of ironclad armored cruiser, "General-Admiral" of the 1870s, and a set of remarkably badly designed circular battleships referred to as 'popovkas' (for Admiral Popov, who conceived the design). The Russian Navy pioneered the wide-scale use of torpedo boats during the Russo-Turkish War of 1877–1878, mainly out of necessity because of the superior numbers and quality of ironclads used by the Turkish navy. Russia expanded her navy in the 1880s and 1890s with modern armored cruisers and battleships, but the ships were manned by inexperienced crews and politically appointed leadership, which enhanced their defeat in the Battle of Tsushima on 27 May 1905.
The US Navy ended the Civil War with about fifty monitor-type coastal ironclads; by the 1870s most of these were laid up in reserve, leaving the USA virtually without an ironclad fleet. Another five large monitors were ordered in the 1870s. The limitations of the monitor type effectively prevented the USA from projecting power overseas, and until the 1890s the USA would have come off badly in a conflict with even Spain or the Latin American powers. The 1890s saw the beginning of what became the Great White Fleet, and it was the modern pre-Dreadnoughts and armored cruisers built in the 1890s which defeated the Spanish fleet in the Spanish–American War of 1898. This started a new era of naval warfare.
Ironclads were widely used in South America. Both sides used ironclads in the Chincha Islands War between Spain and the combined forces of Peru and Chile in the early 1860s. The powerful Spanish participated in the Battle of Callao but was unable to inflict significant damage upon the Callao defences. Besides, Peru was able to deploy two locally built ironclads based on American Civil War designs, "Loa" (a wooden ship converted into a casemate ironclad) and (a small monitor armed with a single 68-pdr gun), as well as two British-built ironclads: , a centre-battery ship, and the turret ship . "Numancia" was the first ironclad to circumnavigate the world, arriving in Cádiz on 20 September 1867, and earning the motto: "Enloricata navis que primo terram circuivit" ["First ironclad ship to sail around the world"]). In the War of the Pacific in 1879, both Peru and Chile had ironclad warships, including some of those used a few years previously against Spain. While "Independencia" ran aground early on, the Peruvian ironclad made a great impact against Chilean shipping, delaying Chilean ground invasion by six months. She was eventually caught by two more modern Chilean centre-battery ironclads, and at the Battle of Angamos Point.

Ironclads were also used from the inception of the Imperial Japanese Navy. (Japanese: 甲鉄, literally "Ironclad", later renamed Azuma 東, "East") had a decisive role in the Naval Battle of Hakodate Bay in May 1869, which marked the end of the Boshin War, and the complete establishment of the Meiji Restoration. The IJN continued to develop its strength and commissioned a number of warships from British and European shipyards, first ironclads and later armored cruisers. These ships engaged the Chinese Beiyang fleet which was superior on paper at least at the Battle of the Yalu River. Thanks to superior short-range firepower, the Japanese fleet came off better, sinking or severely damaging eight ships and receiving serious damage to only four. The naval war was concluded the next year at the Battle of Weihaiwei, where the strongest remaining Chinese ships were surrendered to the Japanese.

There is no clearly defined end to the ironclad, besides the transition from wood hulls to all-metal. Ironclads continued to be used in World War I. Towards the end of the 19th century, the descriptions 'battleship' and 'armored cruiser' came to replace the term 'ironclad'.

The proliferation of ironclad battleship designs came to an end in the 1890s as navies reached a consensus on the design of battleships, producing the type known as the pre-Dreadnought. These ships are sometimes covered in treatments of the ironclad warship. The next evolution of battleship design, the dreadnought, is never referred to as an 'ironclad'.

Most of the ironclads of the 1870s and 1880s served into the first decades of the 1900s. For instance, a handful of US navy monitors laid down in the 1870s saw active service in World War I. Pre-Dreadnought battleships and cruisers of the 1890s saw widespread action in World War I and in some cases through to World War II.

H. G. Wells coined the term "The Land Ironclads" in a short story published in 1903, to describe fictional large armored fighting vehicles moving on Pedrail wheels.

A number of ironclads have been preserved or reconstructed as museum ships.





</doc>
<doc id="251815" url="https://en.wikipedia.org/wiki?curid=251815" title="Once More, with Feeling (Buffy the Vampire Slayer)">
Once More, with Feeling (Buffy the Vampire Slayer)

"Once More, with Feeling" is the seventh episode of the sixth season of the supernatural drama television series "Buffy the Vampire Slayer" (1997–2003) and the only one in the series performed as a musical. It was written and directed by the show's creator, Joss Whedon, and originally aired on UPN in the United States on November 6, 2001.

"Once More, with Feeling" explores changes in the relationships of the main characters, using the plot device that a demon—credited as "Sweet" but unnamed in the episode—compels the people of Sunnydale to break into song at random moments to express hidden truths. The title of the episode comes from a line sung by Sweet; once the characters have revealed their truths and face the consequences of hearing each other's secrets, he challenges them to "say you're happy now, once more, with feeling".

All of the regular cast performed their own vocals, although two actors were given minimal singing at their request. "Once More, with Feeling" is the most technically complex episode in the series, as extra voice and dance training for the cast was interspersed with the production of four other "Buffy" episodes. It was Joss Whedon's first attempt at writing music, and different styles—from 1950s sitcom theme music to rock opera—express the characters' secrets in specific ways. The episode was well received critically upon airing, specifically for containing the humor and wit to which fans had become accustomed. The musical format allowed characters to stay true to their natures while they struggled to overcome deceit and miscommunication, fitting with the sixth season's themes of growing up and facing adult responsibilities. It is considered one of the most effective and popular episodes of the series, and—prior to a financial dispute in 2007—was shown in theaters with the audience invited to sing along.

Throughout the series Buffy Summers (Sarah Michelle Gellar), in her role as the Vampire Slayer, is assisted by her close friends, who refer to themselves as the "Scooby Gang". These include Xander Harris (Nicholas Brendon), a young man without particular strengths or talents, but devoted to Buffy and her calling, and Willow Rosenberg (Alyson Hannigan), a young woman who has grown from a shy but gifted student into a strong woman and powerful user of magic. They are mentored by Buffy's "Watcher", Rupert Giles (Anthony Stewart Head), a paternal figure since the first season, when Buffy moved to Sunnydale after her parents' divorce. Xander is engaged to Anya Jenkins (Emma Caulfield), a former vengeance demon who has become human. They have struggled with disclosing their engagement to the rest of the group and individually doubt their impending marriage.

Buffy died at the end of the fifth season ("The Gift"), sacrificing herself in place of her younger sister Dawn (Michelle Trachtenberg) in order to save the world. In the first episode of the sixth season, Willow, believing Buffy to be in Hell, used magic to bring her back from the grave. Buffy was in fact at peace, in what she thinks was heaven, but she has kept this a secret from her friends. Since her resurrection, Buffy has been lost and without inspiration to perform her duties as a Slayer. Willow is romantically involved with Tara Maclay (Amber Benson), a powerful but ethical witch. Tara has previously expressed concern at Willow's use of her emergent magical powers for trivial or personal matters. In the preceding episode ("All the Way"), Willow cast a spell to make Tara forget an argument about her abuse of magic. In the same episode, Dawn, who has been stealing from stores, including Anya's magic shop, lies to Buffy and goes on a clandestine and almost deadly date. Left to take care of Dawn after the death of their mother Joyce Summers (Kristine Sutherland) in the fifth season ("The Body"), Buffy has come to depend more heavily on Giles. Following Dawn's date, Buffy asks Giles to shoulder responsibility for disciplining her, much to his discomfort.

Buffy's former nemesis is Spike (James Marsters), a vampire. In the fourth season The Initiative, a secret military organization whose mission is to evaluate and eliminate demonic beings, rendered Spike harmless by implanting a microchip in his head that causes him intense pain when he attacks humans. However, the chip does not affect him when he harms demons and he now often fights on Buffy's side, after at first fighting just for the pleasure of brawling. His motivations changed when, in the fifth season, Spike realized he had fallen in love with Buffy. She initially rejected him, but just before her death they had begun to form a friendship of sorts. She has been confiding in him; prior to this episode, he is the only one to whom Buffy has revealed that she was in heaven.

Throughout "Buffy the Vampire Slayer", music serves as a narrative tool, integral to character development and action. The mood is set by music, characters discuss it, and writers use it to emphasize differences between generations. In an essay on the use of music in the series, Jacqueline Bach writes that in conjunction with the sixth season themes of growing up, "Once More, with Feeling" gives music a central role instead of keeping it in the background.

When Buffy is on patrol, she laments in song about how uninspired her life has become ("Going Through the Motions"). The next morning at the Magic Box, the gang reveal that they also sang that evening. Led by Giles, the gang theorizes about the cause of the singing; they sense no immediate danger but agreeing that by working together they can overcome anything ("I've Got a Theory/Bunnies/If We're Together"). Buffy learns that the whole town is affected when she looks outside the shop to see a large group (led by series writer and producer David Fury) singing and dancing about how a dry-cleaning service got their stains out ("The Mustard").

Tara and Willow leave to "research" at home, but dally along the way while Tara muses about how much Willow has improved her life ("Under Your Spell"). The next morning, Xander and Anya perform a duet about their secret annoyances with each other and their respective doubts about their impending marriage ("I'll Never Tell"). They realize that the songs are bringing out hidden secrets, and later insist to Giles that something evil is to blame. As they argue, they walk past a woman (series writer and producer Marti Noxon) protesting a parking ticket ("The Parking Ticket"). That evening, Buffy visits Spike, who angrily tells Buffy to leave him alone if she will not love him ("Rest in Peace").

Dawn tells Tara she is glad that Tara and Willow have made up after their argument. Since Tara has no recollection of an argument, she suspects that Willow has used magic to alter her memory. She goes to the Magic Box to consult a book, leaving Dawn alone. Dawn starts to bemoan that no one seems to notice her ("Dawn's Lament"), but is soon seized by minions of Sweet (Hinton Battle), a zoot suit-wearing, tap-dancing, singing demon. They take Dawn to The Bronze, where her attempt to escape transforms into an interpretive dance with the minions ("Dawn's Ballet") before she meets Sweet. He tells Dawn that he has come to Sunnydale in response to her "invocation", and he will take her to his dimension to make her his bride ("What You Feel") when his visit is complete.

At the Magic Box, Giles recognizes that he must stand aside if Buffy is to face her responsibilities in caring for Dawn instead of relying on him ("Standing") and Tara finds a picture of the forget-me-not flower Willow used to cast a spell on her in a book of magic. Giles and Tara separately resolve to leave the people they love, respectively Buffy and Willow — Giles wants to leave Buffy for her own good, while Tara wants to leave Willow because she has become horrified by Willow’s magical manipulation of their relationship ("Under Your Spell / Standing—Reprise"). Captured by Spike outside the store, one of Sweet’s minions conveys a challenge from Sweet for Buffy to rescue Dawn from The Bronze. Giles forbids the gang to assist Buffy, so she goes alone, despite having no will to do so; eventually Giles and the Scoobies change their minds and leave to catch up. Although Spike initially thinks that things would be better for him if Buffy was dead, he also changes his mind and decides to help Buffy; Sweet opines that Buffy is drawn to danger ("Walk Through the Fire").

Meeting Sweet at The Bronze, Buffy offers a deal to Sweet: she will take the place of her sister if she can’t kill him. When asked by Sweet what she thinks about life, Buffy gives her pessimistic take on its meaning ("Something to Sing About"). When the others arrive, she divulges that Willow took her from heaven, and Willow reacts with horror at finding out what she’s done. Upon divulging this truth, Buffy gives up on singing and dances so frenetically that she begins to smoke — on the verge of combusting as Sweet’s other victims have been shown to do — until Spike stops her, telling her that the only way to go forward is to just keep living her life. Xander then reveals that he, not Dawn, called Sweet, hoping he would be shown a happy ending for his marriage plans. Sweet, after releasing Xander from the obligation to be Sweet's “bride”, tells the group how much fun they have been ("What You Feel—Reprise") and disappears. The Scoobies realize that their relationships have been changed irreversibly by the secrets revealed in their songs ("Where Do We Go from Here?"). Spike leaves The Bronze, but Buffy follows him out, and they kiss ("Coda").

Joss Whedon had wanted to make a musical episode since the start of the series. This was heightened during the fifth season when he hosted a Shakespeare reading at his house, to which the cast was invited. They began drinking and singing, demonstrating to Whedon that certain cast members had musical talents. Whedon knew he would have to write an entire score, which would take weeks or months. During the first three seasons of "Buffy", he was unable to take more than two weeks off at a time, and the constraints of writing and directing the show precluded him from putting forth the effort of preparing a musical. Whedon spoke to the show's producer, Gareth Davies, about his idea; they agreed that a musical episode would be written.

Whedon spent six months writing the music for "Once More, with Feeling". When he returned after the end of the fifth season, he presented Davies with a script and CD, complete with notated and orchestrated music, which Davies found "mind-boggling". The actors were initially bewildered; in 2012, James Marsters commented that "it's obvious now that they were good songs but the thing was Joss and his wife Kai, they don't sing very well. And they don't play piano very well. The songs sounded really cheesy and horrible... We were saying, 'Joss, you're ruining our careers.'"

Preparing for the episode was physically difficult for some of the cast members, most of whom had little experience singing and dancing. They spent three months in voice training. Two choreographers worked with Whedon and the cast on dance sequences. Michelle Trachtenberg (Dawn), who is trained in ballet, requested a dance sequence in lieu of a significant singing part, and Alyson Hannigan (Willow), according to Whedon, begged him not to give her many lines. Sarah Michelle Gellar (Buffy) told the BBC that "It took something like 19 hours of singing and 17 hours of dancing in between shooting four other episodes" and she was so anxious about singing that she "hated every moment of it". When Whedon suggested using a voice double for her, however, she said, "I basically started to cry and said, 'You mean someone else is going to do my big emotional turning point for the season?' In the end, it was an incredible experience and I'm glad I did it. And I never want to do it again." Davies was so impressed with Hinton Battle's performance on Broadway in "The Wiz" that he asked Battle to play the demon Sweet. Battle, a three-time Tony-winner, wore prosthetic make-up for the first time to give him a demonic red face. Sweet was portrayed as "slick", smooth and stylish; in contrast, most demons on the series were designed to be crude and ugly. The set for The Bronze was used frequently throughout the series, but stairs were built from the stage to maximize floor space for Battle's dance.

Running eight minutes longer than any in the series, the episode was also the most technical and complex. Whedon, who has stated this is one of his favorite "Buffy" episodes, used a widescreen letterbox format for filming (the only episode in the series to get this treatment), different lighting to bring out the sets more vibrantly, and long takes for shooting—including a complicated shot with a full conversation, a song, and two choreographed dances that took 21 attempts to get right. These were designed to give viewers all the clues they needed to establish all the nuances of the relationships between characters. Davies commented that the intricacies of filming this episode were "infinitely more complicated than a regular "Buffy"" episode, and Whedon stated in the DVD commentary that he was ambitious to prove what television is capable of, saying "it just depends how much you care". UPN, the television network that aired "Buffy"s last two seasons, promoted the episode by displaying Gellar's face on billboards with music notes over her eyes, and held a special premiere event. Network president Dean Valentine remarked he thought it was "one of the best episodes of television I ever saw in my life".

Critics hailed the episode as successful in telling a complex story about all the characters in a unique way, while retaining the series' effective elements of writing and character development. Throughout the show—as in the rest of the series—the characters self-consciously address their own dialogue and actions. Anya describes her own duet "I'll Never Tell" as "a retro pastiche that's never gonna be a breakaway pop hit". With a characteristic dry demeanor, Giles explains that he overheard the information about Sunnydale residents spontaneously combusting as he was eavesdropping upon the police taking "witness arias". In her opening number, "Going Through the Motions", Buffy sings that she feels as though she is playing a part: "nothing here is real, nothing here is right". The song introduces the character's emotional state but also removes the barrier between the actor and the audience, as Gellar the actor portrays Buffy, who feels she is merely playing the part of the Slayer. This hints to the audience that the episode's musical format is strange to the actors and characters. According to "Buffy" essayist Richard Albright, the lack of polish among cast members' singing voices added to the authenticity of their breaking out into song for the first time in the series. Whedon included self-conscious dialogue and references about the characters being in a musical and showed their reluctance toward song and dance, so that the audience would feel more comfortable with the improbability of such a thing happening on the show.

The dynamic nature of the characters was a unique element of writing in the series at the time. Once they were established in the twelve episodes of the first season, characters began to change and relationships were developed in the second. This continued through the series to the point of unpredictability that sometimes became unsettling to fans. "Buffy" essayist Marguerite Krause asserts that the monsters and demons faced by the Scoobies are thin symbolism for the show's true focus: relationships and how to maintain or ruin them. Common among most of these relationships—romantic, platonic, and familial—is, according to Krause, a "failure to communicate, lack of trust, [and the] inability to envision or create a viable future". Miscommunication is worsened or sustained through multiple episodes and seasons, leading to overwhelming misunderstanding and critical turning points for the characters, some of whom do not recover.

"Once More, with Feeling" propelled the story arc for season six by allowing characters to confess previously taboo issues to themselves and each other. Whedon commented that he was "obsessive about progressing a plot in a song, about saying things we haven't said", comparing the musical theater format to the fourth-season episode "Hush", in which characters begin communicating when they stop talking. According to "Buffy" essayist Zoe-Jane Playdon, earlier episodes' "false saccharine behaviour" impedes the characters so crucially that it summons a demon to force them to be honest. The consequences in the episode of concealing truth, spontaneous combustion, is an allusion to "Bleak House" by Charles Dickens—of whom Whedon is a fan—where characters also face immolation for being deceitful. For Buffy, however, truth is slow in coming, as she continues to lie to the Scoobies, claiming to forget what she sang about in the graveyard during "Going Through the Motions". Buffy continues her charade in the chorus number "If We're Together", beginning the song by persuading others to join in one by one, as if each is convinced that she is still invested and in charge, and their strength as a group is infallible. Although she asks in verse "Apocalypse / We've all been there / The same old trips / Why should we care?", all the Scoobies join her, including Giles despite his suspicions that Buffy is no longer interested in her life.

Secrets reveal themselves steadily throughout the episode. Xander fears that his future marriage will turn him into an argumentative drunk like his father. He attempts to avoid his fears through the song "I'll Never Tell", singing "'coz there's nothing to tell", after summoning Sweet to Sunnydale to show him that he and Anya will be happy. Amid the various annoyances Xander and Anya express through this song, some verses are clear-sighted observations of behavior, such as Anya's accusation that Xander—once in love with Buffy—uses Buffy as a mother figure to hide behind. Anya also avoids the truth by burying herself in wedding plans without thinking critically about what being married will entail; instead she considers Xander an accessory to her desired lifestyle. Of all the characters, Anya is the most preoccupied with the style of singing and songs, demanding to know if Spike sang "a breakaway pop hit, or a book number", and asking Dawn if the pterodactyl she facetiously says she gave birth to also broke into song. Anya and Xander's duet is the only song in the episode to address the audience directly. During the long single-shot scene when she and Xander talk over each other insisting to Giles that evil must be at play, Anya refers to the audience, saying "It was like we were being watched ... Like there was a wall missing ... in our apartment ... Like there were only three walls and not a fourth wall." Albright asserts that Anya's constant preoccupation with her and others' performances indicates that she has serious doubts about her future supporting role as Xander's wife.

Giles' truth, according to Whedon, is that he realizes he must not "fight my kid's battles or my kid will never grow up", which he sings in "Standing" while he throws knives at Buffy as part of her training. Whedon remarked that this touch "is the kind of complete turnaround that is a staple of the "Buffy" universe". Tara's heartfelt love song also has an ironic subtext; although she appears to mean that she is fulfilled by her relationship with Willow, the lyrics include multiple allusions to Willow working her manipulative will over Tara, overlaid with Tara's euphoric singing about her pleasure in their union. In "", Lorna Jowett calls the song between Willow and Tara the transformational event in their relationship, from Tara's subservient bearing towards Willow, into a relationship of equals. Two "Buffy" essayists note that Willow and Giles sing together at the start of the episode, but later Tara and Giles share a duet to express the diminished part each plays in their respective relationships.

Although "Once More, with Feeling" allows all the characters to confess truthfully, with the exception of Willow, it does not resolve the behavior that demanded confession in the first place. At the end of the episode, Buffy kisses Spike, initiating a romance that she hides from her friends. Their relationship lasts until the end of the series, marked for a time by Buffy's loathing of him because he has no soul. Her relationship with Spike, however, allows her to feel lust and attraction, which she yearns for after being pulled back from a heavenly dimension. In "The Psychology of Joss Whedon", Mikhail Lubyansky writes that, although Buffy's first step toward re-engaging with her life is telling the Scoobies the truth in the song "Something to Sing About", she does not find meaning again until the end of the season. In his essay "A Kantian Analysis of Moral Judgment in "Buffy the Vampire Slayer"", Scott Stroud explains that Buffy, as the central character throughout the series, is torn between her desires and her duty, in a Kantian illustration of free will vs. predeterminism, symbolized by her responsibility as a Slayer and her adolescent impulses. In earlier seasons, this takes the form of simpler pleasures such as dating and socializing, interspersed with defeating evil forces. It reaches a climax in the ultimate sacrifice when Buffy offers to die to save the world. However, "Once More, with Feeling", according to Stroud, is the turning point at which she begins to face her responsibility to the community, her friends and her family. Not only does she continue her Slaying despite a lack of inspiration, but for the rest of the season she works at a humiliating job to provide for her sister and friends.

"Once More, with Feeling" was Joss Whedon's first attempt at writing music, which he had always wanted to do. He learned how to play guitar to write several songs. Christophe Beck, a regular composer for the series, filled in the overture and coda and composed "Dawn's Ballet". Whedon is a fan of Stephen Sondheim, and used him as the inspiration for much of the music, particularly with the episode's ambiguous ending. Cast member James Marsters (Spike) said, "Some of Joss' music is surprisingly complicated. Maybe it's a Beatles thing. He doesn't know enough to know what he can't do and he's smashing rules."

The episode's musical style varies significantly. Buffy's opening number, "Going Through the Motions", was influenced heavily by the Disney song "Part of Your World" sung by Ariel in "The Little Mermaid". Whedon wanted to use a similar opening in which the heroine explains her yearning. While singing her song, Buffy fights three vampires and a demon who themselves break into a choreographed dance; Whedon wanted this to be fun but not distracting. The song ends with chord influences from Stephen Schwartz's "Pippin" and a visual tribute to Disney: as Buffy stakes a vampire, it turns to dust that swirls around her face.

Whedon chose the most complicated scene, with the most dancers and choreography in the classic style of musical theater, to accompany an 18-second song ("The Mustard") "to get it out of the way" for more personal numbers later in the episode. Stephanie Zacharek of Salon.com considers this "brilliant because it frees even people who hate musicals to settle into the story without getting hung up on the genre's conventions". The musical styles span from a jaunty 1950s sitcom arrangement of the Buffy theme in the opening credits—the only episode in the series to begin without the normal version of the theme song and full cast roll, signifying a genre shift—to Anya's hard-rock version of "Bunnies". Whedon assigned Emma Caulfield the rock-opera format because Caulfield often sang in such a way to him on the set. Spike's "Rest in Peace" is also a rock song, which Whedon wrote after completing the episode's first song, Tara's "Under Your Spell", a contemporary pop song with radio-play potential. Xander and Anya's duet—the most fun to shoot but difficult to write, according to Whedon—is inspired by Fred Astaire-Ginger Rogers comedies as evidenced by the silken pajama costumes and art deco apartment setting. Musically, the song uses influences from Ira Gershwin, a Charleston rhythm, and jazz-like chord slides. Giles' "Standing" is a ballad to Buffy that she does not hear, unlike the songs revealing truths elsewhere in the episode. Whedon shot the scene so that Giles moves in real time while Buffy works out in slow motion, to accentuate Giles' distance from her. Buffy's not hearing his song was intentional; Whedon explained, "You can sing to someone in musicals and they can never know how you feel or how much you love them, even if they're standing right in front of you".

"Under Your Spell" received attention from Buffy studies writers because it presents a frank and unflinching expression of lesbian romance. "Buffy the Vampire Slayer" was the first show in U.S. television history to portray a long-term lesbian relationship among the core cast of characters. Previous televised depictions of lesbian relations were primarily limited to single "coming out" or "lesbian kiss" episodes, showing lesbian-identified characters as affectionate but not erotic. Tara and Willow demonstrate throughout the series, and specifically in "Once More, with Feeling", that they are "intensely sexual", according to "Buffy" essayist Justine Larbalestier. Near the end of Tara's song, she sings, "Lost in ecstasy / Spread beneath my Willow tree / You make me / Com — plete", as Tara levitates off the bed while Willow tacitly performs cunnilingus on her. Lorna Jowett called the song "the most erotic scene" of the series. Whedon admitted on the DVD commentary for the episode that the song is "pornography" and "probably the dirtiest lyric I've ever written, but also very, very beautiful".

"Buffy" essayist Ian Shuttleworth writes that Amber Benson (Tara) has "the sweetest singing voice of all the lead players", referring to "Under Your Spell" as "heavenly and salacious"; author Nikki Stafford concurs, writing that Benson "has the most stunning voice, showing a surprising range". Whedon acknowledged that the "lyrical, heavenly quality" of Benson's voice led him to assign her the episode's love song. Alyson Hannigan (Willow) was unwilling to sing much and her performance is "apprehensive", according to Shuttleworth. He considers this an example of Tara's quieter strength coming out in front of Willow's showy demonstrations of powerful magic. Buffy studies scholar Rhonda Wilcox interprets Willow's diminished role representing the show's silence about Willow's descent into addiction and darkness through the rest of the season. Benson remarked that Tara's story arc is significant within the episode, starting out with ecstasy but soon recognizing the illusory circumstances surrounding her bliss and that "life can't be perfect all the time".

The most complicated song, "Walk Through the Fire", leads all the characters to the climax from different locations for different reasons, reminiscent of the "Tonight Quintet" from "West Side Story". When they all sing the chorus at once to the line "We will walk through the fire / And let it — burn", two fire trucks race behind the Scoobies as they proceed to the Bronze. Whedon called the shot the "single greatest thing we ever did". Each of the singers in this song, which "marries soft rock to the function of a dirge", connects musically to earlier songs while foreshadowing Buffy's next number and the final chorus, providing an ominous anxiety.

Buffy's numbers are the most complex, changing key and tempo when she begins to reveal the secrets she swore she never would. This appears specifically in "Something to Sing About", which starts with uptempo platitudes: "We'll sing a happy song / And you can sing along: / Where there's life, there's hope / Every day's a gift / Wishes can come true / Whistle while you work ..." While singing, she kills Sweet's minions with a pool cue. Whedon attempted to make the song tuneful yet chaotic to express the main point of the episode. It transitions suddenly into her desire to be like normal girls, then changes again, slowing the tempo as she challenges Sweet not to give her a song, but "something to sing about". Musicologist Amy Bauer categorizes the tempo shifts as "rock ballad to punk polka to hymn" that indicates Buffy's turmoil. The key and tempo slow again, as Buffy finally reveals "I live in hell / 'Cause I've been expelled from heaven / I think I was in heaven" with the chord changing from B minor to B diminished, each time she repeats "heaven". When replying to her, Spike has the same shift from minor to diminished each time he repeats the word "living."

The episode nears the end with "Where Do We Go from Here?", as the Scoobies stand dazed and disoriented, facing different directions. As they sing "Understand we'll go hand in hand / But we'll walk alone in fear", they line up, hold hands, then fling each other's hands away in a piece of what Whedon calls "literal choreography". Each of the eight characters in this line wears a color in the visible spectrum, a conscious decision by the costume designer. The couples in the group wear opposite colors (Giles in green and Buffy in red, Anya in blue and Xander in orange, Tara in yellow and Willow in purple), and Rhonda Wilcox interprets the color-coding and choreography to represent the "tension between the individual and the group". The characters as a chorus sing "The curtains close on a kiss, God knows / We can tell the end is near", moments before Buffy runs out to kiss Spike and the show closes with actual curtains. As Spike and Buffy kiss, a swell of music accompanies them, similar to the ending of "Gone with the Wind". Lyrics sung moments before, however, forecast the uncertainty of the relationship between Spike and Buffy, as well as their contrasting reasons for initiating any romance; Spike wants to feel love from Buffy, while she simply wants to feel.

When the episode was originally broadcast in the United States on UPN on November 6, 2001, it received a Nielsen rating of 3.4 and a share of 5. This placed the episode in sixth place in its timeslot, and 88th among broadcast television for the week of November 5–11, 2001. It was the most watched program on UPN that night, and the third most watched program that week, trailing episodes of "" and "WWF SmackDown". This was a decrease from the 3.7 rating received by the previous episode a week prior.

"Once More, with Feeling" received widespread critical acclaim from media and critics when it aired, during overseas syndication, and in reminiscences of the best episodes of "Buffy" after the series ended. Although Salon.com writer Stephanie Zacharek states "(t)he songs were only half-memorable at best, and the singing ability of the show's regular cast ranged only from the fairly good to the not so great", she also asserts that it works "beautifully", paces itself gracefully, and is "clever and affecting". Zacharek's unenthusiastic assessments of the music and cast's singing abilities were not shared by other writers. Debi Enker in Australia's "The Age" writes, "Giles (Anthony Stewart Head) and Tara (Amber Benson) are terrific, Xander (Nicholas Brendon) and Dawn (Michelle Trachtenberg) struggle valiantly, and Willow (Alyson Hannigan) barely sings a note". Tony Johnston in "The Sunday Herald Sun" writes that Gellar "struggles on some of her higher notes, but her dance routines are superb, Michelle Trachtenberg's Dawn reveals sensual dance moves way beyond her tender years, and James Marsters' Spike evokes a sort of Billy Idol yell to disguise his lack of vocal proficiency [...] The rest of the cast mix and match like ready-made Broadway troupers." Johnston counts "I'll Never Tell" as one of the episode's "standout moments". Connie Ogle in "The Miami Herald" calls the songs "better and far more clever than most of the ones you'll hear on Broadway these days".

Writers agree that the episode was risky and could have failed spectacularly. Jonathan Bernstein in the British newspaper "The Observer" writes "What could have been, at best, an eccentric diversion and, at worst, a shuddering embarrassment, succeeded on every level [...] It provided a startling demonstration that creator Joss Whedon has a facility with lyrics and melody equal to the one he's demonstrated for the past six seasons with dialogue, character and plot twists. Rather than adopt the 'Hey, wouldn't it be wacky if we suddenly burst into song?' approach practised by "Ally McBeal", the "Buffy" musical was entirely organic to the series' labyrinthine progression." Johnston in the "Sunday Herald Sun" says, "There is just so much to this marvellously cheeky episode that suggests the show can take any route it pleases and pull it off", while Debi Enker in "The Age" comments, "Whedon demonstrates yet again what "Buffy" aficionados have known and appreciated for years: that his wit, playfulness and readiness to take a risk make his television efforts rise way above the pack." Steve Murray in "The Atlanta Journal-Constitution" characterizes the episode as "scary in a brand-new way", saying "Once More, with Feeling" is "as impressive as Whedon's milestone episodes 'Hush' and 'The Body; the episode is "often hilarious", according to Murray, and acts as "(b)oth spoof and homage, [parodying] the hokiness of musicals while also capturing the guilty pleasure and surges of feeling the genre inspires".

Writing in the "Toronto Star", Vinay Menon calls "Once More, with Feeling" "dazzling" and writes of "Joss Whedon's inimitable genius"; he goes on to say "(f)or a show that already violates conventions and morphs between genres, its allegorical narrative zigging and zagging seamlessly across chatty comedy, drama and over-the-top horror, 'Once More, with Feeling' is a towering achievement [...] The show may be anchored by existential weightiness, it may be painted with broad, supernatural brushstrokes, but in the end, this coming-of-age story, filled with angst and alienation, is more real than any other so-called teen drama [...] So let's add another line of gushing praise: 'Once More, with Feeling' is rhapsodic, original, deeply affecting, and ultimately, transcendental. Quite simply, television at its best."

The episode was nominated for an Emmy Award for Outstanding Musical Direction, but the National Academy of Television Arts and Sciences (NATAS) neglected to include the title on the ballots for Emmy nominations in 2002. NATAS attempted to remedy this by mailing a postcard informing its voters that it should be included, but the episode did not win. NATAS' oversight, according to the "Washington Post", was "another example of the lack of industry respect afforded one of television's most consistently clever shows". Ogle in "The Miami Herald" vigorously protests this omission, writing, "[T]he most astonishing, entertaining hour (hour plus, actually) of TV in the past year slips by virtually unnoticed. Nothing here is real; nothing here is right. "Buffy the Vampire Slayer"'s musical episode, 'Once More, with Feeling', registers a paltry outstanding music direction nomination. Nice for the musical directors. A stake through the aspirations of writer/director Joss Whedon, the beating creative heart of "Buffy", the only TV writer brave and clever enough to use horror as one great big wonderful metaphor for growing up [...] 'Once More, with Feeling' is TV of a different sort, something that comes along once in a lifetime and should not be buried but celebrated and rewarded." The episode was also nominated for a Best Dramatic Presentation Hugo Award and a Best Script Nebula Award, both given for excellence in science fiction and fantasy writing. In 2009 "TV Guide" ranked the episode #14 on its list of "TV's Top 100 Episodes of All Time". For its 65th anniversary, "TV Guide" picked it as the fifth best episode of the 21st century.

An album including all 14 songs in the episode, with Christophe Beck's scores for three other "Buffy" episodes, was released by Rounder Records in September 2002 as season seven premiered. John Virant, president and chief executive of Rounder Records, told the "Los Angeles Times", "I remember watching the episode when it aired last October, and after it was over, I said to my wife, 'That's the best hour of TV I've ever seen. Someone should put that [soundtrack] out.' I inquired at Fox, just following up, and they said, 'Well, we tried, it didn't happen. If you want to take a run at it, feel free. AllMusic gives the album five out of five stars, stating that the music is "every bit as fun as the episode itself", praising the voices of Benson, Marsters and Head. Reviewer Melinda Hill states it is "a must-have for "Buffy" fans, but it wouldn't be out of place in anyone's collection".

In addition to featuring on the sixth season box set, "Once More, with Feeling" was individually released on DVD in Region 2 format on April 14, 2003, the only episode to be individually released. In Region 1, the episode was released on the sixth season box set on May 25, 2004, over a year later than the Region 2 release.

Since the musical episode of "Buffy" aired, several other series have worked musical format into episodes, including "Scrubs", ("My Musical") in 2007, an episode of "Grey's Anatomy" entitled "Song Beneath the Song" in 2011 and "", ("Mayhem of the Music Meister!") in 2009. The musical television episode was declared a genre, a gimmick, according to Mary Williams at Salon.com, for series that had run out of interesting story lines and characters. Both Williams and Margaret Lyons at "New York" magazine, however, declared "Once More, with Feeling" the "gold standard" for musical episodes. Despite this, Joss Whedon recognized the influence "Once More, with Feeling" has had on other shows, but denied that it was primarily responsible for the rise in musical television episodes or series such as "Glee", citing the popularity of "High School Musical" instead.

"Buffy the Vampire Slayer" developed an enthusiastic fan following while it aired. Following its series finale, fans continued their appreciation in theater showings of "Once More, with Feeling" where attendees are encouraged to dress like the show's characters, sing along to the musical numbers, and otherwise interact in the style of "The Rocky Horror Picture Show". Clinton McClung, a New York-based film programmer, got the idea for a sing-along from audience-participation showings of "The Sound of Music" in 2003. The next year, he began putting on sing-alongs to "Once More, with Feeling" in Boston's Coolidge Corner Theater, which became so popular that it went on the road. Audience members received props to use during key scenes, as well as directions (for example, to yell "Shut up, Dawn!" at Buffy's younger sister), and a live cast performed the episode alongside the screen.

"Buffy" sing-alongs received growing media attention as they spread. At the 2007 Los Angeles Film Festival, a special screening and sing-along was held that featured both Marti Noxon and Joss Whedon giving brief speeches to the audience. In October 2007, after a dispute with the Screen Actors Guild over unpaid residuals, 20th Century Fox pulled the licensing for public screenings of "Once More, with Feeling", effectively ending official "Buffy" sing-alongs. Whedon called the cancellation "hugely depressing" and attempted to influence the studio to allow future showings.




</doc>
<doc id="251885" url="https://en.wikipedia.org/wiki?curid=251885" title="Northern gannet">
Northern gannet

The northern gannet ("Morus bassanus") is a seabird, the largest species of the gannet family, Sulidae. It is native to the coasts of the Atlantic Ocean, breeding in Western Europe and North America. The sexes are similar in appearance. The adult northern gannet has a mainly white streamlined body with a long neck, long and slender wings. It is long with a wingspan. The head and nape have a buff tinge that is more prominent in breeding season, and the wings are edged with dark brown-black feathers. The long pointed bill is blue-grey, contrasting with black bare skin around the mouth and eyes. Juveniles are mostly grey-brown, becoming increasingly white in the five years it takes them to reach maturity.

Nesting takes place in colonies on both sides of the north Atlantic, the largest of which are at Bass Rock (75,000 pairs as of 2014), St Kilda (60,000 pairs as of 2013) and Ailsa Craig (33,000 pairs as of 2014) in Scotland, Grassholm in Wales, and Bonaventure Island (60,000 pairs in 2009) off the coast of Quebec. Its breeding range has extended northward and eastward, colonies being established on Russia's Kola Peninsula in 1995 and Bear Island, southernmost island of Svalbard, in 2011. Colonies are mostly located on offshore islands with cliffs, from which the birds can more easily launch into the air. The northern gannet undertakes seasonal migrations and hunts for the fish that form the bulk of its diet by high-speed dives into the sea.

The gannet was previously hunted for food in parts of its range, and the traditional practice still continues in the Outer Hebrides of Scotland and the Faroe Islands. It faces few natural or man-made threats, and since its population is growing it is considered to be a least-concern species by the International Union for Conservation of Nature (IUCN). As a conspicuous and common bird, it has been mentioned in several ancient myths and legends.

The Swiss naturalist Conrad Gessner named the northern gannet as "Anser bassanus" or "scoticus" in the 16th century, noting that the Scots called it "solendguse". The former name was also used by the English naturalist Francis Willughby in the 17th century; the species was known to him from a colony in the Firth of Forth and a stray bird that was found near Coleshill, Warwickshire. It was one of the many species originally described by the Swedish zoologist Carl Linnaeus in the landmark 1758 10th edition of his "Systema Naturae", where it was given the binomial name "Pelecanus bassanus". The French biologist Brisson placed it in the genus "Sula" in 1760, and his compatriot Louis Vieillot moved the species to his new genus "Morus" in 1816. "Morus" is derived from Ancient Greek "moros", meaning "foolish", and refers to the lack of fear shown by breeding gannets and boobies, which enables them to be easily killed. The specific name "bassanus" is from the Bass Rock in the Firth of Forth. The ornithologist Bryan Nelson in 1978 supported the species' inclusion in "Sula" as he felt the differences in anatomy, behaviour, ecology and morphology between gannets and boobies were not sufficient to warrant separate genera.

Charles Lucian Bonaparte described the American populations as "Sula americana" in 1838, though the basis for distinguishing them from the European species was unclear and the name is now considered to be a synonym.

"Northern gannet" has been designated as the official common name for the species by the International Ornithologists' Union (IOC). It is also known as the North Atlantic gannet. "Gannet" is derived from Old English "ganot", meaning "strong or masculine", which is ultimately from the same Old Germanic root as "gander". "Soland goose" and similar old names for the northern gannet such as "solan" or "solan goose" derive from a hypothetical Scottish Gaelic "sulan", itself borrowed from the Old Norse "sula". The literal meaning is "cleft stick", referring to the appearance of the conspicuous crossed black wing tips on a perched northern gannet. Old regional names such as Norfolk's "herring gant" or Yorkshire's "mackerel gant" refer to typical fish prey. Lincolnshire's "gaunt", although derived from the same Germanic root, usually applies to the great crested grebe, but the English writer Richard Hakluyt used the term in 1600 to refer to the gannet, "a great White foule". Young birds have been called "spotted booby" or "parliament goose", the former term referring to their plumage. The feeding habits of the gannet have led to its name being used as slang for a gluttonous person, a usage first recorded in 1929.

The Sulidae, the gannets and boobies, appeared about 30 million years ago. Early Sulidae fossils resembled the boobies, although they were more aquatic, the gannets splitting off later, about 16 million years ago. The gannets evolved in the northern hemisphere, later colonising the southern oceans. The most ancient extant species may be the Abbott's booby, possibly the sole survivor of an otherwise extinct separate lineage. A 2011 genetic study of nuclear and mitochondrial DNA suggests that the ancestor of the gannets arose around 2.5 million years ago before splitting into northern and southern lineages. The latter then split into the Cape and Australasian gannets around 0.5 million years ago. The three gannets are generally considered to be separate species forming a superspecies, though they have also formerly been classified as subspecies of "Sula bassanus".

An adult northern gannet is long, weighs , and has a wingspan, making it the largest gannet and the largest seabird native to the western Palearctic. The two sexes are generally of a similar size and appearance. The plumage is white with dark brown to black wing tips; the primary flight feathers, primary coverts and alulae are dark. The head and neck are tinged buff-yellow, becoming much more prominent in the breeding season. Males are more deeply coloured than females. The eyes have a light blue to light grey iris surrounded by a thin black ring of bare skin. The beak is long, strong and conical with a slight downcurve at the end and a sharp cutting edge. In adults, the beak is blue-grey with dark grey or black edges. There is a black groove running the length of the mandible that merges into the skin around the eyes. A black band of bare skin also separates the pale feathers of the forehead and throat from the bill, which gives the gannet its distinctive face markings. The four-toed feet are joined by a membrane that can vary in colour from dark grey to dark brown. There are coloured lines running along the toes that continue along up the legs. These are typically greenish-yellow in males and bluish in females and probably have a role in mating.

Fledglings are dark grey to slate-grey with upperparts and wings finely speckled with white. There is a prominent V-shaped white area under the rump. The wing tips and tail are dark brown-black, partly tipped with white. The bill and iris are dark brown. They can weigh more than by the time they leave the nest at about 10 weeks of age. In the second year the bird's appearance changes depending on the different phases of moulting: they can have adult plumage at the front and continue to be brown at the rear. Gannets gradually acquire more white in subsequent seasons until they reach maturity after five years.

Northern gannets are slightly larger and thicker-billed than Cape or Australian gannets. The northern gannet has more white in the wings and an all-white tail, the other species having black tips to their tail feathers. Individuals on the west coast of Africa could be confused with vagrant masked boobies, though the latter is smaller overall, lacks the buff tinge to the head, and has a black tail. From a distance, or in poor visibility, albatrosses can be confused with northern gannets, particularly those with immature plumage that have more black on the wings.

Northern gannets have streamlined bodies adapted for plunge-diving at high speed, including powerful neck muscles, and a spongy bone plate at the base of the bill. The nostrils are inside the bill and can be closed to prevent water entry; the eyes are protected by strong nictitating membranes. There are subcutaneous air sacs in the lower body and along the sides. Other air sacs are located between the sternum and the pectoral muscles and between the ribs and the intercostal muscles. These sacs are connected to the lungs and are filled with air when the bird breathes in. The air can be returned to the lungs by muscle contractions.

The feathers are waterproof, which allows the birds to spend long periods in water. A water-impermeable secretion produced by a sebaceous gland covers the feathers and the birds spread it across their body using their beak or head. Individuals have a subcutaneous fat layer, dense down feathers and tightly overlapping feathers that help them withstand low temperatures. A reduced blood flow in the webbing on their feet outside of the breeding season also helps to maintain body temperature when the birds swim.

The northern gannet is a loud and vocal bird, particularly in the colony. Its typical call is a harsh "arrah-arrah" or "urrah-urrah", which is emitted upon arriving or when challenging other gannets at the colony. The call is shortened to a "rah" "rah" when fishing or collecting nesting material, and lengthened to a "ooo-ah" when taking off. The calls of the sexes are similar. According to Nelson northern gannets can recognize the call of their breeding partner, their chicks and birds in neighbouring nests. Individuals from outside this sphere are treated with more aggression.

The northern gannet's breeding range is on both sides of the North Atlantic on coasts influenced by the Gulf Stream, There are colonies in the Gulf of Saint Lawrence and on the islands off the east coast of Canada. They normally nest in large colonies, on cliffs overlooking the ocean or on small rocky islands. The water needs to be cool enough for Atlantic mackerel and herring, which are the main food source for the northern gannet. These areas also overlie the continental shelf. Northern gannet colonies can be found in the far north in regions that are very cold and stormy, and Nelson has suggested that they can survive in these regions for several reasons, including the combination of body weight and a powerful beak that allows them to capture strong muscular fish, and the ability to dive to great depths and capture prey far from the cliffs. Their fat reserves act as weight when diving and as reserves during extended periods without food.

The northern limit of their breeding area depends on the presence of waters that are free of sea ice during the breeding season. Therefore, while Greenland and Svalbard offer suitable breeding sites, the Arctic regions have summers that are too short to allow the northern gannets to lay their eggs and raise a brood, which requires between 26 and 30 weeks. The southern limit of their distribution mainly depends on the presence of sufficient prey. There is fossil evidence of northern gannets breeding on Crete in the Pleistocene.

Some northern gannet breeding colonies have been recorded as being located in the same place for hundreds of years. The cliffs containing the colonies appear white when seen from a distance, due to the number of nesting birds present on them. There is a written record of a colony on the island of Lundy from 1274. There were only 70 nests by 1871, and the colony finally disappeared by 1909 at the latest. More than two-thirds of the world population breeds around the coasts of the British Isles. Colonies include:

After the breeding season, adult northern gannets disperse over a wide area although they travel no more than from the breeding colony. It is not known if all birds from one colony migrate to the same over-wintering area. Many adults migrate to the west of the Mediterranean, passing over the Strait of Gibraltar and flying over land as little as possible. Other birds follow Africa's Atlantic coastline to arrive in the Gulf of Guinea. Immature northern gannets from colonies in Canada fly to the Gulf of Mexico, much further south than the adults.
The immature gannets migrate southwards for great distances and have been recorded as far south as Ecuador. In their second year some birds return to the colony they were born in, where they arrive later than the mature birds. They then migrate south again at the end of the breeding season, but travel shorter distances in this second migration. Gannets from Alderney have been tracked since 2015 to gain better knowledge of their movements. One individual was found to have travelled from its colony in Alderney to Scandinavian waters, a round trip of around 2,700 km (1,680 mi).

The species has been recorded as a vagrant in many central and eastern European countries as far south and west as the Black Sea, and also in Bermuda, Cuba, Cyprus, Egypt, Kazakhstan, Jan Mayen and Syria. In February 2016, one was recorded from Ceará in northeastern Brazil—the first sighting in the Southern Hemisphere.

The wings of the northern gannet are long and narrow and are positioned towards the front of the body, allowing efficient use of air currents when flying. Even in calm weather they can attain velocities of between although their flying muscles are relatively small: in other birds flying muscles make up around 20% of total weight, while in northern gannets the flying muscles are less than 13%. Despite their speed, they cannot manoeuvre in flight as well as other seabirds. Northern gannets need to warm up before flying. They also walk with difficulty and this means that they have problems getting airborne from a flat area. They take off from water by facing into the wind and strongly beating their wings. In light winds and high waves they are sometimes unable to take off and they can become beached.

Gannets alight on land using angled wings, fanned tail and raised feet to control their speed, not always successfully, since damaged or broken wings were recorded as a frequent cause of death in adults at one colony.

Northern gannets forage for food during the day, generally by diving at high speed into the sea. They search for food both near to their nesting sites but also further out to sea. Birds that are feeding young have been recorded searching for food up to from their nest. It has been found that 2% of birds nesting in the colony on Bass Rock search for fish at Dogger Bank, between away. It is likely that they fly further than this while foraging, possibly up to double the distance; normally they fly less than . Some studies have found that the duration and direction of flights made while foraging for food are similar for both sexes, although there are significant differences in the search behaviour of males and females. Female northern gannets are not only more selective than males in choosing a search area: they also make longer and deeper dives and spend more time floating on the surface than males. 

Gannets will follow fishing boats or cetaceans to find discarded or injured fish.
They forage from heights of up to with no clear preference, and typically dive from between . They dive with their bodies straight and rigid, wings tucked close to the body but angled back, extending beyond the tail, before piercing the water like an arrow. They control the direction of the dive using their wings and tail, and fold their wings against the body just before impact. Birds can hit the water at speeds of up to . This allows them to penetrate up to below the surface, and they will swim down to an average , sometimes deeper than . The bird’s subcutaneous air sacs may have a role in controlling their buoyancy.

Gannets usually push their prey deeper into the water and capture it as they return to the surface. When a dive is successful, they swallow the fish underwater before surfacing, and never fly with the fish in their bill. Larger fish are swallowed headfirst, smaller fish are swallowed sideways or tail-first. The fish is stored in a branched bag in the throat and does not cause drag when in flight.
Their white colour helps other gannets to identify one of their kind and they can deduce the presence of a shoal of fish by this diving behaviour; this in turn facilitates group foraging, which makes capturing their prey easier. The colour also makes the gannet less visible to the fish underneath. Northern gannets also forage for fish while swimming with their head under water.

They eat mainly fish in length that shoal near the surface. Virtually any small fish (roughly 80–90% of their diet) or other small pelagic species (largely squid) will be taken opportunistically. Sardines, anchovies, haddock, smelt, Atlantic cod and other shoal-forming species are eaten.

The oldest birds are the first to return to the northern gannet's breeding colonies. Birds not of breeding age arrive a few weeks later. In general, birds first return to a colony (not uncommonly the one in which they were hatched) when they are two or three years old. Once an individual has successfully bred in a colony it will not normally change to another. Nesting starts in March or April.

Immature birds stay on the edges of the colony. They may even make a nest but they do not breed until they are four or five years old. Some birds of this age occupy empty nests that they will aggressively defend if they have sat on them for two or three days. If an apparently empty nest has an owner, the immature bird will leave without a struggle when the owner arrives to take possession.

The preferred nesting sites are on coastal hillsides or cliffs. If these are not available northern gannets will nest in groups on islands or flat surfaces. As they find it more difficult to take off from such locations they will often cross the area occupied by an adjacent nest causing an aggressive reaction from the sitting pair; this means that the stress levels are higher in this type of colony than in those on steeper surfaces. Notwithstanding this, nests are always built close together and otherwise ideal nesting sites will not be used if they are some distance from a colony. On average there are 2.3 nests per square metre (1.9 per square yard). Both sexes fiercely defend the area around their nest. Where space allows, the distance between nests is double the reach of an individual.

Nests are made from seaweed, plants, earth and debris from the sea. The males usually collect the materials. Nests are compact cups typically in height. The area which a nest occupies grows throughout the breeding season as the breeding pairs throw their excrement outside the nest. Over years, nests can reach 2 m (7 ft) in height.

Northern gannets lay one egg that on average weighs , which is light for such a large seabird. The egg is around long by wide and the shell is pale blue and translucent initially before fading to a chalky white surface that is easily stained. Where two eggs are found in a nest this is the result of two females laying an egg in the same nest or one egg being stolen from another nest. Northern gannets will lay a replacement egg if the first is lost. Incubation takes 42 to 46 days, during which time the egg is surrounded by the brooding bird's warm, webbed feet. Just before hatching begins, the brooding bird releases the egg from its feet to prevent the egg from breaking under the adult's weight as the chick breaks it open. This is a frequent cause of death for chicks of birds that are breeding for the first time. The process of breaking the eggshell can take up to 36 hours. The webbed feet are also used to cover the chicks, which are only rarely left alone by their parents. Chicks that are left unattended are often attacked and killed by other northern gannets.

Newly hatched chicks are featherless and are dark blue or black in colour. In the second week of life they are covered in white down, replaced over the next five weeks by dark brown feathers flecked with white. Young chicks are fed regurgitated semi-digested fish by their parents, who open their mouths wide for their young to fetch the food from the back of their throats. Older chicks receive whole fish. Unlike the chicks of other species, northern gannet chicks do not move about the nest or flap their wings to ask for food: this reduces the likelihood that they will fall from the nest.

The adults feed their offspring for around 13 weeks, right up until the time they leave. The young birds fledge between 84 and 97 days old, departing by launching themselves off a cliff and flying—a procedure for which it is impossible to practice beforehand. If they leave the nest in bad weather they can be mortally wounded as they can be blown against the rocks. The young birds are attacked by adults if unattended. Once they leave the nest they stay at sea learning to fish and fly, their flight skills being too poor for them to return to the breeding ledges.

Northern gannets have only one brood a year. The survival rate for young birds for their first four years is 30% and the annual survival rate for adults is 91.9%. The typical lifespan after becoming adult is 17 years, and the maximum known age is 37 years 4 months 16 days. Gannet pairs are monogamous and may remain together over several seasons, if not for all of their lives. The pairs separate when their chicks leave the nest but they bond again the following year. Should one of the pair die, the other bird will find another mate.

Northern gannets exhibit many types of aggressive behaviour while they are nesting. Confrontations normally only take place between birds of the same sex. Females will lower their heads before an aggressive male that is defending its nest: this will expose the back of the female’s neck and the male will take it in its beak and expel the female from the nest. A female will not react if a male approaches a nest but it will react fiercely if another female approaches. The fights between males occupying nests for the first time are particularly intense. Such fights can last for up to two hours and lead to serious injuries. Birds lunge at each other and lock bills, wrestling for extended periods while neighbours peck at them. The fights are preceded by threatening gestures, which are also seen outside the breeding season. Males demonstrate ownership of a nest by gesturing towards their neighbours in a "bowing display"; their heads and beaks point down, and their wings are held up and away from the body, yet folded backwards. The male moves his head from side to side before bowing forwards.

Males try to attract an available female after establishing a territory. The females will fly over the colony several times before landing. Their posture, with the neck stretched out, tells the male that they are available for courtship. The male will then shake their heads in a similar way to when they are guarding their nest, but with their wings closed. Mated pairs engage in a "fencing display" when the male arrives back at the next. The two birds stand breast to breast with wings spread and bills extended vertically. They fence and scissor with their bills rapidly, calling loudly at the same time. Fencing is interspersed with bill bowing.

The northern gannet is not heavily predated. The only known habitual natural predators of adults are bald eagles and white-tailed eagles. Predators of eggs and nestlings include the great black-backed gull and American herring gull, common ravens, ermine, and red fox. Attacks at sea are insignificant though large sharks and seals may rarely snatch a gannet out at sea.

Kleptoparasitism by skuas, particularly the great skua, occurs at breeding sites. The skua chases its victim until it disgorges its stomach contents, providing a meal for the attacker. Skuas may catch the tip of the gannet's wing, causing it to fall into the sea, or seize the tail to tip its victim into the water. The gannet is only released when it has regurgitated its catch.

External parasites include feather lice, although there are relatively few species and none are found on the head. As with grebes and divers it may be that the short head feathers provide insufficient cover for the parasite. In one species, "Michaelichus bassani", immature lice are found in the membranes lining the subcutaneous air-cells. "Ixodes" mites include the widespread "I. uriae".

The spiny-headed worm "Corynosoma tunitae" appears to occur only in gannets and closely related seabird families such as the cormorants. The tapeworm "Tetrabothrius bassani" adsorbs toxic heavy metals at a higher concentration than the gannet's own tissues, with an average 12 times as much cadmium as the gannet's pectoral muscles and 7–10 times the lead level of the bird's kidney and liver. Since levels of these toxic metals are detectable in the parasite earlier than in the host, the tapeworm might be used as an early indicator of marine pollution.

A 2004 survey counted 45 gannet breeding colonies and some 361,000 nests. The population is apparently growing between 3% and 5% a year, although this growth is concentrated in just a few colonies. Although northern gannet populations are now stable, their numbers were once greatly reduced due to loss of habitat, removal of eggs and killing of adults for their meat and feathers. In 1939, there were 22 colonies and some 83,000 nests, which means that the populations have increased fourfold since that time.

In 1992, the International Union for the Conservation of Nature (IUCN) estimated the bird’s population to be some 526,000. After taking into account an estimate produced for BirdLife International in 2004 of the European population, the IUCN revised its global population to between 950,000 and 1,200,000 individuals.

The IUCN lists northern gannets as a species of least concern, as they are widely distributed and as there is a large population that appears to be growing, due to high breeding success with 75% of eggs producing fledged young.

 In Homer's "Odyssey", the sea goddess Leucothea ( "white goddess"), appears "in the likeness of a Gannet" and tells the shipwrecked Odysseus to discard his cloak and raft, instead offering him her veil to wind round himself which will save his life and enable him to reach land.

Another early reference to the gannet is in the seventh-century Old English epic poem "The Seafarer".

There I heard naught but seething sea,
Ice-cold wave, awhile a song of swan
Then came to charm me gannets' pother
And whimbrels trills for laughter of men,
Kittiwake singing instead of mead.
An old myth from Mykines in the Faroe Islands tells of the giant Tórur seeking mercy following defeat at the hands of Óli, the islanders' head man and magician. In return, he gave them whales, driftwood logs and a bird unique to the archipelago, on condition that the inhabitants did not laugh at his gifts. Over time, the islanders forgot their promise, and lost the whales and logs, but fearful of losing a valuable food source, they never mocked the gannets that Tórur had given them.
Gannets have long been eaten for food. Birds, mainly the young, were taken from Bass Rock for at least 350 years until 1885, when the annual cull of about 1,500 individuals finally ceased, and Shetland gannets were sold as "Highland goose" in London restaurants during World War II. Views of the palatability of this bird are mixed, but as well as being a food for the poor it also regularly featured in Scottish royal banquets. In Scotland gannets were traditionally salted to preserve them until they got to market, this technique being replaced by partially cooking or smoking in the era of modern transport. They are normally served roasted, although sometimes raw when pickled or dried.

The best-known site was the remote island of St Kilda, where adults and eggs were taken in the spring. The fat chicks, known locally as "gugas", were harvested from the precipitous cliffs in August, just before they could fly, and thrown to waiting boats far below. Much of the meat was salted in barrels for storage, but the rest of the bird was also used. Islanders paid their rent in feathers for stuffing pillows and furniture, the gannet stomachs were used to hold oil derived from the carcasses, and the breastbones served as lamp wicks.

Hunting on St Kilda ceased in 1910, but the gannetry on Sula Sgeir is still exploited under a licence that permits 2,200 chicks to be taken each year. During the hunt, ten men live on the island, and the cleaned birds are singed on a fire fuelled by their own oil-rich offal. The filleted birds are then taken to Stornoway, where each hunter receives 200 skins to give away or sell. The continuing existence of the practice of hunting and eating gannets attracts criticism in some quarters. The island's name "Sula Sgeir" itself derives from "sula", meaning "gannet", and the Old Norse "skerr", a skerry. Other sites that continued hunting into the twentieth century were Eldey in Iceland, where the activity ceased in 1939, and Mykines, where small-scale culling still persists. About 500 young are culled for consumption each year in Mykines, using techniques similar to those of the Sula Sgeir hunts.

Although the Bass Rock population fell to fewer than 4,000 pairs in the early nineteenth century, the population soon recovered once hunting ceased, and St Kilda was harvested sustainably for hundreds of years. Elsewhere, the recovery was less complete. The Bird Rocks colony in the Gulf of St Lawrence may once have held 250,000 birds, but unchecked hunting, including for fish bait, meant that the population was only 1,000 birds by 1932, despite government protection since 1904.




</doc>
<doc id="252163" url="https://en.wikipedia.org/wiki?curid=252163" title="Operation Epsom">
Operation Epsom

Operation Epsom, also known as the First Battle of the Odon, was a British Second World War offensive that took place between 26 and 30 June 1944, during the Battle of Normandy. The offensive was intended to outflank and seize the German-occupied city of Caen, an important Allied objective, in the early stages of Operation Overlord, the Allied invasion of north-west Europe.

Preceded by Operation Martlet to secure the right flank of the advance, Operation Epsom began early on 26 June, with units of the 15th (Scottish) Infantry Division advancing behind a rolling artillery barrage. Air cover was sporadic for much of the operation, because poor weather in England forced the last-minute cancellation of bomber support. Accompanied by the tanks of the 31st Tank Brigade, the 15th (Scottish) Division made steady progress and by the end of the first day had overrun much of the German outpost line, although some difficulties remained in securing the flanks. In mutually costly fighting over the following two days, a foothold was secured across the River Odon and efforts were made to expand this, by capturing strategic points around the salient and moving up the 43rd (Wessex) Infantry Division. In response to powerful German counter-attacks, by 30 June some of the British forces across the river were withdrawn, bringing the operation to a close. 

Many casualties were suffered by both sides but unlike General Bernard Montgomery, the Allied commander in Normandy, "Generalfeldmarschall" Erwin Rommel was unable to withdraw units into reserve after the battle, as they were needed to hold the front line. The British retained the initiative, attacked several more times over the following two weeks and captured Caen in Operation Charnwood in mid-July. Interpretations of the intention and conduct of Operation Epsom differ widely but there is general agreement concerning its effect on the balance of forces in Normandy. The Germans contained the offensive but only by committing all their strength, including two panzer divisions newly arrived in Normandy, which had been intended for an offensive against British and American positions around Bayeux.

The Norman city of Caen was a D-Day objective for the British 3rd Infantry Division that landed on Sword Beach on 6 June 1944. The capture of Caen, while "ambitious", was described by the official historian, L. F. Ellis, as the most important D-Day objective assigned to Lieutenant-General John Crocker and I Corps. Operation Overlord called for the British Second Army (Lieutenant-General Miles Dempsey), to secure the city and then form a front line from Caumont-l'Éventé to the south-east of Caen. The intention was to acquire space for airfields and to protect the left flank of the US First Army (Lieutenant General Omar N. Bradley), while it fought the Battle of Cherbourg. 

Possession of Caen and its surroundings would give the Second Army a suitable staging area for a push south to capture Falaise, which could be used as the pivot for a swing left to advance on Argentan and then towards the Touques River. Hampered by congestion in the beachhead, which delayed the deployment of its armoured support and forced to divert effort to attack strongly held German positions along the route to the town, the 3rd Infantry Division was unable to assault Caen in force on D-Day and was stopped short by the 21st Panzer Division. Follow-up attacks failed as German reinforcements arrived. Abandoning the direct approach, Operation Perch—a pincer attack by I and XXX Corps—was launched on 7 June, to encircle Caen from the east and west. 

I Corps, striking south out of the Orne bridgehead, was halted by the 21st Panzer Division and the attack by XXX Corps west of Caen was stopped in front of Tilly-sur-Seulles by the "Panzer-Lehr-Division". To force "Panzer-Lehr" to withdraw or surrender and to keep operations fluid, part of the 7th Armoured Division pushed through a gap in the German front line near Caumont and captured Villers-Bocage. The Battle of Villers-Bocage led to the vanguard of the 7th Armoured Division being ambushed and withdrawing from the town but by 17 June, "Panzer Lehr" had also been forced back and XXX Corps had taken Tilly-sur-Seulles.

Another attack by the 7th Armoured Division and other offensive operations were abandoned when a severe storm descended on the English Channel on 19 June. The storm lasted for three days and further delayed the Allied build-up. Most of the convoys of landing craft and ships already at sea were driven back to ports in Britain; towed barges and other loads (including of floating roadways for the Mulberry harbours) were lost and 800 craft were left stranded on Normandy beaches until the spring tides in July. 

Planning began for a second offensive, codenamed Operation Dreadnought, to be launched out of the Orne bridgehead by the British VIII Corps (Lieutenant-General Richard O'Connor), outflanking Caen from the east. Dreadnought was cancelled following objections from O'Connor after studying the ground and an attack towards Évrecy was considered and rejected, either by Montgomery or Dempsey. In a postwar interview with Chester Wilmot, Dempsey claimed that he told Montgomery that he was going to cancel the proposed operation on 18 June. The weather from 19–22 June grounded Allied aircraft and the Germans took advantage of the respite from air attacks to improve their defences. Infantry positions were protected with minefields and 88 mm guns were dug into in hedgerows and woods covering the approaches to Caen.

On 20 June, Field Marshal Erwin Rommel, the commander of "Heeresgruppe B" (Army Group B), was ordered by Hitler to launch a counter-offensive against the Allies between the towns of Caumont-l'Éventé (Caumont) and Saint-Lô. The objective was to cut a corridor between the American and British armies, by recapturing the city of Bayeux (taken by the British on 7 June) and the coast beyond. Four SS panzer divisions and one "Heer" panzer division were assigned to the task. Their assault was to be spearheaded by the II SS Panzer Corps, comprising the 9th SS Panzer Division "Hohenstaufen" and 10th SS Panzer Division "Frundsberg", recently arrived from the Eastern Front. The 1st SS Panzer Division "Leibstandarte SS Adolf Hitler", 2nd SS Panzer Division "Das Reich" and 2nd Panzer Division would support the attack. Most of the tanks used by these formations were Panzer IVs and Panthers, supplemented by sturmgeschütz (assault guns) and Tigers—the Panthers and Tigers being among the most lethal and well-protected German armoured vehicles of the war.

On 18 June, Montgomery issued a directive to Dempsey to launch a new pincer attack with the aim of capturing Caen. The initial plan called for I and XXX Corps to attack west of Caen for four days, before VIII Corps launched the main attack out of the Orne bridgehead, east of Caen, on 22 June. It was soon realised that VIII Corps would not be able to assemble within the small perimeter of the Orne bridgehead and the following day the plan was revised. A preliminary operation was to take place three days before the main assault. The 51st (Highland) Infantry Division (I Corps) was ordered to strike south from the Orne bridgehead, to prevent units of the 21st Panzer Division from being transferred. Operation Martlet was to commence one day before Epsom with the 49th (West Riding) Infantry Division and the 8th Armoured Brigade (XXX Corps) securing the right flank of VIII Corps, by capturing the high ground to the south-west.

The main role in Operation Epsom was assigned to the newly arrived VIII Corps, consisting of 60,244 men. VIII Corps would launch their offensive from the beachhead gained by the 3rd Canadian Infantry Division. Their operation was to take place in four phases, with its ultimate objective being the high ground near Bretteville-sur-Laize, south of Caen. VIII Corps would be supported by fire from 736 guns, three cruisers and the monitor . The Royal Air Force was to provide a preliminary bombardment by 250 bombers and close air support thereafter.

The 15th (Scottish) Infantry Division would lead the assault. During Phase I, codenamed "Gout", they were to take the villages of Sainte Manvieu and Cheux. In Phase II ("Hangover"), the division would advance to capture several crossings over the Odon River and the villages of Mouen and Grainville-sur-Odon. Should resistance during the opening phase prove light, the 11th Armoured Division would seize the bridges over the Odon River by "coup de main". During the first two phases, the 43rd (Wessex) Infantry Division—to be reinforced on 28 June with the infantry brigade of the Guards Armoured Division—was to remain on the start line to provide a "firm base".
In the third phase, "Impetigo", the 43rd Division would move forward to relieve all Scottish infantry north of the Odon. The 15th Division would then assemble across the river and expand the bridgehead by capturing several important villages. In the final phase, codenamed "Goitre", elements of the 43rd Division would cross the river to hold the area taken, while the 15th Division would continue to expand their bridgehead. The 11th Armoured Division would attempt to force a crossing over the River Orne and advance on their final objective of Bretteville-sur-Laize. The 4th Armoured Brigade, although attached to the 11th Armoured Division, was restricted to operations between the Odon and Orne to protect the Corps flank and to be in a position to attack westwards or towards Caen, as necessary.

Depending on the success of VIII Corps attack, I Corps would then launch two supporting operations codenamed "Aberlour" and "Ottawa". In the former the 3rd Infantry Division, supported by a Canadian infantry brigade, would attack north of Caen; the latter would be a move by the 3rd Canadian Infantry Division and the 2nd Canadian Armoured Brigade to take the village and airfield of Carpiquet. Originally planned for 22 June, Epsom was postponed until 26 June, to make up deficiencies in manpower and materiel. The initial opposition was expected to come from the depleted 12th SS Panzer Division Hitlerjugend ("Hitler Youth"), elements of the 21st Panzer Division, and the Panzer Lehr.

On 23 June, the 51st (Highland) Infantry Division attacked with the 152nd (Highland) Infantry Brigade. The Highland infantry advanced towards the village of Sainte-Honorine-la-Chardronette before daybreak, without an artillery bombardment, surprising the German garrison. The Highlanders were counter-attacked by Kampfgruppe von Luck of the 21st Panzer Division during the morning but by midday the village was firmly in British hands. German attention and resources were diverted by the success of the Highlanders as VIII Corps prepared for further attacks out of the Orne bridgehead.

At 0415 on 25 June, the 49th (West Riding) Infantry Division supported by the 8th Armoured Brigade and 250 guns, began Operation Martlet against the junction of the Panzer Lehr and 12th SS Panzer divisions. The first objective, Fontenay-le-Pesnel was fought over all day but stubborn German resistance prevented its capture. An infantry battalion supported by tanks, advanced around the village to the west and took Tessel Wood, where they received several German counter-attacks, which were repulsed by British artillery fire and close air support. By nightfall, the 49th Division had failed to reach Rauray leaving the terrain dominating the right flank of VIII Corps in German hands. Martlet forced the I SS Panzer Corps to commit the remaining tanks of the 12th SS Panzer Division against the XXX Corps front, for a counter-attack the following day. During the night, the Germans in Fontenay-le-Pesnel withdrew to straighten the front line and infantry from the 49th Division secured the village before dawn.

Poor weather hampered the start of Operation Epsom on 26 June, where rain over the battlefield had made the ground boggy; over the United Kingdom in the early hours, there was a heavy mist resulting in aircraft being grounded and the bombing being called off. No. 83 Group RAF, based in Normandy, were able to provide air support throughout the operation.

The 49th (West Riding) Infantry Division resumed Operation Martlet at 0650, although much of its artillery support from VIII Corps was diverted to the main operation. The Germans were able to slow the British advance and then launched an armoured riposte. This initially gained ground but was stalled when British armour moved up and the two sides duelled in the confined terrain. Informed during the afternoon that a big British offensive was under way further east, SS-Standartenführer Kurt Meyer of 12th SS Panzer called off the counter-attack and ordered his tank companies to return to their positions south of Rauray. During the rest of the day the 49th Division was able to make progress, eventually halting just north of Rauray.

At 0730 the 44th (Lowland) Infantry Brigade and the 46th (Highland) Infantry Brigade of the 15th (Scottish) Infantry Division, supported by the 31st Tank Brigade moved off their start lines behind a rolling barrage fired from 344 guns. The 46th Brigade initially advanced without armoured support, because in bypassing the mine and booby trap-ridden village of Le Mesnil-Patry, its tanks were forced to negotiate minefields flanking the village. The 2nd Battalion, Glasgow Highlanders faced only light resistance, while the 9th Battalion The Cameronians, ran into the grenadiers of the 12th SS Panzer Division, who had allowed the barrage to pass over their positions before opening fire. Reuniting with their tanks at around 1000, by midday the two battalions were fighting for control of their initial objectives; Cheux and Le Haut du Bosq.

The 44th Brigade encountered little opposition until coming under machine gun fire at a small stream, following which German resistance was much heavier. Between 0830 and 0930, the 6th Battalion, The Royal Scots Fusiliers and the 8th Battalion, The Royal Scots reached their initial objectives of Sainte Manvieu and La Gaule. After much hand to hand fighting they believed the villages to be captured just after midday, although they later found that some German remnants were holding out. Tanks and infantry from the 12th SS and the 21st Panzer divisions launched two counter-attacks to regain Sainte Manvieu but were repulsed with the aid of intensive artillery fire. The main German opposition in this section of their outpost line, had been from part of the I Battalion, 26th Panzergrenadier Regiment, which had been mostly overrun and the divisional pioneer battalion. The Germans in Rauray, which had not been captured the previous day, were able to subject the British brigades to observed artillery and indirect tank fire, causing considerable casualties and destruction, especially within the village of Cheux.
At 1250 a squadron of the 11th Armoured Division reconnaissance regiment north of Cheux, was ordered to advance towards the Odon, preparatory to an attempt by the divisional armoured brigade to rush the bridges. Owing to minefields near the village, debris blocking its streets and German holdouts attacking the tanks, it was not until 1400 that the regiment was able to make progress. By 1430 the squadron arrived on a ridge south of Cheux where it was engaged by twenty Panzer IVs, sent by the 12th SS Panzer Division from the Rauray area, Tiger tanks from the 3rd Company 101st Heavy SS Panzer Battalion and armour from the 21st Panzer Division. More tanks from the 11th Armoured Division arrived but determined German resistance halted any further advance and by the end of the day the division had lost twenty-one tanks. At 1800 the 227th (Highland) Brigade of the 15th (Scottish) Infantry Division, was committed to the battle. The Highlanders were delayed by fighting in support of the rest of the division and only two companies from the 2nd Battalion Gordon Highlanders made much progress. They entered the northern outskirts of Colleville by 2100 but soon found themselves cut off by German counter-attacks. After heavy and confused fighting one company was able to break out and rejoin the battalion. To stop the British offensive, that evening Field Marshal Rommel ordered assistance from all available units of II SS Panzer Corps.

With no attacks during the night, the German command believed that the British offensive had been contained. During the early hours of 27 June, II SS Panzer Corps was ordered to resume preparations for its counter-offensive towards Bayeux. On the right of the British advance, the I SS Panzer Corps launched a counter-attack with 80 tanks, which was disorganised by artillery fire, before foundering on the anti-tank guns of the 49th (West Riding) Infantry Division, who then resumed their attempt to secure VIII Corps flank. Rauray was taken by the 49th Division at 1600 on 27 June, after further heavy fighting against the 12th SS Panzer Division. German forces had been diverted from opposing VIII Corps advance and the fall of Rauray denied the Germans an important observation point, although they remained in control of an area of high ground to the south.

Epsom was resumed at 0445 by the 10th Battalion, Highland Light Infantry of the 227 (Highland) Infantry Brigade. With support from Churchill tanks; the battalion intended to make a bid for the Odon crossing at Gavrus. The Highlanders immediately ran into stiff opposition from elements of the 12th SS Panzer Division and despite heavy artillery support were unable to advance all day. Casualties were heavy on both sides. At 0730 the 2nd Battalion, Argyll and Sutherland Highlanders, also of the 227th Highland Brigade, launched an attack aimed at capturing the Odon crossing at Tourmauville, north-west of the village of Baron-sur-Odon. With the German forces engaged by the Highland Light Infantry, the Argyll and Sutherland Highlanders supported by the 23rd Hussars, were able to advance to Colleville with relative ease. There the small German garrison supported by 88 mm guns, inflicted heavy casualties upon the British and denied them the village until the afternoon. The battalion seized the bridge at Tourmauville at around 1700 and a bridgehead was established. By 1900, two depleted squadrons of the 23rd Hussars and a company of the 8th Battalion, Rifle Brigade (Prince Consort's Own) had crossed the Odon into the bridgehead.

The remainder of the 15th (Scottish) Infantry Division around Cheux and Sainte Manvieu, was being relieved by the 43rd (Wessex) Infantry Division. When the 5th Battalion, Duke of Cornwall's Light Infantry, of the 214th Infantry Brigade, moved into the outskirts of Cheux, they found that the Scottish infantry had moved on and the vacant position had been reoccupied by grenadiers of 12th SS Panzer Division. After battling to recapture the position, at 0930 the battalion was counter-attacked by six Panthers of the 2nd Panzer Division. The attack penetrated Cheux and several British anti-tank guns were destroyed before it was beaten off. Further attacks by the 2nd Panzer Division were halted but the entire front was "a mass of small engagements". For the rest of the morning and afternoon, the Scottish infantry and the 4th and 29th Armoured brigades expanded the salient north of the Odon and secured the rear of the Argyll and Sutherland Highlanders. During late evening the men of the 159th Infantry Brigade (11th Armoured Division) were transported in trucks through the narrow "Scottish Corridor" to Tourville, where they dismounted and crossed the Odon on foot to reinforce the bridgehead. During the night Kampfgruppe Weidinger, a 2,500-strong battle group from the 2nd SS Panzer Division arrived at the front and was placed under the command of the Panzer Lehr Division.

During the early hours of 28 June, a battle group of the 1st SS Panzer Division, "Kampfgruppe Frey", arrived at the front and was placed under the command of the 12th SS Panzer Division. At 0810, General Friedrich Dollmann, the 7th Army commander, ordered SS-Obergruppenführer Paul Hausser to divert the II SS Panzer Corps, to counter-attack south of Cheux. Hausser replied that no counter-attack could be launched until the following day, as so many of his units had yet to reach the front. The German command was thrown into disarray by Dollmann's sudden death, when Rommel and Gerd von Rundstedt (OB West) were en route to a conference with Hitler and out of touch with the situation. It was not until 1500 that Hausser was appointed commander of the 7th Army, with Willi Bittrich replacing him as commander of II SS Panzer Corps. (Hausser was advised to retain control of the Corps until the following morning.) Pending the return of Rommel to Normandy, Hausser was also to be supreme commander in the invasion area. At 1700 the command structure was changed again; the 7th Army under Hausser would be responsible for the invasion front facing the American army, while the Panzer Group West (General Geyr von Schweppenburg) was to be responsible for the invasion front facing the Anglo-Canadian forces.
At 0530 elements of the 15th (Scottish) Infantry Division with tank support, launched a new assault to capture the village of Grainville-sur-Odon. After shelling and close quarter street fighting, the Scots secured the village by 1300 hours; German counter-attacks followed but were repulsed. At 0600 the Germans began two strong flanking attacks, with the intention of pinching out the British salient. "Kampfgruppe Frey" on the eastern flank, launched an attack north of the Odon, supported by Panzer IVs of the 21st Panzer Division. This reached the villages of Mouen and Tourville but the British counter-attacked from the direction of Cheux, resulting in confused heavy fighting throughout the day. Frey's battle group managed to gain control of Mouen and British counter-attacks supported by tanks halted any further advance but were unable to retake the village. British patrols found Marcelet partly empty, the German front line having been pulled back towards Carpiquet.

On the western flank, "Kampfgruppe Weidinger" supported by Panthers, tried to recapture Brettevillette, Grainville-sur-Odon and ultimately Mondrainville. The British defenders (Brettevillette and on Point 110: the 1st Battalion Tyneside Scottish, 11th Battalion Durham Light Infantry (49th (West Riding) Infantry Division) and 4th/7th Dragoon Guards (8th Armoured Brigade). In Grainville-sur-Odon and le Valtru: 7th Battalion Seaforth Highlanders, 9th Battalion Cameronians (Scottish Rifles) and 9th Royal Tank Regiment.) held their positions, launching local counter-attacks to retake lost ground and eventually the German offensive was stopped, within of linking up with the lead elements of "Kampfgruppe Frey".

South of the Odon, at 0900 the Argyll and Sutherland Highlanders advanced out of the bridgehead, to capture a bridge north of the village of Gavrus. Heavy fighting took place into the afternoon before both village and bridge were in Scottish hands. Infantry from the 11th Armoured Division, expanded the bridgehead by taking the village of Baron-sur-Odon and the 23rd Hussars with infantry advanced on Hill 112 (). Having secured its northern slope and dislodged the defenders from its crest, they were unable to advance further, due to the Germans dug in on the reverse slope. Several counter-attacks were launched by 12th SS Panzer and the battered Hussars were relieved at 1500 by the 3rd Royal Tank Regiment but neither side was able to take complete control of the hill. The 11th Armoured Division had lost nearly 40 tanks on its slopes by the end of the day and was surrounded on three sides but troops managed to reach and reinforce the position.

With the weather improving over the United Kingdom and Normandy, Hausser's preparations for his counter stroke came under continual harassment from Allied aircraft and artillery fire, delaying the start of the attack to the afternoon. From the number of German reinforcements arriving in the VIII Corps sector and aerial reconnaissance, O'Connor suspected that the Germans were organising a counter-stroke. XXX Corps was still some way to the north, leaving the VIII Corps right flank vulnerable, O'Connor postponed attacks by I Corps and ordered VIII Corps onto the defensive. Dempsey, privy to ULTRA decrypts of intercepted German signal traffic, knew the counter-attack was coming and approved O'Connor's precautions. VIII Corps began to reorganise to meet the attack. Supply echelons for Hausser's divisions were located in the Évrecy–Noyers-Bocage–Villers-Bocage area and were the focus of RAF fighter-bomber attention throughout the morning and early afternoon; the RAF claimed the destruction of over 200 vehicles.

VIII Corps also launched spoiling attacks, at 0800 1st Battalion Worcestershire Regiment, from the 43rd Division, assaulted Mouen, without tanks behind an artillery barrage. By 1100 the battalion had forced the 1st SS Panzer Division panzergrenadiers back and the 7th Battalion Somerset Light Infantry moved up and dug in on the Caen–Villers-Bocage road. The 129th Brigade of the 43rd Division, swept the woods and orchards around Tourville-sur-Odon, before crossing the river north of Baron-sur-Odon and clearing the south bank. An attempt by the 44th Brigade of the 15th Division to advance towards the Odon and link up with the force holding the Gavrus bridges failed, leaving this position isolated and in the salient the 44th Battalion Royal Tank Regiment failed to capture Hill 113 () north of Évrecy, after clashing with 10th SS Panzer Division and losing six tanks. Elements of the 11th Armoured Division attacked Esquay-Notre-Dame west of Hill 112 but were repulsed and an attack by the 8th Rifle Brigade and the 3rd Royal Tank Regiment on the southern slope of the hill, drove the Germans from the position.
Hausser intended that the 9th SS Panzer Division, with "Kampfgruppe Weidinger" protecting its left flank, to cut across the British salient north of the Odon, while the 10th SS Panzer Division retook Gavrus and Hill 112 south of the river. The 9th SS Panzer attack began at 1400, heavily supported by artillery. The 19th and 20th SS Panzergrenadier Regiments supported by Panthers, Panzer IV's and assault guns attacked Grainville, le Haut du Bosq and le Valtru, aiming for Cheux. A British company was overrun and tanks and infantry penetrated le Valtru, where anti-tank guns knocked out four German tanks in the village and artillery fire forced their supporting infantry to withdraw. Confused fighting, at times hand-to-hand, took place outside Grainville and the Panzergrenadiers captured a tactically important wood, before being forced back by a British counter-attack. The Panzergrenadiers claimed they also captured Grainville but no British sources support this and by nightfall British infantry were in control of the village.

At around 1600, the British captured an officer of the 9th SS Panzer Division who was conducting a reconnaissance. He was found to be carrying a map and notebook containing details of new attacks. Around 1830, the Germans attacked the 15th (Scottish) Infantry Division on the right flank. One unit was being relieved and in the confusion, German tanks and infantry slipped through the British defences, with some units advancing before running into heavy resistance. By 2300, the attack by the 9th SS Panzer had been stopped. Supporting attacks against the British eastern flank had been planned but German tank concentrations assembling in the Carpiquet area, had been so severely disrupted by RAF fighter-bombers during the afternoon, that the attacks never materialised.

The 10th SS Panzer Division launched its attack behind schedule at 1430. Following clashes earlier in the day the British were waiting but after five hours of battle, the Scottish infantry defending Gavrus had been pushed back into a pocket around the bridge, north of the village. An artillery bombardment caused the Germans to withdraw but the British did not reoccupy the village. Moving towards Hill 113, the 2nd Grenadier Battalion, Panzergrenadier Regiment 21 and 2nd Battalion, Panzer Regiment 10 of 10th SS Panzer ran into the 44th Battalion The Royal Tank Regiment and 2nd Battalion (The King's Royal Rifle Corps) in Évrecy, who thwarted their attempt to occupy the hill. Dealing with this obstacle took the remainder of the day and the attack on Hill 112 was postponed. The Germans claimed the destruction of 28 tanks while the British recorded the loss of 12.

Believing the German attacks on 29 June indicated more counter-attacks for the following day, Dempsey reinforced the Odon bridgehead with a brigade of the 43rd division and pulled in its perimeter. The 159th Infantry Brigade of the 11th Armoured Division was placed under the command of the 15th (Scottish) Infantry Division and acceding to O’Connor’s wishes for additional infantry, Dempsey attached the newly arrived 53rd (Welsh) Infantry Division to VIII Corps; the lead brigade arrived near the Epsom start line during the night. To hold Hill 112, it was necessary hold Évrecy and Hill 113 for which there were insufficient troops and Dempsey ordered the 29th Armoured Brigade to abandon the hill. To hold the area between Rauray and the Odon, Dempsey withdrew the 29th Armoured Brigade north across the river after dark, ready for the expected German offensive.

Bittrich ordered a resumption of the offensive during the night of 29–30 June, hoping to avoid Allied air support. The 19th and 20th Regiments of the 9th SS Panzer Division, renewed their attacks against Grainville-sur-Odon and le Valtru in the dark but little progress was made against the 11th Armoured Division north of the Odon and heavy British artillery bombardments. At 0120, the 10th SS Panzer Division started to move towards Hill 112 and at dawn, covered by a heavy artillery barrage they assaulted the vacated British positions. Unaware that the British had pulled back, Panzergrenadiers and tanks of the 10th SS Panzer advanced on the hill from the south and south-west and infantry from 12th SS Panzer attacked from the east and south-east. Meeting no opposition, by noon the Germans had occupied the hill. A British counter-attack and artillery fire broke up a follow-up attack towards Baron-sur-Odon.

Bittrich called off further offensive action against VIII Corps. In the evening Hausser, commanding the 7th Army, informed Rommel's headquarters that his counter-attacks had been temporarily suspended due to "tenacious enemy resistance" and intensive Allied artillery and naval gunfire. Unaware of this and believing that more German attacks would follow, Dempsey closed down Operation Epsom. The front gradually settled down save for skirmishing, although both sides spent the remainder of the day heavily shelling one another. The battleship HMS "Rodney" contributed by bombarding villages suspected of containing German headquarters; one was later found to have housed the headquarters of the I SS Panzer Corps. With no further British offensive moves due, in the afternoon the Gavrus bridges were given up, the Scottish defenders being withdrawn across the Odon. At 2030 the town of Villers-Bocage, a vital traffic centre for the German forces, was destroyed by 250 RAF heavy bombers. It had been intended to catch German troops by the bombing but only French civilians were present.

The II SS Panzer Corps resumed its counter offensive on 1 July, after spending most of the preceding 24 hours regrouping. Unaware that the British had ended their operation and with overcast weather interfering with Allied air support, Bittrich believed he had an opportunity to prevent the 11th Armoured Division continuing its advance across the Orne. Before dawn the 10th SS Panzer Division advanced, supported by heavy mortar and artillery fire. The Germans took the village of Baron-sur-Odon quickly but a counter-attack by the 31st Tank Brigade retook it by noon. Heavy shelling broke up other attacks by 10th SS Panzer from Hill 112 and British patrols later found Panzergrenadiers on the northern slope of the hill.

The 9th SS Panzer Division spent the day attempting to force the British lines between Rauray and the Odon. Supplemented by Panzergrenadiers of the 2nd SS Panzer Division and following a preliminary bombardment, tanks and infantry of 9th SS Panzer advanced behind a smoke screen and broke through the outer British defences. The Germans were stopped by secondary positions in front of Rauray and on high ground to the south-east, although some troops penetrated as far as Haut du Bosq. Further German attacks throughout the day, were met with intense artillery fire and made no progress, in the early evening a British counter-attack with Sherman and flame-throwing Churchill Crocodile tanks restored the original front line. The attacks were costly for both sides, thirty German tanks were claimed destroyed, mostly by the 49th (West Riding) Infantry Division, troops of the 12th SS Panzer Division had been repulsed during the morning and artillery fire halted attacks from other formations.

Having had to commit his last strategic reserves to contain the British offensive, on 29 June Rommel requested permission from Hitler to allow the 7th Army to begin a fighting withdrawal towards the River Seine; a move which would be mirrored by German forces in southern France to form a new front line along the Seine towards the Swiss border. This was partially endorsed by Hausser, who on 30 June proposed a retirement from Caen. Encouraged by the fighting in the valley of the Odon, Hitler stated that "we must not allow mobile warfare to develop", committing his troops in Normandy to "a policy of aggressive and unyielding defence". On 2 July, Scottish patrols produced the first evidence of this, reporting that south of the Odon the Germans were digging in. Aerial photographs taken two days later, showed large numbers of newly dug weapon positions and by 8 July, the German forces facing VIII Corps had entrenched themselves. Some local adjustments occurred as both sides sought to improve their tactical position and the 12th SS Panzer Division captured Fontaine-Étoupefour on 2 July.
The VIII Corps, in battle for the first time, had broken through elaborate German defensive positions and advanced nearly . By throwing in their last reserves, the Germans had been able to achieve a defensive success at the operational level, by containing the British offensive. More than 4,000 casualties were inflicted upon the British but the effort cost the Germans more than 3,000 men. The German commanders had been forced to commit their armoured reserves piecemeal to meet threats as they developed, counter-attacking at a disadvantage. Over tanks were destroyed, the organisation of the remaining forces was disrupted and their offensive power much reduced. With few infantry divisions to relieve them, the panzer divisions were forced to remain in the front line rather than pulling back into reserve to recover.

Operation Epsom has been analysed by many military historians and commentators. S. A. Hart wrote in 2007, that post-war publication of memoirs by Allied generals had led to disputes along national lines during the 1950s and 1960s, with American historians generally critical of Montgomery and the actions of the Anglo-Canadian forces, while "pro-Montgomery" historians set out to refute these criticisms. Also published during this period were the national official campaign histories, which were thoroughly-researched but avoided detailed critical analysis of the controversies. During the 1980s, revisionist writers concentrated on the perceived deficiencies of the Allies and since the late 1990s, two schools of thought have been revising the revisionists, some expanding on revisionist work, by providing a more detailed campaign analysis and those who have tried to show that the techniques employed by the Anglo-Canadian forces were appropriate to conditions in Normandy.

In 1983, Carlo D’Este wrote that the most logical place for a British attack would have been out of the Orne bridgehead, on the extreme eastern flank of the Allied lodgement. An attack there had been rejected by Montgomery, Dempsey and O’Connor as unrealistic. Some writers described the intent of Epsom as an attack to gain ground, while others have suggested that the operation had other objectives. In 2004, Williams wrote that due to ULTRA intercepts, Montgomery was aware of Rommel's plan to attack towards Bayeux and that Epsom was intended to forestall it. Wilmot in 1952 wrote that the operation was intended to draw the I SS Panzer Corps and the newly arrived II SS Panzer Corps into battle around Caen. Hart wrote that Montgomery wanted to keep the initiative and prevent German armoured forces from moving from to the west against the US First Army or being relieved and forming a reserve. The arrival of the II SS Panzer Corps was a catalyst for Operation Epsom, which retaining the initiative by forcing the German command to use the II SS Panzer Corps against VIII Corps. Hastings wrote in 1985 that "no sane commander" would mount an attack as big as Epsom without "every hope of breaking through the German defences, or at least of causing the enemy to make substantial withdrawals". D’Este wrote that "No amount of pretence can conceal that the real object had been a short pincer movement to outflank Caen".

Lloyd Clark wrote: "On the battlefield, Epsom ended, rather ignominiously, in a sort of draw" and that judging the effects of Operation Epsom is hampered by disagreement about Montgomery's intent. In written orders Montgomery required an advance across the Orne River and the capture of high ground south of Caen, which was not achieved. Clark wrote that there were implicit objectives with strategic implications, more important than the capture of ground. In 1971, Ambrose wrote of Epsom veering off-course from the plan and D'Este wrote that Epsom was "an operation of immense intentions which were not attained", calling it a "dismal failure". In 2004, Trew and Badsey wrote of the British "failure" that it "... took most of six Panzer Divisions to stop Epsom short of its final objectives..." and Reynolds in 2002, wrote that without the commitment of these six divisions, it was highly likely that the British offensive would have achieved its goals. Daglish in 2007 wrote that while the original concept of Epsom had failed, the offensive was a strategic success. By withdrawing the 11th Armoured Division across the Odon and then into reserve, the 21st Army Group had re-created the threat of an offensive near Caen. By the end of June, all German armoured forces in Normandy were concentrated on the Second Army front.

Shulman had written in 1947, that with the defeat of its second armoured counter-attack in June, the German command had thrown away its most effective troops and Reynolds wrote that while the operation was costly for the British, it caused "grievous losses" to the Germans. In the VIII Corps history published in 1945, Jackson wrote that Epsom failed in its overt goal but that "when seen as part of Montgomery's series of rapid and consecutive blows against the German Army in Normandy, the importance of Epsom becomes more apparent and there is little doubt that it did play a significant part in the Allies' eventual success in the region". D'Este wrote that the losses inflicted on the German army were "purely in terms of men and material". Copp in 2003 wrote that too much emphasis had been given to a "win-lose" criterion, whereas a cost-benefit approach provided more insight. Describing the standard German practice of counter-attacking when driven from a position, Copp wrote that the Germans courted losses that could not be readily replaced, "One such counter-attack on 22 July resulted in 10SS regaining control of the Bon Repas–Évrecy road, a clear victory in a win-lose narrative but a typical German defeat in any cost-benefit analysis".

In 2013, Buckley wrote that by 1 July, there was a stalemate in which the British were established south of the Odon but had retired from Hill 112, in what may have been a premature decision. The Germans had maintained a continuous front but only by using reserves which made it impossible to begin the counter-offensive planned by , which made the offensive a considerable Allied success, as part of a strategy of attrition based on organised fire power. Looked on as an attempt to break through and force the Germans out of Caen the operation failed but in terms of Montgomery's strategy it was a costly victory. The German defence of Normandy never recovered from the damage inflicted during Epsom, the initiative was lost and German counter-attack tactics failed in the face of Allied fire power, with even greater cost than that inflicted on the British; the German command structure and assumptions on which the defence was based were undermined.

Clark wrote that casualties in the 15th (Scottish) Infantry Division were and from Buckley gave casualties for the division as killed, the casualties incurred from 1945 and that the other units in the operation had The losses among the 11th Armoured Division and 43rd (Wessex) Infantry Division, were killed in the 11th Armoured Division. No figures are provided for the 49th (West Riding) Infantry Division, 51st (Highland) Infantry Division or the 8th Armoured Brigade, that conducted preliminary operations and attacks in support of Epsom. From VIII Corps lost and On 1 July, a further were killed and wounded and were reported missing. These figures exclude formations conducting preliminary operations and attacks in support of Epsom. The Germans had more than during Epsom; the 9th SS Panzer Division suffered the 10th SS Panzer Division the 12th SS Panzer Division The Germans lost from 26 June to midnight on 1 July, and among them. In 2015, Napier published new figures for equipment losses of and tanks.

The increasingly costly static defence led to disputes in the German high command. On the evening of 1 July in a conversation with Wilhelm Keitel, Rundstedt said "Make peace, you fools." Shortly afterwards, Günther von Kluge replaced him as Commander in Chief West. Due to his disagreements with Hitler over how the campaign should be conducted, Schweppenburg was replaced by Heinrich Eberbach as commander of Panzer Group West.

During the lull both sides made changes to their dispositions. The 53rd (Welsh) Infantry Division relieved the 15th (Scottish) Infantry Division in the west of the British salient, while the 43rd (Wessex) Infantry Division relieved the infantry of the 11th Armoured Division who were still holding the Odon bridgehead. The Germans moved up the 277th Infantry Division which began to relieve the 9th SS Panzer Division and the battle group of the 2nd SS Panzer Division.

A few days later the British Second Army launched Operation Charnwood, to take Caen. This incorporated the postponed attack on Carpiquet, originally planned for Epsom as Operation Ottawa but now codenamed Operation Windsor. In a frontal assault the northern half of the city was captured, with the remaining portions being taken during Operations Atlantic and Goodwood in the third week of July. Fighting in the Odon Valley continued and on 10 July Operation Jupiter was launched by VIII Corps to push back the German forces near the village of Baron-sur-Odon, retake Hill 112 and advance to the River Orne. The Second Battle of the Odon began on 15 July to divert German attention from the ground where Operation Goodwood was to take place. The second battle has been called one of the bloodiest encounters of the campaign.

The British and Commonwealth system of battle honours recognised participation in Operation Epsom in 1956, 1957 and 1958, by the award to 34 units of the battle honour "Odon", for service on and around the river from 25 June to 2 July 1944. The award was accompanied by honours for four actions during the operation: "Fontenay le Pesnil" on "Cheux" from "Tourmauville Bridge" on 27 June and "Defence of Rauray" from 



</doc>
<doc id="253074" url="https://en.wikipedia.org/wiki?curid=253074" title="Governor of Kentucky">
Governor of Kentucky

The Governor of the Commonwealth of Kentucky is the head of the executive branch of government in the Commonwealth of Kentucky. Fifty-seven men and one woman have served as Governor of Kentucky. The governor's term is four years in length; since 1992, incumbents have been able to seek re-election once before becoming ineligible for four years. Throughout the state's history, four men have served two non-consecutive terms as governor, and two others have served two consecutive terms. Kentucky is one of only five U.S. states that hold gubernatorial elections in odd-numbered years immediately before the United States Presidential Election. The current governor is Matt Bevin, who was first elected in 2015.

The governor's powers are enumerated in the state constitution. There have been four constitutions of Kentucky—adopted in 1792, 1799, 1850, and 1891, respectively—and each has enlarged the governor's authority. Among the powers appropriated to the governor in the constitution are the ability to grant pardons, veto legislation, and call the legislature into session. The governor serves as commander-in-chief of the state's military forces and is empowered to enforce all laws of the state. The officeholder is given broad statutory authority to make appointments to the various cabinets and departments of the executive branch, limited somewhat by the adoption of a merit system for state employees in 1960. Because Kentucky's governor controls so many appointments to commissions, the office has been historically considered one of the most powerful state executive positions in the United States. Additionally, the governor's influence has been augmented by wide discretion in awarding state contracts and significant influence over the legislature, although the latter has been waning since the mid-1970s.

The history of the office of Governor is largely one of long periods of domination by a single party, though different parties were predominant in different eras. Federalists were rare among Kentuckians during the period of the First Party System, and Democratic Republicans won every gubernatorial election in the state until 1828. The Second Party System began when the Democratic-Republicans split into Jacksonian Democrats (the predecessor of the modern Democratic Party) and National Republicans (later to become Whigs). Beginning with the election of Thomas Metcalfe in 1828, the Whigs dominated the governorship until 1851, with John Breathitt being the only Democrat elected during that period.

With the collapse of the Whig Party in the 1850s, Democrats took control of the governorship for the duration of the Third Party System, with Charles S. Morehead of the Know Nothing Party being the only exception. The election of Republican William O'Connell Bradley in 1895 began the only period of true two-party competition for the governorship; from Bradley's election through 1931, five Republicans and six Democrats held the office of governor of Kentucky. Since 1931, only four Republicans have served as governor of Kentucky; current governor Matt Bevin, whose term began in 2015, is the most recent.

In all four Kentucky constitutions, the first power enumerated to the governor is to serve as commander-in-chief of the state's militia and military forces. In 1799, a stipulation was added that the governor would not personally lead troops on the battlefield unless advised to do so by a resolution of the General Assembly. Such a case occurred in 1813 when Governor Isaac Shelby, a veteran of the Revolutionary War, was asked to lead a band of Kentucky troops to aid William Henry Harrison at the Battle of the Thames. For his service, Shelby received the Thanks of Congress and the Congressional Gold Medal.

Among the other powers and responsibilities of the governor that appear in all four constitutions are the power to enforce all laws, the power to fill vacancies in elected offices until the next meeting of the General Assembly, and the power to remit fines and grant pardons. The power to pardon is not applicable to cases of impeachment, and in cases of treason, a gubernatorial pardon is only effective until the end of the next session of the General Assembly, which can grant a full pardon for treason. The 1891 constitution further required that, with each application for a pardon, the governor file "a statement of the reasons for his decision thereon, which ... shall always be open to public inspection." This requirement was first proposed by a delegate to the 1850 constitutional convention, but it was rejected at that time. Historically, power in Kentucky's executive has been split amongst a variety of elected positions—including Lieutenant Governor, Attorney General, Auditor of Public Accounts, Treasurer, and several commissioners—but in the late 20th century, political power has centralized in the office of Governor.

The power of the governor to adjourn the General Assembly for a period of up to four months if the two houses cannot agree on a time to adjourn appears in all four constitutions. The governor is also empowered to convene the General Assembly "on extraordinary occasions". Since the 1799 constitution, the governor has been permitted to call the legislature into session somewhere other than the state capital if the capital had, since the last legislative session, "become dangerous from an enemy or from contagious diseases." This was an important provision in the early days of the Commonwealth, when epidemics like smallpox posed a danger to the populace. One notable example of an attempt to employ this power was in 1900 when Republican Governor William S. Taylor attempted to adjourn the legislature and re-convene it in heavily Republican London, Kentucky following the shooting of William Goebel. Taylor claimed a state of insurrection existed in the capital, but defiant Democrats refused to heed the call to adjourn or to convene in London.

The 1891 constitution added a provision that the governor must specify the reason for any specially-called legislative session, and that no other business could be considered during the session. There is, however, no constitutional requirement that the legislature conduct any business during the called session. In 2007, Republican governor Ernie Fletcher called the Assembly into session to consider a long list of items. The Democratically-controlled House of Representatives maintained that none of the items were urgent enough that they could not wait until the regular session convened; they claimed that Fletcher was calling the session only to boost his sagging poll numbers before the upcoming election in which he faced a challenge from Democrat Steve Beshear. The House convened on the day appointed and adjourned an hour later without transacting any business.

Unlike the U.S. President, the governor does not have the option of a pocket veto. If the governor does not make a decision to sign or veto a bill, it automatically becomes law after ten days. In the event that the legislature adjourns to prevent the return of a bill by veto, the bill becomes law three days after the commencement of the next legislative session unless the governor explicitly vetoes it. (With the federal pocket veto, the bill is considered vetoed after ten days if the legislature adjourns.)

The 1799 constitution contained, for the first time, the power of the governor to veto legislation; this power was substantially similar to, and probably based upon, that found in the 1792 New Hampshire Constitution and the 1798 Georgia Constitution. The 1891 constitution empowered the governor with a line-item veto, but its use was forbidden on constitutional amendments and laws related to the classification of property for tax purposes. The governor's veto can be overridden by roll-call majority votes of both houses of the legislature.

Although setting the state budget is a legislative function in many states, Kentucky governors are required by statute to present a proposed biennial budget to the General Assembly for approval shortly after the beginning of its even-year sessions. The governor's budget has often been approved with few changes, but since the Republicans took control of the state senate for the first time in 1999, approval has become a much more contentious process. The General Assembly failed to pass a budget before the end of its session in both 2002 and 2004. In both cases, the state operated under an executive spending plan drafted by the governor until the legislature could re-convene and pass a budget. In 2005 the Kentucky Supreme Court ruled that the governor had no authority to expend funds without legislative approval, and that if legislators failed to pass a budget in the future, only expenditures explicitly authorized in the state constitution could be made.

Although the Kentucky constitution designates the governor as the head of the executive branch of state government, it does not specify the means of carrying out that role. Empowered to nominate all constitutional officers by the state's first constitution, that power of the office of the governor has been reduced in subsequent constitutions, as more of those offices became elective. Because the governor is not explicitly authorized by the constitution to conduct many of the functions necessary to administer the state government, the officeholder has had to rely on empowering legislation enacted by the General Assembly. With this in mind, Kentucky historian Thomas D. Clark wrote in 2004 that extensive executive powers had been granted through the creation of a large number of commissions that reported to the governor:
During the past century and a half, and especially in the later 20th century, it would have been impossible for state government to operate efficiently without a broadening of executive powers. Through the years the General Assembly has created a myriad of commissions and turned them over to the governor to exercise administrative oversight. ... All of these commissions extended the influence of the governor into every phase of human life in the commonwealth, well beyond the limitations of executive power envisioned by delegates to the constitutional convention in 1891.

By 1934, the executive branch consisted of sixty-nine boards, commissions, and agencies in addition to the constitutional officers, although the members of these commissions were often the constitutional officers themselves. Governor Ruby Laffoon proposed the Administrative Reorganization Act of 1934 to organize these boards and commissions into seventeen executive departments and seven independent agencies. The General Assembly passed this legislation, giving the executive branch some semblance of structure for the first time.
Laffoon's successor, A. B. "Happy" Chandler, called a special legislative session in 1936 seeking passage of another reorganization act. This act abolished several commissions and organized those remaining into ten statutory departments: Finance, Revenue, Highways, Health, Welfare, Industrial Relations, Business Regulation, Conservation, Libraries and Archives, and Mines and Minerals. The Act also created the Executive Cabinet, consisting of the constitutional officers and the heads of each of the ten statutory departments. The efficiencies created by Chandler's reorganization allowed him to pay off more than three-quarters of the state's $28.5 million debt. Besides effecting the reorganization of the executive branch, the Reorganization Act of 1936 also explicitly empowered the governor to appoint executive department heads and establish, combine, or divide departments as necessary. Later statutes gave the governor the power to appoint advisory committees on reorganization, appoint deputy heads of divisions, transfer employees and change their responsibilities within the executive branch, and establish general rules of conduct for executive branch members.

In the 35 years between the time of Chandler's reorganization and the election of Wendell H. Ford as governor in 1971, the executive branch had again become unwieldy. 60 departments and 210 boards reported directly to the governor by 1972, and duplication of services between departments had created inefficiencies. On January 1, 1973, a plan that Ford had issued in late 1972 took effect, consolidating the departments reporting to him into six program cabinets: Consumer Protection and Regulation, Development, Education and the Arts, Human Resources, Safety and Justice, and Transportation. Ford continued merging departments and reorganizing the executive branch throughout 1973 to the extent that, by the end of the year, there were only three program cabinets (Development, Education and the Arts, and Consumer Protection and Regulation) and four additional departments (Human Resources, Justice, Natural Resources and Environmental Protection, and Transportation).

By 2002, the executive branch had again grown to fourteen cabinets, but had no additional departments. Shortly after his election in 2003, Governor Ernie Fletcher undertook the last major reorganization of the executive branch to date, reducing the number of cabinets to nine—Justice and Public Safety, Education and Workforce Development, Environmental and Public Protection, Transportation, Economic Development, Health and Family Services, Finance and Administration, Tourism, Arts and Heritage, and Personnel.

Because the governor controls so many appointments to commissions—approximately 2,000 according to a 1992 estimate—the office has been historically considered one of the most powerful state executive positions in the United States. Additionally, the governor is given wide discretion in awarding state contracts, further augmenting his influence. In the second half of the 20th century, attempts were made to curb the use of the governor's appointment power for political patronage. During his second term in office, Happy Chandler issued an executive order creating a merit system that forbade the hiring or firing of state employees for political reasons; his successor, Bert T. Combs, pushed a new merit system through the legislature, protecting it from abolition by executive order. Despite the presence of the merit system, many governors have been criticized for abusing their appointment power. In 2005, Ernie Fletcher and several members of his administration were indicted for violating the merit system in their hiring practices; the charges were later dropped as part of an agreement with the prosecutor, Attorney General Greg Stumbo.

In "The Kentucky Encyclopedia", Eastern Kentucky University professor Paul Blanchard writes that "Many observers consider the governor's informal powers—those derived from tradition, custom, and precedent—as important as the formal powers." Frequently the leaders of their political parties at the state level, Kentucky governors usually control the party's delegations to state and national party conventions. Though given few powers with regard to the legislature, Kentucky governors can exercise a great deal of influence over the General Assembly, often hand-selecting the leadership of both chambers. A move toward a more independent legislature began in the last quarter of the 20th century, particularly during the administration of Governor John Y. Brown, Jr. from 1979 to 1983. Brown was much less engaged in legislative affairs than his predecessors; he did not seek to influence the selection of the legislature's leadership, and he left on vacation during one of the two legislative sessions of his term. The trend toward a coequal legislature continued under the administrations of Brown's two immediate successors, Martha Layne Collins and Wallace Wilkinson, neither of whom was considered a strong executive.

The governor is also the most visible state officer and is the center of political attention in the Commonwealth. The official host of the state when dignitaries visit, the governor frequently delivers addresses at various dedications and ceremonies, and appears on national television with the winner of the annual Kentucky Derby. The state constitution requires the governor to address the legislature periodically regarding the state of the Commonwealth. This address, traditionally given annually, is often targeted directly at the state's citizens as much as, or more so than, the legislature. The governor can use the address to extol the accomplishments of his or her term and lay out a specific plan for the upcoming legislative session; the contents of the address often shape the agenda of the session. The state's media outlets devote significant coverage to the governor's actions, and many strong governors have used the media to win support for their agendas and criticize political enemies.

Candidates for the office of governor of Kentucky must be at least thirty years of age and have resided in the state for at least six years preceding the general election. The residency requirement was increased from two years to six years in the constitution of 1799 and all subsequent constitutions. The 1792 constitution—the state's first—also included an exception for candidates who had been absent from the state "on the public business of the United States or of this State." The age requirement was raised from thirty years to thirty-five years in the 1799 constitution and was returned to thirty years in the 1891 constitution.

A prohibition against any person concurrently holding the office of governor and a federal office appears in the first three state constitutions, but is absent in the state's current charter. Additionally, the 1799 constitution barred a "minister of any religious society" from holding the office. This language was possibly aimed at the sitting governor, James Garrard, who was an ordained Baptist minister and had frequently clashed with the legislature. The prohibition against ministers holding the office remained in the 1850 constitution, but was removed from the 1891 constitution.

In the 1891 constitution, a section was included that forbade anyone from holding any state office—including the office of governor—who had "either directly or indirectly, give[n], accept[ed] or knowingly carr[ied] a challenge to any person or persons to fight in single combat, with a citizen of this State, with a deadly weapon, either in or out of the State". This provision reflected the prevalence of duelling in the South at the time. Though anachronistic, the provision remains in the state constitution and the gubernatorial oath of office, which states:

The governor's term has been for four years in all four state constitutions. The governor was not term-limited in the 1792 constitution, but in the 1799 constitution, the governor was made ineligible for re-election for seven years following the expiration of his term. The provision did not apply to then-sitting governor James Garrard, who was re-elected in 1799. In the 1850 constitution, the period of ineligibility following the expiration of the governor's term was shortened to four years, and it remained so in the 1891 constitution. In 1953, Governor Lawrence Wetherby lamented the challenges presented by the term limit coupled with biennial legislative sessions:
A Kentucky governor is elected under our constitution for four years without legal opportunity, regardless of how acceptable his program has been, to put it before the public for approval or rejection. In practical application he must successfully run the legislative gauntlet during the first hurried ninety days he is in office if he is to adopt a program and have an administration worthy of history's harsh pen. The remaining general assembly two years hence is invariably plagued with vicissitudes common to 'lame duck' tenures.

The idea of removing the gubernatorial term limit was first proposed in the 1850 constitutional convention, but was vigorously opposed by some of the state's best known statesmen of the day, including Archibald Dixon, Garrett Davis, Benjamin Hardin, and Charles A. Wickliffe. Not until 1992 was an amendment to the state constitution passed to help ameliorate the situation by making the governor eligible to succeed himself one time before becoming ineligible for four years. Succession amendments had been proposed and defeated during the administrations of John Y. Brown, Jr. and Wallace Wilkinson, but then-Governor Brereton Jones was able to see it passed because, unlike Brown and Wilkinson, he was willing to exempt the present incumbents, including himself, from the succession provision. Paul E. Patton, with victories in the elections of 1995 and 1999, was the first governor to be elected to consecutive terms since the 1992 amendment. Another constitutional amendment, passed in November 2000, called for a 30-day legislative session to be held in odd-numbered years between the longer 60-day sessions held in even-numbered years.

In the 1792 constitution, the governor and state senators were chosen by electors, in a manner similar to the operation of the United States Electoral College. In the 1795 gubernatorial election, Benjamin Logan received 21 electoral votes, James Garrard received 17, Thomas Todd received 14, and John Brown received 1. The constitution did not specify whether election required a plurality or a majority of the electoral votes cast; in the absence of any instruction, the electors held a runoff vote, wherein most of Todd's electors voted for Garrard, giving him a majority. The secretary of state certified Garrard's election, though Attorney General John Breckinridge questioned the legality of the second vote and Logan formally protested it. Ultimately, Breckinridge determined that he was not empowered by the state constitution to intervene, and Logan gave up the challenge. The 1799 constitution changed the method of selecting the governor to direct election by majority vote and prescribed that, in the event of a tie vote, the governor would be chosen by lot in the Kentucky General Assembly. This provision has remained since 1799.

After the development of the party system, it became commonplace for political parties to choose their nominees for the office of governor via a nominating convention. Thomas Metcalfe was the first gubernatorial candidate chosen by a nominating convention; he was nominated by the National Republican Party at their convention in December 1827. Governor Ruby Laffoon, elected in 1931, was the last governor of Kentucky nominated by a convention. Laffoon's lieutenant governor, Happy Chandler, pushed the legislature to mandate party primaries, which
they did in 1935. Party primaries remain required by law today. In 1992, the state constitution was amended to require candidates for governor and lieutenant governor to be nominated and elected as a ticket.

Kentucky is one of only five U.S. states to hold gubernatorial elections in odd-numbered years—commonly called an off-year election. Louisiana, Mississippi, Virginia, and New Jersey also hold off-year gubernatorial elections. The general election for governor and lieutenant governor is held on the first Tuesday after the first Monday in November. The governor and lieutenant governor are inaugurated on the fifth Tuesday after their election. This was changed from the fourth Tuesday after the election by the 1850 constitution.

Under Kentucky's first constitution (1792), the Speaker of the Kentucky Senate became acting governor upon the death, resignation, or removal of the sitting governor from office, until a new election could be held. The 1799 constitution created the office of lieutenant governor, who acted as Speaker of the Senate, but was not otherwise considered a member of that body. The lieutenant governor was to become governor in the event of the sitting governor's death, resignation, or removal from office and was to act in a gubernatorial capacity any time the governor was out of the state. Whenever the lieutenant governor became the new governor, the Senate was to elect one of its members to act as Speaker; that individual then became next in the line of gubernatorial succession. A provision of the 1850 constitution added that, if the governor's term had more than two years remaining at the time of his death, resignation, or removal from office, a special election would be called to fill the office; the lieutenant governor would become the new governor and serve in the interim.

In the 1891 constitution, the chain of succession was extended. It mandated that, if the Senate was not in session and therefore did not have an elected Speaker, the secretary of state, or in the event of his inability to qualify, the attorney general, would become acting governor in the event of the death, resignation, or removal from office of the sitting governor and lieutenant governor. The secretary of state or attorney general would then be required to call the Senate into session to elect a Speaker, who would subsequently become governor. A 1992 amendment to the state constitution removed the provision under which the lieutenant governor became acting governor when the sitting governor was out of the state. It also relieved the lieutenant governor of his duties in the Senate and created the office of President of the Kentucky Senate, chosen from among the state senators, who presides over the Senate. The amendment also modified the chain of succession again—it is now as follows:

If the office devolves upon the Attorney General or State Auditor, that individual is required to call the Senate into session to elect a president, who would subsequently become governor.

The first instance of gubernatorial succession in Kentucky's history occurred upon the death of Governor George Madison in 1816. Madison was extremely popular as a twice-wounded war hero. He died of tuberculosis just three weeks into his term. His lieutenant governor, Gabriel Slaughter, ascended to the governorship and immediately made two very unpopular appointments. These moves engendered much animosity toward Slaughter, and a movement began in the House of Representatives to hold a new election for governor. Leaders of the movement, including a young John C. Breckinridge, claimed that Slaughter was only the "acting governor" until a new governor was elected. The call for a new election failed in the House in 1815, but was approved by the House in 1817 only to fail in the Senate. Slaughter served out the rest of Madison's term and in so doing, established the precedent that the lieutenant governor would be the permanent successor to the governor upon the latter's death, resignation, or removal from office.

Besides Madison, four other governors have died while in office—John Breathitt, James Clark, John L. Helm, and William Goebel. All died of natural causes except Goebel, who is the only governor of any U.S. state to have been assassinated. Goebel lost the contentious 1899 gubernatorial election to William S. Taylor, but challenged the results. While the General Assembly was considering the challenge, Goebel was shot. Days later, the General Assembly decided in favor of Goebel, ousting Taylor from office and making Goebel governor. Goebel was sworn in on his sick bed and died two days later. His lieutenant governor, J. C. W. Beckham, succeeded him.

Seven men have resigned the office of governor before the end of their terms—John J. Crittenden, Beriah Magoffin, John W. Stevenson, Augustus O. Stanley, Happy Chandler, Earle C. Clements, and Wendell H. Ford. Six resigned to accept a higher office: Crittenden was appointed Attorney General of the United States and the other five were elected to the U.S. Senate. Only Beriah Magoffin resigned under duress. A Confederate sympathizer during the Civil War, Magoffin's power was entirely checked by a hostile, pro-Union legislature. With the state's government in gridlock, Magoffin agreed to resign in exchange for being able to name his successor. Lieutenant Governor Linn Boyd had died in office, and the Speaker of the Senate, John F. Fisk, was not acceptable to Magoffin as a successor. Fisk resigned as Speaker, and the Senate elected Magoffin's choice, James Fisher Robinson as Speaker. Magoffin then resigned, Robinson was elevated to governor, and Fisk was re-elected as Speaker of the Senate.

All elected officials in Kentucky, including the governor, are subject to impeachment for "any misdemeanors in office". The articles of impeachment must be issued by the House of Representatives and the trial is conducted by the Senate. If convicted, the governor is subject to removal from office and may be prohibited from holding elected office in the state thereafter. Impeached governors may also be subject to trial in the criminal or civil court system. No governor of Kentucky has been impeached.

Each iteration of the Kentucky Constitution has provided that the governor receive a salary. Under the first three constitutions, the governor's salary could not be increased or reduced while he was in office; this provision was extended to all public officials in the present constitution. The governor's salary is set by law, and is equal to $60,000 times the increase in the consumer price index between January 1, 1984, and the beginning of the current calendar year. In 2014, the governor's salary was $186,730.

The Kentucky Governor's Mansion is the official residence of the governor of Kentucky. The present Governor's Mansion, constructed in 1914 and listed on the National Register of Historic Places in 1972, is located at 704 Capitol Avenue in the state capital of Frankfort. It is the second building to serve as the official residence of the governor of Kentucky. The Kentucky Revised Statutes provide that "[t]he Governor shall have the use of the mansion and the furniture therein and premises, free of rent, but the purchase of furniture for the mansion shall be upon the recommendation of the secretary of the Finance and Administration Cabinet".

The state's first governor's mansion was constructed during the gubernatorial tenure of James Garrard. According to tradition, future governors Thomas Metcalfe (a stonemason) and Robert P. Letcher (who worked at his father's brickyard) participated in the construction of the first governor's mansion. After the construction of the present governor's mansion, the old governor's mansion became the official residence of the lieutenant governor. Lieutenant governor Steve Henry vacated the mansion in 2002 so it could be renovated; following the renovation, it became a state guest house and official entertainment space for the governor. For many years, the mansion was the oldest official residence still in use in the United States. Located at 420 High Street in Frankfort, it was listed on the National Register of Historic Places in 1971.

Political parties had developed in the United States before Kentucky became a state. Because most early Kentuckians were Virginians, they naturally allied with the Democratic-Republicans, the party of Thomas Jefferson and James Madison; the latter was a cousin of George Madison, the state's sixth governor. Political victories were few and far between for Federalists in Kentucky, and none of Kentucky's governors were members of the Federalist Party. Military service was the most important consideration for voters in Kentucky's early gubernatorial elections. John Breathitt, elected Kentucky's eleventh governor in 1832, was the first Kentucky governor not to have served in the military.

The Federalist Party had died out nationally by 1820, but new party divisions were soon to form in Kentucky. The Panic of 1819 left many Kentuckians deeply in debt and without a means of repaying their creditors. Two factions grew up around the issue of debt relief. Those who favored laws favorable to debtors were dubbed the "Relief Party" and those who favored laws protecting creditors were called the "Anti-Relief Party". While not formal political parties—members of both factions still considered themselves Democratic-Republicans—these factions defined the political dialogue of the 1820s in Kentucky. The debt relief issue began under Gabriel Slaughter, who identified with the Anti-Relief Party, but Slaughter's two immediate successors, John Adair and Joseph Desha, were members of the Relief Party. The struggle between the two parties culminated in the Old Court – New Court controversy, an attempt by the pro-relief legislature to abolish the Court of Appeals because the court overturned some debt relief measures as unconstitutional. The controversy ended with the restoration of the Old Court over Desha's veto in late 1826.

Although many Old Court supporters—typically the state's wealthy aristocracy—gravitated to the National Republican Party (later to be called Whigs) that formed in the 1820s, it is inaccurate to assume the Anti-Relief Party as a whole became National Republicans and the Relief Party became Democrats. The primary factor in determining which party Kentuckians aligned with was their faith in Whig Party founder and native son, Henry Clay. From the election of Thomas Metcalfe in 1828 to the expiration of John L. Helm's term in 1851, only one Democrat held the office of governor: John Breathitt, who died a year and a half into his term and was succeeded in office by his lieutenant governor, James Turner Morehead, a National Republican.

Following the collapse of the Whig Party in the early 1850s, many former Whigs joined the Know Nothing, or American, Party, and Charles S. Morehead was elected governor from that party in 1855. Sectarian tensions gripped the state in the lead-up to the Civil War, and while the majority of Kentuckians favored the preservation of the Union above all else, a self-constituted group of Confederate sympathizers met at Russellville and formed a Confederate government for the state. While this provisional government never displaced the elected government in Frankfort, two men served as Confederate governors of Kentucky.

From the close of the Civil War until 1895, Kentuckians elected a series of Bourbon Democrats with Confederate sympathies as governor, including two men—James B. McCreary and Simon Bolivar Buckner—who had served in the Confederate States Army. The Democratic dominance was broken by William O'Connell Bradley, who was elected the state's first Republican governor in 1895. Bradley's election marked the beginning of thirty years of true, two-party competition for the governorship in the state. Between 1895 and 1931, five Republicans and six Democrats held the office of governor. Since 1931, however, the Republicans have been unable to preserve this level of parity, and in that period only four of the twenty elected governors have been from the Republican party, including incumbent Matt Bevin.




</doc>
<doc id="253828" url="https://en.wikipedia.org/wiki?curid=253828" title="The Mummy (1999 film)">
The Mummy (1999 film)

The Mummy is a 1999 American action horror film written and directed by Stephen Sommers. The film stars Brendan Fraser, Rachel Weisz, John Hannah, and Kevin J. O'Connor, with Arnold Vosloo in the titular role as the reanimated mummy. It is a loose remake of the 1932 film "The Mummy". In this film, adventurer Rick O'Connell travels to Hamunaptra, the city of the dead, with a librarian and her brother. There, they accidentally awaken Imhotep, a cursed high priest from the reign of the pharaoh Seti I.

Filming began in Marrakech, Morocco, on May 4, 1998, and lasted seventeen weeks; the crew had to endure dehydration, sandstorms, and snakes while filming in the Sahara. The visual effects were provided by Industrial Light & Magic, who blended film and computer-generated imagery to create the mummy. Jerry Goldsmith provided the orchestral score.

"The Mummy" opened on May 7, 1999, and grossed $43 million in 3,210 theaters during its opening weekend in the United States. The film went on to gross $416 million worldwide. The box-office success led to two sequels—"The Mummy Returns" and ""—as well as an animated series, and the prequel/spin-off film "The Scorpion King". Universal Pictures also opened a roller coaster, "Revenge of the Mummy", in 2004.

In Thebes, Egypt, 1290 BC, high priest Imhotep has a love affair with Anck-su-Namun, the mistress of Pharaoh Seti I. When the Pharaoh discovers the affair, Imhotep and Anck-su-Namun assassinate him. Imhotep flees, while Anck-su-Namun kills herself, intending for Imhotep to resurrect her. Imhotep and his priests steal her corpse and travel to Hamunaptra, the city of the dead, but the resurrection ritual is stopped by Seti's bodyguards, the Medjai. Imhotep's priests are all mummified alive, while Imhotep himself is sentenced to suffer the Hom Dai, the worst of Egyptian curses; he is buried alive with flesh-eating scarab beetles. Imhotep is sealed away in a sarcophagus at the feet of a statue of the Egyptian god Anubis and kept under strict surveillance by the Medjai to prevent Imhotep's return.

In 1926, Jonathan Carnahan presents his sister, Evelyn, a librarian and aspiring Egyptologist, with an intricate box and map that lead to Hamunaptra. Jonathan reveals he stole the box from an American adventurer, Rick O'Connell, who discovered the city three years earlier while in the French Foreign Legion. Rick makes a deal with Evelyn to lead them there if they release him from prison.

Rick leads Evelyn and her party to the city, where the group encounters a band of American treasure hunters guided by Rick's cowardly colleague Beni Gabor. The expeditions are attacked by the Medjai, led by the warrior Ardeth Bay. Against Ardeth's advice to leave the city, the two expeditions continue to excavate. Evelyn searches for the famous Book of the Living, a book made of pure gold. Instead of finding the book, she, Rick, and Jonathan stumble upon the statue of Anubis and the remains of Imhotep buried underneath. The team of Americans, meanwhile, discover the black Book of the Dead, accompanied by canopic jars carrying Anck-su-Namun's preserved organs.

At night, Evelyn takes the Book of the Dead and reads a page aloud, accidentally awakening Imhotep. The expeditions return to Cairo, but Imhotep follows them with the help of Beni. Imhotep returns to full strength by killing the members of the American expedition, and brings the ten plagues back to Egypt. Seeking a way to stop Imhotep, Rick, Evelyn and Jonathan meet Ardeth at a museum. Ardeth hypothesizes that Imhotep wants to resurrect Anck-su-Namun again and plans to do so by sacrificing Evelyn. Evelyn believes that if the Book of the Dead brought Imhotep back to life, the Book of the Living can kill him again, and deduces the book's whereabouts. Imhotep corners the group with an army of slaves. Evelyn agrees to accompany Imhotep if he spares the rest of the group.

Imhotep, Evelyn, and Beni return to Hamunaptra, pursued by Rick, Jonathan, and Ardeth. Imhotep prepares to sacrifice Evelyn, but she is rescued after an intense battle with Imhotep's mummified priests. When Evelyn reads from the Book of Amun-Ra, Imhotep becomes mortal again, and Rick forces him into the River of Death. Imhotep leaves the world of the living, but not before vowing revenge. While looting treasure from the pyramid, Beni accidentally sets off an ancient booby trap and is trapped by a swarm of flesh-eating scarabs as Hamunaptra collapses into the sand. Ardeth rides away as Rick and Evelyn kiss and ride off into the sunset on a pair of camels laden with Beni's treasure.

Brendan Fraser plays Rick O'Connell, an American adventurer who served in the French Foreign Legion. Producer James Jacks offered the role of Rick O'Connell to Tom Cruise (who was later cast in the reboot film), Brad Pitt, Matt Damon and Ben Affleck but the actors were not interested or could not fit the role into their respective schedules. Jacks and director Stephen Sommers were impressed with the money that "George of the Jungle" was making at the box office and cast Brendan Fraser as a result; Sommers also commented that he felt Fraser fit the Errol Flynn swashbuckling character he had envisioned perfectly. The actor understood that his character "doesn't take himself too seriously, otherwise the audience can't go on that journey with him".

Rachel Weisz portrays Evelyn Carnahan, a clumsy but brilliant Egyptologist. Evelyn undertakes the expedition to Hamunaptra to discover an ancient book, proving herself to her peers. The character was named in tribute to Lady Evelyn Carnarvon, the daughter of amateur Egyptologist Lord Carnarvon, both present at the opening of the tomb of Tutankhamen in 1922. Rachel Weisz was not a big fan of horror films but did not see this film as such. As she said in an interview, "It's hokum, a comic book world."

South African stage actor Arnold Vosloo plays Imhotep. Vosloo understood the approach that Sommers was going for in his screenplay, but only agreed to take on the role of Imhotep "if I could do it absolutely straight. From Imhotep's point of view, this is a skewed version of 'Romeo and Juliet'."

Other major roles include John Hannah as Jonathan Carnahan, Evelyn's bumbling older brother; Kevin J. O'Connor as Jonathan's cowardly former compatriot in the French Foreign Legion, Beni Gabor. Oded Fehr plays the Medjai Ardeth Bay, Erick Avari museum curator Dr. Terence Bey, and Patricia Velásquez Imhotep's lover Anck-Su-Namun. Minor roles include Bernard Fox as Captain Winston Havelock, a pilot and friend of Rick's, Omid Djalili as a Egyptian prison warden, and Jonathan Hyde, Stephen Dunham, Corey Johnson, and Tuc Watkins as members of the American expedition to Hamunaptra.

In 1992, producers James Jacks and Sean Daniel decided to update the original 1932 "Mummy" film for the 1990s. Universal Studios gave them the go-ahead, but only if they kept the budget around $10 million. Jacks remembers that the studio "essentially wanted a low-budget horror franchise"; in response, Jacks and Daniel recruited horror filmmaker/writer Clive Barker on board to direct. Barker's vision for the film was violent, with the story revolving around the head of a contemporary art museum who turns out to be a cultist trying to reanimate mummies. Jacks recalls that Barker's take was "dark, sexual and filled with mysticism", and that, "it would have been a great low-budget movie". After several meetings, Barker and Universal lost interest and parted company.

Director Joe Dante was the next choice, increasing the budget for his idea of Daniel Day-Lewis as a brooding Mummy. This version's draft was written by Alan Ormsby, and was later re-written by John Sayles. It was set in contemporary times and focused on reincarnation with elements of a love story. It came close to being made with some elements, like the flesh-eating scarabs, making it to the final product. However, at that point, the studio wanted a film with a budget of $15 million and rejected Dante's version.

Filmmaker George A. Romero was brought in with a vision of a zombie-style horror film similar to "Night of the Living Dead", but which also relied heavily upon elements of tragic romance and ambivalence of identity. Romero completed a draft in October 1994, co-written with Ormsby and Sayles, that revolved around female archaeologist Helen Grover and her discovery in Abydos of the tomb of Imhotep, an Egyptian general who lived in the time of Ramesses II. Unfolding in a nameless American city in modern times, events are set into motion when Imhotep inadvertently awakens as a result of his preserved cadaver having been exposed to rays from an MRI scan in a high-tech forensic archaeology lab. The script progresses to a fish-out-of-water story when Imhotep, having regained his youthful appearance, recognizes the need to adapt to a contemporary society that is three thousand years removed from the one he came from. Assuming at first that he is a representative from the Bureau of Antiquities, Helen finds herself drawn into a tentative relationship with Imhotep while also experiencing clairvoyant flashbacks to a previous life in Nineteenth Dynasty Egypt as a priestess of Isis. Summoning mystical powers through incantation, Imhotep later resurrects the mummy of Karis, a loyal slave whose body had been resting alongside his master's in the same tomb but is now held in the local museum. After escaping into the city sewer system, Karis embarks on a vengeful rampage against the various criminal fences and high society antiquarians who had acquired stolen relics from his tomb. Romero's script was considered too dark and violent by Jacks and the studio, who wanted a more accessible picture. Compounding the issue was the fact that Romero was unable to extricate from a contract for a different film project he had in negotiation at the time with MGM, and so his involvement with the film was severed and the development of an entirely new script was commissioned to other writers.

Mick Garris was attached to direct but eventually left the project, and Wes Craven was offered the film but turned it down. Stephen Sommers called Jacks and Daniel in 1997 with his vision of "The Mummy" "as a kind of Indiana Jones or "Jason and the Argonauts" with the mummy as the creature giving the hero a hard time". Sommers had seen the original film when he was eight, and wanted to recreate the things he liked about it on a bigger scale. He had wanted to make a "Mummy" film since 1993, but other writers or directors were always attached. Finally, Sommers received his window of opportunity and pitched his idea to Universal with an 18-page treatment. At the time, Universal's management had changed in response to the box office failure of "", and the loss led the studio to want to revisit its successful franchises from the 1930s. Universal liked this idea so much that they approved the concept and increased the budget from $15 million to $80 million.

Filming began in Marrakech, Morocco on May 4, 1998 and lasted 17 weeks. Photography moved to the Sahara desert outside the small town of Erfoud, and to the United Kingdom before completion of shooting on August 29, 1998. The crew could not shoot in Egypt because of the unstable political conditions. To avoid dehydration in the scorching heat of the Sahara, the production's medical team created a drink that the cast and crew had to consume every two hours. Sandstorms were daily inconveniences. Snakes, spiders and scorpions were a major problem, with many crew members having to be airlifted out after being bitten.

Brendan Fraser nearly died during a scene where his character is hanged. Weisz remembered, "He [Fraser] stopped breathing and had to be resuscitated." The production had the official support of the Moroccan army, and the cast members had kidnapping insurance taken out on them, a fact Sommers disclosed to the cast only after shooting had finished.

Production designer Allan Cameron found a dormant volcano near Erfoud where the entire set for Hamunaptra could be constructed. Sommers liked the location because, "A city hidden in the crater of an extinct volcano made perfect sense. Out in the middle of the desert you would never see it. You would never think of entering the crater unless you knew what was inside that volcano." A survey of the volcano was conducted so that an accurate model and scale models of the columns and statues could be replicated back at Shepperton Studios, where all of the scenes involving the underground passageways of the City of the Dead were shot. These sets took 16 weeks to build, and included fiberglass columns rigged with special effects for the movie's final scenes. Another large set was constructed in the United Kingdom on the dockyard at Chatham which doubled for the Giza Port on the River Nile. This set was in length and featured "a steam train, an Ajax traction engine, three cranes, an open two-horse carriage, four horse-drawn carts, five dressing horses and grooms, nine pack donkeys and mules, as well as market stalls, Arab-clad vendors and room for 300 costumed extras".

The filmmakers reportedly spent $15 million of the $80 million budget on special effects, provided by Industrial Light & Magic; the producers wanted a new look for the Mummy so that they would avoid comparisons to past movies. John Andrew Berton, Jr., Industrial Light & Magic's Visual Effects Supervisor on "The Mummy", started developing the look three months before filming started. He said that he wanted the Mummy "to be mean, tough, nasty, something that had never been seen by audiences before". Berton used motion capture in order to achieve "a menacing and very realistic Mummy". Specific photography was conducted on actor Arnold Vosloo so that the special effects crew could see exactly how he moved and replicate it.

To create the Mummy, Berton used a combination of live action and computer graphics. He matched the digital prosthetic make-up pieces on Vosloo's face during filming. Berton said, "When you see his film image, that's him. When he turns his head and half of his face is missing and you can see right through on to his teeth, that's really his face. And that's why it was so hard to do." Vosloo described the filming as a "whole new thing" for him; "They had to put these little red tracking lights all over my face so they could map in the special effects. A lot of the time I was walking around the set looking like a Christmas tree." Make-Up Effects Supervisor Nick Dudman produced the physical creature effects in the film, including three-dimensional make-up and prosthetics. He also designed all of the animatronic effects. While the film made extensive use of computer generated imagery, many scenes, including ones where Rachel Weisz's character is covered with rats and locusts, were real, using live animals.

The Mummy: Original Motion Picture Soundtrack was composed and conducted by Jerry Goldsmith, with orchestrations provided by Alexander Courage. The soundtrack was released by Decca Records on May 4, 1999. Like many Goldsmith scores, the main theme uses extensive brass and percussion elements; Goldsmith also used sparing amounts of vocals, highly unusual for most of his work.

Overall, Goldsmith's score was well received. AllMusic described it as a "grand, melodramatic score" which delivered the expected highlights. Other reviews positively noted the dark, percussive sound meshed well with the plot, as well as the raw power of the music. The limited but masterful use of the chorus was also lauded, and most critics found the final track on the CD to be the best overall. On the other hand, some critics found the score lacked cohesion, and that the constant heavy action lent itself to annoying repetition. Roderick Scott off CineMusic.net summed up the score as "representative of both Goldsmith's absolute best and his most mediocre. Thankfully [...] his favourable work on this release wins out."

"The Mummy" opened on May 7, 1999, and grossed $43 million in 3,210 theaters in the United States on its opening weekend. The film went on to gross $415 million worldwide (domestic: $155 million; foreign: $260 million).

"The Mummy" received mixed reviews from critics. On Rotten Tomatoes the film holds a 58% rating, based on 89 reviews, with an average rating of 5.8/10. The website's critical consensus reads, "It's difficult to make a persuasive argument for "The Mummy" as any kind of meaningful cinematic achievement, but it's undeniably fun to watch." On Metacritic the film has a score of 48 out of 100, based on 34 critics, indicating "mixed or average reviews". Audiences polled by CinemaScore gave the film an average grade of "B" on an A+ to F scale.

Roger Ebert, of the "Chicago Sun-Times", gave the film 3 out of 4 stars, writing "There is hardly a thing I can say in its favor, except that I was cheered by nearly every minute of it. I cannot argue for the script, the direction, the acting or even the mummy, but I can say that I was not bored and sometimes I was unreasonably pleased." Likewise, Owen Gleiberman of "Entertainment Weekly" gave the film a "B−" grade and said, ""The Mummy" would like to make you shudder, but it tries to do so without ever letting go of its jocular inconsequentiality." Bob Graham of the "San Francisco Chronicle" gave the film high marks for the acting as well as the special effects.

Stephen Holden from "The New York Times" wrote, "This version of "The Mummy" has no pretenses to be anything other than a gaudy comic video game splashed onto the screen. Think "Raiders of the Lost Ark" with cartoon characters, no coherent story line and lavish but cheesy special effects. Think "Night of the Living Dead" stripped of genuine horror and restaged as an Egyptian-theme Halloween pageant. Think "Abbott and Costello Meet the Mummy" grafted onto a Bing Crosby-Bob Hope road picture ("The Road to Hamunaptra"?) and pumped up into an epic-size genre spoof." Publications like "The Austin Chronicle" and "Dallas Observer" came to the conclusion that despite good acting and special effects, the movie lacked cohesion; talking about the special effects, the "Observer" lamented "If only generating a soul for the film itself were so easy." Other publications such as "Jump Cut" felt that Industrial Light and Magic's lock on special effects proved detrimental to "The Mummy"; "The mummy", Ernest Larson wrote for the "Jump Cut", "is standard-issue I.L.&M.". Kim Newman of the British Film Institute judged the picture inferior to the original, as all the time was spent on special effects, instead of creating the atmosphere which made the original film such a classic. "USA Today" gave the film two out of four stars and felt that it was "not free of stereotypes", a sentiment with which the BFI concurred. "If someone complains of a foul odor, you can be sure an Arab stooge is about to enter a scene. Fraser, equally quick with weapon, fist or quip, may save the day, but even he can't save the picture", "USA Today" wrote.

"The Mummy"s box office performance led to numerous sequels and spinoffs. In 2001, the sequel "The Mummy Returns" was released; the film features most of the surviving principal characters, as a married couple, Rick and Evelyn confront Imhotep and the Scorpion King. The film also introduces the heroes' son, Alex. The two films inspired both an animated series which lasted two seasons, and a spin-off prequel, "The Scorpion King" (2002), telling the story of the Akkadian warrior as he was crowned king. It also includes three sequels and one prequel.

A second sequel, called "", was released on August 1, 2008. The story takes place in China with the "Terracotta Emperor" inspiring the villain, while Rachel Weisz was replaced with Maria Bello.

The film also inspired a roller coaster, "Revenge of the Mummy" in three Universal Studios Theme Parks: Hollywood, California; Orlando, Florida; and Sentosa, Singapore.

Two video game adaptations of "The Mummy" were published by Konami under license from Universal Interactive Studios in 2000: an Action Adventure for the PlayStation and PC developed by Rebellion Developments, as well as a Game Boy Color puzzle game developed by Konami Nagoya.

On April 4, 2012, Universal announced their plans to reboot the franchise. The film is intended to be the first installment in the Dark Universe, titled "The Mummy", and was released in June 2017.


 


</doc>
<doc id="254507" url="https://en.wikipedia.org/wiki?curid=254507" title="Percy Grainger">
Percy Grainger

George Percy Aldridge Grainger (8 July 188220 February 1961) was an Australian-born composer, arranger and pianist who lived in the United States from 1914 on and became a citizen in 1918. In the course of a long and innovative career, he played a prominent role in the revival of interest in British folk music in the early years of the 20th century. Although much of his work was experimental and unusual, the piece with which he is most generally associated is his piano arrangement of the folk-dance tune "Country Gardens".

Grainger left Australia at the age of 13 to attend the Hoch Conservatory in Frankfurt. Between 1901 and 1914 he was based in London, where he established himself first as a society pianist and later as a concert performer, composer and collector of original folk melodies. As his reputation grew he met many of the significant figures in European music, forming important friendships with Frederick Delius and Edvard Grieg. He became a champion of Nordic music and culture, his enthusiasm for which he often expressed in private letters, sometimes in crudely racial or anti-Semitic terms.

In 1914, Grainger moved to the United States, where he lived for the rest of his life, though he travelled widely in Europe and in Australia. He served briefly as a bandsman in the United States Army during the First World War through 1917–18, and took American citizenship in 1918. After his mother's suicide in 1922, he became increasingly involved in educational work. He also experimented with music machines, which he hoped would supersede human interpretation. In the 1930s he set up the Grainger Museum in Melbourne, his birthplace, as a monument to his life and works, and as a future research archive. As he grew older, he continued to give concerts and to revise and rearrange his own compositions, while writing little new music. After the Second World War, ill health reduced his levels of activity. He considered his career a failure. He gave his last concert in 1960, less than a year before his death.

Percy Grainger was born on 8 July 1882 in Brighton, a suburb of Melbourne, Australia. His father John Grainger, was an English-born architect who had emigrated to Australia in 1877. He won professional recognition for his design of the Princes Bridge across the Yarra River in Melbourne. His mother was Rose Annie Aldridge, daughter of Adelaide hotelier George Aldridge and his wife.

John Grainger was an accomplished artist, with broad cultural interests and a wide circle of friends. These included David Mitchell, whose daughter Helen later gained worldwide fame as an operatic soprano under the name Nellie Melba. John's claims to have "discovered" her are unfounded, although he may have offered her encouragement. John was a heavy drinker and a womaniser who, Rose learned after the marriage, had fathered a child in England before coming to Australia. His promiscuity placed deep strains upon the relationship. Rose discovered shortly after Percy's birth that she had contracted a form of syphilis, a sexually transmitted disease, from her husband. Despite this, the Graingers stayed together until 1890, when John went to England for medical treatment. After his return to Australia, they lived apart. Rose took over the work of raising Percy, while John pursued his career as chief architect to the Western Australian Department of Public Works. He had some private work, designing Nellie Melba's home, Coombe Cottage, at Coldstream.

Except for three months' formal schooling as a 12-year-old, during which he was bullied and ridiculed by his classmates, Percy was educated at home. Rose, an autodidact with a dominating presence, supervised his music and literature studies and engaged other tutors for languages, art and drama. From his earliest lessons, Percy developed a lifelong fascination with Nordic culture; writing late in life, he said that the Icelandic "Saga of Grettir the Strong" was "the strongest single artistic influence on my life". As well as showing precocious musical talents, he displayed considerable early gifts as an artist, to the extent that his tutors thought his future might lie in art rather than music. At the age of 10 he began studying piano under Louis Pabst, a German immigrant then considered to be Melbourne's leading piano teacher. Grainger's first known composition, "A Birthday Gift to Mother", is dated 1893. Pabst arranged Grainger's first public concert appearances, at Melbourne's Masonic Hall in July and September 1894. The boy played works by Bach, Beethoven, Schumann and Scarlatti, and was warmly complimented in the Melbourne press.

After Pabst returned to Europe in the autumn of 1894, Grainger's new piano tutor, Adelaide Burkitt, arranged for his appearances at a series of concerts in October 1894, at Melbourne's Royal Exhibition Building. The size of this enormous venue horrified the young pianist; nevertheless, his performance delighted the Melbourne critics, who dubbed him "the flaxen-haired phenomenon who plays like a master". This public acclaim helped Rose to decide that her son should continue his studies at the Hoch Conservatory in Frankfurt, Germany, an institution recommended by William Laver, head of piano studies at Melbourne's Conservatorium of music. Financial assistance was secured through a fund-raising benefit concert in Melbourne and a final recital in Adelaide, after which mother and son left Australia for Europe on 29 May 1895. Although Grainger never returned permanently to Australia, he maintained considerable patriotic feelings for his native land, and was proud of his Australian heritage.

In Frankfurt, Rose established herself as a teacher of English; her earnings were supplemented by contributions from John Grainger, who had settled in Perth. The Hoch Conservatory's reputation for piano teaching had been enhanced by the tenure, until 1892, of Clara Schumann as head of piano studies. Grainger's piano tutor was James Kwast, who developed his young pupil's skills to the extent that, within a year, Grainger was being lauded as a prodigy. Grainger had difficult relations with his original composition teacher, Iwan Knorr; he withdrew from Knorr's classes to study composition privately with Karl Klimsch, an amateur composer and folk-music enthusiast, whom he would later honour as "my only composition teacher".

Together with a group of slightly older British students – Roger Quilter, Balfour Gardiner, Cyril Scott and Norman O'Neill, all of whom became his friends – Grainger helped form the Frankfurt Group. Their long-term objective was to rescue British and Scandinavian music from what they considered the negative influences of central European music. Encouraged by Klimsch, Grainger turned away from composing classical pastiches reminiscent of Handel, Haydn and Mozart, and developed a personal compositional style, the originality and maturity of which quickly impressed and astonished his friends. At this time Grainger discovered the poetry of Rudyard Kipling and began setting it to music; according to Scott, "No poet and composer have been so suitably wedded since Heine and Schumann."

After accompanying her son on an extended European tour in the summer of 1900, Rose, whose health had been poor for some time, suffered a nervous collapse and could no longer work. To replace lost income, Grainger began giving piano lessons and public performances; his first solo recital was in Frankfurt on 6 December 1900. Meanwhile he continued his studies with Kwast, and increased his repertoire until he was confident he could support himself and his mother as a concert pianist. Having chosen London as his future base, in May 1901 Grainger abandoned his studies. With Rose, he left Frankfurt for the UK.

Before leaving Frankfurt, Grainger had fallen in love with Kwast's daughter Mimi. In an autobiographical essay dated 1947, he says that he was "already sex-crazy" at this time, when he was 19. John Bird, Grainger's biographer, records that during his Frankfurt years, Grainger began to develop sexual appetites that were "distinctly abnormal"; by the age of 16 he had started to experiment in flagellation and other sado-masochistic practices, which he continued to pursue through most of his adult life. Bird surmises that Grainger's fascination with themes of punishment and pain derived from the harsh discipline to which Rose had subjected him as a child.

In London, Grainger's charm, good looks and talent (with some assistance from the local Australian community) ensured that he was quickly taken up as a pianist by wealthy patrons. He was soon performing in concerts in private homes. "The Times" critic reported after one such appearance that Grainger's playing "revealed rare intelligence and a good deal of artistic insight". In 1902 he was presented by the socialite Lillith Lowrey to Queen Alexandra, who thereafter frequently attended his London recitals. Lowrey, 20 years Grainger's senior, traded patronage and contacts for sexual favours – he termed the relationship a "love-serve job". She was the first woman with whom he had sex; he later wrote of this initial encounter that he had experienced "an overpowering landslide" of feeling, and that "I thought I was about to die. If I remember correctly, I only experienced fear of death. I don't think that any joy entered into it".

In February 1902 Grainger made his first appearance as a piano soloist with an orchestra, playing Tchaikovsky's first piano concerto with the Bath Pump Room Orchestra. In October of that year he toured Britain in a concert party with Adelina Patti, the Italian-born opera singer. Patti was greatly taken by the young pianist and prophesied a glorious career for him. The following year he met the German-Italian composer and pianist Ferruccio Busoni. Initially the two men were on cordial terms (Busoni offered to give Grainger lessons free of charge) and, as a result, Grainger spent part of the 1903 summer in Berlin as Busoni's pupil. However, the visit was not a success; as Bird notes, Busoni had expected "a willing slave and adoring disciple", a role Grainger was not willing to fulfill. Grainger returned to London in July 1903; almost immediately he departed with Rose on a 10-month tour of Australia, New Zealand and South Africa, as a member of a party organised by the Australian contralto Ada Crossley.

Before going to London Grainger had composed numerous Kipling settings, and his first mature orchestral pieces. In London, when he found time he continued to compose; a letter to Balfour Gardiner dated 21 July 1901 indicates that he was working on his "Marching Song of Democracy" (a Walt Whitman setting), and had made good progress with the experimental works "Train Music" and "Charging Irishrey". In his early London years he also composed "Hill Song Number 1" (1902), an instrumental piece much admired by Busoni.

In 1905, inspired by a lecture given by the pioneer folk-song historian Lucy Broadwood, Grainger began to collect original folk songs. Starting at Brigg in Lincolnshire, over the next five years he gathered and transcribed more than 300 songs from all over the country, including much material that had never been written down before. From 1906 Grainger used a phonograph, one of the first collectors to do so, and by this means he assembled more than 200 Edison cylinder recordings of native folk singers. These activities coincided with what Bird calls "the halcyon days of the 'First English Folksong Revival'".

As his stature in the music world increased, Grainger became acquainted with many of its leading figures, including Vaughan Williams, Elgar, Richard Strauss and Debussy. In 1907 he met Frederick Delius, with whom he achieved an immediate rapport – the two musicians had similar ideas about composition and harmony, and shared a dislike for the classical German masters. Both were inspired by folk music; Grainger gave Delius his setting of the folk song "Brigg Fair", which the older composer developed into his well-known orchestral rhapsody, dedicated to Grainger. The two remained close friends until Delius's death in 1934.

Grainger first met Grieg at the home of the London financier Sir Edgar Speyer, in May 1906. As a student Grainger had learned to appreciate the Norwegian's harmonic originality, and by 1906 had several Grieg pieces in his concert repertoire, including the piano concerto. Grieg was greatly impressed with Grainger's playing, and wrote: "I have written Norwegian Peasant Dances that no one in my country can play, and here comes this Australian who plays them as they ought to be played! He is a genius that we Scandinavians cannot do other than love." During 1906–07 the two maintained a mutually complimentary correspondence, which culminated in Grainger's ten-day visit in July 1907 to the composer's Norwegian home, "Troldhaugen" near Bergen. Here the two spent much time revising and rehearsing the piano concerto in preparation for that year's Leeds Festival. Plans for a long-term working relationship were ended by Grieg's sudden death in September 1907; nevertheless, this relatively brief acquaintance had a considerable impact on Grainger, and he championed Grieg's music for the rest of his life.

After fulfilling a hectic schedule of concert engagements in Britain and continental Europe, in August 1908 Grainger accompanied Ada Crossley on a second Australasian tour, during which he added several cylinders of Maori and Polynesian music to his collection of recordings. He had resolved to establish himself as a top-ranking pianist before promoting himself as a composer, though he continued to compose both original works and folk-song settings. Some of his most successful and most characteristic pieces, such as "Mock Morris", "Handel in the Strand", "Shepherd's Hey" and "Molly on the Shore" date from this period. In 1908 he obtained the tune of "Country Gardens" from the folk music specialist Cecil Sharp, though he did not fashion it into a performable piece for another ten years.

In 1911 Grainger finally felt confident enough of his standing as a pianist to begin large-scale publishing of his compositions. At the same time, he adopted the professional name of "Percy Aldridge Grainger" for his published compositions and concert appearances. In a series of concerts arranged by Balfour Gardiner at London's Queen's Hall in March 1912, five of Grainger's works were performed to great public acclaim; the band of thirty guitars and mandolins for the performance of "Fathers and Daughters" created a particular impression. On 21 May 1912 Grainger presented the first concert devoted entirely to his own compositions, at the Aeolian Hall, London; the concert was, he reported, "a sensational success". A similarly enthusiastic reception was given to Grainger's music at a second series of Gardiner concerts the following year.

In 1905 Grainger began a close friendship with Karen Holten, a Danish music student who had been recommended to him as a piano pupil. She became an important confidante; the relationship persisted for eight years, largely through correspondence. After her marriage in 1916 she and Grainger continued to correspond and occasionally met until her death in 1953. Grainger was briefly engaged in 1913 to another pupil, Margot Harrison, but the relationship foundered through a mixture of Rose's over-possessiveness and Grainger's indecision.

In April 1914 Grainger gave his first performance of Delius's piano concerto, at a music festival in Torquay. Thomas Beecham, who was one of the festival's guest conductors, reported to Delius that "Percy was good in the "forte" passages, but made far too much noise in the quieter bits". Grainger was receiving increasing recognition as a composer; leading musicians and orchestras were adding his works to their repertoires. His decision to leave England for America in early September 1914, after the outbreak of the First World War, damaged his reputation among his patriotically minded British friends. Grainger wrote that the reason for this abrupt departure was "to give mother a change" – she had been unwell for years. However, according to Bird, Grainger often explained that his reason for leaving London was that "he wanted to emerge as Australia's first composer of worth, and to have laid himself open to the possibility of being killed would have rendered his goal unattainable". "The Daily Telegraph" music critic Robin Legge accused him of cowardice, and told him not to expect a welcome in England after the war, words that hurt Grainger deeply.

Grainger's first American tour began on 11 February 1915 with a recital at New York's Aeolian Hall. He played works by Bach, Brahms, Handel and Chopin alongside two of his own compositions: "Colonial Song" and "Mock Morris". In July 1915 Grainger formally registered his intention to apply for US citizenship. Over the next two years his engagements included concerts with Nellie Melba in Boston and Pittsburgh and a command performance before President Woodrow Wilson. In addition to his concert performances, Grainger secured a contract with Duo-Art for making pianola rolls, and signed a recording contract with Columbia Records.

In April 1917 Grainger received news of his father's death in Perth. On 9 June 1917, after America's entry into the war, he enlisted as a bandsman in the U.S. Army with the 15th Coastal Artillery Corps Band in New York City. He had joined as a saxophonist, though he records learning the oboe: "I long for the time when I can blow my oboe well enough to play in the band". In his 18 months' service, Grainger made frequent appearances as a pianist at Red Cross and Liberty bond concerts. As a regular encore he began to play a piano setting of the tune "Country Gardens". The piece became instantly popular; sheet music sales quickly broke many publishing records. The work was to become synonymous with Grainger's name through the rest of his life, though he came in time to detest it. On 3 June 1918 he became a naturalised American citizen.

After leaving the army in January 1919, Grainger refused an offer to become conductor of the Saint Louis Symphony Orchestra and resumed his career as a concert pianist. He was soon performing around 120 concerts a year, generally to great critical acclaim, and in April 1921 reached a wider audience by performing in a cinema, New York's Capitol Theatre. Grainger commented that the huge audiences at these cinema concerts often showed greater appreciation for his playing than those at established concert venues such as Carnegie Hall and the Aeolian. In the summer of 1919 he led a course in piano technique at Chicago Musical College, the first of many such educational duties he would undertake in later years.

Amid his concert and teaching duties, Grainger found time to re-score many of his works (a habit he continued throughout his life) and also to compose new pieces: his "Children's March: Over the Hills and Far Away", and the orchestral version of "The Power of Rome and the Christian Heart" both originated in this period. He also began to develop the technique of elastic scoring, a form of flexible orchestration which enabled works to be performed by different numbers of players and instrument types, from small chamber groups up to full orchestral strength.

In April 1921 Grainger moved with his mother to a large house in White Plains, New York. This was his home for the remainder of his life. From the beginning of 1922 Rose's health deteriorated sharply; she was suffering from delusions and nightmares, and became fearful that her illness would harm her son's career. Because of the closeness of the bond between the two, there had long been rumours that their relationship was incestuous; in April 1922 Rose was directly challenged over this issue by her friend Lotta Hough. From her last letter to Grainger, dated 29 April, it seems that this confrontation unbalanced Rose; on 30 April, while Grainger was touring on the West Coast, she jumped to her death from an office window on the 18th floor of the Aeolian Building in New York City. The letter, which began "I am out of my mind and cannot think properly", asked Grainger if he had ever spoken to Lotta of "improper love". She signed the letter: "Your poor insane mother".

After Rose's funeral, Grainger sought solace in a return to work. In autumn 1922 he left for a year-long trip to Europe, where he collected and recorded Danish folk songs before a concert tour that took him to Norway, the Netherlands, Germany and England. In Norway he stayed with Delius at the latter's summer home. Delius was by now almost blind; Grainger helped fulfil his friend's wish to see a Norwegian sunset by carrying him (with some assistance) to the top of a nearby mountain peak. He returned to White Plains in August 1923.

Although now less committed to a year-round schedule of concerts, Grainger remained a very popular performer. His eccentricities, often exaggerated for publicity reasons, reportedly included running into auditoriums in gym kit and leaping over the piano to create a grand entrance. While he continued to revise and re-score his compositions, he increasingly worked on arrangements of music by other composers, in particular works by Bach, Brahms, Fauré and Delius. Away from music, Grainger's preoccupation with Nordic culture led him to develop a form of English which, he maintained, reflected the character of the language before the Norman conquest. Words of Norman or Latin origin were replaced by supposedly Nordic word-forms, such as "blend-band" (orchestra), "forthspeaker" (lecturer) and "writ-piece" (article). He called this "blue-eyed" English. His convictions of Nordic superiority eventually led Grainger, in letters to friends, to express his views in crudely racial and anti-Semitic terms; the music historian David Pear describes Grainger as, "at root, a racial bigot of no small order".

Grainger made further trips to Europe in 1925 and 1927, collecting more Danish folk music with the aid of the octogenarian ethnologist Evald Tang Kristensen; this work formed the basis of the "Suite on Danish Folksongs" of 1928–30. He also visited Australia and New Zealand, in 1924 and again in 1926. In November 1926, while returning to America, he met Ella Ström, a Swedish-born artist with whom he developed a close friendship. On arrival in America the pair separated, but were reunited in England the following autumn after Grainger's final folk-song expedition to Denmark. In October 1927 the couple agreed to marry. Ella had a daughter, Elsie, who had been born out of wedlock in 1909. Grainger always acknowledged her as a family member, and developed a warm personal relationship with her.

Although Bird asserts that before her marriage, Ella knew nothing of Grainger's sado-masochistic interests, in a letter dated 23 April 1928 (four months before the wedding) Grainger writes to her: "As far as my taste goes, blows [with the whip] are most thrilling on breasts, bottom, inner thighs, sexparts". He later adds, "I shall thoroly thoroly understand if you cannot in any way see yr way to follow up this hot wish of mine". The couple were married on 9 August 1928 at the Hollywood Bowl, at the end of a concert which, in honour of the bride, had included the first performance of Grainger's bridal song "To a Nordic Princess".

From the late 1920s and early 1930s Grainger became involved increasingly with educational work in schools and colleges, and in late 1931 accepted a year's appointment for 1932–33 as professor of music at New York University (NYU). In this role he delivered a series of lectures under the heading "A General Study of the Manifold Nature of Music", which introduced his students to a wide range of ancient and modern works. On 25 October 1932 his lecture was illustrated by Duke Ellington and his band, who appeared in person; Grainger admired Ellington's music, seeing harmonic similarities with Delius. On the whole, however, Grainger did not enjoy his tenure at NYU; he disliked the institutional formality, and found the university generally unreceptive to his ideas. Despite many offers he never accepted another formal academic appointment, and refused all offers of honorary degrees. His New York lectures became the basis for a series of radio talks which he gave for the Australian Broadcasting Commission in 1934–35; these were later summarised and published as "Music: A Commonsense View of All Types". In 1937 Grainger began an association with the Interlochen National Music Camp, and taught regularly at its summer schools until 1944.

The idea of establishing a Grainger Museum in Australia had first occurred to Grainger in 1932. He began collecting and recovering from friends letters and artifacts, even those demonstrating the most private aspects of his life, such as whips, bloodstained shirts and revealing photographs. In September 1933 he and Ella went to Australia to begin supervising the building work. To finance the project, Grainger embarked on a series of concerts and broadcasts, in which he subjected his audiences to a vast range of the world's music in accordance with his "universalist" view. Controversially, he argued for the superior achievements of Nordic composers over traditionally recognised masters such as Mozart and Beethoven.

Among various new ideas, Grainger introduced his so-called "free-music" theories. He believed that conformity with the traditional rules of set scales, rhythms and harmonic procedures amounted to "absurd goose-stepping", from which music should be set free. He demonstrated two experimental compositions of free music, performed initially by a string quartet and later by the use of electronic theremins. He believed that ideally, free music required non-human performance, and spent much of his later life developing machines to realize this vision.

While the building of the museum proceeded, the Graingers visited England for several months in 1936, during which Grainger made his first BBC broadcast. In this, he conducted "Love Verses from "The Song of Solomon"" in which the tenor soloist was the then unknown Peter Pears. After spending 1937 in America, Grainger returned to Melbourne in 1938 for the official opening of the Museum; among those present at the ceremony was his old piano teacher Adelaide Burkitt. The museum did not open to the general public during Grainger's lifetime, but was available to scholars for research.

In the late 1930s Grainger spent much time arranging his works in settings for wind bands. He wrote "A Lincolnshire Posy" for the March 1937 convention of the American Band Masters' Association in Milwaukee, and in 1939, on his last visit to England before the Second World War, he composed "The Duke of Marlborough's Fanfare", giving it the subtitle "British War Mood Grows".

The outbreak of war in Europe in September 1939 curtailed Grainger's overseas travelling. In the autumn of 1940, alarmed that the war might precipitate an invasion of the United States eastern seaboard, he and Ella moved to Springfield, Missouri, in the centre of the continent. From 1940 Grainger played regularly in charity concerts, especially after the attack on Pearl Harbor brought the United States into the war in December 1941; the historian Robert Simon calculates that Grainger made a total of 274 charity appearances during the war years, many of them at Army and Air Force camps. In 1942 a collection of his Kipling settings, the "Jungle Book" cycle, was performed in eight cities by the band of the Gustavus Adolphus College from St. Peter, Minnesota.

Exhausted from his wartime concerts routine, Grainger spent much of 1946 on holiday in Europe. He was suffering a sense of career failure; in 1947, when refusing the Chair of Music at Adelaide University, he wrote: "If I were 40 years younger, and not so crushed by defeat in every branch of music I have essayed, I am sure I would have welcomed such a chance". In January 1948 he conducted the premiere of his wind band setting of "The Power of Rome and the Christian Heart", written for the Goldman Band to celebrate the 70th birthday of its founder. Afterward, Grainger denigrated his own music as "commonplace" while praising Darius Milhaud's "Suite Française", with which it had shared the programme.
On 10 August 1948, Grainger appeared at the London Proms, playing the piano part in his "Suite on Danish Folksongs" with the London Symphony Orchestra under Basil Cameron. On 18 September he attended the Last Night of the Proms, standing in the promenade section for Delius's "Brigg Fair". Over the next few years several friends died: Gardiner in 1950, Quilter and Karen Holten in 1953. In October 1953 Grainger was operated on for abdominal cancer; his fight against this disease would last for the rest of his life. He continued to appear at concerts, often performed in church halls and educational establishments rather than major concert venues. 

In 1954, after his last Carnegie Hall appearance, Grainger's long promotion of Grieg's music was recognised when he was awarded the St. Olav Medal by King Haakon of Norway. But he expressed a growing bitterness in his writings and correspondence; in a letter to the Danish composer Herman Sandby, a lifelong friend, he bemoaned the continuing ascendency in music of the "German form", and asserted that "all my compositional life I have been a leader without followers".

After 1950 Grainger virtually ceased to compose. His principal creative activity in the last decade of his life was his work with Burnett Cross, a young physics teacher, on free music machines. The first of these was a relatively simple device controlled by an adapted pianola. Next was the "Estey-reed tone-tool", a form of giant harmonica which, Grainger expectantly informed his stepdaughter Elsie in April 1951, would be ready to play free music "in a few weeks". A third machine, the "Cross-Grainger Kangaroo-pouch", was completed by 1952. Developments in transistor technology encouraged Grainger and Cross to begin work on a fourth, entirely electronic machine, which was incomplete when Grainger died.

In September 1955 Grainger made his final visit to Australia, where he spent nine months organising and arranging exhibits for the Grainger Museum. He refused to consider a "Grainger Festival", as suggested by the Australian Broadcasting Commission, because he felt that his homeland had rejected him and his music. Before leaving Melbourne, he deposited in a bank a parcel that contained an essay and photographs related to his sex life, not to be opened until 10 years after his death.

By 1957 Grainger's physical health had markedly declined, as had his powers of concentration. Nevertheless, he continued to visit Britain regularly; in May of that year he made his only television appearance, in a BBC "Concert Hour" programme when he played "Handel in the Strand" on the piano. Back home, after further surgery he recovered sufficiently to undertake a modest winter concerts season. On his 1958 visit to England he met Benjamin Britten, the two having previously maintained a mutually complimentary correspondence. He agreed to visit Britten's Aldeburgh Festival in 1959, but was prevented by illness. Sensing that death was drawing near, he made a new will, bequeathing his skeleton "for preservation and possible display in the Grainger Museum". This wish was not carried out.

Through the winter of 1959–60 Grainger continued to perform his own music, often covering long distances by bus or train; he would not travel by air. On 29 April 1960 he gave his last public concert, at Dartmouth College in Hanover, New Hampshire, although by now his illness was affecting his concentration. On this occasion his morning recital went well, but his conducting in the afternoon was, in his own words, "a fiasco". Subsequently confined to his home, he continued to revise his music and arrange that of others; in August he informed Elsie that he was working on an adaptation of one of Cyril Scott's early songs. His last letters, written from hospital in December 1960 and January 1961, record attempts to work, despite failing eyesight and hallucinations: "I have been trying to write score for several days. But I have not succeeded yet."

Grainger died in the White Plains hospital on 20 February 1961, at the age of 78. His body was flown to Adelaide where, on 2 March, he was buried in the Aldridge family vault in the West Terrace Cemetery, alongside Rose's ashes. Ella survived him by 18 years; in 1972, aged 83, she married a young archivist, Stewart Manville. She died at White Plains on 17 July 1979.

Grainger's own works fall into two categories: original compositions and folk music arrangements. Besides these, he wrote many settings of other composers' works. Despite his conservatory training he rebelled against the disciplines of the central European tradition, largely rejecting conventional forms such as symphony, sonata, concerto and opera. With few exceptions his original compositions are miniatures, lasting between two and eight minutes. Only a few of his works originated as piano pieces, though in due course almost all of them were, in his phrase, "dished up" in piano versions.

The conductor John Eliot Gardiner describes Grainger as "a true original in terms of orchestration and imaginative instrumentation", whose terseness of expression is reminiscent in style both of the 20th-century Second Viennese School and the Italian madrigalists of the 16th and 17th centuries. Malcolm Gillies, a Grainger scholar, writes of Grainger's style that "you know it is 'Grainger' when you have heard about one second of a piece". The music's most individual characteristic, Gillies argues, is its texture – "the weft of the fabric", according to Grainger. Different textures are defined by Grainger as "smooth", "grained" and "prickly".

Grainger was a musical democrat; he believed that in a performance each player's role should be of equal importance. His elastic scoring technique was developed to enable groups of all sizes and combinations of instruments to give effective performances of his music. Experimentation is evident in Grainger's earliest works; irregular rhythms based on rapid changes of time signature were employed in "Love Verses from "The Song of Solomon"" (1899), and "Train Music" (1901), long before Stravinsky adopted this practice. In search of specific sounds Grainger employed unconventional instruments and techniques: solovoxes, theremins, marimbas, musical glasses, harmoniums, banjos, and ukuleles. In one early concert of folk music, Quilter and Scott were conscripted as performers, to whistle various parts. In "Random Round" (1912–14), inspired by the communal music-making he had heard in the Pacific Islands on his second Australasian tour, Grainger introduced an element of chance into performances; individual vocalists and instrumentalists could make random choices from a menu of variations. This experiment in "aleatory" composition presaged by many decades the use of similar procedures by avant-garde composers such as Berio and Stockhausen.

The brief "Sea Song" of 1907 was an early attempt by Grainger to write "beatless" music. This work, initially set over 14 irregular bars and occupying about 15 seconds of performing time, was a forerunner of Grainger's free-music experiments of the 1930s. Grainger wrote: "It seems to me absurd to live in an age of flying, and yet not be able to execute tonal glides and curves". The idea of tonal freedom, he said, had been in his head since as a boy of eleven or twelve he had observed the wave-movements in the sea. "Out in nature we hear all kinds of lovely and touching "free" (non-harmonic) combinations of tones; yet we are unable to take up these beauties ... into the art of music because of our archaic notions of harmony." In a 1941 letter to Scott, Grainger acknowledged that he had failed to produce any large-scale works in the manner of a Bach oratorio, a Wagner opera or a Brahms symphony, but excused this failure on the grounds that all his works before the mid-1930s had been mere preparations for his free music.

As a student, Grainger had learned to appreciate the music of Grieg, and came to regard the Norwegian as a paragon of Nordic beauty and greatness. Grieg in turn described Grainger as a new way forward for English composition, "quite different from Elgar, very original". After a lifetime interpreting Grieg's works, in 1944 Grainger began adapting the Norwegian's E minor Piano Sonata, Op. 7 as a "Grieg-Grainger Symphony", but abandoned the project after writing 16 bars of music. By this time, Grainger acknowledged that he had not fulfilled Grieg's high expectations of him, either as a composer or as a pianist. He also reflected on whether it would have been better, from the point of view of his development as a composer, had he never met the Griegs, "sweet and dear though they were to me".

Grainger was known for his musical experimentation and did not hesitate to exploit the capabilities of the orchestra. One early ambitious work was "The Warriors" (1913), an 18-minute suite which he dedicated to Delius. The music, which mixes elements of other Grainger works with references to Arnold Bax, Arnold Schönberg and Richard Strauss, requires a huge orchestral ensemble alongside at least three pianos – in one performance, Grainger used nineteen pianos with thirty pianists – to be played by "exceptionally strong vigorous players". Critics were undecided as to whether the work was "magnificent", or merely "a magnificent failure".

Grainger considered himself an Australian composer who, he said, wrote music "in the hopes of bringing honor and fame to my native land". However, much of Grainger's working life was spent elsewhere, and the extent to which he influenced Australian music, within his lifetime and thereafter, is debatable. His efforts to educate the Australian musical public in the mid-1930s were indifferently received, and did not attract disciples; writing in 2010, the academic and critic Roger Covell identifies only one significant contemporary Australian musician – the English-born horn player, pianist and conductor David Stanhope – working in the Grainger idiom. In 1956, the suggestion by the composer Keith Humble that Grainger be invited to write music for the opening of the 1956 Summer Olympics in Melbourne was rejected by the organisers of the Games.

Grainger was a life-long atheist and believed he would only endure in the body of work he left behind.
To assist that survival he established the Grainger Museum, which was given little attention before the mid-1970s; it was initially regarded as evidence either of an over-large ego or of extreme eccentricity. Since then the University of Melbourne's commitment to the museum has, Covell asserts, "rescued [it] permanently from academic denigration and belittlement". Its vast quantities of materials have been used to investigate not only Grainger's life and works, but those of contemporaries whom Grainger had known: Grieg, Delius, Scott and others. The Grainger home at 7 Cromwell Place, White Plains, New York, is now the Percy Grainger Library and is a further repository of memorabilia and historic performance material, open to researchers and visitors.

In Britain, Grainger's main legacy is the revival of interest in folk music. His pioneering work in the recording and setting of folk songs greatly influenced the following generation of English composers; Benjamin Britten acknowledged the Australian as his master in this respect. After hearing a broadcast of some Grainger settings, Britten declared that these "[knocked] all the Vaughan Williams and R. O. Morris arrangements into a cocked hat". In the United States, Grainger left a strong educational legacy through his involvement, over 40 years, with high school, summer school and college students. Likewise, his innovative approaches to instrumentation and scoring have left their mark on modern American band music; Timothy Reynish, a conductor and teacher of band music in Europe and America, has described him as "the only composer of stature to consider military bands the equal, if not the superior, in expressive potential to symphony orchestras." Grainger's attempts to produce "free music" by mechanical and later electronic means, which he considered his most important work, produced no follow-up; they were quickly overtaken and nullified by new technological advances. Covell nevertheless remarks that in this endeavour, Grainger's dogged resourcefulness and ingenious use of available materials demonstrate a particularly Australian aspect of the composer's character – one of which Grainger would have been proud.

In 1945 Grainger devised an informal ratings system for composers and musical styles, based on criteria that included originality, complexity and beauty. Of forty composers and styles, he ranked himself equal ninth – behind Wagner and
Delius, but well ahead of Grieg and Tchaikovsky. Nevertheless, in his later years he frequently denigrated his career, for example writing to Scott: "I have never been a true musician or true artist". His failure to be recognised as a composer for anything beyond his popular folk-song arrangements was a source of frustration and disappointment; for years after his death the bulk of his output remained largely unperformed. From the 1990s an increase in the number of Grainger recordings has brought a revival of interest in his works, and has enhanced his reputation as a composer. An unsigned tribute published on the "Gramophone" website in February 2011 to commemorate the 50th anniversary of Grainger's death opined that "though he would never be put on a pedestal to join the pantheon of immortals, he is unorthodox, original and deserves better than to be dismissed by the more snooty arbiters of musical taste".

Of Grainger the pianist, "The New York Times" critic Harold C. Schonberg wrote that his unique style was expressed with "amazing skill, personality and vigor". The early enthusiasm which had greeted his concert appearances became muted in later years, and reviews of his performances during the final ten years of his life were often harsh. However, Britten regarded Grainger's late recording of the Grieg concerto, from a live performance at Aarhus in 1957, as "one of the noblest ever committed to record" – despite the suppression of the disc for many years, because of the proliferation of wrong notes and other faults. Brian Allison from the Grainger Museum, referring to Grainger's early displays of artistic skills, has speculated that had John Grainger's influence not been removed, "Percy Aldridge Grainger may today be remembered as one of Australia's leading painters and designers, who just happened to have a latent talent as a pianist and composer". The ethnomusicologist John Blacking, while acknowledging Grainger's contribution to social and cultural aspects of music, nevertheless writes that if the continental foundation of Grainger's musical education had not been "undermined by dilettantism and the disastrous influence of his mother, I am sure that his ultimate contribution to the world of music would have been much greater".

Between 1908 and 1957 Grainger made numerous recordings, usually as pianist or conductor, of his own and other composers' music. His first recordings, for The Gramophone Company Ltd (later HMV), included the cadenza to Grieg's piano concerto; he did not record a complete version of this work on disc until 1945. Much of his recording work was done between 1917 and 1931, under contract with Columbia. At other times he recorded for Decca (1944–45 and 1957), and Vanguard (1957). Of his own compositions and arrangements, "Country Gardens", "Shepherd's Hey" and "Molly on the Shore" and "Lincolnshire Posy" were recorded most frequently; in recordings of other composers, piano works by Bach, Brahms, Chopin, Grieg, Liszt and Schumann figure most often. Grainger's complete 78 rpm solo piano recordings are now available on compact disc as a CD box set.

During his association with the Duo-Art company between 1915 and 1932, Grainger made around 80 piano rolls of his own and others' music using a wooden robot designed to play a concert grand piano via an array of precision mechanical fingers and feet; replayings of many of these rolls have subsequently been recorded on to compact disc. This reproduction system allowed Grainger to make a posthumous appearance in the Albert Hall, London, during the 1988 last night of the Proms as soloist with the BBC Symphony Orchestra in Grieg's Piano Concerto.

Since Grainger's death, recordings of his works have been undertaken by many artists and issued under many different labels. In 1995 Chandos Records began to compile a complete recorded edition of Grainger's original compositions and folk settings. Of 25 anticipated volumes, 19 had been completed as of 2010; these were issued as a CD boxed set in 2011, to mark the 50th anniversary of the composer's death.

Notes

References



</doc>
<doc id="255474" url="https://en.wikipedia.org/wiki?curid=255474" title="Amazing Stories">
Amazing Stories

Amazing Stories is an American science fiction magazine launched in April 1926 by Hugo Gernsback's Experimenter Publishing. It was the first magazine devoted solely to science fiction. Science fiction stories had made regular appearances in other magazines, including some published by Gernsback, but "Amazing" helped define and launch a new genre of pulp fiction.

As of 2018, "Amazing" has been published, with some interruptions, for ninety-two years, going through a half-dozen owners and many editors as it struggled to be profitable. Gernsback was forced into bankruptcy and lost control of the magazine in 1929. In 1938 it was purchased by Ziff-Davis, who hired Raymond A. Palmer as editor. Palmer made the magazine successful though it was not regarded as a quality magazine within the science fiction community. In the late 1940s "Amazing" presented as fact stories about the Shaver Mystery, a lurid mythos that explained accidents and disaster as the work of robots named deros, which led to dramatically increased circulation but widespread ridicule. "Amazing" switched to a digest size format in 1953, shortly before the end of the pulp-magazine era. It was sold to Sol Cohen's Universal Publishing Company in 1965, which filled it with reprinted stories but did not pay a reprint fee to the authors, creating a conflict with the newly formed Science Fiction Writers of America. Ted White took over as editor in 1969, eliminated the reprints and made the magazine respected again: "Amazing" was nominated for the prestigious Hugo Award three times during his tenure in the 1970s. Several other owners attempted to create a modern incarnation of the magazine in the following decades, but publication was suspended after the March 2005 issue. A new incarnation appeared in July 2012 as an online magazine. Print publication resumed with the Fall 2018 issue.

Gernsback's initial editorial approach was to blend instruction with entertainment; he believed science fiction could educate readers. His audience rapidly showed a preference for implausible adventures, and the movement away from Gernsback's idealism accelerated when the magazine changed hands in 1929. Despite this, Gernsback had an enormous impact on the field: the creation of a specialist magazine for science fiction spawned an entire genre publishing industry. The letter columns in "Amazing", where fans could make contact with each other, led to the formation of science fiction fandom, which in turn had a strong influence on the development of the field. Writers whose first story was published in the magazine include John W. Campbell, Isaac Asimov, Howard Fast, Ursula K. Le Guin, Roger Zelazny, and Thomas M. Disch. Overall, though, "Amazing" itself was rarely an influential magazine within the genre after the 1920s. Some critics have commented that by "ghettoizing" science fiction, Gernsback harmed its literary growth, but this viewpoint has been countered by the argument that science fiction needed an independent market to develop in to reach its potential.

By the end of the 19th century, stories centered on scientific inventions, and stories set in the future, were appearing regularly in popular fiction magazines. The market for short stories lent itself to tales of invention in the tradition of Jules Verne. Magazines such as "Munsey's Magazine" and "The Argosy", launched in 1889 and 1896 respectively, carried a few science fiction stories each year. Some upmarket "slick" magazines such as "McClure's", which paid well and were aimed at a more literary audience, also carried scientific stories, but by the early years of the 20th century, science fiction (though it was not yet called that) was appearing more often in the pulp magazines than in the slicks.

In 1908, Hugo Gernsback published the first issue of "Modern Electrics", a magazine aimed at the scientific hobbyist. It was an immediate success, and Gernsback began to include articles on imaginative uses of science, such as "Wireless on Saturn" (December 1908). In April 1911, Gernsback began the serialization of his science fiction novel, "Ralph 124C 41+", but in 1913 he sold his interest in the magazine to his partner and launched a new magazine, "Electrical Experimenter", which soon began to publish scientific fiction. In 1920 Gernsback retitled the magazine "Science and Invention", and through the early 1920s he published much scientific fiction in its pages, along with non-fiction scientific articles.

Gernsback had started another magazine called "Practical Electrics" in 1921. In 1924, he changed its name to "The Experimenter", and sent a letter to 25,000 people to gauge interest in the possibility of a magazine devoted to scientific fiction; in his words, "the response was such that the idea was given up for two years." However, in 1926 he decided to go ahead, and ceased publication of "The Experimenter" to make room in his publishing schedule for a new magazine. The editor of "The Experimenter", T. O'Conor Sloane, became the editor of "Amazing Stories". The first issue appeared on 10 March 1926, with a cover date of April 1926.

Initially the magazine focused on reprints; the first original story was "The Man From the Atom "(Sequel)"" by
G. Peyton Wertenbaker in the May 1926 issue.
In the August issue, new stories (still a minority) were noted with an asterisk in the table of contents.
The editorial work was largely done by Sloane, but Gernsback retained final say over the fiction content. Two consultants, Conrad A. Brandt and Wilbur C. Whitehead, were hired to help find fiction to reprint. Frank R. Paul, who had worked with Gernsback as early as 1914, became the cover artist; Paul had produced many illustrations for the fiction in "The Electrical Experimenter". "Amazing" was issued in the large bedsheet format, 8.5 × 11.75 in (216 × 298 mm), the same size as the technical magazines. It was an immediate success and by the following March reached a circulation of 150,000.
Gernsback saw there was an enthusiastic readership for "scientifiction" (the term "science fiction" had not yet been coined), and in 1927 started a Discussions section and issued "Amazing Stories Annual". The annual sold out, and in January 1928, Gernsback launched a quarterly magazine, "Amazing Stories Quarterly", as a regular companion to "Amazing". It continued on a fairly regular schedule for 22 issues.
Gernsback was slow to pay his authors and creditors; the extent of his investments limited his liquidity. On 20 February 1929 his printer and paper supplier opened bankruptcy proceedings against him. It has been suggested that Bernarr Macfadden, another magazine publisher, maneuvered to force the bankruptcy because Gernsback would not sell his titles to Macfadden, but this is unproven. Experimenter Publishing did not file any defence and was declared bankrupt by default on 6 March 1929; "Amazing" survived with its existing staff, but Hugo and his brother, Sidney, were forced out as directors. Arthur H. Lynch took over as editor-in-chief, though Sloane continued to have effective control of the magazine's contents. The receivers, Irving Trust, sold the magazine to Bergan A. Mackinnon on 3 April 1929.

In August 1931, "Amazing" was acquired by Teck Publications, a subsidiary of Bernarr Macfadden's Macfadden Publications. Macfadden's deep pockets helped insulate "Amazing" from the financial strain caused by the Great Depression. The schedule of "Amazing Stories Quarterly" began to slip, but "Amazing" did not miss an issue in the early 1930s. However, it became unprofitable to publish over the next few years. Circulation dropped to little more than 25,000 in 1934, and in October 1935 it switched to a bimonthly schedule.

By 1938, with "Amazing"<nowiki>'</nowiki>s circulation down to only 15,000, Teck Publications was having financial problems. In January 1938 Ziff-Davis took over the magazine and shortly thereafter moved production to Chicago; the April issue was assembled by Sloane but published by Ziff-Davis. Bernard Davis, who ran Ziff-Davis's editorial department, attempted to hire Roger Sherman Hoar as editor; Hoar turned down the job but suggested Raymond A. Palmer, an active local science fiction fan. Palmer was hired that February, taking over editorial duties with the June 1938 issue. Ziff-Davis launched "Fantastic Adventures", a fantasy companion to "Amazing", in May 1939, also under Palmer's editorship. Palmer quickly managed to improve "Amazing's" circulation, and in November 1938, the magazine went monthly again, though this did not last throughout Palmer's tenure: between 1944 and 1946 the magazine was bimonthly and then quarterly for a while before returning to a longer-lasting monthly schedule.

In September 1943 Richard Shaver, an "Amazing" reader, began to correspond with Palmer, who soon asked him to write stories for the magazine. Shaver responded with a story called "I Remember Lemuria", published in the March 1945 issue, which was presented by Palmer as a mixture of truth and fiction. The story, about prehistoric civilizations, dramatically boosted "Amazing"'s circulation, and Palmer ran a new Shaver story in every issue, culminating in a special issue in June 1947 devoted entirely to the Shaver Mystery, as it was called. "Amazing" soon drew ridicule for these stories. A derisive article by William S. Baring-Gould in the September 1946 issue of "Harper's" prompted William Ziff to tell Palmer to limit the amount of Shaver-related material in the magazine; Palmer complied, but his interest (and possibly belief) in this sort of material was now significant, and he soon began planning to leave Ziff-Davis. In 1947 he formed Clark Publications, launching "Fate" the following year, and in 1949 he resigned from Ziff-Davis to edit that and other magazines.

Howard Browne, who had been on a leave of absence from Ziff-Davis to write fiction, took over as editor and began by throwing away 300,000 words of inventory that Palmer had acquired before he left. Browne had ambitions of moving "Amazing" upmarket, and his argument was strengthened by Street & Smith, one of the longest established and most respected publishers, who shut down all of their pulp magazines in the summer of 1949. The pulps were dying, largely as a result of the success of pocketbooks, and Street & Smith decided to concentrate on their slick magazines. Some pulps struggled on for a few more years, but Browne was able to persuade Ziff and Davis that the future was in the slicks, and they raised his fiction budget from one cent to a ceiling of five cents per word. Browne managed to get promises of new stories from many well-known authors, including Isaac Asimov and Theodore Sturgeon. He produced a dummy issue in April 1950, and planned to launch the new incarnation of "Amazing" in April 1951, the 25th anniversary of the first issue. However, the economic impact of the Korean War, which broke out in June 1950, led to budget cuts. The plans were cancelled, and Ziff-Davis never revived the idea.

Browne's interest in "Amazing" declined when the project to turn it into a slick magazine was derailed. Although he stayed involved with "Fantastic Adventures", another Ziff-Davis magazine, he left the editing work on "Amazing" to William Hamling and Lila Shaffer. In December 1950, when Ziff-Davis moved their offices from Chicago to New York, Hamling stayed behind in Chicago, and Browne revived his involvement with the magazine.

In 1952, Browne convinced Ziff-Davis to try a high-quality digest fantasy magazine. "Fantastic", which appeared in the summer of that year, focused on fantasy rather than science fiction and was so successful that it persuaded Ziff-Davis to switch "Amazing" from pulp format to digest in early 1953 (while also switching to a bimonthly schedule). Circulation fell, however, and subsequent budget cuts limited the story quality in both "Amazing" and "Fantastic". "Fantastic" began to print science fiction as well as fantasy. Circulation increased as a result, but Browne, who was not a science fiction aficionado, once again lost interest in the magazines.

Paul W. Fairman replaced Browne as editor in September 1956. Early in Fairman's tenure, Bernard Davis decided to try issuing a companion series of novels, titled "Amazing Stories Science Fiction Novels". Readers' letters in "Amazing" had indicated a desire for novels, which "Amazing" did not have room to run. The novel series did not last; only one, Henry Slesar's "20 Million Miles to Earth", appeared. However, in response to readers' interest in longer fiction, Ziff-Davis expanded "Amazing" by 16 pages, starting with the March 1958 issue, and the magazine began to run complete novels.

Fairman left to edit "Ellery Queen's Mystery Magazine" at the end of 1958, and his place was taken by Cele Goldsmith. Goldsmith had been hired in 1955 as a secretary and became assistant editor to help cope with the additional work created when Ziff-Davis launched two short-lived magazines, "Dream World" and "Pen Pals", in 1956. Ziff-Davis were not confident of Goldsmith's abilities as an editor, so when Fairman left, a consultant, Norman Lobsenz, was hired to work with her. She performed well, however, and Lobsenz's involvement soon became minimal.

Goldsmith is well regarded by science fiction historians for her innovation, and the impact she had on the early careers of writers such as Ursula K. Le Guin and Roger Zelazny, but circulation lagged during her tenure. By 1964 "Fantastic"'s circulation was down to 27,000, with "Amazing" doing little better. The following March both "Amazing" and "Fantastic" were sold to Ultimate Publishing Company, run by Sol Cohen and Arthur Bernhard. Goldsmith was given the choice of going with the magazines or staying with Ziff-Davis; she stayed, and Cohen hired Joseph Wrzos to edit the magazines, starting with the August and September 1965 issues of "Amazing" and "Fantastic", respectively. Wrzos used the name "Joseph Ross" on the mastheads to avoid mis-spellings. Both magazines immediately moved to a bi-monthly schedule.

Cohen had acquired reprint rights to the magazines' back issues, although Wrzos did get Cohen to agree to print one new story every issue. Cohen was also producing reprint magazines such as "Great Science Fiction" and "Science Fiction Classics", but no payment was made to authors for any of these reprints. This brought Cohen into conflict with the Science Fiction Writers of America (SFWA), a professional writers' organization formed in 1965. Soon SFWA called for a boycott of Ultimate's magazines until Cohen agreed to make payments. Cohen agreed to pay a flat fee for all stories, and then in August 1967 this was changed to a graduated rate, depending on the length of the story. Harry Harrison had acted as an intermediary in Cohen's negotiations with SFWA, and when Wrzos left in 1967, Cohen asked Harrison to take over. "SF Impulse", which Harrison had been editing, had folded in February 1967, so Harrison was available. He secured Cohen's agreement that the policy of printing almost nothing but reprinted stories would be phased out by the end of the year, and took over as editor with the September 1967 issue.

By February 1968 Harrison decided to leave, as Cohen was showing no signs of abandoning the reprints. He resigned, and suggested Barry Malzberg to Cohen as a possible successor. Cohen knew Malzberg from his work at the Scott Meredith Literary Agency, and thought that he might be more amenable than Harrison to continuing the reprint policy. Malzberg took over in April 1968, but immediately came into conflict with Cohen over the reprints, and then threatened to resign in October 1968 over a disagreement about artwork Malzberg had commissioned for a cover. Cohen contacted Robert Silverberg, then the president of SFWA, and told him (falsely) that Malzberg had actually resigned. Silverberg recommended Ted White as a replacement. Cohen secured White's agreement and then fired Malzberg; White assumed control with the May 1969 issue.

When White took over as editor, "Amazing"'s circulation was about 38,500, only about 4% of which were subscribers (as opposed to newsstand sales). This was a very low ebb for subscriptions; "Analog", by comparison, sold about 35% of its circulation through subscriptions. Cohen's wife mailed out the subscription copies from home, and Cohen had never tried to increase the subscriber base as this would have increased the burden on his wife. White worked hard to increase the circulation despite Cohen's lack of support, but met with limited success. One of his first changes was to reduce the typeface to increase the amount of fiction in the magazine. To pay for this he increased the price of both "Fantastic" and "Amazing" to 60 cents, but this had a strong negative effect on circulation, which fell about 10% from 1969 to 1970.

In 1972, White changed the title to "Amazing Science Fiction", distancing the magazine slightly from some of the pulp connotations of "Amazing Stories". White worked at a low wage, and his friends often read manuscripts for free, but despite his efforts the circulation continued to fall. From near 40,000 when White joined the magazine, the circulation fell to about 23,000 in October 1975. White was unwilling to continue with the very limited financial backing that Cohen provided, and he resigned in 1975. Cohen was able to convince White to remain; White promised to stay for one more year, but in the event remained as editor until late 1978.

"Amazing" raised its price from 75 cents to $1.00 with the November 1975 issue. The schedule switched to quarterly beginning with the March 1976 issue; as a result, the 50th anniversary issue had a cover date of June 1976. In 1977, Cohen announced that "Amazing" and "Fantastic" had lost $15,000, though "Amazing"'s circulation (at nearly 26,000) was as good as it had been for several years. Cohen looked for a new publisher to buy the magazines, but in September of the following year sold his half-share in the company to his partner, Arthur Bernhard. White had occasionally suggested to Cohen that "Amazing" would benefit from a redesign and investment; he made the same suggestions to Bernhard in early October. According to White, Bernhard not only said no, but told him he would not receive a salary until the next issue was turned in. In late 1978 White resigned, and returned all manuscripts in his possession to their authors, even if copy-edited and ready for publication. White claimed Bernhard had told him to do this, though Bernhard denied it.

Elinor Mavor took over as editor in early 1979. She had worked for Bernhard as an illustrator and in the production department of several of his magazines, though not for "Amazing". She had also been an editor at "Bill of Fare", a restaurant trade magazine. Mavor had read a good deal of science fiction but knew nothing about the world of science fiction magazines when she took over. She was not confident that a woman would be accepted as the editor of a science fiction magazine, so she initially used the pseudonym "Omar Gohagen" for both "Amazing" and "Fantastic", dropping it late in 1980. Circulation continued to fall, and Bernhard refused to consider Mavor's request to undertake a subscription drive, which might have helped. Instead, in late 1980, Bernhard decided to merge the two magazines. "Fantastic"'s last independent issue was October 1980; thereafter the combined magazine returned to a bimonthly schedule. At the same time the title was changed to "Amazing Science Fiction Stories". Bernhard cut Mavor's salary after the merger, as she was editing only one magazine. Despite this, she stayed with "Amazing", but was unable to prevent circulation from dropping again, down to only 11,000 newsstand sales in 1982.

Shortly after the merger, Bernhard decided to retire, and approached Edward Ferman, the editor of "Fantasy and Science Fiction", and Joel Davis, at Davis Publications, among others, about a possible sale of "Amazing". Jonathan Post, of Emerald City Publishing, believed he had concluded a deal with Bernhard, and began to advertise for submissions, but the negotiations failed. Bernhard also approached George H. Scithers, who declined, but put Bernhard in touch with Gary Gygax of TSR. On 27 May 1982 TSR, Inc. acquired the trademarks and copyrights of "Amazing Stories". Scithers was taken on by TSR as editor beginning with the November 1982 issue. He was replaced by Patrick Lucien Price in September 1986, and then by Kim Mohan in May 1991. TSR ceased publication of "Amazing" with the Winter 1995 issue, but in 1997, shortly after they were acquired by Wizards of the Coast, the magazine was relaunched, again with Mohan as editor. This version lasted for only ten issues, though it did include a special celebratory 600th issue in early 2000. The science fiction trade journal "Locus" commented in an early review that distribution of the magazine seemed to be weak. The title proved unable to survive: the last issue of this version was dated Summer 2000. The title was then acquired by Paizo Publishing, who launched a new monthly version in September 2004. The February 2005 issue was the last printed; a March 2005 issue was released in PDF format, and in March 2006 Paizo announced that it would no longer publish "Amazing". In September 2011, the trademark for "Amazing Stories" was acquired by Steve Davidson. Two online issues appeared, in July and August 2012, followed by another in 2014. Davidson relaunched print publication of "Amazing Stories" with the Fall 2018 issue.

Gernsback's editorial in the first issue asserted that "Not only do these amazing tales make tremendously interesting reading—they are also always instructive". He had always believed that "scientifiction", as he called these stories, had educational power, but he now understood that the fiction had to entertain as well as to instruct. His continued belief in the instructional value of science fiction was not in keeping with the general attitude of the public towards pulp magazines, which was that they were "trash".

The first issue of "Amazing" contained only reprints, beginning with a serialization of "Off on a Comet", by Jules Verne. In keeping with Gernsback's new approach, this was one of Verne's least scientifically plausible novels. Also included were H. G. Wells's "The New Accelerator", and Edgar Allan Poe's "The Facts in the Case of M. Valdemar"; Gernsback put the names of all three authors on the cover. He also reprinted three more recent stories. Two came from his own magazine, "Science and Invention"; these were "The Man from the Atom" by G. Peyton Wertenbaker and "The Thing from—'Outside'" by George Allan England. The third was Austin Hall's "The Man Who Saved the Earth", which had appeared in "All-Story Weekly".

In the June 1926 issue Gernsback announced a competition to write a short story to suit a cover drawn by illustrator Frank R. Paul, with a first prize of $250. The competition drew over 360 entries, seven of which were eventually printed in "Amazing". The winner was Cyril G. Wates, who sold three more stories to Gernsback in the late 1920s. Two other entrants went on to become successful writers: one was Clare Winger Harris, whose story, "The Fate of the Poseidonia", took third place in the competition, and was published in the June 1927 issue as by "Mrs. F.C. Harris". The other notable entrant was A. Hyatt Verrill, with "The Voice from the Inner World", which appeared in July 1927.

A letter column, titled "Discussions" soon appeared, and became a regular feature with the January 1927 issue. Many science fiction readers were isolated in small communities, knowing nobody else who liked the same fiction. Gernsback's habit of publishing the full address of all his correspondents meant that the letter column allowed fans to correspond with each other directly. Science fiction fandom traces its beginnings to the letter column in "Amazing" and its competitors, and one historian of the field, author Lester del Rey, has commented that the introduction of this letter column "may have been one of the most important events in the history of science fiction".

For the first year, "Amazing" contained primarily reprinted material. It was proving difficult to attract new, high-quality material, and Gernsback's slowness at paying his authors did not help. Writers such as H.P. Lovecraft, H.G. Wells, and Murray Leinster all avoided "Amazing" because Gernsback took so long to pay for the stories he printed. The slow payments were probably known to many of the other active pulp writers, which would have further limited the volume of submissions. New writers did appear, but the quality of their stories was often weak.

Frederik Pohl later said that Gernsback's magazine published "the kind of stories Gernsback himself used to write: a sort of animated catalogue of gadgets". Gernsback discovered that the audience he had attracted was less interested in scientific invention stories than in fantastical adventures. A. Merritt's "The Moon Pool", which began serialization in May 1927, was an early success; there was little or no scientific basis to the story, but it was very popular with "Amazing"'s readers. The covers, all of which were painted by Paul, were garish and juvenile, leading some readers to complain. Raymond Palmer, later to become an editor of the magazine, wrote that a friend of his was forced to stop buying "Amazing" "by reason of his parents' dislike of the cover illustrations". Gernsback experimented with a more sober cover for the September 1928 issue, but it sold poorly, and so the lurid covers continued. The combination of poor quality fiction with garish artwork has led some critics to comment that Gernsback created a "ghetto" for science fiction, though it has also been argued that the creation of a specialized market allowed science fiction to develop and mature as a genre.

Among the regular writers for "Amazing" by the end of the 1920s were several who were influential and popular at the time, such as David H. Keller and Stanton Coblentz, and some who would continue to be successful for much longer, most notably Edward E. Smith and Jack Williamson. Smith's "The Skylark of Space", written between 1915 and 1920, was a seminal space opera that found no ready market when "Argosy" stopped printing science fiction. When Smith saw a copy of the April 1927 issue of "Amazing", he submitted it to Sloane, and it appeared in the August–October 1928 issues. It was such a success that Sloane requested a sequel before the second installment had been published. It was also in the August 1928 issue that "Armageddon – 2419 AD", by Philip Francis Nowlan, appeared; this was the first appearance of Buck Rogers in print.

Sloane took over full control of the content of "Amazing" when Gernsback left in 1929. He was infamous for his slow response to manuscripts, and when "Astounding Stories" was launched in January 1930, with better rates and faster editorial response, some of Sloane's writers quickly defected. Little of quality appeared in "Amazing" during Sloane's tenure, though "The Lost Machine", an early story by John Wyndham, appeared in April 1932, under Wyndham's real name of John Beynon Harris. John W. Campbell and Howard Fast sold their first stories to Sloane; Campbell's "When the Atoms Failed" appeared in the January 1930 issue, and Fast's "Wrath of the Purple" was printed in the October 1932 issue.

Raymond Palmer, who took over in 1938 after production of the magazine was moved to Chicago, was less interested in the educational possibilities of science fiction than Sloane had been. He wanted the magazine to provide escapist entertainment, and had no interest in scientific accuracy. His terse instruction—"Gimme Bang-Bang"—to one pulp writer sums up his approach. Palmer disposed of almost all of Sloane's accumulated inventory, instead acquiring stories from local Chicago writers he knew through his connections with science fiction fandom. He also added features such as a "Correspondence Corner" and a "Collectors' Corner" to appeal to fans, and introduced a "Meet the Authors" feature, though on at least one occasion the featured author was a pseudonym, and the biographical details were invented. An illustrated back cover was tried, and soon became standard. In 1939 Palmer acquired Isaac Asimov's first sale, "Marooned off Vesta".

In the 1940s, several writers established themselves as a stable of reliable contributors to "Amazing". These included David Wright O'Brien and William P. McGivern, both of whom wrote an immense amount for Ziff-Davis, much of it under house names such as Alexander Blade. John Russell Fearn became a prolific contributor, using the pseudonyms "Thornton Ayre" and "Polton Cross". Palmer also encouraged long-time science fiction writers to return, publishing pulp authors such as Ed Earl Repp and Eando Binder. This policy did not always meet with approval from "Amazing"'s readers, who, despite a clear preference for action and adventure stories, could not stomach the work of some of the early pulp writers such as Harry Bates.
The first Shaver Mystery story, "I Remember Lemuria", by Richard S. Shaver, appeared in the March 1945 issue. Shaver claimed that all the world's accidents and disasters were caused by an ancient race of deros (short for "detrimental robots") who lived in underground cities. This explanation for the world's ills, coming towards the end of World War II, struck a chord with "Amazing"'s readership. Palmer received over 2,500 letters, instead of the usual 40 or 50, and proceeded to print a Shaver story in every issue. The June 1947 issue was given over entirely to the Shaver Mystery. From March 1948 the Shaver Mystery was dropped as a regular feature of the magazine, at Ziff's insistence. Palmer left the following year, and Browne, his successor, "was determined to make sure that the lunatics were no longer in charge of the asylum", in the words of science fiction historian Mike Ashley.

Browne had acquired some good-quality material in the process of planning the launch of a new slick version of "Amazing", and when the plan was abandoned this material appeared in the continuing pulp version. This included "Operation RSVP" by H. Beam Piper, and "Satisfaction Guaranteed" by Isaac Asimov. Despite the cancellation of the planned change to a slick format, news had reached the writing community of "Amazing"'s new approach, and Browne began to receive much better material than Palmer had been able to publish. The existing stable of "Amazing" writers, such as Rog Phillips and Chester S. Geier, were replaced by writers such as Fritz Leiber, Fredric Brown, and Clifford D. Simak. Browne also discovered several writers who went on to success in the field, publishing first stories by Walter M. Miller, Mack Reynolds, John Jakes, Milton Lesser and Charles Beaumont, all within the space of nine months in late 1950 and early 1951. Browne was disappointed by the cancellation of the planned slick version, however, and to some extent reverted to Palmer's policy of publishing sensational fiction. In 1952, for example, he serialized the anonymous "Master of the Universe", which purported to be a history of the future from 1975 to 2575.

With the change to digest size in 1953, Browne once again attempted to use higher-quality fiction. The first digest issue, dated April–May 1953, included stories by Ray Bradbury, Robert Heinlein, Richard Matheson, Theodore Sturgeon, and Murray Leinster. Further well-regarded stories appeared over the course of 1953, including Arthur C. Clarke's "Encounter in the Dawn", and Henry Kuttner's "Or Else". Subsequent budget cuts meant that Browne was unable to sustain this level. As in the 1940s, "Amazing" gained a stable of writers who appeared frequently, though this time the quality of the writers was rather higher—it included Harlan Ellison, Robert Silverberg, and Randall Garrett—and the regular writers were not appearing only in Ziff-Davis magazines. This remained the situation after Browne's departure in 1956 and through Paul Fairman's tenure.

Cele Goldsmith's tenure as editor began with the opportunity to showcase two very well-established writers: E.E. Smith and Isaac Asimov. Smith's "The Galaxy Primes" began serialization in March 1959. Asimov's first published story, "Marooned off Vesta", had appeared in the March 1939 issue of "Amazing", and Goldsmith reprinted it in March 1959 along with a sequel and Asimov's comments on the story. She soon began to publish some of the better new writers. Cordwainer Smith's "Golden the Ship Was—Oh! Oh! Oh!" appeared in April; and by the middle of the following year she had managed to attract stories from Robert Sheckley, Alan E. Nourse, Fritz Leiber, Gordon R. Dickson, Robert Bloch, and James Blish. The changes she made were enough to bring Robert Heinlein back as a subscriber; Heinlein read a copy of the June 1961 issue, which, he said, "... caused me to think I had been missing something."
In September 1960 "Amazing" began to carry Sam Moskowitz's series of author profiles, which had begun in "Fantastic", the sister magazine. The following month the cover and logo were redesigned. In April 1961, the 35th anniversary of the first issue, Goldsmith ran several reprints, including stories by Ray Bradbury and Edgar Rice Burroughs. Goldsmith had little previous experience with science fiction, and bought what she liked, rather than trying to conform to a notion of what science fiction should be. The result was the debut of more significant writers in her magazines than anywhere else at that time. She published the first stories of Ursula K. Le Guin, Roger Zelazny, Piers Anthony and Thomas M. Disch, among many others. Award-winning stories published during Goldsmith's editorship include Zelazny's "He Who Shapes", a story about the use of dream therapy to cure phobias. It was serialized in the January and February 1965 issues, and won a Nebula Award, an annual award voted on by science fiction writers. Goldsmith often wrote long, helpful letters to her authors: Zelazny commented in a letter to her that "Most of anything I have learned was stimulated by those first sales, and then I learned, and possibly even learned more, from some of the later rejections". Disch and Le Guin have also acknowledged the influence Goldsmith had on their early careers.

The cover art for "Amazing" had been largely supplied by Ed Valigursky during the late fifties, but during the early sixties a much wider variety of artists appeared, including Alex Schomburg, Leo Summers and Ed Emshwiller. Frank Paul, who had painted all the covers for the first few years of "Amazing", contributed a wraparound cover for the April 1961 35th anniversary issue; this was his last cover art for a science fiction magazine.

Goldsmith's open-minded approach meant that "Amazing" and "Fantastic" published some writers who did not fit into the other magazines. Philip K. Dick's sales to magazines had dropped, but his work began to appear in "Amazing", and Goldsmith also regularly published David R. Bunch's stories of Moderan, a world whose inhabitants were part human and part metal. Bunch, whose stories were "bewildering, exotic word pictures" according to Mike Ashley, had been unable to sell regularly elsewhere.

When Sol Cohen bought both "Amazing" and "Fantastic" in early 1965, he decided to maximize profits by filling the magazines almost entirely with reprints. Cohen had acquired second serial rights from Ziff-Davis to all stories that had been printed in both magazines, and also in the companion magazines such as "Fantastic Adventures". Joseph Wrzos, the new editor, persuaded Cohen that at least one new story should appear in each issue; there was sufficient inventory left over from Goldsmith's tenure for this to be done without acquiring new material. Readers initially approved of the policy, since it made available some well-loved stories from earlier decades that had not been reprinted elsewhere. Both of Wrzos's successors, Harry Harrison and Barry Malzberg, were unable to persuade Cohen to use more new fiction.

When Ted White took over, it was on condition that the reprints be phased out. This took some time: for a while both "Amazing" and "Fantastic" continued to include one reprint every issue; with the May 1972 issue the transformation was complete, and all stories were new. As well as eliminating the reprints, White reintroduced features such as a letter column and "The Clubhouse," a fanzine review and fannish news column. He continued the book review column, and a series of science articles by Gregory Benford and David Book. White also redesigned the look of the magazine, making it, in sf historian Mike Ashley's words, "far more modern and sophisticated".

White was willing to print a variety of fiction, mixing traditional stories with more experimental material that was influenced by the British New Wave or by 1960s psychedelia. In 1971 he serialized Ursula K. Le Guin's "The Lathe of Heaven", about a man whose dreams can modify reality. One writer influenced by this was James Tiptree, Jr., who later wrote that "after first plowing into the first pulpy pages of the 1971 "Amazing" in which "Lathe" came out, my toe-nails began to curl under and my spine hair stood up." White's willingness to experiment led to "Amazing" running more stories with sexual content than other magazines. One such story, White's own "Growing Up Fast in the City", was criticized as pornographic by some of "Amazing"'s readers. Other stories, such as Rich Brown's "Two of a Kind", about the violent rape of a black woman and the subsequent death of her rapists, also led to controversy. White printed more conventional fiction as well, much of it high quality. The magazine was nominated for the Hugo award (a readers' award, named for Hugo Gernsback) for best editor three times during his tenure (1970, 1971 and 1972), finishing third each time.

White's ability to attract new writers suffered because of the low rates he paid: one cent per word, as compared to three or five cents per word at the leading competitive magazines. To compensate, White cultivated new writers whose experimental work was not selling elsewhere. He made a deal in 1971 with Gordon Eklund, who was hesitating to become a full-time writer because of the financial risks. White agreed to buy anything Eklund wrote, on condition that Eklund himself believed it was a good story. The result was that much of Eklund's fiction appeared in "Amazing" and "Fantastic" over the next few years.

"Amazing"'s reputation had been for formulaic science fiction almost since it began, but White was able to take the magazine to a higher standard than any other editor except Cele Goldsmith, and gave "Amazing" a respected position in the field. His successors were not able to maintain the same level of quality.

When Elinor Mavor took over, in early 1979, she had no experience with science fiction magazines, and was unaware of the history of bad feeling within the science fiction community about the poor payments for reprinted stories. She was given an extremely limited budget to work with, and had few stories on hand to work with initially, and as a result her first issues contained several reprints. Mavor experimented in her first year with some new ideas, such as starting a story on the back cover in order to hook readers into buying the magazine to finish the story. She also began a serial story in graphic format that used reader input to continue its plot. It was not a success and "thankfully", according to Mike Ashley, the experiment was terminated after only three episodes.

Over time Mavor was to some extent able to reverse the negative perceptions of "Amazing" among established authors, but she was initially forced to work primarily with newer writers. Early discoveries of hers include Michael P. Kube-McDowell, John E. Stith and Richard Paul Russo. In a notice published in her first issue, she asked readers for help in assembling news, reviews and fan information, and soon added columns that covered these areas. In 1981 Robert Silverberg began a series of opinion columns. The artwork was of high quality, including work by Stephen Fabian, and later by David Mattingly.

After the merger with "Fantastic", Mavor continued to draw well-known writers to the magazine, including Orson Scott Card, George R. R. Martin, and Roger Zelazny. Brad Linaweaver's "Moon of Ice", which appeared in March 1982, was nominated for a Nebula award; Martin's "Unsound Variations", which had appeared the issue before, was nominated for both a Nebula and a Hugo award.

Historian James Gunn's assessment of "Amazing" in the 1980s is that Mavor, Scithers and Price, who between them edited "Amazing" for a decade, were unable to sustain the standards established by Ted White in the 1970s. Brian Stableford, by contrast, comments that both Scithers and Price made efforts to publish good material, and that the packaging, from 1991 onwards, was perhaps the best presented of any science fiction magazine.

With the Wizards of the Coast relaunch in 1998 the contents, under editor Kim Mohan, became more media-focused. The initial plan was to have two or three stories per issue based on films, TV, and games. The 600th issue, in early 2000, included a Harlan Ellison story, as well as a story from the 100th issue, the 200th issue, and so on, up to the 500th issue. Pamela Sargent also contributed a story. The Paizo publishing relaunch, in 2004, was even more focused on media content than the Wizards of the Coast version had been, with much more movie and comics-related material than science fiction. Several well-known authors appeared in the first issue, including Harlan Ellison, Bruce Sterling, and Gene Wolfe. Paizo also ran a blog for the magazine. The fiction received positive reviews, but Paizo soon put the magazine on temporary hold, and canceled it permanently the following year. The title remained in limbo until Steve Davidson's online version appeared in 2012.

"Amazing Stories" was influential simply by being the first of its kind. In the words of science fiction writer and critic Damon Knight, the magazine was "a snag in the stream of history, from which a V-shape spread out in dozens and then in hundreds of altered lives". Many early fans of the field began to communicate with each other through the letter column, and to publish fanzines—amateur fan publications that helped establish connections among fans across the country. Many of these fans in turn became successful writers; and the existence of an organized science fiction fandom, and of writers such as Ray Bradbury, Arthur C. Clarke, and Isaac Asimov, who came to writing directly from fandom, can be dated to the creation of "Amazing Stories". After the first few years, when there was little or no competition, "Amazing Stories" never again led the field in the eyes of critics or fans. Despite its long history, the magazine rarely contributed much to science fiction beyond the initial creation of the genre, though Gernsback himself is commemorated in the name "Hugo", which is the almost universally used term for the World Science Fiction Society's annually presented Science Fiction Achievement Awards. Gernsback has also been called the "Father of Science Fiction" for his role in creating "Amazing Stories".

Bibliographers do not always agree who should be listed as editor of any given issue of "Amazing". For example, Gernsback was in control for the first three years, but Sloane performed all the editorial duties related to fiction, and he is sometimes described as the editor. Similarly, later editors were sometimes under the supervision of editorial directors. Bernard Davis held the title of "Editor" of all Ziff-Davis magazines when at that company,with the actual editing of the magazines done by respective "Managing Editors".The table below, and the charts above, generally follow the mastheads in the magazines, with short notes added. More details are given in the publishing history section, above, which focuses on when the editors involved actually obtained control of the magazine contents, instead of when their names appeared on the masthead.

"Amazing" began as a bedsheet format magazine and remained so until October 1933, when it switched to pulp size. With the April–May 1953 issue "Amazing" became a digest. Seven issues in the early 1980s, from November 1980 to November 1981, were a half-inch taller than the regular digest size, but thereafter the magazine reverted to the standard digest format. In May 1991 the magazine returned to a large format, but this lasted only until the Winter 1994 issue, and the next three issues were digest-sized again. When the magazine reappeared in 1998, it was in bedsheet format and remained that size until the very end. The last issue, March 2005, was distributed only as a PDF download, never as a physical magazine. The volume numbering contained some irregularities: the numbering given in the tables above appears to be in error for the period from 1979 to 1983, but in fact it is given correctly in the table. Note also that vol. 27 no. 8 was a single issue, not two, as it seems to be from the table; it was dated Dec 1953/Jan 1954.

The title of the magazine changed several times:

Two different series of reprints of "Amazing" appeared in the United Kingdom. First came a single undated issue from Ziff-Davis, in November 1946. In June 1950, Thorpe & Porter began a second series that lasted until 1954, and totalled 32 issues. The Ziff-Davis issue and the first 24 issues from Thorpe & Porter were pulp-sized; the last eight were digests. The Thorpe & Porter issues were undated, but the pulp issues were numbered from 1 to 24, and were initially bimonthly. The March 1951 issue was followed by April and November, however, and in 1952 issues appeared in February, March, April, June, July, September and November. 1953 saw nine pulp issues, omitting only March and May; and with December came the change to digest-size and a perfectly regular bimonthly schedule that lasted until February 1955. These last eight issues were numbered volume 1, numbers 1 to 8. There was also a Canadian edition, which lasted for 24 issues, from September 1933 to August 1935, from Teck Publications; these were identical to the US editions except that the front covers were overprinted with "Printed in Canada on Canadian Paper". A Japanese edition ran for seven issues in mid-1950, selecting stories from "Fantastic Adventures" as well as from "Amazing".

From 1940 to 1943, and again from 1947 to 1951, copies of "Amazing Stories" were rebound, three at a time, and resold as "Amazing Stories Quarterly". A total of 27 of these issues appeared; they should not be confused with the magazine of the same name which ran from 1928 to 1934 as a companion to "Amazing Stories".

Several anthologies of stories from "Amazing" have been published, including:

Director Steven Spielberg licensed the title for use on an American television show called "Amazing Stories" that ran from 1985 to 1987. Between 1998 and 2000, "Amazing Stories" published a series of short stories based upon the "Star Trek" franchise. In 2002, these stories were reissued by Pocket Books in the collection "Star Trek: The Amazing Stories".





</doc>
<doc id="255811" url="https://en.wikipedia.org/wiki?curid=255811" title="Green Park tube station">
Green Park tube station

Green Park is a London Underground station located on the north side of Green Park, with entrances on both sides of Piccadilly. It is served by the Jubilee, Piccadilly and Victoria lines. On the Jubilee line it is between Bond Street and Westminster; on the Piccadilly line it is between Piccadilly Circus and Hyde Park Corner and on the Victoria line it is between Victoria and Oxford Circus. It is in fare zone 1.

The station was opened in 1906 by the Great Northern, Piccadilly and Brompton Railway (GNP&BR) and was originally named "Dover Street" due to its location in that street. It was modernised in the 1930s when lifts were replaced with escalators and extended in the 1960s and 1970s when the Victoria and Jubilee lines were constructed.

The station is near The Ritz Hotel, the Royal Academy of Arts, St James's Palace, Berkeley Square, Bond Street, the Burlington Arcade and Fortnum & Mason, and is one of two serving Buckingham Palace (the other being St James's Park).

During the final years of the 19th century and the early years of the 20th century numerous competing schemes for underground railways through central London were proposed. A number of the schemes submitted to parliament for approval as private bills included proposals for lines running under Piccadilly with stations in the area of the current Green Park station.

The first two proposals came before parliament in 1897. The Brompton and Piccadilly Circus Railway (B&PCR) proposed a line between South Kensington and Piccadilly Circus and the City and West End Railway (C&WER) proposed a line between Hammersmith and Cannon Street. The B&PCR proposed a station on the north side at Dover Street and the C&WER proposed a station on the south side at Arlington Street. Following review by parliament, the C&WER bill was rejected and the B&PCR bill was approved and received royal assent in August 1897.

In 1902, the Charing Cross, Hammersmith and District Railway (CCH&DR) proposed a line between Charing Cross and Barnes with a parallel shuttle line running between Hyde Park Corner and Charing Cross. A station was planned at Walsingham House on the north-east corner of Green Park. This scheme was rejected by parliament.

The same year, the Central London Railway (CLR, now the central section of the Central line) submitted a bill that aimed to turn its line running between Shepherd's Bush and Bank into a loop by constructing a second roughly parallel line to the south. This would have run along Piccadilly with a station at St James's Street just to the east of Dover Street. Delayed while a royal commission considered general principles of underground railways in London, the scheme was never fully considered and although it was re-presented in 1903, it was dropped two years later.

A third scheme for 1902 was the Piccadilly, City and North East London Railway (PC&NELR) which proposed a route between Hammersmith and Southgate. It planned a station at Albermarle Street, just to the east of Dover Street. Although favoured in parliament and likely to be approved, this scheme failed due to a falling-out between the backers and the sale of part of the proposals to a rival.

In 1905, some of the promoters of the PC&NELR regrouped and submitted a proposal for the Hammersmith, City and North East London Railway. As the CLR had done previously, the company proposed a station at St James's Street. Due to failures in the application process, this scheme was also rejected.

While the various rival schemes were unsuccessful in obtaining parliamentary approval, the B&PCR was unsuccessful in raising the funds needed to construct its line. It was not until after the B&PCR had been taken over by Charles Yerkes's Metropolitan District Electric Traction Company that the money became available. Tunnelling began in 1902 shortly before the B&PCR was merged with the Great Northern and Strand Railway to create the Great Northern, Piccadilly and Brompton Railway (GNP&BR, the predecessor of the Piccadilly line).

The GNP&BR opened the station on 15 December 1906 as "Dover Street". As with most of the other GNP&BR stations, the station building, on the east side of Dover Street, was designed by Leslie Green. It featured the company's standard red glazed terracotta facade with wide semi-circular arches at first-floor level. Platform and passageway walls were decorated in glazed cream tiles in Green's standard arrangement with margins, patterning and station names in mid-blue. When it opened, the station to the west was Down Street. The station was provided with four Otis electric lifts paired in two diameter shafts and a spiral stair in a smaller shaft. The platforms are below the level of Piccadilly.

The station was busy and unsuccessful attempts to control crowds with gates at platform level were made in 1918. In the 1930s, the station was included amongst those modernised in conjunction with the northern and western extensions of the Piccadilly line. A new sub-surface ticket hall was opened on 18 September 1933 with a pair of Otis escalators provided to replace the lifts. The new ticket hall was accessed from subway entrances in Piccadilly. On the north side, an entrance was provided in Devonshire House on the corner with Stratton Street; on the south side an entrance was constructed on a piece of land taken from the park. The shelter for the southern entrance was designed by Charles Holden. The original station building, the lifts and the redundant below-ground passages were closed. Part of the ground floor was used as a tea shop until the 1960s. In 1955, a third escalator was added to help deal with increased passenger numbers.

Proposals for an underground line linking Victoria to Finsbury Park date from 1937 when planning by the London Passenger Transport Board (LPTB) for future services considered a variety of new routes and extensions to existing lines. Parliament approved the line in 1955, but a shortage of funds meant that work did not start until after government loans were approved in 1962.

Construction works began in 1962. The 1930s ticket hall under the roadway of Piccadilly was enlarged to provide space for new Victoria line escalators and a long interchange passageway was provided between the Victoria line and Piccadilly line platforms. In 1965 a collapse of soft ground during the excavation of one of the tunnels near Green Park station meant that the ground had to be chemically stabilised before work could continue. The disused station building in Dover Street was demolished the following year in conjunction with the works for the new line. A vent shaft was constructed and an electrical sub-station was built in the basement of the new building. The 1930s entrance on the south side of Piccadilly was also reconstructed.

The enlarged ticket hall, new platforms and passageways were decorated in grey tiles. Platforms are approximately below street level. Platform roundel signs were on backlit illuminated panels. Seat recesses on the Victoria line platforms were tiled in an abstract pattern by Hans Unger of coloured circles representing a bird's-eye view of trees in Green Park.

After trial running of empty trains from 24 February 1969, the Victoria line platforms opened on 7 March 1969 with the opening of the third stage of the line between Warren Street and Victoria. The same day, the Queen officially opened the line by riding a train from Green Park to Oxford Circus.

The origins of the Jubilee line are less clearly defined than those of the Victoria line. During World War II and throughout the 1950s and early 1960s consideration was given to various routes connecting north-west and south-east London via the West End and the City of London. Planning of the Victoria line had the greater priority and it was not until after construction of that line started that detailed planning began for the new line, first called the Fleet line in 1965 as it was planned to run in an east-west direction along Fleet Street. Lack of funding meant that only the first stage of the proposed line, from Baker Street to Charing Cross, received royal assent in July 1969; funding was agreed in August 1971.

Tunnelling began in February 1972 and was completed by the end of 1974. In 1977, during construction of the stations, the name of the line was changed to the Jubilee line, to mark the Queen's Silver Jubilee that year. A construction shaft in Hays Mews north of the station was used for an electrical substation and ventilation shaft. At Green Park, the ticket hall was enlarged slightly to provide space for escalators for the new line which connect to an intermediate concourse providing interchange between the Jubilee and Victoria lines. A second flight of escalators descends to the Jubilee line platforms, which are below street level, the deepest of the three sets. Interchange between the Jubilee and Piccadilly lines was via the ticket hall. Platform walls were tiled in a deep red with black leaf patterns by June Fraser. Trial running of trains began in August 1978 and the Jubilee line opened on 1 May the next year. The line had been officially opened by Prince Charles the previous day, starting with a train journey from Green Park to Charing Cross. In 1993, to alleviate congestion, a third escalator was installed in the lower flight to replace a fixed staircase.
Work on the Fleet line's stages 2 and 3 did not proceed and it was not until 1992 that an alternative route was approved. The Jubilee line extension took the line south of the River Thames via Waterloo, which was impractical to reach from the line's existing terminus at Charing Cross. New tunnels branching from the original route south of Green Park were to be constructed, and the line to Charing Cross was to be closed. Tunnelling began in May 1994, and improvements were carried out at Green Park to provide a direct passageway connection between the Jubilee and Piccadilly lines, including lifts to the platforms at each end. A new ventilation shaft and an emergency exit to Arlington Street were built. The new extension opened in stages starting at Stratford in the east, with services to Charing Cross ending on 19 November 1999 and the final section between Green Park and Waterloo opening the following day.

In 2008, Transport for London (TfL) announced a project to provide step-free access to all three lines in advance of the 2012 London Olympics. The project also included the construction of a new entrance on the south side of Piccadilly with ramped access directly from Green Park. Work commenced in May 2009 to install two lifts from the ticket hall to the Victoria line platforms and the interchange passageway to the Piccadilly line. This work and a third lift in the new park-side entrance between the street level and the ticket hall were completed ahead of schedule in 2011. At the same time, Green Park station underwent a major improvement programme which saw the tiling on the Victoria and Piccadilly line platforms and the interchange passageways replaced. When the Jubilee line opened, the Hans Unger tiling in the seat recesses of the Victoria line platforms was replaced with a design using the used on the Jubilee line platforms; the Unger design was reinstated during the restoration.
The new park entrance and street level shelter feature artwork within the Portland stone cladding titled "Sea Strata" designed by John Maine RA. The "Diana Fountain" was relocated from its original site in the centre of the park to form the centrepiece of the new entrance.

To help moderate temperatures in the station, a system using cool ground water extracted from boreholes sunk into the chalk aquifer below London was installed. The extracted water passes through a heat exchanger connected to the cast-iron tunnel lining and the warmed water is returned to the aquifer through a second set of boreholes away.

In July 2005, a report, "DLR Horizon 2020 Study", for the Docklands Light Railway (DLR) examined "pragmatic development schemes" to expand and improve the DLR network between 2012 and 2020. One of the proposals was an extension of the DLR from Bank to Charing Cross. Unused tunnels under Strand constructed as part of Stage 1 of the Fleet line would be enlarged to accommodate the larger DLR trains. In 2011, the DLR published a proposal to continue the extension to Victoria via Green Park. No further work has been done on these proposals.

At around 9.00 pm on 9 October 1975, members of the Provisional IRA's Balcombe Street Gang detonated a bomb at a bus stop outside Green Park station, killing 23-year-old Graham Ronald Tuck and injuring 20 others. The attack was part of a bombing campaign carried out by the gang and in addition to the death and injuries caused damage to the Ritz Hotel and neighbouring buildings.

The station is in Travelcard Zone 1, between Bond Street and Westminster on the Jubilee line, Hyde Park Corner and Piccadilly Circus on the Piccadilly line and Victoria and Oxford Circus on the Victoria line. On weekdays Jubilee line trains typically run every 2–2½ minutes between 05:38 and 00:34 northbound and 05:26 and 00:45 southbound; on the Piccadilly line trains typically run every 2½–3½ minutes between 05:48 and 00:34 westbound and 00:32 eastbound, and on the Victoria line trains typically run every 100–135 seconds between 05:36 and 00:37 northbound and 05:36 and 00:31 southbound.

As of it is the station on the London Underground with million passengers using it.

London Buses routes 6, 9, 14, 19, 22 and 38 and night routes N9, N19, N22, N38 and N97 serve the station.

The opening scene of the 1997 film version of Henry James's "The Wings of the Dove" was set on the eastbound platforms at both Dover Street and Knightsbridge stations, both represented by the same studio mock-up, complete with a working recreation of a 1906 Stock train.



</doc>
<doc id="256672" url="https://en.wikipedia.org/wiki?curid=256672" title="Sherman Minton">
Sherman Minton

Sherman "Shay" Minton (October 20, 1890 – April 9, 1965) was a United States Senator from Indiana and later an Associate Justice of the Supreme Court of the United States. He was a member of the Democratic Party.

After attending college and law school, Minton served as a captain in World War I, following which he launched a legal and political career. In 1930, after multiple failed election attempts, and serving as a regional leader in the American Legion, he became a utility commissioner under the administration of Indiana Governor Paul V. McNutt. Four years later, Minton was elected to the United States Senate. During the campaign, he defended New Deal legislation in a series of addresses in which he suggested it was not necessary to uphold the Constitution during the Great Depression crisis. Minton's campaign was denounced by his political opponents, and he received more widespread criticism for an address that became known as the "You Cannot Eat the Constitution" speech. As part of the New Deal Coalition, Minton championed President Franklin D. Roosevelt's unsuccessful court packing plans in the Senate and became one of his top Senate allies.

After Minton failed in his 1940 Senate re-election bid, Roosevelt appointed him as a United States Circuit Judge of the United States Court of Appeals for the Seventh Circuit. After Roosevelt's death, President Harry S. Truman, who had developed a close friendship with Minton during their time together in the Senate, nominated him to the Supreme Court. He was confirmed by the Senate on October 4, 1949, by a vote of 48 to 16, 15 Republicans and one Democrat (Harry Flood Byrd of Virginia) voting against him. He served on the Supreme Court for seven years. An advocate of judicial restraint, Minton was a regular supporter of the majority opinions during his early years on the Court; he became a regular dissenter after President Dwight Eisenhower's appointees altered the Bench's composition. In 1956, poor health forced Minton's retirement, after which he traveled and lectured until his death in 1965.

Historians note the unusual contrast between his role as a partisan liberal Senator and his role as a conservative jurist. They attribute his shift in position as a reaction to the relationship between the New Deal senators and the conservative 1930s Court, which ruled much of the New Deal legislation unconstitutional. When Minton became a Supreme Court Justice, the Senate had become more conservative and the Court more activist, causing him to support conservative minority positions. As a Justice, Minton frequently played the role of peace-maker and consensus builder during a period when the Court was riven with feuds. He generally ruled in favor of order over freedom as a result of his broad interpretation of governmental powers. These rulings and their limited impact lead some historians to have a negative opinion of his judicial record. Other historians point out Minton's strong commitment to his judicial principles as a valuable attribute. In 1962, the Sherman Minton Bridge in southern Indiana and the Minton-Capehart Federal Building in Indianapolis were named in his honor.

Sherman Minton was born on October 20, 1890, to John Evan and Emma Livers Minton, in their Georgetown, Indiana, home. He was the third of the family's five children and was nicknamed Shay because of his younger brother's inability to properly pronounce "Sherman". Minton's paternal grandfather, Jonathan Minton, was killed during the American Civil War and his father grew up on his own. Minton's parents married in 1883.

Minton received his basic education in a two-room schoolhouse in Georgetown, which he attended through eighth grade. He was exposed to politics from an early age; his father took him to several political rallies, including an 1895 speech by Democratic Party leader William Jennings Bryan. His father was a day laborer for the New Albany and St. Louis Air Line Railway. In 1898, he became disabled when he suffered heat stroke while working. His condition meant he could not work; the family became impoverished and had to subsist on the limited yield of their small farm. Minton's mother developed breast cancer in 1899. A traveling doctor attempted to remove her tumors in April 1900, performing the operation with her laid on the family dinner table, but she died during the procedure. The death was an emotional blow to Minton; thereafter, he refused to attend church and spoke against God, whom he blamed for his mother's death. Minton's father married Sarah Montague on December 3, 1901.

As Minton grew older, he was frequently in trouble with the people in his neighborhood. In 1904, he was arrested for disregarding a town ordinance forbidding bicyclists to ride on the sidewalk. He was taken before a justice of the peace and fined three dollars, an incident he later credited with changing his outlook on life and sparking his desire to become a lawyer. To accomplish that goal, and continue supporting his family, he traveled with his older brother Herbert to Fort Worth, Texas, to take a job at the Swift and Company meat packing plant. His father and younger siblings soon joined him in Texas after the two brothers' income was able to cover their expenses. After saving enough money to help establish the family in a new home, Minton returned to Indiana to attend high school, leaving his family in Texas.

Minton started at Edwardsville High School in 1905, aged fourteen. The following year the school was consolidated with nearby New Albany High School. There, he participated in the football, baseball, and track teams. He founded the school's first debate club, the Wranglers, which won several awards. He worked in a local arcade, and during summer vacations returned to Fort Worth to work at the Swift plant. He was briefly expelled from school after committing a prank in February 1908. The school was under the guidance of the innovative Superintendent Charles Allen Prosser, who only let Minton return after he formally apologized before the entire school a week later. Minton began dating Gertrude Gurtz in his senior year, and the two remained in regular correspondence after he left for college. He graduated high school at the top of his class in 1910.

Minton was intent on attending college; during the summer of 1910, he took a job as a Swift Company salesman in the Fort Worth area to help pay his way. He returned to Indiana and enrolled at Indiana University Bloomington in September 1911, taking enough classes to complete his first three years of courses in two years. Despite the heavy workload, he joined the school's baseball and debate teams, and participated in the campus' Jackson Club, an organization for Democrats. His college years were formative and had significant influence on his future political career. He became friends with future Governor of Indiana Paul V. McNutt, future presidential candidate Wendell L. Willkie, and several other men who later became influential in the state. During his second year he ran out of money, but could not return to Texas to earn more because of his class schedule. He lodged in the Phi Delta Theta (ΦΔΘ) international fraternity house and subsisted mostly on wild berries, leftover bread from the cafeteria and free milk. He completed undergraduate school at the top of his class in 1913. In 1915, he graduated from the Indiana University School of Law in Bloomington, at what is now known as the Indiana University Maurer School of Law. During law school, he played end and fullback for the Indiana University football team.

Minton ranked first in his class. This placement entitled him to serve as librarian at the legal college. The position paid a fair salary and allowed him to live more comfortably for his last two years of school. He graduated from law school in 1915, again at the top of his class, and won a one-year scholarship to take post-graduate courses at Yale Law School, where he earned a Master of Laws degree. While at Yale, he focused on studying constitutional law and attended the regular lectures of former President of the United States and future Chief Justice of the United States William Howard Taft. His LL.M. thesis at Yale was entitled "Theory of the Action." Taft remarked that Minton's post-graduate thesis was among the best he had ever read. Along with Lewis F. Powell Jr., Minton is one of two United States Supreme Court justices to have earned an LL.M. degree. Minton continued to improve his oratory skills and continued debating at Yale; he won the Wayland Club prize for extemporaneous public speaking, and helped organize the university's legal aid society. He earned a post-graduate master's degree from Yale Law School in 1916.

In May 1916, Minton returned to New Albany, where he opened a law practice and renewed his relationship with Gurtz. He took several cases and gained experience working pro bono to assist the local county prosecutor. He joined the Chautauqua lecture circuit, and traveled to several cities to give speeches. During one lecture circuit, he met William Jennings Bryan. The three-time Presidential candidate advised the young Hoosier about politics, inspiring him to consider a career in public life.

In 1917, just after the United States declared war on Germany and entered World War I, Minton enlisted in the United States Army. He took an officers training course at Fort Benjamin Harrison in hope of earning a commission, but was not among those chosen to become an officer. In August he was granted a brief leave of absence; he returned to New Albany, where he married Gurtz on August 11. He returned to camp in September and requested to repeat his training course, still hoping to receive a commission; after finishing the training he was commissioned as a captain. The American Expeditionary Forces, Eighty-fourth Division, to which Minton belonged, was dispatched to France in July 1918. Minton and his unit served on the Western Front at Verdun, Soissons, and later protecting supply lines in Belgium. During most of his time in the war, his unit was responsible for scouting roads to ensure safe transport of men and supplies to the front lines. He saw no combat.

When President Woodrow Wilson came to Paris in 1919, Minton was in charge of a security detail guarding the negotiation hall and was able to meet Wilson. When the war ended, Minton remained briefly with the Army of Occupation in Germany before being discharged in August 1919. He chose to remain in Paris for several months to study Roman law, international law, civil law and jurisprudence at the University of Paris. He returned home in March 1920. The first of Minton's three children, Sherman Jr., was born while he was away. Minton's daughter Mary-Anne was born in 1923, and his second son, John, in 1925.

When Minton returned home he reopened his law practice and decided to enter politics. He ran for office in Indiana's 3rd congressional district, but lost the Democratic primary, despite significant campaigning and his war record. He lost to John Ewing, 6,502 votes to 3,170, second place in a field of five candidates. After the loss, he briefly joined the Indiana law firm of Stonsenburg and Weathers, two politically active lawyers, before moving to Miami, Florida, where he joined another firm, Shutts & Bowen. In January 1928, he left the Miami practice and returned to Stonsenburg and Weathers. He attempted to secure the Democratic nomination to run for Congress in 1930, but was again defeated, this time by the former state party chairman Eugene B. Crowe.

The following year, Minton became a local commander of the American Legion. The group had a large and active membership in the state at the time, and he used his position to encourage support of Democratic Party agenda. Paul McNutt was the national commander, and the two men became political allies. When McNutt became governor in 1930, he offered Minton a position at the head of a new utility regulation commission. As commissioner, Minton successfully imposed regulations that reduced state telephone bills by a combined total of $525,000. The cuts received widespread media coverage, and Minton was credited in the reports with the success.

Becoming popular among the party leadership during his two years as commissioner, Minton was encouraged by party leaders to run for the United States Senate in 1934. At the state Democratic Party Convention he ran against Earl Peters, a former chairman of the state party. With the support of McNutt, Minton won the nomination on the third ballot with 827 votes to Peters' 586.

Minton launched a statewide campaign in August 1934 and began delivering speeches in defense of the New Deal. He blamed Republicans for the conditions of the Great Depression. His opponent, incumbent Republican Senator Arthur Raymond Robinson, accused Minton of playing "Santa Claus" by trying to give everyone "presents". He also criticized Minton's support of the New Deal, which Robinson and Republicans called unconstitutional. Minton's initial campaign slogan was "You can't offer a hungry man the Constitution", a slogan he unveiled in a debate with Robinson in Corydon on August 11. He continued using the slogan, and on September 11, Minton delivered his infamous "You Cannot Eat the Constitution" speech, in which he concluded the urgent needs of the masses outweighed the need to uphold the constitution. The speech backfired wildly and papers and opponents across the state called Minton's remarks traitorous. Minton stopped using the slogan and explained his position again using new terms, but his opponents continued to dog him over the issue. The Republicans also faulted popular governor McNutt and his reorganization of the government, and McNutt became more personally involved in the election. With the state party's more direct involvement, Minton won the election with 52 percent of the vote.

Minton took his Senate seat in January 1935. As a freshman, he sat in the back row of the chamber next to fellow freshman Harry Truman, and the pair quickly became friends. Minton was made a member of a special Lobby Investigation Committee chaired by Senator Hugo Black, that was set up to look into questionable lobbyist groups. According to professor of political science Linda C. Gugin, a Minton biographer, in practice the committee's investigations were politically motivated and directed against groups that were challenging New Deal legislation.

William Randolph Hearst, a prominent and wealthy media magnate, began using his newspapers to deride the committee's "reckless attacks on freedom". Minton led the effort to counter Hearst and delivered a speech criticizing his support of the Republican Party. In 1937, Senator Black was appointed to the Supreme Court and left the Senate, and Minton secured his post as chair of the committee. Minton immediately began a full-scale investigation of the media conglomerate controlled by Frank E. Gannett, accusing him of publishing Republican Party propaganda. For several weeks, Minton delivered speeches against Gannett in the Senate, and Gannett responded in kind in his newspapers. Minton finally introduced legislation that would have made it "illegal to publish information known to be false". Gannett, and a large number of allies in newspapers and on radio, immediately began to charge Minton and the Democratic Party with an assault on the freedom of the press. Minton's allies in Congress asked him to withdraw the bill because of its political repercussions, and he dropped the matter.

Minton tried again to expose what he believed to be Republican control of the media. He led the committee to target a newspaper with national circulation, "Rural Progress". Minton accused the publishers of improperly accepting large sums of money from corporations and the editors of undue influence from this money. The owner of the paper, Maurive V. Renolds, was summoned before the committee for a hearing, where Minton demanded to know why he was accepting money from corporations. When Renolds asked his manager, Dr. Glen Frank, to help him answer the questions, Minton and fellow Democratic senators began to shout Dr. Frank down. As he was saying that the money from the corporations was for advertising in the magazine, Minton beat his gavel and yelled, "This committee doesn't intend to permit you to use this as a forum to air your Republican views."

Minton did not realize that Frank was also president of the University of Wisconsin, and soon suffered retaliation for the way he had treated Frank. Frank went on NBC radio stations around the country and lambasted Minton for his rudeness. He made lengthy arguments accusing Minton of attempting to violate the Bill of Rights. Minton was outraged, but the arguments had an effect among voters in Indiana. In 1938, he sought funding to launch a massive nationwide investigation of media conglomerates for proof of Republican interference in the press. Democratic Senator Edward R. Burke led an effort to defeat the measure and privately accused Minton of damaging the Democrats' cause, which led Minton to leave the Lobby Investigation Committee.

Minton was a fierce partisan during his time in the Senate, and regularly abused his opponents verbally. Democratic Senator Huey Long became one of Minton's favorite targets because of Long's often-threatened filibusters. During one of the filibusters, Long threatened to join the Republican Party. After most senators had left the chamber, Minton remained for several hours to periodically taunt Long. After tiring of the taunts, Long launched a rebuttal from the podium, calling Minton a vicious politician whose positions would cost Minton re-election. The exchange was unusual for its tone and later made national news.

Minton was involved in many such exchanges, including a particularly fierce one with Republican Senator Lester J. Dickinson in March 1936. Dickinson delivered a speech in the Senate castigating President Franklin D. Roosevelt for carrying out what he termed illegal and unconstitutional acts. Minton responded with a range of accusations, some personal, against Dickinson and his "political naivety".

In 1936, the United States Supreme Court ruled the Agricultural Adjustment Act of 1933 unconstitutional. For the first time, Minton gave speeches criticizing the court for overriding the will of Congress. He accused the court of allowing itself to be influenced by political motives rather than the law. In response to the court ruling, Minton began drafting a bill which would allow the Supreme Court to declare a law unconstitutional only if seven out the nine justices supported the decision. In February 1937, before Minton introduced his bill, President Roosevelt introduced a plan of his own to deal with the Supreme Court. Roosevelt proposed adding more justices to the court and creating a mandatory retirement age; the changes would allow him to appoint an overwhelming majority to the court, more sympathetic to his agenda, ensuring the safety of legislation passed by his party.

Minton was pleased with Roosevelt's bill and quickly became its leading supporter in the Senate. The measure was placed in an omnibus bill designed to reform judicial salaries and districting, among many other measures. Republicans quickly discovered the court-packing provision and targeted the bill. Democrats had overwhelming super-majorities in Congress, and passage of the bill at first seemed assured. Minton's support of the bill helped him earn the position of Senate majority whip, allowing him to more effectively push for its passage. Minton delivered six radio addresses on behalf of his party in support of the bill, but public opinion could not be swayed in the Democrats' favor.

Minton received a death threat in the form of an envelope containing a shotgun shell and a message advising him to not vote for the court packing plan. Many Democrats, fearing their re-election prospects, joined with Republicans and defeated the bill. Minton was unhappy with the loss and it cost him considerable support among his voters, but as a result of his close connection with the bill and the leaders of his party, he gained more influence with the Democrats.

Although Minton supported the Roosevelt Administration and became a regular guest at the White House, Minton opposed the president on some measures. He voted to override a presidential veto of a grant of $2.5 ($ billion in 2015 dollars) in bonus pay for World War I soldiers (Bonus Army). He supported the Dyer Anti-Lynching Bill, which Roosevelt feared would cost the party support in the southern states. He also supported an extension of the Hatch Act of 1939, a law that prevented federal employees from being forced to take part in state election campaigns, effectively lessening the influence of federal patronage.

As World War II neared, Minton took a cautious position on United States involvement. When the Soviet Union invaded Finland, Minton voted against granting a loan to Finland to help finance its defense efforts. He also opposed selling munitions and weapons to the Allies or the Axis powers. He advocated and supported expanding the American military and believed that American entry into the war was inevitable, but should be delayed as long as possible. He voted in favor of the Smith Act, which made it a crime to advocate the overthrow of the government, a law specifically targeted at communists and fascists in the United States. In his final year in office, there was considerable speculation in the press that Minton would be named to higher office by Roosevelt, including cabinet positions and the Supreme Court, but neither happened.

Minton ran for re-election to his Senate seat in 1940. McNutt was challenging Roosevelt for the Presidential nomination, forcing Minton to choose between the administration and his allies in the state party. Minton sided with Roosevelt, which cost him McNutt's and the Indiana Democratic Party machine's support in his re-election bid.

The Republican presidential candidate, Wendell Willkie was also a native of Indiana, and Minton faced a difficult challenge to win re-election. He referred to Willkie as a "sycophant for the rich and famous". Willkie never responded to Minton's taunts, leaving Minton's opponent in the Senate race, Raymond E. Willis, to respond to Minton's charges. Willis had run for the Senate two years earlier but was defeated by Democrat Frederick Van Nuys. Willis faulted Minton on a range of topics but focused on the legislation Minton supported while in the Senate. Willis claimed that much of the legislation was unconstitutional and Minton's positions were detrimental to the nation. Minton responded by pointing out Willis's connections to wealthy corporations and accused him of not caring for the people. Minton's campaign focused on the achievements of the New Deal programs. He claimed farm income in Indiana had doubled since 1932, and highlighted the passage of the Old Age Pension laws. His support for conscription and military preparedness for the coming war proved unpopular with voters and cost him considerable support, but according to historian William Radcliff it was Willkie's favorite son status, which led many Hoosiers to vote Republican, that proved to be the election's deciding factor. Despite Minton's heavy campaigning, he lost the close election to Willis by 5,179 votes out of over 1.5 million cast.

Roosevelt won the 1940 presidential election. After Minton left office in January 1941, he was given a position in the Roosevelt administration as a reward for his loyalty during the court packing failure. He served as one of the president's advisers and a liaison between the White House and Congress. The extent of his duties is not fully known; Linda Gugin has speculated that he may have managed Roosevelt's patronage system. Minton was responsible for getting several officials appointed to high offices in the federal bureaucracy and numerous others appointed to lower ranking positions. He also convinced Roosevelt to support the creation of a Senate defense committee chaired by Truman, a position that brought Truman into the national spotlight and helped him gain the vice presidency.

On May 7, 1941, Roosevelt announced Minton's nomination to the Chicago-based United States Court of Appeals for the Seventh Circuit. Minton was confirmed unanimously by the Senate on May 12, 1941, and received his commission on May 22, 1941. Minton resigned from his post in the administration, but even after he began working on the court, Minton remained active in Democratic politics behind the scenes and was in regular correspondence with Roosevelt to make patronage suggestions.

Minton took his oath of office on May 29, 1941, but the court was in recess at the time. He took his seat when it returned to session on October 7, 1941. The court had the highest court load of all the appellate courts in the nation at that time, averaging 40 cases per judge annually. The men on the court were close friends, and Minton developed a particularly close friendship with Judge J. Earl Major; Major offered Minton financial assistance during his later illnesses. Major had been on the court for several years and held a judicial philosophy similar to Minton's. The two men regularly attended baseball games and were frequent guests in each other's homes.

World War II broke out shortly after Minton joined the court, creating a flood of cases in which legal precedent provided little guidance, including challenges to wartime measures, selective service laws, price controls, rationing and civil liberties. In the majority of these cases, the court affirmed the decisions of the district courts, but in several the court was required to establish a precedent. Minton stated on several occasions his personal preference to affirm the decisions of the lower courts. He believed that the court that heard the case and pronounced judgment was generally able to make a decision that was superior to appellate courts' decisions. He believed the appellate process should be reserved for the more serious cases and cases where the lower court had clearly made a mistake.

Minton was described by William Radcliff as a "faithful disciple of judicial restraint," an unexpected development when compared to his overtly partisan political career. Radcliff attributed Minton's conservative position to the distaste he developed for the courts when they overturned legislation passed while he was in the Senate. The courts actions led him to strongly believe in the limited exercise of judicial power when evaluating the constitutionality of governmental conduct. Much of the recently passed New Deal legislation was being tried in the courts for constitutionality and enforcement, putting Minton in the uncommon position of adjudicating cases depending on legislation he had helped write.

During his time on the Seventh Circuit, Minton authored 253 of the court's opinions, including twelve dissenting opinions. Some of his opinions won praise; the editors of "Tax Magazine" commented favorably on Minton's opinions on tax law, calling them "direct Hoosier logic". Other court reporting papers made similar comments, applauding the manner in which he turned complex issues to simple questions that could easily be understood.

In the case of "Sunkist v. Sunkist" and "Quaker Oats Co. v. General Mills", the court created a long-standing precedent in their decision making it possible for different companies to use the same brand and product name as long as they produced dissimilar products. In another case, the court set a short-lived precedent allowing companies to artificially raise prices in local markets if the purpose was to artificially lower prices in another market to remain competitive. After Minton joined the United States Supreme Court, the decision was appealed to that body; Minton recused himself from the case, which the court decided to overturn. In another decision, Minton was in the majority that ruled under the Sherman Antitrust Act that the New York Great Atlantic and Pacific Tea Company was a monopoly, ordering the company to break up its grocery business. Minton was also in the majority in several cases filed to enforce decisions made by the National Labor Relations Board, usually to end worker strikes.

In the case of "United States v. Knauer", the government was denying the wife of a United States citizen entry into the country because of her possible ties to Nazism. In a much criticized majority opinion which Minton co-authored with Judge Major, he stated that the "alien did not have any legal right—[her] status was a political decision to be made by officials in government." Many liberals condemned the court at the time of the decision. The case ruling was upheld by the Supreme Court in a 1946 appeal.

One of Minton's favorite cases was that of "Modernistic Candies, Inc. v. Federal Trade Commission". The candy company produced a one-cent gumball dispenser in which almost all the gumballs were the same color. A few different-colored gumballs were included which, when dispensed, entitled the purchaser to a prize from the merchant who owned the machine. The FTC had an injunction put in place barring the company from producing the machines because they claimed it violated anti-gambling laws. Minton wrote the majority opinion and sided with the majority to keep the injunction in place, but dryly mocked the counsel for the defense and the gambling law, stating:

Counsel for the petitioner discussed at great length from a sociological point of view, of the age-old problem of the gambling instinct in the human being. According to his analysis, gambling pervades our entire economic system; thus insurance contracts are a gamble, stock and grain exchange transactions are gambles, and the farmer's dependence on weather is a gamble. Counsel's attempt to apply this analysis to the present case left us cold and unimpressed. He even reminded us that our great idol, Mr. Chief Justice John Marshall, in his day attended the horse races and wagered with his clergyman. In fact, they ran a book. As indicating how times have changed and how even our coarse nature has yielded to the protecting care of governmental policy, we confess we do not even know a bookmaker, clerical or otherwise, and our passes to the beautiful race tracks around Chicago lie in our desk unused.

Minton often lamented that he was required to "pronounce the law as it was written, but on no occasion [c]ould he make the law."

After Roosevelt's death and Truman's succession to the Presidency, Minton continued offering advice to the new administration on a range of topics, including patronage and political maneuvering. Truman appointed Minton as head of the War Department Clemency Board, a panel of judges charged with overseeing reviews of decisions made by the courts-martial. The panel met every two weeks which, along with his responsibilities on the circuit court, kept Minton very busy and afforded him little rest, leading to a deterioration in his health. While yachting with President Truman on Memorial Day in 1945, Truman asked Minton to accept an appointment to the position of Solicitor General of the United States. Minton declined because of his health, but he told Truman he would be interested in a seat on the Supreme Court.

In September 1945, Minton suffered a heart attack while in Washington; he was hospitalized for three months at Walter Reed Hospital. After returning to work, he was forced to rest regularly due to gradually worsening anemia, and he sought to lessen his workload. To further complicate his health, on August 5, 1949, Minton tripped over a stone in his yard and broke his leg. The injury forced him to walk with a cane for the remainder of his life.

At a September 15, 1949, news conference, Truman announced Minton's nomination to the Supreme Court, succeeding the deceased Justice Wiley Rutledge. Minton had already privately accepted the nomination several days earlier after a telephone conversation with Truman. Truman touted Minton's extensive law education and his years of experience on the circuit courts as the reason for his nomination.

News of Minton's appointment received mixed reviews nationally. "The New York Times" said that Truman had allowed personal and political friendship to influence his choice. "The New Republic" said "the President is again reverting to his deplorable habit of choosing men for high post because they happen to be his friends...". The "Washington Post" raised questions about Minton's ability to be confirmed by the Senate due to the power many of his foes held in the body. The "Indianapolis Star" offered a more sympathetic opinion, pointing out Minton's qualifications and the pride Indiana could take in having a native on the Supreme Court. The article noted that he would be the most educated justice on the court, should he be confirmed.

Indiana Senator William E. Jenner led opponents of Minton's nomination, including some of Minton's old foes, in an attempt to bring him before the body for hearings. Minton wrote a letter to the Senate Judicial Committee answering several of their questions, but refused to submit himself to a hearing. He mentioned his broken leg and hinted in his letter that it could be detrimental to his health to travel in his condition. He also stated that, as a sitting judge and former member of the Senate, it would be improper for him submit to a hearing. Although hearings had occurred irregularly in the past, it was not customary at that time to have a hearing on a nominee. During an absence of Jenners, Minton's allies worked to have the hearing request dropped and the Judicial Committee sent the measure to the full Senate in a vote of 9 to 2. Senator Homer S. Ferguson attempted to have the nomination returned to committee but the motion failed, 45–21. The long debate over Minton's appointment focused on his partisanship, support of the court packing plan during his time in the Senate, and poor health. His opponents launched numerous delaying tactics; the Senate session before the vote to confirm Minton lasted until midnight. His confirmation was approved 48–16 on October 4, 1949 and he received his commission on October 5, 1949. To date, Minton remains the last member of Congress, sitting or former, to be appointed to the United States Supreme Court, and he is the only native of Indiana to be appointed to the court.

Minton's central judicial philosophy was to ascertain and uphold the original intent of legislation. He continued to take a broad view of governmental powers, demonstrated in his dissenting opinion in the case of "Youngstown Sheet & Tube Co. v. Sawyer", which ruled unconstitutional President Truman's wartime seizure of several steel mills to avert a workers' strike. Of all the cases in which Minton was involved, he disagreed most with the Youngstown decision and "went into a tirade" during the conference where the decision was made. He argued that there "could be no vacant spot in power when the security of the nation is at stake." Despite his strong protest, he could not influence the Court to permit the president to seize the plants without congressional approval. Minton joined with Chief Justice Fred M. Vinson and Justice Stanley Forman Reed in the dissenting opinion that the President had the authority through the war powers clause of the constitution.

Minton abhorred racial segregation and provided a solid vote to strike down the school segregation practices at issue in 1954's landmark case of "Brown v. Board of Education"; it was among the few decisions in which he sided against the government. According to William Radcliff, the majority opinion authored by Minton in the 1953 case "Barrows v. Jackson" was his most skillfully written opinion. He framed the complex question of the case as: "Can a racially restrictive covenant be enforced at law by a suit for damages against a co-covenantor who allegedly broke the covenant?" The Court decided the answer in the negative.

In the area of civil liberties, Minton adhered to the doctrine of "fundamental fairness", a test established by the Supreme Court in 1937. In one decision, Minton stated that the right of free speech was not an absolute right, and could be regulated so as not to violate the rights of others. In "United States v. Rabinowitz", Minton wrote the Court's opinion upholding a lower court ruling which allowed police to search automobiles without a warrant, provided there was probable cause to justify the search.

Minton voted to uphold anticommunist legislation during the period of the "red scare", siding with the majority in 1951's "Dennis v. United States", which upheld the conviction of the leader of the US Communist Party. During the same period, the Court was split over the legality of governmental loyalty tests. Many agencies had programs in place to ensure that members of the government were not communists. Minton's vote proved to be the deciding factor in cases regarding loyalty tests. In the case of "Bailey v. Richardson", Minton's vote upheld the legality of the loyalty tests, while in the decision he authored in the case of "Joint Anti-Fascist Refugee Committee v. McGrath", he voted to uphold the plaintiff's position that he had been terminated illegally because of his support of fascist ideology. Minton's position gradually shifted to allowing the loyalty tests to take place, and in "Adler v. Board of Ed. of City of New York" he wrote the majority opinion allowing the tests and upholding New York's Feinberg Law. This proved to be the most important vote as it allowed the tests to be given with only minimal suspicion of a person's disloyalty to the government.

Because of Minton's previous Congressional partisanship, many liberals believed he would support their positions when on the Court. Throughout his tenure, Minton regularly disappointed them, leading many to rail against him. A lawyer writing for the "New Jersey Law Journal" labeled Minton a "spokesman against freedom", calling him "a man of conspicuous judicial shortcomings, whose votes against civil liberties exceeded those of any other man on the Court, and who wrote comparatively few opinions of other kinds." Linda Gugin pointed out that Minton was a disappointment to liberals because he consistently chose order over freedom. Gugin also concludes that Minton had the strongest commitment to judicial restraint and ideological neutrality of any justice, past or present.

Although Minton was on the Supreme Court, he remained casually involved in Democratic internal politics. He wrote Truman several letters criticizing Justices Robert H. Jackson and Hugo Black, referring to Black as a demagogue. He also offered advice on dealing with Republican opposition in the Senate. In a 1954 letter, after Truman left office, he urged Truman to help focus public attention on the economy and away from communism, a threat he claimed the Republicans were exaggerating to avoid confronting their own problems.

After Truman's withdrawal from the 1952 presidential campaign, Minton made remarks indicating he had advised Truman to stay out of the contested New Hampshire primary election to begin with. In August 1956, a reporter asked Minton about his preferred candidate in the upcoming presidential election. Minton answered, "I have great confidence in Adlai Stevenson." He also remarked that Dwight D. Eisenhower was politically handicapped. Minton was lambasted in the media for his endorsement, which he attempted to retract a few days later after being advised to do so by other members of the Court.

Truman's other appointees to the Court provided consistent conservative votes, and during Minton's first years on the Court it was returned to the conservatism of the William Howard Taft era. While on the Court, Minton transformed from a New Deal senator into an almost reactionary judge as an ally of Justice Felix Frankfurter. Empirical coding of votes shows that Minton was the most conservative justice on the Court during his first year, and remained in the conservative half of the court for the duration of his career.

Minton did not enjoy the limited influence of his judicial role in the later years of his term, when he was more frequently in the minority in voting on cases. After the deaths of Chief Justice Fred M. Vinson and Justice Robert Jackson, Minton found himself with little support for many of his opinions, which led him to begin considering retirement.

The shifting position of the Court led to personal animosity between members of its two wings. Despite his disappointment over the Court's positions on some issues, Minton remained popular among his colleagues on the Court as he didn't take sides in their personal disagreements; he proved a soothing presence during a period marked by bitter personal feuds between strong personalities such as William O. Douglas and Felix Frankfurter.

Minton informed Eisenhower of his intention to retire in a letter on September 7, 1956, in which he dryly stated his retirement was authorized by law. Eisenhower responded with a brief note wishing him a happy retirement. Although he did not tell the president, Minton informed the members of the Court that his duties were too taxing on his health. His anemia had steadily worsened, slowing him physically and mentally. Minton served as a Justice until October 15, 1956, retiring after 7 years and 3 days of service. He was succeeded by William J. Brennan Jr.

Announcing his departure, Minton remarked, "There will be more interest in who will succeed me than in my passing. I'm an echo." Despite the health difficulties, Minton regretted his decision almost immediately.

Minton returned to his New Albany home, where he took a much lighter workload. He gave occasional lectures at Indiana University and continued to give public speeches from time to time. For several years after retiring from the Supreme Court, Minton occasionally accepted assignments to serve temporarily on one of the lower federal courts. He received an honorary doctorate degree from the University of Louisville. He took many trips around the United States, and two trips to Europe. In England, he received an honorary doctorate from Oxford University in 1956.

Despite his failing health, Minton remained active in the Democratic Party. He was most concerned with President Eisenhower, who he believed was incompetent. He remained in regular correspondence with Truman, and the two met on several occasions at Democratic Party functions.

In late March 1965, Minton was admitted to Floyd Memorial Hospital in New Albany, where it was found he was suffering internal bleeding. He died in his sleep early in the morning of April 9. Minton's wife was Roman Catholic; his funeral was held at the now-defunct Holy Trinity Catholic Church and was attended by many dignitaries, including several sitting members of the Supreme Court, the governors of Indiana and Kentucky, and several members of Congress. He was buried in the Holy Trinity Cemetery, on Green Valley Road in New Albany. Minton himself was nominally Catholic and had shunned Christianity for most of his life; he only began to occasionally attend mass following his retirement. He left most of his personal papers and judicial records to the Truman Presidential Library.

Minton is the eponym of the Sherman Minton Bridge, which carries Interstate 64 across the Ohio River, connecting western Louisville, Kentucky with New Albany, Indiana. Minton attended the dedication of the bridge at a 1962 ceremony. He is also the namesake of the annual Sherman Minton Moot Court Competition, held at the Indiana University Maurer School of Law. He is also honored (with Indiana Senator Homer E. Capehart)—in the "Brutalist" style designed by Woollen, Molzan and Partners and with architectural art by Milton Glaser—in the centrally located Minton-Capehart Federal Building on Indiana World War Memorial Plaza in Indianapolis. A bronze bust of Minton was created and put on display in the Indiana Statehouse.

While some writers like Linda Gugin and legal historian William Radcliff have given high praise to Minton's logic in his written opinions, they point out that his positions had little long-term impact. Other legal historians, like Bernard Schwartz, have more negative opinion of Minton's judicial career. Schwartz wrote that Minton "was below mediocrity as a Justice. His opinions, relatively few for his tenure, are less than third rate, characterized by their cavalier approach to complicated issues." Schwartz went on to say, "he ranks near the bottom of any list of Justices." Most of the precedents Minton helped establish were overturned by the Warren Court in the years immediately following his retirement. In total he wrote sixty-seven majority opinions along with several of the dissenting opinions. Gugin authored a work in rebuttal to Schwartz's harsh critique, saying that Minton's rulings were "predictable based on the principles of deference, precedent, and strict interpretation"; she attributed his poor ranking to the bias of reviewers in favor of judicial activism.

Minton's time on the court marked the end of a transitory period in the judiciary. Since Minton, justices have tended to serve increasingly longer terms on the court, which has had strong political science implications on the Supreme Court. The growing concept of judicial non-partisanship became the norm in American politics after Minton—he was the last member of Congress of be appointed to the court. Linda Gugin and Professor James St. Clair have noted that the federal courts have lost a valuable point of view by not having experienced legislators among their ranks.

Minton played an important role behind the scenes of the Court as a peacemaker between its two opposing factions. These attempts to keep the peace led Justice Frankfurter to remark that while Minton would never be remembered as a great justice, he would be remembered as a great colleague by his fellow justices.





</doc>
<doc id="259110" url="https://en.wikipedia.org/wiki?curid=259110" title="Bodiam Castle">
Bodiam Castle

Bodiam Castle () is a 14th-century moated castle near Robertsbridge in East Sussex, England. It was built in 1385 by Sir Edward Dalyngrigge, a former knight of Edward III, with the permission of Richard II, ostensibly to defend the area against French invasion during the Hundred Years' War. Of quadrangular plan, Bodiam Castle has no keep, having its various chambers built around the outer defensive walls and inner courts. Its corners and entrance are marked by towers, and topped by crenellations. Its structure, details and situation in an artificial watery landscape indicate that display was an important aspect of the castle's design as well as defence. It was the home of the Dalyngrigge family and the centre of the manor of Bodiam.

Possession of Bodiam Castle passed through several generations of Dalyngrigges, until their line became extinct, when the castle passed by marriage to the Lewknor family. During the Wars of the Roses, Sir Thomas Lewknor supported the House of Lancaster, and when Richard III of the House of York became king in 1483, a force was despatched to besiege Bodiam Castle. It is unrecorded whether the siege went ahead, but it is thought that Bodiam was surrendered without much resistance. The castle was confiscated, but returned to the Lewknors when Henry VII of the House of Lancaster became king in 1485. Descendants of the Lewknors owned the castle until at least the 16th century.

By the start of the English Civil War in 1641, Bodiam Castle was in the possession of Lord Thanet. He supported the Royalist cause, and sold the castle to help pay fines levied against him by Parliament. The castle was subsequently dismantled, and was left as a picturesque ruin until its purchase by John Fuller in 1829. Under his auspices, the castle was partially restored before being sold to George Cubitt, 1st Baron Ashcombe, and later to Lord Curzon, both of whom undertook further restoration work. The castle is protected as a Grade I listed building and Scheduled Monument. It has been owned by The National Trust since 1925, donated by Lord Curzon on his death, and is open to the public.

Edward Dalyngrigge was a younger son and thus deprived of his father's estates through the practice of primogeniture, hence he had to make his own fortunes. By 1378, he owned the manor of Bodiam by marrying into a land-owning family. From 1379 to 1388, Dalyngrigge was a Knight of the Shire for Sussex and one of the most influential people in the county. By the time he applied to the king for a licence to crenellate (build a castle), the Hundred Years' War had been fought between England and France for nearly 50 years. Edward III of England (reigned 1327–1377) pressed his claim for the French throne and secured the territories of Aquitaine and Calais. Dalyngrigge was one of many Englishmen who travelled to France to seek their fortune as members of Free Companies – groups of mercenaries who fought for the highest bidder. He left for France in 1367 and journeyed with Lionel, Duke of Clarence and son of Edward III. After fighting under the Earl of Arundel, Dalyngrigge joined the company of Sir Robert Knolles, a notorious commander who was reputed to have made 100,000 gold crowns as a mercenary from pillage and plunder. It was as a member of the Free Companies that Dalyngrigge raised the money to build Bodiam Castle; he returned to England in 1377.

The Treaty of Bruges (1375) ensured peace for two years, but after it expired, fighting resumed between England and France. In 1377 Edward III was succeeded by Richard II. During the war, England and France struggled for control of the English Channel, with raids on both coasts. With the renewed hostilities, Parliament voted that money should be spent on defending and fortifying England's south coast, and defences were erected in Kent in anticipation of a French invasion. There was internal unrest as well as external threats, and Dalyngrigge was involved in suppressing the Peasants' Revolt of 1381. The manor of Bodiam was granted a charter in 1383 permitting a weekly market and an annual fair to be held. In 1385, a fleet of 1,200 ships – variously cogs, barges, and galleys – gathered across the English Channel at Sluys, Flanders; the population of southern England was in a state of panic. Later in the year, Edward Dalyngrigge was granted a licence to fortify his manor house.

Dalyngrigge's licence from Richard II permitted him to refortify his existing manor house, but instead he chose a fresh site to build a castle on. Construction was completed in one phase, and most of the castle is in the same architectural style. Archaeologist David Thackray has deduced from this that Bodiam Castle was built quickly, probably because of the threat from the French. Stone castles were usually time-consuming and expensive to build, often costing thousands of pounds. Dalyngrigge was Captain of the port of Brest in France from 1386 to 1387, and as a result was probably absent for the first years of the castle's construction. It replaced the old manor house as Dalyngrigge's main residence and the administrative centre of the manor. It is not recorded when Bodiam Castle was completed, but Thackray suggests that it was before 1392; Dalyngrigge did not have long to spend in the completed castle, as he was dead by 1395.

Danlyngrigge's estates, including the castle, were inherited by his son, John Dalyngrigge. Like his father, John enjoyed the favour of the king and was described as the "King's Knight"; in 1400 he was granted an annual allowance of 100 marks by the king. He died on 27 September 1408; his will ensured that his property belonged to his widow, Alice. John and Alice had no children, so on her death in 1443 the estates and castle were passed on to Richard Dalyngrigge, John's cousin. Richard died without issue, so in accordance with John's will the estates passed on to Richard's sister Philippa in 1470. She was married to Sir Thomas Lewknor, from a prominent Sussex family who owned land all over the country.
Sir Thomas Lewknor was a supporter of the House of Lancaster during the Wars of the Roses, which began in 1455. When Richard of the House of York ascended to the throne as Richard III in 1483, Lewknor was accused of treason and of raising men-at-arms in southeast England. In November 1483, Lewknor's uncle and Thomas Howard, the Earl of Surrey, were given permission to levy men and besiege Bodiam Castle, where Lewknor was based. It is not recorded whether the siege went ahead, and Thackray suggests that Lewknor surrendered without much resistance. His property was confiscated, and Nicholas Rigby was made constable of the castle. On Henry VII's accession to the English throne the attainder was revoked, and Bodiam Castle was returned to Lewknor. However, not all the surrounding land was returned to the family until 1542. Possession of Bodiam Castle passed through several generations of the Lewknor family. Although the inheritance of the castle can be traced through the 16th and 17th centuries, there is little to indicate how it was used in this period, or if the family spent much time in it.

Following the death of Sir Roger Lewknor in 1543, his estates were divided among his descendants, and the castle and manor were split. John Levett of Salehurst purchased the castle in 1588. In 1623, most of the estates of Bodiam were bought by Sir Nicholas Tufton, later Earl of Thanet. His son, John Tufton, 2nd Earl of Thanet, inherited Nicholas's property on his father's death in 1631; it was John Tufton who reunited possession of castle and manor when he bought Bodiam Castle in 1639. John Tufton was a supporter of the Royalist cause during the English Civil War, and led an attack on Lewes, and was involved in a Royalist defeat at Haywards Heath. Parliament confiscated some of his lands in 1643, and more in 1644, as well as fining him £9,000 (£ today). To help pay his fine, Tufton sold Bodiam Castle for £6,000 (£ today) in March 1644 to Nathaniel Powell, a Parliamentarian.

After the Civil War, Powell was made a baronet by Charles II. Although it is unrecorded when Bodiam Castle was dismantled (slighted), it was probably after it was bought by Powell. During and after the Civil War, many castles were slighted to prevent them from being reused. Not all were destroyed completely, and in some cases care was taken not to unnecessarily deface the structure. At Bodiam, it was deemed sufficient to dismantle the barbican, the bridges, and the buildings inside the castle. When Nathaniel Powell died in 1674 or 1675, Bodiam Castle was passed on to his son, also called Nathaniel. After the second Nathaniel, the castle came into the possession of Elizabeth Clitherow, his daughter-in-law.

In 1722 Sir Thomas Webster bought the castle. For over a century, Bodiam Castle and its associated manor descended through the Webster family. It was in this period that the site became popular as an early kind of tourist attraction because of its connection with the medieval period. The first drawings of Bodiam Castle date from the mid-18th century, when it was depicted as a ruin overgrown with ivy. Ruins and medieval buildings such as Bodiam Castle served as an inspiration for the revival in Gothic architecture and the renovation of old structures.

The third Sir Godfrey Webster began looking for buyers for the castle in 1815, and in 1829 he finally managed to sell it and of the surrounding land to John 'Mad Jack' Fuller for £3,000 (£ today). Fuller repaired one of the towers, added new gates to the site, and removed a cottage which had been built within the castle in the 18th century; he is thought to have bought the castle to prevent the Webster family from dismantling it and reusing its materials. George Cubitt, later Baron Ashcombe, purchased the castle and its from Fuller's grandson in 1849, for over £5,000 (£ today). Cubitt continued the renovations that Fuller started. He commissioned the first detailed survey of Bodiam Castle in 1864, and undertook repairs to the tower at the southwest corner of the site, which had almost entirely collapsed. Because there was then a fashion for ruins covered in ivy, the vegetation was not removed despite its detrimental effect on the masonry, and the trees which had taken root in the courtyard were left.
Lord Curzon decided that "so rare a treasure [as Bodiam Castle] should neither be lost to our country nor desecrated by irreverent hands". Curzon made enquiries about buying the castle, but Cubitt did not wish to sell. However, after Cubitt's death, Curzon was able to make a deal with Cubitt's son, and he bought Bodiam Castle and its lands in 1916. Curzon began a programme of investigation at Bodiam in 1919, and with architect William Weir restored parts of the castle. The moat, on average about deep but deep in the southeast corner, was drained and of mud and silt removed; during excavations the original footings of the bridges to the castle were discovered. Nearby hedges and fences were removed to provide an unobscured view of the castle. There were excavations in the interior, and a well was discovered in the basement of the southwest tower. Vegetation was cleared, stonework repaired, and the original floor level re-established throughout the castle. A cottage was built to provide a museum to display the finds from the excavations and a home for a caretaker. Bodiam Castle was given to the National Trust in 1925.

The National Trust continued the restoration work, and added new roofs to the towers and gatehouse. Excavations were resumed in 1970, and the moat was once again drained. Bodiam Castle was used in "Monty Python and the Holy Grail" in an establishing shot identifying it as "Swamp Castle" in the "Tale of Sir Lancelot" sequence. The Royal Commission on the Historical Monuments of England carried out a survey of the earthworks surrounding Bodiam Castle in 1990. In the 1990s, Bodiam Castle was at the centre of a debate in castle studies over the balance between militaristic and social interpretations of such sites. The arguments focused on elements such as the apparent strength of the defences – such as the imposing moat  – and elements of display. It has been suggested that the moat could have been drained in a day because the embankment surrounding it was not substantial, and that as such it did not pose a serious obstacle to an attacker. Also, the large windows in the castle's exterior were defensive weak points. The castle is a Scheduled Monument, which means it is a "nationally important" historic building and archaeological site which has been given protection against unauthorised change. It is also a Grade I listed building, and recognised as an internationally important structure. Today the castle is open to the public, and according to figures released by the Association of Leading Visitor Attractions, nearly 175,598 people visited in 2017. In the opinion of historian Charles Coulson, Bodiam "represents the popular ideal of a medieval castle".

The castle's location was ostensibly chosen to protect England's south coast from raids by the French. A landscape survey by the Royal Commission for Historic Monuments concluded that if this were the case, then Bodiam Castle was unusually sited, as it is far from the medieval coastline.
The area surrounding Bodiam Castle was landscaped when the castle was built, to increase its aesthetic appeal. Archaeologists Oliver Creighton and Robert Higham have described Bodiam as one of the best examples of landscaping to emphasise a castle. The water features were originally extensive, but only the moat survives, along with the earthworks left over from its construction. Roughly rectangular, the moat is supplied by several springs, some of them within it, which made it difficult to drain during the excavations of the 1930s. A moat can prevent attackers from gaining access to the base of a castle's walls, but in the case of Bodiam it also had the effect of making the castle appear larger and more impressive by isolating it in its landscape. The moat is now regarded more as an ornamental feature than a defence. The approach to the castle through the moat and satellite ponds was indirect, giving visitors time to view the castle in its intended splendour. Military historian Cathcart King describes the approach as formidable, and considers it the equal of the 13th-century castles of Edward I in Wales, such as Caerphilly Castle.

The castle sits roughly in the middle of the moat. The postern gate at the rear would have been connected to the moat's south bank by a drawbridge and a long timber bridge. The main entrance on the north side of the castle is today connected to the north bank by a wooden bridge, but the original route would have included two bridges: one from the main entrance to an island in the moat, and another connecting the island to the west bank. For the most part the bridge was static, apart from the section closest to the west bank, which would have been a drawbridge. The island in the moat is called the Octagon, and excavations on it have uncovered a garderobe (toilet), suggesting that there may have been a guard on the island, although it is unclear to what extent it was fortified. The Octagon was connected to a barbican by a bridge, probably a drawbridge. The castle's 28 toilets drained directly into the moat, which in the words of archaeologist Matthew Johnson would have been effectively an "open sewer".

A quadrangular castle, Bodiam is roughly square-shaped. This type of castle, with a central courtyard and buildings against the curtain wall, was characteristic of castle architecture in the 14th century. Bodiam Castle has been described by military historian Cathcart King as the most complete surviving example of a quadrangular castle. There are circular towers at each of the four corners, with square central towers in the south, east, and west walls. The main entrance is a twin-towered gatehouse in the north face of the castle. There is a second entrance from the south; the postern gate is through a square tower in the middle of the south wall. The towers are three storeys high, taller than the curtain walls and the buildings in the castle which are two storeys high.

Between the Octagon and the main gatehouse in the north wall was a barbican, of which little survives – just a piece of the west wall – although the structure was originally two storeys high. The surviving fabric includes a slot for a portcullis for the barbican's north gate, although there are no hinges for gates. The base of a garderobe demonstrates that second storey would have provided space for habitation, probably a guard room. Drawings from the late 18th century show the ground floor of the barbican still standing and includes detail such as vaulting inside the passageway.
The gatehouse in the castle's north wall is three storeys high; now reached by a static bridge, it was originally connected to the barbican by a drawbridge. The top of the gatehouse is machicolated, and the approach is overlooked by gun-loops in the gatehouse towers. The gatehouse is the only part of the castle which has gun-loops, and the curtain wall and towers are studded with windows for domestic use rather than military. There are guardrooms on the ground floor and a basement beneath them. The passage would originally have had three wooden portcullises. Above the entrance passage is an arch in the gateway, although it leads nowhere. The ceiling of the passage through the gatehouse into the castle is vaulted and pierced with murder holes. Murder holes were most likely used to drop objects on attackers, similar to machicolations, or to pour water to extinguish fires.

Just above the gate, there are three coats of arms carved in relief into the arch; from left to right they are the arms of the Wardeux, Dalyngrigge, and Radynden families. The Wardeux family was that of Edward Dalyngrigge's wife; the Radyndens were relations of the Dalyngrigges. Above the arms is a helm bearing a unicorn head crest. Three coats of arms also decorate the postern gate; the central arms is that of Sir Robert Knolles, who Edward Dalyngrigge had fought for in the Hundred Years' War, but those flanking it are blank.

Although the exterior of Bodiam Castle has largely survived, the interior is ruinous. The domestic buildings within the castle lined the curtain walls. However, remains are substantial enough to recreate a plan of the castle. The structure was divided into separate living areas for the lord and his family, high-status guests, the garrisons, and servants. The south range of the castle consisted of the great hall, the kitchens, and associated rooms. The great hall, to the east of the centrally located postern gate, was and would have been as tall as the curtain wall. To the west of the great hall was the pantry and buttery, linked to the great hall by a screens passage. The three standing arches gave access to different rooms, the pantry, buttery and the kitchen which was at the far west of the south range. This layout was typical of large medieval houses. The great hall was the social centre of the castle, and where the lord would have entertained guests. The buttery and pantry occupied the bottom floor, and above was a room of unknown purpose. The buttery had a cellar and was used to store ale and wine, while the pantry held the supplies for the kitchen. To prevent heat from the cooking fires becoming unbearable, the kitchen was as tall as the curtain walls to provide a large space to absorb the heat. In the southwest tower was a well, from which water would have been drawn for the household.

Along the east wall is a chapel, a hall, and an antechamber. To accommodate the chapel, the curtain wall near the northeast corner projects further into the moat than the rest of the wall along the east side. Immediately south of the chapel was the main accommodation for the lord and his family. The buildings were two storeys high and incorporated a basement. The exact layout of the rooms is unclear.
Arranged along the west curtain wall was an extra hall and a kitchen; it is not certain what these were used for, although it is probable that these were intended to provide for the household's retainers. The "retainers' hall" had no windows on its west side and would have been relatively dark compared to the great hall. Also, whereas the great hall had a large fireplace, the "retainers' hall" had none. The hall was adjacent to the kitchen, to which it was directly connected, with no screens passage in between. Above the "retainers' hall", which was confined to the ground floor, was a room with no fireplace and of unclear purpose.

East of the main gatehouse was a two-storey building with a basement. The basement was probably used for storage while the above two floors provided accommodation. The purpose of the buildings along the west end of the north range is uncertain. The sparse arrangement, with little provision for lighting, has led to suggestions that it was used as stables, however there are no drains which are usually associated with stables. The tower in the northwest corner of the castle had a garderobe and fireplace on each of the three above-ground floors, and there was a basement underneath.


Footnotes
Bibliography



</doc>
<doc id="260841" url="https://en.wikipedia.org/wiki?curid=260841" title="Mana (series)">
Mana (series)

The Mana series, known in Japan as , is a medieval-fantasy action role-playing game series created by Koichi Ishii, with development formerly from Square, and is currently owned by Square Enix. The series began as a handheld side story to Square's flagship franchise "Final Fantasy", though the "Final Fantasy" elements were subsequently dropped starting with the second installment, "Secret of Mana", in order to become its own series. It has grown to include games of various genres within the fictional world of Mana, with recurring stories involving a world tree, its associated holy sword, and the fight against forces that would steal their power. Several character designs, creatures, and musical themes reappear frequently.

Four games were released in the series between 1991 and 1999: the original "Seiken Densetsu" (1991)—"Final Fantasy Adventure" in North America and "Mystic Quest" in Europe—for the Game Boy, "Secret of Mana" (1993) for the Super Nintendo Entertainment System, "Seiken Densetsu 3" (1995) for the Super Famicom, and "Legend of Mana" for the PlayStation, though "Seiken Densetsu 3" was not released outside Japan. A remake of the original game, "Sword of Mana" (2003), was published for the Game Boy Advance. All of the original games were action role-playing games, though they included a wide variety of gameplay mechanics, and the stories of the games were connected only thematically.

In 2006 and 2007, four more games were released as part of the "World of Mana" subseries, an attempt by Square Enix to release games in a series over a variety of genres and consoles. These were "Children of Mana" (2006), an action-oriented dungeon crawler game for the Nintendo DS; "Dawn of Mana" (2006), a 3D action-adventure game for the PlayStation 2; "Friends of Mana" (2006), a Japan-only multiplayer role-playing game for mobile phones; and "Heroes of Mana" (2007), a real-time strategy game for the DS. "Children" was developed by Nex Entertainment and "Heroes" by Brownie Brown, founded by several developers of "Legends", though Ishii oversaw development of all four games. Three more games have been released since the "World of Mana" subseries ended: "Circle of Mana" (2013), a Japan-only card battle game for the GREE mobile platform, "Rise of Mana" (2014), a Japan-only free-to-play action role-playing game for iOS, Android, and PlayStation Vita, and "Adventures of Mana" (2016), a 3D remake of "Final Fantasy Adventure" for the PlayStation Vita, iOS, and Android. In addition to the games, four manga series and one novelization have been released in the "Mana" franchise.

The "Mana" series reception has been very uneven, with early games rated higher by critics than more recent titles. "Secret of Mana" have been regarded as some of the best 2D action role-playing games ever made, and their music has inspired several orchestral concerts, while the games from the "World of Mana" series have been rated considerably lower. As of March 2011, "Mana" series titles have sold over 6 million units.

Square trademarked "Seiken Densetsu" in , intending to use it for a game project subtitled "The Emergence of Excalibur", and led by Kazuhiko Aoki for the Famicom Disk System. According to early advertisements, the game would consist of an unprecedented five floppy disks, making it one of the largest titles developed for the Famicom up until that point. Although Square solicited pre-orders for the game, Kaoru Moriyama, a former Square employee, affirms that management canceled the ambitious project before it advanced beyond the early planning stages. In October 1987, customers who had placed orders were sent a letter informing them of the cancellation and had their purchases refunded. The letter also suggested to consider placing an order on another upcoming Square role-playing game in a similar vein: "Final Fantasy".

In , Square reused the "Seiken Densetsu" trademark for an unrelated Game Boy action role-playing game directed by Koichi Ishii. Originally developed under the title "Gemma Knights", the game was renamed "Seiken Densetsu: Final Fantasy Gaiden" (published in North America as "Final Fantasy Adventure" and in Europe as "Mystic Quest"). Beginning with the sequel, "Secret of Mana", "Seiken Densetsu" was subsequently "spun off" into its own series of action role-playing games distinct from "Final Fantasy", named the "Mana" series outside Japan. Four titles in the series were released between 1993 and 2003. "Secret of Mana" was originally intended to be a launch title for the Super NES CD-ROM Adapter, but when the add-on was cancelled it was cut down into a standard Super NES cartridge, with many of the cut ideas appearing in other Square titles. It was followed in 1995 by the Japan-only "Seiken Densetsu 3"; the game was originally planned to be released in English as "Secret of Mana 2", but technical issues and localization costs prohibited the release. The final new game in the series' initial run is the 1999 "Legend of Mana", developed for the PlayStation. "Legend" is a 2D game like its predecessors, despite the PlayStation's 3D focus, because the console could not handle the full 3D world Ishii envisioned where one could interact with natural shaped objects. 2003 saw the release of "Sword of Mana", a remake of the original "Seiken Densetsu" for the Game Boy Advance. The remake was outsourced to Brownie Brown, which was composed of many of the Square employees who had worked on "Legend".

In 2003, Square, now Square Enix, began a drive to begin developing "polymorphic content", a marketing and sales strategy to "[provide] well-known properties on several platforms, allowing exposure of the products to as wide an audience as possible". The first of these was the "Compilation of Final Fantasy VII", and Square Enix intended to have campaigns for other series whereby multiple games in different genres would be developed simultaneously. Although no such project for the "Mana" series had been announced by this point, it was announced in late 2004 that an unnamed "Mana" game was in development for the upcoming Nintendo DS platform. In early 2005, Square Enix announced a ""World of Mana"" project, the application of this "polymorphic content" idea to the "Mana" franchise, which would include several games across different genres and platforms. These games, as with the rest of the series, would not be direct sequels or prequels to one another, even if appearing so at first glance, but would instead share thematic connections. The first release in this project and the sixth release in the "Mana" series was announced in September 2005 as "Children of Mana" for the DS. Four games were released in 2006 and 2007 in the "World of Mana" subseries: "Children of Mana", "Dawn of Mana", and "Friends of Mana" in 2006, and "Heroes of Mana" in 2007.

Each game in the "World of Mana" series was different, both from each other and from the previous games in the series. "Children" is an action-oriented dungeon crawler game for the DS, developed by Nex Entertainment; "Dawn" is a 3D action-adventure game for the PlayStation 2; "Friends" is a Japan-only multiplayer role-playing game for mobile phones; and "Heroes" is a real-time strategy game for the DS, developed by Brownie Brown. While Ishii was the designer for all four games, he served as the director and producer for "Dawn", which was considered the main game of the four and was released as "Seiken Densetsu 4" in Japan. The theme of the subseries for Ishii, especially "Dawn", was about exploring how to add "the feeling of touch" to a game. He had held off on designing new "Mana" games after "Legend" was unable to meet his desires, until he felt that technology had improved enough to let him create what he envisioned. A fifth game for the subseries was considered for the Wii in 2006, but did not enter development. In April 2007, a month after the release of the final game of the "World of Mana", Ishii left Square Enix to lead his own development company, named Grezzo.

No further games were made in the "Mana" series until 2013, when Square Enix released "Circle of Mana", a Japan-only card battle game for the GREE mobile platform. It was followed in 2014 by "Rise of Mana", a Japan-only free-to-play action role-playing game for iOS, Android, and PlayStation Vita, and in 2016 by "Adventures of Mana", a 3D remake of "Final Fantasy Adventure" for the PlayStation Vita, iOS, and Android. In August 2017, a 3D remake of "Secret of Mana" was announced for PlayStation 4, PlayStation Vita, and Microsoft Windows, for release on February 15, 2018.

The "Mana" series is the result of Koichi Ishii's desire to create a fictional world. In Ishii's opinion, "Mana" is not a series of video games, but rather a world which is illustrated by and can be explored through video games. When working on the series, Koichi Ishii draws inspiration from abstract images from his memories of childhood, as well as movies and fantasy books that captivated him as a child. Ishii takes care to avoid set conventions, and his influences are correspondingly very wide and non-specific. Nonetheless, among his literary influences, he acknowledges Tove Jansson's "Moomin", Lewis Carroll's "Alice's Adventures in Wonderland", and J. R. R. Tolkien's "Lord of the Rings".

While some titles of the "World of Mana" series do share direct connections with other installments, the games of the series have few concrete links. There is no overall explicit in-game chronological order. Further, according to Koichi Ishii in 2006 the games do not take place in exactly the same world, and characters or elements who appear in different titles are best considered alternate versions of each other. Instead, the connections between each title are more abstract than story-based, linked only on the karmic level. Contradicting this assertion, Ishii has also said in an interview that "Children" is set ten years after "Dawn", while "Heroes" is set one generation prior to "Seiken Densetsu 3".

A common element of the series is its seamless, real-time battle system. The system was developed by Koichi Ishii and improved upon by Hiromichi Tanaka, out of a desire to create a system different from the one featured in the first few "Final Fantasy" titles. While action-based, the "Mana" battle system is intended to be playable even by newcomers as well as veterans. The system is coupled with the distinctive hierarchical "Ring Command" menu system, featured prominently in "Secret of Mana" and "Seiken Densetsu 3", and to a lesser extent in later installments. Each ring is a set of icons with a textual infobox explanation which, upon selection, allow the player to use an item, cast a spell, look up in-game statistics, or change the game's settings. Navigation within a menu is achieved by rotating the ring through the cursor left or right, while switching to a different menu is achieved by pressing the up or down buttons. Although not part of the series, the spin-off "Secret of Evermore", developed by the North American Square Soft, was also built upon the "Ring Command" system.

The "Mana" series features several recurring characters and beings, including "Final Fantasy" creatures such as Chocobos in "Final Fantasy Adventure" and "Legend of Mana", as well as Moogles in "Secret of Mana" and as a status ailment in "Seiken Densetsu 3" and "Sword of Mana". Watts is a dwarf blacksmith wearing a horned helmet who upgrades the player's weaponry. Usually, an anthropomorphic cat merchant is found outside of town areas and allows a player to save the game and buy supplies at high prices. This role is played by Neko in "Secret of Mana", and Niccolo in "Legend of Mana" and "Sword of Mana". In the Japanese games these merchants share the name Nikita.

The Mana Tree and the Mana Sword, called Excalibur in "Final Fantasy Adventure"s English version, are recurring plot devices which have been featured in every game of the series. The mystical Mana Tree is a source of magic which sustains the balance and nature of the series' world. The Mana Sword is typically used to restore this balance when it becomes lost in the games. "Final Fantasy Adventure" explains that if the Mana Tree dies, a member of the Mana Family will become the "seed" of a new Tree. A sprout of the Mana Tree is called a Gemma, while protectors of the Tree, who wield the Mana Sword, are called Gemma Knights. In "Seiken Densetsu 3", a Goddess is said to have turned into the Mana Tree after creating the world with the Mana Sword. The Mana Tree is destroyed near the game ending in "Final Fantasy Adventure" and "Secret of Mana", but a character becomes the new Mana Tree in the former game.

Elemental Spirits, also called Mana Spirits, are beings who govern the magic elements of the series' world, and are at the core of the games' magic system as they are used to cast magic spells. Eight types of spirits have appeared in the series since "Secret of Mana", and each embodies a different element. Their names are homonyms of mythological beings or phenomena. In "Secret of Mana" and "Seiken Densetsu 3", usage of their power is enabled upon the main characters' meeting with them. In "Legend of Mana", the spirits serve as factors in the Land Creation System. In "Legend of Mana" and "Sword of Mana", multiple spirits of the same elemental type appear. In terms of storyline, in "Seiken Densetsu 3" and "Heroes of Mana", the spirits are charged to protect the Mana Stones in which the Mana Goddess sealed eight elemental benevodons (God-Beasts in the fan-translation of "SD3"). In "Dawn of Mana"<nowiki>'</nowiki>s North American version, each spirit speaks with a particular European accent, such as French or Scottish.

Rabites, known as in the Japanese versions of the games, are cute, fictional, rabbit-like creatures appearing as a common enemy in the series since its beginning. The Rabite has become a sort of mascot for the "Mana" series, much the same way as the Chocobo represents "Final Fantasy", and is one of its most recognizable icons. The Rabite resembles a bodiless, one-toothed rabbit with large ears that curve upward and form a point at the tip, and a round, puffy pink tail that moves by hopping along the ground. It is most commonly yellow colored, but also pink, lilac, black, and white, and are variously minor enemies, "superboss" characters and even friendly units and pets. Rabites are also mentioned in "Final Fantasy X-2" with an accessory comically named "Rabite's Foot", which increases a character's luck statistic; as well as "Final Fantasy Tactics Advance", where they appear in the description of one of the game's optional missions as an endangered species due to being poached for good luck charms. Rabites have appeared prevalently in several pieces of "Mana" merchandise, including plush dolls, cushions, lighters, mousepads, straps, telephone cards, and T-shirts.

Flammie, sometimes spelled Flammy, is the name of a fictional species of flying dragons, as well as the proper name of some its members, featured in several games of the series. A Flammie's appearance is a mixture of draconian, mammalian, and reptilian features, and its coloring has varied throughout the series. Flammies typically serve as a means of transportation in the game by allowing a player's characters to ride on a Flammie's back to different locations in the game's world. In "Secret of Mana" and "Seiken Densetsu 3", the Super NES's Mode 7 graphic capabilities allows the player to control a Flammie from either a "behind the back" third-person or top-down perspective, and fly over the landscape as it scrolls beneath them. In terms of story, the Flammies were created by the Moon Gods, and are part of an endless cycle of destruction and rebirth as the stronger versions of Flammies—known as Mana Beasts, or in Japanese—destroy the world and the Mana Sword and Tree restore the world.

The "Mana" series has had several different composers. "Final Fantasy Adventure" was composed by Kenji Ito; it was his second original score. Ito's music is mainly inspired by images from the game rather than outside influences. The scores for "Secret of Mana" and "Seiken Densetsu 3" were both composed by Hiroki Kikuta. Despite difficulties in dealing with the hardware limitations, Kikuta tried to express, in the music of "Secret of Mana", two "contrasting styles", namely himself and the game. This was to create an original score which would be neither pop music nor standard game music. Kikuta worked on the music for the two games mostly by himself, spending nearly 24 hours a day in his office, alternating between composing and editing to create an immersive three-dimensional sound. Kikuta considers the score for "Secret of Mana" his favorite creation. His compositions for "Secret of Mana" and "Seiken Densetsu 3" were partly inspired by natural landscapes. In 1995, Kikuta released an experimental album of arranged music from the two installments, titled "Secret of Mana +", which features one 50-minute-long track.

"Legend of Mana"'s score was composed by Yoko Shimomura, and of all her compositions, she considers it the one that best expresses herself. Kenji Ito returned to the series with "Sword of Mana". He also composed roughly one third of the "Children of Mana" soundtrack, while the rest was composed by Masaharu Iwata and Takayuki Aihara. Ito was the main composer for "Dawn of Mana", assisted by Tsuyoshi Sekito, Masayoshi Soken, and Junya Nakano, as well as main theme composer Ryuichi Sakamoto. In North America, purchasers of "Dawn of Mana" from participating retailers were offered a sampler disc, titled "Breath of Mana", which features a selection of tracks from the game. Shimomura has returned to the series with "Heroes of Mana", while also contributing one song to "Rise of Mana".

A five-volume manga based on "Legend of Mana" was drawn by Shiro Amano and published in Japan by Enterbrain between 2000 and 2002. It features a comedic story about the game's main character, here named Toto. A German version was published by Egmont Manga & Anime in 2003. A collection of four-panel comic strips, drawn by various authors and titled "Sword of Mana Yonkoma Manga Theatre", was published in Japan by Square Enix on January 16, 2004. It included a questionnaire that, if sent back, allowed participants to win illustrations signed by Koichi Ishii and Shinichi Kameoka, as well as special T-shirts. Enterbrain also published a "Sword of Mana" manga adaptation in Japan on February 25, 2004, drawn by a collaboration of authors led by Shiro Amano. Two days later, Square Enix published a two-volume novelization of "Sword of Mana" in Japan written by Matsui Oohama. An original manga, named "Seiken Densetsu: Princess of Mana", was drawn by Satsuki Yoshino and published in the Japanese magazine "Gangan Powered" on February 22, 2007.

The "Mana" series has been mostly well received, though each title has seen varied levels of success. RPGFan called "Final Fantasy Adventure" one of the best things to happen to the Game Boy, while IGN considered it the best action RPG on the console after "". GameSpot referred to "Secret of Mana" as "one of Square's masterpieces on the SNES". The game has appeared on several list of top games, including ranked number 97 on "Famitsu"'s top 100 games of all time. "Seiken Densetsu 3" was called "easily one of the best RPGs to come out of the 16-bit era" by Nintendo Life. "Famitsu" rated "Legend of Mana" at 31/40 and "Heroes of Mana" at 32/40. The NPD Group ranked "Legend of Mana" as the top seller the week of its release, and in 2006 was re-released as part of the Ultimate Hits series.

Many of the "World of Mana" titles have not been as critically successful as the original five games in the series, and though the franchise has been praised for their attempts at trying new ways of experiencing the games' fictional world, there have been various gameplay design flaws that have hindered the later games. 1UP.com commented that despite the game's excellent presentation and storytelling, "Dawn of Mana" did not match the level of gameplay of the early "Mana" games. Prior to the "World of Mana" games, RPGamer called the series a "treasured favorite". After the release of "Heroes of Mana", they commented that the "World of Mana" series is "cursed", and the future of the series looked "bleak".

The music of the "Mana" series, especially "Secret of Mana", has received wide acclaim and fan enthusiasm. The "Secret of Mana" soundtrack was one of the first official soundtracks of video games music released in the United States and thus before fully mainstream interest in RPGs. The "Secret of Mana"s opening theme, "Angel's Fear", was rated at number 7 on IGN's Top Ten RPG Title tracks, calling it a "magical title song that captures our hearts". It was also featured in the third Orchestral Game Concert. "Secret of Mana" is also the number 6 most remixed soundtrack on the popular video game music site OverClocked ReMix, with "Seiken Densetsu 3" tied at 18. The music of the other titles have also been well received. RPGFan called the music to "Final Fantasy Adventure" "addictive", despite its low, MIDI-like quality. GameSpy called "Children of Mana"s music some of the best Nintendo DS music yet and referred to it as "beautiful". "Game Informer" complimented "Dawn of Mana"s music, calling it good. IGN referred to "Legend of Mana"s music as "beautiful" and stated the background music brought "intensity", "suspense", and "subtle nuance" to the game. Other reviewers echoed similar praise with GameSpot calling it "excellently orchestrated" and RPGFan calling the music one of the game's good points.

The "Mana" series has sold well overall, and as of March 2011, series titles have sold over 6 million units. The original "Seiken Densetsu" sold over 700,000 units, and its remake "Sword of Mana" sold over 277,000 copies in Japan. "Secret of Mana" has shipped over 1.83 million copies worldwide. "Legend of Mana" sold over 400,000 units in its first week alone as the highest-selling release that week in Japan, and over 700,000 copies in Japan by the end of the year. "Children of Mana" sold over 281,000 copies in Japan, and "Dawn of Mana" sold over 410,000 copies worldwide. "Heroes of Mana" sold over 178,000 copies worldwide. The PlayStation Vita version of "Rise of Mana" downloaded over 100,000 times.


</doc>
<doc id="262008" url="https://en.wikipedia.org/wiki?curid=262008" title="USS Congress (1799)">
USS Congress (1799)

USS "Congress" was a nominally rated 38-gun wooden-hulled, three-masted heavy frigate of the United States Navy. She was named by George Washington to reflect a principle of the United States Constitution. James Hackett built her in Portsmouth New Hampshire and she was launched on 15 August 1799. She was one of the original six frigates whose construction the Naval Act of 1794 had authorized. Joshua Humphreys designed these frigates to be the young Navy's capital ships, and so "Congress" and her sisters were larger and more heavily armed and built than the standard frigates of the period.

Her first duties with the newly formed United States Navy were to provide protection for American merchant shipping during the Quasi War with France and to defeat the Barbary pirates in the First Barbary War. During the War of 1812 she made several extended length cruises in company with her sister ship and captured, or assisted in the capture of twenty British merchant ships. At the end of 1813, due to a lack of materials to repair her, she was placed in ordinary for the remainder of the war. In 1815 she returned to service for the Second Barbary War and made patrols through 1816. In the 1820s she helped suppress piracy in the West Indies, made several voyages to South America, and was the first U.S. warship to visit China. "Congress" spent her last ten years of service as a receiving ship until ordered broken up in 1834.

In 1785 Barbary pirates, most notably from Algiers, began to seize American merchant vessels in the Mediterranean. In 1793 alone, eleven American ships were captured and their crews and stores held for ransom. To combat this problem, proposals were made for warships to protect American shipping, resulting in the Naval Act of 1794. The act provided funds to construct six frigates, but included a clause that if peace terms were agreed to with Algiers, the construction of the ships would be halted.

Joshua Humphreys' design was unusual for the time, being deep, long on keel and narrow of beam (width) and mounting very heavy guns. The design called for a diagonal scantling (rib) scheme intended to restrict hogging while giving the ships extremely heavy planking. This design gave the hull a greater strength than a more lightly built frigate. Humphreys' design was based on his realization that the fledgling United States of the period could not match the European states in the size of their navies. This being so, the frigates were designed to overpower other frigates with the ability to escape from a ship of the line.

"Congress" was given her name by President George Washington after a principle of the United States Constitution. Her keel was reportedly laid down late in 1795 at a shipyard in Portsmouth, New Hampshire. James Hackett was charged with her construction and Captain James Sever served as a superintendent. Her construction proceeded slowly and was completely suspended when in March 1796, a peace treaty was signed with Algiers. "Congress" remained at the shipyard, incomplete, until relations with France deteriorated in 1798 with the start of the Quasi-War. At the request of then President John Adams, funds were approved on 16 July to complete her construction.

The Naval Act of 1794 had specified 36-gun frigates. However, "Congress" and her sister-ship were re-rated to 38s because of their large dimensions, being in length and in width.

The "ratings" by number of guns were meant only as an approximation, and "Congress" often carried up to 48 guns. Ships of this era had no permanent battery of guns such as modern Navy ships carry. The guns and cannons were designed to be completely portable and often were exchanged between ships as situations warranted. Each commanding officer outfitted armaments to their liking, taking into consideration factors such as the overall tonnage of cargo, complement of personnel aboard, and planned routes to be sailed. Consequently, the armaments on ships would change often during their careers, and records of the changes were not generally kept.

During her first cruise in the Quasi-War against France, "Congress" was noted to be armed with a battery of forty guns consisting of twenty-eight and twelve . For her patrols during the War of 1812, she was armed with a battery of forty-four guns consisting of twenty-four 18 pounders and twenty .

"Congress" launched on 15 August 1799 under the command of Captain Sever. After fitting-out in Rhode Island, she set off on her maiden voyage 6 January 1800 sailing in company with "Essex" to escort merchant ships to the East Indies. Six days later she lost all of her masts during a gale. Because her rigging had been set and tightened in a cold climate, it had slackened once she reached warmer temperatures. Without the full support of the rigging, all the masts fell during a four-hour period, killing one crew member trying to repair the main mast.

The crew rigged an emergency sail and limped back to the Gosport Navy Yard for repairs. While there, some of Sever's junior officers announced that they had no confidence in his ability as a commanding officer. A hearing was held, and Captain Sever was cleared of any wrongdoing and remained in command of "Congress", though many of his crew soon transferred out to .

Remaining in port for six months while her masts and rigging were repaired, she finally sailed again on 26 July for the West Indies. "Congress" made routine patrols escorting American merchant ships and seeking out French ships to capture. On two occasions she almost ran aground; first while pursuing a French privateer, she ran into shallow water where large rocks were seen near the surface. Although their exact depth was not determined, Sever immediately abandoned pursuit of the privateer and changed course towards deeper waters. Her second close call occurred off the coast of the Caicos Islands, when during the night she drifted close to the reefs. At daybreak her predicament was discovered by the lookouts.

A peace treaty with France was ratified on 3 February 1801 and "Congress" returned to Boston in April. In accordance with an act of Congress passed on 3 March and signed by President John Adams, thirteen frigates then currently in service were to be retained. Seven of those frigates, including "Congress", were to be placed in ordinary. En route to the Washington Navy Yard, she passed Mount Vernon on her way up the Potomac and Captain Sever ordered her sails lowered, flag at half mast, and a 13-gun salute fired to honor the recently deceased George Washington. "Congress" decommissioned at Washington along with and .

During the United States' preoccupation with France during the Quasi-War, troubles with the Barbary States were suppressed by the payment of tribute to ensure that American merchant ships were not harassed and seized. In 1801 Yusuf Karamanli of Tripoli, dissatisfied with the amount of tribute he was receiving in comparison to Algiers, demanded an immediate payment of $250,000. In response, Thomas Jefferson sent a squadron of frigates to protect American merchant ships in the Mediterranean and pursue peace with the Barbary States.

The first squadron, under the command of Richard Dale in , was instructed to escort merchant ships through the Mediterranean and negotiate with leaders of the Barbary States. A second squadron was assembled under the command of Richard Valentine Morris in however, the performance of Morris's squadron was so poor that he was recalled and subsequently dismissed from the Navy in 1803. A third squadron was assembled under the command of Edward Preble in and by mid-1804 they had successfully fought the Battle of Tripoli Harbor.

President Jefferson reinforced Preble's squadron in April and ordered four frigates to sail as soon as possible. "President", "Congress", "Constellation" and "Essex" were placed under the direction of Commodore Samuel Barron. "Congress" was captained by John Rodgers and two months were spent preparing the squadron for the voyage. They departed in late June and arrived at Gibraltar on 12 August. "Congress" and "Essex" were immediately sent to patrol off the coast of Tangier and when they returned to Gibraltar two weeks later, "Congress" continued on to Tripoli.

"Congress", accompanied by "Constellation", assumed blockade duties of Tripoli and captured one "xebec" before sailing for Malta on 25 October for repairs. On 6 November Rodgers assumed command of "Constitution" and in his place, Stephen Decatur assumed command of "Congress". The next recorded activity of "Congress" is in early July 1805 when she was sent in company with to blockade Tunisia. They were joined on the 23rd by additional U.S. Navy vessels. In early September, "Congress" carried the Tunisian ambassador back to Washington DC. Afterward, placed in ordinary at the Washington Navy Yard, she served as a classroom for midshipmen training through 1807.

In 1811 "Congress" required extensive repairs before recommissioning with
Captain John Rogers in command. She performed routine patrols early in 1812 before war was declared on 18 June. Upon the declaration she was assigned to the squadron of Commodore Rodgers sailing in company with , , "President" and .

Almost immediately Rogers was informed by a passing American merchant ship of a fleet of British merchantmen en route to Britain from Jamaica. "Congress" sailed along in pursuit, but was interrupted when "President" began pursuing HMS "Belvidera" on 23 June. "Congress" trailed behind "President" during the chase and fired her bowchasers at the escaping "Belvidera". Unable to capture "Belvidera", the squadron returned to the pursuit of the Jamaican fleet. On 1 July they began to follow a trail of coconut shells and orange peels the Jamaican fleet had left behind them. Sailing to within one day's journey of the English Channel, the squadron never sighted the convoy and Rodgers called off the pursuit on the 13th. During their return trip to Boston, "Congress" assisted in the capture of seven merchant ships, including the recapture of an American vessel.

Making her second cruise against the British with "President", "Congress" sailed from Boston on 8 October. On the 31st of that month, both ships began to pursue , which was escorting two merchant ships. "Galatea" and her charges were chased for about three hours, during which "Congress" captured the merchant ship "Argo". In the meantime, "President" kept after "Galatea" but lost sight of her as darkness fell. "Congress" and "President" remained together during November but they did not find a single ship to capture. On their return to the United States they passed north of Bermuda, proceeded towards the Virginia capes, and arrived back in Boston on 31 December. During their entire time at sea, the two frigates captured nine prizes.

"Congress" and "President" were blockaded in Boston by the Royal Navy until they slipped through the blockade on 30 April 1813 and put to sea for their third cruise of the war. On 2 May they pursued but she outran them both and escaped. "Congress" parted company with "President" on the 8th and patrolled off the Cape Verde Islands and the coast of Brazil. She only captured four small British merchant ships during this period and returned to the Portsmouth Navy Yard for repairs in late 1813. By this time of the war, materials and personnel were being diverted to the Great Lakes, which created a shortage of resources necessary to repair her. Due to the amount of repairs she needed, it was decided instead to place her in ordinary, where she stayed for the remainder of the war.

Soon after the United States declared war against Britain in 1812, Algiers took advantage of the United States' preoccupation with Britain and began intercepting American merchant ships in the Mediterranean. On 2 March 1815, at the request of President James Madison, Congress declared war on Algiers. Work preparing two American squadrons promptly began—one at Boston under Commodore William Bainbridge, and one at New York under Commodore Steven Decatur.

Captain Charles Morris assumed command of "Congress" and assigned to the squadron under Bainbridge. After repairs and refitting, she transported the Minister to Holland William Eustis to his new post. "Congress" departed in June and after a few weeks at Holland, sailed for the Mediterranean and arrived at Cartagena, Spain in early August joining Bainbridge's squadron. By the time of "Congress"s arrival, however, Commodore Decatur had already secured a peace treaty with Algiers.

"Congress", , and sailed in company with Bainbridge's flagship —the first commissioned ship of the line of the U.S. Navy—as a show of force off Algiers. The squadron subsequently made appearances off Tripoli and Tunis and arrived at Gibraltar in early October. From there, "Congress" and many other ships were ordered back to the United States. She arrived at Newport, Rhode Island, remained there shortly, and proceeded to Boston where she decommissioned in December and assigned to ordinary.

In June 1816 Charles Morris again commanded "Congress" and began preparations for a cruise to the Pacific Coast of the United States. His objective was taking possession of Fort Astoria from the British and conducting inquiries at various ports along the coast to further improve commercial trade. These plans were canceled, however, when a U.S. Navy ship collided with a Spanish Navy vessel in the Gulf of Mexico. Consequently, Morris commanded a squadron of ships in the Gulf to ensure that American merchant commerce in the area would continue unmolested.

"Congress" arrived in the Gulf of Mexico in December 1816 and made patrols through July 1817 performing duties that Morris described as "tedious and uninteresting". From there she sailed for Haiti where Morris and an agent of the United States negotiated a settlement with Henri Christophe over the case of a captured vessel. Afterward, "Congress" sailed for Venezuela to observe and gather information regarding the ongoing Venezuelan War of Independence. She arrived about 21 August and visited the Venezuelan city of Barcelona soon after.

Upon return to the Norfolk Navy Yard later the same year, Morris requested relief as commander due to failing health and Arthur Sinclair assumed command. Sinclair began preparing for a return voyage to South America carrying a diplomatic contingent to assure various South American countries of the United States' intention to remain neutral in their conflicts with Spain for independence. The diplomats included Caesar A. Rodney, John Graham, Theodorick Bland, Henry Brackenridge, William Reed, and Thomas Rodney. "Congress" departed on 4 December and returned to Norfolk in July 1818.

Early in 1819 "Congress" made a voyage under the command of Captain John D. Henley to China, becoming the first U.S. warship to visit that country. She returned to the United States in May 1821. Shortly afterward, pirates in the West Indies began seizing American merchant ships and in early 1822, she served as the flagship of Commodore James Biddle. She is recorded as collecting prisoners from the captured pirate ship "Bandara D'Sangare" on 24 July of that year. Her next recorded activity is returning to Norfolk in April 1823 where Biddle immediately prepared for a voyage to Spain and Argentina to deliver the newly appointed Ministers, Hugh Nelson and Caesar A. Rodney respectively.

Extensive modifications were required to the berth deck of "Congress" in order to accommodate Rodney's wife and eleven children. Additionally, Rodney's household goods and furniture, described by Biddle as "enough to fill a large merchant ship," were loaded into her hold that required much of the ships stores to be relocated. She departed from Wilmington, Delaware on 8 June and arrived at Gibraltar where Hugh Nelson disembarked for Spain. On 18 September "Congress" arrived at Rio de Janeiro, Brazil, where Rodney hired his own merchant ship to carry his family the rest of the distance to Buenos Aires. "Congress" subsequently returned to Norfolk on 17 December.

After her return, "Congress" served as a receiving ship; being moved between the Norfolk and Washington Navy Yards under tow as needed. She remained on this duty for the next ten years until a survey of her condition was performed in 1834, and found unfit for repair, she was broken up the same year.




</doc>
<doc id="262120" url="https://en.wikipedia.org/wiki?curid=262120" title="Operation Uranus">
Operation Uranus

Operation Uranus () was the codename of the Soviet 19–23 November 1942 strategic operation in World War II which led to the encirclement of the German Sixth Army, the Third and Fourth Romanian armies, and portions of the German Fourth Panzer Army. The operation was executed at roughly the midpoint of the five month long Battle of Stalingrad, and was aimed at destroying German forces in and around Stalingrad. Planning for Operation Uranus had commenced in September 1942, and was developed simultaneously with plans to envelop and destroy German Army Group Center (Operation Mars) and German forces in the Caucasus. The Red Army took advantage of the German army's poor preparation for winter, and the fact that its forces in the southern Soviet Union were overstretched near Stalingrad, using weaker Romanian troops to guard their flanks; the offensives' starting points were established along the section of the front directly opposite Romanian forces. These Axis armies lacked heavy equipment to deal with Soviet armor.

Due to the length of the front created by the German summer offensive, aimed at taking the Caucasus oil fields and the city of Stalingrad, German and other Axis forces were forced to guard sectors beyond the length they were meant to occupy. The situation was exacerbated by the German decision to relocate several mechanized divisions from the Soviet Union to Western Europe. Furthermore, units in the area were depleted after months of fighting, especially those which took part in the fighting in Stalingrad. The Germans could only count on the XXXXVIII Panzer Corps, which had the strength of a single panzer division, and the 29th Panzergrenadier Division as reserves to bolster their Romanian allies on the German Sixth Army's flanks. In comparison, the Red Army deployed over one million personnel for the purpose of beginning the offensive in and around Stalingrad. Soviet troop movements were not without problems, due to the difficulties of concealing their build-up, and to Soviet units commonly arriving late due to logistical issues. Operation Uranus was first postponed from 8 to 17 November, then to 19 November.

At 07:20 Moscow time on 19 November, Soviet forces on the northern flank of the Axis forces at Stalingrad began their offensive; forces in the south began on 20 November. Although Romanian units were able to repel the first attacks, by the end of 20 November the Third and Fourth Romanian armies were in headlong retreat, as the Red Army bypassed several German infantry divisions. German mobile reserves were not strong enough to parry the Soviet mechanized spearheads, while the Sixth Army did not react quickly enough nor decisively enough to disengage German armored forces in Stalingrad and reorient them to defeat the impending threat. By late 22 November Soviet forces linked up at the town of Kalach, encircling some 290,000 men east of the Don River. Instead of attempting to break out of the encirclement, German leader Adolf Hitler decided to keep Axis forces in Stalingrad and resupply them by air. In the meantime, Soviet and German commanders began to plan their next movements.

On 28 June 1942, the Wehrmacht began its offensive against Soviet forces opposite of Army Group South, codenamed Case Blue. After breaking through Red Army forces by 13 July, German forces encircled and captured the city of Rostov. Following the fall of Rostov, Hitler split German forces operating in the southern extremity of the southern Russian SFSR in an effort to simultaneously capture the city of Stalingrad and the Caucasus oil fields. The responsibility to take Stalingrad was given to the Sixth Army, which immediately turned towards the Volga River and began its advance with heavy air support from the "Luftwaffe's" "Luftflotte 4". On 7 August, two German panzer corps were able to flank and encircle a Soviet force of 50,000 personnel and approximately 1,000 tanks, and on 22 August German forces began to cross the Don River to complete the advance towards the Volga. The following day, the Battle of Stalingrad began when vanguards of the Sixth Army penetrated the suburbs of the city.

By November the Sixth Army had occupied most of Stalingrad, pushing the defending Red Army to the banks of the Volga River. By this stage, there were indications of an impending Soviet offensive which would target Wehrmacht forces around the city, including increased Soviet activity opposite the Sixth Army's flanks, and information gained through the interrogation of Soviet prisoners. However, the German command was intent upon finalizing its capture of Stalingrad. In fact, head of Army General Staff General Franz Halder had been dismissed in September after his efforts to warn about the danger which was developing along the over-extended flanks of the Sixth Army and the Fourth Panzer Army. As early as September the Soviet "Stavka" (high command) began planning a series of counteroffensives to encompass the destruction of German forces in the south, fighting in Stalingrad and in the Caucasus, and against Army Group Center. Ultimately, command of Soviet efforts to relieve Stalingrad was put under the leadership of General Aleksandr Vasilevsky.

The "Stavka" developed two major operations to be conducted against Axis forces near Stalingrad, "Uranus" and "Saturn", and also planned for Operation Mars, designed to engage German Army Group Center in an effort to distract reinforcements and to inflict as much damage as possible. Operation Uranus involved the use of large Soviet mechanized and infantry forces to encircle German and other Axis forces directly around Stalingrad. As preparations for the offensive commenced, the attack's starting points were positioned on stretches of front to the rear of the German Sixth Army, largely preventing the Germans from reinforcing those sectors quickly where Axis units were too overstretched to occupy effectively. The offensive was a double envelopment; Soviet mechanized forces would penetrate deep into the German rear, while another attack would be made closer to the German Sixth Army in an effort to attack German units there directly in the rear. While the Red Army prepared, the German high commanders—influenced by their belief that the Red Army, building up opposite Germany Army Group Center to the north, was incapable of mounting a simultaneous offensive in the south—continued to deny the possibility of an impending Soviet offensive.

Case Blue involved German and other Axis forces sprawled out across a front over wide and several hundred kilometers deep, while the decision to conquer Stalingrad had stretched Axis forces even more thinly by drawing away personnel eastwards. For example, in early July the Sixth Army was defending a line, while also committing to an offensive which involved a distance of around . Army Group B, which was split from Army Group South (the forces operating around the Caucasus were named Army Group A), seemed strong on paper: it included the Second and Sixth German, Fourth "Panzer", Fourth and Third Romanian, Eighth Italian, and Second Hungarian Armies. Army Group B had the 48th Panzer Corps, which had the strength of a weakened panzer division, and a single infantry division as reserves. For the most part the German flanks were held by arriving non-German Axis armies, while German forces were used to spearhead continued operations in Stalingrad and in the Caucasus.
While Adolf Hitler expressed confidence in the ability of non-German Axis units to protect German flanks, in reality these units relied on largely obsolete equipment and horse-drawn artillery, while in many cases the harsh treatment of enlisted personnel by officers caused poor morale. In regard to mechanization, the First Romanian Armored Division was equipped with around 100 Czech-built Panzer 35(t) tanks, armed with a gun ineffective against the armor of Soviet T-34 tanks. Similarly, their PaK anti-tank guns were also antiquated and they were largely short of ammunition. Only after repeated requests did the Germans send the Romanian units PaK guns; six per division. These units were extended over very large sections of front; for example, the Third Romanian Army occupied a line long, while the Fourth Romanian Army protected a line no less than long. The Italians and Hungarians were positioned at the Don west of the Third Romanian Army, but the German commanders did not hold in high regard the capability of those units to fight.

Generally, German forces were in no better shape; they were weakened by months of fighting the Red Army, and, while "Stavka" raised new armies, the German high command attempted to maintain its existing mechanized units. Furthermore, during the course of the German offensive between May and November 1942, two motorized divisions, the elite Leibstandarte and the Großdeutschland, were redeployed from Army Group A to the West, to provide a mechanized reserve in case of an Allied landing in France. The Sixth Army had also suffered many casualties during the fighting in the city of Stalingrad proper. In some cases, such as that of the 22nd Panzer Division, their equipment was no better than that of the First Romanian Armored Division. German formations were also overextended along large stretches of front; the XI Army Corps, for example, had to defend a front around long.

The Red Army allocated an estimated 1,100,000 personnel, 804 tanks, 13,400 artillery pieces and over 1,000 aircraft for the upcoming offensive. Across the Third Romanian Army, the Soviets placed the redeployed 5th Tank Army, as well as the 21st and 65th Armies, in order to penetrate and overrun the German flanks. The German southern flank was targeted by the Stalingrad Front's 51st and 57th Armies, led by the 13th and 4th Mechanized Corps; these would punch through the Fourth Romanian Army, in order to link up with the 5th Tank Army near the town of Kalach. In total, the Soviets had amassed 11 armies and various independent tank brigades and corps.

Preparations for the offensive were, however, far from perfect; on 8 November, "Stavka" issued orders to postpone the launch date of the operation, because transportation delays had prevented many units from being able to move into place. In the meantime, units at the front went through a number of war games to practice repelling an enemy counterattack and exploiting a breakthrough with mechanized forces. These movements were masked through a deception campaign by the Soviets, including the decrease of radio traffic, camouflage, operational security, using couriers for communication instead of radio, and active deception, such as increasing troop movements around Moscow. Troops were ordered to build defensive fortifications, to offer false impressions to the Germans, while fake bridges were put up to divert attention from the real bridges being built across the Don River. The Red Army also stepped up attacks against Army Group Center and set up dummy formations to maintain the idea of a main offensive against German forces in the center.

The Soviet Stalingrad Front forces were subject to heavy bombardment, making mobilization more difficult. The 38 engineer battalions allocated to the front were responsible for ferrying ammunition, personnel and tanks across the Volga River while carrying out minor reconnaissance along sections of the front which were to be the breakthrough points of the impending offensive. In three weeks the Red Army transported around 111,000 soldiers, 420 tanks and 556 artillery pieces across the Volga.

On 17 November Vasilevsky was recalled to Moscow, where he was shown a letter written to Stalin by General Volsky, commander of the 4th Mechanized Corps, who urged calling off the offensive. Volsky believed the offensive as planned was doomed to failure due to the state of the forces earmarked for the operation; he suggested postponing the offensive and redesigning it entirely. Many Soviet soldiers had not been issued with winter garments, and many died of frostbite, "due to the irresponsible attitude of commanders". Although Soviet intelligence made honest efforts to collect as much information as possible on the disposition of the Axis forces arrayed in front of them, there was not much information on the state of the German Sixth Army. Vasilevsky wanted to call off the offensive. The Soviet commanders, overruling Vasilevsky, agreed the offensive would not be called off, and Stalin personally rang Volsky, who reiterated his intention to carry out the operation if ordered to do so.

Operation Uranus, postponed until 17 November, was again postponed for two days when Soviet General Georgy Zhukov was told the air units allotted to the operation were not ready; it was finally launched on 19 November. Shortly after 5 a.m. Lieutenant Gerhard Stöck, posted with the Romanian IV Army Corps on the Kletskaya sector called Sixth Army headquarters housed in Golubinsky, offering intelligence on a pending attack which would occur after 05:00 that morning; however, because his call had come in after five and false alarms were common during this time, the duty officer on the other end of the line was not keen on waking the Army Chief of Staff, General Arthur Schmidt. Although Soviet commanders suggested postponing the bombardment due to poor visibility from thick fog, front headquarters decided to proceed. At 07:20 Moscow time (05:20 German time) Soviet artillery commanders received the codeword "Siren", prompting an 80-minute artillery bombardment directed almost entirely against the non-German Axis units protecting the German flanks. At 7:30, the Katyusha rocket-launchers fired the first salvos and were soon joined in by the 3,500 guns and mortars stretching along the few breakthrough sectors in front of the Third Romanian Army and the northern shoulder of the German Sixth Army's flank. Although thick fog prevented the Soviet artillery from correcting their aim, their weeks of preparation and ranging allowed them to lay down accurate fire on enemy positions along the front. The effect was devastating, as communication lines were breached, ammunition dumps destroyed and forward observation points shattered. Many Romanian personnel who survived the bombardment began to flee to the rear. Soviet heavy artillery aimed at Romanian artillery positions and second-echelon formations also caught the retreating Romanian soldiers. 

The offensive against the Third Romanian Army began at 08:50, led by the 21st and 65th Soviet Armies and the 5th Tank Army. The first two assaults were repulsed by the Romanian defenders, and the effects of the heavy artillery bombardment had actually made it more difficult for Soviet armor to navigate through the minefields and terrain. However, the lack of heavy anti-tank artillery caused the Romanian defense to collapse; a breakthrough by the 4th Tank Corps and 3rd Guards Cavalry Corps was established by noon. Soon after, the 5th Tank Army was able to gain a breakthrough against the Second Romanian Corps, followed by the Eighth Cavalry Corps. As Soviet armor navigated through the thick fog by compass, overrunning Romanian and German artillery positions, three Romanian infantry divisions began to fall back in disarray; the Third Romanian Army had been outflanked to the West and East. After receiving the news of the Soviet attack, Sixth Army headquarters failed to order the 16th and 24th Panzer Divisions, hitherto engaged in Stalingrad, to reorient themselves to bolster the Romanian defenses; instead the task was given to the seriously understrength and poorly equipped 48th Panzer Corps.

The 48th Panzer Corps had fewer than 100 serviceable modern tanks to combat Soviet armor. Furthermore, they lacked fuel, and the shortage of tanks forced commanders to organize tank crews into infantry companies; the 22nd Panzer Division, which formed part of the corps, was almost completely destroyed in the fighting that ensued. The 22nd had entered the fighting with fewer than thirty working tanks, and left with a company of tanks. The Romanian 1st Armored Division, attached to the 48th Panzer Corps, engaged the Soviet 26th Tank Corps after having lost communications with their German corps commanders, and were defeated by 20 November. As the Soviets continued to advance southwards, many Soviet tank crews began to suffer from the worsening blizzard, which affected men and equipment, and blocked gunsights. It was not uncommon for tanks to lose traction on the ground, and for a crew member to have an arm broken as he was thrown around inside the hull. However, the blizzard also neutralized the German corps' coordination.

The rout of the Third Romanian Army began by the end of 19 November. The Soviet 21st Army and 5th Tank Army were able to capture some 27,000 Romanian prisoners—the bulk of three divisions—and then continue their advance southwards. Soviet cavalry was used to exploit the breakthrough, sever communications between the Romanians and the Italian 8th Army, and to block any possible counterattack against the Soviet flank. While the Red Air Force strafed retreating Romanian soldiers, the "Luftwaffe" provided only negligible opposition. The withdrawal of the 1st Romanian Cavalry Division, originally positioned on the German 376th Infantry Division's flank, allowed the 65th Army to bypass German defenses. As German forces began to react late on 19 November, another attack developed on the Sixth Army's flank to the south.

In the early morning of 20 November "Stavka" telephoned Stalingrad Front commander Andrei Yeremenko asking if he would begin his portion of the offensive on schedule, at 08:00. He responded he would do so only if the fog lifted; although the 51st Army opened its artillery barrage on time because front headquarters could not contact the division, the rest of the forces prepared for the operation received orders to postpone the attack until 10:00. The 51st Army engaged the Romanian 6th Corps, taking many prisoners. As the 57th Army joined the attack at 10:00, the situation developed in such a way that the Stalingrad Front could throw its armored corps into battle. The German 297th Infantry Division watched as its Romanian support failed to put up resistance against the Red Army. However, confusion and lack of control caused the Soviet 4th and 13th Mechanized Corps to stumble as they began to exploit the breakthroughs achieved by the opening offensive.

The Germans responded quickly by redeploying their only reserve in the area, the 29th Panzergrenadier Division. Despite initial victories against Soviet armored forces, the Romanian collapse forced the division to again redeploy in an attempt to shore up defenses to the south. The 29th Panzergrenadier Division's counterattack had cost the Red Army around fifty tanks, and caused Soviet commanders to worry about the safety of their left flank. However, the German division's redeployment meant that by the end of the day only the 6th Romanian Cavalry Regiment was positioned between advancing Soviet forces and the Don River.

While the Stalingrad Front launched its offensive on 20 November, the 65th Soviet Army continued to apply pressure to the German 11th Corps along the northern shoulder of the Sixth Army's flank. The Red Army's 4th Tank Corps advanced beyond the German 11th Corps, while the 3rd Guards Cavalry Corps crashed into the German unit's rear. The German 376th Infantry Division and the Austrian 44th Infantry Division began to redeploy to face the enemy on their flanks, but were hindered by shortage of fuel. The 14th Panzer Division's remaining panzer regiment destroyed a flanking regiment of the Soviet 3rd Guards Cavalry Corps, but its anti-tank artillery suffered heavy casualties when it was overrun by Soviet forces. By the end of the day the Soviet 1st Tank Corps was chasing the retreating 48th Panzer Corps, while the Soviet 26th Tank Corps had captured the town of Perelazovsky, almost to the northwest of Stalingrad.

The Red Army's offensive continued on 21 November, with forces of the Stalingrad Front achieving penetrations of up to . By this time remaining Romanian units in the north were being destroyed in isolated battles, while the Red Army began to engage flanking portions of the German Fourth Panzer and Sixth Armies. The German 22nd Panzer Division, despite attempting a short counterattack, was reduced to little more than a tank company and forced to withdraw to the southwest. The Soviet 26th Tank Corps, having destroyed a large portion of the Romanian 1st Armored Division, continued its advance to the southeast, avoiding engaging enemy left behind, although remnants of the Romanian 5th Corps were able to reorganize and put up a hastily constructed defense in the hope that it would be aided by the German 48th Panzer Corps. Surrounded by 5th Tank Army on one side and 21st Army on the other, the bulk of 3rd Romanian Army was isolated in the region of Raspopinskaya where General Lascar took control of the remnants of 4th and 5th Corps, whereas the neighboring 1st Armored Division was still trying to break free and link with 22nd Panzer Division. That day German General Friedrich Paulus, commander of the Sixth Army, received reports that the Soviets were less than from his headquarters; furthermore, there were no remaining units which could contest the Soviet advance. In the south, after a brief halt, the Soviet 4th Mechanized Corps continued its advance north, removing German defenders from several towns in the area, towards Stalingrad. As German forces in and around Stalingrad were at risk, Hitler ordered German forces in the area to establish an "all-around defensive position" and designated forces between the Don and Volga rivers as "Fortress Stalingrad", rather than allow the Sixth Army to attempt to break out. The Sixth Army, other Axis units, and most of the Fourth Panzer Army's German units were caught inside the growing Soviet encirclement. Only the 16th Panzergrenadier Division began to fight its way out. Lack of coordination between Soviet tanks and infantry as the Red Army's tank corps attempted to exploit the breakthrough along the Germans' southern flank allowed much of the Fourth Romanian Army to escape destruction.

On 22 November Soviet forces began to cross the Don River and continued their advance towards the town of Kalach. German forces defending Kalach, mostly composed of maintenance and supply personnel, were not aware of the Soviet offensive until 21 November, and even then did not know in what strength the Red Army was approaching. The task of taking the bridge at Kalach was given to the Soviet 26th Tank Corps, which used two captured German tanks and a reconnaissance vehicle to approach it and fire on the guards. Soviet forces broke into the town by mid-morning and drove the defenders out, allowing themselves and the 4th Tank Corps to link up with the Red Army's 4th Mechanized Corps approaching from the south. The encirclement of German forces in Stalingrad was completed on 22 November 1942. That day Soviet formations also continued to fight pockets of Romanian resistance, such as that put up by the Romanian 5th Corps.

The encirclement of 6th Army was effective on 23 November. Around 16:00, near the village of Sovetsky, the forward detachments of 36th Mechanized Brigade from the Stalingrad Front’s 4th Mechanized Corps sighted the approaching tanks of 45th Brigade from the Southwestern Front’s 4th Tank Corps. At first they mistook them for Germans because they did not fire green flares as was agreed for a reconnaissance signal and several tanks were damaged in a short exchange of fire. After clarification the linkup was achieved. It was reenacted later for the newsreels.

The junction between the armored troops of 21st and 51st Armies from Vatutin’s and Eremenko’s fronts completed the surrounding of Paulus’s group of forces: two German armies among the most powerful in the Wehrmacht, 22 divisions and 150 separate regiments or battalions, and an enormous amount of materiel. Never before in the war were so many troops of the mighty Germany caught together. Such a feat was so unusual that the Stavka’s own initial estimation of the encircled enemy force was only a quarter of its actual strength, because besides the fighting troops there was a huge amount of extra personnel from various professions, engineer sections, Luftwaffe ground staff and others. Fighting continued on 23 November as the Germans attempted in vain to mount local counterattacks to break the encirclement. By this time Axis personnel inside the encirclement moved east towards Stalingrad to avoid Soviet tanks, while those that managed to escape the encirclement moved west toward German and other Axis forces.

Operation Uranus trapped between 250,000 and 300,000 Axis soldiers within an area stretching from east to west and north to south. The pocket contained four infantry corps, a panzer corps belonging to the Fourth Panzer and Sixth Armies, and surviving elements of two Romanian divisions, a Croat infantry regiment and other specialist units. Trapped equipment included around 100 tanks, 2,000 artillery pieces and mortars and 10,000 trucks. The withdrawal to Stalingrad left lines of retreat littered with helmets, weapons and other equipment, and heavy equipment which had been destroyed was left on the side of the road. Bridges spanning the Don River were jammed with traffic, as surviving Axis soldiers hastily made their way eastwards in the cold weather, attempting to escape Soviet armor and infantry threatening to cut them off from Stalingrad. Many wounded Axis personnel were trampled, and many of those who attempted to cross the river on foot on the ice fell through and drowned. Hungry soldiers filled Russian villages scouring for supplies, while supply dumps were often looted in search of cans of food. The last stragglers crossed the Don River by 24 November, and demolished the bridges to seal off the Fourth Panzer and Sixth Armies from the Soviets in Stalingrad.

The Sixth Army, in the midst of chaos, began to build defensive lines, hampered by the lack of fuel, ammunition and rations, and further burdened by the advancing Russian winter. It was also tasked with plugging gaps in the line caused by the disintegrating Romanian forces. On 23 November, some German units destroyed or burned everything not necessary for a breakout operation and began to pull back towards the northern end of Stalingrad. However, after the Germans had abandoned their winter bunkers, the Soviet 62nd Army was able to destroy the German 94th Infantry Division on the open ground; survivors of the German division were attached to the 16th and 24th Panzer Divisions. Although German military commanders were of the opinion that Wehrmacht forces caught in the encirclement should break out, between 23 and 24 November Hitler decided instead to hold the position and attempt to resupply the Sixth Army by air. The personnel trapped in Stalingrad would require at least of supplies per day, a task which the depleted "Luftwaffe" was in no condition to carry out. Furthermore, the revived Red Air Force was a threat to German aircraft attempting to fly over the encirclement. Although by December the "Luftwaffe" had assembled a fleet of around 500 aircraft, this was still insufficient to supply the Sixth Army and elements of the Fourth Panzer Army with the required supplies. During the first half of December the Sixth Army received less than 20% of their daily requirements.

In the meantime, the Red Army strengthened its outer encirclement with the intention of destroying the encircled German units. Soviet armies would attack German units to the east and the south, aiming to split German units into smaller groups. These orders became effective on 24 November, and were to be executed without a major regrouping or movement of reserves. The outer encirclement ran for an estimated , although only three-quarters of that distance was actually covered by Soviet troops; the distance between the outer and inner encirclements was around . The Soviet high command also began planning for Operation Saturn, which was aimed at destroying the Italian Eighth Army and cutting off German forces in the Caucasus. The Soviet "Stavka" planned "Saturn" to start on about 10 December.

German forces in the area had been further split up, as German general Erich von Manstein was given command of the newly created Army Group Don, comprising the German Fourth Panzer and Sixth Armies, and the Third and Fourth Romanian Armies. Although the situation looked bleak for the Germans, a moment of relative calm had settled after the end of Operation Uranus; German and Soviet forces were planning their next movements.





</doc>
<doc id="262170" url="https://en.wikipedia.org/wiki?curid=262170" title="Black-shouldered kite">
Black-shouldered kite

The black-shouldered kite ("Elanus axillaris"), also known as the Australian black-shouldered kite, is a small raptor found in open habitat throughout Australia. It resembles similar species found in Africa, Eurasia and North America, including the black-winged kite, a species that has in the past also been called "black-shouldered kite". Measuring around in length with a wingspan of , the adult black-shouldered kite has predominantly grey-white plumage and prominent black markings above its red eyes. It gains its name from the black patches on its wings. The primary call is a clear whistle, uttered in flight and while hovering. It can be confused with the related letter-winged kite in Australia, which is distinguished by the striking black markings under its wings

The species forms monogamous pairs, breeding between August and January. The birds engage in aerial courtship displays which involve high circling flight and ritualised feeding mid-air. Three or four eggs are laid and incubated for around thirty days. Chicks are fully fledged within five weeks of hatching and can hunt for mice within a week of leaving the nest. Juveniles disperse widely from the home territory. The black-shouldered kite hunts in open grasslands, searching for its prey by hovering and systematically scanning the ground. It mainly eats small rodents, particularly the introduced house mouse, and has benefitted from the modification of the Australian landscape by agriculture. It is rated as least concern on the International Union for Conservation of Nature (IUCN)'s Red List of Endangered species.

The black-shouldered kite was first described by English ornithologist John Latham in 1801, as "Falco axillaris". Its specific name is derived from the Latin "axilla", meaning "armpit", relating to the dark patches under the wings. He reported the description came from a bird that had been kept for two months in the early colony.
The species description was based on one of four paintings by Australian painter Thomas Watling of a bird in the Sydney district in the 1790s.

English naturalist John Gould described the same species as "Elanus notatus" in 1838 from a specimen from New South Wales, apparently unaware of Latham's description. English zoologist George Robert Gray followed Latham using the binomial "Elanus axillaris" in 1849. Gould conceded Latham's name was valid and hence had precedence, and "E. notatus" was reduced to synonymy. Australian ornithologist Gregory Mathews argued that Latham's description mentioned "black" axillaries and hence must have referred to the letter-winged kite, and that Watling's drawings were inconclusive. He promoted the use of "E. notatus" over "E. axillaris" in 1916. This was followed for many years. But in 1980 Australian taxonomists Richard Schodde and Ian J. Mason refuted Mathews' claim that the original description of "E. axillaris" was ambiguous and reinstated the name. This has been followed by subsequent authorities. The black-shouldered kite is monotypic; no subspecies are recognised.

"Black-shouldered kite" has been designated the official name by the International Ornithologists' Union (IOC). It has also been called the Australian black-shouldered kite to distinguish it from the Eurasian black-winged kite ("E. caeruleus") and American white-tailed kite ("E. leucurus")—both formerly known as "black-shouldered kite". Watling had recorded the Dharug term "Geo-ga-rack".

In 1959, American ornithologist Kenneth C. Parkes noted that the plumage of the black-shouldered kite is similar to that of the black-winged and white-tailed kites, and proposed that all three were subspecies of a single cosmopolitan species "E. caeruleus"—much like the peregrine falcon ("Falco peregrinus"). Researchers William S. Clark and Richard C. Banks disputed this, pointing out the differences in anatomical proportions such as wing shape and tail length, and hunting behavior ("E. caeruleus" rarely hunts by hovering, unlike the other two species) and proposed the species be separated again in 1992. They are regarded as distinct in the IOC World Bird List.

Molecular evidence shows that the black-shouldered kite and its relatives belong to a subfamily Elaninae that is an early offshoot within the raptor family Accipitridae. There is some evidence they are more divergent from other raptors and better placed in their own family.

The adult black-shouldered kite is around in length, with a wingspan of between . The female is slightly heavier, weighing on average around compared to the male's average weight of . The sexes have similar plumage. The crown, neck and upperparts are pale grey, while the head and underparts are white. A black comma-shaped marking lies in front of and stretches over and behind the eye, which is deep red and surrounded by a black orbital ring. The leading edge of the outer wing is black. When perched, this gives the species its prominent black "shoulders". The central rectrices of the tail are pale grey, while the rest of the tail feathers are white. The bill is short with a sharp, hooked tip to the upper mandible. Its nostrils and the cere are bright or dull yellow and the bill is black. The legs and feet are also yellow or golden-yellow, and the feet have three toes facing forwards and one toe facing backwards.

The juvenile has a white forehead and chin and rusty brown neck, nape and breast with darker streaks. The back and wings are mottled buff or brown. There is a less distinctive dark shoulder patch, but a larger comma-shaped patch over the eyes. The eyes themselves are dark brown. The bill is black with a horn-coloured cere.

Black-shouldered kites spiral into the wind like a kestrel. They soar with v-shaped up-curved wings, the primaries slightly spread and the tail widely fanned, giving the tail a squarer appearance and visible 'fingers' on the wings. In level flight progress is rather indirect. Their flight pattern has been described as 'winnowing' with soft steady beats interspersed with long glides on angled wings. They can most often be seen hovering with wings curved and tail pointing down.
The black-shouldered kite is very similar to the related letter-winged kite ("E. scriptus"), but has the black mark above and behind the eye, a white rather than grey crown, and shows all-white underparts in flight except for the black markings on the shoulder, dark wingtips, and a small black patch on the underwing. It is slightly larger than the nankeen kestrel ("Falco cenchroides"). The latter species lacks wing markings and has pale brown plumage. It keeps its wings level when soaring, and has a faster wingbeat when hovering. The grey falcon ("Falco hypoleucos") has somewhat similar coloration to the black-shouldered kite but is bulkier and heavier overall and lacks the black markings. Its wings are barred and it preys on birds. The grey goshawk ("Accipiter novaehollandiae") has wider more rounded wings, underwing markings and glides with lowered wings.

The black-shouldered kite is generally silent, except in the breeding season when its calls, though weak, can be persistent. It primarily utters a clear whistled "chee, chee, chee" call in flight and while hovering, or a hoarse wheezing "skree-ah" when perched. A short high whistle is the primary contact call between a pair, while a harsh scraping call is the most common call used by the female and large young, and brooding females call to their young with a deep, soft, frog-like croak.

A variety of different calls have been recorded from captive birds, including harsh, harmonic, chatter and whistle vocalisations. Harsh calls were made when a bird was alarmed or agitated, whistle-type calls were emitted in general contexts, sometimes monotonously, and shorter duration "chatter" calls were given when a bird sighted a human near the enclosure.

Black-shouldered kites may be sedentary or nomadic, and are generally found in open grasslands or valleys where there are scattered clumps of trees, where the grass or groundcover is accessible from the air and ranges from 30 cm to 1.5 m (1–3 ft) high. As well as native grasslands they forage over pastures, cereal or vegetable crops and vineyards, often focusing on areas that have been recently harvested or ploughed and hence rendering prey more exposed. In urban areas they are encountered on the edge of towns on wasteland, irregularly mown areas, sports fields, golf courses or grassy roadside verges. They also hunt over coastal dunes and drier marshland, but avoid areas with dense cover such as forest as well as bare or rocky ground.

Their numbers fluctuate during drought and floods, and can be irruptive in response to sudden increases in mouse populations. The most distant banding recovery was from the Red Banks area in South Australia to Lithgow in eastern New South Wales three and a half years later, a distance of .

Although reported throughout Australia, they are most common in the relatively fertile south-east and south-west corners of the mainland, and in south-east Queensland. They are rare in the deep desert and dryer areas such as western Cape York or the Northern Territory, and are occasional visitors to northern Tasmania, King Island, and the Torres Strait islands.

Black-shouldered kites usually hunt singly or in pairs, though where food is plentiful they occur in small family groups and can be loosely gregarious at times of irruptions, with up to 70 birds reported feeding together during a mouse plague. They roost communally, like other "Elanus" species. They are territorial when food is not abundant. The practice of "tail flicking" where, on landing, the tail is flicked up and lowered and the movement repeated persistently is thought to be a possible territorial display.

Aerial courtship displays involve single and mutual high circling flight, and the male may fly around with wings held high rapidly fluttering, known as flutter-flight. Courting males dive at the female, feeding her in mid-flight. The female grabs food from the male's talons with hers while flipping upside-down. They may lock talons and tumble downwards in a ritualised version of grappling, but release just before landing. All courtship displays are accompanied by constant calling.

Black-shouldered kites form monogamous pairs. The breeding season is usually August to January, but is responsive to mice populations, and some pairs breed twice in a good season. Both sexes collect material for the nest but the female alone builds it. A large untidy shallow cup of sticks usually in the foliage near the top of trees, the nest takes anywhere from two to six weeks to be built. It is constructed of thin twigs and is around across when newly built, but growing to around across and deep after repeated use. The nest is lined with green leaves and felted fur, though linings of grass and cow dung have also been reported. It is generally located in the canopy of an isolated or exposed tree in open country, elevated or more above the ground. Black-shouldered kites have been known to use old Australian magpie, crow or raven nests.

Females perform most of the care of eggs and nestlings, though males take a minor share of incubation and brooding. The clutch consists of three to four dull white eggs of a tapered oval shape measuring and with red-brown blotches that are often heavier around the larger end of the egg. The eggs are laid at intervals of two to five days. The female incubates the eggs for 30 days and when the eggs hatch the chicks are helpless but have soft down covering their body. For the first two weeks or so the female broods the chicks constantly, both day and night. She does no hunting at all for the first three weeks after hatching, but calls to the male from the nest, and he generally responds by bringing food. The female feeds the chicks with the mice brought back to the nest by the male, feeding them in tiny pieces for the first week or two, at which time the chicks are capable of swallowing a mouse whole. The nestling period lasts around 36 days, and the post-fledging period at least 36 days with parental feeding for at least 22 days. When the chicks are older both parents take it in turns to feed them. Black feathers start to appear along the chicks' wings when they are about a fortnight old, and they are fully fledged and are ready to fly in five weeks. Within a week of leaving the nest the young birds are capable of hunting for mice on their own.

Juveniles disperse widely, taking up territory that can be as far as from the nest site.

The black-shouldered kite has become a specialist predator of the introduced house mouse, often following outbreaks of mouse plagues in rural areas. It takes other suitably-sized creatures when available, including grasshoppers, rats, small reptiles, birds, and even (very rarely) rabbits, but mice and other mouse-sized mammals account for over 90% of its diet. Its influence on mouse populations is probably significant; adults take two or three mice a day each if they can, around a thousand mice a year. On one occasion, a male was observed bringing no less than 14 mice to a nest of well-advanced fledglings within an hour. In another study, a female kite was seen to struggle back to fledglings in the nest with a three-quarters grown rabbit, a heavy load for such a small bird.

Like other elanid kites, the black-shouldered kite hunts by quartering grasslands for small creatures. This can be from a perch, but more often by hovering in mid-air. It is diurnal, preferring to hunt during the day, particularly in the early morning and mid to late afternoon, and occasionally hunts in pairs. Its hunting pattern, outside breeding periods and periods of abundant prey, has distinct crepuscular peaks, perhaps corresponding to mouse activity. When hunting, the kite hovers with its body hanging almost vertically, and its head into the wind. Unlike the nankeen kestrel, the black-winged kite shows no obvious sideways movement, even in a strong breeze. One study of a nesting pair noted that the male searched aerially for 82% of the search time. Typically, a kite hovers above a particular spot, peering down intently, sometimes for only a few seconds, often for a minute or more, then glides swiftly to a new vantage point and hovers again. When hunting from a perch, a dead tree is the preferred platform. Like other "Elanus" kites, The black-shouldered kite grips a vertical branch with a foot on either side, each one above the other and turned inwards, which enables them to maintain a secure footing on relatively small branches. Though hovering is the most common hunting method, the kites have been observed searching the ground beneath a vantage point for periods of up to an hour.

When a mouse or other prey is spotted, the kite drops silently onto it, feet-first with wings raised high; sometimes in one long drop to ground level, more often in two or more stages, with hovering pauses at intermediate heights. Prey is seized in the talons and about 75% of attacks are successful. Prey can either be eaten in flight or carried back to a perch. Birds will have a favoured feeding perch, beneath which accumulate piles of pellets or castings.

European occupation of Australia has, on the whole, benefited the black-shouldered kite through land clearing and irrigation for agriculture and grain harvesting and storage practices which provide suitable conditions for much larger numbers of mice. As the species has a large range and an increasing population, it is listed as "Least Concern" on the IUCN Red List of Threatened species. In southwestern Australia, it has become one of the most commonly recorded raptors in the wheatbelt. According to raptor researcher Stephen Debus, this species did not suffer from eggshell thinning during the period of DDT use in Australia, though he believes it is possible that secondary poisoning may occur from rodenticides used during mouse plagues or from pesticides used during locust plagues. Populations in areas with high sheep and rabbit numbers may decline, as these animals compact the soil and reduce the available habitat for mice.



</doc>
<doc id="262875" url="https://en.wikipedia.org/wiki?curid=262875" title="Tichborne case">
Tichborne case

The Tichborne case was a legal "cause célèbre" that captivated Victorian England in the 1860s and 1870s. It concerned the claims by a man sometimes referred to as Thomas Castro or as Arthur Orton, but usually termed "the Claimant", to be the missing heir to the Tichborne baronetcy. He failed to convince the courts, was convicted of perjury and served a long prison sentence.

Roger Tichborne, heir to the family's title and fortunes, was presumed to have died in a shipwreck in 1854 at age 25. His mother clung to a belief that he might have survived, and after hearing rumours that he had made his way to Australia, she advertised extensively in Australian newspapers, offering a reward for information. In 1866, a butcher known as Thomas Castro from Wagga Wagga came forward claiming to be Roger Tichborne. Although his manners and bearing were unrefined, he gathered support and travelled to England. He was instantly accepted by Lady Tichborne as her son, although other family members were dismissive and sought to expose him as an impostor.

During protracted enquiries before the case went to court in 1871, details emerged suggesting that the Claimant might be Arthur Orton, a butcher's son from Wapping in London, who had gone to sea as a boy and had last been heard of in Australia. After a civil court had rejected the Claimant's case, he was charged with perjury; while awaiting trial he campaigned throughout the country to gain popular support. In 1874, a criminal court jury decided that he was not Roger Tichborne and declared him to be Arthur Orton. Before passing a sentence of 14 years, the judge condemned the behaviour of the Claimant's counsel, Edward Kenealy, who was subsequently disbarred because of his conduct.

After the trial, Kenealy instigated a popular radical reform movement, the Magna Charta Association, which championed the Claimant's cause for some years. Kenealy was elected to Parliament in 1875 as a radical independent but was not an effective parliamentarian. The movement was in decline when the Claimant was released in 1884, and he had no dealings with it. In 1895, he confessed to being Orton, only to recant almost immediately. He lived generally in poverty for the rest of his life and was destitute at the time of his death in 1898. Although most commentators have accepted the court's view that the Claimant was Orton, some analysts believe that an element of doubt remains as to his true identity and that, conceivably, he was Roger Tichborne.

The Tichbornes, of Tichborne Park near Alresford in Hampshire, were an old English Catholic family who had been prominent in the area since before the Norman Conquest. After the Reformation in the 16th century, although one of their number was hanged, drawn and quartered for complicity in the Babington Plot to assassinate Queen Elizabeth I, the family in general remained loyal to the Crown, and in 1621 Benjamin Tichborne was created a baronet for services to King James I.

In 1803 the seventh baronet, Sir Henry Tichborne, was captured by the French in Verdun during the Napoleonic Wars and detained as a civil prisoner for some years. With him in captivity were his fourth son, James, and a nobly born Englishman, Henry Seymour of Knoyle. Despite his confinement, Seymour managed to conduct an affair with the daughter of the Duc de Bourbon, as a result of which a daughter, Henriette Felicité, was born in about 1807. Years later, when Henriette had passed her 20th birthday and remained unmarried, Seymour thought his former companion James Tichborne might make a suitable husband—although James was close to his own age and was physically unprepossessing. The couple were married in August 1827; on 5 January 1829 Henriette gave birth to a son, Roger Charles Doughty Tichborne.

Sir Henry had been succeeded in 1821 by his eldest son, Henry Joseph, who fathered seven daughters but no male heir. As baronetcies are inherited only by males, when Henry Joseph died in 1845 the immediate heir was his younger brother Edward, who had assumed the surname of Doughty as a condition of a legacy. Edward's only son died in childhood, so James Tichborne became next in line to the baronetcy, and after him, Roger. As the family's fortunes had been greatly augmented by the Doughty bequest, this was a considerable material prospect.

After Roger's birth, James and Henriette had three more children: two daughters who died in infancy and a second son, Alfred, born in 1839. The marriage was unhappy, and the couple spent much time apart, he in England, she in Paris with Roger. As a consequence of his upbringing, Roger spoke mainly French, and his English was heavily accented. In 1845 James decided that Roger should complete his education in England and placed him in the Jesuit boarding school Stonyhurst College, where he remained until 1848. In 1849 he sat the British army entrance examinations and then took a commission in the 6th Dragoon Guards, in which he served for three years, mainly in Ireland.

When on leave, Roger often stayed with his Uncle Edward at Tichborne Park and became attracted to his cousin Katherine Doughty, four years his junior. Sir Edward and his wife, though they were fond of their nephew, did not consider marriage between first cousins desirable. At one point the young couple were forbidden to meet, though they continued to do so clandestinely. Feeling harassed and frustrated, Roger hoped to escape from the situation through a spell of overseas military duty; when it became clear that the regiment would remain in the British Isles, he resigned his commission. On 1 March 1853 he left for a private tour of South America on board "La Pauline", bound for Valparaíso in Chile.

On 19 June 1853 "La Pauline" reached Valparaíso, where letters informed Roger that his father had succeeded to the baronetcy, Sir Edward having died in May. In all, Roger spent 10 months in South America, accompanied in the first stages by a family servant, John Moore. In the course of his inland travels he may have visited the small town of Melipilla, which lies on the route between Valparaíso and Santiago. Moore, who had fallen ill, was paid off in Santiago, while Roger travelled to Peru, where he took a long hunting trip. By the end of 1853 he was back in Valparaíso, and early in the new year he began a crossing of the Andes. At the end of January, he reached Buenos Aires, where he wrote to his aunt, Lady Doughty, indicating that he was heading for Brazil, then Jamaica and finally Mexico. The last positive sightings of Roger were in Rio de Janeiro, in April 1854, awaiting a sea passage to Jamaica. Although he lacked a passport he secured a berth on a ship, the "Bella", which sailed for Jamaica on 20 April.
On 24 April 1854 a capsized ship's boat bearing the name "Bella" was discovered off the Brazilian coast, together with some wreckage but no personnel, and the ship's loss with all hands was assumed. The Tichborne family were told in June that Roger must be presumed lost, though they retained a faint hope, fed by rumours, that another ship had picked up survivors and taken them to Australia. Sir James Tichborne died in June 1862, at which point, if he was alive, Roger became the 11th baronet. As he was by then presumed dead, the title passed to his younger brother Alfred, whose financial recklessness rapidly brought about his near-bankruptcy. Tichborne Park was vacated and leased to tenants.

Encouraged by a clairvoyant's assurance that her elder son was alive and well, in February 1863 Lady Tichborne, Roger's mother, began placing regular newspaper advertisements in "The Times" offering a reward for information about Roger Tichborne and the fate of the "Bella". None of these produced results; however, in May 1865 Lady Tichborne saw an advertisement placed by Arthur Cubitt of Sydney, Australia, on behalf of his "Missing Friends Agency". She wrote to him, and he agreed to place a series of notices in Australian newspapers. These gave details of the "Bella"&apos;s last voyage and described Roger Tichborne as "of a delicate constitution, rather tall, with very light brown hair and blue eyes". A "most liberal reward" would be given "for any information that may definitely point out his fate".

In October 1865 Cubitt informed Lady Tichborne that William Gibbes, a lawyer from Wagga Wagga, had identified Roger Tichborne in the person of a bankrupt local butcher using the name Thomas Castro. During his bankruptcy examination Castro had mentioned an entitlement to property in England. He had also talked of experiencing a shipwreck and was smoking a briar pipe which carried the initials "R.C.T." When challenged by Gibbes to reveal his true name, Castro had initially been reticent but eventually agreed that he was indeed the missing Roger Tichborne; henceforth he became generally known as the Claimant.

Cubitt offered to accompany the supposed lost son back to England and wrote to Lady Tichborne requesting funds. Meanwhile, Gibbes asked the Claimant to make out a will and to write to his mother. The will gave Lady Tichborne's name as "Hannah Frances" and disposed of numerous nonexistent parcels of Tichborne property. In the letter to his mother, the Claimant's references to his former life were vague and equivocal but were enough to convince Lady Tichborne that he was her elder son. Her willingness to accept the Claimant may have been influenced by the death of her younger son, Alfred, in February.

In June 1866 the Claimant moved to Sydney, where he was able to raise money from banks on the basis of a statutory declaration that he was Roger Tichborne. The statement was later found to contain many errors, although the birthdate and parentage details were given correctly. It included a brief account of how he had arrived in Australia: he and others from the sinking "Bella", he said, had been picked up by the "Osprey", bound for Melbourne. On arrival he had taken the name Thomas Castro from an acquaintance from Melipilla and had wandered for some years before settling in Wagga Wagga. He had married a pregnant housemaid, Mary Ann Bryant, and taken her child, a daughter, as his own; a further daughter had been born in March 1866.

While in Sydney the Claimant encountered two former servants of the Tichborne family. One was a gardener, Michael Guilfoyle, who at first acknowledged the identity of Roger Tichborne but later changed his mind when asked to provide money to facilitate the return to England. The second, Andrew Bogle, was a former slave at the Duke of Buckingham and Chandos's plantation in Jamaica who had thereafter worked for Sir Edward for many years before retiring. The elderly Bogle did not immediately recognise the Claimant, whose weight contrasted sharply with Roger's remembered slender build; however, Bogle quickly accepted that the Claimant was Roger, and remained convinced until the end of his life. On 2 September 1866 the Claimant, having received funds from England, sailed from Sydney on board the "Rakaia" with his wife and children in first class, and a small retinue including Bogle and his youngest son Henry George in second class. Good living in Sydney had raised his weight on departure to , and during the long voyage he added another . After a journey involving several changes of ship, the party arrived at Tilbury on 25 December 1866.

After depositing his family in a London hotel, the Claimant called at Lady Tichborne's address and was told she was in Paris. He then went to Wapping in East London, where he enquired after a local family named Orton. Finding that they had left the area, he identified himself to a neighbour as a friend of Arthur Orton, who, he said, was now one of the wealthiest men in Australia. The significance of the Wapping visit would become apparent only later. On 29 December the Claimant visited Alresford and stayed at the Swan Hotel, where the landlord detected a resemblance to the Tichbornes. The Claimant confided that he was the missing Sir Roger but asked that this be kept secret. He also sought information concerning the Tichborne family.

Back in London, the Claimant employed a solicitor, John Holmes, who agreed to go with him to Paris to meet Lady Tichborne. This meeting took place on 11 January at the Hôtel de Lille. As soon as she saw his face, Lady Tichborne accepted him. At Holmes's behest she lodged with the British Embassy a signed declaration formally testifying that the Claimant was her son. She was unmoved when Father Châtillon, Roger's childhood tutor, declared the Claimant an impostor, and she allowed Holmes to inform "The Times" in London that she had recognised Roger. She settled an income of £1,000 a year on him, and accompanied him to England to declare her support before the more sceptical members of the Tichborne family.

The Claimant quickly acquired significant supporters; the Tichborne family's solicitor Edward Hopkins accepted him, as did J.P. Lipscomb, the family's doctor. Lipscomb, after a detailed medical examination, reported that the Claimant possessed a distinctive genital malformation. It would later be suggested that Roger Tichborne had this same defect, but this could not be established beyond speculation and hearsay. Many people were impressed by the Claimant's seeming ability to recall small details of Roger Tichborne's early life, such as the fly fishing tackle he had used. Several soldiers who had served with Roger in the Dragoons, including his former batman Thomas Carter, recognised the Claimant as Roger. Other notable supporters included Lord Rivers, a landowner and sportsman, and Guildford Onslow, the Liberal MP for Guildford who became one of the Claimant's staunchest advocates. Rohan MacWilliam, in his account of the case, calls this wide degree of recognition remarkable, particularly given the Claimant's increasing physical differences from the slim Roger. By mid-June 1867 the Claimant's weight had reached almost and would increase even more in the ensuing years.

Despite Lady Tichborne's insistence that the Claimant was her son, the rest of the Tichbornes and their related families were almost unanimous in declaring him a fraud. They recognised Alfred Tichborne's infant son, Henry Alfred, as the 12th baronet. Lady Doughty, Sir Edward's widow, had initially accepted the evidence from Australia but changed her mind soon after the Claimant's arrival in England. Lady Tichborne's brother Henry Seymour denounced the Claimant as false when he found that the latter neither spoke nor understood French (Roger's first language as a child) and lacked any trace of a French accent. The Claimant was unable to identify several family members and complained about attempts to catch him out by presenting him with impostors. Vincent Gosford, a former Tichborne Park steward, was unimpressed by the Claimant, who, when asked to name the contents of a sealed package that Roger left with Gosford before his departure in 1853, said he could not remember. The family believed that the Claimant had acquired from Bogle and other sources information that enabled him to demonstrate some knowledge of the family's affairs, including, for example, the locations of certain pictures in Tichborne Park. Apart from Lady Tichborne, a distant cousin, Anthony John Wright Biddulph, was the only relation who accepted the Claimant as genuine; however, as long as Lady Tichborne was alive and maintaining her support, the Claimant's position remained strong.

On 31 July 1867 the Claimant underwent a judicial examination at the Chancery Division of the Royal Courts of Justice. He testified that after his arrival in Melbourne in July 1854 he had worked for William Foster at a cattle station in Gippsland under the name of Thomas Castro. While there, he had met Arthur Orton, a fellow Englishman. After leaving Foster's employment the Claimant had subsequently wandered the country, sometimes with Orton, working in various capacities before setting up as a butcher in Wagga Wagga in 1865. On the basis of this information, the Tichborne family sent an agent, John Mackenzie, to Australia to make further enquiries. Mackenzie located Foster's widow, who produced the old station records. These showed no reference to "Thomas Castro", although the employment of an "Arthur Orton" was recorded. Foster's widow also identified a photograph of the Claimant as Arthur Orton, thus providing the first direct evidence that the Claimant might in fact be Orton. In Wagga Wagga one local resident recalled the butcher Castro saying that he had learned his trade in Wapping. When this information reached London, enquiries were made in Wapping by a private detective, ex-police inspector Jack Whicher, and the Claimant's visit in December 1866 was revealed.

Arthur Orton, a butcher's son born on 20 March 1834 in Wapping, had gone to sea as a boy and had been in Chile in the early 1850s. Sometime in 1852 he arrived in Hobart, Tasmania, in the transport ship "Middleton" and later moved to mainland Australia. His employment by Foster at Gippsland terminated around 1857 with a dispute over wages. Thereafter he disappears; if he was not Castro, there is no further direct evidence of Orton's existence, although strenuous efforts were made to find him. The Claimant hinted that some of his activities with Orton were of a criminal nature and that to confound the authorities they had sometimes exchanged names. Most of Orton's family failed to recognise the Claimant as their long-lost kinsman, although it was later revealed that he had paid them money. However, a former sweetheart of Orton's, Mary Ann Loder, did identify the Claimant as Orton.

Lady Tichborne died on 12 March 1868, thus depriving the Claimant of his principal advocate and his main source of income. He outraged the family by insisting on taking the position of chief mourner at her funeral mass. His lost income was rapidly replaced by a fund, set up by supporters, that provided a house near Alresford and an income of £1,400 (£145,278 in 2016) a year.

In September 1868, together with his legal team, the Claimant went to South America to meet face-to-face with potential witnesses in Melipilla who might confirm his identity. He disembarked at Buenos Aires, ostensibly to travel to Valparaíso overland and there rejoin his advisers who were continuing by sea. After waiting two months in Buenos Aires he caught a ship home. His explanations for this sudden retreat—poor health and the dangers from brigands—did not convince his backers, many of whom withdrew their support; Holmes resigned as his solicitor. Furthermore, on their return his advisers reported that no one in Melipilla had heard of "Tichborne", although they remembered a young English sailor called "Arturo".

The Claimant was now bankrupt. In 1870 his new legal advisers launched a novel fundraising scheme: Tichborne Bonds, an issue of 1,000 debentures of £100 face value, the holders of which would be repaid with interest when the Claimant obtained his inheritance. About £40,000 was raised, though the bonds quickly traded at a considerable discount and were soon being exchanged for derisory sums. The scheme allowed the Claimant to continue to meet his living and legal expenses for a while. After a delay while the Franco-Prussian War and its aftermath prevented key witnesses from leaving Paris, the civil case that the Claimant hoped would confirm his identity finally came to court in May 1871.

The case was listed in the Court of Common Pleas as "Tichborne v. Lushington", in the form of an action for the ejectment of Colonel Lushington, the tenant of Tichborne Park. The real purpose, however, was to establish the Claimant's identity as Sir Roger Tichborne and his rights to the family's estates; failure on his part would expose him as an impostor. In addition to Tichborne Park's , the estates included manors, lands and farms in Hampshire, and considerable properties in London and elsewhere, which altogether produced an annual income of over £20,000, equivalent to several millions in 21st-century terms.

The hearing, which took place within the Palace of Westminster, began on 11 May 1871 before Sir William Bovill, who was Chief Justice of the Common Pleas. The Claimant's legal team was led by William Ballantine and Harding Giffard, both highly experienced advocates. Opposing them, acting on instructions from the bulk of the Tichborne family, were John Duke Coleridge, the Solicitor General (he was promoted to Attorney-General during the hearing), and Henry Hawkins, a future High Court judge who was then at the height of his powers as a cross-examiner. In his opening speech, Ballantine made much of Roger Tichborne's unhappy childhood, his overbearing father, his poor education and his frequently unwise choices of companions. The Claimant's experiences in an open boat following the wreck of the "Bella" had, said Ballantine, impaired his memories of his earlier years, which explained his uncertain recall. Attempts to identify his client as Arthur Orton were, Ballantine argued, the concoctions of "irresponsible" private investigators acting for the Tichborne family.

The first witnesses for the Claimant included former officers and men from Roger Tichborne's regiment, all of whom declared their belief that he was genuine. Among servants and former servants of the Tichborne family called by Ballantine was John Moore, Roger's valet in South America. He testified that the Claimant had remembered many small details of their months together, including clothing worn and the name of a pet dog the pair had adopted. Roger's cousin Anthony Biddulph explained that he had accepted the Claimant only after spending much time in his company.

On 30 May Ballantine called the Claimant to the stand. During his examination-in-chief, the Claimant answered questions on Arthur Orton, whom he described as "a large-boned man with sharp features and a lengthy face slightly marked with smallpox". He had lost sight of Orton between 1862 and 1865, but they had met again in Wagga Wagga, where the Claimant had discussed his inheritance. Under cross-examination the Claimant was evasive when pressed for further details of his relationship with Orton, saying that he did not wish to incriminate himself. After questioning him on his visit to Wapping, Hawkins asked him directly: "Are you Arthur Orton?" to which he replied "I am not". The Claimant displayed considerable ignorance when questioned about his time at Stonyhurst. He could not identify Virgil, confused Latin with Greek, and did not understand what chemistry was. He caused a sensation when he declared that he had seduced Katherine Doughty and that the sealed package given to Gosford, the contents of which he earlier claimed not to recall, contained instructions to be followed in the event of her pregnancy. Rohan McWilliam, in his chronicle of the affair, comments that from that point on the Tichborne family were fighting not only for their estates but for Katherine Doughty's honour.

On 7 July the court adjourned for four months. When it resumed, Ballantine called more witnesses, including Bogle and Francis Baigent, a close family friend. Hawkins contended that Bogle and Baigent were feeding the Claimant with information, but in cross-examination he could not dent their belief that the Claimant was genuine. In January 1872 Coleridge began the case for the defence with a speech during which he categorised the Claimant as comparable with "the great impostors of history". He intended to prove that the Claimant was Arthur Orton. He had over 200 witnesses lined up, but it transpired that few were required. Lord Bellew, who had known Roger Tichborne at Stonyhurst, testified that Roger had distinctive body tattoos which the Claimant did not possess. On 4 March the jury notified the judge that they had heard enough and were ready to reject the Claimant's suit. Having ascertained that this decision was based on the evidence as a whole and not solely on the missing tattoos, Bovill ordered the Claimant's arrest on charges of perjury and committed him to Newgate Prison.

From his cell in Newgate, the Claimant vowed to resume the fight as soon as he was acquitted. On 25 March 1872 he published in the "Evening Standard" an "Appeal to the Public", requesting financial help to meet his legal and living costs: "I appeal to every British soul who is inspired by a love of justice and fair play, and is willing to defend the weak against the strong". The Claimant had gained considerable popular support during the civil trial; his fight was perceived by many as symbolising the problems faced by the working class when seeking justice in the courts. In the wake of his appeal, support committees were formed throughout the country. When he was bailed early in April, on sureties provided by Lord Rivers and Guildford Onslow, a large crowd cheered him as he left the Old Bailey.

At a public meeting in Alresford on 14 May, Onslow reported that subscriptions to the defence fund were already pouring in and that invitations to visit and speak had been received from many towns. As the Claimant addressed meetings up and down the country, journalists following the campaign often commented on his pronounced cockney accent, suggestive of East London origins. The campaign drew in some high-level supporters, among whom was George Hammond Whalley, a controversial anti-Catholic who was MP for Peterborough. He and Onslow were sometimes incautious in their speeches; after a meeting in St James's Hall, London, on 11 December 1872, each made specific charges against the Attorney General and the Government of trying to pervert the course of justice. They were fined £100 each for contempt of court.

With few exceptions, the mainstream press was hostile to the Claimant's campaign. To counteract this, his supporters launched two short-lived newspapers, the "Tichborne Gazette" in May 1872 and the "Tichborne News and Anti-Oppression Journal" in June. The former was wholly devoted to the Claimant's cause and ran until Onslow's and Whalley's contempt convictions in December 1872. The "Tichborne News", which concerned itself with a broader range of perceived injustices, closed after four months.

The criminal case, to be heard in the Queen's Bench, was listed as "Regina v. Castro", the name Castro being the last uncontested alias of the Claimant. Because of its expected length, the case was scheduled as a "trial at bar", a device that allowed a panel rather than one judge to hear it. The president of the panel was Sir Alexander Cockburn, the Lord Chief Justice. His decision to hear this case was controversial, since during the civil case he had publicly denounced the Claimant as a perjurer and a slanderer. Cockburn's co-judges were Sir John Mellor and Sir Robert Lush, experienced Queen's Bench justices.

The prosecution team was largely that which had opposed the Claimant in the civil case, minus Coleridge. Hawkins led the team, his main assistants being Charles Bowen and James Mathew. The Claimant's team was significantly weaker; he would not re-engage Ballantine and his other civil case lawyers declined to act for him again. Others refused the case, possibly because they knew they would have to present evidence concerning the seduction of Katherine Doughty. The Claimant's backers eventually engaged Edward Kenealy, an Irish lawyer of acknowledged gifts but known eccentricity. Kenealy had previously featured in several prominent defences, including those of the poisoner William Palmer and the leaders of the 1867 Fenian Rising. He was assisted by undistinguished juniors: Patrick MacMahon, an Irish MP who was frequently absent, and the young and inexperienced Cooper Wyld. Kenealy's task was made more difficult when several of his upper-class witnesses refused to appear, perhaps afraid of the ridicule they anticipated from the Crown's lawyers. Other important witnesses from the civil case, including Moore, Baigent and Lipscombe, would not give evidence at the criminal trial.

The trial, one of the lengthiest cases heard in an English court, began on 21 April 1873 and lasted until 28 February 1874, occupying 188 court days. The tone was dominated by Kenealy's confrontational style; his personal attacks extended not only to witnesses but to the Bench and led to frequent clashes with Cockburn. Under the legal rules that then applied to criminal cases, the Claimant, though present in court, was not allowed to testify. Away from the court he revelled in his celebrity status; the American writer Mark Twain, who was then in London, attended an event at which the Claimant was present and "thought him a rather fine and stately figure". Twain observed that the company were "educated men, men moving in good society... It was 'Sir Roger', always 'Sir Roger' on all hands, no one withheld the title".

Altogether, Hawkins called 215 witnesses, including numbers from France, Melipilla, Australia and Wapping, who testified either that the Claimant was not Roger Tichborne or that he was Arthur Orton. A handwriting expert swore that the Claimant's writing resembled Orton's but not Roger Tichborne's. The entire story of rescue by the "Osprey" was, Hawkins asserted, a fraud. A ship of that name had arrived in Melbourne in July 1854 but did not correspond to the Claimant's description. Furthermore, the Claimant had provided the wrong name for "Osprey"s captain, and the names he gave for two of "Osprey"s crew were found to belong to members of the crew of the "Middleton", the ship which had landed Orton at Hobart. No mention of a rescue had been found in "Osprey"s log or in the Melbourne harbourmaster's records. Giving evidence on the contents of the sealed packet, Gosford revealed that it contained information regarding the disposition of certain properties, but nothing relating to Katherine Doughty's seduction or pregnancy.

Kenealy's defence was that the Claimant was victim of a conspiracy which encompassed the Catholic Church, the government and the legal establishment. He frequently sought to demolish witnesses' character, as with Lord Bellew, whose reputation he destroyed by revealing details of the peer's adultery. Kenealy's own witnesses included Bogle and Biddulph, who remained steadfast, but more sensational testimony came from a sailor called Jean Luie, who claimed that he had been on the "Osprey" during the rescue mission. Luie identified the Claimant as "Mr Rogers", one of six survivors picked up and taken to Melbourne. On investigation Luie was found to be an impostor, a former prisoner who had been in England at the time of the "Bella"’s sinking. He was convicted of perjury and sentenced to seven years' imprisonment.

After closing addresses from Kenealy and Hawkins, Cockburn began summing-up on 29 January 1874. His speech was prefaced by a severe denunciation of Kenealy's conduct, "the longest, severest and best merited rebuke ever administered from the Bench to a member of the bar" according to the trial's chronicler John Morse. The tone of the summing-up was partisan, frequently drawing the jury's attention to the Claimant's "gross and astonishing ignorance" of things he would certainly know if he were Roger Tichborne. Cockburn rejected the Claimant's version of the sealed package contents and all imputations against Katherine Doughty's honour. Of Cockburn's peroration, Morse remarked that "never was a more resolute determination manifested [by a judge] to control the result". While much of the press applauded Cockburn's forthrightness, his summing-up was also criticised as "a Niagara of condemnation" rather than an impartial review.

The jury retired at noon on Saturday 28 February, and returned to the court within 30 minutes. Their verdict declared that the Claimant was not Roger Tichborne, that he had not seduced Katherine Doughty, and that he was indeed Arthur Orton. He was thus convicted of perjury. The jury added a condemnation of Kenealy's conduct during the trial. After the judges refused his request to address the court, the Claimant was sentenced to two consecutive terms of seven years' imprisonment. Kenealy's behaviour ended his legal career; he was expelled from the Oxford circuit mess and from Gray's Inn, so that he could no longer practise. On 2 December 1874 the Lord Chancellor revoked Kenealy's patent as a Queen's Counsel.

The court's verdict swelled the popular tide in favour of the Claimant. He and Kenealy were hailed as heroes, the latter as a martyr who had sacrificed his legal career. George Bernard Shaw, writing much later, highlighted the paradox whereby the Claimant was perceived simultaneously as a legitimate baronet and as a working-class man denied his legal rights by a ruling elite. In April 1874 Kenealy launched a political organisation, the "Magna Charta Association", with a broad agenda that reflected some of the Chartist demands of the 1830s and 1840s. In February 1875 Kenealy fought a parliamentary by-election for Stoke-upon-Trent as "The People's Candidate", and won with a resounding majority. However, he failed to persuade the House of Commons to establish a royal commission into the Tichborne trial, his proposal securing only his own vote and the support of two non-voting tellers, against 433 opposed. Thereafter, within parliament Kenealy became a generally derided figure, and most of his campaigning was conducted elsewhere. In the years of the Tichborne movement's popularity a considerable market was created for souvenirs in the form of medallions, china figurines, teacloths and other memorabilia. However, by 1880 interest in the case had declined, and in the General Election of that year Kenealy was heavily defeated. He died of heart failure a few days after the election. The Magna Charta Association continued for several more years, with dwindling support; "The Englishman", the newspaper founded by Kenealy during the trial, closed down in May 1886, and there is no evidence of the Association's continuing activities after that date.

The Claimant was released on licence on 11 October 1884 after serving 10 years. He was much slimmer; a letter to Onslow dated May 1875 reports a loss of . Throughout his imprisonment he had maintained that he was Roger Tichborne, but on release he disappointed supporters by showing no interest in the Magna Charta Association, instead signing a contract to tour with music halls and circuses. The British public's interest in him had largely waned; in 1886 he went to New York but failed to inspire any enthusiasm there and ended up working as a bartender.

He returned in 1887 to England, where, although not officially divorced from Mary Ann Bryant, he married a music hall singer, Lily Enever. In 1895, for a fee of a few hundred pounds, he confessed in "The People" newspaper that he was, after all, Arthur Orton. With the proceeds he opened a small tobacconist's shop in Islington; however, he quickly retracted the confession and insisted again that he was Roger Tichborne. His shop failed, as did other business attempts, and he died destitute, of heart disease, on 1 April 1898. His funeral caused a brief revival of interest; around 5,000 people attended Paddington cemetery for the burial in an unmarked pauper's grave. In what McWilliam calls "an act of extraordinary generosity" the Tichborne family allowed a card bearing the name "Sir Roger Charles Doughty Tichborne" to be placed on the coffin before its interment. The name "Tichborne" was registered in the cemetery's records.

Commentators have generally accepted the trial jury's verdict that the Claimant was Arthur Orton. However, McWilliam cites the monumental study by Douglas Woodruff (1957), in which the author posits that the Claimant could just possibly have been Roger Tichborne. Woodruff's principal argument is the sheer improbability that anyone could conceive such an imposture from scratch, at such a distance, and then implement it: "[I]t was carrying effrontery beyond the bounds of sanity if Arthur Orton embarked with a wife and retinue and crossed the world, knowing that they would all be destitute if he did not succeed in convincing a woman he had never met and knew nothing about first-hand, that he was her son".

In 1876, while the Claimant was serving his prison sentence, interest was briefly raised by the claims of William Cresswell, an inmate of a Sydney lunatic asylum, that he was Arthur Orton. There was circumstantial evidence that indicated some connection with Orton, and the Claimant's supporters campaigned to have Cresswell brought to England. Nothing came of this, although the question of Cresswell's possible identity remained a matter of dispute for years. In 1884 a Sydney court found the matter undecided, and ruled that the "status quo" should be maintained; Cresswell stayed in the asylum. Shortly before his death in 1904 he was visited by the contemporaneous Lady Tichborne, who found no physical resemblance to any member of the Tichborne family.

Attempts have been made to reconcile some of the troubling uncertainties and contradictions within the case. To explain the degree of facial resemblance (which even Cockburn accepted) of the Claimant to the Tichborne family, Onslow suggested in "The Englishman" that Orton's mother, a woman named Mary Kent, was an illegitimate daughter of Sir Henry Tichborne, Roger Tichborne's grandfather. An alternative story has Mary Kent being seduced by James Tichborne, making Orton and Roger half-brothers. Other versions have Orton and Roger as companions in crime in Australia, with Orton killing Roger and assuming his identity. The Claimant's daughter by Mary Ann Bryant, Teresa Mary Agnes, maintained that her father confessed to her that he had killed Arthur Orton and thus could not disclose details of his Australian years. There is no direct evidence for any of these theories. Teresa continued to proclaim her identity as a Tichborne daughter, and in 1924 was imprisoned for making threats and demands for money to the family.

Woodruff submits that the legal verdicts, although fair given the evidence before the courts, have not fully resolved the "great doubt" that Cockburn admitted hung over the case. Woodruff wrote in 1957: "Probably for ever, now, its key long since lost... a mystery remains". A 1998 article in "The Catholic Herald" suggested that DNA profiling might resolve the mystery. The enigma has launched numerous retellings of the story in book and film, including the short story "Tom Castro, the Implausible Imposter" from Jorge Luis Borges's "Universal History of Infamy", and David Yates's 1998 film "The Tichborne Claimant". Thus, Woodruff concludes, "the man who lost himself still walks in history, with no other name than that which the common voice of his day accorded him: the Claimant".


Notes
Citations
Bibliography



</doc>
<doc id="262979" url="https://en.wikipedia.org/wiki?curid=262979" title="History of Sesame Street">
History of Sesame Street

The preschool educational television program "Sesame Street" was first aired on public broadcasting television stations November 10, 1969, and reached its 50th season in 2019. The history of "Sesame Street" has reflected changing attitudes to developmental psychology, early childhood education, and cultural diversity. Featuring Jim Henson's Muppets, animation, live shorts, humor and celebrity appearances, it was the first television program of its kind to base its content and production values on laboratory and formative research, and the first to include a curriculum "detailed or stated in terms of measurable outcomes". Initial responses to the show included adulatory reviews, some controversy and high ratings. By its 40th anniversary in 2009, "Sesame Street" was broadcast in over 120 countries, and 20 independent international versions had been produced.

The show was conceived in 1966 during discussions between television producer Joan Ganz Cooney and Carnegie Corporation vice president Lloyd Morrisett. Their goal was to create a children's television show that would "master the addictive qualities of television and do something good with them", such as helping young children prepare for school. After two years of research, the newly formed Children's Television Workshop (CTW) received a combined grant of $8 million from the Carnegie Corporation, the Ford Foundation and the U.S. federal government to create and produce a new children's television show.

By the show's tenth anniversary in 1979, nine million American children under the age of six were watching "Sesame Street" daily, and several studies showed it was having a positive educational impact. The cast and crew expanded during this time, including the hiring of women in the crew and additional minorities in the cast. In 1981, the federal government withdrew its funding, so the CTW turned to other sources, such as its magazine division, book royalties, product licensing and foreign income. During the 1980s, "Sesame Street"s curriculum expanded to include topics such as relationships, ethics and emotions. Many of the show's storylines were taken from the experiences of its writing staff, cast and crew, most notably the death of Will Lee—who played Mr. Hooper—and the marriage of Luis and Maria.

In recent decades, "Sesame Street" has faced societal and economic challenges, including changes in the viewing habits of young children, more competition from other shows, the development of cable television and a drop in ratings. After the turn of the 21st century, the show made major structural adaptations, including changing its traditional magazine format to a narrative format. Because of the popularity of the Muppet Elmo, the show incorporated a popular segment known as "Elmo's World". "Sesame Street" has won eleven Grammys and over a hundred Emmys in its history—more than any other children's show.

In the late 1960s, 97% of all American households owned a television set, and preschool children watched an average of 27 hours of television per week; programs created for them were widely criticized for being too violent and for reflecting commercial values. Producer Joan Ganz Cooney called children's programming a "wasteland", and she was not alone in her criticism. Many children's television programs were produced by local stations, with little regard for educational goals, or cultural diversity. As writer David Borgenicht stated, the use of children's programming as an educational tool was "unproven" and "a revolutionary concept".

According to children's media experts Edward Palmer and Shalom M. Fisch, children's television programs of the 1950s and 1960s duplicated "prior media forms". For example, they tended to show simple shots of a camera's-eye view of a location filled with children, or they recreated storybooks with shots of book covers and motionless illustrated pages. The hosts of these programs were "insufferably condescending", though one exception was "Captain Kangaroo", created and hosted by Bob Keeshan, which author Michael Davis described as having a "slower pace and idealism" that most other children's shows lacked.

Early childhood educational research had shown that when children were prepared to succeed in school, they earned higher grades and learned more effectively. Children from low-income families had fewer resources than children from higher-income families to prepare them for school. Research had shown that children from low-income, minority backgrounds tested "substantially lower" than middle-class children in school-related skills, and that they continued to have educational deficits throughout school. The field of developmental psychology had grown during this period, and scientists were beginning to understand that changes in early childhood education could increase children's cognitive growth. Because of these trends in education, along with the great societal changes occurring in the United States during this era, the time was ripe for the creation of a show like "Sesame Street".

Since 1962, Cooney had been producing talk shows and documentaries at educational television station WNDT, and in 1966 had won an Emmy for a documentary about poverty in America. In early 1966, Cooney and her husband Tim hosted a dinner party at their apartment in New York; experimental psychologist Lloyd Morrisett, who has been called "Sesame Street's" "financial godfather", and his wife Mary were among the guests. Cooney's boss, Lewis Freedman, whom Cooney called "the grandfather of "Sesame Street"", also attended the party, as did their colleague Anne Bower. As a vice-president at the Carnegie Corporation, Morrisett had awarded several million dollars in grants to organizations that educated poor and minority preschool children. Morrisett and the other guests felt that even with limited resources, television could be an effective way to reach millions of children.

A few days after the dinner party, Cooney, Freedman, and Morrisett met at the Carnegie Corporation's offices to make plans; they wanted to harness the addictive power of television for their own purposes, but did not yet know how. The following summer, despite Cooney's lack of experience in the field of education, Morrisett hired her to conduct research on childhood development, education and media, and she visited experts in these fields across the United States and Canada. She researched their ideas about the viewing habits of young children and wrote a report on her findings.

Cooney's study, titled "Television for Preschool Education", spelled out how television could be used to help young children, especially from low-income families, prepare for school. The focus on the new show was on children from disadvantaged backgrounds, but Cooney and the show's creators recognized that in order to achieve the kind of success they wanted, it had to be equally accessible to children of all socio-economic and ethnic backgrounds. At the same time, they wanted to make the show so appealing to inner-city children that it would help them learn as much as children with more educational opportunities.

Cooney proposed that public television, even though it had a poor track record in attracting inner-city audiences, could be used to improve the quality of children's programming. She suggested using the television medium's "most engaging traits", including high production values, sophisticated writing, and quality film and animation, to reach the largest audience possible. In the words of critic Peter Hellman, "If [children] could recite Budweiser jingles from TV, why not give them a program that would teach the ABCs and simple number concepts?" Cooney wanted to create a program that would spread values favoring education to nonviewers—including their parents and older siblings, who tended to control the television set. To this end, she suggested that humor directed toward adults be included, which, as Lesser reported, "may turn out to be a pretty good system in forcing the young child to stretch to understand programs designed for older audiences". Cooney also believed cultural references and guest appearances by celebrities would encourage parents and older siblings to watch the show together.

As a result of Cooney's proposal, the Carnegie Corporation awarded her a $1 million grant in 1968 to establish the Children's Television Workshop (CTW) to provide support to the creative staff of the new show. Morrisett, who was responsible for fundraising, procured additional grants from the United States federal government, the Corporation for Public Broadcasting, and the Ford Foundation for the CTW's initial budget, which totaled $8 million; obtaining funding from this combination of government agencies and private foundations protected the CTW from economic pressures experienced by commercial networks. "Sesame Street" was an expensive program to produce because the creators decided they needed to compete with other programs that invested in professional, high quality production.

The producers spent eighteen months preparing the new show, something unprecedented in children's television. The show had a budget of $28,000 per episode. After being named executive director of the CTW, Cooney began to assemble a team of producers: Jon Stone was responsible for writing, casting, and format; David Connell took over animation and volume; and Samuel Gibbon served as the show's chief liaison between the production staff and the research team. Stone, Connell, and Gibbon had worked on "Captain Kangaroo" together, but were not involved in children's television when Cooney recruited them. At first, Cooney planned to divide the show's production of five episodes a week among several teams, but she was advised by CBS vice-president Mike Dann to use only one. This production team was led by Connell, who had gained experience producing many episodes in a short period of time, a process called "volume production", during his eleven years working on "Captain Kangaroo".

The CTW hired Harvard University professor Gerald S. Lesser to design the show's educational objectives and establish and lead a National Board of Advisers. Instead of providing what Lesser called "window dressing", the Board actively participated in the construction of educational goals and creative methods. At the Board's direction, Lesser conducted five three-day curriculum planning seminars in Boston and New York City in summer 1968. The purpose of the seminars was to ascertain which school-preparation skills to emphasize in the new show. The producers gathered professionals with diverse backgrounds to obtain ideas for educational content. They reported that the seminars were "widely successful", and resulted in long and detailed lists of possible topics for inclusion in the "Sesame Street" curriculum; in fact, the seminars produced more suggested educational objectives than could ever be addressed by one television series.

Instead of focusing on the social and emotional aspects of development, the producers decided to follow the suggestions of the seminar participants and emphasize cognitive skills, a decision they felt was warranted by the demands of school and the wishes of parents. The objectives developed during the seminars were condensed into key categories: symbolic representation, cognitive processes, and the physical and social environment. The seminars set forth the new show's policy about race and social issues and provided the show's production and creative team with "a crash course" in psychology, child development, and early childhood education. They also marked the beginning of Jim Henson's involvement in "Sesame Street". Cooney met Henson at one of the seminars; Stone, who was familiar with Henson's work, felt that if they could not bring him on board, they should "make do without puppets".

The producers and writers decided to build the new show around a brownstone or an inner-city street, a choice Davis called "unprecedented". Stone was convinced that in order for inner-city children to relate to "Sesame Street", it needed to be set in a familiar place. Despite its urban setting, the producers decided to avoid depicting more negativity than what was already present in the child's environment. Lesser commented, "[despite] all its raucousness and slapstick humor, "Sesame Street" became a sweet show, and its staff maintains that there is nothing wrong in that".

The new show was called the "Preschool Educational Television Show" in promotional materials; the producers were unable to agree on a name they liked and waited until the last minute to make a decision. In a short, irreverent promotional film shown to public television executives, the producers parodied their "naming dilemma". The producers were reportedly "frantic for a title"; they finally settled on the name that they least disliked: "Sesame Street", inspired by Ali Baba's magical phrase, although there were concerns that it would be too difficult for young children to pronounce. Stone was one of the producers who disliked the name, but, he said, "I was outvoted, for which I'm deeply grateful".

The responsibility of casting for "Sesame Street" fell to Jon Stone, who set out to form a cast where white actors were in the minority. He did not begin auditions until spring 1969, several weeks before five test shows were due to be produced. He filmed the auditions, and Palmer took them into the field to test children's reactions. The actors who received the "most enthusiastic thumbs up" were cast. For example, Loretta Long was chosen to play Susan when the children who saw her audition stood up and sang along with her rendition of "I'm a Little Teapot". Stone reported that casting was the only aspect that was "just completely haphazard". Most of the cast and crew found jobs on "Sesame Street" through personal relationships with Stone and the other producers. Stone hired Bob McGrath (an actor and singer best known at the time for his appearances on Mitch Miller's sing-along show on NBC) to play Bob, Will Lee to play Mr. Hooper, and Garrett Saunders to play Gordon.

"Sesame Street" was the first children's television program that used a curriculum with clear and measurable outcomes, and was the first to use research in the creation of the show's design and content. Research in "Sesame Street" had three functions: to test if the show was appealing to children, to discover what could be done to make the show more appealing, and to report to the public and the investors what impact the show had on its young viewers. Ten to fifteen percent of the show's initial budget of $8 million was devoted to research, and researchers were always present in the studio during the show's filming. A "Writer's Notebook" was developed to assist writers and producers in translating the research and production goals into televised material; this connected the show's curriculum goals and its script development. The Muppet characters were created to fill specific curriculum needs: Oscar the Grouch, for example, was designed to teach children about their positive and negative emotions. Lesser called the collaboration between researchers and producers, as well as the idea of using television as an educational tool, the "CTW model". Cooney agreed, commenting, "From the beginning, we—the planners of the project—designed the show as an experimental research project with educational advisers, researchers, and television producers collaborating as equal partners".

The producers of "Sesame Street" believed education through television was possible if they captured and sustained children's attention; this meant the show needed a strong appeal. Edward Palmer, the CTW's first Director of Research and the man Cooney credited with building the CTW's foundation of research, was one of the few academics in the late 1960s researching children's television. He was recruited by the CTW to test if the curricula developed in the Boston seminars were reaching their audience effectively. Palmer was also tasked with designing and executing the CTW's in-house research and with working with the Educational Testing Service (ETS). His research was so crucial to Sesame Street that Gladwell asserted, "... without Ed Palmer, the show would have never lasted through the first season".

Palmer and his team's approach to researching the show's effectiveness was innovative; it was the first time formative research was conducted in this way. For example, Palmer developed "the distractor", which he used to test if the material shown on "Sesame Street" captured young viewers' attention. Two children at a time were brought into the laboratory; they were shown an episode on a television monitor and a slide show next to it. The slides would change every seven seconds, and researchers recorded when the children's attention was diverted away from the episode. They were able to record almost every second of "Sesame Street" this way; if the episode captured the children's interest 80–90% of the time, the producers would air it, but if it only tested 50%, they would reshoot. By the fourth season of the show, the episodes rarely tested below 85%.

During the production of "Sesame Street's" first season, producers created five one-hour episodes to test the show's appeal to children and examine their comprehension of the material. Not intended for broadcast, they were presented to preschoolers in 60 homes throughout Philadelphia and in day care centers in New York City in July 1969. The results were "generally very positive"; children learned from the shows, their appeal was high, and their attention was sustained over the full hour. However, the researchers found that although children's attention was high during the Muppet segments, their interest wavered during the "Street" segments, when no Muppets were on screen. This was because the producers had followed the advice of child psychologists who were concerned that children would be confused if human actors and Muppets were shown together. As a result of this decision, the appeal of the test episodes was lower than the target.

The Street scenes, as Palmer described them, were "the glue" that "pulled the show together", so producers knew they needed to make significant changes. On the basis of their experience on "Captain Kangaroo", Cannell, Stone, and Gibbon thought the experts' opinions were "nonsense"; Cooney agreed. Lesser called their decision to defy the recommendations of their advisers "a turning point in the history of "Sesame Street"". The producers reshot the Street segments; Henson and his coworkers created Muppets that could interact with the human actors, specifically Oscar the Grouch and Big Bird, who became two of the show's most enduring characters. In addition, the producers found Saunders' role as Gordon not to be as likable by children watching the show, resulting in the character being recast by Matt Robinson, who was initially the show's filmed segments producer. These test episodes were directly responsible for what Gladwell called "the essence of "Sesame Street"—the artful blend of fluffy monsters and earnest adults".

Two days before the show's premiere, a thirty-minute preview entitled "This Way to Sesame Street" aired on NBC. The show was financed by a $50,000 grant from Xerox. Written by Stone and produced by CTW publicist Bob Hatch, it was taped the day before it aired. "Newsday" called the preview "a unique display of cooperation between commercial and noncommercial broadcasters".

"Sesame Street" premiered November 10, 1969. It was widely praised for its originality, and was well received by parents as well as children. The show reached only 67.6% of the nation, but earned a 3.3 Nielsen rating, meaning 1.9 million households and 7 million children watched it each day. In "Sesame Street's" first season, the ETS reported that children who watched the show scored higher in tests than less-frequent viewers.

In November 1970, the cover of "Time" magazine featured Big Bird, who had received more fan mail than any of the show's human hosts. The magazine declared, "... It is not only the best children's show in TV history, it is one of the best parents' shows as well". An executive at ABC, while recognizing that "Sesame Street" was not perfect, said the show "opened children's TV to taste and wit and substance" and "made the climate right for improvement". Other reviewers predicted commercial television would be forced to improve its children's programming, something that did not substantially occur until the 1990s. "Sesame Street" won a Peabody Award, three Emmys, and the Prix Jeunesse award in 1970. President Richard Nixon sent Cooney a congratulatory letter,<Davis, pp. 198-199</ref> and Dr. Benjamin Spock predicted the program would result in "better-trained citizens, fewer unemployables in the next generation, fewer people on welfare, and smaller jail populations".

"Sesame Street" was not without its detractors; there was little criticism of the show in the months following its premiere, but it increased at the end of its first season and beginning of the second season. In May 1970, a state commission in Mississippi voted to not air the show on the state's newly launched public television network. A member of the commission leaked the vote to "The New York Times," stating that "Mississippi was not yet ready" for the show's integrated cast. Cooney called the ban "a tragedy for both the white and black children of Mississippi". The state commission reversed its decision after the vote made national news.

The producers of "Sesame Street" made a few changes in its second season. Segments that featured children became more spontaneous and allowed more impromptu dialogue, even when it meant cutting other segments. Since federal funds had been used to produce the show, more segments of the population insisted upon being represented on "Sesame Street"; for example, the show was criticized by Hispanic groups for the lack of Latino characters in the early years of production. A committee of Hispanic activists, commissioned by the CTW in 1970, called "Sesame Street" "racist" and said the show's bilingual aspects were of "poor quality and patronizing". The CTW responded to these critics by hiring Hispanic actors, production staff, and researchers. By the mid-70s, Morrow reported that "the show included Chicano and Puerto Rican cast members, films about Mexican holidays and foods, and cartoons that taught Spanish words".

While "New York Magazine" reported criticism of the presence of strong single women in the show, organizations like the National Organization for Women (NOW) expressed concerns that the show needed to be "less male-oriented". For example, members of NOW took exception to the character Susan, who was originally a housewife. They complained about the lack of, as Morrow put it, "credible female Muppets" on the show; Morrow reported that Henson's response was that "women might not be strong enough to hold the puppets over the long hours of taping". The show's producers responded by making Susan a nurse and by hiring a female writer.

By the mid-1970s, "Sesame Street", according to Davis, had become "an American institution". ETS conducted two "landmark" studies of the show in 1970 and 1971 which demonstrated "Sesame Street" had a positive educational impact on its viewers. The results of these studies led to the producers securing funding for the show over the next several years, and provided the CTW with additional ways to promote it. By the second season, "Sesame Street" had become so popular that the design of ETS' experiments to track the show's educational outcomes had to be changed: instead of comparing viewers with a control group of non-viewers, the researchers studied the differences among levels of viewing. They found that children who watched "Sesame Street" more frequently had a higher comprehension of the material presented.

Producer Jon Stone was instrumental in guiding the show during these years. According to Davis, Stone "gave "Sesame Street" its soul"; without him "there would not have been "Sesame Street" as we know it". Frank Oz regarded Stone as "the father of "Sesame Street"", and Cooney considered Stone "the key creative talent on "Sesame Street" and "probably the most brilliant writer of children's material in America". Stone was able to recognize and mentor talented people for his crew. He actively hired and promoted women during a time when few women earned top production jobs in television. His policies provided the show with a succession of female producers and writers, many of whom went on to lead the boom in children's programming at Nickelodeon, the Disney Channel, and PBS in the 1990s and 2000s. One of these women was Dulcy Singer, who later became the first female executive producer of "Sesame Street".

After the show's initial success, its producers began to think about its survival beyond its development and first season and decided to explore other funding sources. The CTW decided to depend upon government agencies and private foundations to develop the show. This would protect it from the financial pressures experienced by commercial networks, but created problems in finding continued support. This era in the show's history was marked by conflicts between the CTW and the federal government; in 1978, the US Department of Education refused to deliver a $2 million check until the last day of the CTW's fiscal year. As a result, the CTW decided to depend upon licensing arrangements, publishing, and international sales for its funding. Henson owned the trademarks to the Muppet characters: he was reluctant to market them at first, but agreed when the CTW promised that the profits from toys, books, and other products were to be used exclusively to fund the CTW. The producers demanded complete control over all products and product decisions; any product line associated with the show had to be educational, inexpensive, and not advertised during its airings. The CTW approached Random House to establish and manage a non-broadcast materials division. Random House and the CTW named Christopher Cerf to assist the CTW in publishing books and other materials that emphasized the curriculum. In 1980, the CTW began to produce a touring stage production based upon the show, written by Connell and performed by the Ice Follies.

Shortly after the premiere of "Sesame Street", the CTW was approached by producers, educators, and officials in other nations, requesting that a version of the show be aired in their countries. Former CBS executive Mike Dann left commercial television to become vice-president of the CTW and Cooney's assistant; Dann began what Charlotte Cole, vice president for the CTW's International Research department, called the "globalization" of "Sesame Street". A flexible model was developed, based upon the experiences of the creators and producers of the original show. The shows came to be called "co-productions", and they contained original sets, characters, and curriculum goals. Depending upon each country's needs and resources, different versions were produced, including dubbed versions of the original show and independent programs. By 2009, "Sesame Street" had expanded into 140 countries; "The New York Times" reported in 2005 that income from the CTW's international co-productions of the show was $96 million.

"Sesame Street's" cast expanded in the 1970s, better fulfilling the show's original goal of greater diversity in both human and Muppet characters. The cast members who joined the show were Sonia Manzano (Maria), who also wrote for the show, Northern Calloway (David), Alaina Reed (Olivia), Emilio Delgado (Luis), Linda Bove (Linda), and Buffy Sainte-Marie (Buffy). In 1975, Roscoe Orman became the third actor to play Gordon, succeeding Hal Miller, who had briefly replaced Matt Robinson.

New Muppet characters were introduced during the 1970s. Count von Count was created and performed by Jerry Nelson, who also voiced Mr. Snuffleupagus, a large Muppet that required two puppeteers to operate. Richard Hunt, who, in Jon Stone's words, joined the Muppets as a "wild-eyed 18-year-old and grew into a master puppeteer and inspired teacher", created Gladys the Cow, Forgetful Jones, Don Music, and the construction worker Sully. Telly Monster was performed by Brian Muehl; Marty Robinson took over the role in 1984. Frank Oz created Cookie Monster. Matt Robinson created the "controversial" (as Davis called him) character Roosevelt Franklin. Fran Brill, the first female puppeteer for the Muppets, joined the Henson organization in 1970, and originated the character Prairie Dawn. In 1975, Henson created "The Muppet Show", which was filmed and produced in London; Henson brought many of the Muppet performers with him, so opportunities opened up for new performers and puppets to appear on "Sesame Street".

The CTW wanted to attract the best composers and lyricists for "Sesame Street", so songwriters like Joe Raposo, the show's music director, and writer Jeff Moss were allowed to retain the rights to the songs they wrote. The writers earned lucrative profits, and the show was able to sustain public interest. Raposo's "I Love Trash", written for Oscar the Grouch, was included on the first album of "Sesame Street" songs, "The Sesame Street Book & Record", recorded in 1970. Moss' "Rubber Duckie", sung by Henson for Ernie, remained on the Top-40 Billboard charts for seven weeks that same year. Another Henson song, written by Raposo for Kermit the Frog in 1970, "Bein' Green", which Davis called "Raposo's best-regarded song for "Sesame Street"", was later recorded by Frank Sinatra and Ray Charles. "Sing", which became a hit for The Carpenters in 1973, and "Somebody Come and Play", were also written by Raposo for "Sesame Street".

In 1978, Stone and Singer produced and wrote the show's first special, the "triumphant" "Christmas Eve on Sesame Street", which included an O Henry-inspired storyline in which Bert and Ernie gave up their prized possessions—Ernie his rubber ducky and Bert his paper clip collection—to purchase each other Christmas gifts. Bert and Ernie were played by Frank Oz and Jim Henson, who in real life were, like the puppets they played, colleagues and friends. To Davis, this demonstrated the puppeteers' remarkable ability to play "puppetry's Odd Couple". In Singer's opinion, the special—which Stone also wrote and directed—demonstrated Stone's "soul", and Sonia Manzano called it a good example of what "Sesame Street" was all about. The special won Emmys for Stone and Singer in 1979, beating, among others, an independently-produced "Sesame Street" special for CBS.

By the show's tenth anniversary in 1979, nine million American children under the age of six were watching "Sesame Street" daily. Four out of five children had watched it over a six-week period, and 90% of children from low-income inner-city homes regularly viewed the show.

In 1984, the Federal Communications Commission (FCC) deregulated commercial restrictions on children's television. Advertising during network children's programs almost doubled, and deregulation resulted in an increase in commercially oriented programming. "Sesame Street" was successful during this era of deregulation despite the fact that the United States government terminated all federal funding of the CTW in 1981. By 1987, the show was earning $42 million per year from its magazine division, book royalties, product licensing, and foreign income—enough to cover two-thirds of its expenses. Its remaining budget, plus a $6 million surplus, was covered by revenue from its PBS broadcasts.

According to Davis, "Sesame Street"s second decade was spent "turning inward, expanding its young viewers' world". The show's curriculum grew to include more "affective" teaching—relationships, ethics, and positive and negative emotions. Many of the show's storylines were taken from the experiences of its writing staff, cast, and crew. In 1982, Will Lee, who had played Mr. Hooper since the show's premiere, died. For the 1983 season, the show's producers and research staff decided they would explain Mr. Hooper's death to their preschool audience, instead of recasting the role: the writer of that episode, Norman Stiles, said, "We felt we owed something to a man we respected and loved". They convened a group of psychologists, religious leaders, and other experts in the field of grief, loss, and separation. The research team conducted a series of studies before the episode to ascertain if children were able to understand the messages they wanted to convey about Mr. Hooper's death; the research showed most children did understand. Parents' reactions to the episode were, according to the CTW's own reports, "overwhelmingly positive". The episode, which won an Emmy, aired on Thanksgiving Day in 1983 so parents could be home to discuss it with their children. Author David Borgenicht called the episode "poignant"; Davis called it "a landmark broadcast" and "a truly memorable episode, one of the show's best". Caroll Spinney, who played Big Bird and who drew the caricatures prominently used in the episode, reported the cast and crew were moved to tears during filming.

In the mid-1980s, Americans were becoming more aware of the prevalence of child abuse, so "Sesame Street"s researchers and producers decided to "reveal" Mr. Snuffleupagus in 1985. "Snuffy" had never been seen by any of the adults on the show and was considered Big Bird's "imaginary friend". The show's producers were concerned about the message being sent to children; "If children saw that the adults didn't believe what Big Bird said (even though it was true), they would be afraid to talk to adults about dramatic or disturbing things that happened to them".

For the 1988 and 1989 seasons, the topics of love, marriage, and childbirth were addressed when the show presented a storyline in which the characters Luis and Maria fall in love, marry, and have a child named Gabi. Sonia Manzano, the actress who played Maria, had married and become pregnant; according to the book "Sesame Street Unpaved", published after the show's thirtieth anniversary in 1999, Manzano's real-life experiences gave the show's writers and producers the idea. Before writing began, research was done to gain an understanding of what previous studies had revealed about preschoolers' understanding of love, marriage, and family. The show's staff found that at the time that there was very little relevant research done about children's understanding of these topics, and no books for children had been written about them. Studies done after the episodes about Maria's pregnancy aired showed that as a result of watching these episodes, children's understanding of pregnancy increased.

Davis called the 1990s a "time of transition on Sesame Street". Several people involved in the show from its beginnings died during this period: Jim Henson in 1990 at the age of 53 "from a runaway strep infection gone stubbornly, foolishly untreated"; songwriter Joe Raposo from non-Hodgkin's lymphoma fifteen months earlier; long-time cast member Northern Calloway of cardiac arrest in January 1990; puppeteer Richard Hunt of AIDS in early 1992; CTW founder and producer David Connell of bladder cancer in 1995; director Jon Stone of amyotrophic lateral sclerosis in 1997; and writer Jeff Moss of colon cancer in 1998.

By the early 1990s, "Sesame Street" was, as Davis put it, "the undisputed heavyweight champion of preschool television". "Entertainment Weekly" reported in 1991 that the show's music had been honored with eight Grammys. The show's dominance, however, was soon challenged by another PBS television show for preschoolers, "Barney & Friends", and "Sesame Street's" ratings declined. The producers of "Sesame Street" responded, at the show's twenty-fifth anniversary in 1993, by expanding and redesigning the show's set, calling it "Around the Corner". New human and Muppet characters were introduced, including Zoe (performed by Fran Brill), baby Natasha and her parents Ingrid and Humphrey, and Ruthie (played by comedian Ruth Buzzi). The "Around the Corner" set was dismantled in 1997. Zoe, one of the few characters that survived, was created to include another female Muppet on the show: her spunky and fearless personality was intended to break female stereotypes. According to Davis, she was the first character developed on the show by marketing and product development specialists, who worked with the researchers at the CTW. (The quest for a "break-out" female Muppet character continued into 2006 with the creation of Abby Cadabby, who was created after nine months of research.) In 1998, for the first time in the show's history, "Sesame Street" pursued funding by accepting corporate sponsorship. Consumer advocate Ralph Nader, who had been a guest on the show, urged parents to protest the move by boycotting the show.
For "Sesame Street"s 30th anniversary in 1999, its producers researched the reasons for the show's lower ratings. For the first time since the show debuted, the producers and a team of researchers analyzed "Sesame Street" content and structure during a series of two-week-long workshops. They also studied how children's viewing habits had changed in the past thirty years. They found that although the show was produced for those between the ages of three and five, children began watching it at a younger age. Preschool television had become more competitive, and the CTW's research showed the traditional magazine format was not the best way to attract young children's attention. The growth of home videos during the '80s and the increase of thirty-minute children's shows on cable had demonstrated that children's attention could be sustained for longer periods of time, but the CTW's researchers found that their viewers, especially the younger ones, lost attention in "Sesame Street" after 40 to 45 minutes.

Beginning in 1998, a new 15-minute segment shown at the end of each episode, "Elmo's World", used traditional elements (animation, Muppets, music, and live-action film), but had a more sustained narrative. "Elmo's World" followed the same structure each episode, and depended heavily on repetition. Unlike the realism of the rest of the show, the segment took place in a stylized crayon-drawing universe as conceived by its host. Elmo, who represented the three- to four-year-old child, was chosen as host of the closing segment because he had always tested well with this segment of their audience. He was created in 1980 and originally performed by Brian Muehl, and later Richard Hunt, but did not become what his eventual portrayer, Kevin Clash, called a "phenomenon" until Clash took over the role in 1985. Eventually, Elmo became, as Davis reported, "the embodiment" of "Sesame Street", and "the marketing wonder of our age" when five million "Tickle Me Elmo" dolls were sold in 1996. Clash believed the "Tickle Me Elmo" phenomenon made Elmo a household name and led to the "Elmo's World" segment. Michael Jeter was a favorite with younger audiences in his role as Mr. Noodle's brother, Mister Noodle on Sesame Street from 1999 to 2003.

In 2002, "Sesame Street"s producers went further in changing the show to reflect its younger demographic, fundamentally changing the show's structure, which had relied on "Street scenes" interrupted by live-action videos and animation. The target age for "Sesame Street" shifted downward, from four years to three years, after the show's 33rd season. As co-executive producer Arlene Sherman stated, "We basically deconstructed the show". The producers expanded upon the "Elmo's World" by changing from a magazine format to a narrative format, which made the show easier for young children to navigate. Sherman called the show's new look "startlingly different". Following its tradition of addressing emotionally difficult topics, "Sesame Street's" producers chose to address the attacks of 9/11 during this season on its premiere episode, which aired February 4, 2002. This episode, as well as a series of four episodes that aired after Hurricane Katrina in 2005, were used in Sesame Workshop's Community Outreach program.

In 2006, the United States Department of State called "Sesame Street" "the most widely viewed children's television show in the world". Over half of the show's international co-productions were made after 2001; according to the 2006 documentary "The World According to Sesame Street", the events of 9/11 inspired the producers of these co-productions. In 2003, "Takalani Sesame", a South African co-production, elicited criticism in the United States when its producers created Kami, the first HIV-positive Muppet, whose purpose was educating children in South Africa about the epidemic of AIDS. The controversy, which surprised the Sesame Workshop, was short-lived and died down after Kofi Annan and Jerry Falwell praised the Workshop's efforts. By 2006, "Sesame Street" had won more Emmy Awards than any other children's show, including winning the outstanding children's series award for twelve consecutive years—every year the Emmys included the category. By 2009, the show had won 118 Emmys throughout its history, and was awarded the Outstanding Achievement Emmy for its 40 years on the air.

By "Sesame Street"s 40th anniversary, it was ranked the fifteenth most popular children's show on television. When the show premiered in 1969, 130 episodes a year were produced; in 2009, because of rising costs, twenty-six episodes were made. In 2000, the Children's Television Workshop, which had changed its name to the Sesame Workshop (SW) in June 2000 to better reflect its entry into non-television and interactive media, launched a website with a library of free video clips and free podcasts from throughout the show's history. The 2008–2009 recession, which led to budget cuts for many nonprofit arts organizations, severely affected "Sesame Street"; in spring 2009, the SW had to lay off 20% of its staff.

"Sesame Street"s 40th anniversary was commemorated by the 2008 publication of "Street Gang: The Complete History of Sesame Street", by Michael Davis, which has been called "the definitive statement" about the history of the show.

Starting in 2009, the producers of "Sesame Street" took steps to bring back older viewers; it was also successful in increasing its audience viewership among 3-to-5 year-olds by the end of the 40th season. In 2012, the show's 43rd season, "Elmo's World" was replaced with "Elmo the Musical", which was targeted at the program's older viewers. Subsequently, in September 2014, starting with the show's 45th season, Sesame Workshop began distributing a half-hour version of the program to PBS member stations. The new version, which complemented the existing hour-long broadcast and focuses more on interstitial segments (although certain segments such as "Elmo the Musical" or "Abby's Flying Fairy School" are omitted from that version), was added because of increasing mobile and online viewing among children as well as growing competition for preschoolers on linear and online television, an increase in use of PBS Kids' mobile video app during 2013 and decreasing broadcast viewership; the half-hour version airs weekday afternoons on PBS member television stations (with the hour-long version continuing to air in the morning) and was made available for streaming online and on mobile devices through PBS' website, mobile app and Roku channel.

On August 13, 2015, as part of a five-year programming and development deal, Sesame Workshop announced that first-run episodes of "Sesame Street" would move to premium television service HBO (which had not aired any original children's programming since 2005) in late 2015. Sesame Workshop sought the deal because of declining revenue from viewer donations, and decreases in distribution fees paid by PBS member stations and licensing for merchandise sales (particularly through Sesame Workshop's dependence upon revenue from DVD sales), with the intent to having the show remain on PBS in some fashion (HBO already had involvement in public television at the time of the deal, providing funding for the talk show "Charlie Rose"); the deal also came in the wake of changing viewing habits of American children over the previous ten years. HBO will hold first-run rights to all newer episodes of the series starting with season 46, after which they will air on PBS member stations following a nine-month exclusivity window, with no charge to the stations for airing the content; however, HBO has not announced whether first-run episodes will air on the pay service's main channel or its multiplex channel HBO Family. The agreement also gives HBO exclusive rights to stream past and future "Sesame Street" episodes on HBO Go and HBO Now – assuming those rights from Amazon Video and Netflix. On August 14, Sesame Workshop announced that it would phase out its in-house subscription streaming service, Sesame Go, as a standalone service; instead of shutting it down entirely, it intends to scale back its offerings to either provide access to a reduced slate of free content or act as a portal for "Sesame Street"s website.

In April 2017, "Sesame Street" introduced a new Muppet called Julia with Autism to the show.

In 2019, "Sesame Street" will celebrate its "50th anniversary" with a traveling show performing from February until December 2019.



</doc>
<doc id="263286" url="https://en.wikipedia.org/wiki?curid=263286" title="Antbird">
Antbird

The antbirds are a large passerine bird family, Thamnophilidae, found across subtropical and tropical Central and South America, from Mexico to Argentina. There are more than 230 species, known variously as antshrikes, antwrens, antvireos, fire-eyes, bare-eyes and bushbirds. They are related to the antthrushes and antpittas (family Formicariidae), the tapaculos, the gnateaters and the ovenbirds. Despite some species' common names, this family is not closely related to the wrens, vireos or shrikes.

Antbirds are generally small birds with rounded wings and strong legs. They have mostly sombre grey, white, brown and rufous plumage, which is sexually dimorphic in pattern and colouring. Some species communicate warnings to rivals by exposing white feather patches on their backs or shoulders. Most have heavy bills, which in many species are hooked at the tip.

Most species live in forests, although a few are found in other habitats. Insects and other arthropods form the most important part of their diet, although small vertebrates are occasionally taken. Most species feed in the understory and midstory of the forest, although a few feed in the canopy and a few on the ground. Many join mixed-species feeding flocks, and a few species are core members. To various degrees, around eighteen species specialise in following swarms of army ants to eat the small invertebrates flushed by the ants, and many others may feed in this way opportunistically.

Antbirds are monogamous, mate for life, and defend territories. They usually lay two eggs in a nest that is either suspended from branches or supported on a branch, stump, or mound on the ground. Both parents share the tasks of incubation and of brooding and feeding the nestlings. After fledging, each parent cares exclusively for one chick.

Thirty-eight species are threatened with extinction as a result of human activities. Antbirds are not targeted by either hunters or the pet trade. The principal threat is habitat loss, which causes habitat fragmentation and increased nest predation in habitat fragments.

The antbird family Thamnophilidae used to be considered a subfamily, Thamnophilinae, within a larger family Formicariidae that included antthrushes and antpittas. Formerly, that larger family was known as the "antbird family" and the Thamnophilinae were "typical antbirds". In this article, "antbird" and "antbird family" refer to the family Thamnophilidae.

Thamnophilidae was removed from Formicariidae, leaving behind the antthrushes and antpittas, due to recognition of differences in the structure of the breastbone (sternum) and syrinx, and Sibley and Ahlquist's examination of DNA–DNA hybridization. The Thamnophilidae antbirds are members of the infraorder Tyrannides (or tracheophone suboscines), one of two infraorders in the suborder Tyranni. The Thamnophilidae are now thought to occupy a fairly basal position within the infraorder, i. e. with regard to their relatives the antthrushes and antpittas, tapaculos, gnateaters, and also the ovenbirds. The sister group of the Thamnophilidae is thought to be the gnateaters. The ovenbirds, tapaculos, antthrushes and antpittas are thought to represent a different radiation of that early split.

The antbird family contains over 230 species, variously called antwrens, antvireos, antbirds and antshrikes. The names refer to the relative sizes of the birds (increasing in the order given, though with exceptions) rather than any particular resemblance to the true wrens, vireos or shrikes. In addition, members of the genus "Phlegopsis" are known as bare-eyes, "Pyriglena" as fire-eyes and "Neoctantes" and "Clytoctantes" as bushbirds. Although the systematics of the Thamnophilidae is based on studies from the mid-19th century, when fewer than half the present species were known, comparison of the myoglobin intron 2, GAPDH intron 11 and the mtDNA cytochrome "b" DNA sequences has largely confirmed it. There are two major clades – most antshrikes and other larger, strong-billed species as well as "Herpsilochmus", versus the classical antwrens and other more slender, longer-billed species – and the monophyly of most genera was confirmed.

The Thamnophilidae contains several large or very large genera and numerous small or monotypic ones. Several, which are difficult to assign, seem to form a third, hitherto unrecognised clade independently derived from ancestral antbirds. The results also confirmed suspicions of previous researchers that some species, most notably in "Myrmotherula" and "Myrmeciza", need to be assigned to other genera. Still, due to the difficulties of sampling from such a large number of often poorly known species, the assignment of some genera is still awaiting confirmation.

The antbirds are a group of small to medium-sized passerines that range in size from the large giant antshrike, which measures 45 cm (18 in) and weighs 150  g (5.29  oz), to the tiny 8-cm (3 in) pygmy antwren, which weighs 7  g (0.25 oz). In general terms, "antshrikes" are relatively large-bodied birds, "antvireos" are medium-sized and chunky, while "antwrens" include most smaller species; "antbird" genera can vary greatly in size. Members of this family have short rounded wings that provide good manoeuvrability when flying in dense undergrowth. The legs are large and strong, particularly in species that are obligate ant-followers. These species are well adapted to gripping vertical stems and saplings, which are more common than horizontal branches in the undergrowth, and thus the ability to grip them is an advantage for birds following swarms of army ants. The claws of these antbirds are longer than those of species that do not follow ants, and the soles of some species have projections that are tough and gripping when the foot is clenched. Tarsus length in antbirds is related to foraging strategy. Longer tarsi typically occur in genera such as the "Thamnophilus" antshrikes that forage by perch-gleaning (sitting and leaning forward to snatch insects from the branch), whereas shorter tarsi typically occur in those that catch prey on the wing, such as the "Thamnomanes" antshrikes.

Most antbirds have proportionately large, heavy bills. Several genera of antshrike have a strongly hooked tip to the bill, and all antbirds have a notch or 'tooth' at the tip of the bill which helps in holding and crushing insect prey. The two genera of bushbirds have upturned chisel-like bills.

The plumage of antbirds is soft and not brightly coloured, although it is occasionally striking. The colour palette of most species is blackish shades, whitish shades, rufous, chestnut and brown. Plumages can be uniform in colour or patterned with barring or spots. Sexual dimorphism – differences in plumage colour and pattern between males and females – is common in the family. Overall the pattern within the family is for the males to have combinations of grey, black or white plumage and the females having buff, rufous and brown colours. For example, the male dot-winged antwren is primarily blackish, whereas the female has rust-coloured underparts. In some genera, such as "Myrmotherula", species are better distinguished by female plumage than by male. Many species of antbirds have a contrasting 'patch' of white (sometimes other colours) feathers on the back (known as interscapular patches), shoulder or underwing. This is usually concealed by the darker feathers on the back but when the bird is excited or alarmed these feathers can be raised to flash the white patch. dot-winged antwrens puff out white back patches, whereas in bluish-slate antshrikes and white-flanked antwrens the white patch is on the shoulder.

The songs and calls of antbirds are generally composed of repeated simple uncomplicated notes. The family is one of the suboscines (suborder Tyranni) which have simpler syrinxes ("voiceboxes") than other songbirds. Nevertheless, their songs are distinctive and species-specific, allowing field identification by ear. Antbirds rely on their calls for communication, as is typical of birds in dark forests. Most species have at least two types of call, the "loudsong" and the "softsong". The functions of many calls have been deduced from their context; for example some loudsongs have a territorial purpose and are given when birds meet at the edges of their territories, or during the morning rounds of the territory. Pairs in neighbouring territories judge the proximity of rivals by the degradation of the song caused by interference by the environment. In bouts of territorial defence the male will face off with the other male and the female with her counterpart. Loudsong duets are also potentially related to the maintenance of pair bonds. The functions of softsongs are more complex, and possibly related to pair-bond maintenance. In addition to these two main calls a range of other sounds are made; these include scolding in mobbing of predators. The calls of antbirds are also used interspecifically. Some species of antbirds and even other birds will actively seek out ant-swarms using the calls of some species of ant-followers as clues.

The distribution of the antbirds is entirely Neotropical, with the vast majority of the species being found in the tropics. A few species reach southern Mexico and northern Argentina. Some species, such as the barred antshrike, have a continental distribution that spans most of the South and Middle American distribution of the family; others, such as the ash-throated antwren, have a tiny distribution.

Antbirds are mostly birds of humid lowland rainforests. Few species are found at higher elevations, with less than 10% of species having ranges above 2000  m (6500 ft) and almost none with ranges above 3000  m (10000 ft). The highest species diversity is found in the Amazon basin, with up to 45 species being found in single locations in sites across Brazil, Colombia, Bolivia and Peru. The number of species drops dramatically towards the further reaches of the family's range; there are only seven species in Mexico, for example. Areas of lower thamnophilid diversity may contain localised endemics, however. The Yapacana antbird, for example, is restricted to the stunted woodlands that grow in areas of nutrient-poor white-sand soil (the so-called Amazonian caatinga) in Brazil, Venezuela and Colombia. Some species are predominantly associated with microhabitats within a greater ecosystem; for example, the bamboo antshrike is predominantly found in bamboo patches.

Antbirds are diurnal: they feed, breed and defend territories during the day. Many of the family are, however, reluctant to enter areas of direct sunlight where it breaks through the forest canopy. Antbirds will engage in anting, a behaviour in which ants (or other arthropods) are rubbed on the feathers before being discarded or eaten. While this has conventionally been considered a way to remove and control feather parasites, it has been suggested that for antbirds it may simply be a way to deal with the distasteful substances in prey items.

The main component of the diet of all antbirds is arthropods. These are mostly insects, including grasshoppers and crickets, cockroaches, praying mantises, stick insects and the larvae of butterflies and moths. In addition antbirds often take spiders, scorpions and centipedes. They swallow smaller prey items quickly, whereas they often beat larger items against branches in order to remove wings and spines. Larger species can kill and consume frogs and lizards as well, but generally these do not form an important part of the diet of this family. Other food items may also be eaten, including fruit, eggs and slugs.

The family uses a number of techniques to obtain prey. The majority of antbirds are arboreal, with most of those feeding in the understory, many in the middle story and some in the canopy. A few species feed in the leaf litter; for example, the wing-banded antbird forages in areas of dense leaf-litter. It does not use its feet to scratch the leaf litter, as do some other birds; instead it uses its long bill to turn over leaves rapidly (never picking them up). The antbirds that forage arboreally show a number of techniques and specialisations. Some species perch-glean, perching on a branch watching for prey and snatching it by reaching forward, where others sally from a perch and snatch prey on the wing. In both cases birds will hop through the foliage or undergrowth and pause, scanning for prey, before pouncing or moving on. The time paused varies, although smaller species tend to be more active and pause for shorter times.

Many species participate in mixed-species feeding flocks, forming a large percentage of the participating species within their range. Some of these are core or "nuclear species". These nuclear species share territories with other nuclear species but exclude conspecifics (members of the same species) and are found in almost all flocks; these are joined by "attendant species". Loud and distinctive calls and conspicuous plumage are important attributes of nuclear species as they promote cohesion in the flock. The composition of these flocks varies geographically; in Amazonia species of "Thamnomanes" antshrike are the leading nuclear species; elsewhere other species, such as the dot-winged antwrens and checker-throated antwrens, fill this role. Other species of antwren and antbird join them along with woodcreepers, ant-tanagers, foliage-gleaners and greenlets. The benefits of the mixed flock are thought to be related to predation, since many eyes are better for spotting predatory hawks and falcons. Comparisons between multi-species feeding flocks in different parts of the world found that instances of flocking were positively correlated with predation risk by raptors. For example, where "Thamnomanes" antshrikes lead the group they give loud warning calls in the presence of predators. These calls are understood and reacted to by all the other species in the flock. The advantage to the "Thamnomanes" antshrikes is in allowing the rest of the flock, which are typically gleaners, to act as beaters, flushing prey while foraging which the antshrikes can obtain by sallying. Similar roles are filled in other flocks by other antbird species or other bird families, for example the shrike-tanagers. Within the feeding flocks competition is reduced by microniche partitioning; where dot-winged antwrens, checker-throated antwrens and white-flanked antwrens feed in flocks together, the dot-wings feed in the densest vines, the white-flank in less dense vegetation, and the checker-throats in the same density as the latter but in dead foliage only.

Swarms of army ants are an important resource used by some species of antbird, and the one from which the family's common name is derived. Many species of tropical ant form large raiding swarms, but the swarms are often nocturnal or raid underground. While birds visit these swarms when they occur, the species most commonly attended by birds is the Neotropical species "Eciton burchellii", which is both diurnal and surface-raiding. It was once thought that attending birds were actually eating the ants, but numerous studies in various parts of "Eciton burchellii's" range has shown that the ants act as beaters, flushing insects, other arthropods and small vertebrates into the waiting flocks of "ant followers". The improvement in foraging efficiency can be dramatic; a study of spotted antbirds found that they made attempts at prey every 111.8 seconds away from ants, but at swarms they made attempts every 32.3 seconds. While many species of antbirds (and other families) may opportunistically feed at army ant swarms, 18 species of antbird are obligate ant-followers, obtaining most of their diet from swarms. With only three exceptions, these species never regularly forage away from ant swarms. A further four species regularly attend swarms but are as often seen away from them. Obligate ant-followers visit the nesting bivouacs of army ants in the morning to check for raiding activities; other species do not. These species tend to arrive at swarms first, and their calls are used by other species to locate swarming ants.

Because army ants are unpredictable in their movements, it is impractical for obligate ant-followers to maintain a territory that always contains swarms to feed around. Antbirds have evolved a more complicated system than the strict territoriality of most other birds. They generally (details vary among species) maintain breeding territories but travel outside those territories in order to feed at swarms. Several pairs of the same species may attend a swarm, with the dominant pair at the swarm being the pair which holds the territory that the swarm is in. In addition to competition within species, competition among species exists, and larger species are dominant. In its range, the ocellated antbird is the largest of the obligate ant-following antbirds and is dominant over other members of the family, although it is subordinate to various species from other families (including certain woodcreepers, motmots and the rufous-vented ground cuckoo). At a swarm, the dominant species occupies positions above the central front of the swarm, which yields the largest amount of prey. Smaller, less dominant species locate themselves further away from the centre, or higher above the location of the dominant species, where prey is less plentiful.

Antbirds are monogamous, in almost all cases forming pair bonds that last the life of the pair. Studies of the dusky antbird and the white-bellied antbird did not find "infidelity". In the white-plumed antbird divorces between pairs are common, but, as far as known, this species is exceptional. In most species the pair defends a classic territory, although the nesting territories of ant followers are slightly different (see feeding above). Territories vary in size from as small as 0.5 ha for the Manu antbird, to 1500  m (5000 ft) in diameter for the ocellated antbird. Ocellated antbirds have an unusual social system where the breeding pair forms the nucleus of a group or clan that includes their male offspring and their mates. These clans, which can number up to eight birds, work together to defend territories against rivals. Pair bonds are formed with courtship feeding, where the male presents food items to the female. In spotted antbirds males may actually feed females sufficiently for the female to cease feeding herself, although she will resume feeding once copulation has occurred. Mutual grooming also plays a role in courtship in some species.
The nesting and breeding biology of antbirds have not been well studied. Even in relatively well-known species the breeding behaviour can be poorly known; for example the nest of the ocellated antbird was first described in 2004. Nests are constructed by both parents, although the male undertakes more of the work in some species. Antbird nests are cups of vegetation such as twigs, dead leaves and plant fibre, and they follow two basic patterns: either suspended or supported. Suspended cups, which may hang from forks in branches, or between two branches, are the more common style of nest. Supported nests rest upon branches, amongst vines, in hollows, and sometimes on mounds of vegetation on the ground. Each species nests at the level where it forages, so a midstory species would build its nest in the midstory. Closely related species nest in the same ways. For example, antvireos in the genus "Dysithamnus" are all suspension nesters.
Almost all antbirds lay two eggs. A few species of antshrike lay three eggs, and a smaller number of antbirds lay one egg, but this is unusual. Small clutch sizes are typical of tropical birds compared to more temperate species of the same size, possibly due to nest predation, although this is disputed. Both parents participate in incubation, although only the female incubates at night. The length of time taken for chicks to hatch is 14–16 days in most species, although some, such as the dusky antbird, can take as long as 20 days. The altricial chicks are born naked and blind. Both parents brood the young until they are able to thermoregulate, although, as with incubation, only the female broods at night. In common with many songbirds, the parents take faecal sacs for disposal away from the nest. Both parents feed the chicks, often bringing large prey items. When the chicks reach fledging age, after 8–15 days, attending parents call their chicks. As each chick leaves the nest it is cared for exclusively from then on by the parent that was present then. After the first chick fledges and leaves with a parent the remaining parent may increase the supply of food to speed up the process of fledging. After fledging, chicks spend the first few days well hidden as the parents bring them food. Chicks of some species may not become independent of the parents for as long as four months in some antwrens, but two months is more typical for the rest of the family.

Antbirds are common components of the avifauna of some parts of the Neotropics and are thought to be important in some ecological processes. They are preyed upon by birds of prey, and their tendency to join flocks is thought to provide protection against such predation. The greater round-eared bat preys on some antbird species, such as the white-bibbed antbird and the scaled antbird; the latter is the bat's preferred prey. Nests, including incubating adults, chicks and eggs, are vulnerable to predators, particularly snakes but also nocturnal mammals. Nesting success is low for many species, particularly in areas of fragmented habitat.

It was once suggested that the relationship between the obligate and regular ant-followers and the army ants, particularly "Eciton burchellii", was mutualistic, with the ants benefiting by having the birds chase prey back down towards them. However, experiments where ant followers were excluded have shown that the foraging success of the army ants was 30% lower when the birds were present, suggesting that the birds' relationship was in fact parasitic. This has resulted in a number of behaviours by the ants in order to reduce kleptoparasitism, including hiding of secured prey in the leaf litter and caching of food on trails. It has been suggested that the depressive effect of this parasitism slows the development of "E. burchellii" swarms and in turn benefits other ant species which are preyed upon by army ants. The ant-following antbirds are themselves followed by three species of butterfly in the family Ithomiinae which feed on their droppings. Bird droppings are usually an unpredictable resource in a rainforest, but the regular behaviour of ant followers makes the exploitation of this resource possible.

As of April 2008, 38 species are considered by the IUCN to be near threatened or worse and therefore at risk of extinction. Antbirds are neither targeted by the pet trade nor large enough to be hunted; the principal cause of the decline in antbird species is habitat loss. The destruction or modification of forests has several effects on different species of antbirds. The fragmentation of forests into smaller patches affects species that are averse to crossing gaps as small as roads. If these species become locally extinct in a fragment, this reluctance to cross unforested barriers makes their re-establishment unlikely. Smaller forest fragments are unable to sustain mixed-species feeding flocks, leading to local extinctions. Another risk faced by antbirds in fragmented habitat is increased nest predation. An unplanned experiment in fragmentation occurred on Barro Colorado Island, a former hill in Panama that became an isolated island during the flooding caused by the creation of the Panama Canal. Numerous species of antbird formerly resident in the area were extirpated, in no small part due to increased levels of nest predation on the island. While the species lost from Barro Colorado are not globally threatened, they illustrate the vulnerability of species in fragmented habitats and help explain the declines of some species. The majority of threatened species have very small natural ranges. Some are also extremely poorly known; for example the Rio de Janeiro antwren is known only from a single specimen collected in 1982, although there have been unconfirmed reports since 1994 and it is currently listed as critically endangered. Additionally, new species are discovered at regular intervals; the Caatinga antwren was described in 2000, the acre antshrike in 2004, the sincorá antwren in 2007, and the description of a relative of the Paraná antwren discovered in 2005 in the outskirts of São Paulo is being prepared. While not yet scientifically described, conservation efforts have already been necessary, as the site of discovery was set out to be flooded to form a reservoir. Consequently, 72 individuals were captured and transferred to another locality.



</doc>
<doc id="264037" url="https://en.wikipedia.org/wiki?curid=264037" title="Pitta">
Pitta

Pittas are a family, Pittidae, of passerine birds found in Asia, Australasia and Africa. There are thought to be 40 to 42 species of pittas, all similar in general appearance and habits. The pittas are Old World suboscines, and their closest relatives among other birds are the broadbills in the genera "Smithornis " and "Calyptomena". Initially placed in a single genus, as of 2009 they have been split into three genera: "Pitta", "Erythropitta" and "Hydrornis". Pittas are medium-sized by passerine standards, at in length, and stocky, with strong, longish legs and long feet. They have very short tails and stout, slightly decurved bills. Many have brightly coloured plumage.

Most pitta species are tropical, although a few species can be found in temperate climates. They are mostly found in forests, but some live in scrub and mangroves. They are highly terrestrial and mostly solitary, and usually forage on wet forest floors in areas with good ground cover. They eat earthworms, snails, insects and similar invertebrate prey, as well as small vertebrates. Pittas are monogamous and females lay up to six eggs in a large domed nest in a tree or shrub, or sometimes on the ground. Both parents care for the young. Four species of pittas are fully migratory, and several more are partially so, though their migrations are poorly understood. 

Four species of pitta are listed as endangered by the International Union for Conservation of Nature; a further nine species are listed as vulnerable and several more are near-threatened. The main threat to pittas is habitat loss in the form of rapid deforestation, but they are also targeted by the cage-bird trade. They are popular with birdwatchers because of their bright plumage and the difficulty in seeing them.

The first pitta to be described scientifically was the Indian pitta, which was described and illustrated by George Edwards in 1764. Carl Linnaeus included the species in his revised 12th edition (1766–1768) of the "Systema Naturae" based on Edwards' descriptions and illustrations as well as other accounts, placing it with the Corvidae as "Corvus brachyurus". Ten years later Statius Müller moved it and three other pittas to the thrush family Turdidae and the genus "Turdus", due to similarities of morphology and behaviour. In 1816 Louis Vieillot moved it to the new genus "Pitta". The name is derived from the word "pitta" in the Telugu language of South India meaning "small bird".

The family's closest relatives have for a long time been assumed to be the other suboscine birds (suborder Tyranni), and particularly the Old World suboscines; the broadbills, asities and the New World sapayoa. These arboreal relatives were formerly treated as two families, and are now either combined into a single taxon or split into four. A 2006 study confirmed that these were indeed the closest relatives of the pittas. The clade they form, the Eurylaimides, is one of the two infraorders of suboscines, which is one of three suborders of the passerine birds. With regards to their relationship within the Eurylaimides, another 2006 study placed the pittas as a sister clade to two clades of broadbills and asities. This same study postulated an Asian origin for the Eurylaimides and therefore the pittas. 

Two DNA studies, from 2015 and 2016, came to a different conclusion, finding that the Eurylaimides were divided into two clades and that the pittas formed a clade with the broadbills of the genera "Smithornis " and "Calyptomena", with the remaining broadbills and asities in the other clade. The 2016 study also disputed the earlier claims about the origin of the group, and concluded that the most likely ancestral home of the pittas and the Eurylaimides was Africa (the sapayoa having diverged before the core clades had reached Africa). The study found that the pittas diverged from the "Smithornis" and "Calyptomena" broadbills 24 to 30 million years ago, during the Oligocene. The pittas diverged and spread through Asia before the oscines (suborder Passeri) reached the Old World from Australia.

The number of pitta genera has varied considerably since Vieillot, ranging from one to as many as nine. In his 1863 work "A Monograph of the Pittidae", Daniel Elliot split the pittas into two genera, "Pitta" for the species with comparatively long tails and (the now abandoned) "Brachyurus" for the shorter-tailed species. Barely two decades later, in 1880/81, John Gould split the family into nine genera, in which he also included the lesser melampitta (in the genus "Melampitta") of New Guinea, where it was kept until 1931 when Ernst Mayr demonstrated that it had the syrinx of an oscine bird. Soon afterwards, Philip Sclater's "Catalogue of the Birds of the British Museum" brought the number back down to three.
Modern treatments of taxa within the family vary as well. A 1975 checklist included six genera, whereas the 2003 volume of the "Handbook of the Birds of the World", which covered the family, placed all the pittas in a single genus. Writing in 1998, Johannes Erritzoe stated that most contemporary authors considered the family to contain a single genus. Before 2006 the family was not well studied using modern anatomical or phylogenetic techniques; two studies, in 1987 and 1990, each used only four species, and comparisons amongst the family as a whole had relied mostly on external features and appearances.
A 2006 study of the nuclear DNA of the pittas was the first to examine most representatives of the family, and found evidence of three major clades of pitta. Based on the study the pittas were split into three genera. The first clade, using the genus name "Erythropitta", included six species that had previously been considered closely related based on external features. They are all generally small species with small tails, extensive amounts of crimson or red on the underparts, and greenish or blueish backs. The second genus, "Hydrornis", includes variable Asian species. These species are unified morphologically in exhibiting sexual dimorphism in their plumage, as well as in possessing cryptic juvenile plumage (in all the species thus-far studied). This genus includes the eared pitta, which had often been placed into its own genus, "Anthocincla", on account of its apparently primitive characteristics. The third genus, "Pitta", is the most widespread. Most species in this genus have green upperparts with a blue wing-patch, dark upperparts and cinnamon-buff underparts. This clade contains all the migratory pitta species, and it is thought that many of the pitta species from islands are derived from migratory species. This division of the pittas into three genera has been adopted by the International Ornithological Congress' (IOC) "", the "Handbook of the Birds of the World"'s HBW Alive checklist, and the International Union for Conservation of Nature (which follows the HBW Alive checklist).

As with genera, there has been considerable variation in the number of accepted pitta species. The checklists of Sclater and Elliot at the end of the 19th century contained 48 and 47 species respectively. More recent checklists have had fewer than this, one from 1975 listing just 24 species. Since the 1990s, the figure has been between 30 and 32 species; the 2003 "Handbook of the Birds of the World" recognised 30. One species not recognised by the handbook is the black-crowned pitta, which it treated as a subspecies of either the garnet pitta or the graceful pitta. Since the publication of the handbook, further splits to pitta species have been made; in 2010 the banded pitta was split into three species, one endemic to Java and Bali, one endemic to Borneo and one found in Sumatra and the Thai-Malay Peninsula. A 2013 study found that the red-bellied pitta, a widespread species found from Sulawesi to Australia, was actually a species complex. The study divided it into 17 new species, although some authorities have recognised fewer, for example the IOC have recognised only 10.

The pittas are small to medium-sized passerines, ranging in size from the blue-banded pitta at to the giant pitta, which can be up to in length. In weight they range from . Pittas are stout-bodied birds with long, strong tarsi (lower leg bones) and long feet. The colour of the legs and feet can vary dramatically even within a species. This may be a characteristic used by females in judging the quality of a prospective mate. The wings have ten primaries that are generally rounded and short; those of the four migratory species are more pointed. Although pittas are behaviourally reluctant to fly, they are capable and even strong fliers. The tails range from being short to very short, and are composed of twelve feathers. 

Unlike most other forest-floor bird species, the plumage of pittas is often bright and colourful. Only one species, the eared pitta, has entirely cryptic colours in the adults of both sexes. In the same genus, "Hydrornis", are three further species with drabber than average plumage, the blue-naped pitta, blue-rumped pitta and rusty-naped pitta. Like the other "Hydrornis" pittas they are sexually dimorphic in their plumage, the females tending towards being drabber and more cryptic than the males. In general the sexes in the family tend to be very similar if not identical. Across most of the family the brighter colours tend to be on the undersides, with patches or areas of bright colours on the rump, wings and uppertail coverts being concealable. Being able to conceal bright colours from above is important as most predators approach from above, although there are four species that have brighter upperparts.

The pittas are generally birds of tropical forests, semi-forests and scrub. Most species need forests with lots of cover, a rich understory, and leaf litter for feeding, and they are often found near waterways as well. Some species inhabit swamps and bamboo forests, and the mangrove pitta, as its name suggests, is a mangrove specialist. Several species are lowland forest specialists. For example, the rainbow pitta is not found above . Other species may occur at much higher elevations, including, for example, the rusty-naped pitta, which has been found up to . The altitudinal preferences varies in the fairy pitta across its range, it can be found up to in Taiwan but stays at lower altitudes in Japan. As well as natural habitats, pittas may use human-altered spaces. For example, migrating blue-winged pittas and hooded pittas use parks and urban gardens in Singapore.

The greatest diversity of pittas is found in South-east Asia. Of the three genera, the large genus "Pitta" is the most widespread. The two species found in Africa, the African pitta and green-breasted pitta, are from this clade, as is the most northerly species (the fairy pitta) and the most southerly (the noisy pitta, "Pitta versicolor"). The most remote insular endemics are in this group as well, including the black-faced pitta, which is endemic to the Solomon Islands. The pittas of the clade "Erythropitta" are mostly found in Asia. with one species, the Papuan pitta, reaching the north of Australia. The "Hydrornis" pittas are exclusively Asian. Some pittas have large distributions, like the hooded pitta, which ranges from Nepal to New Guinea, while others have much smaller ones, like the superb pitta, which is endemic to the tiny island of Manus in the Admiralty Islands.

The movements of pittas are poorly known and notoriously difficult to study. Bird ringing studies have not shed much light on this. One study in the Philippines ringed 2000 red-bellied pittas but only recaptured ten birds, and only one of these recaptures was more than two months after the initial capture. Only four species of pitta are fully or mostly migratory, all in the genus "Pitta": the Indian pitta, the African pitta, the fairy pitta and the blue-winged pitta. As well as these four, the northern subspecies of the hooded pitta is a full migrant. Other species make smaller or more local, and poorly understood, movements across small parts of their range, including the noisy pitta of Australia. The migration of pittas is apparently nocturnal, and pittas migrate in small loose flocks that use the same resting and foraging sites each year.

Pittas are diurnal, requiring light to find their often cryptic prey. They are nevertheless often found in darker areas and are highly secretive, though they will respond to imitations of their calls. They are generally found as single birds, even young birds not associating with their parents unless they are being fed. The only exception to their solitary lifestyle is small groups that have been observed forming during migration.

The pittas are strongly territorial, with territories varying in size from in the African pitta to in the rainbow pitta. They have also been found to be highly aggressive in captivity, attacking other species and even their own, although such behaviour has not been observed in the wild. Pittas will perform territory-defence displays on the edges of their territories, although fights between rivals have only been recorded once. One such territorial display is given by the rainbow pitta, which holds its legs straight and bows to a rival on the edge of its territory, while making a purring call. Displays like this are paired with calls made out of sight of potential rivals; these territorial calls are frequent and can account for up to 12% of a bird's daylight activity. Migratory species will defend non-breeding feeding territories as well as their breeding ones. 

The vocalisations of pittas are best described as calls, as they are generally short, mono or disyllabic, and often fluting or whirring. They are made by both sexes and throughout the year. One species, the black-and-crimson pitta, was also described making a mechanical noise (sonation) in 2013. The sonation, a clapping sound, was made in flight and is hypothesised to be made by the wings.

Earthworms form the major part of the diet of pittas, followed by snails. Earthworms can become seasonally unavailable in dry conditions when the worms move deeper into the soil, and pittas also take a wide range of other invertebrate prey, including many insects groups such as termites, ants, beetles, true bugs, and lepidopterans. Freshwater crabs, centipedes, millipedes, and spiders are also taken. Some species, such as the fairy pitta and rainbow pitta, have been recorded feeding on small vertebrate prey. This including skinks, frogs, snakes and, in the case of the fairy pitta, shrews. There are also records of some pittas taking plant food, such as the "Carpentaria" palm fruits or maize seeds.

Pittas feed in a thrush-like fashion, moving aside leaves with a sweeping motion of the bill. They have also been observed to probe the moist soil with their bills to locate earthworms. They have a keen sense of smell, and it has been suggested that they are able to locate earthworms this way. This suggestion was supported by a study which found that the Indian pitta has the largest olfactory bulb of 25 passerines examined. Eight species have been recorded using stones as anvils on which to smash open snails to eat, and the rainbow pitta has been observed using the root of a tree to do so.

Like most birds, pittas are monogamous breeders, and defend breeding territories. Most species are seasonal breeders, timing their breeding to occur at the onset of the rainy season. An exception to this is the superb pitta, which breeds almost year-round, as the island of Manus on which it breeds remains wet all year. The courtship behaviours of the family are poorly known, but the elaborate dance of the African pitta includes jumping into the air with a puffed-out breast and parachuting back down to the perch.
Pittas build a rudimentary nest that is a dome with a side entrance. The structure of the nest is consistent across the whole family. The nest is as large as a rugby ball, and is usually well-camouflaged amongst vines or vegetation of some kind. The nest's appearance is also difficult to distinguish from a heap of leaves pushed together by the wind, although a few species create a "doormat" of sticks (sometimes decorated with mammal dung) by the entrance. The nests can either be placed on the ground or in trees. Some species always nest in trees, like both African species, others nest only on the ground, and others show considerable variation. Both sexes help to build the nest, but the male does most of the work. It takes around two to eight days to build a new nest; this probably varies depending on the experience of the birds involved. A new nest is constructed for each nesting attempt, and work on building a nest for a second brood may start while the chicks from the first brood are still being fed.

The clutch size varies by species. Typically three to five eggs are laid, but two is typical for the garnet pitta, whereas six is more common for the blue-winged pitta and the Indian pitta. It is thought that species with higher levels of predation tend to have smaller clutches, as smaller clutches involve fewer provisioning trips that might alert a predator to the presence of a nest, and smaller clutches are easier to replace if lost. Clutch size may vary within a species depending on latitude. A study of noisy pittas found that birds in the tropics had smaller clutch sizes than those in more temperate environments. The eggs of pittas are slightly pointed at one end, and generally smooth (the deeply pitted eggs of the superb pitta being the exception to this). The size of eggs varies by species, smaller-sized species laying smaller eggs. There is also some variation in egg size within a species in species with large ranges. For example, the eggs of noisy pittas are smaller closer to the tropics. Eggs are typically white or creamy, and usually slightly glossy.
Both parents incubate the clutch, the period between laying and hatching being between 14 and 18 days (14 to 16 being more typical). The chicks usually hatch asynchronously, over several days, but in some species the hatching is synchronous. On hatching the Gurney's pitta parents are reported to consume the eggshells. This behaviour ensures that the calcium used to create the eggs is not lost. It is unknown if other species do this, but it is a common behaviour among birds. As with the incubation, both parents are involved in rearing the chicks. The chicks of pittas are entirely altricial, hatching both naked and blind, and dependent upon their parents for warmth, food and nest sanitation. Young chicks are brooded continuously, the female brooding alone in some species and sharing responsibilities with the male in others. The males and females make regular feeding trips to the chicks; one study of Gurney's pittas found a pair made 2300 feeding visits to the nest, traveling an estimated over the nestling stage. Earthworms are important food items for many species, and the dominant item in the nestling diet of some. 73% of the parental visits of fairy pittas, 63% of rainbow pitta's, up to 79% of Gurney's pitta's visits involved bringing earthworms. Parents can and do carry more than one item in their bills during visits; in a study of breeding fairy pittas, as many as six items were observed being brought in a single visit, although less than four was typical. When the chicks are small, prey may be broken up before being fed to the chicks, and larger prey items like skinks and snakes are only fed to the older chicks able to manage them.

The brilliant plumage of many pittas has resulted in considerable interest in pittas from people living within their range, scientists, aviculturists and birdwatchers, and has led to the colloquial name jewel-thrushes. Such is their attractiveness that, in Borneo, even the body of a dead pitta can be a favoured toy for local children. They have proven difficult to maintain and breed in captivity, requiring large amounts of space, humidity and sufficient vegetation of the right kind. Pittas are a very popular group of birds with birdwatchers, due to the dazzling plumage of many species and the relative difficulty of seeing these retiring birds in dark forests. Their desirability as birdwatching targets was the subject of the book "The Jewel Hunter" (2013), in which the writer Chris Goodie recounted his attempt to see every species of pitta.

Pittas are generally forest birds and, as such, are vulnerable to habitat loss caused by rapid deforestation. They can also be difficult birds to survey and are easily overlooked. Four species are assessed to be endangered, and a further nine are listed as vulnerable by the IUCN. Eight species are listed as near-threatened, and one, the Louisiade pitta, is too poorly known to be assessed and is listed as data deficient. 

The Gurney's pitta was not seen for 34 years between 1952 and 1986, before a small population was discovered in southern Thailand. This small population declined after its rediscovery, and, by 2000, it had reached a low of 10 pairs, and was listed as critically endangered. In 2003, the species was found in Burma for the first time since 1914, and in large numbers, between nine and thirty five thousand pairs. Although the species was considerably less threatened than thought, it is still of considerable conservation concern, as deforestation of the habitat in Burma continues. The rapid rate of deforestation in Borneo has pushed the blue-headed pitta, considered common and secure as recently as 1996, into the list of species considered vulnerable. 

Pittas have been targeted by poachers for the illegal wild-bird trade. They are not targeted because of their song, as many songbirds are, and may simply be captured as bycatch from collecting other species, and because of their attractive plumage. According to some trappers, they also may end up being eaten for food. On Manus, locals report that predation by snakes, including the brown tree snake, is responsible for the rarity of the endangered superb pitta, but the snake, the introduction of which is responsible for several extinctions of island birds across the Pacific, is native to the island, and is therefore likely a natural threat.

There are 42 species of pitta in three genera according to the International Ornithological Congress' (IOC) "Birds of the World: Recommended English Names".



</doc>
<doc id="264228" url="https://en.wikipedia.org/wiki?curid=264228" title="Rogers Hornsby">
Rogers Hornsby

Rogers Hornsby, Sr. (April 27, 1896 – January 5, 1963), nicknamed "The Rajah", was an American baseball infielder, manager, and coach who played 23 seasons in Major League Baseball (MLB). He played for the St. Louis Cardinals (1915–1926, 1933), New York Giants (1927), Boston Braves (1928), Chicago Cubs (1929–1932), and St. Louis Browns (1933–1937). He was named the National League (NL)'s Most Valuable Player (MVP) twice, and was a member of one World Series championship team.

Born and raised in Winters, Texas, Hornsby played for several semi-professional and minor league teams. In 1915, he began his major league career with the St. Louis Cardinals and remained with the team for 12 seasons. During this period, Hornsby won his first MVP Award and the Cardinals won the 1926 World Series. After that season, he spent one season with the New York Giants and another with the Boston Braves before being traded to the Chicago Cubs. He played with the Cubs for four years and won his second MVP Award before the team released him in 1932. Hornsby re-signed with the Cardinals in 1933, but was released partway through the season and was picked up by the St. Louis Browns. He remained there until his final season in 1937. From 1925 to 1937, Hornsby was intermittently his own manager. After retiring as a player, he managed the Browns in 1952 and the Cincinnati Reds from 1952 to 1953.

Hornsby is regarded as one of the best hitters of all time. He had 2,930 hits and 301 home runs in his career; his career batting average of .358 is second only to Ty Cobb, at .367, in MLB history. He also won two Triple Crowns and batted .400 or more three times during his career. He is the only player to hit 40 home runs and bat .400 in the same year (1922). His batting average for the 1924 season was .424, a mark that no player has matched since. He was elected to the National Baseball Hall of Fame in 1942 and the St. Louis Cardinals Hall of Fame in 2014.

Hornsby married three times, in 1918, 1924, and 1957, and had two children.

Known as someone who was difficult to get along with, he was not well liked by his fellow players. He never smoked, drank, or went to the movies, but frequently gambled on horse races during his career.

Hornsby was born in Winters, Texas, the last of Ed and Mary (Rogers) Hornsby's six children. When Hornsby was two years old, his father died of unknown causes. Four years later, the surviving Hornsbys moved to Fort Worth, Texas, so Hornsby's brothers could get jobs in the meat packing industry to support the family.

Hornsby started playing baseball at a very young age; he once said, "I can't remember anything that happened before I had a baseball in my hand." He took a job with the Swift and Company meat industry plant as a messenger boy when he was 10 years old, and he also served as a substitute infielder on its baseball team. By the age of 15, Hornsby was already playing for several semi-professional teams. He also played baseball for North Side High School until 10th grade, when he dropped out to take a full-time job at Swift and Company. While he was in high school, Hornsby also played on the football team, alongside future College Football Hall of Famer Bo McMillin.

In 1914, Hornsby's older brother Everett, a minor league baseball player for many years, arranged for Rogers to get a tryout with the Texas League's Dallas Steers. He made the team, but did not play in any games for the Steers; he was released after only two weeks. Following his dismissal, he signed with the Hugo Scouts of the Class D Texas–Oklahoma League as their shortstop for $75 per month ($ today). The Scouts went out of business a third of the way through the season, and Hornsby's contract was sold to the Denison Champions of the same league for $125 ($ today). With both teams in 1914, Hornsby batted .232 and committed 45 errors in 113 games.

The Denison team changed its name to the Denison Railroaders and joined the Western Association in 1915. They raised Hornsby's salary to $90 per month ($ today). Hornsby's average improved that season to .277 in 119 games, but he made 58 errors. Nonetheless, his contributions helped the Railroaders win the Western Association pennant. At the end of the season, a writer from "The Sporting News" said that Hornsby was one of about a dozen Western Association players to show any major league potential.

Hornsby came to the attention of the St. Louis Cardinals during an exhibition series between that team and the Railroaders in spring training in 1915. Cardinals' manager Miller Huggins told his only scout, Bob Connery, to look for minor league players to fill the roster of their financially struggling team. In September, the Cardinals purchased Hornsby's contract from Denison and added him to their major league roster, although his only professional baseball experience had been in Class D. Hornsby's first game came on September 10, when he relieved Art Butler at shortstop in a 7–1 loss to the Cincinnati Reds. Three days later he started a game, and he got his first hit the next day against Rube Marquard of the Brooklyn Robins. Hornsby finished the season with a .246 average in 57 at-bats while the Cardinals finished in sixth place in the National League (NL). At only 19 years old, Hornsby was the fourth-youngest player in the NL that year.

The Cardinals picked up Roy Corhan from the San Francisco Seals of the Pacific Coast League to play at shortstop in 1916, making Hornsby one of three candidates for the position. Hornsby's great performance in spring training, a shoulder injury to Corhan, and poor hitting by Butler meant Hornsby was the starting shortstop on Opening Day. He had both runs batted in (RBIs) in the Cardinals' 2–1 victory over the Pittsburgh Pirates that day. On May 14, he hit his first major league home run against Jeff Pfeffer of Brooklyn. He rotated among infield positions before finally settling in at third base for much of the second half of the year. Late in the season, he missed 11 games with a sprained ankle. He finished 1916 with a .313 average, fourth in the NL, and he was one short of the league lead in triples with 15.

Hornsby returned to the shortstop position in 1917 after Corhan returned to San Francisco and Butler was released. After playing nearly every game throughout the first month of the season, Hornsby was called away from the team on May 29 after his brother William was shot and killed in a saloon. Rogers attended the funeral on June 1 and returned to the Cardinals on June 3, finishing the season without missing any more playing time. His batting statistics improved from the previous season; his .327 batting average was second in the league, and he led the league in triples (17), total bases (253), and slugging percentage (.484).

Many baseball players were drafted to fight in World War I in 1918, but Hornsby was given a draft deferment because he was supporting his family. During the offseason, Miller Huggins, unhappy with the Cardinals' management, left the team to manage the New York Yankees. He was replaced by Jack Hendricks, who had managed the Indianapolis Indians to a pennant in the American Association the previous year. Hornsby lacked confidence in Hendricks's ability to run the Cardinals, and the two men developed animosity towards each other as a result of Hornsby's growing egotism and fondness for former manager Huggins. Under Hendricks, Hornsby's batting average dipped to .281. He had problems off the field too; on June 17, Hornsby hit St. Louis resident Frank G. Rowe with his Buick when Rowe stepped out in front of traffic to cross an intersection. Rowe sued Hornsby for $15,000 ($ today), but Hornsby eventually settled for a smaller, undisclosed amount, and the case was dismissed. He was still among the league leaders in triples and slugging percentage in 1918, but after the season ended with the Cardinals in last place, he announced that he would never play under Hendricks again. Partially due to Hornsby's complaints, Hendricks was fired after the season and replaced by Branch Rickey, then president of the Cardinals.

In 1919, after the Cardinals acquired shortstop Doc Lavan, Rickey tried converting Hornsby into a second baseman in spring training. Hornsby played third base for most of the year. His batting average was low at the beginning of the season but improved by June. At season's end, his average of .318 was second-highest in the league, and he also finished second in total bases and runs batted in.

In 1920, Rickey moved Hornsby to second base, where he remained for the rest of his career. He started the year with a 14-game hitting streak. On June 4, he had two triples and two RBIs as the Cardinals defeated the Chicago Cubs 5–1, a game that ended future Hall of Famer Grover Cleveland Alexander's 11-game winning streak. Hornsby finished the season with the first of seven batting titles by hitting .370, and he also led the league in on-base percentage (.431), slugging percentage (.559), hits (218), total bases (329), doubles (44), and RBIs (94).

The beginning of the live-ball era led to a spike in hitting productivity throughout the majors, which helped Hornsby to hit with increased power during the 1921 season. He hit .397 in 1921, and his 21 home runs were second in the league, more than twice his total in any previous season. He also led the league in on-base percentage (.458), slugging percentage (.639), runs scored (131), RBIs (126), doubles (44), and triples (18). The Cardinals held a special day in Hornsby's honor on September 30 before a home game against the Pittsburgh Pirates, and they presented Hornsby with multiple awards before the game, including a baseball autographed by President of the United States Warren G. Harding. The Cardinals beat the Pirates 12–4 that day as Hornsby hit a home run and had two doubles.

By the 1922 season, Hornsby was considered a big star, having led the league in batting average, hits, doubles, and runs batted in multiple times. As a result, he sought a three-year contract for $25,000 per season. After negotiating with Cardinals management, he settled for a three-year, $18,500 contract ($ today), which made him the highest-paid player in league history to that point. On August 5, Hornsby set a new NL record when he hit his 28th home run of the season off of Jimmy Ring of the Philadelphia Phillies. From August 13 through September 19, he had a 33-game hitting streak. Hornsby set National League records in 1922 with 42 home runs, 250 hits and a .722 slugging percentage (still the highest ever for players with 600+ at-bats). His .401 batting average was the highest in the National League since 1897. He won the first of his two Triple Crowns that year, and he led the league in RBIs (152), on-base percentage (.459), doubles (46), and runs scored (141). His 450 total bases in 1922 remain the National League single-season record. On defense, Hornsby led all second basemen in putouts, double plays, and fielding percentage. His batting performance that year was, and still is, one of the finest in MLB history, and his 42 home runs are still the most ever for a .400 hitter.
On May 8, 1923, Hornsby suffered an injury to his left knee in a game against the Phillies when he turned to make a throw. He returned 10 days later, but the injury lingered, and he was removed from a game against the Pirates on May 26 to be examined by Robert Hyland, the Cardinals' physician. Hyland had Hornsby's knee placed in a cast for two weeks, after which he returned to the Cardinals. During a game in August, Hornsby was on third base late in the game and threw up his hands in disgust in response to a sign flashed by Rickey; he had given the current batter the take sign, and Hornsby felt the batter should have hit the ball. After the game, he and Rickey fought in the clubhouse, but teammates quickly broke it up. Hornsby missed several games late in the year with injuries that the Cardinals (and Hyland) did not believe to be serious; as a result he was fined $500 ($ today) and suspended for the last five games of the year. However, Hornsby still won his fourth consecutive NL batting title with a batting average of .384. He also repeated as the leader in on-base percentage (.459) and slugging percentage (.627).

Hornsby raised his average to .424 in 1924, which is the fourth-highest batting average in a single season in MLB history, and the live-ball era batting average record. He led the league with 89 walks, producing a .507 on-base percentage, a national league record for over 75 years. His slugging percentage of .696 again led the league, as did his 121 runs scored, 227 hits, and 43 doubles; he hit 25 home runs as well. That year, the NL reintroduced its Most Valuable Player (MVP) award. Although Hornsby was expected to win the award, it went to Dazzy Vance instead. Cincinnati voter Jack Ryder left Hornsby's name off his ballot altogether because he believed Hornsby was an MVP on the stat sheet, but was not a team player. In 1962, the Baseball Writers' Association of America presented Hornsby with an award retroactively recognizing him as the 1924 MVP.
In 1925, Sam Breadon, the owner of the Cardinals, wished to replace Rickey as manager. Hornsby initially declined the job. After discovering that Rickey planned to sell his stock in the Cardinals if he was replaced as field manager, Hornsby agreed to take the job as long as Breadon would help him purchase the stock. Breadon agreed, and Hornsby became the Cardinals' manager. Hornsby finished the year with his second Triple Crown, when he combined a .403 batting average with 39 home runs and 143 RBIs in 138 games. He bested teammate Jim Bottomley in the batting title race by nearly 40 points. His 1925 batting average has not been matched by any National Leaguer since. That year, he won the MVP Award, receiving 73 out of 80 possible votes. His .756 slugging percentage and 1.245 on-base plus slugging set National League records that stood until broken by Barry Bonds in 2001. The Cardinals finished in fourth place in 1925, finishing one game over .500, though the team won 64 games and lost 51 under Hornsby. During the year, his wife Jeanette had a son, Billy.

Hornsby had an off-year offensively in 1926, as he hit only .317 with 11 home runs. Nonetheless, St. Louis won its first NL pennant. In the 1926 World Series, the Cardinals defeated the Yankees in a seven-game series; Hornsby tagged out Babe Ruth on a stolen base attempt, ending the Series and giving St. Louis its first undisputed world championship. During post-season negotiations for a new contract, Hornsby demanded $50,000 per year for three years. Breadon agreed to a one-year contract for $50,000 ($ today). When Hornsby refused to give way, the Cardinals traded him to the New York Giants for Frankie Frisch and Jimmy Ring on December 20, 1926. The trade was briefly postponed as NL president John Heydler stated that Hornsby could not play for the Giants while he held stock in the Cardinals. Hornsby wanted $105 per share for his stock, a price Breadon was unwilling to pay. In early 1927, Hornsby was able to sell his shares at $105 each, enabling him to officially become a Giant.

Hornsby enjoyed a better season in 1927, as he hit .361 and led the league in runs scored (133), walks (86), and on-base percentage (.448). He managed the Giants for part of the year as well, as manager John McGraw dealt with health problems. Hornsby's performance helped guide the Giants to a 92–62 win–loss record during the season, which was good enough for third place in the NL. However, Hornsby's gambling problems at the racetrack and distrust of Giants' management annoyed team owner Charles Stoneham. During the offseason he was traded to the Boston Braves for Jimmy Welsh and Shanty Hogan.

With the Boston Braves in 1928, Hornsby was again the league's most productive hitter; he won his seventh batting title with a .387 average, also leading the league in on-base percentage (.498), slugging percentage (.632), and walks (107). One month into the season, manager Jack Slattery resigned, and the Braves hired Hornsby to be his replacement. The Braves, however, lost 103 games and finished in seventh place out of eight teams in the NL. They were struggling financially as well, and when the Chicago Cubs offered $200,000 ($ today) and five players for Hornsby, the Braves found the offer too good to pass up.

Hornsby hit .380 for Chicago in 1929 while recording 39 home runs and a league-leading .679 slugging percentage. His 156 runs scored led the major leagues and is still the team record while his .380 batting average remains the highest for a Cub since 1895. He also collected another MVP award, and the Cubs won the NL pennant. However, they lost in the 1929 World Series to the Philadelphia Athletics in five games, as Hornsby batted .238 with one RBI. He also set a World Series record for strikeouts with eight.

After the first two months of the 1930 season, Hornsby was batting .325 with two home runs. In the first game of a doubleheader against the Cardinals, Hornsby broke his ankle while advancing to third base. He did not return until August 19, and he was used mostly as a pinch-hitter for the rest of the season. When Joe McCarthy was fired with four games remaining in the season Hornsby became the team's manager. Hornsby finished the year with a .308 batting average and two home runs.

On April 24, 1931, Hornsby hit three home runs and drove in eight runs in a 10–6 victory over Pittsburgh. Hornsby played in 44 of the first 48 games, but after a disappointing performance he only played himself about half the time for the rest of the year. In 100 games, he had 90 RBIs, 37 doubles, and a batting average of .331. He also led the league in on-base percentage (.421) for the ninth time in his career. The team finished 84–70, 17 games back of the pennant-winning Cardinals, and four games back of the Giants.

The 1931 season was Hornsby's last as a full-time player. Boils on his feet bothered him during the start of the 1932 season, and he did not play his first game until May 29. Hornsby played right field from May 29 to June 10, appeared in two games as a pinch hitter, played third base from July 14 through July 18, and played one last game as a Cub when he pinch-hit on July 31.

William Veeck, Sr., who was running the team, was unhappy with Hornsby's management of the team. Hornsby maintained strict rules, and Veeck thought his managing style hurt team morale. Veeck believed Hornsby broke a cardinal rule of baseball in one particular incident. Hornsby disagreed with a call made by the umpire. Instead of disputing the call himself, as was the manager's job, Hornsby sent another player to argue with the umpire. That player was ejected from the game. On August 2, although the Cubs were in second place, Hornsby was released, and Charlie Grimm replaced him as manager. Hornsby had played 19 games, batting .224 with one home run and seven RBIs. Although the Cubs advanced to the 1932 World Series, the players voted not to give Hornsby any of the World Series money.

Hornsby did not play for the rest of 1932, but the Cardinals signed him as a player on October 24 for the 1933 season. He played regularly at second base from April 25 through May 5, but he was used mostly as a pinch hitter with the Cardinals. On July 22, he had his final NL hit in a 9–5 loss to the Braves. Through July 23, Hornsby was batting .325 with two home runs and 21 RBIs. However, the Cardinals chose to place him on waivers.

Hornsby was claimed by the last-place St. Louis Browns of the American League (AL) on July 26 as player-manager. Bill Killefer had just resigned as Browns manager, and Browns owner Phil Ball wanted Hornsby as a replacement. Hornsby appeared in 11 games for the Browns. He had three hits, including a home run, in nine at-bats. The Browns finished in last place in the AL. That year, Hornsby began operating a baseball school in Hot Springs, Arkansas, which he ran on and off between 1933 and 1951 with various associates.
In 1934, Hornsby started only two games, one at third base, and the other in right field. In all of his other appearances, he was a pinch hitter. For the season, he batted .304 with one home run and 11 RBIs. The Browns improved on their previous season, finishing in sixth place out of eight teams in the AL.

Hornsby played in 10 games in the 1935 season, starting in 4. From April 16 through April 21, he started at first base, and he started at third base on May 22. He finished the year with five hits and a .208 average, while the Browns slipped to seventh place.

Hornsby only appeared in two games with the team during the 1936 season. On May 31, his pinch-hit single in the ninth inning gave the Browns an 11–10 win over the Detroit Tigers. In his other appearance on June 9, he played first base in a 5–3 win over the Yankees. The Browns again finished in seventh place.

In 1937, Hornsby played in 20 games. On April 21, in his first game of the year, Hornsby hit the final home run of his career in a 15–10 victory over the Chicago White Sox. On July 5, he had the final hit of his career in a 15–4 loss in the second game of a doubleheader with the Cleveland Indians.

On July 20, Hornsby appeared in what would be his final game, a 5–4 loss to the Yankees. A day later, Hornsby was fired as manager and released as a player by the Browns, who were in last place at the time of his release. His release was partly due to an incident with Browns owner Donald Barnes. On July 15, Hornsby won $35,000 ($ today) from betting on a horse race. When he tried to use $4,000 of this money to pay off a debt to Barnes, Barnes refused it, since it had come from a bookmaker. Hornsby protested to Barnes, "The money is as good as the money you take from people in the loan-shark business. It's better than taking interest from widows and orphans ..."; that made his release five days later an easy decision for Barnes. Hornsby finished the 1937 season with a .321 batting average and 18 hits in 20 games, and was the oldest player in the AL that season.

Before opening his own baseball school, Hornsby was an instructor at the "Roy Doan Baseball School", which operated from 1934-38 at Ban Johnson Park, Fogel Field and Majestic Park in Hot Springs, Arkansas, the site of many early Spring training facilities. Then, in 1939, Hornsby, started the "Rogers Hornsby Baseball College" in Hot Springs after Doan moved his School elsewhere. Hornsby ran the six-week event annually until 1952, usually attracting 100-200 prospects. Cy Young, Jimmie Foxx, Tris Speaker and Schoolboy Rowe were among the instructors for Hornsby's School. Held in conjunction with the baseball schools was "The George Barr Umpire School", the first umpire instructional school, with students under the direction of Barr, a Major League Umpire.

Following his release from the Browns, Hornsby was unable to retire because he had lost so much money gambling over the years. He signed as a player-coach with the Baltimore Orioles of the International League in 1938 before leaving them to play for and manage the Chattanooga Lookouts of the Southern Association for the rest of the season. Hornsby then returned to the Orioles to manage them for 1939, but he did not return to the club following the season. Halfway through 1940, he signed to manage the Oklahoma City Indians of the Texas League. He led them from last place to the Texas League playoffs, where they fell to the Houston Buffaloes in four games. Hornsby began 1941 managing the Indians once again, but he resigned in the middle of the season. In November, he became the general and field manager of the Fort Worth Cats, also of the Texas league. Fort Worth finished in third place and made the playoffs in 1942, but they were eliminated in the first round by the Shreveport Sports.

Hornsby went unsigned by any team in 1943, but he signed as a player-manager with the Veracruz Blues of "La Liga Mexicana" in Mexico in 1944. After hitting a game-winning grand slam for the second win of a series in March, he resigned when the team owner complained that the win would diminish the crowd for the third game of the series. Following his release, he did some commentary for radio station WTMV, assisted the Cleveland Indians in spring training in 1947, and became a TV announcer for Chicago Cubs games in 1949.

Hornsby did not become a manager or coach again until 1950, when he was hired to manage the Texas League's Beaumont Roughnecks. Beaumont won the pennant, but they were swept in the first round of the playoffs by the San Antonio Missions. The next year, in 1951, Hornsby managed the Seattle Rainiers of the Pacific Coast League. Under Hornsby's leadership, the Rainiers won the pennant.

In 1952, Hornsby was again hired to manage the St. Louis Browns, his first major league job in 16 years. The Browns' owner, Bill Veeck, was the son of former Cubs president and general manager William Veeck, Sr. Hornsby was not well received by the players, however. On June 9, he was fired due to a disagreement with Veeck over an incident against the Yankees the day before. During the game, a fan prevented Gil McDougald of the Yankees from catching a fly ball, and the umpire ruled that it was fan interference. Hornsby did not initially argue the call, and a few minutes later Veeck forced him to do it (when it was already too late to do anything about it). This led to Hornsby and the Browns parting ways. The Browns players were so happy about Hornsby's firing that they gave Veeck an engraved trophy to thank him.

A little over a month later, on July 26, Hornsby was hired to replace Luke Sewell as manager of the Cincinnati Reds. After Hornsby completed two mediocre seasons with the club, the Reds announced that he would not return for 1954. He finished his MLB managerial career with a record of 701–812. Following his dismissal, Hornsby worked as a coach for the Chicago Cubs from 1958 to 1960 before becoming a scout and third base coach for the New York Mets in 1962. In 1963, Hornsby died of a heart attack. He was buried in Hornsby Bend Cemetery near Austin, Texas.

Baseball experts and sportswriters consider Hornsby to be one of the greatest hitters of all time. His lifetime batting average of .358 is only exceeded by Ty Cobb's career mark of .367. He won seven batting titles in total, a feat tied or exceeded by only five players (Cobb (11 or 12, depending on the source), Tony Gwynn (8), Honus Wagner (8), Rod Carew (7), and Stan Musial (7)). Hornsby led the National League in slugging percentage nine times, a record that still stands. He also hit more home runs, drove in more runs, and had a higher batting average than any other National League player during the 1920s, which makes him one of four players in baseball history (along with Honus Wagner, Ted Williams, and Albert Pujols) to win a decade "triple crown". He hit a career total of 301 home runs and was the first player to reach 300 while playing mostly in the National League. His 264 home runs as a second baseman was a major league record for that position until Joe Morgan surpassed him in 1984. Hornsby was also a very consistent hitter whether he was playing at home or on the road. His lifetime home batting average was .359, and his lifetime away batting average was .358. Ted Williams, who had the highest career batting average since Hornsby, said that Hornsby was the greatest hitter for power and average in baseball, and Frankie Frisch said of him, "He's the only guy I know who could hit .350 in the dark." Hornsby also holds second place on the unofficial major league record list of "consecutive games with two or more hits" with 13 games, first place honors going to Count Campau's 15-game streak. Hornsby is only the second right-handed batter in history to hit over .400 three times and is considered, according to the "Los Angeles Times", to be the greatest right-handed hitter in history. He led the National League in batting average, on-base percentage, slugging percentage, and total bases every year from 1920 to 1925. He is one of only two players (the other being Ted Williams) to win the batting Triple Crown more than once, but only Hornsby batted .400 on both occasions.

Rogers Hornsby was so respected as a hitter that once, when a rookie pitcher complained to umpire Bill Klem that he thought he had thrown Rogers a strike, Klem replied, "Son, when you pitch a strike, Mr. Hornsby will let you know."
Hornsby was also renowned for his speed, and was considered to be the fastest player in the National League in his prime. He did not try to steal very often but used his speed to take extra bases. Between 1916 and 1927 Hornsby had 30 inside-the-park home runs, and he led the league with 17 triples in 1917 and 18 triples in 1921; he had 20 triples in 1920.

Hornsby never went to movies or read books, convinced that it would harm a batter's eyesight, and he never smoked or drank. However, he was often hard to get along with, a major reason he changed teams so frequently in the last decade of his career. He usually left due to falling out with the front office. Most of the players he managed did not like him due to his insistence that others follow his lifestyle, although some (like Woody English and Clint Courtney) did. Hornsby never played cards, but he did bet frequently on horse races, and he lost more than he won. His gambling was often a factor in his dismissal from a team. By most contemporary accounts, he was at least as mean and nasty as Cobb, who was known in his time for his aggressive attitude and dirty play.

Hornsby was elected into the National Baseball Hall of Fame in 1942. In 1999, Hornsby was ranked ninth on "The Sporting News" list of Baseball's Greatest Players. Later that year, he was named to the Major League Baseball All-Century Team. In 2001, writer Bill James ranked him as the 22nd-greatest player and the third-greatest second baseman in baseball history, while at the same time documenting his unpopularity and his difficult personality. He is also tied for eighth overall with Stan Musial in wins above replacement for position players. Hornsby has also been recognized on the St. Louis Walk of Fame In January, 2014, the Cardinals announced Hornsby among 22 former players and personnel to be inducted into the St. Louis Cardinals Hall of Fame Museum for the inaugural class of 2014.

On September 23, 1918, Hornsby married Sarah Elizabeth Martin, whom he had known since he played for the Denison Railroaders, in Philadelphia. They had a son, Rogers Hornsby, Jr., on November 15, 1920. Rogers Jr. died in a plane crash on December 23, 1949 near Savannah, Georgia.

During 1922 he began seeing Jeanette Pennington Hine, who was married to an automobile-supply salesman named John Hine. On June 12, 1923, Hornsby divorced Sarah, and Hine divorced her spouse in 1923 as well; the two were married on February 28, 1924. As a result of the divorce, Sarah took custody of Rogers Jr.

Hornsby and Jeanette had a son, Billy, on June 2, 1925. Billy played baseball for several years in the minor leagues, but never reached the majors. Hornsby and Jeanette became estranged in December 1944, and Hornsby began seeing a woman named Bernadette Harris, whom he called his "personal good friend and secretary", in 1945. They lived together after 1948, until Harris committed suicide by jumping out of a third-story window on September 7, 1953. The suicide was attributed to depression. Following Jeanette's death on June 1, 1956, Hornsby married Marjorie Bernice Frederick Porter on January 27, 1957. They remained together until Hornsby's death in 1963.



</doc>
<doc id="265667" url="https://en.wikipedia.org/wiki?curid=265667" title="Pattern Recognition (novel)">
Pattern Recognition (novel)

Pattern Recognition is a novel by science fiction writer William Gibson published in 2003. Set in August and September 2002, the story follows Cayce Pollard, a 32-year-old marketing consultant who has a psychological sensitivity to corporate symbols. The action takes place in London, Tokyo, and Moscow as Cayce judges the effectiveness of a proposed corporate symbol and is hired to seek the creators of film clips anonymously posted to the internet.

The novel's central theme involves the examination of the human desire to detect patterns or meaning and the risks of finding patterns in meaningless data. Other themes include methods of interpretation of history, cultural familiarity with brand names, and tensions between art and commercialization. The September 11, 2001 attacks are used as a motif representing the transition to the new century. Critics identify influences in "Pattern Recognition" from Thomas Pynchon's postmodern detective story "The Crying of Lot 49".

"Pattern Recognition" is Gibson's eighth novel and his first one to be set in the contemporary world. Like his previous work, it has been classified as a science fiction and postmodern novel, with the action unfolding along a thriller plot line. Critics approved of the writing but found the plot unoriginal and some of the language distracting. The book peaked at number four on the "New York Times" Best Seller list, was nominated for the 2003 British Science Fiction Association Award, and was shortlisted for the 2004 Arthur C. Clarke Award and Locus Awards.

Before writing "Pattern Recognition", the author, William Gibson, published seven novels (one co-written) and numerous short stories beginning in 1977. His previous novel, "All Tomorrow's Parties", was published in October 1999 as the conclusion of the Bridge trilogy. "Pattern Recognition" was written between 2001 and 2002 while Gibson was living in Vancouver, British Columbia and released in February 2003. "Pattern Recognition" was originally intended to be a stand-alone novel, but afterwards Gibson wrote "Spook Country" and "Zero History" which take place in the same universe and use some of the same characters.

Gibson traveled to Tokyo in 2001 to prepare for this new novel, which takes place in London, Moscow, and Tokyo. He did not travel to London or Moscow but used interviews with friends and internet resources for research. In September 2001 Gibson had written about 100 pages but was struggling to finish. He stopped writing after watching the September 11, 2001 attacks on television and "realized [the novel] had become a story that took place in an alternate time track, in which Sept. 11 hadn't happened". He considered abandoning the novel but a few weeks later re-wrote portions to use the attacks as a motivating factor for the distress the main character feels. In a 2003 interview he said, "There I was, in the winter of 2001, with no idea what the summer of 2002 was going to be like. ... In the original post-9/11 draft, London felt more like London is feeling right now. Cayce keeps seeing trucks full of soldiers. But I took that out, because as it got closer to the time, it wasn't actually happening."

Advertising consultant Cayce Pollard, who reacts to logos and advertising as if to an allergen, arrives in London in August 2002. She is working on a contract with the marketing firm Blue Ant to judge the effectiveness of a proposed corporate logo for a shoe company. During the presentation, graphic designer Dorotea Benedetti becomes hostile towards Cayce as she rejects the first proposal. After dinner with some Blue Ant employees, the company founder Hubertus Bigend offers Cayce a new contract: to uncover who is responsible for distributing a series of anonymous, artistic film clips via the internet. Cayce had been following the film clips and participating in an online discussion forum theorizing on the clips' meaning, setting, and other aspects. Wary of corrupting the artistic process and mystery of the clips, she reluctantly accepts. Cayce is not entirely comfortable with Ivy's chat group called "Fetish:Footage:Forum" (or F:F:F), as shown by the following excerpt:

A friend from the discussion group, who uses the handle Parkaboy, privately emails her saying a friend of a friend has discovered an encrypted watermark on one clip. They concoct a fake persona, a young woman named Keiko, to seduce the Japanese man who knows the watermark code. Cayce, along with an American computer security specialist, Boone Chu, hired to assist her, travels to Tokyo to meet the man and retrieve the watermark code. Two men attempt to steal the code but Cayce escapes and travels back to London. Boone travels to Columbus, Ohio to investigate the company that he believes created the watermark. Meanwhile, Blue Ant hires Dorotea who reveals that she was previously employed by a Russian lawyer whose clients have been investigating Cayce. The clients wanted Cayce to refuse the job of tracking the film clips and it was Dorotea's responsibility to ensure this.

Through a completely random encounter Cayce meets Voytek Biroshak and Ngemi, the former an artist using old ZX81 microcomputers as a sculpture medium, the latter a collector of rare technology (he mentions purchasing Stephen King's word processor, for example). Another collector, and sometime 'friend' of Ngemi's, Hobbs Baranov, is a retired cryptographer and mathematician with connections in the American National Security Agency. Cayce strikes a deal with him: she buys a Curta calculator for him and he finds the email address to which the watermark code was sent. Using this email address Cayce makes contact with Stella Volkova whose sister Nora is the maker of the film clips.

Cayce flies to Moscow to meet Stella in person and watch Nora work. Nora is brain damaged from an assassination attempt and can only express herself through film. At her hotel, Cayce is intercepted and drugged by Dorotea and wakes up in a mysterious prison facility. Cayce escapes; exhausted, disoriented and lost, she nearly collapses as Parkaboy, who upon Cayce's request was flown to Moscow, retrieves her and brings her to the prison where the film is processed. There Hubertus, Stella and Nora's uncle Andrei, and the latter's security employees are waiting for her. Over dinner with Cayce, the Russians reveal that they have been spying on her since she posted to a discussion forum speculating that the clips may be controlled by the Russian Mafia. They had let her track the clips to expose any security breaches in their distribution network. The Russians surrender all the information they had collected on her father's disappearance and the book ends with Cayce coming to terms with his absence while in Paris with Parkaboy, whose real name is Peter Gilbert.


The novel uses a third-person narrative in the present tense with a somber tone reminiscent of a "low-level post-apocalypticism". Cayce's memories of the September 11, 2001 attacks, which briefly use the future tense, are told by Gibson as "a Benjaminian seed of time", as one reviewer calls it, because of the monistic and lyrical descriptions of Cayce's relationship to objects with the attacks in the background. Two neologisms appear in the novel: "gender-bait" and "mirror-world". Gibson created the term "mirror-world" to acknowledge a locational-specific distinction in a manufactured object that emerged from a parallel development process, for example opposite-side driving or varied electrical outlets. "Gender-bait" refers to a male posing as a female online to elicit positive responses. The term "coolhunter", not coined by Gibson but used in the marketing industry for several years, is used to describe Cayce's profession of identifying the roots of emerging trends.

The September 11, 2001 attacks are used as a motif representing a break with the past with Cayce's father, who disappears during the attacks, as the personification of the 20th century. Gibson viewed the attacks as a nodal point after which "nothing is really the same". One reviewer commented that in "Gibson's view, 9-11 was the end of history; after it we are without a history, careening toward an unknown future without the benefit of a past—our lives before 9-11 are now irrelevant." Cayce's search for her father and Damien's excavation of the German bomber symbolize the historicist search for a method to interpret people's actions in the past. Coming to terms with her father's disappearance may be interpreted as a requiem for those lost to the 20th century, something that may have been influenced by Gibson coming to terms with the loss of his own father.

The film clips are a motif used to enhance the theme of the desire to find meaning or detect patterns. They are released over the internet and gain a cult following, in the same way that the lonelygirl15 videoblog gained an international following in 2006. Corporate interest in the footage is aroused by its originality and global distribution methods. The characters debate whether the anonymous clips are part of a complete narrative or a work in progress, and when or where they were shot. This enigmatic nature of the footage is said to metaphorically represent the nature of the confusing and uncertain post-9/11 future. The author Dennis Danvers has remarked that the footage being edited down to a single frame is like the world compressed into a single novel. The footage, released freely to a global audience with a lack of time or place indicators, has also been contrasted to "Pattern Recognition" written under contract for a large corporation and which uses liminal name-dropping that definitively sets it in London, Tokyo, and Moscow in 2002.

The central theme throughout the novel involves the natural human propensity to search for meaning with the constant risk of apophenia. Followers of the seemingly random clips seek connections and meaningfulness in them but are revealed to be victims of apophenia as the clips are just edited surveillance camera footage. Likewise, Cayce's mother turns to investigating electronic voice phenomena after Cayce's father disappears. Science fiction critic Thomas Wagner underscores the desire for meaning, or pattern recognition, using a comparison between the film clips and Cayce's search for her father after the attacks: [T]he very randomness and ineffability of the clips flies in the face of our natural human tendency towards pattern recognition ... [T]he subculture that surrounds "following the footage" ... [is] an effective plot device for underscoring the novel's post-9/11 themes: to wit, the uncertainty of the fabric of day-to-day life people began to feel following that event … [We] as people don't like uncertainty, don't like knowing that there's something we can't comprehend. And if we can't fit something into an existing pattern, then by golly we'll come up with one. Within the marketing world, Cayce is portrayed not as an outside rebel, but rather a paragon of the system. Inescapably within the system, she seeks an epistemological perspective to objectively interpret patterns. The review in "The Village Voice" calls this search "a survival tactic within the context of no context—dowsing for meaning, and sometimes settling for the illusion of meaning".

Using 20th-century relics, such as a Curta calculator, an excavated Stuka, Hobbs Baranov, and Voytek's planned ZX81 show, Gibson raises the question of how a contemporary society views past societies. Gibson portrays the past century as dominated by conflict, suspicion, and espionage. Following the disappearance of Cayce's father, a designer of embassy security systems, on September 11, 2001, Cayce is left feeling "ungrieved" until she reviews footage and records of that day tracking his movements until he vanishes.

Following this line of thought Gibson raises the question of how the future will view today's society. The novel "adopts a postmodern historicism" perspective, through the arguments presented by Bigend, Cayce, and Parkaboy. Bigend and Cayce's view of history are compared to those of philosopher Benedetto Croce in that they believe history is open for interpretation when re-written from the frame of reference of another society. Parkaboy rejects this view, believing that history can be an exact science.

The book explores a tension between originality and monoculture by focusing on the artist's relationship with a commercialized world and its marketing of free art and consumer products. Critic Lisa Zeidner argues that the artist's "loyalty and love" involved with creating originality counters Bigend's assertion that everything is a reflection of something else and that the creative process no longer rests with the individual. Commercialism is portrayed as a monoculture that assimilates originality. The Tommy Hilfiger brand is used as an example, "simulacra of simulacra of simulacra. A dilute tincture of Ralph Lauren, who had himself diluted the glory days of Brooks Brothers, who themselves had stepped on the product of Jermyn Street and Savile Row ... There must be some Tommy Hilfiger event horizon, beyond which it is impossible to be more derivative, more removed from the source, more devoid of soul."

One critic points out that the marketing agency Blue Ant is named after the wasp Blue Ant: "it's a wasp with a painful sting. The female hunts for a ground-dwelling cricket. She paralyses it with a sting and lays her egg on it. The still living yet immobile cricket becomes food for the wasp's young. What a clever metaphor for the process of targeting, commodifying, and marketing cool." On the other hand, as Rudy Rucker notes, while new art is constantly threatened by commodification, it is dependent on the monoculture for its launching point and uniqueness. Gibson's product positioning language and Cayce's analysis of consumerist trends show that society is not a victim of consumerism, but rather its creator who helps shape it without ever stepping outside it. Alex Link argues that rather than a simple attack on consumerism outright, the novel outlines a complex interrelationship between art, brand design, and terrorism as varying attitudes to history, terror, and community.

The novel's language is viewed as rife with labeling and product placements. Postmodern theorist Fredric Jameson calls it "a kind of hyped-up name-dropping ... [where] an encyclopaedic familiarity with the fashions ... [creates] class status as a matter of knowing the score rather than of having money and power". He also calls it "postmodern nominalism" in that the names express the new and fashionable. This name-dropping demonstrates how commercialism has created and named new objects and experiences and renamed (or re-created) some that already existed. This naming includes nationalities; there are eight references to nationality (or locality) in the first three pages. Zeidner wrote that the novel's "new century is unsettlingly transitional making it difficult to maintain an individual identity". One character argues that "there will soon be no national identity left … [as] all experience [will be] reduced, by the spectral hand of marketing, to price-point variations on the same thing." This is juxtaposed against the footage that contains no hints of time period or location. Globalization is represented by characters of varying nationalities, ease of international travel, portable instant communication, and commercial monoculture recognizable across international markets. As an example, Gibson writes how one ‘yes or no' decision by Cayce on the logo will impact the lives of the people in remote places who will manufacture the logos and how it will infect their dreams.

While some reviewers regard the novel as a thriller, others see it as an example of post-millennial science fiction with stories set in the "technocultural future-present". Some reviewers note that the novel furthers the post-millennial trend in science fiction of illustrating society's inability to imagine a definitive future and the use of technologies once considered advanced or academic now commonplace within society and its vernacular. Gibson said that the only science fiction elements are "[t]he Footage and Cayce's special talents" but that he "never bought that conceit that science fiction is about the future". Dennis Danvers explained the use of science fiction as a narrative strategy: [s]cience fiction, in effect, has become a narrative strategy, a way of approaching story, in which not only characters must be invented, but the world and its ways as well, without resorting to magic or the supernatural, where the fantasy folks work. A realist wrestling with the woes of the middle class can leave the world out of it by and large except for an occasional swipe at the shallowness of suburbia. A science fiction writer must invent the world where the story takes place, often from the ground up, a process usually called world-building. In other words, in a science fiction novel, the world itself is a distinctive and crucial character in the plot, without whom the story could not take place, whether it's the world of Dune or Neuromancer or 1984. The world is the story as much as the story is in the world. Part of Gibson's point ... is that we live in a time of such accelerated change and layered realities, that we're all in that boat, like it or not. A novel set in the "real world" now has to answer the question, "Which one?"

These elements, and the use of the September 11, 2001 attacks as a breaking point from the past, led academics to label it a postmodern novel. The attacks mark the point where the 'modern', that is the 20th-century certainty in society's advancement towards a better future, changed to the 'postmodern', that is the 21st-century uncertainty in which future will develop. Fredric Jameson finds Gibson using culture as the determinant of change for the first time with this novel, rather than technology. Jameson focuses on the novel's "postmodern nominalism" that uses brand names to refresh old objects and experiences.

In post-structural literary theory Cayce is compared with the main character, Oedipa Maas, of Thomas Pynchon's "The Crying of Lot 49" as detectives interpreting clues but with neither the character nor the reader knowing if there actually is a pattern to be found and, if there is one, whether it is real or conspiracy. Gibson's use of name-dropping brands to create a sense of "in-group style … of those in the know" is traced back to Thomas Pynchon's 1963 novel "V." . Gibson's writing style is said to be similar to Raymond Chandler's detective stories and Alfred Hitchcock's thrillers that used MacGuffins (the identity of the maker of the footage, in this case) to drive the story. Gibson's social observations are influenced by the works of Naomi Klein and Malcolm Gladwell.

While markedly different from his previous writing, in that it is not set in an imaginary future with imaginary technologies, "Pattern Recognition" includes many of his previous elements, including impacts of technology shifts on society, Japanese computer experts and Russian mafia figures. In common with Gibson's previous work, Paul Di Filippo found the following in "Pattern Recognition": "the close observation of the culture's bleeding edge; an analysis of the ways technology molds our every moment; the contrasting of boardroom with street; the impossibility and dire necessity of making art in the face of instant co-optation; the damaged loner facing the powers-that-be, for both principle and profit".

"Pattern Recognition" was released on February 3, 2003 as Gibson launched a 15-city tour. The novel was featured on the January 19 cover of "The New York Times Book Review". In the American market it peaked at number four on the "New York Times" Best Seller list for hardcover fiction on February 23 and spent nine weeks on "USA Today's" Top 150 Best-Selling Books peaking at number 34. In the Canadian market, the novel peaked at number three on "The Globe and Mail's" best seller list on February 15 in the hardcover fiction category. The novel was shortlisted for the 2004 Arthur C. Clarke Award and the British Science Fiction Association Award.

Gibson's writing was positively received by science fiction writers Dennis Danvers, Candas Jane Dorsey, and Rudy Rucker. Rucker has written: "[w]ith a poet's touch, he tiles words into wonderful mosaics" and Danvers wrote that "no sentence has a subject if it can do without one". One critic found the prose to be as "hard and compact as glacier ice" and another that it "gives us sharply observed small moments inscribed with crystalline clarity". Gibson's descriptions of interiors and of the built environments of Tokyo, Russia and London were singled out as impressive, and "The Village Voice"'s review remarked that "Gibson expertly replicates the biosphere of a discussion board: the coffee-shop intimacy, the fishbowl paranoia, the splintering factions, the inevitable flame war". Lisa Zeidner of "The New York Times Book Review" elaborated: As usual, Gibson's prose is ... corpuscular, crenelated. His sentences slide from silk to steel, and take tonal joy rides from the ironic to the earnest. But he never gets lost in the language, as he sometimes has in the past. Structurally, this may be his most confident novel. The secondary characters and their subplots are more fully developed, right down to their personal e-mail styles. Without any metafictional grandstanding, Gibson nails the texture of Internet culture: how it feels to be close to someone you know only as a voice in a chat room, or to fret about someone spying on your browser's list of sites visited. Filled with name-dropping of businesses and products, such as MUJI, Hotmail, iBook, Netscape, and G4, the language of the novel was judged by one critic to be "awkward in its effort to appear "cool" " while other critics have found it overdone and feared it would quickly date the novel. The "Pittsburgh Post-Gazette" review commented that the "constant, unadulterated "hipster-technocrat, cyber-MTV" lingo [is] overdone and inappropriate" On the technology, Cory Doctorow found Gibson's use of watermarks and keystroke logging to be hollow and has noted that "Gibson is no technologist, he's an accomplished and insightful social critic ... and he treats these items from the real world as metaphor. But ... Gibson's metaphorical treatment of these technologies will date this very fine book".

Some critics found the plot to be a conventional "unravel-the-secret" and "woman on a quest" thriller. Toby Litt wrote that "[j]udged just as a thriller, "Pattern Recognition" takes too long to kickstart, gives its big secrets away before it should and never puts the heroine in believable peril". The conclusion, called "unnecessarily pat" by one critic, was compared by Litt with the "ultimate fantasy ending of 1980s movies – the heroine has lucked out without selling out, has kept her integrity but still ended up filthy rich." The review in the "Library Journal" called the novel a "melodrama of beset geekdom" that "may well reveal the emptiness at the core of Gibson's other fiction", but recommended it for all libraries due to the author's popularity.

The hardcover edition, released in February 2003, was published by the Penguin Group imprint G. P. Putnam's Sons. Berkley Books published the trade paperback one year later, on February 3, 2004, and a mass market paperback in February 2005. In the UK the paperback was published by Penguin Books a year after its Viking Press imprint published the hardcover version. In 2004 it was published in French, Danish, Japanese, German, and Spanish. In 2005 the book was published in Russia. The translation made by Nikita Krasnikov was awarded as the best translation of the year.

Tantor Media published the 10.5-hour-long, unabridged audiobook on April 1, 2004 and re-released it on January 1, 2005. Voiced by Shelly Frasier, it was criticized by John Adams of "Locus" as being pleasant but with distracting dialects. The audiobook is available as a digital download from audible.com.

The digital radio station BBC 7 broadcast (now BBC Radio 4 Extra) an abridged version of the novel, voiced by Lorelei King, in five 30-minute episodes in February and October 2007. Post-punk band Sonic Youth included a track called "Pattern Recognition" on their 2004 album "Sonic Nurse" that opens with the lyric "I'm a cool hunter making you my way". A film adaptation was initiated in April 2004 with producer Steve Golin's production company Anonymous Content and the studio Warner Bros. Pictures hiring director Peter Weir. Screenwriters David Arata, D. B. Weiss, and Weir co-wrote the screenplay but in May 2007, Gibson commented on his personal blog that he believed Weir would not be proceeding with the project. In 2014 it was announced that Morten Tyldum had been attached to the project.


</doc>
<doc id="266034" url="https://en.wikipedia.org/wiki?curid=266034" title="O. G. S. Crawford">
O. G. S. Crawford

Osbert Guy Stanhope Crawford (28 October 1886 – 28 November 1957), better known as O. G. S. Crawford, was a British archaeologist who specialised in the study of prehistoric Britain and the archaeology of Sudan. For most of his career the archaeological officer of the Ordnance Survey (OS), he wrote a range of books on archaeological subjects and was a keen proponent of aerial archaeology.

Born in Bombay, British India, to a wealthy middle-class Scottish family, Crawford moved to England as an infant and was raised by his aunts in London and Hampshire. He studied geography at Keble College, Oxford, and worked briefly in that field before devoting himself professionally to archaeology. Employed by the philanthropist Henry Wellcome, Crawford oversaw the excavation of Abu Geili in Sudan before returning to England shortly before the First World War. During the conflict he served in both the London Scottish Regiment and the Royal Flying Corps, where he was involved in ground and aerial reconnaissance along the Western Front. After an injury forced a period of convalescence in England, he returned to the Western Front, where he was captured by the German Army in 1918 and held as a prisoner of war until the end of the conflict.

In 1920, Crawford was employed by the Ordnance Survey, touring Britain to plot the location of archaeological sites, and in the process identifying several previously unknown sites. Increasingly interested in aerial archaeology, he used Royal Air Force photographs to identify the extent of the Stonehenge Avenue, excavating it in 1923. With the archaeologist Alexander Keiller, he conducted an aerial survey of many counties in southern England and raised the finances to secure the land around Stonehenge for The National Trust. In 1927, he established the scholarly journal "Antiquity", which contained contributions from many of Britain's most prominent archaeologists, and in 1939 he served as president of The Prehistoric Society. An internationalist and socialist, he came under the influence of Marxism and for a time became a Soviet sympathiser. During the Second World War he worked with the National Buildings Record, photographically documenting Southampton. After retiring in 1946, he refocused his attention on Sudanese archaeology and wrote several further books prior to his death.

Friends and colleagues remembered Crawford as a cantankerous and irritable individual. His contributions to British archaeology, including in "Antiquity" and aerial archaeology, have been widely acclaimed; some have referred to him as one of the great pioneering figures in the field. His photographic archive remained of use to archaeologists into the 21st century. A biography of Crawford by Kitty Hauser was published in 2008.

O. G. S. Crawford was born on 28 October 1886 at Breach Candy, a suburb of Bombay in British India. His father, Charles Edward Gordon Crawford, was a civil servant who had been educated at Marlborough College and Wadham College, Oxford before moving to India, where he became a High Court judge at Thane. The Crawford family came from Ayrshire in Scotland, and the child's great-uncle was the politician Robert Wigram Crawford. Crawford's mother, Alice Luscombe Mackenzie, was the daughter of a Scottish army doctor and his Devonshire wife. Alice died a few days after her son's birth, and so when he was three months old, Crawford was sent to England aboard the P&O liner "Bokhara". During the journey he was entrusted to the care of his paternal aunt Eleanor, an Anglican nun who was the head of the Poona Convent of the Community of St Mary the Virgin.

In Britain, he spent the next seven years with two paternal aunts who lived together near to Portland Place in the Marylebone district of central London. Like his father, they were devout Christians, having been the children of a Scottish clergyman. Under their guardianship Crawford had little contact with other children or with men. Crawford saw his father on the few occasions that the latter visited England, prior to his death in India in 1894. In 1895, Crawford and his two aunts moved to a rural house in East Woodhay, Hampshire. Initially educated at Park House School, which he enjoyed, he was then moved to Marlborough College, his father's "alma mater". He was unhappy there, complaining about bullying and enforced sporting activities, and characterising it as a "detestable house of torture".

At the school, Crawford was influenced by his housemaster, F. B. Malim, who presided over the archaeological section of the college's Natural History Society and encouraged the boy's interest in the subject. It is possible that Malim provided something of a father figure for the young Crawford. With the society, Crawford visited such archaeological sites as Stonehenge, West Kennet Long Barrow, Avebury, and Martinsell. It was also through the society that he obtained Ordnance Survey maps of the landscape, allowing him to explore the downs near to his aunts' home. He began excavation of a barrow near to Bull's Copse, thus attracting the attention of the antiquarian Harold Peake, who was then involved in compiling the "Victoria County History of Berkshire". Peake and his wife lived a Bohemian lifestyle, being vegetarians and social reformers, and their ideas had a strong impact on Crawford. Under the Peakes' influence, Crawford rejected his religious upbringing in favour of a rationalist world-view based in science. Crawford gained an appreciation from Peake for the understanding of past societies through an examination of the geographical landscape rather than simply through texts or artefacts.

Following his schooling, Crawford won a junior scholarship to study at Keble College, Oxford. There he began reading "literae humaniores" in 1905 but—after gaining only a third-class score in his second year exams—he switched courses to study geography in 1908. In 1910 he gained a distinction for his diploma, for which he had conducted a study of the landscape surrounding Andover. Reflecting his interest in the relationship between geography and archaeology, during a walking tour of Ireland he had also written a paper on the geographic distribution of Bronze Age flat bronze axes and beakers in the British Isles. It was presented to the Oxford University Anthropological Society before being published in "The Geographical Journal". The archaeologist Grahame Clark later related that the paper "marked a milestone in British Archaeology; it was the first real attempt to deduce prehistoric events from the geographical distribution of archaeological objects". Crawford's fellow archaeologist Mark Bowden stated that while archaeological distribution maps had been previously produced, "archaeological data had never before been married with environmental information" in the way that Crawford did in this article.

After Crawford graduated, Professor A. J. Herbertson offered him a job as a junior demonstrator in the university's geography department. Crawford agreed, and served in the teaching position over the ensuing year. Through Herbertson, Crawford was introduced to the geographer Patrick Geddes. Crawford then decided to focus his attentions on archaeology rather than geography even though few professional positions in the field existed in Britain at the time. Looking elsewhere for archaeological employment, he unsuccessfully applied for a Craven Fellowship and for a post at Bombay Museum.

At Herbertson's recommendation, in 1913 Crawford gained employment as an assistant on William Scoresby Routledge and Katherine Routledge's expedition to Easter Island. The expedition had the intention of learning more about the island's first inhabitants and its Moai statues. After the team departed from Britain aboard the schooner "Mana", Crawford began quarrelling with the Routledges. Informing them that they had demonstrated an "extraordinary lack of courtesy" and "appalling stinginess" toward both him and other crew members, he left the ship at Cape Verde and returned to Britain. He then gained employment from the wealthy philanthropist Henry Wellcome, who sent him to Egypt to gain further training in archaeological excavation from G. A. Reisner. Wellcome then sent him to Sudan, where Crawford was given charge of the excavation of the Meroitic site at Abu Geili, remaining there from January to June 1914. On his return to England—where he was planning on sorting through the artefacts found in Sudan—he and his friend Earnest Hooton began excavation of a long barrow on Wexcombe Down in Wiltshire.

It was while Crawford was engaged in this excavation that the United Kingdom entered the First World War. At Peake's encouragement, Crawford enlisted in the British Army, joining the London Scottish Regiment and was sent to reinforce the First Battalion on the Western Front. The battalion marched to Béthune to relieve the British line, fighting at Givenchy. Crawford was afflicted with influenza and malaria, and in February he was invalided back to England and stationed at Birmingham for his recuperation. After he recovered, he applied to join the Royal Flying Corps (RFC) but was deemed too heavy. He was commissioned in May 1915. In July 1915 he joined the Royal Berkshire Regiment as part of the Third Army, being stationed at Beauval and then St. Pol. Using his existing skills, he served as the regiment's maps officer, and was responsible for mapping the areas around the front line, including German Army positions. He also took photographs which were used for British propaganda purposes, and in 1916 he guided the writer H. G. Wells around the trenches on the latter's visit to the Front.

In January 1917, Crawford successfully applied to join the RFC as an observer with the 23rd Squadron, which flew over enemy lines to make observations and draw maps. On his maiden flight, the German Army opened fire on his aircraft, and his right foot was pierced by bullets and badly injured. To recuperate, he spent time at various hospitals in France and England before being sent to the RFC Auxiliary Hospital at the Heligan estate in Cornwall. During this time in England he spent a weekend at Wells's home in Dunmow, Essex, embracing the latter's desire for a united world government and the idea that writing about global history was a contribution to that cause. While at Heligan, Crawford began work on a book, "Man and his Past", in which he examined a broad sweep of human history from an archaeological and geographical perspective.

In September 1917, Crawford—who had been promoted to the position of squadron intelligence officer—joined the 48th Squadron, for which he again took aerial photographs during reconnaissance missions. While on one flight in February 1918, Crawford's aircraft was shot at and forced to land in German-held territory; he and his co-pilot were taken as prisoners of war. He was initially imprisoned at Landshut in Bavaria, from where he tried to escape by swimming down the River Isar; the river current proved too strong and he was soon recaptured. He was then transferred to Holzminden prisoner-of-war camp, where he was aware of an escape plan involving tunnelling out of the camp, but did not take part. Instead he spent much of his time working on "Man and his Past" and reading works by Wells, Carl Jung, and Samuel Butler. Crawford remained in the camp for seven months, until the declaration of armistice, at which he returned to Britain and was demobilised.

Back in England, Crawford finished writing "Man and his Past", which was published by Oxford University Press in 1921. According to the historian of archaeology Adam Stout, the book was "a manifesto, a rallying-cry for a new generation of archaeologists who shared in the idealism and the faith in the potential of Progress". Bowden suggested that it could be seen as a "manifesto for geoarchaeology, environmental archaeology and economic archaeology. The unifying theme is that all these topics should be approached through the compilation of maps". In discussing geographical methods for delineating "cultures", the work fit within the theoretical trend of culture-historical archaeology, but did not attempt to apply the concept of culture in a systematic fashion.

Crawford also returned to field work, carrying out archaeological excavation for the Cambrian Archaeological Association in both Wiltshire and Wales. In mid-1920, he excavated at Roundwood, Hampshire and on the Isle of Wight for Sir William Portal.

His expertise resulted in his being invited by Charles Close, the Director-General of the Ordnance Survey (OS), to join that organisation as their first archaeological officer. Accepting the position, Crawford moved to Southampton and began work at the project in October 1920. His arrival at the OS generated some resentment, with co-workers often seeing his post as superfluous and deeming archaeology to be unimportant. His job entailed correcting and updating information about archaeological monuments as the OS maps were revised, and involved him undertaking much fieldwork, travelling across the British landscape to check the location of previously recorded sites and discover new ones. He began in Gloucestershire in late 1920, visiting 208 sites around the Cotswolds and adding 81 previously unknown barrows to the map. Based on his research in this region, in 1925 he published his book "Long Barrows and the Stone Circles of the Cotswolds and the Welsh Marches".

As part of his job, he travelled around Britain, from Scotland in the north to the Scilly Isles in the south, often conducting his fieldwork by bicycle. At archaeological sites he took photographs and stored them in his archive, and he also obtained aerial photographs of archaeological sites taken by the Royal Air Force.
In this he was aided by regional antiquarian societies and by his correspondents, whom he called his "ferrets". In 1921, the Ordnance Survey published Crawford's work, "Notes on Archaeology for Guidance in the Field", in which he explained how amateur archaeologists could identify traces of old monuments, roads, and agricultural activity in the landscape. He also began producing "period maps" in which archaeological sites were marked; the first of these was on Roman Britain, and featured Roman roads and settlements. First published in 1924, it soon sold out, resulting in a second edition in 1928. He followed this with a range of further maps in the 1930s: "England in the Seventeenth Century", "Celtic Earthworks of Salisbury Plain", "Neolithic Wessex", and "Britain in the Dark Ages". Although his position had initially been precarious, in 1926 it was made permanent, despite the reluctance of the Treasury, which financed the OS at the time. By 1938, he had been able to persuade the OS to employ an assistant, W. F. Grimes, to aid him in his work.

Crawford became particularly interested in the new technique of aerial archaeology, claiming that this new process was to archaeology what the telescope was to astronomy. His association with it was honoured in Wells' 1939 novel "The Shape of Things to Come", which names a survey aeroplane that discovers an ancient archaeological device "Crawford". He produced two OS leaflets containing various aerial photographs, printed in 1924 and 1929 respectively. Through these and other works he was keen to promote aerial archaeology, coming to be firmly identified with the technique. Not a keen aerial photographer himself, he did not personally take the photographs, but collected most of them on visits to RAF bases or (in the 1930s) from individual flyers such as George Allen and Gilbert Insall. He used sources such as Anglo-Saxon boundary charters, place-names and folklore to identify possible locations of prehistoric and Roman sites.

Using RAF aerial photographs, Crawford determined the length of the Avenue at Stonehenge before embarking on an excavation of the site with A. D. Passmore in late 1923. This project attracted press attention, resulting in Crawford being contacted by the marmalade magnate and archaeologist Alexander Keiller. Keiller invited Crawford to join him in an aerial survey, financed by Keiller himself, in which they flew over Berkshire, Dorset, Hampshire, Somerset, and Wiltshire in 1924, taking photographs of archaeological traces in the landscape. Many of these images were published in Crawford and Keiller's "Wessex from the Air" in 1928. In 1927 Crawford and Keiller helped raise the finances to buy the land around Stonehenge and present it to The National Trust to prevent it from being damaged by further agricultural or urban development. Previously, in 1923, Crawford had assisted Keiller in campaigning to prevent a radio mast being erected on the archaeologically significant Windmill Hill in Wiltshire, with Keiller later purchasing the hill and the surrounding Avebury area. Despite this working relationship, the two never became friends, perhaps a result of their highly divergent opinions and interests outside of archaeology.

In 1927, Crawford founded "Antiquity; A Quarterly Review of Archaeology", a quarterly journal designed to bring together the research of archaeologists working across the world to supplement the variety of regional antiquarian periodicals that were then available. In particular, Crawford saw "Antiquity" as a rival to the "Antiquaries Journal" published by the Society of Antiquaries. Crawford was contemptuous of the Society, disliking their neglect of prehistory and believing that they did little valuable research. Although designed to have an international scope, "Antiquity" exhibited a clear bias towards the archaeology of Britain, with its release coinciding with the blossoming of British archaeology as a field of study. It contained contributions from a variety of young archaeologists who came to dominate the field of British archaeology, among them V. Gordon Childe, Grahame Clark, Cyril Fox, Christopher Hawkes, T. D. Kendrick, Stuart Piggott, and Mortimer Wheeler. They shared Crawford's desire to professionalise the field, thereby taking it away from the domination of antiquarian hobbyists and in a more scientific direction. To some of these individuals, Crawford himself was affectionately known as "Ogs" or "Uncle Ogs"

The journal proved influential from the start. Although not initially using a process of peer review, Crawford asked his friends to read through submissions that he was unsure about. As well as seeking to shape and define the discipline, "Antiquity" sought to spread news of archaeological discoveries to a wider public, thereby being more accessible than pre-existing scholarly journals. This resulted in Crawford receiving letters from proponents of various pseudo-archaeological ideas, such as the ley line theory of Alfred Watkins; he filed these letters under a section of his archive titled "Crankeries" and was annoyed that educated people believed such ideas when they were demonstrably incorrect. He refused to publish an advert in "Antiquity" for "The Old Straight Track" by Watkins, who became very bitter towards him. In 1938, Crawford served as President of the Prehistoric Society; in this position he instigated a series of excavations, inviting the German archaeologist Gerhard Bersu—persecuted in Germany by the Nazi authorities—to move to England to oversee the excavation of Little Woodbury.

Crawford enjoyed foreign travel. In 1928 the OS sent him to the Middle East to collect aerial photographs that had been produced during the First World War and which were stored at Baghdad, Amman, and Heliopolis. In mid-1931 he visited Germany and Austria, furthering his interest in photography through the purchase of a Voigtländer. He later visited Italy with the intent of examining the possibility of producing OS maps pinpointing the country's archaeological sites; in November 1932 he met with the Italian leader Benito Mussolini, who was interested in Crawford's ideas about creating an OS map of archaeological sites in Rome. This was part of a wider project to produce a series of maps covering the entirety of the Roman Empire, for which Crawford visited various parts of Europe during the late 1920s and 1930s. Holiday destinations included Germany, Austria, Romania, Corsica, Malta, Algeria, and Tunisia, and in 1936 he purchased a plot of land in Cyprus on which he had a house built. During these vacations, he visited archaeological sites and met with local archaeologists, encouraging them to contribute articles to "Antiquity".

Crawford believed that society would progress with the growth of internationalism and the increased application of science. Politically, he had moved toward socialism under the influence of Childe, who had become a close friend. He expressed the view that socialism was "the natural corollary of science in the regulation of human affairs". He attempted to incorporate Marxist ideas into his archaeological interpretations, as a result producing articles such as "The Dialectical Process in the History of Science", which was published in "The Sociological Review". He became enthusiastic about the Soviet Union, a state governed by the Marxist Communist Party, viewing it as the forerunner of a future world state.

With his friend Neil Hunter, he travelled to the Soviet Union in May 1932, sailing to Leningrad aboard the "Smolny". Once there, they followed a prescribed tourist itinerary, visiting Moscow, Nizhni Novgorod, Stalingrad, Rostov-on-Don, Tiflis, Armenia, Batum, and Sukhum. Crawford admired what he perceived as the progress that the Soviet Union had made since the fall of the Tsarist regime, the increasingly classless and gender-equal status of its population, and the respect accorded to scientists in planning its societal development. He described his holiday with glowing praise in a book, "A Tour of Bolshevy", stating that he did so to "hasten the downfall of capitalism" while at the same time making "as much money as possible" out of capitalists. The book was rejected by the publisher Victor Gollancz, after which Crawford decided not to approach other publishers, instead giving typed copies of the work to his friends. Although he became involved with the Friends of the Soviet Union and wrote several articles for the "Daily Worker" newspaper, he never joined the Communist Party of Great Britain, nor did he become involved in organised politics at all, perhaps fearing that to do so would jeopardise his employment in the civil service.

In Britain, he photographed sites associated with the prominent Marxists Karl Marx and Vladimir Lenin. He also photographed the signs erected by landowners and religious groups, believing that in doing so he was documenting the traces of capitalist society before they would be swept away by socialism. Both in Britain and on a visit to Germany he photographed pro-fascist and anti-fascist propaganda and graffiti. Like many leftists at the time, he believed that fascism was a temporary, extreme expression of capitalist society that would soon be overcome by socialism. He nevertheless expressed admiration for the German archaeological establishment under the Nazi government, highlighting that the British state lagged far behind in terms of funding excavations and encouraging the study of archaeology in universities; he refrained from commenting on the political agenda that the Nazis had in promoting archaeology.

Despite his socialist and pro-Soviet beliefs, Crawford believed in collaborating with all foreign archaeologists, regardless of political or ideological differences. In early 1938, he lectured on aerial archaeology at the German Air Ministry; the Ministry published his lecture as "Luftbild und Vorgeschichte", and Crawford was frustrated that the British government did not publish his work with the same enthusiasm. From there, he visited Vienna to meet with his friend, the archaeologist Oswald Menghin; Menghin took Crawford to an event celebrating the Anschluss, at which he met the prominent Nazi Josef Bürckel. Shortly after, he holidayed in Schleswig-Holstein, where German archaeologists took him to see the Danevirke.

In the late 1930s he began work on a book titled "Bloody Old Britain", which he described as "an attempt to apply archaeological methods to the study of contemporary society" and in which he was heavily critical of his homeland. It examined 1930s Britain through its material culture, with Crawford reaching the judgement that it was a society in which appearances were given greater importance than value, with clothing, for instance, emphasising bourgeois respectability over comfort. He attributed much of this to the impact of capitalism and consumerism on British culture. The work fitted within an established genre of 1930s publications which lamented the state of British society, in particular the quality of its food and manufactured products as well as its increasing suburbanisation. By the outbreak of the Second World War the work had become less marketable due to its unpatriotic nature, and when in 1943 Crawford proposed it to Methuen Publishing they turned it down; he gave copies to a few friends, but never published it.

In anticipation of the Second World War, Crawford expressed the view that he would "remain neutral" and not take sides, not because he favoured fascism over liberal democracy but because he saw both as repugnant forms of capitalist society which would ultimately be swept away by a socialist revolution; in his words the war would be "a clash of imperialisms, a gangsters' feud". After war broke out, he decided that in the event of a German invasion of Britain he would destroy all of his leftist literature lest he be persecuted for possessing it.

In November 1940, the German Luftwaffe began bombing Southampton, where the OS offices were located. Crawford removed some of the old OS maps and stored them in the garage of his house at Nursling, while also unsuccessfully urging the Director-General to remove the OS' archive of books, documents, maps and photographs to a secure location. Subsequently, the OS headquarters were destroyed in the bombing, resulting in the loss of most of their archive. The refusal of the OS administration to take his warnings seriously infuriated Crawford, exacerbating his anger about the civil service's red tape and bureaucracy. In his words, "trying to get a move on in the Civil Service was like trying to swim in a lake of glue". Resigning his membership in various British societies, he unsuccessfully tried to find employment abroad.

With little for an archaeology officer to do at the OS in wartime, in mid-1941 Crawford was seconded to the Royal Commission on the Historical Monuments of England "for special duties during wartime". They assigned him to carry out a project of photographic documentation in Southampton for the National Buildings Record, producing images of many old buildings or architectural features that were threatened by the Luftwaffe's bombing campaign. He appreciated the value of this work, taking 5,000 photographs over the course of the war. In 1944, the Council for British Archaeology was founded, and while Crawford was invited to serve on its first council, he declined the offer, being lukewarm about the project.

In 1946, at the earliest possible opportunity, Crawford resigned his post at the OS, where he was replaced by Charles Philips. He remained in the Southampton area and retained his interest in the city's architecture, in particular that of the Middle Ages. In 1946 he was a founding member of a lobby group, Friends of Old Southampton, which sought to protect the city's historic architecture from destruction amid post-war development. During the post-war period he also came to be preoccupied and terrified by the prospect of a nuclear war, urging archaeological authorities to make copies of all their information and disperse it in different locations to ensure that knowledge survived any forthcoming Third World War. Retaining his left-wing interests, in 1945 and 1946 he had some involvement with the Labour Party, although elsewhere he mocked the "ignorant" who thought that Labour "genuinely" represented socialism. In the latter part of the 1940s he became increasingly disillusioned with the Soviet Union after reading Arthur Koestler's "Darkness at Noon", a book about Joseph Stalin's Great Purge and Moscow show trials, as well as learning of how Soviet scientists who did not support the ideas of Trofim Lysenko had been persecuted. In 1950—after reading the memoir of Margarete Buber-Neumann—he declared himself to be "fanatically anti-Soviet [and] anti-communist".

In 1949, Crawford was elected a Fellow of the British Academy, and in 1950 he became a Commander of the Most Excellent Order of the British Empire. In 1952 he was made an honorary Doctor of Letters by the University of Cambridge for his contributions to aerial archaeology.

Crawford returned his attention to Sudanese archaeology, describing Sudan as "an escape-land of the mind at a time when the island of Britain was an austere prison". At the invitation of the Sudanese government, he visited the country on an archaeological reconnaissance trip in January 1950, before visiting the Middle Nile in 1951. At Nursling, he wrote a book on the northern Sudanese Funj Sultanate of Sennar, which appeared in the same year as his long-delayed report on the Abu Geili excavation, co-written with Frank Addison. He followed this with the 1953 book "Castles and Churches in the Middle Nile Region". Another of Crawford's book projects in this period was a short history of Nursling, as well as an introductory guide to landscape studies, "Archaeology in the Field", published in 1953. In 1955 he then published his autobiography, "Said and Done", which the archaeologist Glyn Daniel and the historian Mark Pottle—the authors of Crawford's entry in the "Dictionary of National Biography"—described as "a vivacious and amusing autobiography in which his character comes clearly through".

After the discovery of prehistoric rock art on Stonehenge in 1953, Crawford decided to examine the engravings on the megalithic monuments in Brittany. Inspired by this subject, in 1957 he published "The Eye Goddess". In this book he argued that many of the abstract designs featured in prehistoric rock art were representations of eyes. He further argued that they provided evidence for a religion devoted to a mother goddess which had existed across the Old World from the Palaeolithic through to the period of Christianisation. That same decade also witnessed similar ideas regarding a Neolithic religion focused around a great goddess being espoused in the works of Childe and Daniel; the historian Ronald Hutton later observed that "whether or not there was ever an 'Age of the Goddess' in Neolithic Europe, there certainly was one among European intellectuals in the mid twentieth century". Crawford's book was not well received within academia.

Crawford was also interested in cats, and learned how to mimic cat noises, performing these on a BBC broadcast, "The Language of Cats", which proved popular and led to a range of fan letters. A publisher in the United States invited him to write a book on the subject, but Crawford never completed it. In the mid-1950s, Crawford began to take an interest in astronomy and cosmological ideas about the origin of the universe, favouring Fred Hoyle's steady state theory about an eternal universe with no beginning or end.

In 1951, an edited volume, "Aspects of Archaeology in Britain and Beyond: Essays Presented to O. G. S. Crawford", was published, having been edited by Grimes and brought out to mark Crawford's 65th birthday. Reviewing the anthology for "Antiquity", J. v. d. Waals and R. J. Forbes described it as "an exquisite birthday present". Many of Crawford's associates worried about him, aware that he lived alone at his cottage in Nursling—with only the company of his elderly housekeeper and cats—and that he lacked either a car or telephone. It was there that he died in his sleep on the night of 28–29 November 1957. He had arranged for some of his letters and books to be destroyed, while others were to be sent to the Bodleian Library, with the proviso that some of them would not be opened until the year 2000. His body was buried in the church graveyard at Nursling. In accordance with his instructions, the title "Editor of "Antiquity"" was inscribed on his gravestone, reflecting his desire to be remembered primarily as an archaeologist. On Crawford's death, the editorship of "Antiquity" was taken on by Daniel.

Crawford's socialist beliefs were known to his colleagues and associates, as was his antipathy toward religion. While he became an atheist during his time at Marlborough College, it is not known exactly when he embraced socialism. He placed a strong emphasis on personal self-sufficiency, and openly expressed contempt for those who required social interaction for their own happiness. His adult life was a solitary one, with no family and no human dependents. His sexual orientation remains unknown, with Bowden noting that Crawford's interactions with women were "cordial but not significant". He was fond of cats, and kept several as pets, also rearing pigs for food as well as growing vegetables in his garden at Nursing. A heavy smoker, he was known for rolling his own cigarettes.

Crawford was often irritable and some colleagues found him exasperating to work with. He was known for his lack of patience, and when angry or frustrated was known to fling his hat to the floor in a gesture of rage. His biographer Kitty Hauser noted that "apparently trifling events left an indelible mark on him", for he would remember a perceived slight for decades. Bowden expressed the view that while Crawford "had a quick temper, which he strove to control ... he was essentially a friendly man", adding that he could be "clubbable, hospitable and kind".

Jonathan Glancey referred to Crawford as "a compelling if decidedly cantankerous anti-hero" and an "essentially Victorian eccentric". Hauser characterised him as "a very British combination of a snob and a rebel", also noting that he was "no great intellectual". Similarly, Clark expressed the view that "Crawford's achievements" stemmed from his "moral integrity and singleness of mind" rather than "any outstanding intellectual brilliance". The journalist Neal Ascherson described Crawford as "not conventionally intellectual". Ascherson added that Crawford was "withdrawn, generally ill at ease with other members of the human species except on paper, and suspicious of personal celebrity", in this way contrasting Crawford with his "gregarious" contemporaries Wheeler and Daniel.

Daniel characterised Crawford as having a "messianic desire" to promote archaeology "to the people of the world". He was opinionated and dogmatic and expressed disdain for those who viewed the past in a different manner to himself. Piggott noted that Crawford was unable to sympathise with the perspectives of those studying past societies through a discipline other than archaeology, such as history or art history, and that he could not sympathise with "anyone not as passionately concerned as himself in field antiquities". For example, in one of his publications, Crawford dismissed historians as being "bookish" and "clean-booted". The archaeologist Jacquetta Hawkes commented that in Crawford's editorials for "Antiquity", he directed "righteous indignation" toward "everybody from the State, Dominion and Colonial Governments, Universities and Museums, to tardy reviewers and careless proof-correctors".

Wheeler—who considered Crawford to be "one of [his] closest friends"—claimed that the latter was "an outspoken and uncompromising opponent" and a man who had a "boyish glee in calling the bluff of convention". He added that Crawford exhibited the "divine impatience of the pioneer" and that he had an "inability to work in harness. If he joined a committee or a sodality, he did so only to resign at the first opportunity." Piggott described Crawford as a mentor who "was encouraging, helpful, and unconventional: his racy outspoken criticism of what then passed for the archaeological Establishment was music to a schoolboy's ear".

Crawford was much respected by his peers. According to Hauser, at the time of his death Crawford had "acquired an almost mythical status among British archaeologists as the uncompromising – if eccentric – progenitor of them all".
In 1999, the archaeologist John Charlton referred to Crawford as "one of the pioneers of British archaeology this century", while nine years later Ascherson described him as "beyond question one of the great figures of the 'modern' generation which transformed British archaeological practice and its institutions between 1918 and – say – 1955". Ascherson noted that Crawford's contributions to archaeology had little to do with archaeological theory and more to do with "the institutions and tools ... which he bequeathed to his profession", including "Antiquity". Crawford devoted little time to interpreting the archaeological record, and when he did so usually embraced functionalist interpretations, believing that people in traditional societies devoted almost all of their time to survival rather than behaving according to religious or symbolic concepts; in this he was typical of his time and was influenced by Marxist materialism.

Crawford was recognised for his contributions to bringing archaeology to a wide sector of the British public. The archaeologist Caroline Malone stated that many viewed Crawford as "an 'amateur's' archaeologist, providing the means to publish and comment outside the restrictions of local journals and to offer a vision of a new and universal discipline". Clark expressed the view that Crawford "always hankered to restore the flesh and blood and to make the past a reality to the living generation", and in doing so helped to attract a greater public audience for British archaeology than many of his colleagues. Wheeler remarked that "he was our greatest archaeological publicist; he taught the world about scholarship, and scholars about one another".
Commenting on Crawford's editorship of "Antiquity", Hawkes expressed the view that his "skill in steering between over-simplification and over-specialization has enabled the Magazine to succeed admirably in its role as go-between for experts and public".

Crawford's system of documenting archaeological sites in the OS' Archaeological Record provided the blueprint on which both the later National Archaeological Records in England, Scotland, and Wales, and the local sites and monuments records were based.
In the 21st century, Crawford's photographic archive stored at Oxford University's Institute of Archaeology was still consulted by archaeologists seeking to view how various sites appeared during the first half of the 20th century.
In 2008, Kitty Hauser's biography, "Bloody Old Britain", was published. Reviewing her work for "The Guardian", Glancey described it as "a truly fascinating and unexpected book". Writing in "Public Archaeology", Ascherson characterised it as "full of clever perception and sympathetic insight" but was critical of its lack of references and "occasional mistakes of fact".

An anonymously assembled list of Crawford's publications up to 1948 was published in his 1951 festschrift.



</doc>
<doc id="266325" url="https://en.wikipedia.org/wiki?curid=266325" title="Sovereign (British coin)">
Sovereign (British coin)

The sovereign is a gold coin of the United Kingdom, with a nominal value of one pound sterling. Struck from 1817 until the present time, it was originally a circulating coin accepted in Britain and elsewhere in the world; it is now a bullion coin and is sometimes mounted in jewellery. In most recent years, it has borne the well-known design of Saint George and the Dragon on the reverse—the initials () of the designer, Benedetto Pistrucci, may be seen to the right of the date.

The coin was named after the English gold sovereign, last minted about 1603, and originated as part of the Great Recoinage of 1816. Many in Parliament believed a one-pound coin should be issued rather than the 21-shilling (£1, 1S) guinea struck until that time. The Master of the Mint, William Wellesley Pole, had Pistrucci design the new coin, and his depiction was also used for other gold coins. Originally, the coin was unpopular as the public preferred the convenience of banknotes, but paper currency of value £1 was soon limited by law. With that competition gone, the sovereign not only became a popular circulating coin, but was used in international trade and in foreign lands, trusted as a coin containing a known quantity of gold.

The British government promoted the use of the sovereign as an aid to international trade, and the Royal Mint took steps to see that lightweight gold coins were withdrawn from circulation. From the 1850s until 1932, the sovereign was also struck at colonial mints, initially in Australia, and later in Canada, South Africa and India—they have been struck again in India since 2013 (in addition to the production in Britain by the Royal Mint) for the local market. The sovereigns issued in Australia initially carried a unique local design, but by 1887, all new sovereigns bore Pistrucci's George and Dragon design. Strikings there were so large that by 1900, about 40 per cent of the sovereigns in Britain had been minted in Australia.

With the start of the First World War in 1914, the sovereign vanished from circulation in Britain, replaced by paper money, and it did not return after the war, though issues at colonial mints continued until 1932. The coin was still used in the Middle East, and demand rose in the 1950s, which the Royal Mint eventually responded to by striking new sovereigns in 1957. It has been struck since then both as a bullion coin and, beginning in 1979, for collectors. Though the sovereign is no longer in circulation, it is still legal tender in the United Kingdom.

There had been an English coin known as the sovereign, first authorised by Henry VII in 1489. It had a diameter of , and weighed , twice the weight of the existing gold coin, the ryal. The new coin was struck in response to a large influx of gold into Europe from West Africa in the 1480s, and Henry at first called it the double ryal, but soon changed the name to sovereign. Too great in value to have any practical use in circulation, the original sovereign likely served as a presentation piece to be given to dignitaries.

The English sovereign, the country's first coin to be valued at one pound, was struck by the monarchs of the 16th century, the size and fineness often being altered. James I, when he came to the English throne in 1603, issued a sovereign in the year of his accession. but the following year, soon after he proclaimed himself King of Great Britain, France and Ireland, he issued a proclamation for a new twenty-shilling piece. About ten per cent lighter than the final sovereigns, the new coin was called the unite, symbolising that James had merged the Scottish and English crowns.

In the 1660s, following the Restoration of Charles II and the mechanisation of the Royal Mint that quickly followed, a new twenty-shilling gold coin was issued. It had no special name at first but the public soon nicknamed it the guinea and this became the accepted term. Coins were at the time valued by their precious metal content, and the price of gold relative to silver rose soon after the guinea's issuance. Thus, it came to trade at 21 shillings or even sixpence more. Popular in commerce, the coin's value was set by the government at 21 shillings in silver in 1717, and was subject to revision downward, though in practice this did not occur. The term sovereign, referring to a coin, fell from use—it does not appear in Samuel Johnson's dictionary, compiled in the 1750s.
This economy was disrupted by the Napoleonic Wars, and gold was hoarded. Among the measures taken to allow trade to continue was the issuance of one-pound banknotes. The public came to like them as more convenient than the odd-value guinea. After the war, Parliament, by the Coinage Act 1816, placed Britain officially on the gold standard, with the pound to be defined as a given quantity of gold. Almost every speaker supported having a coin valued at twenty shillings, rather than continuing to use the guinea. Nevertheless, the Coinage Act did not specify which coins the Mint should strike. A committee of the Privy Council recommended gold coins of ten shillings, twenty shillings, two pounds and five pounds be issued, and this was accepted by George, Prince Regent on 3 August 1816. The twenty-shilling piece was named a sovereign, with the resurrection of the old name possibly promoted by antiquarians with numismatic interests.

William Wellesley Pole, elder brother of the Duke of Wellington, was appointed Master of the Mint (at that time a junior government position) in 1812, with a mandate to reform the Royal Mint. Pole had favoured retaining the guinea, due to the number extant and the amount of labour required to replace them with sovereigns. Formal instruction to the Mint came with an indenture dated February 1817, directing the Royal Mint to strike gold coins weighing 7.988 grams, that is to say, the new sovereign.

The Italian sculptor Benedetto Pistrucci came to London early in 1816. His talent opened the doors of the capital's elite, among them Lady Spencer, who showed Pistrucci a model in wax of Saint George and the Dragon by Nathaniel Marchant and commissioned him to reproduce it in the Greek style as part of her husband's regalia as a Knight of the Garter. Pistrucci had already been thinking of such a work, and he produced the cameo. The model for the saint was an Italian waiter at Brunet's Hotel in Leicester Square, where he had stayed after coming to London.

In 1816, Pole hired Pistrucci to create models for the new coinage. After completing Lady Spencer's commission, by most accounts, Pistrucci suggested to Pole that an appropriate subject for the sovereign would be Saint George. He created a head, in jasper, of King George III, to be used as model for the sovereign and the smaller silver coins. He had prepared a model in wax of Saint George and the Dragon for use on the crown; this was adapted for the sovereign. The Royal Mint's engravers were not able to successfully reproduce Pistrucci's imagery in steel, and the sculptor undertook the engraving of the dies himself.

Pistrucci's design for the reverse of the sovereign features Saint George on horseback. His left hand clutches the rein of the horse's bridle, and he does not wear armour, other than on his lower legs and feet, with his toes bare. Further protection is provided by the helmet, with, on early issues, a streamer or plume of hair floating behind. Also flowing behind the knight is his chlamys, or cloak; it is fastened in front by a fibula. George's right shoulder bears a baltens for suspending the gladius, the sword that he grasps in his right hand. He is otherwise naked—the art critic John Ruskin later considered it odd that the saint should be unclothed going into such a violent encounter. The saint's horse appears to be half attacking, half shrinking from the dragon, which lies wounded by George's spear and in the throes of death.
The original 1817 design had the saintly knight still carrying part of the broken spear. This was changed to a sword when the garter that originally surrounded the design was eliminated in 1821, and George is intended to have broken his spear earlier in the encounter with the dragon. Also removed in 1821 was the plume of hair, or streamer, behind George's helmet; it was restored in 1887,
modified in 1893 and 1902, and eliminated in 2009.

The George and Dragon design is in the Neoclassical style. When Pistrucci created the coin, Neoclassicism was all the rage in London, and he may have been inspired by the Elgin Marbles, which were exhibited from 1807, and which he probably saw soon after his arrival in London. Pistrucci's sovereign was unusual for a British coin of the 19th century in not having a heraldic design, but this was consistent with Pole's desire to make the sovereign look as different from the guinea as possible.

When the sovereign entered circulation in late 1817, it was not initially popular, as the public preferred the convenience of the banknotes the sovereign had been intended to replace. Lack of demand meant that mintages dropped from 2,347,230 in 1818 to 3,574 the following year. Another reasons why few sovereigns were struck in 1819 was in furtherance of a proposal, eventually rejected, by economist David Ricardo to eliminate gold as a coinage metal, though making it available on demand from the Bank of England. Once this plan was abandoned in 1820, the Bank encouraged the circulation of gold sovereigns, but acceptance among the British public was slow. As difficulties over the exchange of wartime banknotes were overcome, the sovereign became more popular, and with low-value banknotes becoming scarcer, in 1826 Parliament prohibited the issuance of notes with a value of less than five pounds in England and Wales. The early sovereigns were heavily exported; in 1819, Robert Peel estimated that of the some £5,000,000 in gold struck in France since the previous year, three-quarters of the gold used had come from the new British coinage, melted down. Many more sovereigns were exported to France in the 1820s as the metal alloyed with the gold contained silver, which could be profitably recovered, with the gold often returned to Britain and struck again into sovereigns. Beginning in 1829, the Mint was able to eliminate the silver, but the drain on sovereigns from before this continued.

George III died in January 1820, succeeded by George, Prince Regent, as George IV. Mint officials decided to continue to use the late king's head on coinage for the remainder of the year.
For King George IV's coinage, Pistrucci modified the George and Dragon reverse, eliminating the surrounding Garter ribbon and motto, with a reeded border substituted. Pistrucci also modified the figure of the saint, placing a sword in his hand in place of the broken lance seen previously, eliminating the streamer from his helmet, and refining the look of the cloak.

The obverse design for George IV's sovereigns featured a "Laureate head" of George IV, based on the bust Pistrucci had prepared for the Coronation medal. The new version was authorised by an Order in Council of 5 May 1821. These were struck every year between 1821 and 1825, but the King was unhappy with the depiction of him and requested a new one be prepared, based on a more flattering bust by Francis Chantrey. Pistrucci refused to copy the work of another artist and was barred from further work on the coinage. Second Engraver (later Chief Engraver) William Wyon was assigned to translate Chantrey's bust into a coin design, and the new sovereign came into use during 1825. It did not bear the George and Dragon design, as the new Master of the Mint, Thomas Wallace, disliked several of the current coinage designs, and had Jean Baptiste Merlen of the Royal Mint prepare new reverse designs. The new reverse for the sovereign featured the Ensigns Armorial, or royal arms of the United Kingdom, crowned, with the lions of England seen in two of the quarters, balanced by that of Scotland and the harp of Ireland. Set on the shield are the arms of Hanover, again crowned, depicting the armorial bearings of Brunswick, Lüneburg and Celle. The George and Dragon design would not again appear on the sovereign until 1871.

William IV's accession in 1830 upon the death of his brother George led to new designs for the sovereign, with the new King's depiction engraved by William Wyon based on a bust by Chantrey. Two slightly different busts were used, with what is usually called the "first bust" used for most 1831 circulating pieces (the first year of production) and some from 1832, with the "second bust" used for the prototype pattern coins that year, as well as for proof coins of 1831, some from 1832 and taking over entirely by 1833. The reverse shows another depiction by Merlen of the Ensigns Armorial, with the date accompanied by the Latin word "Anno", or year. These were struck every year until the year of the King's death, 1837.

The accession of Queen Victoria in 1837 ended the personal union between Britain and Hanover, as under the latter's Salic Law, a woman could not take the Hanoverian throne. Thus, both sides of the sovereign had to be changed. Wyon designed his "Young head" portrait of the Queen, which he engraved, for the obverse, and Merlen engraved the reverse, depicting the royal arms inside a wreath, and likely played some part in designing it. The new coin was approved on 26 February 1838, and with the exception of 1840 and 1867, the "shield back" sovereign was struck at the Royal Mint in London every year from 1838 to 1874. Sovereigns struck at London with the shield design between 1863 and 1874 bear small numbers under the shield, representing which coinage die was used. Records of why the numbers were used are not known to survive, with one widely printed theory that they were used to track die wear.

By 1850, some £94 million in sovereigns and half sovereigns had been struck and circulated widely, well beyond Britain's shores, a dispersion aided by the British government, who saw the sovereign's use as an auxiliary to their imperialist ambitions. Gold is a soft metal, and the hazards of circulation tended to make sovereigns lightweight over time. In 1838, when the legacy of James Smithson was converted into gold in preparation for transmission to the United States, American authorities requested recently-struck sovereigns, likely to maximise the quantity of gold when the sovereigns were melted after arrival in the United States. By the early 1840s, the Bank of England estimated that 20 per cent of the gold coins that came into its hands were lightweight. In part to boost the sovereign's reputation in trade, the Bank undertook a programme of recoinage, melting lightweight gold coins and using the gold for new, full-weight ones. Between 1842 and 1845, the Bank withdrew and had recoined some £14 million in lightweight gold, about one-third of the amount of that metal in circulation. This not only kept the sovereign to standard, it probably removed most of the remaining guineas still in commerce. The unlucky holder of a lightweight gold coin could only turn it in as bullion, would lose at least a penny because of the lightness and often had to pay an equal amount to cover the Bank of England's costs. There was also increased quality control within the Royal Mint; by 1866, every gold and silver coin was weighed individually. The result of these efforts was that the sovereign became, in Sir John Clapham's later phrase, the "chief coin of the world".

The California Gold Rush and other discoveries of the 1840s and 1850s boosted the amount of available gold and also the number of sovereigns struck, with £150 million in sovereigns and half sovereigns coined between 1850 and 1875. The wear problem continued: it was estimated that on average, a sovereign became lightweight after fifteen years in circulation. The Coinage Act 1870 tightened standards at the Royal Mint, requiring sovereigns to be individually tested at the annual Trial of the Pyx rather than in bulk. These standards resulted in a high rejection rate for newly-coined sovereigns, though less than for the half sovereign, which sometimes exceeded 50 per cent. When the Royal Mint was rebuilt in 1882, a deciding factor in the decision to shut down production for renovation rather than move to a new mint elsewhere was the Bank of England's report that there was an abnormally large stock of sovereigns and that no harm would result if they could not be coined at London for a year. Advances in technology allowed sovereigns to be individually weighed by automated machines at the Bank of England by the 1890s and efforts to keep the coin at full weight were aided by an 1889 Act of Parliament which allowed redemption of lightweight gold coin at full face value, with the loss from wear to fall upon the government. The Coinage Act 1889 also authorised the Bank of England to redeem worn gold coins from before Victoria's reign but on 22 November 1890, all gold coins from before her reign were called in by Royal Proclamation and demonetised effective 28 February 1891. Due to an ongoing programme to melt and recoin lightweight pieces, estimates of sovereigns in trade weighing less than the legal minimum had fallen to about 4 per cent by 1900.
The sovereign was seen in fiction: in Dickens's "Oliver Twist", Mrs Bumble is paid for her information with 25 sovereigns. Joseph Conrad, in his novels set in Latin America, refers several times to ship captains keeping sovereigns as a ready store of value. Although many sovereigns were melted down for recoining on reaching a foreign land (as were those for the Smithsonian) it was regarded as a circulating coin in dozens of British colonies and even in nations such as Brazil and Portugal.

In 1871, the Deputy Master of the Mint, Sir Charles Fremantle, restored the Pistrucci George and Dragon design to the sovereign, as part of a drive to beautify the coinage. The return of Saint George was approved by the Queen, and authorised by an Order in Council dated 14 January 1871. The two designs were struck side by side in London from 1871 to 1874, and at the Australian branch mints until 1887, after which the Pistrucci design alone was used. The saint returned to the rarely-struck two- and five-pound pieces in 1887, and was placed on the half-sovereign in 1893. Wyon's "Young head" of Queen Victoria for the sovereign's obverse was struck from 1838 until 1887, when it was replaced by the "Jubilee head" by Sir Joseph Boehm. That obverse was criticised and was replaced in 1893 by the "Old head" by Sir Thomas Brock. Victoria's death in 1901 led to a new obverse for her son and successor, Edward VII by George William de Saulles, which began production in 1902; Edward's death in 1910 necessitated a new obverse for his son, George V by Bertram Mackennal. Pistrucci's George and Dragon design continued on the reverse.

The 1851 discovery of gold in Australia quickly led to calls from the local populace for the establishment of a branch of the Royal Mint in the colonies there. Authorities in Adelaide did not wait for London to act, but set up an assay office, striking what became known as the "Adelaide Pound". In 1853, an Order in Council approved the establishment of the Sydney Mint; the Melbourne Mint would follow in 1872, and the Perth Mint in 1899. The act which regulated currency in New South Wales came into force on 18 July 1855 and stipulated that the gold coins were to be called sovereigns and half-sovereigns. They were also to be the same weight, fineness and value as other sovereigns.
Early issues for Sydney, until 1870, depicted a bust of Victoria similar to those struck in Britain, but with a wreath of banksia, native to Australia, in her hair. The reverse was distinctive as well, with the name of the mint, the word and the denomination on the reverse. These coins were not initially legal tender outside Australia, as there were concerns about the design and about the light colour of the gold used (due to a higher percentage of silver in the alloy) but from 1866 Australian sovereigns were legal tender alongside those struck in London. Beginning in 1870, the designs were those used in London, though with a mint mark "S" or "M" (or, later, "P") denoting their origin. The mints at Melbourne and Sydney were allowed to continue striking the shield design even though it had been abandoned at the London facility, and did so until 1887 due to local popularity. The large issues of the colonial mints meant that by 1900, about 40 per cent of the sovereigns circulating in Britain were from Australia. Dies for the Australian coinage were made at London.
Following the Klondike Gold Rush, the Canadian Government asked for the establishment of a Royal Mint branch in Canada. It was not until 1908 that what is now the Royal Canadian Mint, in Ottawa, opened, and it struck sovereigns with the mint mark "C" from 1908 to 1919, excepting 1912, each year in small numbers. Branch mints at Bombay (1918; mint mark "I") and Pretoria (1923–1932; mint mark "SA") also struck sovereigns. Melbourne and Perth stopped striking sovereigns after 1931, with Sydney having closed in 1926. The 1932 sovereigns struck at Pretoria were the last to be issued intended as currency at their face value.

To address the high demand for gold coins in the Indian market, which does not allow gold coins to be imported, the minting of gold sovereigns in India with mint mark I has resumed since 2013. Indian/Swiss joint venture company MMTC-PAMP mints under licence in its facility close to Delhi with full quality control from the Royal Mint. The coins are legal tender in Great Britain.

In the late 19th century, several Chancellors of the Exchequer had questioned the wisdom of having much of Britain's stock of gold used in coinage. Lord Randolph Churchill proposed relying less on gold coinage and moving to high-value silver coins, and the short-lived double florin or four-shilling piece is a legacy of his views. Churchill's successor, George Goschen, urged the issuance of banknotes to replace the gold coinage, and stated that he would prefer to have £20 million in gold in the Bank of England than 30 million sovereigns in the hands of the public. Fears that widespread forgery of banknotes would shake confidence in the pound put paid to his proposal. In March 1914, John Maynard Keynes noted that the large quantities of gold arriving from South Africa were making the sovereign even more important, "The combination of the demand for sovereigns in India and Egypt with London's situation as the distributing centre of the South African gold is rapidly establishing the sovereign as the predominant gold coin of the world. Possibly it may be destined to hold in the future the same kind of international position as was held for several centuries, in the days of a silver standard, by the Mexican dollar."

As Britain moved towards war in the July Crisis of 1914, many sought to convert Bank of England notes into gold, and the bank's reserves of that metal fell from £27 million on 29 July to £11 million on 1 August. Following the declaration of war against Germany on 4 August, the government circulated one-pound and ten-shilling banknotes in place of the sovereign and half sovereign. Restrictions were placed on sending gold abroad, and the melting-down of coin made an offence. Not all were enthusiastic about the change from gold to paper: J.J. Cullimore Allen, in his 1965 book on sovereigns, recalled meeting his first payroll after the change to banknotes, with the workers dubious about the banknotes and initially asking to be paid in gold. Allen converted five sovereigns from his own pocket into notes, and the workers made no further objection. Conversion into gold was not forbidden, but the Chancellor, David Lloyd George, made it clear that such actions would be unpatriotic and would harm the war effort. Few insisted on payment in gold in the face of such appeals, and by mid-1915, the sovereign was rarely seen in London commerce. The coin was depicted on propaganda posters, which urged support for the war.

Although sovereigns continued to be struck at London until the end of 1917, they were mostly held as part of the nation's gold reserves, or were paid out for war debts to the United States. They were still used as currency in some foreign countries, especially in the Middle East. Sovereigns continued to be struck at the Australian mints, where different economic circumstances prevailed. After the war, the sovereign did not return to commerce in Britain, with the pieces usually worth more as gold than as currency. In 1925, the Chancellor, Winston Churchill, secured the passage of the Gold Standard Act 1925, restoring Britain to that standard, but with gold to be kept in reserve rather than as a means of circulation. The effort failed—Churchill regarded it as the worst mistake of his life—-but some lightweight sovereigns were melted and restruck dated 1925, and were released only later. Many of the Australian pieces struck in the postwar period were to back currency, while the South African sovereigns were mostly for export and to pay workers at the gold mines.

By the time Edward VIII came to the throne in 1936, there was no question of issuing sovereigns for circulation, but pieces were prepared as part of the traditional proof set of coins issued in the Coronation year. With a bust of King Edward by Humphrey Paget and the date 1937, these sovereigns were not authorised by Royal Proclamation prior to the King's abdication in December 1936, and are considered pattern coins. Extremely rare, one sold in 2014 for £516,000, setting a record for a British coin at auction. Sovereigns in proof condition dated 1937 were struck for Edward's brother and successor, George VI, also designed by Paget, the only sovereigns to bear George's effigy. The 1925-dated George V sovereign was restruck in 1949, 1951 and 1952, lowering the value of the original, of which only a few had hitherto been known. These were struck to meet the need for sovereigns, and to maintain the skills of the Royal Mint in striking them.

The sovereign remained popular as a trade coin in the Middle East and elsewhere following the Second World War. The small strikings of 1925-dated sovereigns in the postwar period were not enough to meet the demand, which was met in part by counterfeiters in Europe and the Middle East, who often put full value of gold in the pieces. A counterfeiting prosecution was brought, to which the defence was made that the sovereign was no longer a current coin. The judge directed an acquittal although the sovereign remained legal tender under the Coinage Act 1870.

Sovereigns were struck in 1953, the Coronation year of Elizabeth II, bearing the portrait of the Queen by Mary Gillick, though the gold pieces were only placed in the major museums. A 1953 sovereign sold at auction in 2014 for £384,000. In 1957, the Treasury decided to defend the status of the sovereign both by continuing prosecutions, and by issuing new pieces with the current date. Elizabeth II sovereigns bearing Gillick's portrait were struck as bullion pieces between 1957 and 1959, and from 1962 to 1968. The counterfeiting problem was minimised by the striking of about 45,000,000 sovereigns by 1968, and efforts by Treasury solicitors which resulted in the sovereign's acceptance as legal tender by the highest courts of several European nations. In 1966, the Wilson Government placed restrictions on the holding of gold coins to prevent hoarding against inflation, with collectors required to obtain a licence from the Bank of England. This proved ineffective, as it drove gold dealing underground, and was abandoned in 1970.

The sovereign's role in popular culture continued: in the 1957 novel "From Russia, with Love", Q issues James Bond with a briefcase, the handle of which contains 50 sovereigns. When held at gunpoint on the Orient Express by Red Grant, Bond uses the gold to distract Grant, leading to the villain's undoing. The sovereign survived both decimalisation and the move of the Royal Mint from Tower Hill, London to Llantrisant, Wales. The last of the Gillick sovereigns had been struck in 1968; when production resumed in 1974, it was with a portrait by Arnold Machin. The last coin minted at Tower Hill, in 1975, was a sovereign.

From 1979, the sovereign was issued as a coin for the bullion market, but was also struck by the Royal Mint in proof condition for collectors, and this issuance of proof coins has continued annually. In 1985, the Machin portrait of the Queen was replaced by one by Raphael Maklouf. Striking of bullion sovereigns had been suspended after 1982, and so the Maklouf portrait, struck every year but 1989 until the end of 1997, is seen on the sovereign only in proof condition. In 1989, a commemorative sovereign, the first, was issued for the 500th anniversary of Henry VII's sovereign. The coin, designed by Bernard Sindall, evokes the designs of that earlier piece, showing the Queen enthroned and facing front, as Henry appeared on the old English sovereign. The reverse of the 1489 piece depicts a double Tudor rose fronted by the royal arms; a similar design with updated arms graces the reverse of the 1989 sovereign.

Ian Rank-Broadley designed the fourth bust of the Queen to be used on the sovereign, and this went into use in 1998 and was used until 2015. Bullion sovereigns began to be issued again in 2000, and this has continued. A special reverse design was used in 2002 for the Golden Jubilee, with an adaptation of the royal arms on a shield by Timothy Noad recalling the 19th-century "shield back" sovereigns. The years 2005 and 2012 (the latter, the Queen's Diamond Jubilee) saw interpretations of the George and Dragon design, the first by Noad, the later by Paul Day. In 2009, the reverse was re-engraved using tools from the reign of George III in the hope of better capturing Pistrucci's design. A new portrait of the Queen by Jody Clark was introduced during 2015, and some sovereigns were issued with the new bust. The most recent special designs, in 2016 and 2017, were only for collectors. The 2016 collector's piece, for the Queen's 90th birthday, has a one-year-only portrait of her on the obverse designed by James Butler. The 2017 collector's piece returned to Pistrucci's original design of 1817 for the modern sovereign's 200th birthday, with the Garter belt and motto. A piedfort was also minted, and the bullion sovereign struck at Llantrisant, though retaining the customary design, was given a privy mark with the number 200.

In 2017, a collection of 633 gold sovereigns and 280 half sovereigns was discovered to have been hoarded inside an upright piano which had been donated to a community college in Shropshire, England. The coins, which date from 1847 to 1915, were found by a technician who had been asked to tune the piano, 'stitched into seven cloth packets and a leather drawstring purse' under the piano's keyboard. Despite inquiries being made as to who could have stored the coins, no owner or claimants were found.
Many of the variant designs of the sovereign since 1989 have been intended to appeal to coin collectors, as have the other gold coins based on the sovereign, from the quarter sovereign to the five sovereign piece. To expedite matters, the Royal Mint is authorised to sell gold sovereigns directly to the public, rather than having its output channelled through the Bank of England as was once the case. As a legal tender coin, the sovereign is exempt from capital gains tax for UK residents.

As well as being used as a circulating coin, the sovereign has entered fashion, with some men in the 19th century placing one on their pocket watch chains; wearing one in that fashion came to be seen as a sign of integrity. Others carried their sovereigns in a small purse linked to the watch chain. These customs vanished with the popularisation of the wrist watch. Women also have worn sovereigns, as bangles or ear rings. In the 21st century, the wearing of a sovereign ring has been seen as a sign of chav culture.

Coin auction houses deal in rare sovereigns of earlier date, as do specialist dealers. As well as the 1937 Edward VIII and 1953 Elizabeth II sovereigns, rare dates in the series include the 1819, and the 1863 piece with the number "827" on the obverse in place of William Wyon's initials. The 827 likely is an ingot number, used for some sort of experiment, though research has not conclusively established this. Few 1879 sovereigns were struck at London, and those that remain are often well-worn. Only 24,768 of the Adelaide Pound were struck; surviving specimens are rare and highly prized. The sovereign itself has been the subject of commemoration; in 2005, the Perth Mint issued a gold coin with face value A$25, reproducing the reverse design of the pre-1871 Sydney Mint sovereigns.





</doc>
<doc id="266376" url="https://en.wikipedia.org/wiki?curid=266376" title="Benedetto Pistrucci">
Benedetto Pistrucci

Benedetto Pistrucci (29 May 1783 – 16 September 1855) was an Italian gem-engraver, medallist and coin engraver, probably best known for his Saint George and the Dragon design for the British sovereign coin. Pistrucci was commissioned by the British government to create the large Waterloo Medal, a project which took him thirty years to complete.

Born in Rome in 1783, Pistrucci studied briefly with other artists before striking out on his own at age 15. He became prominent as a cameo carver and was patronised by royalty. In 1815, he moved to Britain, where he would live for most of the rest of his life. His talent brought him to the attention of notables including William Wellesley-Pole, the Master of the Mint. Pole engaged Pistrucci to design new coinage, including the sovereign, which was first issued in 1817 to mixed reactions. Although Pole probably promised Pistrucci the post of Chief Engraver, the position could not be awarded as only a British subject could hold it. This slight became a long-term grievance for Pistrucci.

Talented but temperamental, Pistrucci refused to copy the work of other artists. When in 1823 George IV demanded that an unflattering portrait of him on the coinage be changed with a new likeness to be based on the work of Francis Chantrey, Pistrucci refused and was nearly sacked. The Mint did not dismiss him, lest the money already spent on the Waterloo Medal be wasted. Pistrucci kept his place with the Mint for the rest of his life, eventually completing the Waterloo Medal in 1849, though because of its great size it could not be struck. After Pistrucci's death, the George and Dragon design was restored to the sovereign coin, and is still used today.

Benedetto Pistrucci was born in Rome on 24 May 1783, second child and son of Federico Pistrucci, Senior Judge of the High Criminal Court under the papal government, and Antonia (née Greco). His elder brother Filippo displayed artistic tendencies from a young age, but Benedetto showed mainly a disinclination to study. Federico Pistrucci wanted his sons to follow in his footsteps and sent them to Latin schools. Benedetto began his education in Bologna, where the family had property, but the Pistrucci family was forced to move to Rome in 1794 when Napoleon invaded Italy, and the boys were enrolled in the Roman College.

Napoleon had put a price on Federico Pistrucci's head, as he had prosecuted Bonapartist rebels, so the family fled Rome when the French advanced towards it, stopping in Frosinone, where the boys were again put into an academic school. Filippo satisfied his father with enough academic achievement that he was allowed to take a job with a painter named Mango. Deprived of his brother, Benedetto became despondent and was eventually allowed to work at Mango's. There, he quickly displayed his artistic talent. Mango told Benedetto of his brother Giuseppe Mango, a cameo engraver in Rome. With the Pope and the French having made peace, the family was able to return there, and Benedetto Pistrucci began his training as a cameo carver. He advanced quickly, also taking lessons from Stefano Tofanelli, and soon Giuseppe Mango was selling Pistrucci's carvings as his own. Realising that his works were being sold as counterfeit antiques, Pistrucci began placing a secret mark, the Greek letter "λ" (lambda) on his creations.
Pistrucci's obvious talent made his fellow apprentices envious, and one provoked a fight with him, stabbing him in the abdomen before Pistrucci fended off the attack. Recovering at home, he taught himself to model with wax. Federico Pistrucci decided his son would be better off with a new master, and secured a position for him with Giuseppe Cerbara, but the boy refused, believing that he would have to work in poor conditions. A place with gem-carver Nicolo Morelli was secured, and Pistrucci also attended the "scuola del nudo" art academy at the Campidoglio, where in 1800 he took the first prize for sculpture. Pistrucci felt Morelli was seeking to profit from his ability while giving him little training, and left his position at the age of 15, working from the family home. He was able to pay rent, as from the beginning he had ample commissions for cameos.

Pistrucci's early clients included two of Rome's major art dealers, Ignazio Vescovali and Angelo Bonelli, and Napoleon's three sisters, Elisa, Pauline and Caroline. Pistrucci gained prominence by winning a competition to make a cameo of Elisa (the Grand Duchess of Tuscany), working nearly nonstop for eight days to complete it. The Grand Duchess was so impressed by his work that she gave him studio space at her palace. Pistrucci felt secure enough with this patronage that in 1802, he married Barbara Folchi, daughter of a well-to-do merchant; they had nine children together. He continued working in Rome, turning out portrait cameos and engraved gems, until 1814.
Bonelli returned from a successful trip to Britain in 1814 and proposed that Pistrucci go back with him, arguing that the artist's future was there. Pistrucci was willing, and after making provision for his family left Rome with Bonelli. They first stopped in Perugia so that Pistrucci could say farewell to his brother Filippo, but found him willing to accompany them. By Turin, Filippo Pistrucci had decided that Bonelli was not to be trusted, and so informed his brother. When they reached Paris in December 1814, the brothers refused to accompany Bonelli further, and after making threats, the dealer departed. Filippo soon returned to Italy, but Benedetto Pistrucci found his name and art were known in Paris, and set to work. He was there when Napoleon returned from Elba, beginning the Hundred Days, but worked on, unaffected by the war. He saw Napoleon in a garden, and always having a ball of wax with him, quietly modelled the emperor, the last portrait of him done in Europe. After the Battle of Waterloo in June 1815, Pistrucci began preparations to move on to Britain, but it was not until 31 December that he arrived there.

On arrival at Dover, Pistrucci had difficulty with Customs, possibly caused by Bonelli's malice. Once he was able to, he journeyed to London. He had letters of introduction to several people, and Charles Konig, Keeper of Minerals at the British Museum, proved a loyal friend. Through Konig, Pistrucci met the famous naturalist, Sir Joseph Banks, who commissioned the artist to do a portrait of him. While Banks was sitting for Pistrucci, the connoisseur Richard Payne Knight came by, anxious to show Sir Joseph a cameo fragment he had purchased, and which he dated to Ancient Greece. After Banks praised it highly, Pistrucci, on examining it, identified it as his own work, displaying the secret mark he had placed on it. The incident increased Pistrucci's reputation in London.

Pistrucci was introduced to Lord and Lady Spencer by Banks. Lady Spencer showed Pistrucci a model of Saint George and the Dragon by Nathaniel Marchant and commissioned him to reproduce it in the Greek style as part of her husband's regalia as a Knight of the Garter. Pistrucci had already been thinking of such a work, and he produced the cameo. The model for the saint was an Italian waiter at Brunet's Hotel in Leicester Square, where he had stayed after coming to London.

Sir Joseph commissioned Pistrucci to craft a cameo of King George III. As the King was ill with porphyria, Pistrucci modelled the likeness from Marchant's three-shilling bank token, and cut it in red jasper for a fee of 50 guineas. Banks showed the cameo to William Wellesley-Pole, elder brother of the Duke of Wellington and the Master of the Mint, who was greatly impressed by the quality of what he saw. At this time, the Royal Mint was preparing to issue new gold and silver coins as part of the Great Recoinage of 1816, and in June of that year, Pole decided to hire Pistrucci to make models in stone for the new coinage that could be converted into steel dies by the Mint's engravers.

Pole had Pistrucci create three portraits of the King in different sizes. Only two were used, one for the obverse of the half crown, and the other for the shilling and sixpence. Both were modified by Thomas Wyon of the Mint, who engraved the designs in steel. What was dubbed the "bull head" of the King on the 1816 half crown was disliked by the public, and it was replaced by another in 1817. The criticism incensed Pistrucci, who blamed Wyon for bungling the design, and who set about learning to engrave in steel himself.

After completing Lady Spencer's commission, by most accounts, Pistrucci suggested to Pole that an appropriate subject for the sovereign, a new gold coin equal to one pound that was to be struck, would be Saint George. Until the early 20th century, gold coins were struck for circulation, rather than as bullion pieces. Kevin Clancy, in his volume on the history of the sovereign coin, doubted whether the Spencer commission was truly the inspiration for the George and Dragon design which that coin has long featured, and that the idea might not even have come from Pistrucci. Clancy argued that such motifs were common at the time and that the story originated with Pistrucci, whom he deemed an unreliable witness on his own past.

For a fee of 100 guineas (£105), Pistrucci created the sovereign's design, engraving it himself. He depicted the saint atop a fiery steed which is trampling the wounded dragon. George has a broken spear in his hand; part is in the dragon and the remainder on the ground. Pistrucci's original design, used for circulation in 1817–1819 and reprised by the Royal Mint in 2017, has the ribbon of the Order of the Garter surrounding the George and dragon design, with its motto . The design, with Saint George bearing a sword rather than a spear, is ordinarily seen on the sovereign, and was also used for the crown from 1818. Clancy noted of the design process for the crown, "what emerges is the presence of Pole at each turn. He bombarded the young artist with suggestions and instructions on how the design should be changed from the shape of the sword to the perceived ferocity of the dragon." Pistrucci had placed his full last name on both sides of the crown, for which he was criticised by the public, and some said the saint would surely fall off his horse with the next blow.

After the death in 1817 of Thomas Wyon Sr, the father of the man who had adapted Pistrucci's designs, Pole most probably offered Pistrucci the post of chief engraver at the Royal Mint, with a salary of £500 per annum. and a house within the grounds of the Mint. However, it soon appeared that a law passed under William III barred foreigners from the post, and so Pole left it vacant, while granting Pistrucci the salary and emoluments of the office. Sir John Craig wrote in his history of the Royal Mint: "The arrangement was not put into writing, and misunderstanding was easy for a foreigner. Pole categorically denied any commitment beyond the grant for the time being of a salary for coinage designs as cheaper than payment of fees. The Italian persistently contended that he was seduced into Mint service by a promise of formal appointment to the chief engravership". According to H.W.A. Linecar in his book on British coin designs and designers, "the arrangement might have worked very well, even though it was against accepted procedure, had Pistrucci been other than he was."

In 1819, Pistrucci was awarded the commission to design the Waterloo Medal, a huge piece some in diameter that the government planned to award to the victorious generals and national leaders who had defeated Napoleon. Such a medal had been proposed by the Prince Regent (later George IV) soon after the battle. Pistrucci's price was £2,400, and the down payment allowed him to bring his family from Italy. The medal was originally supposed to be to a design by John Flaxman, but Pistrucci refused to engrave the work of another artist, and Pole allowed him to design his own medal, a decision that antagonised London's art establishment against Pistrucci. A gigantic undertaking, the medal would take Pistrucci 30 years to complete.

After the death of George III in 1820, Pistrucci prepared the coinage bust of the new King, George IV. The King despised Pistrucci's work for its bloated expression—according to Clancy, "its full features implying something of the appetites of the monarch". The King and Pistrucci also came into conflict over the Coronation medal, with the King objecting to being placed on the same level as the allegorical representations of his kingdoms. Pistrucci stated, "I shall elevate His Majesty", and did so. The King's toupee also caused difficulty in the engraving process. On the coinage, the sovereign was modified to remove its garter, and the saint's broken spear was replaced by a sword. Thus, it became very similar to the design used on modern-day sovereigns but for the lack of a streamer on Saint George's helmet. This version of the reverse was struck from 1821 to 1825, but Pistrucci's design would be thereafter absent from the sovereign from 1825 to 1874, after his death.

Aware of King George's dissatisfaction at the coinage effigy, the Mint played for time. Pole's resignation in 1823 deprived Pistrucci of a friend and supporter at the Mint. Sculptor Francis Chantrey had prepared a bust of the King which the monarch liked, and ordered that it be placed on the coinage. Pistrucci would not copy the work of another artist, and refused. The new coinage of 1823–1825 was engraved by Pistrucci's assistant, Jean-Baptiste Merlen, and by William Wyon; Pistrucci was thereafter excluded from work on the coinage. The Mint considered sacking Pistrucci, but realised that if it did, the £1,700 advanced for fees and expenses on the Waterloo medal would probably be wasted, and he kept his position and pay on condition he focused on the completion of the medal. Despite this, by 1826, only a portion of one side had been completed. Though the banishment of the George and Dragon design from the sovereign after 1825 was more part of a general redesign of the coinage than an attack upon Pistrucci, according to Clancy he "cannot have masked the sense he must have felt of tides turning against him".

There was conflict at the Mint between Pistrucci and William Wyon, that sometimes involved Merlen. According to Graham Pollard in the "Oxford Dictionary of National Biography", "Pistrucci's temperament did not foster good relations with his colleagues at the mint; the insecurity of his position there was deepened by a spasmodic but bitter campaign conducted through the newspapers by his partisans and those of William Wyon." Pistrucci appealed to each new Master of the Mint for appointment to the post of chief engraver. In 1828, the incumbent Master, George Tierney, worked a compromise that satisfied no one. Wyon was appointed as chief engraver, and Pistrucci as chief medallist, with the salaries of the top two engraving positions divided between them. Of Pistrucci's salary of £350, £50 was conditional on his training an apprentice. Pistrucci in succession named two of his sons, but the allowance was stopped after 1830 as it had come to light that each resided abroad, and one was not a British subject and so was ineligible for regular Mint employment. Pistrucci's understanding of the arrangement was that he would create such medals as might be ordered by government departments, with each medal a separate fee in addition to the annual salary.

This effectively left Pistrucci with little to do at the Mint. He created several medallic works, for example a small memorial medal for the King's brother, Frederick, Duke of York in 1827 that was popular, in royal circles, mounted in rings. He was asked to design the Coronation medal after King William IV came to the throne on George's death in 1830, but declined as he was asked to copy a bust by Chantrey, and the King refused to sit for him. He created, in 1830–1831, the Army Long Service and Good Conduct Medal, the first non-campaign medal of the British Army. He took twelve months to do so, a period of time Craig found unduly long. He continued to cut cameos, and to work, slowly, on the Waterloo Medal. Pistrucci's biographer, Michael A. March, tied his disinclination to work on the Waterloo Medal to his unhappiness about his position at the Mint, and he may have concluded that he would be sacked if he finished the medal. In 1836, the new Master, Henry Labouchere, stated that he felt the medal could be finished in 18 months, and offered Pistrucci payment if he would take on four apprentices and finish it. Pistrucci declined.

Pistrucci enjoyed a friendly relationship with Princess Victoria of Kent, the niece and heiress presumptive of King William, and cut several cameos of her. After she succeeded to the throne as Queen Victoria in 1837, Pistrucci was selected to sculpt her Coronation medal, which he did; the Queen granted him several sittings. Although the Queen was pleased, there were mixed reviews. When questions were asked in the House of Commons, Labouchere stated that Pistrucci may have been ill. Joseph Hume opined that the reverse was no better done than the cheap medals sold in the streets for a penny each. In 1838, Pistrucci made the silver seal of the Duchy of Lancaster, using a new process by which the punch or die could be cast in metal directly from the original wax or clay mould, rather than having to be copied by hand engraving. The following year, Pistrucci left for Rome to take up a position as chief engraver at the papal mint, but returned to London a few months later, deeming the salary too low.

By the early 1840s, the Audit Office was questioning the amount spent on Pistrucci. In 1844, the Master of the Mint, William Gladstone restored Pistrucci's salary to the full £350 and offered him £400 to complete the Waterloo Medal. Pistrucci moved his residence from the Mint on Tower Hill to Fine Arts Cottage, Old Windsor, and set to work in full earnest. He was slowed by injuries from a fall, and it was not until the beginning of 1849 that he submitted the matrices of the medal, and was paid the remaining balance of £1,500. The matrices were so large no one at the Royal Mint was willing to take the risk of hardening them and possibly ruining three decades' work. So only soft impressions were taken, with no medals in gold, silver and bronze as intended, though replicas have since been minted from other dies. Even if the government had struck the medals, there was almost no one to present them to, for of the intended recipients, all were dead but the Duke of Wellington.

The conflict between Pistrucci and William Wyon continued into the late 1840s, and sometimes featured in the press, contributing to the feeling that all was not well at the Mint. A Royal Commission on reform of the Royal Mint was appointed in 1848. Pistrucci submitted a report, in which he settled some old scores. The reforms abolished the positions of chief engraver (Wyon died in 1851) and chief medallist, with Pistrucci appointed a modeller and engraver to the Mint, to receive a salary in addition to payment for any work done.

Pistrucci in 1850 moved from Old Windsor to Flora Lodge, Englefield Green, near Windsor, where he lived with his daughters Maria Elisa and Elena, both gem engravers. He continued to accept private commissions for cameos and medals. Pistrucci died there of "inflammation of the lungs", on 16 September 1855, and is buried at Christ Church, Virginia Water, Surrey.

Pistrucci is probably remembered most for his George and Dragon design for the sovereign. Not greatly liked at the time of its origin, it has come to be celebrated. The Deputy Master of the Mint who restored the design to the sovereign in 1871, Charles Fremantle, stated his view that "it is hardly possible to over-rate the advantages accruing to a coinage from an artistic and well-executed design". By 1893, it was on all of Britain's gold coins; "The Art Journal" described Pistrucci's design as having "triumphantly borne the test of time". Marsh noted, "it is indeed a tribute that his wonderful design should still adorn the gold coinage of our current Queen Elizabeth II. It is one of the finest ever in our coinage history, and has certainly stood the test of time. Long may it continue." Pistrucci's design has also appeared on a non-circulating £20 silver coin in 2013 and on the crown in 1818–1823, 1887–1900, 1902 and 1951.

Roderick Farey, in his biographical articles on Pistrucci, described him as "an Italian with a fiery disposition, he had numerous arguments with the authorities but no-one could doubt his genius firstly as a cameo cutter and later as an engraver and medallist." Those disputes, and a perceived slowness to complete his works (especially the Waterloo Medal) have been sources of the criticism by later writers. Howard Linecar, in his book on British coin designs and designers, wrote, "there is little doubt that Pistrucci held the cutting of these dies as a bargaining counter in his relentless efforts to obtain the post of Chief Engraver at the Royal Mint ... On balance it is perhaps fair to say that Pistrucci, having probably been promised that which he could not have ... squeezed the last drop of blood out of the situation." According to Clancy, "With great talent can often come controversy and throughout his career Pistrucci was acclaimed and reviled in equal measure, maintaining a series of tense relationships with his colleagues, the most pointed of which [was] with his fellow engraver William Wyon." Craig concluded, "Apart from the George and Dragon design, which was less esteemed then than now ... this artist's Mint works, unlike his private commissions, were failures".

The Waterloo Medal is regarded by many as a masterpiece on a par with his St George and the Dragon. Pollard stated that the Waterloo Medal, "shows Pistrucci's command of the types (or figures) of cameos, an understanding of the figurative language of the Roman Renaissance, and an appreciation of the antique sculptured relief—his types, none the less, were always original". Marsh also praised the medal:, "no better piece of intaglio engraving or design has surely ever been seen before or since. It contains as much as thirty ordinary-sized medals, and this alone is more than most medalists achieved in a life time."

Farey concluded his study of Pistrucci,





</doc>
<doc id="266477" url="https://en.wikipedia.org/wiki?curid=266477" title="Niandra LaDes and Usually Just a T-Shirt">
Niandra LaDes and Usually Just a T-Shirt

Niandra LaDes and Usually Just a T-Shirt is the debut solo album by John Frusciante, released on November 22, 1994, on American Recordings. Frusciante released the album after encouragement from several friends, who told him that there was "no good music around anymore."

"Niandra LaDes and Usually Just a T-Shirt" combines avant-garde and stream-of-consciousness styles, with guitar, piano and various effects on a four-track recorder. The album's first half, "Niandra LaDes", was recorded before Frusciante left the Red Hot Chili Peppers in 1992, during the recording of "Blood Sugar Sex Magik". The second half, "Usually Just a T-Shirt", was recorded while the band was on tour in the months leading up to Frusciante's departure. "Niandra LaDes and Usually Just a T-Shirt" sold poorly upon its release in 1994, and was taken off the market, only to be re-released in 1999.

The first-ever vinyl edition of the record was released on November 22, 2017 through Superior Viaduct, offering both a standard black vinyl edition and a deluxe translucent red vinyl edition with 7" b-side strictly limited to 1,000 copies.

Frusciante joined the Red Hot Chili Peppers in 1988, at the age of 18, and released his first album with the group, "Mother's Milk", the following year. The follow-up album, "Blood Sugar Sex Magik", was recorded in an empty mansion that the band decided to live in for the duration of recording. Frusciante adapted well to the environment, and often spent his time alone painting, listening to music, and recording songs that would eventually make up the first half of the album, "Niandra LaDes". "Blood Sugar Sex Magik" was released on September 24, 1991 and was an instant success. The album peaked at number three in the U.S. and went on to sell over 12 million copies worldwide. Soon after the album's release, Frusciante developed a dislike of the band's newfound popularity. He felt that the band was too famous, and wished they were still playing small nightclubs like they were before he joined the group. By his own admission, the band's rise to popularity took Frusciante by surprise, and he could not cope with it. During "Blood Sugar Sex Magik's" promotional tour, Frusciante began using heroin and cocaine heavily. He and vocalist Anthony Kiedis often argued before and after performances. According to Kiedis, Frusciante purposely sabotaged the "Saturday Night Live" performance of "Under the Bridge" by playing the wrong intro for the song and out of key. His relationship with the band had become progressively more strained, and he abruptly quit during the Japanese leg of their world tour in 1992.

After leaving the Red Hot Chili Peppers, Frusciante continued to write and record solo material. He had been doing so since the age of nine, but had never considered releasing his material to the public. That was until several of his friends—including Johnny Depp, Perry Farrell, Gibby Haynes and former Red Hot Chili Peppers band mate Flea—encouraged him to release the material he wrote in his spare time during the "Blood Sugar Sex Magik" sessions. Frusciante began working on final cuts of the songs he had been writing, and producing them at his home in mid-1992. The production process, however, became hampered by his increasingly severe addiction to heroin. "Usually Just a T-Shirt" was recorded in the order it appears, with the final tracks being recorded shortly prior to Frusciante's departure from the Chili Peppers. Frusciante's use of heroin and cocaine became more extreme during the final stages of recording in late 1993; he began viewing drugs as the only way to "make sure you stay in touch with beauty instead of letting the ugliness of the world corrupt your soul."
During a 1994 interview, a visibly intoxicated Frusciante noted that he wrote the album in order to create "interesting music", which he felt no longer existed. He felt contemporary artists were not writing material he deemed worth listening to and the mainstream population were settling for mediocrity. Drugs were another significant topic on which Frusciante based "Niandra LaDes and Usually Just a T-Shirt". According to Frusciante, he "was stoned for every single note [he] played on the album." He increased his drug use to cope with worsening depression that was caused by leaving the Red Hot Chili Peppers, and his subsequent isolation. Several songs on the album deal with his dislike for the Chili Peppers' success, such as the album's eleventh track, "Blood on My Neck From Success".

All of the music on the record was written by Frusciante, save for the cover of hardcore punk band Bad Brains' song "Big Takeover". The track was intentionally slowed down and recorded melodically because of a pastime in which Frusciante sang punk songs in different tempos: "It was just something I had been walking around thinking of in my head. Sometimes I'll walk around singing punk rock songs to myself, but as if they were regular songs instead of punk rock songs, you know, slow it down and make a melody instead of just yelling them out. And then the idea occurred me to record it like a Led Zeppelin ballad with mandolins and stuff." River Phoenix, a friend of Frusciante's, had contributed guitar and backing vocals to two songs that were intended be included on the record, but they were ultimately left off due to protests from his family. These were later included under different names on the album "Smile from the Streets You Hold" in 1997.

"Niandra LaDes and Usually Just a T-Shirt" incorporated Frusciante's avant-garde style of song composition, with his stream-of-consciousness methodology. He recorded, mixed, produced and mastered the entire record by himself, and released it on Rick Rubin's label, American Recordings. Warner Bros., the Chili Peppers' label, originally held the rights to the album because of the leaving-artist clause in Frusciante's Chili Peppers contract. Because he was living as a recluse, however, the label gladly handed the rights over to Rubin, who released the album under his label.

"Niandra LaDes and Usually Just a T-Shirt" was initially previewed by "Billboard" magazine, who said that "Chili Peppers fans might be daunted by the album's elusive experimentalism." A representative of American Recordings did not foresee the album as being viable in any mainstream music stores, and some retailers went as far as to ban it from being sold. After the album was released, Frusciante played three small performances, and participated in a few magazine interviews to promote the album, explaining in one interview that people would only be able to understand his work if "their heads are capable of tripping out." At one point shortly after release, Frusciante began searching for a string quartet to play the album with him on tour. The idea was eventually discarded when he could not find a band that "understands why Ringo Starr is such a great drummer, can play Stravinsky, and also smokes pot." The concept of a tour was ultimately abandoned as well, due to Frusciante's diminishing health.

"Niandra LaDes and Usually Just a T-Shirt" was not widely reviewed, but yielded a generally positive response from critics. Steve Huey of AllMusic, who rated the album four out of five stars, said that "[the album was] an intriguing and unexpected departure from Frusciante's work with the Chili Peppers", and that "the sparse arrangements of the first half help set the stage for the gossamer guitar work later on." He went on to say that "Usually Just a T-Shirt"—the latter half of the album—contained "pleasant psychedelic instrumentals with plenty of backward-guitar effects." Ned Raggett, also of AllMusic, noted that "there's nothing quite so stunning as [Frusciante's] magnificent remake of Bad Brains' 'The Big Takeover'." Adam Williams of PopMatters said the album "fall[s] somewhere between madness and brilliance". He went on to compare Frusciante to Syd Barrett, and felt it was a "hint at a deeply cerebral artist looking within for inspiration and creativity." "High Times"<nowiki>'</nowiki> Tim Kenneally saw the record as "a revelation, both disturbingly intimate and cryptically veiled. Ladeled straight out of the guitarist's stream of consciousness, it's worlds away from the up-front, balls-out funk assault of his former band," with "an ethereal, otherworldly quality." The album received its share of negative criticism as well. "Rolling Stone's" Christian Hoard felt "Frusciante's eccentricities run seriously amok", and that " [the album] sounds like a string of four-track demos. The first part of the album is slightly more tuneful than the more ambient, experimental second section[...] Mostly what you get are Frusciante's acoustic-guitar scratchings and stream-of-conscious ramblings." The first "Rolling Stone" review of the record, however, was positive: "All in all, [the album is] a mess—but definitely a fascinating, often lovely mess. As one might expect of an album titled "Niandra Lades and Usually Just a T-shirt" this is twisted, cool stuff." The "Boston Herald" said that while the album was "a stark display of Frusciante's acoustic guitar virtuosity" and "eerily beautiful", the singing was "terrible; his high notes will drive the neighborhood dogs into a frenzy."

Frusciante's drug addiction worsened as the years progressed. An article published by the "New Times LA" described him as "a skeleton covered in thin skin". He participated in an interview with Dutch public broadcast station VPRO—the first media appearance he made since leaving the Chili Peppers. In the interview Frusciante speaks of the positive effects drugs have had on his mind and proudly admits to being a "junkie". He went on to confess addictions to heroin and crack cocaine, but ultimately described himself as being in the best health of his life. In 1997, Frusciante released his second solo album "Smile From the Streets You Hold", primarily for drug money. "Niandra LaDes and Usually Just a T-Shirt" was estimated to have sold only 45,000 copies when Frusciante ordered it out of print in 1998—when Frusciante rehabilitated and rejoined the Chili Peppers. "Smile From the Streets You Hold" was withdrawn from the market a year later. In 1999 "Niandra LaDes and Usually Just a T-Shirt" was re-released on American Recordings. In the early 2000s, Frusciante said he planned to re-release "Smile From the Streets You Hold" sometime in the future, but did not give any indication as to when. It was eventually re-released on American Records in Europe of 2006.

All songs written by John Frusciante, except where noted.






</doc>
<doc id="267366" url="https://en.wikipedia.org/wiki?curid=267366" title="Mauna Kea">
Mauna Kea

Mauna Kea ( or , ) is a dormant volcano on the island of Hawaii. Its peak is above sea level, making it the highest point in the state of Hawaii. Most of the mountain is under water, and when measured from its oceanic base, Mauna Kea is the tallest mountain in the world measuring over . Mauna Kea is about a million years old, and has thus passed the most active shield stage of life hundreds of thousands of years ago. In its current post-shield state, its lava is more viscous, resulting in a steeper profile. Late volcanism has also given it a much rougher appearance than its neighboring volcanoes due to construction of cinder cones, decentralization of its rift zones, glaciation on its peak, and weathering by the prevailing trade winds. Mauna Kea last erupted 6,000 to 4,000 years ago and is now considered dormant. The peak is about higher than Mauna Loa, its more massive neighbor.

In Hawaiian mythology, the peaks of the island of Hawaii are sacred. An ancient law allowed only high-ranking aliʻi to visit its peak. Ancient Hawaiians living on the slopes of Mauna Kea relied on its extensive forests for food, and quarried the dense volcano-glacial basalts on its flanks for tool production. When Europeans arrived in the late 18th century, settlers introduced cattle, sheep and game animals, many of which became feral and began to damage the mountain's ecological balance. Mauna Kea can be ecologically divided into three sections: an alpine climate at its summit, a "Sophora chrysophylla"–"Myoporum sandwicense" (or māmane–naio) forest on its flanks, and an "Acacia koa"–"Metrosideros polymorpha" (or koa–ōhia) forest, now mostly cleared by the former sugar industry, at its base. In recent years, concern over the vulnerability of the native species has led to court cases that have forced the Hawai'i Department of Land and Natural Resources to eradicate all feral species on the mountain.

With its high elevation, dry environment, and stable airflow, Mauna Kea's summit is one of the best sites in the world for astronomical observation. Since the creation of an access road in 1964, thirteen telescopes funded by eleven countries have been constructed at the summit. The Mauna Kea Observatories are used for scientific research across the electromagnetic spectrum and comprise the largest such facility in the world. Their construction on a landscape considered sacred by Native Hawaiians continues to be a topic of debate.

Mauna Kea is one of five volcanoes that form the island of Hawaii, the largest and youngest island of the Hawaiian–Emperor seamount chain. Of these five hotspot volcanoes, Mauna Kea is the fourth oldest and fourth most active. It began as a preshield volcano driven by the Hawaii hotspot around one million years ago, and became exceptionally active during its shield stage until 500,000 years ago. Mauna Kea entered its quieter post-shield stage 250,000 to 200,000 years ago, and is currently dormant. Mauna Kea does not have a visible summit caldera, but contains a number of small cinder and pumice cones near its summit. A former summit caldera may have been filled and buried by later summit eruption deposits.

Mauna Kea is over in volume, so massive that it and its neighbor, Mauna Loa, depress the ocean crust beneath it by .
The volcano continues to slip and flatten under its own weight at a rate of less than per year. Much of its mass lies east of its present summit. Mauna Kea stands above sea level, about higher than its neighbor Mauna Loa, and is the highest point in the state of Hawaii. Measured from its base on the ocean floor, it rises over , significantly greater than the elevation of Mount Everest above sea level.

Like all Hawaiian volcanoes, Mauna Kea has been created as the Pacific tectonic plate has moved over the Hawaiian hotspot in the Earth's underlying mantle. The Hawaii island volcanoes are the most recent evidence of this process that, over 70 million years, has created the -long Hawaiian Ridge–Emperor seamount chain. The prevailing, though not completely settled, view is that the hotspot has been largely stationary within the planet's mantle for much, if not all of the Cenozoic Era. However, while Hawaiian volcanism is well understood and extensively studied, there remains no definite explanation of the mechanism that causes the hotspot effect.

Lava flows from Mauna Kea overlapped in complex layers with those of its neighbors during its growth. Most prominently, Mauna Kea is built upon older flows from Kohala to the northwest, and intersects the base of Mauna Loa to the south. The original eruptive fissures (rift zones) in the flanks of Mauna Kea were buried by its post-shield volcanism. Hilo Ridge, a prominent underwater rift zone structure east of Mauna Kea, was once believed to be a part of the volcano; however, it is now understood to be a rift zone of Kohala that has been affected by younger Mauna Kea flows.

The shield-stage lavas that built the enormous main mass of the mountain are tholeiitic basalts, like those of Mauna Loa, created through the mixing of primary magma and subducted oceanic crust. They are covered by the oldest exposed rock strata on Mauna Kea, the post-shield alkali basalts of the "Hāmākua Volcanics", which erupted between 250,000 and 70–65,000 years ago. The most recent volcanic flows are hawaiites and mugearites: they are the post-shield "Laupāhoehoe Volcanics", erupted between 65,000 and 4,000 years ago. These changes in lava composition accompanied the slow reduction of the supply of magma to the summit, which led to weaker eruptions that then gave way to isolated episodes associated with volcanic dormancy. The Laupāhoehoe lavas are more viscous and contain more volatiles than the earlier tholeiitic basalts; their thicker flows significantly steepened Mauna Kea's flanks. In addition, explosive eruptions have built cinder cones near the summit. These cones are the most recent eruptive centers of Mauna Kea. Its present summit is dominated by lava domes and cinder cones up to in diameter and hundreds of meters tall.

Mauna Kea is the only Hawaiian volcano with distinct evidence of glaciation. Similar deposits probably existed on Mauna Loa, but have been covered by later lava flows. Despite Hawaii's tropical location, during several past ice ages a drop of a degree in temperature allowed snow to remain at the mountain's summit through summer, triggering the formation of an ice cap. There are three episodes of glaciation that have been recorded from the last 180,000 years: the "Pōhakuloa" (180–130 ka), "Wāihu" (80–60 ka) and "Mākanaka" (40–13 ka) series. These have extensively sculpted the summit, depositing moraines and a circular ring of till and gravel along the mountain's upper flanks. Subglacial eruptions built cinder cones during the Mākanaka glaciation, most of which were heavily gouged by glacial action. The most recent cones were built between 9000 and 4500 years ago, atop the glacial deposits, although one study indicates that the last eruption may have been around 3600 years ago.

At their maximum extent, the glaciers extended from the summit down to between of elevation. A small body of permafrost, less than across, was found at the summit of Mauna Kea before 1974, and may still be present. Small gullies etch the summit, formed by rain- and snow-fed streams that flow only during winter melt and rain showers.
On the windward side of the mountain, stream erosion driven by trade winds has accelerated erosion in a manner similar to that on older Kohala.

Mauna Kea is home to Lake Waiau, the highest lake in the Pacific Basin. At an altitude of , it lies within the Puu Waiau cinder cone and is the only alpine lake in Hawaii. The lake is very small and shallow, with a surface area of and a depth of . Radiocarbon dating of samples at the base of the lake indicates that it was clear of ice 12,600 years ago. Hawaiian lava types are typically permeable, preventing lake formation due to infiltration. Either sulfur-bearing steam altered the volcanic ash to low-permeability clays, or explosive interactions between rising magma and groundwater or surface water during phreatic eruptions formed exceptionally fine ash that reduced the permeability of the lake bed.

No artesian water was known on the island of Hawaii until 1993 when drilling by the University of Hawaii tapped an artesian aquifer more than below sea level, that extended more than of the borehole's total depth. The borehole had drilled through a compacted layer of soil and lava where the flows of Mauna Loa had encroached upon the exposed Mauna Kea surface and had subsequently been subsided below sea level. Isotopic composition shows the water present to have been derived from rain coming off Mauna Kea at higher than above mean sea level. The aquifer's presence is attributed to a freshwater head within Mauna Kea's basal lens. Scientists believe there may be more water in Mauna Kea's freshwater lens than current models may indicate. Two more boreholes were drilled on Mauna Kea in 2012, with water being found at much higher elevations and shallower depths than expected. Donald Thomas, director of the University of Hawaii's Center for the Study of Active Volcanoes believes one reason to continue study of the aquifers is due to use and occupancy of the higher elevation areas, stating: "Nearly all of these activities depend on the availability of potable water that, in most cases, must be trucked to the Saddle from Waimea or Hilo — an inefficient and expensive process that consumes a substantial quantity of our scarce liquid fuels."

The last eruption of Mauna Kea was about 4,600 years ago (about 2600 BC); because of this inactivity, Mauna Kea is assigned a United States Geological Survey hazard listing of 7 for its summit and 8 for its lower flanks, out of the lowest possible hazard rating of 9 (which is given to the extinct volcano Kohala). Since 8000 BC lava flows have covered 20% of the volcano's summit and virtually none of its flanks.

Despite its dormancy, Mauna Kea is expected to erupt again, although there would be enough warning to evacuate. The telescopes on Mauna Kea's summit would be the first to detect the minute amounts of deformation resulting from the volcano's swelling, acting like expensive tiltmeters. Based on earlier eruptions, such an event could occur anywhere on the volcano's upper flanks and would likely produce long lava flows, mostly of a'a, long. Long periods of activity could build a cinder cone at the source. Although not likely in the next few centuries, such an eruption would probably result in little loss of life but significant damage to infrastructure.

The first Ancient Hawaiians to arrive on Hawaii island lived along the shores, where food and water were plentiful. Settlement expanded inland to the Mauna Loa – Mauna Kea region in the 12th and early 13th centuries. Archaeological evidence suggests that these regions were used for hunting, collecting stone material, and possibly for spiritual reasons or for astronomical or navigational observations. The mountain's plentiful forest provided plants and animals for food and raw materials for shelter. Flightless birds that had previously known no predators became a staple food source.

Early settlement of the Hawaiian islands led to major changes to local ecosystems and many extinctions, particularly amongst bird species. Ancient Hawaiians brought foreign plants and animals, and their arrival was associated with increased rates of erosion.
The prevailing lowland forest ecosystem was transformed from forest to grassland; some of this change was caused by the use of fire, but the prevailing cause of forest ecosystem collapse and avian extinction on Hawaii appears to have been the introduction of the Polynesian (or Pacific) rat.

The five volcanoes of Hawaii are revered as sacred mountains; and Mauna Kea's summit, the highest, is the most sacred. For this reason, a "kapu" (ancient Hawaiian law) restricted visitor rights to high-ranking aliʻi. Hawaiians associated elements of their natural environment with particular deities. In Hawaiian mythology, the summit of Mauna Kea was seen as the "region of the gods", a place where benevolent spirits reside. Poliahu, deity of snow, also resides there. In Hawaiian, Mauna Kea is a shortened form of "Mauna a Wakea" which denotes the mountain's connection to the sky father Wakea; however, the English translation of Mauna Kea is "white mountain" in reference to its seasonally snow-capped summit.

Around AD 1100, natives established adze quarries high up on Mauna Kea to extract the uniquely dense basalt (generated by the quick cooling of lava flows meeting glacial ice during subglacial eruptions) to make tools. Volcanic glass and gabbro were collected for blades and fishing gear, and māmane wood was preferred for the handles. At peak quarry activity after AD 1400, there were separate facilities for rough and fine cutting; shelters with food, water, and wood to sustain the workers; and workshops creating the finished product.

Lake Waiau provided drinking water for the workers. Native chiefs would also dip the umbilical cords of newborn babies in its water, to give them the strength of the mountain. Use of the quarry declined between this period and contact with Americans and Europeans. As part of the ritual associated with quarrying, the workers erected shrines to their gods; these and other quarry artifacts remain at the sites, most of which lie within what is now the Mauna Kea Ice Age Reserve.

This early era was followed by peace and cultural expansion between the 12th and late 18th century. Land was divided into regions designed for both the immediate needs of the populace and the long-term welfare of the environment. These "ahupuaa" generally took the form of long strips of land oriented from the mountain summits to the coast. Mauna Kea's summit was encompassed in the ahupuaa of Kaohe, with part of its eastern slope reaching into the nearby Humuula. Principal sources of nutrition for Hawaiians living on the slopes of the volcano came from the māmane–naio forest of its upper slopes, which provided them with vegetation and bird life. Bird species hunted included the uau ("Pterodroma sandwichensis"), nēnē ("Branta sandvicensis"), and palila ("Loxioides bailleui"). The lower koa–ōhia forest gave the natives wood for canoes and ornate bird feathers for decoration.

There are three accounts of foreigners visiting Hawaii before the arrival of James Cook, in 1778. However, the earliest Western depictions of the isle, including Mauna Kea, were created by explorers in the late 18th and early 19th centuries. Contact with Europe and America had major consequences for island residents. Native Hawaiians were devastated by introduced diseases; port cities including Hilo, Kealakekua, and Kailua grew with the establishment of trade; and the adze quarries on Mauna Kea were abandoned after the introduction of metal tools.

In 1793, cattle were brought by George Vancouver as a tribute to King Kamehameha I. By the early 19th century, they had escaped confinement and roamed the island freely, greatly damaging its ecosystem. In 1809 John Palmer Parker arrived and befriended Kamehameha I, who put him in charge of cattle management on the island. With an additional land grant in 1845, Parker established Parker Ranch on the northern slope of Mauna Kea, a large cattle ranch that is still in operation today. Settlers to the island burned and cut down much of the native forest for sugarcane plantations and houses.

The Saddle Road, named for its crossing of the saddle-shaped plateau between Mauna Kea and Mauna Loa, was completed in 1943, and eased travel to Mauna Kea considerably.

The Pohakuloa Training Area on the plateau is the largest military training ground in Hawaii. The base extends from the volcano's lower flanks to elevation, on state land leased to the US Army since 1956. There are 15 threatened and endangered plants, three endangered birds, and one endangered bat species in the area.

Mauna Kea has been the site of extensive archaeological research since the 1980s. Approximately 27 percent of the Science Reserve had been surveyed by 2000, identifying 76 shrines, 4 adze manufacturing workshops, 3 other markers, 1 positively identified burial site, and 4 possible burial sites. By 2009, the total number of identified sites had risen to 223, and archaeological research on the volcano's upper flanks is ongoing. It has been suggested that the shrines, which are arranged around the volcano's summit along what may be an ancient snow line, are markers for the transition to the sacred part of Mauna Kea. Despite many references to burial around Mauna Kea in Hawaiian oral history, few sites have been confirmed. The lack of shrines or other artifacts on the many cinder cones dotting the volcano may be because they were reserved for burial.

In pre-contact times, natives traveling up Mauna Kea were probably guided more by landscape than by existing trails, as no evidence of trails has been found. It is possible that natural ridges and water sources were followed instead. Individuals likely took trips up Mauna Kea's slopes to visit family-maintained shrines near its summit, and traditions related to ascending the mountain exist to this day. However, very few natives reached the summit, because of the strict "kapu" placed on it.

In the early 19th century, the earliest notable "recorded" ascents of Mauna Kea included the following:

In the late 19th and early 20th centuries trails were formed, often by the movement of game herds, that could be traveled on horseback. However, vehicular access to the summit was practically impossible until the construction of a road in 1964, and it continues to be restricted. Today, multiple trails to the summit exist, in various states of use.

Hawaii's geographical isolation strongly influences its ecology. Remote islands like Hawaii have a large number of species that are found nowhere else (see Endemism in the Hawaiian Islands). The remoteness resulted in evolutionary lines distinct from those elsewhere and isolated these endemic species from external biotic influence, and also makes them especially vulnerable to extinction and the effects of invasive species. In addition the ecosystems of Hawaii are under threat from human development including the clearing of land for agriculture; an estimated third of the island's endemic species have already been wiped out. Because of its elevation, Mauna Kea has the greatest diversity of biotic ecosystems anywhere in the Hawaiian archipelago. Ecosystems on the mountain form concentric rings along its slopes due to changes in temperature and precipitation with elevation. These ecosystems can be roughly divided into three sections by elevation: alpine–subalpine, montane, and basal forest.

Contact with Americans and Europeans in the early 19th century brought more settlers to the island, and had a lasting negative ecological effect. On lower slopes, vast tracts of koa–ōhia forest were converted to farmland. Higher up, feral animals that escaped from ranches found refuge in, and damaged extensively, Mauna Kea's native māmane–naio forest. Non-native plants are the other serious threat; there are over 4,600 introduced species on the island, whereas the number of native species is estimated at just 1,000.

The summit of Mauna Kea lies above the tree line, and consists of mostly lava rock and alpine tundra. An area of heavy snowfall, it is inhospitable to vegetation, and is known as the Hawaiian tropical high shrublands. Growth is restricted here by extremely cold temperatures, a short growing season, low rainfall, and snow during winter months. A lack of soil also retards root growth, makes it difficult to absorb nutrients from the ground, and gives the area a very low water retention capacity.

Plant species found at this elevation include "Styphelia tameiameiae", "Taraxacum officinale", "Tetramolopium humile", "Agrostis sandwicensis", "Anthoxanthum odoratum", "Trisetum glomeratum", "Poa annua", "Sonchus oleraceus", and "Coprosma ernodiodes". One notable species is Mauna Kea silversword ("Argyroxiphium sandwicense" var. "sandwicense"), a highly endangered endemic plant species that thrives in Mauna Kea's high elevation cinder deserts. At one stage reduced to a population of just 50 plants, Mauna Kea silversword was thought to be restricted to the alpine zone, but in fact has been driven there by pressure from livestock, and can grow at lower elevations as well.

The Mauna Kea Ice Age Reserve on the southern summit flank of Mauna Kea was established in 1981. The reserve is a region of sparsely vegetated cinder deposits and lava rock, including areas of aeolian desert and Lake Waiau. This ecosystem is a likely haven for the threatened uau ("Pterodroma sandwichensis") and also the center of a study on wēkiu bugs ("Nysius wekiuicola").

Wēkiu bugs feed on dead insect carcasses that drift up Mauna Kea on the wind and settle on snow banks. This is a highly unusual food source for a species in the genus "Nysius", which consists of predominantly seed-eating insects. They can survive at extreme elevations of up to because of natural antifreeze in their blood. They also stay under heated surfaces most of the time. Their conservation status is unclear, but the species is no longer a candidate for the Endangered Species List; studies on the welfare of the species began in 1980. The closely related "Nysius aa" lives on Mauna Loa. Wolf spiders (Lycosidae) and forest tent caterpillar moths have also been observed in the same Mauna Kea ecosystem; the former survive by hiding under heat-absorbing rocks, and the latter through cold-resistant chemicals in their bodies.
The highest forested zone on the volcano, at an elevation of , is dominated by māmane ("Sophora chrysophylla") and naio ("Myoporum sandwicense"), both endemic tree species, and is thus known as māmane–naio forest. Māmane seeds and naio fruit are the chief foods of the birds in this zone, especially the palila ("Loxioides bailleui"). The palila was formerly found on the slopes of Mauna Kea, Mauna Loa, and Hualālai, but is now confined to the slopes of Mauna Kea—only 10% of its former range—and has been declared critically endangered.

The largest threat to the ecosystem is grazing by feral sheep ("Ovis aries"), cattle ("Bos primigenius"), and goats ("Capra hircus") introduced to the island in the late 18th century. Feral animal competition with commercial grazing was severe enough that a program to eradicate them existed as far back as the late 1920s, and continued through to 1949. One of the results of this grazing was the increased prevalence of herbaceous and woody plants, both endemic and introduced, that were resistant to browsing. The feral animals were almost eradicated, and numbered a few hundred in the 1950s. However, an influx of local hunters led to the feral species being valued as game animals, and in 1959 the Hawaii Department of Land and Natural Resources, the governing body in charge of conservation and land use management, changed its policy to a sustained-control program designed to facilitate the sport.

Mouflon ("Ovis aries orientalis") was introduced from 1962–1964, and a plan to release axis deer ("Axis axis") in 1964 was prevented only by protests from the ranching industry, who said that they would damage crops and spread disease. The hunting industry fought back, and the back-and-forth between the ranchers and hunters eventually gave way to a rise in public environmental concern. With the development of astronomical facilities on Mauna Kea commencing, conservationists demanded protection of Mauna Kea's ecosystem. A plan was proposed to fence 25% of the forests for protection, and manage the remaining 75% for game hunting. Despite opposition from conservationists the plan was put into action. While the land was partitioned no money was allocated for the building of the fence. In the midst of this wrangling the Endangered Species Act was passed; the National Audubon Society and Sierra Club Legal Defense Fund filed a lawsuit against the Hawaii Department of Land and Natural Resources, claiming that they were violating federal law, in the landmark case "Palila v. Hawaii Department of Land and Natural Resources" (1978).

The court ruled in favor of conservationists and upheld the precedence of federal laws before state control of wildlife. Having violated the Endangered Species Act, Hawaii state was required to remove all feral animals from the mountainside. This decision was followed by a second court order in 1981. A public hunting program removed many of the feral animals, at least temporarily. An active control program is in place, though it is not conducted with sufficient rigor to allow significant recovery of the māmane-naio ecosystem. There are many other species and ecosystems on the island, and on Mauna Kea, that remain threatened by human development and invasive species.

The Mauna Kea Forest Reserve protects of māmane-naio forest under the jurisdiction of the Hawaii Department of Land and Natural Resources. Ungulate hunting is allowed year-round. A small part of the māmane–naio forest is encompassed by the Mauna Kea State Recreation Area.

A band of ranch land on Mauna Kea's lower slopes was formerly "Acacia koa" – "Metrosideros polymorpha" (koa-ōhia) forest. Its destruction was driven by an influx of European and American settlers in the early 19th century, as extensive logging during the 1830s provided lumber for new homes. Vast swathes of the forest were burned and cleared for sugarcane plantations. Most of the houses on the island were built of koa, and those parts of the forest that survived became a source for firewood to power boilers on the sugarcane plantations and to heat homes. The once vast forest had almost disappeared by 1880, and by 1900, logging interests had shifted to Kona and the island of Maui. With the collapse of the sugar industry in the 1990s, much of this land lies fallow but portions are used for cattle grazing, small-scale farming and the cultivation of eucalyptus for wood pulp.

The Hakalau Forest National Wildlife Refuge is a major koa forest reserve on Mauna Kea's windward slope. It was established in 1985, covering of ecosystem remnant. Eight endangered bird species, twelve endangered plants, and the endangered Hawaiian hoary bat ("Lasiurus cinereus semotus") have been observed in the area, in addition to many other rare biota. The reserve has been the site of an extensive replanting campaign since 1989. Parts of the reserve show the effect of agriculture on the native ecosystem, as much of the land in the upper part of the reserve is abandoned farmland.

Bird species native to the acacia koa–ōhia forest include the Hawaiian crow ("Corvus hawaiiensis"), the akepa ("Loxops coccineus"), Hawaii creeper ("Oreomystis mana"), ʻakiapōlāʻau ("Hemignathus munroi"), and Hawaiian hawk ("Buteo solitarius"), all of which are endangered, threatened, or near threatened; the Hawaiian crow in particular is extinct in the wild, but there are plans to reintroduce the species into the Hakalau reserve.

Mauna Kea's summit is one of the best sites in the world for astronomical observation due to favorable observing conditions. The arid conditions are important for submillimeter and infrared astronomy for this region of the electromagnetic spectrum. The summit is above the inversion layer, keeping most cloud cover below the summit and ensuring the air on the summit is dry, and free of atmospheric pollution. The summit atmosphere is exceptionally stable, lacking turbulence for some of the world's best astronomical seeing. The very dark skies resulting from Mauna Kea's distance from city lights are preserved by legislation that minimizes light pollution from the surrounding area; the darkness level allows the observation of faint astronomical objects. These factors historically made Mauna Kea an excellent spot for stargazing.

In the early 1960s, the Hawaii Island Chamber of Commerce encouraged astronomical development of Mauna Kea, as economic stimulus; this coincided with University of Arizona astronomer Gerard Kuiper's search for sites to use newly improved detectors of infrared light. Site testing by Kuiper's assistant Alika Herring in 1964 confirmed the summit's outstanding suitability. An intense three-way competition for NASA funds to construct a large telescope began between Kuiper, Harvard University, and the University of Hawaii (UH), which only had experience in solar astronomy. This culminated in funds being awarded to the "upstart" UH proposal. UH rebuilt its small astronomy department into a new Institute for Astronomy, and in 1968 the Hawaii Department of Land and Natural Resources gave it a 65-year lease for all land within a radius of its telescope, essentially that above . On its completion in 1970, the UH was the seventh largest optical/infrared telescope in the world.
By 1970, two telescopes had been constructed by the US Air Force and Lowell Observatory. In 1973, Canada and France agreed to build the 3.6 m CFHT on Mauna Kea. However, local organisations started to raise concerns about the environmental impact of the observatory. This led the Department of Land and Natural Resources to prepare an initial management plan, drafted in 1977 and supplemented in 1980. In January 1982, the UH Board of Regents approved a plan to support the continued development of scientific facilities at the site. In 1998, were transferred from the observatory lease to supplement the Mauna Kea Ice Age Reserve. The 1982 plan was replaced in 2000 by an extension designed to serve until 2020: it instituted an Office of Mauna Kea Management, designated for astronomy, and shifted the remaining to "natural and cultural preservation". This plan was further revised to address concern expressed in the Hawaiian community that a lack of respect was being shown toward the cultural values of the mountain.

Today the Mauna Kea Science Reserve has 13 observation facilities, each funded by as many as 11 countries. There are nine telescopes working in the visible and infrared spectrum, three in the submillimeter spectrum, and one in the radio spectrum, with mirrors or dishes ranging from . In comparison, the Hubble Space Telescope has a mirror, similar in size to the UH88, now the second smallest telescope on the mountain.

A "Save Mauna Kea" movement, believes development of the mountain to be sacrilegious. Native Hawaiian non-profit groups such as Kahea, concerned with cultural heritage and the environment also oppose development for cultural and religious reasons. The multi-telescope "outrigger", proposed in 2006 was eventually canceled. A planned new telescope, the Thirty Meter Telescope (TMT), has attracted controversy and protests. The TMT was approved in April 2013. In October 2014, the groundbreaking ceremony for the telescope was interrupted by protesters causing the project to temporarily halt. In late March 2015, demonstrators blocked access of the road to the summit again. On April 2, 2015, 300 protestors were gathered near the visitor's center when 12 people were arrested with 11 more arrested at the summit. Among the concerns of the protest groups are the land appraisals and Native Hawaiians consultation. Construction was halted on April 7, 2015 after protests expanded over the state. After several halts, the project has been voluntarily postponed. Governor Ige announced substantial changes to the management of Mauna Kea in the future but stated the project can move forward. The Supreme Court of Hawaii approved the resumption of construction on 31 October 2018.

The summit of Mauna Kea has an alpine climate. Due to the influence of its tropical latitude, temperature swings are very low in spite of its high elevation. Frosts are common year round, but in spite of the elevation no month is nearly below freezing in terms of average high, although March almost falls below in average means.

From December to February, the ground above is often covered by snow, ranging from a few inches deep to several feet deep. Snow may fall from to and higher in any month, but occurs most often between October and April to early May.

Mauna Kea's coastline is dominated by the Hamakua Coast, an area of rugged terrain created by frequent slumps and landslides on the volcano's flank. The area includes several recreation parks including Kalopa State Recreation Area, Wailuku River State Park and Akaka Falls State Park.

There are over 3,000 registered hunters on Hawaii island, and hunting, for both recreation and sustenance, is a common activity on Mauna Kea. A public hunting program is used to control the numbers of introduced animals including pigs, sheep, goats, turkey, pheasants, and quail. The Mauna Kea State Recreation Area functions as a base camp for the sport. Birdwatching is also common at lower levels on the mountain. A popular site is "Kīpuka Pu'u Huluhulu", a kīpuka on Mauna Kea's flank that formed when lava flows isolated the forest on a hill.
Mauna Kea's great height and the steepness of its flanks provide a better view and a shorter hike than the adjacent Mauna Loa. The height with its risk of altitude sickness, weather concerns, steep road grade, and overall inaccessibility make the volcano dangerous and summit trips difficult. Until the construction of roads in the mid-20th century, only the hardy visited Mauna Kea's upper slopes; hunters tracked game animals, and hikers traveled up the mountain. These travelers used stone cabins constructed by the Civilian Conservation Corps in the 1930s as base camps, and it is from these facilities that the modern mid-level Onizuka Center for International Astronomy telescope support complex is derived. The first Mauna Kea summit road was built in 1964, making the peak accessible to more people.

Today, multiple hiking trails exist, including the Mauna Kea Trail, and by 2007 over 100,000 tourists and 32,000 vehicles were going each year to the Visitor Information Station (VIS) adjacent to the Onizuka Center for International Astronomy. The Mauna Kea Access Road is paved up to the Center at . One study reported that around a third of visitors and two thirds of professional astronomers working on the mountain have experienced symptoms of acute altitude sickness; visitors traveling up the volcano's flanks are advised to stop for at least half an hour and preferably longer at the visitor center to acclimate to the higher elevation. It is strongly recommended to use a four-wheel drive vehicle to drive all the way to the top. Brakes often overheat on the way down and there is no fuel available on Mauna Kea. A free Star Gazing Program is held at the VIS every night from 6-10 pm. Between 5,000 and 6,000 people visit the summit of Mauna Kea each year, and to help ensure safety, and protect the integrity of the mountain, a ranger program was implemented in 2001.




</doc>
<doc id="269945" url="https://en.wikipedia.org/wiki?curid=269945" title="American paddlefish">
American paddlefish

The American paddlefish ("Polyodon spathula") is a species of basal ray-finned fish closely related to sturgeons in the order Acipenseriformes. Fossil records of paddlefish date back over 300million years, nearly 50million years before dinosaurs first appeared. American paddlefish are smooth-skinned freshwater fish commonly called paddlefish, but are also referred to as Mississippi paddlefish, spoon-billed cats, or spoonbills. They are one of only two extant species in the paddlefish family, Polyodontidae. The other is the critically endangered Chinese paddlefish ("Psephurus gladius") endemic to the Yangtze River basin in China. American paddlefish are often referred to as primitive fish, or relict species because they retain some morphological characteristics of their early ancestors, including a skeleton that is almost entirely cartilaginous, a paddle-shaped rostrum (snout) that extends nearly one-third their body length, and a heterocercal tail or caudal fin, much like that of sharks. American paddlefish are a highly derived fish because they have evolved with adaptations such as filter feeding. Their rostrum and cranium are covered with tens of thousands of sensory receptors for locating swarms of zooplankton, which is their primary food source.

American paddlefish are native to the Mississippi River basin and once moved freely under the relatively natural, unaltered conditions that existed prior to the early 1900s. They commonly inhabited large, free-flowing rivers, braided channels, backwaters, and oxbow lakes throughout the Mississippi River drainage basin, and adjacent Gulf drainages. Their peripheral range extended into the Great Lakes, with occurrences in Lake Huron and Lake Helen in Canada until about 90 years ago. American paddlefish populations have declined dramatically primarily because of overfishing, habitat destruction, and pollution. Poaching has also been a contributing factor to their decline and will continue to be as long as the demand for caviar remains strong. Naturally occurring American paddlefish populations have been extirpated from most of their peripheral range, as well as from New York, Maryland, Virginia, and Pennsylvania. The current range of American paddlefish has been reduced to the Mississippi and Missouri River tributaries and Mobile Bay drainage basin. They are currently found in twenty-two states in the U.S., and those populations are protected under state, federal and international laws.

American paddlefish are closely related to sturgeons in the order Acipenseriformes, an order of basal ray-finned fishes that includes sturgeon and paddlefish, several species of which are now extinct. Paddlefish are among the oldest of fishes as evidenced in the fossil record which dates their first appearance approximately 300 to 400million years ago, almost 50million years before the dinosaurs. Fossils of a second extinct species, "P. tuberculata", which date back approximately 60million years ago, were found in the Lower Paleocene Tullock Formation in Montana.

In 1797, French naturalist Bernard Germain de Lacépède established the genus "Polyodon" for paddlefish, which today includes a single extant species, "Polyodon spathula". Lacépède disagreed with Pierre Joseph Bonnaterre's description in "Tableau encyclopédique et méthodique" (1788), which suggested paddlefish were a species of shark. Lacépède noted, "The country and habits of this fish are still unknown." When Lacépède established the binomial, "Polydon feuille", he was unaware the species had already been named in 1772 by taxonomist, Johann Julius Walbaum, who described paddlefish as "Squalus spathula". As a result of Lacépède's inadvertent double naming, "Polyodon spathula" became the preferred scientific name of American paddlefish, and "Squalus spathula" became the synonym as one of two names applied to the group. Walbaum, 1792, is recognized and cited as the authority.

The family Polyodontidae comprises five known taxa; three extinct taxa from western North America, and two extant taxa including the American paddlefish ("Polyodon spathula") native to the Mississippi River Basin in the United States, and the critically endangered Chinese paddlefish ("Psephurus glades") endemic to the Yangtze River Basin in China. American paddlefish are the only living species in the genus "Polyodon". They are often referred to as primitive fish, or relict species, because of morphological characteristics they retain from some of their early ancestors as evidenced in the fossil record which dates them back to the Late Cretaceous, 70 to 75million years ago. Some of their primitive characteristics include a skeleton composed primarily of cartilage, and a deeply forked heterocercal caudal fin similar to that of sharks, although they are not closely related.

Fossil paddlefishes with recognizable rostrums date from the Upper Cretaceous and Paleocene periods 65million years ago. An elongated rostrum is a morphological characteristic of Polyodontidae, but only the genus "Polyodon" ("P. spathula" and the extinct "P. tuberculata") have characteristics adapted specifically for filter feeding, including the jaw, gill arches, and cranium. The gill rakers of American paddlefish are composed of extensive comb-like filaments believed to have inspired the etymology of the genus name, "Polyodon", a Greek compound word meaning "many toothed". Adult American paddlefish are actually toothless, although numerous small teeth less than were found in a juvenile paddlefish measuring . "Spathula" references the elongated, paddle shaped snout or rostrum. Compared to Chinese paddlefish and fossil genera, American paddlefish (and by extension, a fossil relative, "P. tuberculata") are considered to be a highly derived species because of their novel adaptations.

Chinese paddlefish are the closest extant relative of American paddlefish. They are currently listed as critically endangered on the IUCN Red List. Several reports have suggested that Chinese paddlefish may now be extinct. The primary reasons for their decline are similar to those of American paddlefish and include overfishing, the construction of dams, and destruction of habitat. Unlike the planktivorous American paddlefish, Chinese paddlefish are strong swimmers, grow larger, and are opportunistic piscivores that feed on small fishes and crustaceans. Some distinct morphological differences of Chinese paddlefish include a narrower, sword-like rostrum, and a protrusible mouth. They also have fewer, thicker gill rakers than American paddlefish. The last confirmed sighting of a live Chinese paddlefish was made on the Yangtzee River on January 24, 2003. From 2006 to 2008, scientists conducted surveys in an effort to locate the fish. They used several boats, deployed 4762 setlines, 111 anchored setlines and 950 drift nets covering on the upper Yangtze River, most of which lies within the protected area of the Upper Yangtze National Nature Reserve. They did not catch a single fish. They also used hydroacoustic equipment to monitor active sound in water (sonar), but were unable to confirm the presence of paddlefish.

American paddlefish are among the largest and longest-lived freshwater fishes in North America. They have a shark-like body, average in length, weigh , and can live in excess of thirty years. For most populations the median age is five to eight years and the maximum age is fourteen to eighteen years. The age of American paddlefish is best determined by dentary studies, a process which usually occurs on fish harvested during snagging season, a popular sport fishing activity in certain parts of the U.S. The dentary is removed from the lower jawbone, cleaned of any remaining soft tissue, and cross-sectioned to expose the annual rings. The dentary rings are counted in much the same way a tree is aged. Dentary studies suggest that some individuals can live 60 years or longer, and that females typically live longer and grow larger than males.

American paddlefish are smooth-skinned and almost entirely cartilaginous. Their eyes are small and directed laterally. They have a large, tapering operculum flap, a large mouth, and a flat, paddle-shaped rostrum that measures approximately one-third of their body length. During the initial stages of development from embryo to hatchling, American paddlefish have no rostrum. It begins to form shortly after hatching. The rostrum is an extension of the cranium, not of the upper and lower jaws or olfactory system as with the long snouts of other fishes. Other distinguishing characteristics include a deeply forked heterocercal caudal fin and dull coloration, often with mottling, ranging from bluish gray to black dorsally grading to a whitish underbelly.

Scientists began to debate the function of the American paddlefish's rostrum when the species was described in the late 1700s. They had once believed it was used to excavate bottom substrate or functioned as a balancing mechanism and navigational aid. However, laboratory experiments in 1993 that utilized advanced technology in the field of electron microscopy have established conclusively that the rostrum of American paddlefish is covered with tens of thousands of sensory receptors. These receptors are morphologically similar to the ampullae of Lorenzini of sharks and rays, and are indeed passive ampullary-type electroreceptors used by American paddlefish to detect plankton. Clusters of electroreceptors also cover the head and operculum flaps. The American paddlefish's diet consists primarily of zooplankton. Their electroreceptors can detect weak electrical fields, which signal not only the presence of zooplankton, but also the individual feeding and swimming movements of zooplankton appendages. When a swarm of zooplankton is detected, the paddlefish swims forward continuously with their mouth wide open, forcing water over the gill rakers to filter out prey. Such feeding behavior is considered ram suspension-feeding. Further research has indicated that their electroreceptors may also serve as a navigational aid for obstacle avoidance.

American paddlefish have small undeveloped eyes that are directed laterally. Unlike most fishes, American paddlefish hardly respond to overhead shadows or changes in illumination. Electroreception appears to have largely replaced vision as a primary sensory modality, which indicates a reliance on electroreceptors for detecting prey. However, the rostrum is not their only means of food detection. Some reports suggest a damaged rostrum would render American paddlefish less capable of foraging efficiently to maintain good health, but laboratory experiments and field research indicate otherwise. As well as electroreceptors on the rostrum, American paddlefish have sensory pores covering nearly half of the skin surface extending from the rostrum to the top of the head down to the tips of the operculum flaps. Studies have indicated that American paddlefish with damaged or abbreviated rostrums are still able to forage and maintain good health.

American paddlefish are long-lived, sexually late maturing pelagic fish. Females do not begin spawning until they are seven to ten years old, some as late as sixteen to eighteen years old. Females do not spawn every year, rather they spawn every second or third year. Males spawn more frequently, usually every year or every other year beginning around age seven, some as late as nine or ten years of age.

American paddlefish begin their upstream spawning migration sometime during early spring; some begin in late fall. They spawn on silt-free gravel bars that would otherwise be exposed to air or covered by very shallow water were it not for the rises in the river from snow melt and annual spring rains that cause flooding. Although availability of preferred spawning habitat is essential, there are three precise environmental events that must occur before American paddlefish will spawn. The water temperature must be from ; the lengthened photoperiod which occurs in spring triggers biological and behavioral processes that are dependent on increasing day length; and there must be a proper rise and flow in the river before a successful spawn can occur. Historically, American paddlefish did not spawn every year because the precise environmental events only occurred once every 4 or 5 years.

American paddlefish are broadcast spawners, also referred to as mass spawners or synchronous spawners. Gravid females release their eggs into the water over bare rocks or gravel at the same time males release their sperm. Fertilization occurs externally. The eggs become sticky after they are released into the water and will attach to the bottom substrate. Incubation varies depending on water temperature, but in water the eggs will hatch into larval fish in about seven days. After hatching, the larval fish drift downstream into areas of low flow velocity where they forage on zooplankton.

Young American paddlefish are poor swimmers which makes them susceptible to predation. Therefore, rapid first-year growth is important to their survival. Fry can grow about per week, and by late July the fingerlings are around long. Their rate of growth is variable and highly dependent on food abundance. Higher growth rates occur in areas where food is not limited. The feeding behavior of fingerlings is quite different from that of older juveniles and adults. They capture individual plankton one by one, which requires detection and location of individual "Daphnia" on approach, followed by an intercept maneuver to capture the selected prey. By late September fingerlings have developed into juveniles, and are around long. After the 1st year their growth rate slows and is highly variable. Studies indicate that by age 5 their growth rate averages around per year depending on the abundance of food and other environmental influences.

American paddlefish are highly mobile and well adapted to living in rivers. They inhabit many types of riverine habitats throughout much of the Mississippi Valley and adjacent Gulf slope drainages. They occur most frequently in deeper, low current areas such as side channels, oxbows, backwater lakes, bayous, and tailwaters below dams. They have been observed to move more than in a river system.

American paddlefish are endemic to the Mississippi River Basin, historically occurring from the Missouri and Yellowstone rivers in the northwest to the Ohio and Allegheny rivers of the northeast; the headwaters of the Mississippi River south to its mouth, from the San Jacinto River in the southwest to the Tombigbee and Alabama rivers of the southeast. They were extirpated from New York, Maryland and Pennsylvania, as well as from much of their peripheral range in the Great Lakes region, including Lake Huron and Lake Helen in Canada. In 1991, Pennsylvania implemented a reintroduction program utilizing hatchery-reared American paddlefish in an effort to establish self-sustaining populations in the upper Ohio and lower Allegheny rivers. In 1998, New York initiated a stocking program upstream in the Allegheny Reservoir above Kinzua Dam, and a second stocking in 2006 in Conewango Creek, a relatively unaltered section of their historic range. Reports of free ranging adults captured by gill nets have since been documented in Pennsylvania and New York, but there is no evidence of natural reproduction. They are currently found in 22 states in the US, and are protected under state and federal laws. There are 13 states that allow commercial or sport fishing for American paddlefish.

The artificial propagation of American paddlefish began with the efforts of the Missouri Department of Conservation during the early 1960s, and focused primarily on maintenance of the sport fishery. However, it was the growing importance of American paddlefish for their meat and roe that became the catalyst for further development of culture techniques for aquaculture in the United States. Artificial propagation requires broodstock which, because of the late sexual maturation of American paddlefish, are initially obtained from the wild and brought into a hatchery environment. The fish are injected with LH-RH hormone to stimulate spawning. The number of eggs a female may produce depends on the size of the fish and can range anywhere from 70,000–300,000 eggs. Unlike most teleosts, the oviduct branches of American paddlefish and sturgeons are not directly attached to the ovaries; rather, they open dorsally into the body cavity. To determine the status of progression toward maturation, ova staging is performed. The process begins with a minor procedure that involves a small abdominal incision from which to extract a few sample oocytes. The oocytes are boiled in water for a few minutes until the yolk is hardened, and then they are cut in half to expose the nucleus. The exposed nucleus is examined under a microscope to determine stage of maturity.

Once maturation is confirmed, one of three procedures is used to extract the eggs from a female paddlefish. The three procedures are (1) the traditional hand-stripping method, considered to be time consuming and laborious; (2) Caesarean section, a relatively quick surgical method of extracting eggs through a abdominal incision; considered faster than hand stripping, suturing can be time consuming and the incision may result in muscular stress and poor suture retention which lowers survival rate; and (3) MIST, (minimally invasive surgical technique) which is the fastest of the three procedures because it requires less handling of the fish and eliminates the need for suturing. A small internal incision is made in the dorsal area of the oviduct, which allows direct stripping of eggs from the body cavity through the gonopore bypassing the oviductal funnels.

A spermiating male indicates successful production of mature spermatozoa which results in the release of large volumes of milt over the course of three to four days. Milt is collected by inserting a short plastic tube with syringe attached into the urogenital opening of the male and applying light suction with the syringe to draw the milt. The collected milt is diluted in water just prior to adding it to the eggs and the combination is gently stirred for about a minute to achieve fertilization. Fertilized eggs are adhesive and demersal, therefore if incubation is to take place in a flow-through hatching jar, the eggs must be treated to prevent clumping. Incubation usually takes anywhere from five to twelve days.

Advancements in biotechnology have created a global commercial market for the polyculture of American paddlefish. In 1970, American paddlefish were stocked in several rivers in Europe and Asia. Introduction began when five thousand hatched larvae from Missouri hatcheries in the United States were exported to the former USSR for aquacultural utilization. Reproduction was successful in 1988 and 1989, and resulted in the exportation of juveniles to Romania and Hungary. American paddlefish are now being raised in Ukraine, Germany, Austria, the Czech Republic, and the Plovdiv and Vidin regions in Bulgaria. In May 2006, specimens of different sizes and weights were caught by professional fisherman near Prahovo in the Serbian part of the Danube River.

In 1988, fertilized American paddlefish eggs and larvae from Missouri hatcheries were first introduced into China. Since that time, China imports approximately 4.5million fertilized eggs and larvae every year from hatcheries in Russia and the United States. Some American paddlefish are polycultured in carp ponds and sold to restaurants while others are cultured for brood stock and caviar production. China has also exported American paddlefish to Cuba, where they are farmed for caviar production.

American paddlefish are a popular sport fish where their populations are sufficient to allow such activity. Areas where there are no self-sustaining populations rely on state and federal restocking programs to maintain a viable fishery. A 2009 report includes the following states as allowing American paddlefish sport fishing per their respective state and federal regulations: Arkansas, Illinois, Indiana, Iowa, Kansas, Kentucky, Mississippi, Missouri, Montana, Nebraska, North Dakota, Nebraska, Oklahoma, Montana, South Dakota and Tennessee. Since American paddlefish are filter-feeders, they will not take bait or lures, and must be caught by snagging. The official state record in Kansas is a American paddlefish snagged in 2004; Montana, a American paddlefish snagged in 1973; and in North Dakota, a American paddlefish snagged in 2010. The largest American paddlefish on record was captured in West Okoboji Lake, Iowa in 1916 by a spear fisherman, and measured long, and weighed an estimated .

American paddlefish populations have declined dramatically, primarily as a result of overfishing and habitat destruction. In 2004 they were listed as Vulnerable (VU A3de ver 3.1) on the IUCN Red List of Threatened Species. They are currently proposed for listing as VU 3de throughout their range as the result of a U.S. Fish & Wildlife Service assessment. The assessment concluded that "an overall population size reduction of at least 30% may occur within the next 10 years or three generations due to actual or potential levels of exploitation and the effects of introduced taxa, pollutants, competitors or parasites." American paddlefish are filter-feeding pelagic fish that require large, free-flowing rivers with braided channels, backwater areas, oxbow lakes that are rich in zooplankton, and gravel bars for spawning. Series of dams on rivers such as those constructed on the Missouri River have impounded large populations of American paddlefish, and blocked their upstream migration to spawning shoals. Channelization and groynes or wing dykes have caused the narrowing of rivers and altered flow, destroying crucial spawning and nursery habitat. As a result, most impounded populations are not self-sustaining and must be stocked to maintain a viable sport fishery.

Zebra mussel infestations in the Mississippi River, Great Lakes and other Midwest rivers are also negatively affecting American paddlefish populations. Zebra mussels are an invasive species well adapted for explosive population growth as a result of high rates of fecundity and recruitment. As filter feeders, zebra mussels rely on plankton and can filter significant amounts of phytoplankton and zooplankton from the water, altering the availability of an important food source for paddlefish and native unionidae. A few days after the fertilization of zebra mussel eggs, a microscopic larva emerges called a veliger. During this initial stage of development, which usually lasts a few weeks, veligers are able to swim freely in the water column with other microscopic animals comprising zooplankton. Veligers are poor swimmers, making them susceptible to predation by any animal that feeds on zooplankton. However, natural predation of zebra mussels at any stage of development has not made a significant contribution to the long-term reduction of zebra mussel populations.

Poaching has been a contributing factor to declining populations of American paddlefish in the states where they are commercially exploited, particularly while the demand for caviar remains strong. Since the 1980s, a trade embargo on Iran restricted imports of the highly sought after and most expensive beluga caviar from the Caspian Sea, limiting U.S. sources of caviar. The most sought after caviar is produced by sturgeons in the Northern Caspian Sea, but overfishing and poaching have exhausted the supply. American sturgeon and paddlefish populations were targeted as likely substitutes.

The roe of American paddlefish can be processed into caviar similar in taste, color, size and texture to sevruga sturgeon caviar from the Caspian Sea. Several cases of mislabeled American paddlefish roe sold as Caspian Sea caviar have been prosecuted by the U.S. Fish and Wildlife Service (USFWS). State and federal regulations restricting the harvest of American paddlefish populations in the wild, and the illegal trafficking of their roe are strictly enforced. Related violations such as the illegal transport of American paddlefish roe have resulted in convictions with substantial fines and prison sentences. Paddlefish are also protected under CITES, (Convention on the International Trade in Endangered Species of Fauna and Flora).



</doc>
<doc id="270185" url="https://en.wikipedia.org/wiki?curid=270185" title="Oceanic whitetip shark">
Oceanic whitetip shark

The oceanic whitetip shark ("Carcharhinus longimanus"), also known as Brown Milbert's sand bar shark, brown shark, lesser white shark, nigano shark, oceanic white-tipped whaler, and silvertip shark, is a large pelagic requiem shark inhabiting tropical and warm temperate seas. Its stocky body is most notable for its long, white-tipped, rounded fins.

This slow-moving but aggressive fish dominates feeding frenzies, and is a danger to shipwreck or air crash survivors. Recent studies show steeply declining populations because its large fins are highly valued as the chief ingredient of shark fin soup, and as with other shark species, the whitetip faces mounting fishing pressure throughout its range.

The oceanic whitetip shark, or lesser white shark, was described in 1831 by naturalist René-Primevère Lesson, who named the shark "Carcharhinus maou". It was next described by Cuban Felipe Poey in 1861 as "Squalus longimanus". The name "Pterolamiops longimanus" has also been used. The species epithet ' refers to the size of its pectoral fins (' translates from Latin as "long hands"). The oceanic whitetip shark has many common names in English: Brown Milbert's sand bar shark, brown shark, nigano shark, oceanic white-tipped whaler, and whitetip shark.

The rules of the International Commission on Zoological Nomenclature are that in general the first-published description has priority; therefore, the valid scientific name for the oceanic whitetip shark should be "Carcharhinus maou". However, Lesson's name remained forgotten for so long that "Carcharhinus longimanus" remains widely accepted.

The oceanic whitetip is found globally in deep, open oceans, with a temperature greater than , although exceptionally it occurs in water as cold as . It prefers waters between and tends to withdraw from areas when temperatures fall outside of these limits. It was once extremely common and widely distributed, and still inhabits a wide band around the globe; however, recent studies suggest that its numbers have drastically declined. An analysis of the US pelagic longline logbook data between 1992 and 2000 (covering the Northwest and Western Central Atlantic) estimated a decline of 70% over that period.

It is found worldwide between 45°N and 43°S latitude. In September 2004, a vagrant oceanic whitetip shark was seen in the brackish waters of Gullmarsfjorden in Sweden; it died shortly after. This is the only North European record and far north of its usual range limit.

The shark spends most of its time in the upper layer of the ocean—to a depth of —and prefers off-shore, deep-ocean areas. According to longline capture data, increasing distance from land correlates to a greater population of sharks. Occasionally, it is found close to land, in waters as shallow as , mainly around midocean islands such as Hawaii, or in areas where the continental shelf is narrow with access to nearby deep water. It is typically solitary, though gatherings have been observed where food is plentiful. Unlike many animals, it does not have a diurnal cycle, and is active both day and night. Its swimming style is slow, with widely spread pectoral fins. Despite its habitual isolation from members of its own species, pilot fish, dolphinfish, and remora may accompany it. In 1988, Jeremy Stafford-Deitsch reported seeing an individual accompanied by a shortfin pilot whale.

"C. longimanus" most distinguishing characteristics are its long, wing-like pectoral and dorsal fins. The fins are significantly larger than most other shark species, and are conspicuously rounded. The shark's nose is rounded and its eyes are circular, with nictitating membranes.

"C. longimanus" has a 'typical', although somewhat flattened requiem shark body, often with a mildly humpbacked aspect. It is bronze, brown, bluish, or grey dorsally (the colour varies by region), and white ventrally (although it may occasionally have a yellow tint). The oceanic whitetip shark is a medium-sized requiem shark. The largest specimen ever caught measured , an exceptionally large size considering few specimens are known to exceed a length of . The maximum reported weight is . The female is typically larger than the male by . Males attain sexual maturity at and females about . In the Gulf of Mexico in the 1950s, the mean weight of oceanic whitetip sharks was . In the 1990s, the sharks of the species from the same area averaged only .

Most of its fins (dorsal, pectoral, pelvic, and caudal) have white tips (juvenile specimens and some adults may lack these). Along with white tips, the fins may be mottled, and young specimens can have black marks. A saddle-like marking may be apparent between first and second dorsal fins. The shark has several kinds of teeth. Those in the mandible (lower jaw) have a thin, serrated tip and are relatively small and triangular (somewhat fang-like). Between 13 and 15 teeth are on either side of the symphysis. The teeth in the upper jaw are triangular, but much larger and broader with entirely serrated edges— 14 or 15 occur along each side of the symphysis. The denticles lie flat and typically have between five and seven ridges.

"C. longimanus" feeds mainly on pelagic cephalopods and bony fish. However, its diet can be far more varied and less selective—it is known to eat threadfins, stingrays, sea turtles, birds, gastropods, crustaceans, and mammalian carrion. The bony fish it feeds on include lancetfish, oarfish, barracuda, jacks, dolphinfish, marlin, tuna, and mackerel. Its feeding methods include biting into groups of fish and swimming through schools of tuna with an open mouth. When feeding with other species, it becomes aggressive. Peter Benchley, author of "Jaws", observed this shark swimming among pilot whales and eating their faeces.

The oceanic whitetip is usually solitary and slow-moving, and tends to cruise near the top of the water column, covering vast stretches of empty water scanning for possible food sources. Until the 16th century, sharks were known to mariners as "sea dogs" and the oceanic whitetip, the most common ship-following shark, exhibits dog-like behaviour when its interest is piqued: when attracted to something that appears to be food, its movements become more avid and it approaches cautiously but stubbornly, retreating and maintaining a safe distance if driven off, but ready to rush in if the opportunity presents itself. Oceanic whitetips are not fast swimmers, but they are capable of surprising bursts of speed. Whitetips commonly compete for food with silky sharks, making up for its comparatively leisurely swimming style with aggressive displays.

Groups often form when individuals converge on a food source, whereupon a feeding frenzy may occur. This seems to be triggered not by blood in the water or by bloodlust, but by the species' highly strung and goal-directed nature (conserving energy between infrequent feeding opportunities when it is not slowly plying the open ocean). The oceanic whitetip is a competitive, opportunistic predator that exploits the resource at hand, rather than avoiding trouble in favour of a possibly easier future meal.

Segregation by sex and size does not seem to occur. Whitetips follow schools of tuna or squid, and trail groups of cetaceans such as dolphins and pilot whales, scavenging their prey. Their instinct is to follow baitfish migrations that accompany ocean-going ships. When whaling took place in warm waters, oceanic whitetips were often responsible for much of the damage to floating carcasses.

Mating season is in early summer in the northwest Atlantic Ocean and southwest Indian Ocean, although females captured in the Pacific have been found with embryos year round, suggesting a longer mating season there. The shark is viviparous—embryos develop "in utero" and are fed by a placental sac. Its gestation period is one year. Litter sizes vary from one to 15 with the young born at a length around . Sexual maturity is reached around for males and for females.

The oceanic whitetip is a commercially important species for its fins, meat, and oil. It is eaten fresh, smoked, dried, and salted and its hide is used for leather. It is subject to fishing pressure throughout virtually its whole range,although it is more often taken as bycatch than by design, since it is drawn to longline bait that is intended for other species.

Oceanographic researcher Jacques Cousteau described the oceanic whitetip as "the most dangerous of all sharks". Despite the greater notoriety of the great white shark and other sharks habitually found nearer the shore, the oceanic whitetip is suspected to be responsible for many fatal shark bites on humans, as a result of predation on survivors of shipwrecks or downed aircraft. Such incidents are not included in common shark-bite indices for the 20th and 21st centuries, and as a result, the oceanic whitetip does not have the highest number of recorded incidents; only five bites had been recorded as of 2009.

After the USS "Indianapolis" was torpedoed on 30 July 1945, most sailors who survived the sinking reportedly died from exposure to the elements rather than from shark bites. Some sailors, however, are believed to have died from shark bites, and oceanic whitetips are believed to have been responsible in those cases. Also during World War II, the RMS "Nova Scotia", a steamship carrying about 1,000 people near South Africa, was sunk by a German submarine. 192 people survived; many deaths were attributed to the whitetip.

In Egypt in 2010, one oceanic whitetip was implicated in several bites on tourists in the Red Sea near Sharm El Sheikh. The shark was recognized individually by the bite mark taken out of its upper tail lobe. Accumulating evidence revealed this shark to have been conditioned to being hand fed. Upon associating the divers with an easy supply of food, it bit the divers and snorkelers on the areas of the body where it had seen the fish being kept, namely, in the fanny packs the divers carried. This caused the shark to target the divers' buttock and thigh regions in the hope of obtaining a meal. The 2010 Sharm El Sheikh bites resulted in one death and four injuries to humans. The attacks might have been instigated by the overfishing in that area of the Red Sea, effectively forcing the shark closer to shore where the bites took place.

Dr. Christopher Neff, a policy analyst at the University of Sydney, argues that terms like "attack" are laden with cultural stigmatization. Instead of the word "attack", he proposes labeling human-shark interactions, on a scale of extremity, as encounters, minor bites, moderate bites and fatal bites. The term "attack" is only appropriate in specific instances where specialists can confirm the predatory nature of the shark-human encounter, which is extremely difficult to do. While many encounters with oceanic whitetip sharks appear predatory in nature, without the verification of a scientific community in each instance, Neff argues that it is best to assume the accidental or nonpredatory intent of the encounters.

The oceanic whitetip has fared better in captivity than other large sharks of the open ocean, such as the mako and blue shark. Among five recorded captive oceanic whitetips, the three with time records all lived for more than a year in captivity. One of these, a female in Monterey Bay Aquarium's Outer-Bay exhibit, lived for more than three years during which it grew . The two remaining lack a time record, but grew about during their time in captivity.

In 1969, Lineaweaver and Backus wrote of the oceanic whitetip: "[it is] extraordinarily abundant, perhaps the most abundant large animal, large being over 100 pounds [45 kg], on the face of the earth". Little further population study occurred until 2003, when the numbers were estimated to have dropped by as much as 70% in the Northwest and Western Central Atlantic between 1992 and 2000.
Another study focusing on the Gulf of Mexico, using a mix of data from US pelagic longline surveys from the mid-1950s and observations from the late-1990s, estimated a decline in numbers in this location of 99.3% over this period. However, changes in fishing practices and data collection methods complicate estimates.

As a result of these findings, its status on the IUCN Red List was moved to "Vulnerable" globally (from "Lower Risk/Near Threatened") and "Critically Endangered" in the Northwest and Western Central Atlantic areas.

Under the 1995 UN Agreement on the Conservation and Management of Straddling Fish Stocks and Highly Migratory Fish Stocks, coastal and fishing states are specifically required to adopt measures to conserve listed species, but little progress is visible on the oceanic whitetip.

From 3 January 2013, the shark was fully protected in New Zealand territorial waters under the Wildlife Act 1953. The New Zealand Department of Conservation has classified the oceanic whitetip shark as "Migrant" with the qualifier "Secure Overseas" under the New Zealand Threat Classification System.

In March 2013, three endangered commercially valuable sharks, the hammerheads, the oceanic whitetip, and porbeagle were added to Appendix II of CITES, bringing shark fishing and commerce of these species under licensing and regulation.

On January 30, 2018, NOAA Fisheries published a final rule to list the oceanic whitetip shark as a threatened species under the United States Endangered Species Act (ESA) (83 FR 4153).





</doc>
<doc id="271544" url="https://en.wikipedia.org/wiki?curid=271544" title="Ranavalona III">
Ranavalona III

Ranavalona III (November 22, 1861 – May 23, 1917) was the last sovereign of the Kingdom of Madagascar. She ruled from July 30, 1883 to February 28, 1897 in a reign marked by ongoing and ultimately futile efforts to resist the colonial designs of the government of France. As a young woman, she was selected from among several Andriana qualified to succeed Queen Ranavalona II upon her death. Like both preceding queens, Ranavalona entered a political marriage with a member of the Hova elite named Rainilaiarivony, who in his role as Prime Minister of Madagascar, largely oversaw the day-to-day governance of the kingdom and managed its foreign affairs. Ranavalona tried to stave off colonization by strengthening trade and diplomatic relations with the United States and Great Britain throughout her reign. French attacks on coastal port towns and an assault on the capital city of Antananarivo ultimately led to the capture of the royal palace in 1895, ending the sovereignty and political autonomy of the century-old kingdom.

The newly installed French colonial government promptly exiled Rainilaiarivony to Algiers. Ranavalona and her court were initially permitted to remain as symbolic figureheads, but the outbreak of a popular resistance movement – the "menalamba" rebellion – and discovery of anti-French political intrigues at court led the French to exile the queen to the island of Réunion in 1897. Rainilaiarivony died that same year and shortly thereafter Ranavalona was relocated to a villa in Algiers, along with several members of her family. The queen, her family and the servants accompanying her were provided an allowance and enjoyed a comfortable standard of living including occasional trips to Paris for shopping and sightseeing. Despite Ranavalona's repeated requests, she was never permitted to return home to Madagascar. She died of an embolism at her villa in Algiers in 1917 at the age of 55. Her remains were buried in Algiers but were disinterred 21 years later and shipped to Madagascar, where they were placed within the tomb of Queen Rasoherina on the grounds of the Rova of Antananarivo.

Ranavalona III, daughter of Andriantsimianatra and his wife and cousin, Princess Raketaka, was born Princess Razafindrahety on November 22, 1861, at Amparibe, a rural village in the district of Manjakazafy outside Antananarivo. Razafindrahety's lineage, as niece to Queen Ranavalona II and great-granddaughter of King Andrianampoinimerina, qualified her to potentially inherit the throne of the Kingdom of Madagascar. Her parents assigned the care of the infant Razafindrahety to a slave who served the family.

When she was old enough to attend school, Razafindrahety was taken into the custody of her aunt, Queen Ranavalona II, who ensured she began receiving a private education from a London Missionary Society (LMS) teacher. She was described as an industrious and inquisitive child with a strong love of studying the Bible, learning and reading, and she developed affectionate relationships with her teachers. She continued her education throughout her adolescence at the Congregational School of Ambatonakanga, the Friends High School for Girls, and the LMS Girls' Central School. She was baptized as a Protestant at Ambohimanga on April 5, 1874. Her teachers consistently described her as ranking among their strongest students.

As a young woman, Razafindrahety married an Andriana (nobleman) named Ratrimo (Ratrimoarivony). Her husband died several years later on May 8, 1883, aged 22, leaving Razafindrahety a premature widow. According to rumor, Prime Minister Rainilaiarivony may have arranged to have Ratrimo poisoned for political reasons. The Aristocratic Revolution of 1863, which had been orchestrated by Rainilaiarivony's older brother, Prime Minister Rainivoninahitriniony, had replaced the absolute rule of the Andriana with a constitutional monarchy in which power was shared between an Andriana monarch and a Hova (freeman) prime minister. This arrangement was to be cemented by a political marriage between the prime minister and a ruling queen effectively selected by him. As Queen Ranavalona II neared death and the search for her successor began, Rainilaiarivony may have had Ratrimo deliberately poisoned so that Razafindrahety, the most eligible successor, would be free to marry the prime minister and succeed to the throne.

Ranavalona III was proclaimed queen upon the death of her predecessor, Queen Ranavalona II, on July 13, 1883, and moved into Tsarahafatra, a wooden house on the grounds of the royal Rova complex in Antananarivo. Her coronation took place in the Mahamasina neighborhood of Antananarivo on November 22, 1883, her 22nd birthday, where she was given the title "Her Majesty Ranavalona III by the grace of God and the will of the people, Queen of Madagascar, and Protectoress of the laws of the Nation". She chose to break with tradition by supplementing the customary retinue of soldiers at her ceremony with a group of 500 male and 400 female pupils from the capital's best schools. The girls were dressed in white while the boys wore soldiers' uniforms and performed traditional military drills with spears. Ranavalona was crowned wearing a white silk gown with a red train featuring embroidery and gold embellishments. The queen was described in the American press in the following terms: "She is a little above the ordinary height and has delicate features, her complexion is a little darker than that of most of her subjects. She appears quite timid and she presides well at the solemn functions of her court."

Like her two predecessors, Ranavalona concluded a political marriage with Prime Minister Rainilaiarivony. The young queen's role was largely ceremonial as nearly all important political decisions continued to be made by the much older and more experienced prime minister. Ranavalona was frequently called upon to deliver formal speeches ("kabary") to the public on behalf of Rainilaiarivony and would make appearances to inaugurate new public buildings, such as a hospital at Isoavinandriana and a girls' school at Ambodin'Andohalo. Throughout her reign, Ranavalona's aunt, Ramisindrazana, acted as an adviser and exercised considerable influence at court. Ranavalona's older sister, Rasendranoro, whose son Rakatomena and daughter Razafinandriamanitra lived with their mother at the Rova, was also a close companion. An American journalist who visited her palace reported that Ranavalona spent much of her leisure time flying kites or playing lotto, a parlor game, with her relatives and other ladies at court. She also enjoyed knitting, needlework and crocheting and would frequently bring her latest craft project to work on at cabinet meetings. She had a great love of fine garments and was the only Malagasy sovereign to import the majority of her clothing from Paris rather than London.

As sovereign of Madagascar, Ranavalona III became a pawn in the endgame of the maneuvering that had been taking place between the British and French since the beginning of the century. The tension between France and Madagascar had grown especially acute in the three years prior to Ranavalona's succession, with an intensification of attacks in the months prior to her coronation. In February 1883 the northwestern coast was bombarded, followed by the occupation of Mahajanga by the French in May, and bombardment and capture of Toamasina in June. Attacks along the northern coast were ongoing at the time Ranavalona III was crowned in the summer of 1883. Shortly after the French initiated this latest round of hostilities, Prime Minister Rainilaiarivony decided to engage Lieutenant Colonel Digby Willoughby, a Briton who had gained combat experience in the Anglo-Zulu War (but without having been a member of the British armed forces), to oversee the nation's military affairs and train the queen's army to defend the island against the seemingly inevitable French invasion.

Throughout this period Madagascar continued to engage the French in negotiations, but these were to prove unsuccessful with both sides unwilling to capitulate on key points of contention. After two years of stalemate, a column brought an ultimatum to Antananarivo in December 1885, asking for the acceptance of French claims in northeastern Madagascar, a French protectorate over the Sakalava, recognition of French property principles and an indemnity of 1,500,000 francs. This peace treaty was ratified by Ranavalona and Rainilaiarivony in January 1886 and French government representatives two months later.

Prior to ratification, the queen and her prime minister sought clarification about several articles in the main treaty that stated "foreign relations" would be controlled by a French resident and referenced "establishments" at Diego-Suarez Bay. Two key French negotiators, Minister Patrimonio and Admiral Miot, provided an explanation affixed to the treaty as an annex, which led the rulers of Madagascar to deem the treaty an adequate enough safeguard of their nation's sovereignty to warrant their approval and signature. However, the official treaty was published in Paris without the annex or any reference to it. When the annex was later published in London, the French denied it had any legal validity. France declared a protectorate over the island despite the opposition of the Malagasy government and the omission of this term from the treaty.

The international reaction to this latest turn of events was varied and greatly colored by national interests. The British were unwilling to defend Madagascar's sovereignty for fear that the French might retaliate and fail to recognize the British claim to certain protectorates of its own. All official British engagement with Madagascar was henceforth transacted through the French resident, but these communiques were not officially recognized by Ranavalona and her court. The United States and Germany, on the other hand, continued to deal directly with the queen's government as the rightful authority in Madagascar. This discrepancy forced a reinterpretation of one aspect of the treaty, resulting in the queen's authority over internal affairs being maintained.
In 1886 the queen attempted to solicit the support of the United States in preserving Madagascar's sovereignty by sending gifts to then-President Grover Cleveland, including silk "akotofahana" cloths, an ivory pin and a woven basket. However, the United States was neither able nor inclined to assert itself militarily or diplomatically in favor of preserving Madagascar's independence. Ranavalona signed a treaty granting further concessions to the French on December 12, 1887.

France's claim to Madagascar as its protectorate was officially recognized by Britain in the Anglo-French agreement of 1890. Between 1890 and 1894, the French sought to aggressively claim what they believed to be the territorial rights established by the treaty. However, these French land claims and settlements were perceived by Ranavalona and Rainilaiarivony as an unjustifiable encroachment upon Malagasy sovereignty. Ultimately Charles Le Myre de Vilers was sent to persuade the queen and her prime minister to submit to the French interpretation of the treaty with the intent to launch a war and take the island by force if an agreement was not reached. The French offer was flatly refused and diplomatic relations between France and Madagascar were broken off in November 1894.

Upon terminating diplomatic relations, the French bombarded and occupied the harbor of Toamasina on the east coast in December 1894, then captured Mahajanga on the west coast the following month and immediately began their gradual advance, constructing roads through the malarial swamps that hindered passage to the island's interior. The main expeditionary troops arrived in May. Over 6,000 of the original 15,000 French soldiers lost their lives to disease as they gradually moved inland, necessitating several thousand reinforcements drawn from French colonies in Algeria and Sub-Saharan Africa. The column reached the capital in September 1895. For three days the Malagasy army managed to hold the French troops at the periphery of the city, but upon French bombardment of the Rova palace compound with heavy artillery, Ranavalona agreed to surrender control of her kingdom to the French.

France officially annexed Madagascar on January 1, 1896. That August, the French officially declared Madagascar to be their colony and exiled Prime Minister Rainilaiarivony to Algiers (in French Algeria) where he died the following year. The queen and much of her administration remained but were afforded no real political power. Shortly after Rainilaiarivony's exile, Ranavalona was approached by a French official who informed her that a new prime minister would need to be selected. The queen hastily concluded that General Jacques Duchesne, the French general who had successfully led the military campaign against the Merina monarchy, would be a probable choice. Assuming that Malagasy political tradition would be preserved, Ranavalona believed she would be forced to marry whichever man was chosen for the job and worriedly asked if Duchesne was to be her next husband. Surprised, the French official reassured her that France had no intention of imposing a husband on the queen and would never again require her to marry a prime minister. The queen's minister of foreign affairs, Rainitsimbazafy, was nominated to the post of prime minister by mutual consent.

In December 1895, two months after the French capture of Antananarivo, popular resistance to French rule emerged in the form of the "menalamba" ("red shawl") rebellion. This guerrilla war against foreigners, Christianity and political corruption quickly spread throughout the island and was principally conducted by peasants who wore shawls smeared with the red laterite soil of the highlands. The resistance movement gained ground until it was effectively put down by the French military at the end of 1897. Members of Ranavalona's court were accused of encouraging the rebels and many leading figures were executed, including the queen's uncle Ratsimamanga (brother of her favored adviser, Ramisindrazana) and her minister of war, Rainandriamampandry. Ramisindrazana, the queen's aunt, was exiled to Réunion, as the French were reluctant to execute a woman.

The resistance led the government of France to replace the island's civil governor, Hippolyte Laroche, with a military governor, Joseph Gallieni. The day before Gallieni arrived in Antananarivo, he had a message sent to the queen requiring her to present herself and her entourage at the military headquarters, preceded by a standard bearer carrying a French flag. The queen was obliged to sign documents handing over all royal property to France before being placed under arrest and imprisoned in her own palace. She was only allowed to receive visitors who had obtained prior authorization from Gallieni himself. While imprisoned, Ranavalona offered to convert to Roman Catholicism in an attempt to curry French favor but was informed that such a gesture was no longer necessary.

Gallieni exiled Ranavalona from Madagascar on February 27, 1897, and officially abolished the monarchy the next day. French officials ordered the queen to leave her palace at 1:30 in the morning. She was carried from Antananarivo by palanquin as the city slept, accompanied by 700–800 escorts and porters. Throughout the days spent traveling to the eastern port of Toamasina where she would board a ship to Réunion, Ranavalona reportedly drank heavily. At Toamasina on March 6, Ranavalona was notified that her sister Rasendranoro and aunt Ramasindrazana would be arriving shortly, as would the queen's fourteen-year-old niece, Razafinandriamanitra, who was nine months pregnant with the illegitimate child of a French soldier.

Together, the family sailed on "La Peyrouse" to the port of Pointe des Galets, a site twenty kilometers (12.5 miles) from the capital of St. Denis, to secure a discreet arrival. Despite this effort, a crowd of French onlookers jeered and shouted as the boat docked, angry at the queen for the loss of French lives incurred during France's campaign to occupy Madagascar. After waiting for the crowd to disperse, the captain escorted the queen and her party into a horse-drawn buggy, the first Ranavalona had ever seen, and drove to the Hotel de l'Europe in St. Denis. Young Razafinandriamanitra, suffering from the emotional and physical strains of the journey into exile, went into labor shortly after reaching the hotel. She gave birth to a little girl on her second day in Réunion, but could not recover her strength and died five days later. The infant was named Marie-Louise and was baptised a Catholic to avoid antagonizing the French. Marie-Louise, who could have become heir-apparent according to the traditional rules of succession, was adopted by Ranavalona as her own daughter.

Within a month the party had been moved to a house owned by a Madame de Villentroy, located at the corner of "rue de l'Arsenal" and "rue du Rempart" near the French government offices in St. Denis. Ranavalona was reportedly pleased with the two-story house, which had a large walled garden and featured a peaked roof and wrap-around veranda reminiscent of the traditional highland homes of Madagascar. In addition to the queen and her aunt, sister, and grand-niece, the royal household included two secretaries, a cook, a maid, three servants for Ranavalona, and several more servants for her aunt and sister. The queen's private pastor was authorized to make visits freely to the royal household.

The queen's party occupied the house in Réunion for just under two years. As tensions between England and France began to mount once again, this time over the conflict in Sudan, the French authorities became concerned that elements of the population in Madagascar might seize the opportunity to launch a new rebellion against French rule. The queen's proximity to Madagascar was seen as a possible source of encouragement for would-be Malagasy rebels. French authorities made an abrupt decision to remove Ranavalona and her party to Algeria, a more distant location. On February 1, 1899, with very little forewarning, Ranavalona and her family were ordered aboard the "Yang-Tse" accompanied by a secretary-interpreter and several maids. During the 28-day journey to the French port of Marseilles, the passengers stopped over at such ports as Mayotte, Zanzibar, Aden and Djibouti. Throughout the trip, the various captains responsible for the journey were under orders to prevent Ranavalona from speaking with anyone who was not French. The party was held for several months at Marseilles before being transferred to a villa in the Mustapha Superieur area in Algiers. Ranavalona had hoped to continue on to Paris and was greatly disappointed to learn she was instead being sent to Algeria, reportedly bursting into tears, crying like a baby, and remarking, "Who is certain of tomorrow? Only yesterday I was a queen; today I am simply an unhappy, broken-hearted woman."

At the queen's villa in Algiers, Ranavalona was provided with servants and a French female attendant who kept her under observation and remained present whenever the queen entertained guests in her home. In addition, the government of France initially provided Ranavalona with an annual allowance of 25,000 francs paid from the budget for the colony of Madagascar and authorized by the colony's Governor General. Nearly all the queen's property had been seized by the colonial authority, although she had been permitted to keep certain personal belongings, including some of her jewelry. Her initial pension allowed such a humble lifestyle that the colonial government of Algeria lobbied unsuccessfully several times on her behalf to obtain an increase for her. Ranavalona also tasked a servant with selling some of her jewelry for cash, but the plan was discovered by the French colonial authorities and the servant was discharged and sent back to Madagascar.

During the first years of her exile in Algeria, Ranavalona soon discovered the excitement of the socialite lifestyle among the elite of Algiers. She was regularly invited to parties, outings and cultural events and often hosted events of her own. However, homesickness was ever-present and the impossibility of visiting Madagascar contributed to melancholy and boredom. She would frequently take long walks alone in the countryside, along the beach, or through the town to clear her mind and lift her spirits. The queen was eager to see mainland France and especially Paris and repeatedly submitted formal requests for permission to travel. These were routinely denied until May 1901 when Ranavalona received the first of many authorizations to visit France. That very month, the queen moved into a small apartment in the 16th arrondissement of Paris near the Avenue Champs-Élysées and what is now the Place Charles de Gaulle, from which she visited the major sights of the city and was invited to numerous receptions, balls, shows and other events. She was widely received by high society with courtesy and admiration and was offered many gifts including a costly gown. During this first trip, Ranavalona visited the Palace of Versailles, was formally received at the Paris City Hall, and spent three weeks on vacation in Bordeaux. Finally, Ranavalona visited the beaches of Arcachon before exhausting her budget and boarding an Algeria-bound ship at Marseilles in early August. The details of her visit attracted much attention from the Parisian press, which expressed sympathy for the queen's fate and recrimination toward the French government for failing to provide a larger pension or accord her the consideration she deserved as a recipient of the Legion of Honor.
Ranavalona would return to France six more times over the course of the next twelve years. Her frequent visits and excellent reputation made her the "cause célèbre" of many French citizens who pitied the queen's fate and admired her gracious acceptance of her new life. Ranavalona's visits were generally accompanied by much media fanfare and the queen's popularity among the French public grew to the extent that she was featured on the box of "Petit Beurre" biscuits in 1916. The queen's second visit to France occurred in September 1903, when she visited Vic-sur-Cère and Aurillac. Pressure by citizens during this visit succeeded in raising her pension to 37,000 francs. Two years later she would visit Marseilles and Saint-Germain and inhabit a large five-bedroom Parisian apartment in the sixteenth arrondissement from which she would attend the Paris Opera, observe a session of the French House of Representatives and be formally received at the Ministry of the Colonies. Again due to pressure from sympathetic French citizens, Ranavalona's pension was further raised to 50,000 francs per annum. On her next visit in 1907, the queen would use Dives-sur-Mer as a home base to visit the Calvados region, where she was photographed for the French press. From August to September 1910, Ranavalona would visit Paris, Nantes, La Baule and Saint-Nazaire and was repeatedly the target of undesired attention from press photographers. Her 1912 trip to the tiny, remote village of Quiberville would coincide with the increase of her annual pension to 75,000 francs. The queen's final voyage in 1913 would take her to Marseilles, Aix-les-Bains and Allevard.

The advent of World War 1 in 1914 put an end to Ranavalona's visits to France. Throughout her time in Algeria, she and her family regularly attended the weekly Protestant service at the Reformed Church building in central Algiers. After the war began she sought to contribute by vigorously participating in the activities of the Algerian Red Cross.

Ranavalona died without ever having returned to Madagascar, after two formal requests in 1910 and 1912 were refused on the pretext of insufficient funds in the colonial coffers. The exiled queen died suddenly at her villa in Algeria on May 23, 1917, the victim of a severe embolism. Ranavalona was buried at the Saint-Eugene cemetery in Algiers at 10:00 a.m. on May 25. Her funeral was attended by dozens of personal friends, admirers, Red Cross colleagues, members of her church congregation and prominent figures of the political and cultural elite of Algiers. By nine in the morning, a long line of cars had already formed at the entrance to the memorial site.

This effusive display of respect and remembrance on the part of Ranavalona's friends was not mirrored by subsequent actions of the French colonial administration in Madagascar. In June 1925, eight years after the queen's death, the Governor-General of Algeria informed the Governor-General of Madagascar by letter that payments for the maintenance of Ranavalona's tomb were in default. He urged the colonial government in Madagascar to provide funds for the upkeep of the dilapidated tomb, emphasizing that such neglect was unworthy of the queen's memory and the government of France alike. The request was twice refused and the tomb was never refurbished. In November 1938, Ranavalona's remains were exhumed and re-interred in the tomb of Queen Rasoherina at the Rova of Antananarivo in Madagascar. A fire on the night of 6 November 1995 severely damaged the royal tombs and destroyed most of the other buildings at the site. The "lamba"-wrapped remains of Ranavalona III were the only ones that could be saved from the flames. These have since been re-interred in the royal tombs at Ambohimanga.

Following Ranavalona's death, her aunt Ramasindrazana left Algeria and moved to Alpes-Maritimes where she lived out the few remaining years of her life. The heir-apparent, Marie-Louise, had left Ranavalona's villa several years earlier to study at a French high school and would go on to marry a French agricultural engineer named Andre Bosshard on June 24, 1921. Although she continued to receive a small pension from the French government throughout her lifetime, Marie-Louise chose to pursue a career as a nurse and was awarded the Legion of Honor for her medical services during World War II. After Bosshard and the childless Marie-Louise divorced, the young woman reportedly made the most of her new-found freedom as a flamboyant and vivacious socialite. Marie-Louise died in Bazoches-sur-le-Betz on January 18, 1948, without leaving any descendants, and was buried in Montreuil, France.







</doc>
<doc id="272599" url="https://en.wikipedia.org/wiki?curid=272599" title="Aylesbury duck">
Aylesbury duck

The Aylesbury duck is a breed of domesticated duck, bred mainly for its meat and appearance. It is a large duck with pure white plumage, a pink bill, orange legs and feet, an unusually large keel, and a horizontal stance with its body parallel to the ground. The precise origins of the breed are unclear, but raising white ducks became popular in Aylesbury, Buckinghamshire, England, in the 18th century owing to the demand for white feathers as a filler for quilts. Over the 19th century selective breeding for size, shape and colour led to the Aylesbury duck.

Duck rearing became a major industry in Aylesbury in the 19th century. The ducks were bred on farms in the surrounding countryside. Fertilised eggs were brought into the town's "Duck End", where local residents would rear the ducklings in their homes. The opening of a railway to Aylesbury in 1839 enabled cheap and quick transport to the markets of London, and duck rearing became highly profitable. By the 1860s the duck rearing industry began to move out of Aylesbury into the surrounding towns and villages, and the industry in Aylesbury itself began to decline.

In 1873 the Pekin duck was introduced to the United Kingdom. Although its meat was thought to have a poorer flavour than that of the Aylesbury duck, the Pekin was hardier and cheaper to raise. Many breeders switched to the Pekin duck or to Aylesbury-Pekin crosses. By the beginning of the 20th century competition from the Pekin duck, inbreeding, and disease in the pure-bred Aylesbury strain and the rising cost of duck food meant the Aylesbury duck industry was in decline.

The First World War badly damaged the remaining duck industry in Buckinghamshire, wiping out the small scale producers and leaving only a few large farms. Disruption caused by the Second World War further damaged the industry. By the 1950s only one significant flock of Aylesbury ducks remained in Buckinghamshire, and by 1966 there were no duck-breeding or -rearing businesses of any size remaining in Aylesbury itself. Although there is only one surviving flock of pure Aylesbury ducks in the United Kingdom and the breed is critically endangered in the United States, the Aylesbury duck remains a symbol of the town of Aylesbury, and appears on the coat of arms of Aylesbury and on the club badge of Aylesbury United.

The precise origin of the Aylesbury duck is unclear. Before the 18th century, duck breeds were rarely recorded in England, and the common duck, bred for farming, was a domesticated form of the wild mallard. The common duck varied in colour, and as in the wild, white ducks would occasionally occur. White ducks were particularly prized, as their feathers were popular as a filler for quilts.

In the 18th century selective breeding of white common ducks led to a white domestic duck, generally known as the English White. Since at least the 1690s ducks had been farmed in Aylesbury, and raising English Whites became popular in Aylesbury and the surrounding villages. By 1813 it was remarked that "ducks form a material article at market from Aylesbury and places adjacent: they are white, and as it seems of an early breed: they are bred and brought up by poor people, and sent to London by the weekly carriers". The duck farmers of Aylesbury went to great lengths to ensure the ducks retained their white colouring, keeping them clear of dirty water, soil with a high iron content and bright sunlight, all of which could discolour the ducks' feathers. Over time, selective breeding of the English White for size and colour gradually led to the development of the Aylesbury duck.

A rather large duck breed, the Aylesbury duck has pure white plumage and bright orange legs and feet. Its legs are placed midway along the body and it stands with its underside parallel to the ground, giving it a body described as "boat-shaped". It has a relatively long and thin swan-like neck, and a long pink bill which comes straight out from the head.

An Aylesbury duckling incubates in the egg for 28 days. Until eight weeks after hatching, the time of their first moult, ducks and drakes (females and males) are almost indistinguishable. After moulting, males have two or three curved tail feathers and a fainter, huskier quack than the female. By one year of age, females and males grow to an average weight of respectively, although males can reach around .

Unlike the Rouen duck, the other popular meat variety in England in the 19th century, Aylesbury ducks lay eggs from early November. Aylesbury ducks fatten quickly and by eight weeks after hatching weigh up to , large enough to eat but still young and extremely tender. Consequently, their meat came onto the market from February onwards, after the close of the game season but before the earliest spring chickens were on sale. Rouen ducks, whose mallard-like coloration made them less valuable, lay eggs from early February and take six months to grow large enough to eat. As a consequence, Aylesbury ducks were sold primarily in the spring and summer, and Rouen ducks in the autumn and winter.

Unlike most livestock farming in England at this time, the duck breeders and duck rearers of Aylesbury formed two separate groups. Stock ducks—i.e., ducks kept for breeding—were kept on farms in the countryside of the Aylesbury Vale, away from the polluted air and water of the town. This kept the ducks healthy, and meant a higher number of fertile eggs.

Stock ducks would be chosen from ducklings hatched in March, with a typical breeder keeping six males and twenty laying females at any given time. The females would be kept for around a year before mating, typically to an older male. They would then generally be replaced, to reduce the problems of inbreeding. Stock ducks were allowed to roam freely during the day, and would swim in local ponds which, although privately owned, were treated as common property among the duck breeders; breeders would label their ducks with markings on the neck or head. The stock ducks would forage for greenery and insects, supplemented by greaves (the residue left after the rendering of animal fat). As ducks lay their eggs at night, the ducks would be brought indoors overnight.
Female Aylesbury ducks would not sit still for the 28 days necessary for their eggs to hatch, and as a consequence the breeders would not allow mothers to sit on their own eggs. Instead the fertilised eggs would be collected and transferred to the "duckers" of Aylesbury's Duck End.

The duckers of Aylesbury would buy eggs from the breeders, or be paid by a breeder to raise the ducks on their behalf, and would raise the ducklings in their homes between November and August as a secondary source of income. Duckers were typically skilled labourers, who invested surplus income in ducklings. Many of the tasks related to rearing the ducks would be carried out by the women of the household, particularly the care of newly hatched ducklings.

The eggs would be divided into batches of 13, and placed under broody chickens. In the last week of the four-week incubation period the eggs would be sprinkled daily with warm water to soften the shells and allow the ducklings to hatch.

Newly hatched Aylesbury ducklings are timid and thrive best in small groups, so the duckers would divide them into groups of three or four ducklings, each accompanied by a hen. As the ducklings grew older and gained confidence, they would be kept in groups of around 30. Originally the ducks would be kept in every room in the ducker's cottage, but towards the end of the 19th century they were kept in outdoor pens and sheds with suitable protection against cold weather.

The aim of the ducker was to get every duckling as fat as possible by the age of eight weeks (the first moult, the age at which they would be killed for meat), while avoiding any foods which would build up their bones or make their flesh greasy. In their first week after hatching, the ducklings would be fed on boiled eggs, toast soaked in water, boiled rice and beef liver. From the second week on, this diet would gradually be replaced by barley meal and boiled rice mixed with greaves. (Some larger-scale duckers would boil a horse or sheep and feed this to the ducklings in place of greaves.) This high-protein diet was supplemented with nettles, cabbage and lettuce to provide a source of vitamins. As with all poultry, ducks require grit in their diet to break up the food and make it digestible. Aylesbury ducklings' drinking water was laced with grit from Long Marston and Gubblecote; this grit also gave their bills their distinctive pinkish colour. Around 85% of ducklings would survive this eight-week rearing process to be sent to market.
While ducks are naturally aquatic, swimming can be dangerous to young ducklings, and it can also restrict a duck's growth. Thus, although duckers would ensure the ducklings always had a trough or sink to paddle in, the ducklings would be kept away from bodies of water while they were growing. The exception was shortly before slaughter, when the ducklings would be taken for one swim in a pond, as it helped them to feather properly.

Although there were a few large-scale duck rearing operations in Aylesbury, raising thousands of ducklings each season, the majority of Aylesbury's duckers would raise between 400 and 1,000 ducklings each year. Because ducking was a secondary occupation, it was not listed in Aylesbury's census returns or directories and it is impossible to know how many people were engaged in it at any given time. Kelly's Directory for 1864 does not list a single duck farmer in Aylesbury, but an 1885 book comments that: 
The Duck End was one of the poorer districts of Aylesbury. Until the end of the 19th century it had no sewers or refuse collections. The area had a number of open ditches filled with stagnant water, and outbreaks of malaria and cholera were common. The cottages had inadequate ventilation and lighting, and no running water. Faeces from the duck ponds permeated the local soil and seeped into the cottages through cracks in the floors.

When the ducklings were ready for slaughter, the duckers would generally kill them on their own premises. The slaughter would generally take place in the morning, to ensure the ducks would be ready for market in the evening. To keep the meat as white as possible, the ducks would be suspended upside down and their necks broken backwards, and held in this position until their blood had run towards their heads. They were kept in this position for ten minutes before being plucked, as otherwise their blood would collect in those parts of the body from which the feathers had been plucked. The plucking was generally carried out by the women of the household. The plucked carcasses would be sent to market, and the feathers would be sold direct to London dealers.

The market for duck meat in Aylesbury itself was small, and the ducks were generally sent to London for sale. By the 1750s Richard Pococke recorded that four cartloads of ducks were sent from Aylesbury to London every Saturday, and in the late 18th and early 19th centuries the ducks continued to be sent over the Chiltern Hills to London by packhorse or cart.

On 15 June 1839 the entrepreneur and former Member of Parliament for Buckingham, Sir Harry Verney, 2nd Baronet, opened the Aylesbury Railway. Built under the direction of Robert Stephenson, it connected the London and Birmingham Railway's Cheddington railway station on the West Coast Main Line to Aylesbury High Street railway station in eastern Aylesbury. On 1 October 1863 the Wycombe Railway also built a line to Aylesbury, from Princes Risborough railway station to a station on the western side of Aylesbury (the present-day Aylesbury railway station). The arrival of the railway had a powerful impact on the duck industry, and up to a ton of ducks in a night were being shipped from Aylesbury to Smithfield Market in London by 1850.

A routine became established in which salesmen would provide the duckers with labels. The duckers would mark their ducklings with the labels of the firm to whom they wished them to be sold in London. The railway companies would collect ducklings, take them to the stations, ship them to London and deliver them to the designated firms, in return for a flat fee per bird. By avoiding the need for the duckers to travel to market, or the London salesmen to collect the ducklings, this arrangement benefited all concerned, and ducking became very profitable. By 1870 the duck industry was bringing over £20,000 per year into Aylesbury; a typical ducker would make a profit of around £80–£200 per year.

In 1845, the first National Poultry Show was held, at the Zoological Gardens in London; one of the classes of poultry exhibited was "Aylesbury or other white variety". The personal interest of Queen Victoria in poultry farming, and its inclusion in the Great Exhibition of 1851, further raised public interest in poultry. From 1853 the Royal Agricultural Society and the Bath and West of England Society, the two most prominent agricultural societies in England, included poultry sections in their annual agricultural shows. This in turn caused smaller local poultry shows to develop across the country.

Breeders would choose potential exhibition ducks from among newly hatched ducklings in March and April, and they would be given a great deal of extra attention. They would be fed a carefully controlled diet to get them to the maximum weight, and would be allowed out for a few hours each day to keep them in as good a physical condition as possible. Before the show, their legs and feet would be washed, their bills trimmed with a knife and sandpapered smooth, and their feathers brushed with linseed oil. While most breeders would give the ducks a healthy meal before the show to calm them, some breeders would force-feed the ducks with sausage or worms, to get them to as heavy a weight as possible. Exhibition standards judged an Aylesbury duck primarily on size, shape and colour. This encouraged the breeding of larger ducks, with pronounced exaggerated keels, and loose baggy skin. By the beginning of the 20th century the Aylesbury duck had diverged into two separate strains, one bred for appearance and one for meat.

In 1873 the Pekin duck was introduced from China to Britain for the first time. Superficially similar in appearance to an Aylesbury duck, a Pekin is white with orange legs and bill, with its legs near the rear, giving it an upright stance while on land. Although not thought to have such a delicate flavour as the Aylesbury, the Pekin was hardier, a more prolific layer, fattened more quickly, and was roughly the same size as an Aylesbury at nine weeks.

Aylesbury ducks, meanwhile, were becoming inbred, meaning fertile eggs were scarcer and the ducks were more susceptible to disease. Exhibition standards had led to selection for an exaggerated keel by breeders, despite it being unpopular with dealers and consumers. Poultry show judges also admired the long neck and upright posture of Pekin ducks over the boat-like stance of the Aylesbury. Some of the breeders in the Aylesbury area began to cross Pekin ducks with the pure Aylesbury strain. Although the Aylesbury-Pekin cross ducks did not have the delicate flavour of the pure Aylesbury, they were hardier and much cheaper to raise.

Until the mid-19th century duck rearing was concentrated on the Duck End, but by the 1860s it had spread to many other towns and villages in the area, particularly Weston Turville and Haddenham. Contamination of Aylesbury's soil by years of duck rearing, and new public health legislation which ended many traditional practices, caused the decline of the duck rearing industry in the Duck End, and by the 1890s the majority of Aylesbury ducks were raised in the villages rather than the town itself. Population shifts and the improved national rail network reduced the need to rear ducks near London, and large duck farms opened in Lancashire, Norfolk and Lincolnshire. Although the number of ducks raised nationwide continued to grow, between 1890 and 1900 the number of ducks raised in the Aylesbury area remained static, and from 1900 it began to drop.

By the time Beatrix Potter's 1908 "The Tale of Jemima Puddle-Duck"—about an Aylesbury duck although set in Cumbria—caused renewed interest in the breed, the Aylesbury duck was in steep decline. The duckers of Buckinghamshire had generally failed to introduce technological improvements such as the incubator, and inbreeding had dangerously weakened the breed. Meanwhile, the cost of duck food had risen fourfold over the 19th century, and from 1873 onwards competition from Pekin and Pekin cross ducks was undercutting Aylesbury ducks at the marketplace.

The First World War devastated the remaining duckers of Buckinghamshire. The price of duck food rose steeply while the demand for luxury foodstuffs fell, and wartime restructuring ended the beneficial financial arrangements with the railway companies. By the end of the war small-scale duck rearing in the Aylesbury Vale had vanished, with duck raising dominated by a few large duck farms. Shortages of duck food in the Second World War caused further disruption to the industry, and almost all duck farming in the Aylesbury Vale ended. A 1950 "Aylesbury Duckling Day" campaign to boost the reputation of the Aylesbury duck had little effect; by the end of the 1950s the last significant farms had closed, other than a single flock in Chesham owned by Mr L. T. Waller, and by 1966 there were no duck breeders or rearers of any size remaining in Aylesbury. the Waller family's farm in Chesham remains in business, the last surviving flock of pure Aylesbury meat ducks in the country.

Aylesbury ducks were imported into the United States in 1840, although they never became a popular breed. They were, however, added to the American Poultry Association's "Standard of Perfection" breeding guidelines in 1876. As of 2013, the breed was listed as critically endangered in the United States by The Livestock Conservancy.

The Aylesbury duck remains a symbol of the town of Aylesbury. Aylesbury United F.C. are nicknamed "The Ducks" and include an Aylesbury duck on their club badge, and the town's coat of arms includes an Aylesbury duck and plaited straw, representing the two historic industries of the town. The Aylesbury Brewery Company, now defunct, featured the Aylesbury duck as its logo, an example of which can still be seen at the Britannia pub. Duck Farm Court is a shopping area of modern Aylesbury located near the historic hamlet of California, close to one of the main breeding grounds for ducks in the town, and there have been two pubs in the town with the name "The Duck" in recent years; one in Bedgrove that has since been demolished and one in Jackson Road that has recently been renamed.




</doc>
<doc id="272980" url="https://en.wikipedia.org/wiki?curid=272980" title="Texas Tech University">
Texas Tech University

Texas Tech University, often referred to as Texas Tech, Tech, or TTU, is a public research university in Lubbock, Texas. Established on , and originally known as Texas Technological College, it is the flagship institution of the four-institution Texas Tech University System. The university's student enrollment is the seventh-largest in Texas as of the Fall 2017 semester. The university shares its campus with Texas Tech University Health Sciences Center, making it the only campus in Texas to house an undergraduate university, law school, and medical school.

The university offers degrees in more than 150 courses of study through 13 colleges and hosts 60 research centers and institutes. Texas Tech University has awarded over 200,000 degrees since 1927, including over 40,000 graduate and professional degrees. The Carnegie Foundation classifies Texas Tech as having "highest research activity". Research projects in the areas of epidemiology, pulsed power, grid computing, nanophotonics, atmospheric sciences, and wind energy are among the most prominent at the university. The Spanish Renaissance-themed campus, described by author James Michener as "the most beautiful west of the Mississippi until you get to Stanford", has been awarded the Grand Award for excellence in grounds-keeping, and has been noted for possessing a public art collection among the ten best in the United States.

The Texas Tech Red Raiders are charter members of the Big 12 Conference and compete in Division I for all varsity sports. The Red Raiders football team has made 36 bowl appearances, which is 17th most of any university. The Red Raiders basketball team has made 14 appearances in the NCAA Division I Tournament. Bob Knight has coached the second most wins in men's NCAA Division I basketball history and served as the team's head coach from 2001 to 2008. The Lady Raiders basketball team won the 1993 NCAA Division I Tournament. In 1999, Texas Tech's Goin' Band from Raiderland received the Sudler Trophy, which is awarded to "recognize collegiate marching bands of particular excellence".

Although the majority of the university's students are from the southwestern United States, the school has served students from all 50 states and more than 100 countries. Texas Tech University alumni and former students have gone on to prominent careers in government, business, science, medicine, education, sports, and entertainment.

The call to open a college in West Texas began shortly after settlers arrived in the area in the 1880s. In 1917, the Texas legislature passed a bill creating a branch of Texas A&M to be in Abilene. However, the bill was repealed two years later during the next session after it was discovered Governor James E. Ferguson had falsely reported the site committee's choice of location. After new legislation passed in the state house and senate in 1921, Governor Pat Neff vetoed it, citing hard financial times in West Texas. Furious about Neff's veto, some in West Texas went so far as to recommend West Texas secede from the state.

In 1923, the legislature decided, rather than a branch campus, a new university would better serve the region's needs under legislation co-authored by State Senator William H. Bledsoe of Lubbock and State Representative Roy Alvin Baldwin of Slaton in southern Lubbock County. On February 10, 1923, Neff signed the legislation creating Texas Technological College, and in July of that year, a committee began searching for a site. When the committee's members visited Lubbock, they were overwhelmed to find residents lining the streets to show support for hosting the institution. That August, Lubbock was chosen on the first ballot over other area towns, including Floydada, Plainview, Big Spring, and Sweetwater.

Construction of the college campus began on November 1, 1924. Ten days later, the cornerstone of the Administration Building was laid in front of 20,000 people. Governor Pat Neff, Amon G. Carter, Reverend E. E. Robinson, Colonel Ernest O. Thompson, and Representative Richard M. Chitwood, the chairman of the House Education Committee, who became the first Texas Tech business manager, spoke at the event. Chitwood served in the position only fifteen months; he died in November 1926. With an enrollment of 914 students—both men and women—Texas Technological College opened for classes on October 1, 1925. It was originally composed of four schools—Agriculture, Engineering, Home Economics, and Liberal Arts.

Texas Tech grew slowly in the early years. During the 1930s, Bradford Knapp, the university's second president, proceeded with an expansion program, which included new dormitories, the first library (now the mathematics building), a golf course, a swimming pool, paved streets and alleys, and landscaping. A proposed $80,000 allocation for a football stadium was shelved. The library won the approval of Governor James V. Allred. Because the state cut appropriations by 30% at the start of the Great Depression, President Knapp applied for assistance from the major New Deal agencies to expand Texas Tech, including the Works Progress Administration, Public Works Administration (PWA), Civil Works Administration, and the National Youth Administration. Wyatt C. Hedrick, son-in-law of Governor Ross S. Sterling, was the architect of all campus PWA projects.

Military training was conducted at the college as early as 1925, but formal Reserve Officers' Training Corps training did not start until 1936. By 1939, the school's enrollment had grown to 3,890. Although enrollment declined during World War II, Texas Tech trained 4,747 men in its armed forces training detachments. Following the war, in 1946, the college saw its enrollment leap to 5,366 from a low of 1,696 in 1943.

By the 1960s, the school had expanded its offerings to more than just technical subjects. The Faculty Advisory Committee suggested changing the name to "Texas State University", feeling the phrase "Technological College" did not define the institution's scope. While most students supported this change, the Board of Directors and many alumni, wanting to preserve the Double T, opposed it. Other names—University of the Southwest, Texas Technological College and State University, and The Texas University of Art, Science and Technology—were considered, but the Board of Directors chose Texas Tech University, submitting it to the state legislature in 1964.

A failed move by Governor John Connally to have the school placed into the Texas A&M University System, as well as continued disagreement and heated debate over the school's new name, kept the name change from being approved. In spite of objections by many students and faculty, the Board of Directors again submitted the change in 1969. It finally received the legislature's approval on June 6 and the name Texas Tech University went into effect that September. All of the institution's schools, except Law, became colleges.

Texas Tech was integrated in 1961 when three African-American students were admitted. After its initial rejection of the students' enrollment and the threat of a lawsuit, the university enacted a policy to admit "all qualified applicants regardless of color". The university offered its first athletic scholarship to a black student in 1967, when Danny Hardaway was recruited to play for the Red Raiders football team. In 1970, Hortense W. Dixon became the first African American student to earn a doctorate from the university.

In the 1960s and 1970s, the university invested US$150 million in the campus to construct buildings for the library, foreign languages, social sciences, communications, philosophy, electrical and petroleum engineering, art, and architecture. Some other buildings were significantly expanded.

On May 29, 1969, the 61st Texas Legislature created the Texas Tech University School of Medicine. The Texas Legislature expanded the medical school charter in 1979, creating the Texas Tech University Health Sciences Center. TTUHSC, which is now part of the Texas Tech University System, includes Schools of Allied Health Sciences, Medicine, Nursing, Pharmacy, and the Graduate School of Biomedical Sciences. It has locations in four Texas cities in addition to the main campus in Lubbock.

In 2011, the combined enrollment in the Texas Tech University System was greater than 42,000 students—a 48% increase since 2000. Chancellor Kent Hance reiterated plans for Texas Tech's main campus to reach enrollment of 40,000 students by 2020, with additional 5,000 students at Texas Tech University Health Sciences Center and 10,000 students at Angelo State University.

In 1996, the Board of Regents of Texas Tech University created the Texas Tech University System. Former State Senator John T. Montford, later of San Antonio, was selected as the first chancellor to lead the combined academic enterprise. Regents Chair Edward Whitacre Jr. stated the move was made due to the institution's size and complexity. "It's time", he said, "to take the university into the 21st century". The Texas Tech University system originally included Texas Tech University and Texas Tech University Health Sciences Center. On November 6, 2007, the voters of Texas approved an amendment to the Texas Constitution realigning Angelo State University with the Texas Tech University System. Kent Hance, a Texas Tech graduate who had served as United States Representative and as one of the three elected members of the Texas Board which regulates the oil-and-gas industry, assumed the duties of chancellor on December 1, 2006.

Although growth continued at Texas Tech, the university was not immune to controversy. In 2003, a third-year student at the Texas Tech School of Law filed suit against the university over its policy on free speech zones, which restricted student speech to a single "free speech gazebo". The following year, a federal judge declared the policy unconstitutional.

To meet the demands of its increased enrollment and expanding research, the university has invested more than $548 million in new construction since 2000. It has also received more than $65.9 million in private donations. In April 2009, the Texas House of Representatives passed a bill to increase state funding for seven public universities. Texas Tech University is classified by the state as an "Emerging Research University", and is among the universities that will receive additional state funding for advancement toward "Tier 1" status. Three funds—the Research University Development Fund, the Texas Research Incentive Program, and the National Research University Benchmark Fund—have been established and will provide $500 million in grants and matching funds during fiscal years 2010 and 2011. On September 2, 2009, the university announced it had received private gifts totaling $24.3 million. Of these, $21.5 million are eligible for match under the Texas Research Incentive Program. In January 2016, Duane Nellis resigned from the position of President and was replaced by interim President John Opperman.

In late 2011 and throughout 2012–13, construction began on a several new buildings on campus. The construction included a new $20 million Petroleum Engineering and Research building, a new building to house the Rawls College of Business, two new residence halls, a $3.5 million chapel, and extensive remodeling of the building that previously housed the Rawls College of Business.

The school's endowment surpassed the $1 billion barrier for the first time in March 2014 at $1,043,000,000.

By enrollment, Texas Tech is the seventh-largest university in Texas and the largest institution of higher education in the western two-thirds of the state. In the Fall 2014 semester, Texas Tech set a record enrollment with 35,134 students. For the 2014 enrollment year, most students came from Texas (95.17%), followed by New Mexico, California, Colorado, Oklahoma, and Florida. Altogether, the university has educated students from all 50 US states and over 100 foreign countries. Enrollment has continued to increase in recent years, and growth is on track with a plan to have 40,000 students by the year 2020. From 1927 to 2011, the university awarded 173,551 bachelor's, 34,541 master's, 5,906 doctoral, and 7,092 law degrees.

The Princeton Review ranked Texas Tech among the 125 best colleges in the Western United States in its 2015 edition. The 2016 "U.S. News & World Report" rankings listed the university at 168th nationally and 91st amongst public schools. The 2013 Shanghai Jiao Tong Rankings placed Texas Tech University at 401 worldwide, which tied it with fellow Big 12 schools, Oklahoma and Kansas State, among others. In 2010, the "Wall Street Journal" ranked the university 18th in its ranking of graduate desirability for job recruiters. Three of the University's undergraduate programs are ranked by PayScale as in the top 20 nationally in mid-career salary: Art, Physical and Life Sciences, and Education. In its 2015 edition, "U.S. News & World Report" noted the university has a "selective" admissions policy. As a state public university, Texas Tech is subject to Texas House Bill 588, which guarantees Texas high school seniors in the top 10% of their graduating class admission to any public Texas university. In 2012, 20.3% of incoming freshmen were admitted in this manner. About half of incoming freshmen finished in the top quarter of their graduating classes. In 2016, the Carnegie Classification of Institutions of Higher Education listed Texas Tech among 115 most prominent research schools, commonly known as "Carnegie Tier One".

Texas Tech University is accredited by the Southern Association of Colleges and Schools. The university offers 150 bachelor's, 104 master's, and 59 doctoral degree programs. Texas Tech has five satellite campuses located in Texas—in Abilene, Amarillo, Fredericksburg, Highland Lakes, and Junction. Texas Tech also has a satellite campus in Europe, located in Seville, Spain. Additional study-abroad programs are offered in various countries, such as Denmark, England, France, and Italy.

The Office of International Affairs supports and facilitates the international mission of Texas Tech University. It provides services for faculty and students, offers international educational and cultural experiences for the school and community, and contributes to the university's globalization process and its effort to grow as an international educational and research center. The International Cultural Center provides a continual series of conferences, lectures, art exhibitions, and performances.

Texas Tech has expanded from its original four schools to comprise ten colleges and two schools. In 2008, the College of Agricultural Sciences and Natural Resources ranked among the 30 largest schools of agriculture in the country by enrollment.

In the 2015 "U.S. News & World Report" report on higher education, the Whitacre College of Engineering was ranked 94th in the nation. In 2009, the college's Petroleum Engineering Department was ranked 10th best in the nation. The college offers 11 engineering programs accredited by the Accreditation Board for Engineering and Technology. On November 12, 2008, following a $25 million gift from AT&T in honor of alumnus Edward Whitacre Jr., the college was formally renamed the Edward E. Whitacre Jr. College of Engineering.

The largest academic division on campus, the College of Arts and Sciences offers bachelor's, master's, and doctoral degrees in a wide range of subjects from philosophy to mathematics. In 2004, the College of Mass Communications and the College of Visual and Performing Arts were created from programs organized within the College of Arts and Sciences. The College of Mass Communications officially changed its name to the College of Media & Communication in 2012 and offers degrees in several areas, including advertising, journalism and electronic media, and public relations. The College of Visual and Performing Arts was renamed in honor of the contributions by the J. T. & Margaret Talkington Foundation in 2016; Programs offered through Talkington College are accredited by the National Association of Schools of Art and Design, the National Association of Schools of Music, and the National Association of Schools of Theatre.

Once the Division of Home Economics, the College of Human Sciences now offers degrees in applied and professional studies, design, human development, nutrition, hospitality, and retailing. The College of Human Sciences' Department of Personal Financial Planning was ranked in 2011 as the top program out of ten standout programs by the industry newsletter, "Financial Planning". The College of Architecture, founded in 1927, offers programs accredited by the National Architectural Accrediting Board.

The Rawls College of Business, which is accredited by the Association to Advance Collegiate Schools of Business, is the university's business school. The college offers bachelor's, master's, and doctoral degrees in business disciplines. In its 2016 "Best Grad Schools" rankings, "U.S. News & World Report" ranked the graduate business program 91st in the United States. The college's health organization management degree program was ranked 41st. From its origin in 1942, the business school was known as the Division of Commerce, until it was renamed the College of Business Administration in 1956. In 2000, following a $25 million gift from alumnus Jerry S. Rawls, the college was formally renamed the Jerry S. Rawls College of Business Administration.

In 1967, both the College of Education and the Texas Tech University School of Law were founded. The College of Education instructs future teachers and is accredited by the National Council for Accreditation of Teacher Education. The School of Law is an American Bar Association-accredited law school on the main campus in Lubbock, and came in 2nd statewide in the 2013 Bar Examination pass rate with 95.45 percent. The school offers Juris Doctor degrees which can be earned in conjunction with Master of Business Administration or Master of Science degrees through the adjacent Rawls College of Business.

All graduate programs offered at Texas Tech University are overseen by the Graduate School, which was officially established in 1954. The university's Honors College allows select students to design a customized curriculum that incorporates a broad range of disciplines, and offers students the opportunity for early admission into Texas Tech University's medical and law schools.

In September 2008, the University College was established. Formerly known as the College of Outreach and Distance Education, the college was created by bringing together the Division of Off-Campus Sites and the Division of Outreach and Distance Education. Texas Tech's six in-state satellite campuses are under the auspices of the college. Additionally, it oversees the Texas Tech University Independent School District.

The Texas Tech University System also operates a medical school, the Texas Tech University Health Sciences Center. It offers Schools of Allied Health Sciences, Biomedical Sciences, Medicine, Nursing, and Pharmacy. While it is a discrete entity, separate from Texas Tech University, it offers joint degrees (such as MD/MBA) through coordination with the university. Further, the Health Sciences Center is located on the university's main campus in Lubbock. In addition to the Lubbock campus, TTUHSC has campuses located in Abilene, Amarillo, El Paso, Dallas, and Odessa.

Classified by the Carnegie Foundation in 2016 as one of only 115 research universities with "highest activity", Texas Tech University hosts 71 research centers and institutes. In 2008, a team of researchers from Texas Tech University and Harvard University announced the development of an siRNA-based treatment that may ultimately counteract the human immunodeficiency virus (HIV). Human cells infected with HIV, injected into rats, have been cured by the experimental treatment. Clinical trials on humans are expected to begin by 2010. Texas Tech researchers also hold the exclusive license for HemoTech, a human blood substitute composed of bovine hemoglobin. HemoBioTech, the company marketing the technology, believes HemoTech will diminish the intrinsic toxicities that have stifled previous attempts to develop a human blood substitute. On January 14, 2008, Texas Tech University announced the creation of the West Texas Influenza Research Center. The university has concluded human clinical testing of oral interferon in a five-year study of idiopathic pulmonary fibrosis and continues its study of chronic obstructive pulmonary disease.

Following the May 11, 1970, Lubbock Tornado that caused 26 fatalities and over $ (2013 dollars) in damage in Lubbock, the National Wind Institute (formerly the Wind Science and Engineering Research Center or WISE) was established. The National Wind Institute Center, which includes of indoor laboratory space, is focused on research, education, and information outreach. The interdisciplinary research program studies methods to exploit the beneficial qualities of wind and to mitigate its detrimental effects. The center offers education in wind science and engineering to develop professionals who are experts in creating designs which deal effectively with problems caused by high winds. The Center instituted the nation's first Ph.D program in Wind Science and Engineering in 2003. National Wind Institute researchers contributed significantly to the development of the Enhanced Fujita Scale for rating the strength of tornadoes.
Texas Tech has made numerous contributions to NASA projects. Daniel Cooke, Computer Science Department Chair, and his colleagues are working to develop the technical content of the Intelligent Systems Program, and have been awarded a five-year budget valued at $350 million. University scientists have also teamed with NASA's guidance, navigation, and control engineers to develop the Onboard Abort Executive (OAE), software capable of quickly deciding the best course of action during an ascent failure. The Texas Tech Space Research Initiative has also partnered with NASA to perfect methods for growing fresh vegetables in space and to determine the most efficient ways to recycle wastewater. In November 1996, the university dedicated the Charles A. Bassett II Pulse Laboratory to honor engineering alumnus and Gemini-era astronaut Charles A. Bassett II. In total, Texas Tech has helped to produce three astronauts: Bassett, Paul Lockhart, and Rick Husband; Husband was commander of STS-107, the final flight of Space Shuttle "Columbia".

In 2008, the pulsed power electronics laboratory received $4 million in federal funding. Among other things, the money will be used to create compact generators for weapon systems designed to destroy improvised explosive devices (IEDs). The College of Engineering's Nano Tech Center has received approximately $20 million in grants toward its work in applied nanophotonics, the creation and manipulation of advanced materials at the nanoscale that can produce and sense light. Texas Tech's Center for Advanced Analytics and Business Intelligence performs grid computing research through collaboration with the SAS Institute that seeks to improve the speed with which large quantities of data (such as those present in genomics and global economics) can be processed.

Texas Tech's College of Agricultural Science and Natural Resources has received state and federal grants for research projects including the fiber properties of cotton, the antibacterial properties of cotton fabric, and the development of chemical-warfare protective fabrics. The college has also created two grass variants, Shadow Turf, a drought-tolerant turf grass that thrives in shade, and Tech Turf (marketed as Turffalo), a turf grass with the rich color and texture of Bermuda and the resilience of buffalo grass.
Texas Tech offers online and regional programs in addition to programs offered on the main campus. There are programs that are fully online, hybrid/blended, and located at regional sites. The university offers bachelor's, master's, and doctoral degrees, as well as a graduate certification preparation program, at the regional sites of El Paso, Fredericksburg, Highland Lakes, Center at Junction, and Waco.

Texas Tech's online engineering program also gained recognition from US News and World Report, ranking 20th on their list of the best graduate online engineering programs.

The Lubbock campus is home to the main academic university, law school, and medical school (Health Sciences Center). This arrangement makes it the only institution in Texas to have all three units (undergraduate institution, law school, and medical school) on the same campus. The campus, which boasts Spanish Renaissance architecture, was described by American author James A. Michener as the "most beautiful west of the Mississippi until you get to Stanford" and by Stewart Mandel of "Sports Illustrated" as "easily one of the ten most beautiful campuses" he had seen. Many buildings on campus borrow architectural elements from those found at University de Alcalá in Alcalá de Henares, Spain, and Mission San José in San Antonio. A large section of the campus built between 1924 and 1951 is listed on the National Register of Historic Places as the Texas Technological College Historic District. This area is roughly bounded by 6th Street on the north, University Avenue on the east, 19th Street on the south, and Flint Street on the west. In 2008, the Professional Grounds Management Society awarded Texas Tech the Grand Award for excellence in grounds-keeping, and merit awards in 2007, 2010, and 2014.

In 1998, the Board of Regents of the Texas Tech University System created the Texas Tech University Public Art Collection to enliven the campus environment and extend the educational mission of the university. It is funded by using one percent of the estimated total cost of each new building on campus. The collection features pieces from artists such as Tom Otterness and Glenna Goodacre. The Texas Tech University Public Art Collection is ranked among the ten best university public art collections in the United States by Public Art Review.
The university also hosts the Museum of Texas Tech University, which was founded in 1929 and is accredited by the American Alliance of Museums. The museum is home to over three million objects and specimens and houses the Moody Planetarium, art galleries, a sculpture court, and a natural science research laboratory. The museum also operates the Val Verde County research site and the Lubbock Lake Landmark, an archaeological site and natural history preserve in the city of Lubbock. The site has evidence of 12,000 years of use by ancient cultures on the Llano Estacado (Southern High Plains), and allows visitors to watch active archaeological digs. Visiting scientists and tourists may also participate in the discovery process. Lubbock Lake Landmark is a National Historic Landmark, which lists it on the National Register of Historic Places, and is a designated State Archaeological Landmark. Texas Tech is also the location of the Southwest Collection of historical archives and the sponsoring institution of the West Texas Historical Association.
Located on the northern edge of the campus is the National Ranching Heritage Center, a museum of ranching history. The site spans and is home to 38 historic structures that have been restored to their original condition. Structures represented at the center include: a linecamp, a dugout, a bunkhouse, a blacksmith shop, a cowchip house, a schoolhouse, corrals, shipping pens, windmills, chuckwagons, and a coal-burning locomotive.

The university maintains a number of libraries, some general-purpose and some dedicated to specific topics such as architecture and law. Among the most notable of these are the Southwest Collection/Special Collections Library and the Vietnam Center and Archive, the nation's largest and most comprehensive collections of information on the Vietnam War. On August 17, 2007, the Vietnam Center and Archive became the first US institution to sign a formalized exchange agreement with the State Records and Archives Department of Vietnam. This opens the door for a two-way exchange between the entities.

There are over 516 student clubs and organizations at Texas Tech. Many students participate in Greek Life. Texas Tech Greek Life includes 11 Panhellenic Sororities and 24 InterFraternity Council Fraternities, as well as groups in the National Pan-Hellenic Council (NPHC) and Multicultural Greek Council (MGC). The Student Union Building, located centrally on campus, is the hub of daily student activity. It houses restaurants, coffee shops, a book store, meeting rooms, lecture halls, movie rooms, and study areas, as well as the offices and meeting rooms of several student organizations and the Student Government Association. Directly adjacent to the Student Union Building is the School of Music, home of the Texas Tech Goin' Band from Raiderland. The 450-member band, which was awarded the Sudler Trophy in 1999, performs at all home football games and at various other events.

Approximately 20% of students live on campus, and most students live on campus for at least a portion of their academic careers. students with fewer than 30 hours of academic credit are required to live in university housing unless they receive an exemption. Specific residence halls and communities exist for graduate students, athletes, and various specific interests and academic disciplines. Every resident on campus is a member of the Texas Tech Residence Hall Association which provides various on campus programming and leadership opportunities. RHA is led by an Executive Board and Senate with student representatives from each residence hall. The organization is also a member of the South West Affiliate of College and Universities Residence Halls.
International honor societies Phi Beta Kappa (liberal arts and sciences), Delta Epsilon Psi, Beta Gamma Sigma (business), and Tau Beta Pi (engineering) have chapters at the university. Professional, service, and social fraternities and sororities on campus include Alpha Phi Omega (service), Alpha Kappa Psi (business), Delta Sigma Pi (business), Alpha Omega Epsilon (engineering), Phi Alpha Delta (law), Phi Mu Alpha Sinfonia (music), Kappa Kappa Psi (band), and Tau Beta Sigma (band). Professional development and research organizations hosted by the university include the Howard Hughes Medical Institute Undergraduate Research Fellowship Program, the Center for the Integration of Science Education and Research, the Society of Engineering Technologists, Student Bar Association, and the Texas Tech Forensic Union. Texas Tech is also the only Power Five university in Texas that is a Hispanic-serving Institution. Spirit organizations representing Texas Tech include the High Riders, Saddle Tramps, and the Sabre Flight Drill Team. Animal Rights Coalition at Texas Tech is also an active student organisation, coordinating animal welfare and environmental protection events. This includes holding the first Veg Week in West Texas at Texas Tech in 2017.

The university maintains KTXT-FM 88.1, formerly a student radio station focusing on alternative, indie rock, industrial, and hip hop music. After 47 years, the station went off the air on December 10, 2008. It returned in May 2009 with a different format and plans to eventually return to its former style. National Public Radio station KTTZ-FM 89.1, which features classical music and news, is also found on campus. Additionally, the university owns and operates Public Broadcasting Service television station KTTZ-TV. Students run a daily newspaper, "The Daily Toreador", until 2005 known as "The University Daily". The university also produces a yearbook, "La Ventana".
Texas Tech's athletic teams are known as the Red Raiders with the exception of the women's basketball team, which is known as the Lady Raiders. Texas Tech competes in NCAA Division I FBS (formerly Division I-A) and is a member of the Big 12 Conference. From 1932 until 1956, the university belonged to the Border Intercollegiate Athletic Association. After being rejected eight times over more than 20 years, Texas Tech was admitted to the Southwest Conference on May 12, 1956. When the Southwest Conference disbanded in 1995, Texas Tech, along with the University of Texas at Austin, Texas A&M University, and Baylor University, merged with schools from the former Big Eight Conference to form the Big 12. Athletic Director Kirby Hocutt is a member of the College Football Playoff committee.
Of its varsity sports, Texas Tech's women's basketball team has been the only one to claim a national title. The Lady Raiders, led by player Sheryl Swoopes and head coach Marsha Sharp, won the 1993 NCAA Women's Basketball Championship. The men's basketball team has made 14 appearances in the NCAA Men's Division I Tournament. Bob Knight served as men's basketball coach from the beginning of the 2001 season until February 4, 2008. On January 1, 2007, he set the record for most coaching victories in men's NCAA Division I basketball history when the Red Raiders defeated the New Mexico Lobos, 70–68. Upon Knight's retirement, his son Pat Knight became the head coach of the team for several seasons until Billy Gillispie replaced him. In 2013, Tubby Smith replaced Gillispie.

Since 1999, home basketball games have been played at United Spirit Arena, a 15,020-seat multipurpose facility which cost $ in dollars to build. In addition to serving as home to the men's and women's basketball teams, the arena is used by the Red Raider volleyball team. Texas Tech students broke the Big 12 Conference record for student attendance at the United Spirit Arena during a February 25, 2014 loss to Kansas State. The record of 6,086 students fell less than 2,000 short of the national record.

The Red Raiders football team, is a member of the NCAA Football Bowl Subdivision (formerly known as Division I-A) and is currently coached by former Red Raider quarterback Kliff Kingsbury. Throughout the 2000s, then head coach Mike Leach lead the team to national prominence. In 14 of its last 15 seasons, the Red Raiders have finished with a winning record, the fourth-longest such streak in the nation at the time. The Red Raiders have made 36 bowl appearances, which is 17th most of any university. From 1932 to 1956, as members of the Border Intercollegiate Athletic Association, the Red Raiders won eight conference championships and one co-championship, the most held by a Border Conference member. After joining the Southwest Conference, the Red Raiders added conference co-championships in 1976 and 1994.
Jones AT&T Stadium serves as home to the Red Raiders football team. The stadium, named for Clifford B. and Audrey Jones, opened in 1947. In 2000, the stadium was renamed Jones SBC Stadium after SBC Communications made a $30 million contribution to the university. Following SBC Communications' acquisition of AT&T Corporation in 2006 and its subsequent adoption of the AT&T name, the stadium was renamed Jones AT&T Stadium. The stadium's original seating capacity was 27,000, but it was expanded in 1959, 1972, 2003, 2009, 2010, and 2013.

On August 7, 2008, the Board of Regents of the Texas Tech University System announced a $25 million expansion project. The expansion added a Spanish Renaissance-themed façade to the stadium's east side. In addition to the improvements to the facility's exterior, the expansion added 1,000 general-admission seats, 550 club seats, and 26 suites. Texas Tech allocated $19 million to the expansion and added another $6 million through fund-raising initiatives. On November 20, 2008, university officials announced the project's fundraising goal had been exceeded. The expansion' groundbreaking ceremonies took place on November 29, 2008, and construction was completed before the 2009 football season.

In January 2013, construction added another 368 seats in the north endzone and two observation decks. The $11 million project also includes a significantly upgraded jumbotron with a new sound system, a Spanish Renaissance-themed colonnade, and a north end zone concourse that connects the two stadium halves. Along with the other additions, 157 feet of ribbon board will be added on the north end zone, more than 160 linear feet in the northeast and northwest corners of the stadium, and 94 lineal feet in the south end zone over the athletic offices. The construction was completed during the 2013 season. The stadium's capacity is 60,862, making it the third-largest on-campus stadium in Texas.

The Red Raiders baseball team played its first game in 1925. The team has two conference championships, two conference tournament championships, and has made nine NCAA Division I Baseball Championship tournament appearances. Larry Hays coached the team from 1987 to 2008 and compiled a .639 winning percentage. Following Hays' retirement on June 2, 2008, Assistant Coach Dan Spencer was promoted to head coach. Dan Spencer was replaced by Tim Tadlock following the 2012 season and made its first appearance in the College World Series in 2013. At least 20 former Red Raiders baseball players have gone on to play in the Major Leagues. The team plays its home games at Dan Law Field at Rip Griffin Park. The field, renovated in 2012 and located on the main campus in Lubbock, has a seating capacity of 5,050.

Texas Tech's track and field teams coached by Wes Kittley have produced seven Olympic medalists, 16 national champions, over 200 All-Americans and 119 Big 12 Champions including Michael Mathieu, Sally Kipyego, Kennedy Kithuka, Shereefa Lloyd, Gil Roberts and others.

In addition to varsity sports, the university's Sport Clubs Federation offers 30 recreational and competitive sport clubs, including polo, rugby union, lacrosse, fencing, and soccer. In 2006, Texas Tech beat rival Texas A&M to win the United States Polo Association National Intercollegiate Championship.
The Masked Rider is Texas Tech University's oldest mascot. The tradition began in 1936, when "ghost riders" were dared to circle the field prior to home football games. The Masked Rider became an official mascot in 1954, when Joe Kirk Fulton led the team onto the field at the Gator Bowl. According to reports from those present at the game, the crowd sat in stunned silence as they watched Fulton and his horse Blackie rush onto the football field, followed by the team. After a few moments, the silent crowd burst into cheers. Ed Danforth, a writer for the "Atlanta Journal" who witnessed the event, later wrote, "No team in any bowl game ever made a more sensational entrance." In 2000, The Masked Rider tradition was commemorated with the unveiling of a statue outside of the university's Frazier Alumni Pavilion. The sculpture, created by artist Grant Speed, is 25% larger than life.

Today, the Masked Rider, with guns up, leads the team onto the field for all home games. This mascot, adorned in a distinctive gaucho hat like the ones worn by members of the marching band, is one of the most visible figures at Texas Tech.

Texas Tech's other mascot, Raider Red, is a more recent creation. Beginning with the 1971 football season, the Southwest Conference forbade the inclusion of live animal mascots to away games unless the host school consented. For situations where the host school did not want to allow the Masked Rider's horse, an alternative mascot was needed. Jim Gaspard, a member of the Saddle Tramps student spirit organization, created the original design for the Raider Red costume, basing it on a character created by cartoonist Dirk West, a Texas Tech alumnus and former Lubbock mayor. Although the Masked Rider's identity is public knowledge, it has always been tradition that Raider Red's student alter ego is kept secret until the end of his or her tenure. The student serving as Raider Red is a member of the Saddle Tramps or High Riders.

The Carol of Lights is an annual event, sponsored by the Residence Halls Association, traditionally held the first Friday in December, to celebrate the holiday season. The event begins with a carillon concert, from the 43 bells in the west tower of the Administration Building followed a torch-light processional by the Saddle Tramps and High Riders spirit organizations. The Texas Tech Trombone Choir and combined choirs lead the crowd in singing carols and the illumination ceremony culminates with a soloist performance of "O Holy Night" in the Science Quadrangle. This is followed by the lighting ceremony, where 13 buildings within the Texas Technological College Historic District are illuminated with the over 25,000 red, white, and orange lights. The lights remain on the campus buildings until the first week when students come back from the holiday break.

In 1959, Texas Tech University Board of Directors member Harold Hinn planned and provided the funding to cover the Science Quadrangle and Administration Building with 5,000 lights. However, students were away on Christmas break and did not see the display. The following year, the Residence Hall Association sponsored the event under the name "Christmas Sing". In 1961, the event was renamed Carol of Lights and the display increased to 16,000 lights. The tradition has since grown to include decorations like the 38-foot lighted Christmas tree, 3,000 luminaries lining the sidewalks of Memorial Circle, and a 21-foot fresh pine wreath hung on the Physics/Geosciences building.

The most readily identified symbol of Texas Tech is the Double T. The logo, generally attributed to Texas Tech's first football coach, E. Y. Freeland, was first used as decoration on the sweaters for the football players. The Double T existed in its original form as an official logo from 1963 to 1999 and was updated in 2000. The new logo maintains the original premise, but incorporates three-dimensional beveling effects coupled with white trim.

To recognize the importance of the Double T to Texas Tech, the class of 1931 donated the Double T bench. By tradition, freshmen are not allowed to sit on the bench, which is currently located in the courtyard of the Administration Building. The logo is further embodied in the Double T neon sign, donated by the class of 1938 and affixed to the east side of Jones AT&T Stadium. At the time of its purchase, this was reputedly the largest neon sign in existence.

One of the most well-known landmarks on campus is the statue of Will Rogers on his horse Soapsuds. The statue, entitled "Riding Into the Sunset", has resided at the center of the campus since it was dedicated on February 16, 1950, by Rogers' longtime friend Amon G. Carter. Carter claimed that Texas Tech was the ideal setting for the statue, and that it would be an appropriate addition to the traditions and scenery of West Texas. The statue, estimated to cost $25,000 ($239,000 in 2013 dollars) when it was dedicated, stands and weighs . The inscription on the plaque at the base of the statue reads: "Lovable Old Will Rogers on his favorite horse, 'Soapsuds', riding into the Western sunset."

The statue continues to be a part of school tradition. Before every home football game, the Saddle Tramps wrap it with red crêpe paper, a tradition dating back to 1969 and a loss to Texas A&M after which the statue was found covered in maroon paint in an apparent prank. In times of national tragedies, the statue has also been wrapped in black crêpe paper.

According to one campus legend taught to students during freshman orientation, the statue was originally to be positioned with Will Rogers facing due west, so it would appear he was riding into the sunset. However, that position would cause Soapsuds' posterior end to face due east, a dubious greeting to visitors entering by the main eastern campus entrance where the statue is placed. The horse's rear would also be facing downtown Lubbock, potentially insulting the Lubbock business community. The legend holds that this problem was solved by Tech's Civil Engineering department, who calculated that a 23° turn of Soapsuds' head to the north would line up Soapsuds' rear end directly toward College Station, Texas, home of the rival Texas A&M Aggies. Modern surveys and satellite imagery have determined the statue's posterior end actually points roughly equidistantly between College Station and Austin, home of another rival team, the Texas Longhorns.

While the class ring had occasionally used a universal design, by the late 20th century, various styles were available. In 1999, the university reverted to a single ring design for the university's graduates. The new Official Texas Tech Alumni Association Class Ring symbolically captures the essence of Texas Tech with the prominent Double T logo surrounded by the school's full name and date of foundation. By tradition, undergraduates wear the ring with the Double T logo facing themselves. Upon graduation, the ring is turned so the logo faces outward.

One shoulder of the ring displays an image of the Administration Building, with the bells which represent victory. The other shoulder contains the university seal: an American eagle perched above a book, representing the church; a star, representing the State of Texas; a key, representing home; and, a lamp, representing knowledge. These elements are separated by a cross featuring ten cotton bolls, one each for Lubbock and its nine surrounding cotton-producing counties.

The Texas Tech Alumni Association, with over 27,000 members, operates more than 120 chapters in cities throughout the United States and the world. Throughout Texas Tech's history, faculty, alumni, and former students have played prominent roles in many different fields. Among its Distinguished Alumni is Demetrio B. Lakas, President of the Republic of Panama from 1969 to 1978. Three United States Governors, Daniel I. J. Thornton, Governor of Colorado from 1951 to 1955, John Burroughs, Governor of New Mexico from 1959 to 1961, and Preston Smith, Governor of Texas from 1968 to 1972, are graduates of the university.

Three astronauts, including Rick Husband, the final commander of Space Shuttle "Columbia" and recipient of the Congressional Space Medal of Honor, graduated from the university. U.S. Marine Corps Major and Medal of Honor recipient George H. O'Brien Jr. is a distinguished alumnus. Richard E. Cavazos is a two-time Distinguished Service Cross recipient and the first Hispanic and Mexican American to advance to the rank of four-star general in the U.S. Army. United States Air Force Major General Wendy Motlong Masiello, one of the highest-ranking women in the United States Department of Defense, is a 1980 graduate of Texas Tech's Rawls College of Business Administration. Alumna Arati Prabhakar, the current head of DARPA, was the first woman to head the National Institute of Standards and Technology. Ginger Kerrick, American physicist, was the first Hispanic female NASA Flight Director. Texas Tech's influence on the business world is seen in such people as General Motors Chairman and CEO Edward Whitacre Jr., Finisar CEO Jerry S. Rawls, Belo Corporation CEO Dunia A. Shive, and Wellpoint, Inc. president and CEO Angela Braly, ranked by "Fortune" magazine as the most powerful woman in business. Scott Pelley, anchor and managing editor for "CBS Evening News" and correspondent for "60 Minutes", is a graduate of the recently renamed College of Media and Communication. Phil McGraw (Dr. Phil) attended Texas Tech in the 1970s, during his first marriage.

Texas Tech alumni have also made contributions to sports, music, and acting. Texas Tech Red Raiders have gone on to play in the NFL, NBA, WNBA, and MLB. One notable is Donny Anderson who was a member of the Green Bay Packers who won Super Bowl I & Super Bowl II. Current alumni standouts include Oakland Raiders wide receiver Michael Crabtree, NFL All-Pros Zach Thomas of the Miami Dolphins and Kansas City Chiefs, Danny Amendola of the Miami Dolphins, and Wes Welker, who last played for the Los Angeles Rams Others among the university's alumni are folk rocker John Denver, country singer Pat Green, mezzo-soprano Susan Graham, actor Barry Corbin, Friday Night Lights actor Brad Leland, and actor George Eads. John Hinckley Jr., who attempted to assassinate U.S. President Ronald Reagan in 1981, attended the university sporadically from 1973 to 1980.



</doc>
<doc id="273436" url="https://en.wikipedia.org/wiki?curid=273436" title="Exmoor">
Exmoor

Exmoor is loosely defined as an area of hilly open moorland in west Somerset and north Devon in South West England. It is named after the River Exe, the source of which is situated in the centre of the area, two miles north-west of Simonsbath. Exmoor is more precisely defined as the area of the former ancient royal hunting forest, also called Exmoor, which was officially surveyed 1815–1818 as in extent. The moor has given its name to a National Park, which includes the Brendon Hills, the East Lyn Valley, the Vale of Porlock and of the Bristol Channel coast. The total area of the Exmoor National Park is , of which 71% is in Somerset and 29% in Devon.

The upland area is underlain by sedimentary rocks dating from the Devonian and early Carboniferous periods with Triassic and Jurassic age rocks on lower slopes. Where these reach the coast, cliffs are formed which are cut with ravines and waterfalls. It was recognised as a heritage coast in 1991. The highest point on Exmoor is Dunkery Beacon; at it is also the highest point in Somerset. The terrain supports lowland heath communities, ancient woodland and blanket mire which provide habitats for scarce flora and fauna. There have also been reports of the Beast of Exmoor, a cryptozoological cat roaming Exmoor. Several areas have been designated as Nature Conservation Review and Geological Conservation Review sites.

There is evidence of human occupation from the Mesolithic. This developed for agriculture and extraction of mineral ores into the bronze and Iron Ages. The remains of standing stones, cairns and bridges can still be identified. The royal forest was granted a charter in the 13th century, however foresters who managed the area were identified in the Domesday Book. In the Middle Ages sheep farming was common with a system of agistment licensing the grazing of livestock as the Inclosure Acts divided up the land. The area is now used for a range of recreational purposes.

Exmoor has been designated as a national character area (No. 145) by Natural England, the public body responsible for England's natural environment. Neighbouring natural regions include The Culm to the southwest, the Devon Redlands to the south and the Vale of Taunton and Quantock Fringes to the east.

Exmoor was designated a National Park in 1954, under the 1949 National Parks and Access to the Countryside Act. The Exmoor National Park is primarily an upland area with a dispersed population living mainly in small villages and hamlets. The largest settlements are Porlock, Dulverton, Lynton, and Lynmouth, which together contain almost 40 per cent of the park's population. Lynton and Lynmouth are combined into one parish and are connected by the Lynton and Lynmouth Cliff Railway. Exmoor was once a Royal forest and hunting ground, covering , which was sold off in 1818. Several areas within the Exmoor National Park have been declared Sites of Special Scientific Interest due to their flora and fauna. This title earns the site some legal protection from development, damage and neglect. In 1993 an environmentally sensitive area was established within Exmoor.

Exmoor is an upland area formed almost exclusively from sedimentary rocks dating from the Devonian and early Carboniferous periods. The name of the geological period and system, 'Devonian', comes from Devon, as rocks of that age were first studied and described here. With the exception of a suite of Triassic and Jurassic age rocks forming the lower ground between Porlock and Timberscombe and from Minehead to Yarde (within Exmoor National Park but peripheral to the moor itself), all of the solid rocks of Exmoor are assigned to the Exmoor Group, which comprises a mix of gritstones, sandstones, slates, shales, limestone, siltstones and mudstones. Quartz and iron mineralisation can be detected in outcrops and subsoil. The Glenthorne area demonstrates the Trentishoe Member (formerly 'Formation') of the Hangman Sandstone Formation (formerly 'Group'). The Hangman Sandstone represents the Middle Devonian sequence of North Devon and Somerset. These unusual freshwater deposits in the Hangman Grits were mainly formed in desert conditions. As this area of Britain was not subject to glaciation, the plateau remains as a remarkably old landform. The bedrock and more recent superficial deposits are covered in part by moorland which is supported by wet, acid soil.

Exmoor has of coastline. The highest sea cliff on mainland Britain (if a cliff is defined as having a slope greater than 60 degrees) is Great Hangman near Combe Martin at high, with a cliff face of . Its sister cliff is the Little Hangman, which marks the edge of Exmoor. The coastal hills reach a maximum height of at Culbone Hill.

Exmoor's woodlands sometimes reach the shoreline, especially between Porlock and Foreland Point, where they form the single longest stretch of coastal woodland in England and Wales. The Exmoor Coastal Heaths have been recognised as a Site of Special Scientific Interest due to the diversity of plant species present.

The scenery of rocky headlands, ravines, waterfalls and towering cliffs gained the Exmoor coast recognition as a heritage coast in 1991. With its huge waterfalls and caves, this dramatic coastline has become an adventure playground for both climbers and explorers. The cliffs provide one of the longest and most isolated seacliff traverses in the UK. The South West Coast Path, at the longest National Trail in England and Wales, starts at Minehead and runs along all of Exmoor's coast. There are small harbours at Lynmouth, Porlock Weir and Combe Martin. Once crucial to coastal trade, the harbours are now primarily used for pleasure; individually owned sailing boats and non-commercial fishing boats are often found in the harbours. The Valley of the Rocks beyond Lynton is a deep dry valley that runs parallel to the nearby sea and is capped on the seaward side by large rocks, and Sexton's Burrows forms a natural breakwater to the harbour of Watermouth Bay on the coast.

The high ground forms the catchment area for numerous rivers and streams. There are about of named rivers on Exmoor. The River Exe, after which Exmoor is named, rises at Exe Head near the village of Simonsbath, close to the Bristol Channel coast, but flows more or less directly due south, so that most of its length lies in Devon. It reaches the sea at a substantial ria (estuary) on the south (English Channel) coast of Devon. It has several tributaries which arise on Exmoor. The River Barle runs from northern Exmoor to join the River Exe at Exebridge, Devon. The river and the Barle Valley are both designated as biological Sites of Special Scientific Interest. Another tributary, the River Haddeo, flows from the Wimbleball Lake.

Most other rivers arising on Exmoor flow north to the Bristol Channel. These include the River Heddon, which runs along the western edges of Exmoor, reaching the North Devon coast at Heddon's Mouth, and the East and West Lyn rivers, which meet at Lynmouth. Hoar Oak Water is a moorland tributary of the East Lyn River, the confluence being at Watersmeet. The River Horner, which is also known as Horner Water, rises near Luccombe and flows into Porlock Bay near Hurlstone Point. The River Mole arises on the south-western flanks of Exmoor and is the major tributary of the River Taw, which itself flows northward from Dartmoor. Badgworthy Water is one of the small rivers running north to the coast and is associated with the Lorna Doone legends.

Along with the rest of South West England, Exmoor has a temperate climate which is generally wetter and milder than the rest of England. The mean annual temperature at Simonsbath is with a seasonal and diurnal variation, but due to the modifying effect of the sea the range is less than in most other parts of the UK. January is the coldest month, with mean minimum temperatures between . July and August are the warmest months in the region, with mean daily maxima around . In general, December is the month with the least sunshine and June the month with the most sun. The south-west of England has a favoured location with regard to the Azores high pressure when it extends its influence north-eastwards towards the UK, particularly in summer.

Cloud often forms inland, especially near hills, and reduce the amount of sunshine that reaches the park. The average annual sunshine is about 1,600 hours. Rainfall tends to be associated with Atlantic depressions or with convection. In summer, convection, caused by the sun heating the land surface more than the sea, sometimes forms rain clouds and at that time of year a large proportion of the rainfall comes from showers and thunderstorms. Annual precipitation varies from in the east of the park to over at The Chains. However, in the 24 hours of 16 August 1952, more than of rain fell at The Chains. This rainfall, which followed an exceptionally wet summer, led to disastrous flooding in Lynmouth with 34 dead and extensive damage to the small town.

Snowfall is very variable from year to year and ranges from 23 days on the high moors to about 6 on coastal areas. November to March have the highest mean wind speeds, with June to August having the lightest winds. The wind comes mostly from the south-west.

There are two Met Office Weather stations recording climate data within Exmoor: Liscombe and Nettlecombe.

There is evidence of occupation of the area by people from Mesolithic times onward. In the Neolithic period, people started to manage animals and grow crops on farms cleared from the woodland, rather than act purely as hunters and as gatherers. It is also likely that extraction and smelting of mineral ores to make metal tools, weapons, containers and ornaments started in the late Neolithic, and continued into the bronze and Iron Ages. An earthen ring at Parracombe is believed to be a Neolithic henge dating from 5000–4000 BC, and Cow Castle, which is where White Water meets the River Barle, is an Iron Age fort at the top of a conical hill.

Tarr Steps are a prehistoric ( 1000 BC) clapper bridge across the River Barle, about south-east of Withypool and north-west of Dulverton. The stone slabs weigh up to 5 tonnes apiece, and the bridge has been designated by English Heritage as a grade I listed building, to recognise its special architectural, historical or cultural significance. There is little evidence of Roman occupation apart from two fortlets on the coast. Lanacombe is the site of several standing stones and cairns which have been scheduled as ancient monuments. The stone settings are between and high. A series of Bronze Age stone cairns are closely associated with the standing stones.

Holwell Castle, at Parracombe, was a Norman motte-and-bailey castle built to guard the junction of the east–west and north–south trade routes, enabling movement of people and goods and the growth of the population. Alternative explanations for its construction suggest it may have been constructed to obtain taxes at the River Heddon bridging place, or to protect and supervise silver mining in the area around Combe Martin. It was in diameter and high above the bottom of a rock cut ditch which is deep. It was built, in the late 11th or early 12th century. The earthworks of the castle are still clearly visible from a nearby footpath, but there is no public access to them.

According to the late 13th century Hundred Rolls, King Henry II of England (d. 1189) gave William of Wrotham the office of steward of Exmoor. The terms steward, warden and forester appear to be synonymous for the king's chief officer of the royal forest.

The first recorded wardens were Dodo, Almer & Godric who were named in the Domesday Book (1087) as "foresters of Widepolla", Withypool having been the ancient capital of the forest. The family of Denys were associated with Ilchester and "Petherton". William of Wrotham, who died in 1217, was steward of the forests of Exmoor and North Petherton, Somerset. Walter and Robert were named as foresters of Exmoor when they witnessed an early 13th century grant to Forde Abbey. In 1276 the jurors of Brushford manor made a complaint about John de Camera in the Court of Exchequer in which he was described as forester of Exmoor.

William Lucar of "Wythecomb", the brother of Elizabeth Lucar, was forester "temp." under Henry VI, between 1422 and 1461. William de Botreaux, 3rd Baron Botreaux was appointed in 1435 warden of the forests of Exmoor and Neroche for life by Richard Duke of York. The Botreaux family had long held the manor of Molland at the southern edge of Exmoor, but were probably resident mainly at North Cadbury in Somerset. On 10 May 1461 William Bourchier, 9th Baron FitzWarin, feudal baron of Bampton was appointed by King Edward IV as Master Forester of the Forests of Exmoor and Neroche for life. Sir John Poyntz of Iron Acton, Gloucestershire, was warden or chief forester of Exmoor in 1568 when he brought an action in the Court of Exchequer against Henry Rolle (of Heanton Satchville, Petrockstowe), the powerful lord of the manors of Exton, Hawkridge and Withypool.

In 1608 Sir Hugh Pollard was named as chief forester in a suit brought before the Court of Exchequer by his deputy William Pincombe. James Butler, 1st Duke of Ormonde, was named as Keeper of Exmoor Forest in 1660 and 1661. James Boevey was a forester in the 17th century. Sir Richard Acland (or possibly Sir Thomas Dyke Acland) was the last forester up to 1818. One of the roles of the Warden was Master of Staghounds and this role continued to be exercised by the Master of the Devon and Somerset Staghounds, a position extant today. By 1820 the royal forest had been divided up. A quarter of the forest, , was sold to John Knight (1765–1850) in 1818. This section comprises the present Exmoor Parish, whose parish church is situated in Simonsbath.

The parish of Exmoor Forest was part of the Hundred of Williton and Freemanners. During the Middle Ages, sheep farming for the wool trade came to dominate the economy. The wool was spun into thread on isolated farms and collected by merchants to be woven, fulled, dyed and finished in thriving towns such as Dunster. The land started to be enclosed and from the 17th century onwards larger estates developed, leading to establishment of areas of large regular shaped fields. During the 16th and 17th centuries the commons were overstocked with agisted livestock, from farmers outside the immediate area who were charged for the privilege. This led to disputes about the number of animals allowed and the enclosure of land. In the mid-17th century James Boevey was the warden. The house that he built at Simonsbath was the only one in the forest for 150 years. When the royal forest was sold off in 1818, John Knight bought the Simonsbath House and the accompanying farm for £50,000. He set about converting the royal forest into agricultural land. He and his family also built most of the large farms in the central section of the moor as well as of metalled access roads to Simonsbath and a wall around his estate, much of which still survives.

In the mid-19th century a mine was developed alongside the River Barle. The mine was originally called Wheal Maria, then changed to Wheal Eliza. It was a copper mine from 1845–54 and then an iron mine until 1857, although the first mining activity on the site may be from 1552. At Simonsbath, a restored Victorian water-powered sawmill, which was damaged in the floods of 1992, has now been purchased by the National Park and returned to working order; it is now used to make the footpath signs, gates, stiles and bridges for various sites in the park.

In addition to the Exmoor Coastal Heaths Site of Special Scientific Interest (SSSI), two other areas are specifically designated. North Exmoor covers and includes the Dunkery Beacon and the Holnicote and Horner Water Nature Conservation Review sites, and the Chains Geological Conservation Review site. The Chains site is nationally important for its south-western lowland heath communities and for transitions from Ancient woodland through upland heath to blanket mire. The site is also of importance for its breeding bird communities, its large population of the nationally rare heath fritillary butterfly ("Mellicta athalia"), an exceptional woodland lichen flora and its palynological interest of deep peat on the Chains.

The South Exmoor SSSI is smaller, covering and including the River Barle and its tributaries with submerged plants such as alternate water-milfoil ("Myriophyllum alterniflorum"). There are small areas of semi-natural woodland within the site, including some which are ancient. The most abundant tree species is sessile oak ("Quercus petraea"), the shrub layer is very sparse and the ground flora includes bracken, bilberry and a variety of mosses. The heaths have strong breeding populations of birds, including whinchat ("Saxicola rubetra") and European stonechat ("Saxicola rubicola"). Wheatear ("Oenanthe oenanthe") are common near stone boundary walls and other stony places. Grasshopper warbler ("Locustella naevia") breed in scrub and tall heath. Trees on the moorland edges provide nesting sites for Lesser redpoll ("Acanthis cabaret"), common buzzard ("Buteo buteo") and raven ("Corvus corax").

Uncultivated heath and moorland cover about a quarter of Exmoor landscape. Some moors are covered by a variety of grasses and sedges, while others are dominated by heather. There are also cultivated areas including the Brendon Hills, which lie in the east of the National Park. There are also of Forestry Commission woodland, comprising a mixture of broad-leaved (oak, ash and hazel) and conifer trees. Horner Woodlands and Tarr Steps woodlands are prime examples. The country's highest beech tree, above sea level, is at Birch Cleave at Simonsbath but beech in hedgebanks grow up to . At least two species of whitebeam: "Sorbus subcuneata" and Sorbus 'Taxon D' are unique to Exmoor. These woodlands are home to lichens, mosses and ferns. Exmoor is the only national location for the lichens "Biatoridium delitescens", "Rinodina fimbriata" and "Rinodina flavosoralifera", the latter having been found only on one individual tree.

Sheep have grazed on the moors for more than 3,000 years, shaping much of the Exmoor landscape by feeding on moorland grasses and heather. Traditional breeds include Exmoor Horn, Cheviot and Whiteface Dartmoor and Greyface Dartmoor sheep. North Devon cattle are also farmed in the area. Exmoor ponies can be seen roaming freely on the moors. They are a landrace rather than a breed of pony, and may be the closest breed to wild horses remaining in Europe; they are also one of the oldest breeds of pony in the world. The ponies are rounded up once a year to be marked and checked over. In 1818 Sir Thomas Acland, the last warden of Exmoor, took thirty ponies and established the Acland Herd, now known as the Anchor Herd, whose direct descendants still roam the moor. In the Second World War the moor became a training ground, and the breed was nearly killed off, with only 50 ponies surviving the war. The ponies are classified as endangered by the Rare Breeds Survival Trust, with only 390 breeding females left in the UK. In 2006 a Rural Enterprise Grant, administered locally by the South West Rural Development Service, was obtained to create a new Exmoor Pony Centre at Ashwick, at a disused farm with of land with a further of moorland.

Red deer have a stronghold on the moor and can be seen on quiet hillsides in remote areas, particularly in the early morning. The Emperor of Exmoor, a red stag ("Cervus elaphus"), was Britain's largest known wild land animal, until it was killed in October 2010. The moorland habitat is also home to hundreds of species of birds and insects. Birds seen on the moor include merlin, peregrine falcon, Eurasian curlew, European stonechat, dipper, Dartford warbler and ring ouzel. Black grouse and red grouse are now extinct on Exmoor, probably as a result of a reduction in habitat management, and for the former species, an increase in visitor pressure.

The Beast of Exmoor is a cryptozoological cat (see phantom cat) that is reported to roam Exmoor. There have been numerous reports of eyewitness sightings. The BBC calls it "the famous-yet-elusive beast of Exmoor". Sightings were first reported in the 1970s although it became notorious in 1983, when a South Molton farmer claimed to have lost over 100 sheep in the space of three months, all of them apparently killed by violent throat injuries. In response to these reports Royal Marine Commandos were deployed from bases in the West Country to watch for the mythical beast from covert observation points. After 6 months no sightings had been made by the Royal Marines and the deployments were ended. Descriptions of its colouration range from black to tan or dark grey. It is possibly a cougar or black leopard which was released after a law was passed in 1976 making it illegal for them to be kept in captivity outside zoos. In 2006, the British Big Cats Society reported that a skull found by a Devon farmer was that of a puma; however, the Department for Environment, Food and Rural Affairs (Defra) states, "Based on the evidence, Defra does not believe that there are big cats living in the wild in England."

The National Park, 71% of which is in Somerset and 29% in Devon, has a resident population of 10,600. It was designated a National Park in 1954, under the 1949 National Parks and Access to the Countryside Act. About three quarters of the park is privately owned, made up of numerous private estates. The largest landowners are the National Trust, which owns over 10% of the land, and the National Park Authority, which owns about 7%. Other areas are owned by the Forestry Commission, Crown Estate and Water Companies. The largest private landowner is the "Badgworthy Land Company", which represents hunting interests.

From 1954 on, local government was the responsibility of the district and county councils, which remain responsible for the social and economic well-being of the local community. Since 1997 the Exmoor National Park Authority, which is known as a 'single purpose' authority, has taken over some functions to meet its aims to "conserve and enhance the natural beauty, wildlife and cultural heritage of the National Parks" and "promote opportunities for the understanding and enjoyment of the special qualities of the parks by the public", including responsibility for the conservation of the historic environment.

The Park Authority receives 80% of its funding as a direct grant from the government. The Park Authority Committee consists of members from parish and county councils, and six appointed by the Secretary of State. The work is carried out by 80 staff including rangers, volunteers and a team of estate workers who carry out a wide range of tasks including maintaining the many miles of rights of way, hedge laying, fencing, swaling, walling, invasive weed control and habitat management on National Park Authority land. There are ongoing debates between the authority and farmers over the biological monitoring of SSSIs, showing the need for a controlled regime of grazing and burning; farmers claim that these regimes are not practical or effective in the long term.

Sightseeing, walking, cycling and mountain biking taking in Exmoor's dramatic heritage coastline and moorland countryside scenery are the main attractions.
The South West Coast Path starts at Minehead and follows all along the Exmoor coast before continuing to Poole.

The Coleridge Way is an footpath which follows the walks taken by poet Samuel Taylor Coleridge to Lynmouth, starting from Coleridge Cottage at Nether Stowey in the Quantocks where he once lived.
The Two Moors Way runs from Ivybridge in South Devon to Lynmouth on the coast of North Devon, crossing parts of both Dartmoor and Exmoor. Both of these walks intersect with the South West Coast Path, Britain's longest National Trail.
Other Exmoor walking trails include the Tarka Trail, Samaritans Way South West, Macmillan Way West, Exe Valley Way and Celtic Way Exmoor Option.

For others, although the hunting of animal with hounds was made illegal by the Hunting Act 2004, the Exmoor hunts still meet in full regalia and there is a campaign to resurrect this rural sport. Nine hunts cover the area – the Devon and Somerset Staghounds and the Quantock Staghounds, the Exmoor, Dulverton West, Dulverton Farmers and West Somerset Foxhounds, the Minehead Harriers, the West Somerset Beagles and the North Devon Beagles. During the spring, amateur steeplechase meetings (point-to-points) are run by hunts at temporary courses such as Bratton Down and Holnicote. These, along with thoroughbred racing and pony racing, are an opportunity for farmers, hunt staff and the public to witness a day of traditional country entertainment.

The attractions of Exmoor include 208 Scheduled monuments, 16 conservation areas, and other open access land as designated by the Countryside and Rights of Way Act 2000. Exmoor receives approximately 1.4 million visitor days per year which include single day visits and those for longer periods.

Attractions on the coast include the Lynton and Lynmouth Cliff Railway, which connects Lynton to neighbouring picturesque Lynmouth at the confluence of the East Lyn & West Lyn rivers, nearby Valley of Rocks and Watersmeet.

Woody Bay, a few miles west of Lynton, is home to the Lynton & Barnstaple Railway, a narrow-gauge railway which once connected the twin towns of Lynton and Lynmouth to Barnstaple, about 31 km (just over 19 miles) away.

Further along the coast, Porlock is a quiet coastal town with an adjacent salt marsh nature reserve and a harbour at nearby Porlock Weir. Watchet is a historic harbour town with a marina and is home to a carnival, which is held annually in July.

Inland, many of the attractions are small towns and villages or linked to the river valleys, such as the ancient clapper bridge at Tarr Steps and the Snowdrop Valley near Wheddon Cross, which is carpeted in snowdrops in February and, later, displays bluebells. Withypool is also in the Barle Valley, the Two Moors Way passes through the village. As well as Dunster Castle, Dunster's other attractions include a priory, dovecote, yarn market, inn, packhorse bridge, mill and a stop on the West Somerset Railway. Exford lies on the River Exe.

Exmoor has been the setting for several novels including the 19th century "Lorna Doone: A Romance of Exmoor" by R. D. Blackmore, and Margaret Drabble's 1998 novel "The Witch of Exmoor". The park was featured on the television programme "Seven Natural Wonders" twice, as one of the wonders of the West Country.

Wheal Eliza Mine on the River Barle near Simonsbath was an unsuccessful copper and iron mine.

Near Wheddon Cross is Snowdrop Valley, which becomes filled with thousands of little white flowers called snowdrops during early spring. Within the valley is a sawmill, formerly powered by the River Avill, which runs through the valley.





</doc>
<doc id="273808" url="https://en.wikipedia.org/wiki?curid=273808" title="Death on the Rock">
Death on the Rock

"Death on the Rock" is a controversial television documentary, an episode of Thames Television's current affairs series "This Week", broadcast in the United Kingdom on ITV on 28 April 1988. The programme examined the deaths of three Provisional Irish Republican Army (IRA) members in Gibraltar on 6 March 1988 at the hands of the British Special Air Service (codenamed "Operation Flavius"). "Death on the Rock" presented evidence that the IRA members were shot without warning or while attempting to surrender. It was condemned by the British government, while tabloid newspapers denounced it as sensationalist. "Death on the Rock" subsequently became the first individual documentary to be the subject of an independent inquiry, in which it was largely vindicated.

The project began after it emerged that the three IRA members shot in Gibraltar were found to be unarmed and not in possession of a bomb. The series' editor, Roger Bolton, dispatched journalists to Gibraltar and Spain, where they interviewed several people who witnessed the shootings as well as Spanish police officers who had been involved in surveillance of the IRA team. The journalists also filmed the funerals of the IRA members in Belfast. Satisfied by the journalists' findings, Bolton sought a conclusion to the programme; as the British government refused to comment, Bolton recruited a leading human rights lawyer to give his opinion on the findings. The documentary was broadcast on 28 April 1988 (just under two months after the shootings), despite two attempts by Foreign Secretary Sir Geoffrey Howe to have the Independent Broadcasting Authority postpone the broadcast. Using the eyewitness statements, the documentary questioned the government's version of events, and suggested that the three IRA members may have been unlawfully killed. Reporter Julian Manyon summed up the programme's findings: none of the witnesses interviewed for the programme heard the soldiers challenge the trio before opening fire, but variously believed they had seen the IRA members shot in the back, with their hands up, or after falling to the ground. The final contributor was the lawyer recruited by Bolton, who suggested that a judicial inquiry was necessary to resolve the conflicts.

The morning after the broadcast, several tabloid newspapers attacked the documentary, accusing it of sensationalism and "trial by television". In the following days, they mounted a campaign against Carmen Proetta, one of the documentary's main witnesses, accusing her of being a former prostitute and of being anti-British; Proetta later successfully sued several newspapers for libel. Other newspapers accused "Death on the Rock" of misrepresenting the eyewitnesses' statements and criticised the IBA for allowing the documentary to be broadcast. The eyewitnesses interviewed for "Death on the Rock" gave evidence at the inquest into the shootings; most repeated the statements they had given the programme, but one witness—who had told the programme he had seen a soldier stand over one of the IRA members and fire at the man while he was on the ground—retracted his previous statement. As a result of the retraction, Thames commissioned an independent inquiry into the making of "Death on the Rock"—the first time an inquiry had been commissioned into the making of an individual documentary. The Windlesham–Rampton report found that the programme's tendency was to present evidence that the IRA members had been unlawfully killed, but that it sought to raise questions rather than to reach a conclusion. The authors made several criticisms of the documentary, but overall found it a "trenchant" work of journalism, made in "good faith and without ulterior motives". Thames lost its franchise and the IBA was abolished as a result of the Broadcasting Act 1990—decisions which several involved parties believed were influenced by the government's anger at "Death on the Rock".

"This Week" was a current affairs television series that began in 1956. In 1978, it was renamed "TV Eye" and took on a slightly lighter format; the title "This Week" was restored in 1986, after which it became steadily more journalistic. The programme was broadcast simultaneously across the ITV regions and became a mainstay of ITV's current affairs programming. By 1988, the programme had interviewed several prime ministers and leaders of the opposition, including Margaret Thatcher (the incumbent prime minister), who had been interviewed for three full episodes.

On 6 March 1988, three members of an IRA Active Service Unit—Daniel McCann, Mairead Farrell, and Sean Savage—were witnessed parking a car in a car park in Gibraltar; the car park was used as an assembly area for British soldiers preparing for the weekly "changing of the guard" ceremony outside the Convent (the residence of the governor of Gibraltar). The three were suspected by the British authorities of being part of a plot to detonate a car bomb in the car park while it was full of soldiers preparing for the ceremony; while the suspects were walking back towards the Spanish border, they were shot dead by British soldiers, members of the Special Air Service. In the immediate aftermath of the shootings, the British government released a statement to the effect that a large car bomb had been found in Gibraltar, and that three suspected terrorists had been shot dead by the Gibraltar Police. That evening, British television news reported the finding of the alleged car bomb, and added that the IRA members had been involved in a "shootout" with authorities. All of Britain's daily newspapers covered the shootings the following morning, several of which cited the size of the alleged car bomb as and claimed that it was "packed with shrapnel". The same morning, Ian Stewart, Minister of State for the Armed Forces, told BBC Radio 4 that "military personnel were involved" in the shootings, and that "a car bomb was found, which has been defused".

The following day, Sir Geoffrey Howe, the British foreign secretary, made a statement to the House of Commons regarding the shootings, in which he informed the house that the IRA members were unarmed, and that the car parked in the assembly area did not contain an explosive device. Howe stated that the IRA members "made movements which led the military personnel, operating in support of the Gibraltar Police, to conclude that their own lives and the lives of others were under threat". "In light of this response", Howe continued, "they were shot" by "military personnel, operating in support of the Gibraltar Police". Subsequent inquiries led to the discovery of a large quantity of explosives in Marbella ( from Gibraltar), along with detonators and timers.

"This Week" editor, Roger Bolton, initially believed there was little merit in investigating the shootings. Based on the official account of events that was presented in the immediate aftermath of the shootings, Bolton believed that most people would think the IRA members "deserved what they got". Bolton's interest was piqued by Howe's statement, and the revelation in it that the deceased were unarmed and were not in possession of a bomb. Shortly afterwards, he dispatched two of "This Week"s journalists, Julian Manyon and Chris Oxley, to Gibraltar and Spain (respectively) to gather more information on the shootings. Bolton believed that the Milltown Cemetery attack and the corporals killings, two events in Belfast which resulted from the Gibraltar killings, provided "even more compelling reasons" to investigate the shootings; the team considered switching the focus of the programme to the effects the shootings had in Belfast, but decided to continue with the original project.

After ten days' investigation, Oxley was surprised to learn that the Gibraltar Police were handling the police investigation into the shootings, having been closely involved in the events leading up to them. He also grew concerned that the police investigation was insufficiently rigorous when he learned that the police had not taken statements from residents whose flats overlooked the scene of Farrell's and McCann's deaths. The Gibraltar coroner, Felix Pizzarello, welcomed "This Week"s investigation, telling Oxley that he hoped the journalists would uncover witnesses who could assist the inquest. While Oxley was investigating the shootings from Gibraltar, Manyon travelled to Madrid in an attempt to learn more about the surveillance operation which took place in Spain prior to the shootings. Bolton added Alison Cahn to the team on 18 March; her task was to visit the flats which overlooked the petrol station where McCann and Farrell were shot, with the aim of interviewing any residents who might have witnessed the events of 6 March. After several days' work, the team found two eyewitnesses to the shootings who were willing to speak on camera: Stephen Bullock, a local lawyer who had witnessed the events while out for a walk with his wife; and Josie Celecia, a housewife who had seen the shooting of McCann and Savage from her apartment window. Both witnesses' statements appeared to the journalists to be inconsistent with the official account of the shootings.

The journalists quickly decided they needed expert advice on ballistics and explosives, to which end they engaged Lieutenant Colonel George Styles, GC, a retired British Army officer who had served as a bomb-disposal officer in Northern Ireland during the Troubles. Styles arrived in Gibraltar on 23 March, and immediately went to inspect the car park where Savage had parked the white Renault on the day of the shootings, after which he walked through the town along what the journalists believed was the IRA members' most likely route. When asked his opinion by the journalists, Styles cast doubt on the authorities' stated reasons for the shootings. He explained to the journalists that, had Savage's white Renault contained a substantial bomb, the weight would have been evident on the vehicle's springs. Styles also felt that the potential bomb was unlikely to have been detonated with a remote detonator on account of the buildings between the scenes of the shootings and the likelihood that it would be drowned out by other radio signals in the area. Finally, the journalists asked Styles to examine the scenes of the shootings, including ricochet marks that the soldiers' bullets had left on the pumps at the petrol station where McCann and Farrell were shot.

As Styles was examining the ricochet marks, Alison Cahn was approached by an elderly woman, who led Cahn to a nearby apartment building. There, the woman introduced Cahn to her daughter—Carmen Proetta—who told Cahn that she had witnessed the shooting at the petrol station; although initially reluctant, she was persuaded by Cahn to give her account of the events in an affidavit. Proetta asserted that, immediately before McCann and Farrell were shot, she saw a police car travelling north on Winston Churchill Avenue with its siren activated; as she watched, the police car stopped abruptly and four men—one uniformed police officer and three men in civilian clothes—jumped out. She stated that the three men in plain clothes, all carrying pistols, leapt across the central reservation barrier, at which point she saw McCann and Farrell raise their hands. Proetta believed that all three men then opened fire, while McCann and Farrell had their hands in the air, and that neither suspect made any movements towards their clothing or Farrell's handbag. She went on to state that she witnessed one of the men crouch over McCann and Farrell while they were on the ground, and continue to shoot them. According to Styles, Proetta's account of the shooting tallied with the bullet marks he examined at the petrol station; he also found her description of the bullets striking the bodies particularly convincing, believing that only somebody who had witnessed such an event would be able to describe it so vividly. The journalists also discovered that Proetta's account of the soldiers arriving in a police car matched some of the newspaper reports from the day after the shootings.

By the end of March, Cahn had traced two further witnesses to the shootings—Diana Treacy, who claimed to have seen the soldiers shooting Savage in the back without warning and continuing to shoot him while he was on the ground, and Kenneth Asquez, who had provided a hand-written, unsigned statement, but was extremely reluctant to be filmed or named as a witness. He had come to the attention of the journalists through another witness, who provided Cahn with a video recording of the aftermath of the shootings. The journalists approached the witness through a second intermediary—Christopher Finch, a local lawyer who had been assisting them as a consultant—and received a typed but unsigned affidavit. In both documents, Asquez stated that he had been a passenger in a car that was passing the scene of Savage's shooting on 6 March; he described seeing Savage lying on the ground with a soldier standing over him, and witnessing the soldier shoot Savage "two or three times at point-blank range" while the latter was on the ground. The journalists failed to persuade Asquez to sign his affidavit, but decided to incorporate it into the programme nonetheless.

Julian Manyon arrived in Madrid on 11 March, and shortly afterwards engaged Henry Debelius, a journalist and American expatriate, as an interpreter and consultant for the programme. Within days, the two men wrote to the Spanish police headquarters to request information from the authorities and assistance in reconstructing the surveillance operation that preceded the shootings as the IRA team travelled through Spain. Ten days later, they met with a spokesman for the Spanish interior ministry, who confirmed that the Spanish authorities had tracked the three IRA members throughout their time in Spain. The Spanish surveillance operation included multiple cars following the suspects' vehicle, periodically "leap-frogging" each other to avoid attracting attention; use of a helicopter to track the team's movements; constant radio communication between the officers involved and police headquarters; and officers monitoring the suspects' movements at fixed observation posts. The spokesman also told the men that the Spanish kept the British authorities constantly apprised of the IRA team's movements, and that the British were aware of Savage's arrival at the Gibraltar border, and allowed the white Renault he was driving to enter the territory.

As well as the investigation in Gibraltar and Spain, "This Week" conducted some of the filming for "Death on the Rock" in Northern Ireland. Its journalists filmed the funeral of McCann, Savage, and Farrell; while there, Manyon took the opportunity to interview Gerry Adams, leader of Sinn Féin, who refused to confirm that the three were planning a bomb attack on Gibraltar. The team decided against using Adams' interview, and only 45 seconds of the footage was used in the final cut. The journalists were keen to show the potential impact of a bomb like the one the IRA had planned to explode in Gibraltar; they initially hoped to film a controlled explosion of a bomb of similar size, but no private contractor would conduct such an experiment without government approval. In lieu of filming an explosion, "This Week" interviewed Noreen Hill—whose husband was left in a coma as a result of a smaller bombing in Enniskillen in November 1987—to "depict the human tragedy of IRA bombings". They also filmed an interview with a second survivor of the Enniskillen bombing, which was not included in the final cut.

Based on the information his journalists had gathered from eyewitnesses in Gibraltar and that provided by the Spanish authorities, Bolton believed his team had enough to broadcast a documentary about the Gibraltar shootings. The journalists filmed those eyewitnesses who were willing to speak on camera. They also rented a helicopter, and—with the assistance of the Spanish authorities, who provided two police officers who had taken part in the operation—filmed a reconstruction of the Spanish surveillance operation.

Throughout the investigation, the authorities in Britain and Gibraltar refused to provide any information or to comment on the journalists' findings. Thus, "This Week" were unable to present their conclusions to a member of the government and broadcast their reaction, as was the usual practice for closing such a documentary. In place of such a conclusion, Bolton approached George Carman—a leading London lawyer specialising in human rights issues—who agreed to be interviewed for the programme.

On 26 April, two days before "Death on the Rock" was due to air, the British government intervened to prevent its broadcast. Howe telephoned Lord Thomson, chair of the Independent Broadcasting Authority (IBA), to request he force the postponement of the broadcast on the grounds that Howe feared the documentary might prejudice the coroner's inquest. Thomson personally viewed "Death on the Rock" before making the final decision to permit its broadcast, with two alterations to the commentary. He later wrote that, "paradoxically", the decision "was not a difficult one. My colleagues and I saw no reason why the IBA should prevent Thames' journalists interviewing those who claimed to be eyewitnesses and investigating the affair as numerous other journalists had since the shootings, provided that the criminal record of the terrorists and the enormity of the outrage they planned was made clear and the legal position had been established to our satisfaction". With a slightly altered rationale—that the documentary could contaminate witness evidence at the inquest—Howe again attempted to prevent the programme's broadcast on the day it was due to be shown; after taking further legal advice, the IBA upheld its decision to permit the showing of "Death on the Rock".

Final editing of the programme was still under way while the IBA was considering Howe's requests, causing Bolton to worry that it would not be completed in time. The editing was eventually finished just ten minutes before the documentary was due to air. "Death on the Rock" was ultimately broadcast in the United Kingdom on schedule, at 21:00 on 28 April 1988, six weeks after the shootings.
The programme opened with excerpts from two of the interviews prior to the title sequence, followed by an introduction from Jonathan Dimbleby, who told viewers that the evidence presented in the programme was "of critical importance for those who wish to find out what really happened in Gibraltar last month". The commentary cut to Manyon, who introduced Styles and discussed the impact the IRA's bomb would have had, and then to Noreen Hill, whose husband was in a coma as a result of the Enniskillen bombing. Manyon pointed out that the IRA expressed regret after Enniskillen, but that they were by then already planning to attack Gibraltar. Manyon told viewers of the three IRA members' backgrounds, before introducing an interview with an official from the Spanish Interior Ministry, who discussed the Spanish surveillance operation, of which viewers were shown a reconstruction with a voice-over from Manyon. The programme reconstructed Savage's movements as he crossed the border into Gibraltar, parked his car in the assembly area for the ceremony and met up with McCann and Farrell, after which it broadcast part of Howe's statement to the House of Commons: "Their presence and actions near the parked Renault car gave rise to strong suspicion that it contained a bomb, which appeared to be corroborated by a rapid technical examination of the car". Manyon explained that the vehicle was later found not to contain a bomb, and introduced Styles, who believed that such an examination would have shown that the car did not contain a bomb, as the weight would have been evident on the vehicle's springs.

Manyon continued to narrate as the programme reconstructed the IRA team's movements through Gibraltar towards the border until McCann and Farrell reached a petrol station on Winston Churchill Avenue. "Then, suddenly", Manyon told viewers, "shots rang out, and in less than a minute all three terrorists were dead—shot by the SAS". The commentary again cut to Howe's statement, after which Manyon detailed "This Week" investigation. He introduced the four eyewitnesses the journalists had discovered (Diana Treacy, Josie Celecia, Stephen Bullock, and Carmen Proetta). Celecia described witnessing McCann and Farrell walking along Winston Churchill Avenue before hearing several shots, and then seeing a soldier continue to fire at the pair while they were on the ground. Proetta told the programme she saw a police car arrive opposite the petrol station, that three armed men in plain clothes then disembarked, jumped across the central barrier, and shot McCann and Farrell while the latter had their hands up. Bullock was interviewed walking the route he had walked on the day of the shootings; his account was of two men in plain clothes shooting McCann and Farrell at very close range and continuing to shoot as the pair fell and while they were on the ground. Treacy, meanwhile, was walking along Landport Lane when Savage ran past her, pursued by at least one soldier. She stated that she did not hear any warning before Savage was shot; she ran away after the shooting began. Asquez was not named in the broadcast; his statement—that he saw a soldier firing at Savage while the latter was on the ground—was read out by an actor.

Styles told Manyon he believed it unlikely that the IRA would have succeeded in detonating a bomb in the assembly area from the petrol station where McCann and Farrell were shot (a distance of approximately ). Returning to Proetta, the documentary heard her reaction to Howe's statement that McCann and Farrell made threatening movements; Proetta believed that the incident was triggered by the siren from the police car on Winston Churchill Avenue. She believed that any movements McCann and Farrell made were in response to the siren, and was adamant that the pair had their hands up when they were shot. Manyon summed up the programme's findings:

Carman, the QC recruited by Bolton, was the last contributor to the documentary. Presented with "This Week" evidence, he disagreed with Margaret Thatcher's statement that the inquest would be sufficient to establish the facts of the incident. He opined that a more powerful judicial enquiry, possibly headed by a British High Court judge, would be better equipped to eliminate the inconsistencies between the official version of events and the eyewitness statements. In conclusion, Manyon asked Carman "do you believe this case is so important that the government should take such extraordinary steps in order to clarify the facts?" Carman responded "the programme indicates there are serious, important public issues involved, and speaking as a lawyer, one is always anxious when there is contest on the facts in such important areas, they should be properly and efficiently investigated". The documentary closed with Jonathan Dimbleby:

That report was made, as you may have detected, without the cooperation of the British government, which says it will make no comment until the inquest.

As our film contained much new evidence hitherto unavailable to the coroner, we are sending the transcripts to his court in Gibraltar, where it's been made clear to us that all such evidence is welcomed.

From "This Week", goodnight.
The controversy surrounding "Death on the Rock" was "unsurpassed" in Lord Thomson's experience. The morning after the broadcast, the British broadsheets appeared open-minded or moderately favourable to "This Week"; "The Times" told readers that "Death on the Rock" "seemed a significant, thoroughly responsible and serious examination of a most disturbing case" and that it "simply raised serious questions and suggested they needed deep examination". The tabloids, however, berated the programme and its makers. "The Sun" accused the makers of a "cheap scoop" and labelled the programme "IRA propaganda". The "Daily Mail" was equally robust; its main headline read "fury over SAS 'trial by TV'", while in an inside article, it called the programme "woefully one-sided", and accused Bolton of having previously collaborated with the IRA for sensational news stories. That evening, Bolton agreed to appear on Channel 4's "Right to Reply", a show which allowed ordinary viewers to question the makers of controversial television programmes; the programme was pre-recorded, and, unusually, the producers agreed to cut the end of the recording after one of the participants—a former member of Margaret Thatcher's personal staff claiming to be an impartial viewer—launched an attack on Bolton, in which he accused Bolton of associating with terrorists.

Beginning in the days after the broadcast of "Death on the Rock", the British tabloid press mounted a campaign against Carmen Proetta, one of the documentary's key witnesses. The day after the broadcast, the "London Evening Standard" printed a story about Proetta's husband; the piece—citing the Gibraltar Police press officer—claimed that Maxie Proetta was a drug smuggler well known to the Gibraltar Police. Over the course of the week, several of the tabloids ran stories claiming that Carmen Proetta ran an escort agency and that she was a former prostitute with a criminal record; in one headline, "The Sun" labelled her "the tart of Gib". Several stories also attempted to portray Proetta as anti-British, including one in the broadsheet "The Daily Telegraph" which claimed she was one of the 44 people who voted to end the British administration in Gibraltar's 1967 referendum. In fact, Proetta had served briefly as a director of a Spanish tour company and had no criminal record in either Spain or Gibraltar; her husband had been convicted for drug possession in Spain and was, at the time of the shootings, facing separate charges for allowing his boat to be used by drug smugglers. Proetta later sued "The Sun" and other newspapers for libel and won substantial damages.

"The Sunday Times" attempted to undermine the programme's credibility with its own investigative journalism. Citing "official sources", the paper told its readers that "This Week"s account of the shootings was "crucially flawed", and "bore no resemblance to what happened". It went on to claim that several of the programme's witnesses felt that "Death on the Rock" had misrepresented their statements. It stated that the documentary's technical advisor, Lieutenant Colonel George Styles, was aggrieved that two of his "key opinions" had been omitted from the version broadcast—specifically that what Proetta interpreted as a gesture of surrender may have been an involuntary reaction to the bullets striking the suspects' bodies, and that the IRA members could still have detonated a bomb in another vehicle parked on the Spanish side of the border. The latter opinion was omitted because the "This Week" team saw little for the IRA to gain by detonating a bomb on Spanish soil, while the former was included in the broadcast. Josie Celecia, it alleged, had dismissed Proetta's account as "ridiculous", while Stephen Bullock had contradicted Proetta's statement that she had seen plain-clothed soldiers arriving in a police car—testimony "The Sunday Times" believed "destroyed" Proetta's evidence. Both witnesses complained in letters to other newspapers. Through these, it emerged that Bullock had dismissed only one detail in Proetta's evidence as "ridiculous", while he and Proetta had been referring to two distinct police cars in their statements. "The Sunday Times" omitted Styles' belief that the shootings were a pre-emptive attack. Styles' view was one of "two active service units waging war [...] taking [the IRA members] out quickly, cleanly, and without other people being hurt—that seems to be the only way". Several newspapers were critical of the IBA's decision to allow the documentary to be broadcast.

The witnesses uncovered during the production of "Death on the Rock" appeared at the inquest, which began on 6 September. One of the first civilians to give evidence was Allen Feraday, an explosives expert who worked for the Ministry of Defence (MoD); he confirmed Styles' contribution to the documentary—that the IRA had not been known to use a remote-detonated bomb without a direct line of sight to their target. The various expert witnesses at the inquest disagreed as to whether a detonation signal could have reached the parked Renault from the scenes of the shootings. Multiple eyewitnesses gave evidence over the course of the inquest. Four gave evidence which broadly supported the official version of events; in particular, none saw the soldiers shoot McCann, Savage, or Farrell while they were on the ground. The witnesses from "Death on the Rock" also appeared. Stephen Bullock told the coroner that he saw McCann and Savage raise their hands before seeing the SAS shoot them at point-blank range. Josie Celecia's evidence—that she saw a soldier shooting at McCann and Farrell while the pair were on the ground—was stringently challenged by government lawyers, who pointed out that her account had changed somewhat since she had appeared on camera and that she was unable to identify the SAS soldiers from photographs taken by her husband.

Maxie Proetta appeared on 22 September. He told the coroner that he had witnessed four men (three in plain clothes and one uniformed Gibraltar Police officer) arriving opposite the petrol station on Winston Churchill Avenue; the men jumped over the central reservation barrier and Farrell put her hands up, after which he heard a series of shots. In contrast to his wife's testimony, he believed that Farrell's gesture was one of self-defence rather than surrender, and he believed that the shots he heard did not come from the men from the police car. The government lawyers suggested that the police car he and his wife had seen was one seen by other eyewitnesses further south, and that it was responding to the shootings rather than transporting soldiers, but Mr Proetta was adamant that the lawyers' suggestion did not make sense. Carmen Proetta appeared the following day. Mrs Proetta's testimony contained some discrepancies with the evidence she gave to "Death on the Rock"; she was no longer certain that she had seen the SAS shoot McCann and Savage while the latter were on the ground, because she could not recall seeing shell casings being ejected from the soldiers' weapons. The government lawyers questioned the reliability of Proetta's evidence based on her changes, and implied that she behaved suspiciously by giving evidence to "Death on the Rock" before the police. She responded that the police had not spoken to her about the shootings until after "Death on the Rock" had been shown. Asquez, who provided an unsworn statement to the programme through an intermediary, reluctantly appeared at the inquest. He retracted the statements he had given to the journalists, which he claimed he had made up after "pestering" from Major Bob Randall (who had sold the programme a video recording of the aftermath of the shootings). The British tabloids covered Asquez's retraction extensively, while several members of parliament accused "Death on the Rock" of manipulating Asquez in an attempt to discredit the SAS and the British government. However, Asquez's statement contained several details that were not released publicly, and which only entered the public domain during the inquest, though, when questioned by the coroner, Asquez said he could not explain the discrepancy because he was "a bit confused". The inquest concluded on 30 September and the jury returned a verdict of lawful killing.

Following the inquest, the families of McCann, Savage, and Farrell applied to the European Commission of Human Rights for an opinion on whether the authorities' actions in Gibraltar violated Article 2 (the "right to life") of the European Convention on Human Rights (ECHR); "This Week" journalists provided statements to the commission regarding the Spanish surveillance operation (the existence of which had been denied by the British authorities at the inquest). The commission's report found no violation of Article 2, but the commission referred the case to the European Court of Human Rights (ECtHR) for a final decision. The court rejected the families' submission that the British government had conspired to kill the three, but did find a violation of Article 2 in the defective planning and control of the operation. Nevertheless, the applicants' claim for damages was dismissed on the grounds that the trio had been killed while preparing an act of terrorism, though it did order the government to pay the applicants' costs.

Following Asquez's retraction of his statement and his allegation that he was pressured into giving a false account of the events he witnessed, the IBA contacted Thames to express its concern and to raise the possibility of an investigation into the making of the documentary. Thames eventually agreed to commission an independent inquiry into the programme (the first such inquiry into an individual programme), to be conducted by two people with no connection to either Thames or the IBA; to that end, Thames engaged Lord Windlesham and Richard Rampton, QC. Windlesham was a Conservative politician, privy councillor, and former minister in the Home Office and then the Northern Ireland Office; he also had experience of television journalism, having previously managed two television companies. Rampton was a leading barrister specialising in media law and libel. The inquiry's terms of reference were "to inquire into the making and screening of 'Death on the Rock'", including its creation, production, content, and any effect it had had on the inquest.

The report found that the tendency of the evidence presented in the programme was to suggest the terrorists had been unlawfully killed, and that it did not explore alternative explanations in any depth. Nevertheless, Windlesham and Rampton believed that the programme presented evidence for one possible explanation, but sought to raise questions rather than reach a conclusion. In analysing the content of the programme, they found that it allowed the witnesses to give their accounts in their own words rather than presenting them as established fact. Thus, they found that the content did not infringe any requirement for neutrality. The report scrutinised in detail the statements of the eyewitnesses who spoke on camera, including the parts of the interviews that were not included in the broadcast version of the programme. It found, with two exceptions, that the witnesses' statements were fairly represented in the programme. The exceptions were that the programme suggested that Bullock had not heard a warning, when he was in no position to hear whether such a warning was given or not; and that the commentary implied that all four witnesses who appeared on the programme had seen no threatening movements from the IRA members, when only two had been asked whether they witnessed such movements. Windlesham and Rampton also considered Asquez's statement and the journalists' decision to incorporate it into the programme. The report considered that the journalists acted reasonably in using the statement, despite Asquez's refusal to sign it, on the grounds that Asquez had given two separate, near-identical statements (including one to a lawyer), and that they considered it unlikely that somebody would invent such a dramatic account. Nonetheless, the report criticised the programme for not informing viewers of Asquez's refusal to sign the statement.

The Foreign and Commonwealth Office (FCO) made representations to the inquiry that "Death on the Rock" could potentially have had an adverse effect on the inquest on the same grounds that Howe had attempted to delay the broadcast. The first was that the programme might have been seen by members of the inquest jury, and could thus have caused them to reach a conclusion on the shootings before hearing the evidence at the inquest. Considering this submission, the report agreed with the opinions of lawyers consulted by Thames and the IBA that "Death on the Rock" was safe to be broadcast on 28 April 1988. The report considered that Thames withheld distribution of "Death on the Rock" from Gibraltar and Spain specifically to address such concerns, though it was widely discussed in British newspapers (which are widely sold in the territory) and extracts later became available in Gibraltar. The report concluded it was foreseeable that the content of "Death on the Rock" would become known in Gibraltar, but that it would not have prejudiced potential jurors as, in the authors' opinion, the programme raised one possibility, but did not seek to present it as the only possible version of events. The second was that the programme might have contaminated the evidence presented at the inquest, as witnesses might have been tempted to give false or embellished accounts for the television. The report dismissed this concern; the authors believed that all the eyewitnesses gave honest accounts of what they believed they saw, and pointed out that three had given statements to the Gibraltar Police and two had been interviewed by Gibraltarian and British newspapers prior to being interviewed for "Death on the Rock".

Overall, Windlesham and Rampton found "Death on the Rock" to be a "trenchant" work of journalism, made in "good faith and without ulterior motives". In conclusion, the authors believed that "Death on the Rock" proved that "freedom of expression can prevail in the most extensive, and the most immediate, of all the means of mass communication".

The terms of reference of the report did not invite any recommendations, nor did the authors offer any.

"Death on the Rock" was highly praised within the television industry and went on to win the BAFTA Award for Best Documentary and an award from the Broadcasting Press Guild. In 2000, "Death on the Rock" was placed 92nd by industry professionals in a list of the 100 Greatest British Television Programmes compiled by the British Film Institute.

Two other programmes were made about the Gibraltar shootings for British television, both by the BBC. BBC Northern Ireland produced an episode of "Spotlight" which arrived at similar findings to those of "This Week"; Howe attempted to have the programme delayed, using the same rationale with which he requested "Death on the Rock" be postponed. The programme was eventually broadcast, but restricted to Northern Ireland. The BBC's flagship current affairs series "Panorama" made a programme about the SAS and its role in the Troubles to coincide with the end of the Gibraltar inquest; it was postponed by BBC executives in the wake of the controversy surrounding "Death on the Rock".

Academic Christian Potschka described "Death on the Rock" as part of a decade of "unprecedented conflict between government and broadcasters over ... investigative documentaries". Margaret Thatcher "utterly rejected" the findings of the Windlesham–Rampton report. After the reforms brought in by the Broadcasting Act 1990, the process of bidding for ITV franchises was overhauled in an attempt to introduce greater competition. In the subsequent auction, Thames Television lost its contract; several journalists and former Thames employees speculated that the Act was the government's revenge for "Death on the Rock". "This Week" ceased after Thames lost its franchise. Lord Thomson, chairman of the IBA, believed the dispute between the government and the authority had a "very substantial influence on Mrs Thatcher's attitude towards broadcasting policy", which led her to the belief that Thames' franchise should not be renewed. The 1990 Act abolished the IBA, which Thomson believed was directly related to the authority's decision to permit the showing of "Death on the Rock".

It was broadcast again in April 1991 as part of the Channel 4 Banned season.



</doc>
<doc id="274258" url="https://en.wikipedia.org/wiki?curid=274258" title="Dilwale Dulhania Le Jayenge">
Dilwale Dulhania Le Jayenge

Dilwale Dulhania Le Jayenge (), also known by the initialism DDLJ, is an Indian romance film, directed by Aditya Chopra (in his directorial debut), produced by his father Yash Chopra, and written by Javed Siddiqui with Aditya Chopra. Released on 20 October 1995, the film stars Shah Rukh Khan and Kajol. The plot revolves around Raj and Simran, two young non-resident Indians, who fall in love during a vacation through Europe with their friends. Raj tries to win over Simran's family so the couple can marry, but Simran's father has long since promised her hand to his friend's son. The film was shot in India, London and Switzerland, from September 1994 to August 1995.

Earning 1.06 billion (valued at about US$32,766,000 in 1995) in India and 160 million (valued at about US$4,946,000 in 1995) overseas, "Dilwale Dulhania Le Jayenge" became the highest grossing Bollywood film of the year, and one of the most successful Indian films in history. It won 10 Filmfare Awards, the most for a single film at that time, and won the National Film Award for Best Popular Film Providing Wholesome Entertainment. Its soundtrack album became one of the most popular of the 1990s.

Many critics praised the film, which connected with different segments of society by simultaneously promoting strong family values and the following of one's own heart. Its success led other film makers to target the non-resident Indian audience, which was deemed more lucrative for them. It spawned many imitations of its story and style, and homages to specific scenes. "Dilwale Dulhania Le Jayenge" was one of only three Hindi films in the reference book "1001 Movies You Must See Before You Die", and was placed twelfth on the British Film Institute's list of top Indian films of all time. It is the longest-running film in the history of Indian cinema. As of 2018, over 20 years after its first release, it is still being shown at the Maratha Mandir theatre in Mumbai.

Raj Malhotra (Shah Rukh Khan) and Simran Singh (Kajol) are non-resident Indians living in London. Simran was raised by her strict and conservative father, Baldev Singh (Amrish Puri), while Raj's father Dharamvir Malhotra (Anupam Kher) is very liberal. Simran always dreams of meeting her ideal man; her mother Lajjo (Farida Jalal) warns her against this, saying dreams are good, but one should not blindly believe they come true. One day, Baldev receives a letter from his friend Ajit (Satish Shah), who lives in Punjab, India. Ajit wants to keep a promise he and Baldev made to each other 20 years ago—to have Simran marry his son Kuljeet (Parmeet Sethi). Simran is disappointed, as she does not want to marry someone whom she has never met.

One evening, Raj enters Baldev's shop after closing time to buy beer. Baldev refuses, but Raj grabs a case of beer, throws money on the counter, and runs away. An infuriated Baldev calls Raj a disgrace to India. Meanwhile, Raj's father agrees to his request to go on a train trip across Europe with his friends, and Simran's friends have invited her to go on the same trip. Simran asks her father to let her see the world before her marriage, and he reluctantly agrees.

On the trip, Raj and Simran meet. Raj constantly flirts with Simran, much to her irritation. The two miss their train to Zurich and are separated from their friends, but start to travel together and become friends. Raj falls in love with Simran on the journey, and when they part ways in London, Simran realises she is in love with him as well. At home, Simran tells her mother about the boy she met on her trip; Baldev overhears the conversation and becomes enraged with his daughter. He says the family will move to India the next day. Meanwhile, Raj tells his father about Simran and that she will soon get married. When Raj says he believes Simran loves him too, his father encourages him to go after her.

In India, Baldev is reunited with his relatives and his friend Ajit. A miserable Simran and her younger sister Chutki (Pooja Ruparel) take an instant dislike to Simran's fiancé Kuljeet because of his arrogance. Simran pines for Raj, but her mother tells her to forget him because she knows Baldev will never accept their relationship. The next morning, Raj arrives outside of the house where Simran is staying and the two reunite. She begs him to elope with her, but Raj refuses and says he will only marry her with her father's consent. Raj befriends Kuljeet and is quickly accepted by both families. Later, his father arrives in India and also becomes friends with Simran's and Kuljeet's families. Eventually, Lajjo and Chutki discover that Raj is the boy Simran fell in love with in Europe. Lajjo also tells Raj and Simran to run away, but he still refuses. Baldev recognises Raj from the beer incident but eventually accepts him. However, after he discovers a photograph of Raj and Simran together in Europe, he slaps and humiliates Raj and tells him to leave.

As Raj and his father wait at the railway station, Kuljeet, who is angry to learn of Raj's love for Simran, arrives with his friends and attack them. Eventually, Baldev and Ajit arrive and stop the fight, and Raj boards the departing train with his father. Simran then arrives with her mother and sister; she tries to join Raj on the train, but Baldev stops her. Simran begs him to let her go, saying she cannot live without Raj. Baldev, realising nobody loves his daughter more than Raj does, lets her go, and she runs and catches the train as it departs.

Credits adapted from British Film Institute.

Aditya Chopra assisted his father, director and producer Yash Chopra, during the making of "Chandni" (1989), "Lamhe" (1991) and "Darr" (1993). During this time, Aditya wrote several of his own scripts, including one he assumed would be his first film, but eventually became his second, "Mohabbatein" (2000). For three years, he worked on the story that would become "Dilwale Dulhania Le Jayenge" before approaching his father to direct it. Yash did not want to, and tried to persuade Aditya to do it himself. As they were discussing ideas for the script, Aditya conceived the notion that Raj would seek permission for marriage from Simran's stern father, rather than eloping with her. He then became excited about the possibility of directing the film himself. After his mother, the playback singer Pamela Chopra, agreed that the idea was sound, he decided to make this his directorial debut. Aditya wanted to make a wholesome film that people could watch repeatedly. He wanted to diverge from the typical plot line of the time, in which lovers run away when their parents object, and show that if their love was strong enough, the parents would eventually understand.

In May 1994, Aditya read the first draft of the script to several members of the Yash Raj Films production team assigned to work with him, including a cinematographer, an art director and a dialogue writer. They were not impressed, but Aditya held fast to his ideas. He was given total editorial control by his father, the producer, and made the film according to his own tastes and sensibilities. Aditya struggled with both the dialogue writer Javed Siddiqui and the song lyricist Anand Bakshi to develop words that were "young-sounding". There were personal clashes over writing credits on the final script. Pamela's friend Honey Irani believed she deserved a writing credit that she did not receive, and Siddiqui believed Aditya did not deserve partial credit for the dialogue. After "Dilwale Dulhania Le Jayenge", neither of them ever worked with Yash Raj Films again. After approving the script, Yash was consulted about the songs, but mostly left the creative process to his son, and has firmly denied that he was a ghost director on the project. He did not shoot a single frame, and did not even view some portions of the film until it was nearly completed.

Aditya originally wanted the film to be about a relationship between an Indian and an American. He wanted Tom Cruise for the role of Raj but was dissuaded by Yash, who did not want to use a foreign star. They decided their characters would be non-resident Indians (NRIs). Aditya approached Shah Rukh Khan to play the role of Raj. Shah Rukh was initially not interested because of the romantic nature of the role, having had success playing villainous roles. Aditya then asked Saif Ali Khan to play the lead role because he was having problems persuading Shah Rukh to do it. Saif declined for unknown reasons, as did Aamir Khan, causing Aditya to continue pursuing Shah Rukh. Aditya and Shah Rukh had four meetings over several weeks; he finally persuaded Shah Rukh by telling him he could never be a superstar unless he became "every woman's dream man, and every mother's dream son". Since then, Shah Rukh has expressed his gratitude to Aditya for helping to make him a star with this film. Shah Rukh said that fellow actor Salman Khan also encouraged him to do the role, saying that he thought the film would be very successful. Shah Rukh has also noted the similarities in the film's script to his own relationship with Gauri Khan before their marriage.

Kajol was the first choice to play Simran, to which she quickly agreed; she was a good friend of Aditya. She and Shah Rukh had previously worked together in the successful films "Baazigar" (1993) and "Karan Arjun" (1995). Kajol said her character was very difficult for her to relate to, whereas Shah Rukh said Raj's personality was very similar to his own. Aditya chose the name Raj for the character, and the mandolin that he played, based on his admiration for the actor Raj Kapoor. After a successful screen test, Parmeet Sethi was chosen over Armaan Kohli for the role of Kuljeet Singh. In addition to his assistant director Sameer Sharma, Aditya asked for two additional assistants, his brother Uday Chopra and his cousin Karan Johar. Johar also played a small role in the film as Raj's friend. Sharmishta Roy was the film's art director and Manish Malhotra was its costume designer. While Malhotra had many new ideas, Aditya wanted to keep the clothing style simple; he did not want it to distract from the story. Despite this, Malhotra was responsible for the idea of Simran wearing a green dress in the song "Mehndi Laga Ke Rakhna", an unusual colour for a Punjabi bride.

"Dilwale Dulhania Le Jayenge" was filmed in several 5-, 10- and 20-day schedules between September1994 and August1995. The first sequence filmed was for the song "Ho Gaya Hai Tujhko" with Kajol and Shah Rukh in Switzerland. The European journey scenes and songs were mainly filmed in Saanen, Montbovon and Gstaad, Switzerland. Other scenes were shot in England, at locations including Trafalgar Square, King's Cross railway station and Angel Underground station. Film's cinematographer Manmohan Singh, a regular collaborator with Chopra, shot the song "Tujhe Dekha To", including the iconic mustard fields scenes with Shah Rukh and Kajol in the mustard fields in Gurgaon on the outskirts of the National Capital Region Delhi.
The cast faced difficulties while filming the final scene, which shows Simran running to catch the train on which Raj is travelling. The smoldering heat made it difficult to shoot and each time there was a retake, the train took 20 minutes to return.

Saroj Khan was the choreographer throughout most of the production, but after several disputes between her and Aditya, she was replaced by Farah Khan near the end of the shoot. After the film's eventual success, Saroj apologised to Aditya for underestimating him, but she never worked with him again. Farah choreographed the song "Ruk Ja O Dil Deewane", during which Aditya did not tell Kajol that Shah Rukh was going to drop her, as he wanted to capture her genuine reaction. The film's title was suggested by actress Kirron Kher; it came from the song "Le Jayenge Le Jayenge", in the film "Chor Machaye Shor" (1974). The Raj character sings parts of this song during the story, and it recurs at the end. "Dilwale Dulhania Le Jayenge" is believed to be the only Bollywood film with a "Title suggested by" credit. The film has since become universally known by the acronym "DDLJ".

Towards the end of the principal photography, Shah Rukh had to split his time between this film and "Trimurti" (1995), spending half of his day on each film. In early August1995, when filming on "Dilwale Dulhania Le Jayenge" was not yet finished, a release date in October around the time of the Diwali festival was decided upon. Composers Jatin and Lalit Pandit were given only 10 days to complete the background score, and the first copies were printed on 30 September. After filming was complete, Aditya decided to make a Hollywood-style documentary of the film-making process, which had not been done before in India. Karan Johar and Uday were put in charge because they had already been recording some of the process. On 18 October, two days before the film's release, the 30-minute special "Dilwale Dulhania Le Jayenge, The Making" was broadcast on television by Doordarshan.

"Dilwale Dulhania Le Jayenge" repeats the usual conservative agenda of family, courtship and marriage, but it proposes that Indian family values are portable assets that can be upheld regardless of country of residence. To prove this, Raj, an NRI who was brought up in London, is portrayed as the story's "good guy", whereas Kuljeet, raised in India, is portrayed as the villain. This is a reversal of the roles in typical Indian films, which usually portray Indians as being morally superior to Westerners. Here, NRIs are validated as potential model Indian citizens.

The story aims to capture the struggle between traditional family values and the modern value of individualism. Although Raj and Simran want to be together regardless of her father's plans for her, Raj tries to win over his girlfriend's father rather than simply eloping with her. In this and other Indian stories, family values are ultimately considered more important than the romantic plot. Moral values and rules of conduct take precedence over individual desires. The film implies that "Indianness" can be defined by the importance of family life; whether at home or abroad, it is the Indian family system that is recognised as the social institution that most defines Indian identity.

In "Dilwale Dulhania Le Jayenge", the purity/sanctity of women is being related to that of the nation. In the scene after Raj and Simran spend the night together, and Simran is concerned that something happened, Raj tells her: "You think I am beyond values, but I am a Hindustani, and I know what a Hindustani girl's "izzat" (honour) is worth. Trust me, nothing happened last night." This speaks to the Indian diaspora and their need to try and sustain their value system, and the man's responsibility to protect the Indian woman's sexual purity. In "The Routledge Encyclopedia of Films", Ranjani Mazumdar says the film has a running theme of unfulfilled desires, which is exemplified by Raj's father telling him to enjoy life because his own was a struggle, and Simran's mother telling her to run away with Raj because she was unable to live her own dreams.

Scott Jordan Harris, writing for Roger Ebert's website, says the film's popularity lies in its ability to effectively convey two opposing themes appealing to different portions of society. He said, "It argues that we should follow our hearts and chase happiness wherever it leads, regardless of the obstacles in our paths, while simultaneously suggesting we should respect the ways of our elders, particularly our parents, and do nothing that challenges their will". Rachel Dwyer said the film was important for presenting marriage as an understanding between parents and children. While fighting the old tradition of the arranged marriage, it still encouraged the importance of seeking parental consent, even for a love marriage. According to Patricia Uberoi, "Dilwale Dulhania Le Jayenge" reiterates the theme of "Hum Aapke Hain Koun..!" (1994) in a self-conscious manner while also linking it explicitly to the fact that the protagonists tend to remind themselves and each other of what it means to be an Indian.

The "Dilwale Dulhania Le Jayenge" soundtrack features seven songs composed by Jatin Lalit, a duo consisting of the brothers Jatin and Lalit Pandit. Anand Bakshi wrote the lyrics and Lata Mangeshkar, Asha Bhosle, Kumar Sanu, Abhijeet Bhattacharya and Udit Narayan performed the vocals. Jatin Lalit was considered for the job when singer Asha Bhosle contacted Yash Chopra after meeting the duo. It was their first collaboration with Yash Raj Films. They secured the job after singing "Mehndi Laga Ke Rakhna" for Yash. In return, they ensured she sang one song, "Zara Sa Jhoom Loon Main". Pamela Chopra helped them select tunes and instruments to give some of the songs a Punjabi flavour. Bhasker Gupta, writing for AllMusic, said the soundtrack was the best of Jatin Lalit's career, and that it "marked the beginning of the fifth wave in Indian cinema ...". 

The soundtrack became the best-selling Bollywood soundtrack of the year, with 12 million official units sold by HMV, although it is estimated the same number or more copies were pirated. More than 1 million of those sales occurred prior to the film's release, with Chopra earning an advance of for the music rights. Gulshan Kumar sold an unofficial version of the soundtrack under his T-Series label. Combined sales of both the official HMV version and the unofficial T-Series version amounted to 20million copies. The total number of estimated sales including pirated copies range from 25million to over 100million.

In 2005, the album was judged the top Hindi soundtrack of all time by voters on the BBC Asian Network website. Anand Bakshi won his third Filmfare Best Lyricist award after 14 years, having two nominations for this film. The wedding song "Mehndi Laga Ke Rakhna" from the film became an all-time hit; it is played at weddings across the South Asian diaspora. The following is the track listing.

"Dilwale Dulhania Le Jayenge" opened on 20 October 1995 to sold-out shows worldwide. Every show in every theatre in Mumbai—save one—was completely full for the first week. The film was popular among both resident Indians and NRIs. At San Francisco's 720-seat Naz theatre, 1,000 people arrived for the first showing, and the theatre staff were forced to run another show late that night. In the UK, the film ran for over a year, and as of 2017, the Maratha Mandir cinema hall in Mumbai has been showing it for more than 22 years.

The film earned 1.06 billion (valued at about US$32,766,000 in 1995) in India and 160 million (valued at about US$4,946,000 in 1995) overseas; it became the biggest Bollywood grosser of the year, and the second highest-grossing film of the 1990s behind "Hum Aapke Hain Koun..!". It was the second Indian film to gross over 1 billion worldwide, and one of the biggest Bollywood earners of all time. Adjusted for inflation, "Dilwale Dulhania Le Jayenge" is among the highest-grossing Hindi films ever; its domestic net income (533 million at the time) is approximately () when adjusted for inflation. As of 2009, the film had generated over in revenues for the Maratha Mandir since its release. In later years, that theatre ran one matinee show per day at reduced ticket prices, which averaged about 50% occupancy.

"Dilwale Dulhania Le Jayenge" received many favourable reviews. An initial review by weekly magazine "Screen" said of Aditya Chopra, "A young master arrives". Tom Vick, reviewing the film for Allmovie, said, "An immensely likeable movie, "Dilwale Dulhania Le Jayenge" performs the rarely achieved feat of stretching a predictable plot over three hours and making every minute enjoyable." When the film toured the US in 2004 as part of the Cinema India showcase, "The Changing Face of Indian Cinema", Charles Taylor reviewed the film for "Salon" and said, "It's a flawed, contradictory movie—aggressive and tender, stiff and graceful, clichéd and fresh, sophisticated and naive, traditional and modern. It's also, I think, a classic."

Writing for NDTV, Anupama Chopra said, "Perhaps the innocence of Raj and Simran's romance in which they can spend the night together without sex because Raj, the bratish NRI understands the importance of an Indian woman's honor. Perhaps it's the way in which the film artfully reaffirms the patriarchal status quo and works for all constituencies—the NRI and the local viewer. Or perhaps it's the magic of Shah Rukh Khan and Kajol who created a template for modern love, which was hip and cool but resolutely Indian." She also called the film a milestone that shaped Hindi cinema through the 1990s, and one of her personal favourites. In 2004, Meor Shariman of "The Malay Mail" called the film a "must watch" for Bollywood fans, and also for those seeking an introduction to Bollywood.

Raja Sen gave a reflective review for Rediff.com in 2005, calling the film one of the best Hindi films made in the previous 20 years. He said "Shah Rukh Khan gives a fabulous performance, redefining the Lover for the 1990s with great panache", and called Kajol a "real-as-life actress bringing warmth and credulity" to her role. Sen called the film well balanced and said only the fight scene and some mother-daughter dialogue can wear after multiple viewings. Omer M. Mozaffar, writing for Roger Ebert's website in 2012, likened the film to a Disney Princess story, saying, "the young princess feeling trapped by the traditional patriarchy, seeking freedom through discovering the world, but finally finding it through silent, but inappropriate love. The Little Mermaid. Beauty (of the Beast). Jasmine (friends with Aladdin). Pocahontas. Aurora (Sleeping Beauty). And here, Simran." Scott Jordan Harris, also writing for Roger Ebert in 2014, called it "one of the world's favorite films", and said it plays as a masterful soap opera, with one of the best screen couples ever seen. Sogosurvey conducted an online survey in 2016 in which approximately 47% of the people who participated voted "Dilwale Dulhania Le Jayenge" as Bollywood's most evergreen love story.

"Dilwale Dulhania Le Jayenge" was ranked among "The Times of India"'s list of the "10 Bollywood movies you must see before you die". It was one of three Hindi films in the film reference book "1001 Movies You Must See Before You Die", the others being "Mother India" (1957) and "Deewaar" (1975). It was placed twelfth on the British Film Institute's list of top Indian films of all time. It is one of the films on Box Office India's list of "Biggest Blockbusters Ever in Hindi Cinema". The film won a National Film Award and 10 Filmfare Awards, setting the record at the time for the most Filmfare trophies.

In 2001, "Dilwale Dulhania Le Jayenge" overtook "Sholay" (1975), which had run for over five years at the Minerva theatre, as the longest-running film in Indian cinema history. It has been showing at the Maratha Mandir theatre (which was famous for having shown "Mughal-e-Azam" (1960) for three years) since its original release in 1995. There are often people in the audience who have seen the film 50 or more times, but still clap, cheer, mouth the dialogues and sing along with the songs, raising comparisons with "The Rocky Horror Picture Show" (1975), the longest running film in America.

When a theatre strike in early 2011 threatened the film's uninterrupted run, the producer Yash Chopra contacted theatre owners to try and ensure the film would continue. He hoped the film would continue to run for at least 1,000 weeks, which it achieved in December2014. To commemorate the event, cast members including Shah Rukh Khan, Kajol, Anupam Kher, Farida Jalal, Mandira Bedi and Pooja Ruparel appeared on the television show "Comedy Nights with Kapil". Shah Rukh Khan, Kajol and director Aditya Chopra also attended a live chat with fans and a black tie event at the theatre on 12 December. The same day, they launched a coffee table book written by Aditya Chopra about the making of the film. Also in December, Yash Raj Films announced the availability of a collection of commemorative, licensed merchandise from various suppliers to mark the event. The Maratha Mandir's management ended the film's run after 1,009 weeks on 19 February2015 because of low attendance (the last show was viewed by 210 people). However, after an outpouring of support from fans, and talks with the production company, they decided to reinstate the film.

"Dilwale Dulhania Le Jayenge" spawned many imitators of its story and style, especially throughout the 1990s. According to the "Encyclopaedia of Hindi Cinema", it and a handful of other films and young directors started a trend for "designer" films. The authors said that these were "a carefully packaged and branded product in which every little visual and physical detail ... is of utmost importance". In "Bollywood's Top 20: Superstars of Indian Cinema", Namrata Joshi said "Dilwale Dulhania Le Jayenge" "reinvented Bollywood romances so decisively that we can neatly divide them into two eras—before "DDLJ" and after "DDLJ"".

Yash Raj Films was previously known for using locations outside India for item numbers in its films. "Dilwale Dulhania Le Jayenge" started the trend for films designed to appeal to the Indian diaspora, which have foreign locations as integral parts of the story. The characters are themselves diaspora and tend to be able to move with ease between India and the West. Some later films that followed this trend include "Pardes" (1997), "Kabhi Khushi Kabhie Gham..." (2001), "Kal Ho Naa Ho" (2003), "Salaam Namaste" (2005), "Neal 'n' Nikki" (2005) and "Kabhi Alvida Naa Kehna" (2006). "Dilwale Dulhania Le Jayenge" became the first Hindi film blockbuster to feature NRIs as main characters. It helped to establish the diaspora market as a vital source of revenue for the industry; that market was seen as a safer financial investment than the desi market.

Several later films have paid homage to "Dilwale Dulhania Le Jayenge". The Karan Johar-produced "Humpty Sharma Ki Dulhania" (2014) was directly inspired by it. The films "Jab We Met" (2007), "Bodyguard" (2011), "Chalo Dilli" (2011), "Yeh Jawaani Hai Deewani" (2013) and "Chennai Express" (2013) include scenes similar to the climactic train sequence, wherein a woman is running to catch a moving train and is helped aboard by a man with his outstretched arm. The British film "Slumdog Millionaire" (2008) contained a similar train scene, and its final dance sequence was partially shot at the same railway station as the "Dilwale Dulhania Le Jayenge" finale.

Audiences appreciated the screen chemistry between Shah Rukh Khan and Kajol, who later worked together in several successful films including "Kuch Kuch Hota Hai" (1998), "Kabhi Khushi Kabhie Gham..." (2001), "My Name Is Khan" (2010), and "Dilwale" (2015), and are often referred to as Indian cinema's most loved on-screen couple. Shah Rukh Khan credits this film with making him a star, and says it "changed the entire scene for romantic movies of the 90s". During an interview in 2002, he said "Whatever I'll stand for as an actor, in the whole of my career, whenever it ends, it will start with and end at "Dilwale"". The actress Farida Jalal said the film gave her career a boost, saying she got many offers and "could quote any price". It also helped the young careers of Pooja Ruparel, who received advertising offers, and of Sharmistha Roy.

The British Film Institute (BFI) commissioned a book about "Dilwale Dulhania Le Jayenge". It was the first Hindi film chosen for a series of studies on international films, called "BFI Modern Classics". The author was Anupama Chopra and the book was released in 2002. It was reissued in paperback by Harper-Collins as "Dilwale Dulhania Le Jayenge: The Making of a Blockbuster" in 2004. After an unexpectedly long delay, the film was released on DVD by Yash Raj Films in 2002. The release included "The Making" and "300 Weeks Celebration" documentaries, "Success Story" (highlights from the film's premiere), clips from the 41st Filmfare Awards ceremony and other interviews.

In 2006, members of the film crew were honoured at a dinner event to celebrate the film's 500th week since release. It was hosted by the Consulate General of Switzerland in Mumbai and by Switzerland Tourism. In 2010, Yash Raj Films signed an agreement with Indian and Swiss tour companies to provide a tour package called "YRF Enchanted Journey", to allow visitors to Switzerland to view filming locations used for famous Yash Raj films including "Dilwale Dulhania Le Jayenge". In 2014, Yash Raj Films released "Aditya Chopra Relives ... Dilwale Dulhania Le Jayenge (As Told to Nasreen Munni Kabir)", an attractive but expensive book about the making of the film. In response to Indian prime minister Narendra Modi quoting the line "May the force be with you" from the American film franchise "Star Wars" during a visit to the US, President Barack Obama decided to quote a line from a Hindi film during his visit to India in January2015. He chose a line from this film, ""Senorita, bade bade deshon mein ..."" (Miss, in large countries ...), and added "you know what I mean".




</doc>
