<doc id="307179" url="https://en.wikipedia.org/wiki?curid=307179" title="McDonnell XF-85 Goblin">
McDonnell XF-85 Goblin

The McDonnell XF-85 Goblin is an American prototype fighter aircraft conceived during World War II by McDonnell Aircraft. It was intended to deploy from the bomb bay of the giant Convair B-36 bomber as a parasite fighter. The XF-85's intended role was to defend bombers from hostile interceptor aircraft, a need demonstrated during World War II. McDonnell built two prototypes before the Air Force (USAAF) terminated the program.

The XF-85 was a response to a USAAF requirement for a fighter to be carried within the Northrop XB-35 and B-36, then under development. This was to address the limited range of existing interceptor aircraft compared to the greater range of new bomber designs. The XF-85 was a diminutive jet aircraft featuring a distinctive egg-shaped fuselage and a forked-tail stabilizer design. The prototypes were built and underwent testing and evaluation in 1948. Flight tests showed promise in the design, but the aircraft's performance was inferior to the jet fighters it would have faced in combat, and there were difficulties in docking. The XF-85 was swiftly canceled, and the prototypes were thereafter relegated to museum exhibits. The 1947 successor to the USAAF, the United States Air Force (USAF), continued to examine the concept of parasite aircraft under Project MX-106 "Tip Tow", Project FICON and Project "Tom-Tom" following the cancellation.

During World War II, American bombers such as the Boeing B-17 Flying Fortress, Consolidated B-24 Liberator and Boeing B-29 Superfortress were protected by long-range escort fighters such as the Republic P-47 Thunderbolt and North American P-51 Mustang. These fighters could not match the range of the Northrop B-35 or Convair B-36, the next generation of bombers developed by the United States Army Air Forces (USAAF). The development cost for longer-ranged fighters was high, while aerial refueling was still considered risky and technologically difficult. Pilot fatigue had also been a problem during long fighter escort missions in Europe and the Pacific, giving further impetus to innovative approaches.

The USAAF considered a number of different options including the use of remotely piloted vehicles before choosing parasite fighters as the most viable B-36 defense. The concept of a parasite fighter had its origins in 1918, when the Royal Air Force examined the viability of Sopwith Camel parasite fighters operating from "R23" airships. In the 1930s, the U.S. Navy had a short-lived operational parasite fighter, the Curtiss F9C Sparrowhawk, aboard the airships and . Starting in 1931, aircraft designer Vladimir Vakhmistrov conducted experiments in the Soviet Union as part of the Zveno project during which up to five fighters of various types were carried by Polikarpov TB-2 and Tupolev TB-3 bombers. In August 1941, these combinations flew the only combat missions ever undertaken by parasite fighters – TB-3s carrying Polikarpov I-16SPB dive bombers attacked the Cernavodă bridge and Constantsa docks, in Romania. After that attack, the squadron, based in the Crimea, carried out a tactical attack on a bridge over the river Dnieper at Zaporozhye, which had been captured by advancing German troops. Later in World War II, the "Luftwaffe" experimented with the Messerschmitt Me 328 as a parasite fighter, but problems with its pulsejet engines could not be overcome. Other late-war rocket-powered parasite fighter projects such as the Arado E.381 and Sombold So 344 were unrealized "paper projects".

On 3 December 1942, the USAAF sent out a Request for Proposals (RfP) for a diminutive piston-engined fighter. By January 1944, the Air Technical Service Command refined the RfP and in January 1945, the specifications were further revised in MX-472 to specify a jet-powered aircraft. Although a number of aerospace companies studied the feasibility of such aircraft, McDonnell was the only company to submit a proposal to the original 1942 request and later revised requirements. The company's Model 27 proposal was completely reworked to meet the new specifications.

The initial concept for the Model 27 was for the fighter to be carried half-exposed under the B-29, B-35 or B-36. The USAAF rejected this proposal, citing increased drag, and hence reduced range for the composite bomber-fighter configuration. On 19 March 1945, McDonnell's design team led by Herman D. Barkey, submitted a revised proposal, the extensively redesigned Model 27D. The smaller aircraft had an egg-shaped fuselage, three fork-shaped vertical stabilizers, horizontal stabilizers with a significant dihedral, and 37° swept-back folding wings to allow it to fit in the confines of a bomb bay. The diminutive aircraft measured long; the folding wings spanned . Only a limited fuel supply of was deemed necessary for the specified 30-minute combat endurance. A hook was installed along the aircraft's center of gravity; in flight, it retracted to lie flat in the upper part of the nose. The aircraft had an empty weight just short of . To save weight, the fighter had no landing gear. During the testing program, a fixed steel skid under the fuselage and spring-steel "runners" at the underside of the wingtips were installed in case of an emergency landing. Despite the cramped quarters, a pilot was provided with a cordite ejection seat, bail-out oxygen bottle and high-speed ribbon parachute. Four machine guns in the nose made up the aircraft's armament.

In service, the parasite fighter would be launched and retrieved by a trapeze. With the trapeze fully extended, the engine would be airstarted and the release from the mother ship was accomplished by the pilot pulling the nose back to disengage from the hook. In recovery, the aircraft would approach the mother ship from underneath and link up with the trapeze using the retractable hook in the aircraft's nose. The anticipated production shift would see a mixed B-36 fleet with both "fighter carriers" and bombers employed on missions. There were plans that, from the 24th B-36 onward, provisions would be made to accommodate one XF-85, with a maximum of four per bomber envisioned. Up to 10 percent of the B-36s on order were to be converted to fighter carriers with three or four F-85s instead of a bomb load.
On 9 October 1945, the USAAF signed a letter of intent covering the engineering development for two prototypes (US serial numbers "46-523/4"), although the contract was not finalized until February 1947. After the successful conclusion of two reviews of a wooden mock-up in 1946 and 1947 by USAAF engineering staff, McDonnell constructed two prototypes in late 1947. The Model 27D was re-designated XP-85, but by June 1948, it was changed to XF-85 and given the name "Goblin". There were plans to acquire 30 production P-85s, but the USAAF took the cautious approach – if test results from the two prototypes were positive, production orders for more than 100 Goblins would be finalized later.

During wind tunnel testing at Moffett Field, California, the first prototype XF-85 was accidentally dropped from a crane at a height of , causing substantial damage to the forward fuselage, air intake and lower fuselage. The second prototype had to be substituted for the remainder of the wind tunnel tests and the initial flight tests.

As a production series B-36 was unavailable, all XF-85 flight tests were carried out using a converted EB-29B Superfortress mother ship that had a modified, "cutaway" bomb bay complete with trapeze, front airflow deflector and an array of camera equipment and instrumentation. Since the EB-29B, named "Monstro", was smaller than the B-36, the XF-85 would be flight tested, half-exposed. To load the XF-85 into the host plane, a special "loading pit" was dug into the tarmac at South Base, Muroc Field, where all the flight tests originated. On 23 July 1948, the XF-85 flew the first of five captive flights, designed to test whether the EB-29B and its parasite fighter could fly "mated". The XF-85 was carried in a stowed position, but was sometimes tethered and extended into the airstream with the engine off, for the pilot to gain some feel for the aircraft in flight.
McDonnell test pilot Edwin Schoch was assigned to the project, riding in the XF-85 while it was stowed aboard the EB-29B, before attempting a "free" flight on 23 August 1948. After Schoch was released from the bomber at a height of 20,000 ft (6,000 m), he completed a 10-minute proving flight at speeds between 180 and 250 mph (290–400 km/h), testing controls and maneuverability. When he attempted a hook-up, it became obvious the Goblin was extremely sensitive to the bomber's turbulence, as well as being affected by the air cushion created by the two aircraft operating in close proximity. Constant but gentle adjustments of throttle and trim were necessary to overcome the cushioning effect. After three attempts to hook onto the trapeze, Schoch miscalculated his approach and struck the trapeze so violently that the canopy was smashed and ripped free and his helmet and mask were torn off. He saved the prototype by making a belly landing on the reinforced skid at the dry lake bed at Muroc. All flight testing was suspended for seven weeks while the XF-85 was repaired and modified. Schoch used the down period to undertake a series of problem-free dummy dockings with a Lockheed P-80 Shooting Star fighter.

After boosting the trim power by 50 percent, adjusting the aerodynamics, and other modifications, two further mated test flights were carried out before Schoch was able to make a successful release and hookup on 14 October 1948. During the fifth free flight on 22 October 1948, Schoch again found it difficult to hook the Goblin to the bomber's trapeze, aborting four attempts before hitting the trapeze bar and breaking the hook on the XF-85's nose. Again, a forced landing was successfully carried out at Muroc.

With the first prototype's repairs completed, it also joined the flight test program, completing captive flights. While in flight, the Goblin was stable, easy to fly, and recoverable from spins, although initial estimates of a 648 mph (1,043 km/h) top speed proved optimistic. The first test flights revealed that turbulence during approach to the B-29 was significant, leading to the addition of upper and lower fins at the extreme rear fuselage, as well as two wingtip fins to compensate for the increased directional instability in docking. All the initial flights had the hook secured in a fixed position, but when the hook was stowed and later raised, the resulting buffeting added to the difficulty in attempting a hookup. To address the problem, small aerodynamic fairings were added to the hook well that reduced the buffeting when the hook was extended and retracted. When testing resumed, on the 18 March 1948 test flight, Schoch continued to have difficulty in hooking up, striking and damaging the trapeze's nose-stabilizing section, before resorting to another emergency belly landing. After repairs to the trapeze, Schoch flew the first prototype on 8 April 1949, completing a 30-minute free flight test, but after three attempts, abandoned his efforts and resorted to another belly landing at Muroc.

Aware of the problems revealed in flight tests, McDonnell reviewed the program and proposed a new development based on a more conventional design promising a Mach 0.9 capability, using alternatively a 35° swept wing and delta wing. McDonnell also considered adding a telescoping extension to the docking trapeze that would extend the device below the turbulent air under the mother ship. Before any further work on the trapeze, other modifications to the XF-85, or continued design studies on its follow-up could be carried out, the USAF canceled the XF-85 program on 24 October 1949.

Two main reasons contributed to the cancellation. The XF-85's deficiencies revealed in flight testing included a lackluster performance in relation to contemporary jet fighters, and the high demands on pilot skill experienced during docking revealed a critical shortcoming that was never fully corrected. The development of practical aerial refueling for conventional fighters used as bomber escort was also a factor in the cancellation. The two Goblins flew seven times, with a total flight time of 2 hours and 19 minutes with only three of the free flights ending in a successful hookup. Schoch was the only pilot who ever flew the aircraft.

Despite cancellation of the XF-85, the USAF continued to examine the concept of parasite aircraft as defensive fighters through a series of projects. These included Project MX-106 "Tip Tow", Project FICON, and Project "Tom-Tom"—which involved fighter aircraft attached to bomber aircraft by their wingtips. Project FICON ("fighter conveyor") emerged as an effective Convair GRB-36D and Republic RF-84K Thunderflash combined bomber-reconnaissance-fighter, although the role was changed to that of strategic reconnaissance. Project FICON drew heavily on data from the abortive XF-85 project and closely followed McDonnell's recommendations in designing a more refined trapeze. A total of 10 converted B-36s and 25 reconnaissance fighters saw limited service with the Strategic Air Command in 1955–1956, before they were supplemented by more effective aircraft and satellite systems.

After the program's termination, the two XF-85 prototypes were stored, before being surplussed and relegated to museum display in 1950.



</doc>
<doc id="307967" url="https://en.wikipedia.org/wiki?curid=307967" title="Hoodening">
Hoodening

Hoodening (), also spelled hodening and oodening, is a folk custom found in Kent, a county in south-eastern England. The tradition entails the use of a wooden hobby horse known as a hooden horse that is mounted on a pole and carried by an individual hidden under a sackcloth. Originally, the tradition was restricted to the area of East Kent, although in the twentieth century it spread into neighbouring West Kent. It represents a regional variation of a "hooded animal" tradition that appears in various forms throughout the British Isles.

As recorded from the eighteenth to the early twentieth centuries, hoodening was a tradition performed at Christmas time by groups of farm labourers. They would form into teams to accompany the horse on its travels around the local area, and although the makeup of such groups varied, they typically included an individual to carry the horse, a leader, a man in female clothing known as a "Mollie", and several musicians. The team would then carry the hooden horse to local houses and shops, where they would expect payment for their appearance. Although this practice is extinct, in the present the hooden horse is incorporated into various Kentish Mummers plays and Morris dances that take place at different times of the year.

The origins of the hoodening tradition, and the original derivation of the term "hooden", remain subject to academic debate. An early suggestion was that "hooden" was related to the Anglo-Saxon pre-Christian god Woden, and that the tradition therefore originated with pre-Christian religious practices in the early medieval Kingdom of Kent. This idea has not found support from historians or folklorists studying the tradition. A more widely accepted explanation among scholars is that the term "hooden" relates to "hooded", a reference to the sackcloth worn by the individual carrying the horse. The absence of late medieval references to such practices and the geographic dispersal of the various British hooded animal traditions—among them the Mari Lwyd of south Wales, the Broad of the Cotswolds, and the Old Ball, Old Tup, and Old Horse of northern England—have led to suggestions that they derive from the regionalised popularisation of the sixteenth and seventeenth-century fashion for hobby horses among the social elite.

The earliest textual reference to the hoodening tradition comes from the first half of the eighteenth century. Scattered references to it appeared over the next century and a half, many of which considered it to be a declining tradition that had died out in many parts of Kent. Aware of this decline, in the early twentieth century the folklorist and historian Percy Maylam documented what survived of the tradition and traced its appearances in historical documents, publishing his findings as "The Hooden Horse" in 1909. Although deemed extinct at the time of the First World War, the custom was revived in an altered form during the mid-twentieth century, when the use of the hooden horse was incorporated into some modern Kentish folk traditions.

Surviving sources testify to the fact that while there was some variation in the hoodening tradition as it was practiced by different individuals in different parts of East Kent, it was nevertheless "on the whole remarkably uniform". The hooden horse, which was at the centre of the tradition, was usually made out of a wooden horse's head affixed to a pole about four feet long, with a hinged jaw that was moved by a string. This horse was then carried aloft by an individual who was concealed beneath a dark cloth. As part of the hoodening custom, a team of "hoodeners", consisting of between four and eight men, would carry the horse through the streets. This team included the horse operator, a "Groom", "Driver", or "Waggoner" who carried a whip and led the horse by a bridle, a "Jockey" who would attempt to mount the horse, a "Mollie" who was a man dressed as a woman, and one or two musicians. All of the men were farm labourers, usually being those who worked with horses. 

The team performed the custom at Christmas time, and usually on Christmas Eve. The team would arrive at people's houses where they would sing a song before being admitted entry. Once inside, the horse pranced and gnashed its jaw, while the Jockey attempted to mount it, and the Mollie swept the floor with a broom while chasing any girls present. Sometimes they would sing further songs and carols. Upon being presented with payment, the team would leave to repeat the process at another house.

Historians have catalogued 33 recorded instances of the hoodening tradition extant in Kent prior to the twentieth-century revival. These are clustered in a crescent shape along the eastern and northern coasts of the county, and all were found within the area historically defined as East Kent, the tradition being unknown in neighbouring West Kent. More specifically, the folklorist Percy Maylam noted that there were no records of the tradition having been found west of Godmersham. This region was "a well populated area" during the period in which the hoodeners were active, and Maylam noted that all of the areas in which the tradition was found contained the East Kentish dialect. The folklorist E. C. Cawte analysed the historical distribution of the hoodeners and found that it did not correspond with the areas of early Anglo-Saxon settlement in Kent, nor did it accord with the county's coal mining areas. He concluded that "there is no apparent reason why the custom did not spread further afield".

Hoodening was part of a wider "hooded animal" tradition that Cawte identified as existing in different forms in various parts of Britain. Features common to these customs were the use of a hobby horse, the performance at Christmas time, a song or spoken statement requesting payment, and the use of a team who included a man dressed in women's clothing. In South Wales, the Mari Lwyd tradition featured troupes of men with a hobby horse knocking at doors over the Christmas period. In an area along the border between Derbyshire and Yorkshire, the Old Tup tradition featured groups knocking on doors around Christmas carrying a hobby horse that had a goat's head. The folklorist Christina Hole drew parallels between hoodening and the Christmas Bull tradition recorded in Dorset and Gloucestershire. In south-west England, there are two extant hobby horse traditions—the Padstow 'Obby 'Oss festival and Minehead Hobby Horse—which take place not at Christmas time but on May Day.
Although the origins of these traditions are not known with any certainty, the lack of any late medieval references to such practices may suggest that they emerged from the documented elite fashion for hobby horses in the sixteenth and seventeenth centuries. In this, the hooded animal traditions may be comparable to England's Morris dance tradition, which became a "nation-wide craze" in the sixteenth and seventeenth centuries before evolving into "a set of sharply delineated regional traditions".

Maylam noted that most nineteenth-century sources describing the tradition had spelled the word as "hoden", but that he favoured "hooden" because it better reflected the pronunciation of the word with its long vowel. He added that "the word 'hooden' rhymes with 'wooden' and not with 'sodden' as some writers appear to think". Given this pronunciation, Cawte suggested that "oodening" was a better spelling for the tradition's name. Maylam also noted that none of the hoodeners with whom he communicated were aware of the etymology of the term, and that similarly they were unaware of the tradition's historical origins.

The term "hoodening" is thus of unknown derivation. One possible explanation for the origin of "hooden" was that it had emerged as a mispronunciation of "wooden", referring to the use of the wooden horse. Maylam was critical of this idea, expressing the view that such a mispronunciation was unlikely to emerge from the Kentish dialect. A second possibility is that the name "hooden" was a reference to the hooded nature of the horse's bearer. The historian Ronald Hutton deemed this to be the "simplest" derivation, while folklorists Cawte and Charlotte Sophia Burne also considered it the most likely explanation. Maylam was also critical of this, suggesting that the cloth under which the carrier was concealed was too large to be considered a hood.
In his "History of Kent", the antiquarian Alfred John Dunkin suggested that "Hodening" was a corruption of "Hobening", and that it was ultimately derived from the Gothic "hopp", meaning horse. Maylam opined that Dunkin's argument could be "ignored", stating that it rested on the erroneous assumption that "Hodening" began with a short vowel.

Maylam concluded that the hoodening tradition was "a mutilated survival" of a form of Morris dance. Noting that some medieval Morris dancers had incorporated games devoted to the English folk hero Robin Hood into their custom, he suggested that "hoodening" might have originally been a reference to Robin Hood. This idea was challenged by Burne, who noted that in his legends, Robin Hood was always depicted as an archer rather than a horse-rider, thus questioning how he had come to be associated with the hooden horse. She further noted that the medieval games devoted to Robin Hood all took place in May rather than at Christmas, as hoodening did. Cawte also criticised Maylam's argument, noting that there was no evidence of Morris dancing in Kent prior to the twentieth century, and that neither hoodening nor Robin Hood had a particularly close association with the Morris dance to start with.

In 1807, an anonymous observer suggested that the term "hoden" was linked to the Anglo-Saxon god Woden, and that the tradition might be "a relic of a festival to commemorate our Saxon ancestors landing in Thanet". In 1891, it was suggested that the custom had once been known as "Odining", a reference to the early medieval Scandinavian god Odin. The author of this idea further suggested that the custom had begun either with the ritual wearing of the skins of horses sacrificed to Odin, or as an early Christian mockery of such Odinic practices. 

Maylam noted that he was initially attracted to the idea that the term "hodening" had derived from "Woden"—an Old English name that he thought a more likely origin than the Old Norse "Odin"—but that upon investigating this possibility found "no sufficient evidence" for it. He added that it would seem unlikely that the "W" would be lost from "Woden" in the Kentish dialect, citing the example of Woodnesborough, a Kentish village whose name is often interpreted as having derived from "Woden" and which clearly retains its use of "W". He concluded that "one feels that the theory is based on inferences and analogies not strong enough for a foundation to carry the building erected on them". The idea of linking the tradition to Woden was also dismissed as unlikely by both Burne and Cawte.

Believing it likely that the hoodening tradition "substantially pre-dates" its earliest textual appearances, the folklorist Geoff Doel suggested the possibility that it had originated as a Midwinter rite to re-energise the vegetation. As evidence for this claim, Doel noted that other English winter folk customs, such as the Apple Wassail, have also been interpreted in this manner. He also suggested that the use of the horse in the tradition may have some connections to either the use of the white horse as the symbol of Kent, and the use of Hengist and Horsa (meaning "stallion" and "horse" in Old English) as prominent characters in the origin myths of the early medieval Kingdom of Kent.

The oldest known textual reference to hoodening comes from the "Alphabet of Kenticisms", a manuscript authored by Samuel Pegge, an antiquary who served as the vicar of Godmersham in Kent from 1731 to 1751. After Pegge died, the manuscript was obtained by the palaeographer Sir Frederic Madden, and after his death it was purchased by the English Dialect Society, who published it in 1876. In this manuscript, Pegge noted simply that "Hoodening (huod.ing) is a country masquerade at Christmas times", comparing it to Mumming and the Winster Guisers of Derbyshire.

The earliest known textual description of the tradition is provided by a letter that was published in a May 1807 edition of "European Magazine". The letter had been written by an anonymous individual who was describing an encounter with the hoodeners on a visit to the Kentish coastal town of Ramsgate in Thanet:

Later commenting on this source, Maylam highlighted that its author did not appear to be from Kent and that, from their use of wording, it appeared that they had been told about the tradition by locals but had not actually witnessed it first hand. As such, Maylam suggested that the author may have been wrong in describing the use of a horse's skull in the Ramsgate tradition, given that both later sources and the hoodeners of his own time all used a wooden model of a horse's head. At the same time, Maylam noted that the use of a horse's skull was not impossible, for such skulls had also been used in the hobby horse traditions of other parts of Britain.

The anonymously authored account was repeated almost verbatim in a range of other publications in the coming decades, giving its description far wider exposure. The first printed reference to the hooden horse having a wooden head appeared in Mackenzie E. C. Walcott's "Guide to the Coast of Kent", published in 1859, where he referred to a "curious custom [which] used to prevail" in Ramsgate. Maylam later suggested that the Ramsgate hooden horse tradition died out between 1807 and 1838, for he had interviewed elderly town residents in the early twentieth century and while several were aware that it had once taken place in the town, none could recall it happening in their own lifetime.

Many years after the event, the Kentish antiquarian J. Meadows Cooper related that while sitting in a pub on the outskirts of Margate on Boxing Day 1855 he had encountered a party carrying a hooden horse that entered the building. Another local resident, Mrs. Edward Tomlin, later related that as a child she had lived at a house named Updown, near Margate, and that she remembered the hooden horse visiting them at Christmas time during the 1850s and up until 1865. Maylam's researches also found recollections of a hooden horse that had appeared in Herne and Swalecliffe but which had been discontinued in the 1860s, another that was active from Wingate Farm House in Harbledown during the 1850s, and one that had been active at Evington but which had ceased by the 1860s. He found another based at Lower Hardres that had been active from at least the 1850s under the leadership of Henry Brazier; it was subsequently taken over by his son John, until the tradition ended locally in 1892.
In a January 1868 edition of the "Kentish Gazette", an anonymous author mentioned that hoodening had taken place in Minster, Swale on the Christmas Eve of 1867. The author noted that the tradition featured carol singing and the ringing of handbells, which were accompanied by the appearance of a hooden horse; they expressed surprise at this latter event because they had thought that the horse was "as extinct as the megatherium".

In their 1888 "Dictionary of the Kentish Dialect", W. D. Parish and W. F. Shaw claimed that "Hodening" was a term used in Kent to refer to a custom involving the singing of carols, but that in the past "Hoodening" had been applied to "a mumming or masquerade" involving the hooden horse. They added that they had gained information on this older custom in 1876 from the Reverend H. Bennett Smith of St Nicholas-at-Wade, who had in turn learned from a retired farmer in his parish that "the farmer used to send annually round the neighbourhood the best horse under the charge of the wagoner, and that afterwards instead, a man used to represent the horse, being supplied with a tail, and with a wooden figure of a horse's head, and plenty of horse hair for a mane... The custom has long since ceased."

Parish and Shaw did not mention what time of year the tradition took place or its geographical location. They also made no reference to a sack concealing the person carrying the horse. Doel thought it likely that neither Parish or Shaw had ever seen a hooden horse, and that instead their information was based on older written sources. He also thought it noteworthy that they described the tradition using the past tense, indicating that they considered it to be either dead or dying at the time of writing. Maylam believed that the information regarding the decline of the tradition was erroneous, because hoodeners were still active in St. Nicholas-at-Wade during the early twentieth century and various locals living in the area at the time could recall it taking place in the area back to the 1840s.

In December 1889, a letter written by a resident of St. Lawrence named Charles J. H. Saunders appeared in the "Bromley Record". Saunders stated that he had conversed with many elderly residents of Thanet on the subject of hoodening, and that they informed him that the custom had been discontinued around fifty years previously, after a woman in Broadstairs was so scared by the hooden horse that she died. He added that a horse's skull was rarely used, "owing to the difficulty procuring one", and that the wooden head was thus typically used as a replacement. He stated that the hoodening company typically consisted of a "Jockey" who placed himself on the back of the individual carrying the horse, and that it was the "sport" that bystanders attempted to throw him off, resulting in violence. The horse and jockey were also accompanied by two singers, two attendants, and an individual dressed as an "old woman" carrying a broom; when the company knocked on people's doors, it was the old woman's job to sweep the inhabitants feet away with her broom and to chase any girls until being paid off with money or refreshments. He was of the opinion that the custom had been restricted to the Isle of Thanet, noting that locals informed him that it had been carried out in Ramsgate, St. Lawrence, Minster, St. Nicholas, Acol, Monkton, and Birchington. Contradicting this were several letters published in the "Church Times" in January 1891 which attested to the continuing practice of the hooden horse tradition at both Deal and Walmer.

Percy Maylam was born into a farming family in 1865 at Pivington Farm in Pluckley, and in 1890 became a solicitor of the Supreme Court before working as a solicitor at Canterbury. As well as being a keen cricketer and coin collector, Maylam was an amateur historian and in 1892 joined the Kent Archaeological Society. During the 1880s, Maylam came upon the hoodening tradition and began undertaking research into it, searching for textual references to the tradition in books, periodicals, and newspapers, and interviewing those involved in three extant traditions, at St Nicholas-at-Wade, Walmer, and Deal. He expressed the opinion that "in these days Kent possesses so few genuine popular customs of this kind that we cannot afford to be indifferent to those still in existence. This is my excuse for my attempt to record the custom as now existing before it is utterly lost to us." 

The period in which Maylam conducted his research was one that was witnessing increased interest in the recording of Britain's rural folk culture, in particular by members of the professional classes—of which Maylam was a member—in part due to the fear that such traditions were rapidly dying out. Such folklore collecting was encouraged by The Folklore Society, with whom Maylam was associated, and also by the widely read book "The Golden Bough", a work of comparative folkloristics authored by the anthropologist James Frazer. Maylam published his research in 1909 as "The Hooden Horse", in an edition limited to 303 copies. The book was reviewed in the journal "Folklore" by Burne, who described it as "an admirable piece of work, careful, thorough, unambitious, and complete in itself". Cawte later described it as "unusually good", while Fran and Geoff Doel regarded it as "a very enlightened piece of Edwardian folk research".

Maylam concluded that at the time, there was only one hooden horse still in active use in Thanet, that stored at Hale Farm in St. Nicholas-at-Wade, which he noted was brought out each Christmas to visit Sarre, Birchington, and St. Nicholas-at-Wade itself. The members included a man in female garb, known as the Mollie, in their procession, but added that this had not been done for some time and was thus reintroduced for Maylam's benefit. In his book, Maylam included a photograph of the horse taken at Sarre in 1905. On Christmas Eve 1906, Maylam encountered a second hooden horse, this time at Walmer. This horse came into the local hotel tearoom at about 6.30 pm, accompanied by two musicians—one playing the tambourine and the other the concertina—and a man named Robert Laming who led the horse itself. They were wearing ordinary clothes, but informed Maylam that they had once worn smock frocks as part of the tradition. They had no Mollie, and the members could not recall a Mollie ever having been part of their custom. The hotel owner's daughter placed a gratuity in the horse's mouth, before the troupe moved on to the local shops, where they were also given gratuities in a similar manner. Maylam talked to the troupe about the tradition, and eventually organised the photographing of the Walmer horse and those who accompanied it in March 1907.

Maylam also interviewed those involved in the hoodening tradition at Deal, whom he encountered in the summer of 1909. One elderly gentleman, Robert Skardon, related that his father had once led the town's hoodening troupe, in which he personally carried the head, his father the drum, his "Uncle John Beaney" the fiddle, and "old Harry Chorner" the piccolo. For many years they had included a man dressed in woman's clothing, who was known as a "Daisy" rather than a "Mollie", but that this had been discontinued. Skardon had given up the tradition many years previously, and the hooden horse itself had come into the possession of Elbridge Bowles of Great Mongeham, who continued to lead a hoodening troupe after Christmas each year, visiting Deal as well as the neighbouring villages of Finglesham, Ripple, Tilmanstone, Eastry, and Betteshanger. Maylam was also informed that at the time of Britain's involvement in the Second Boer War, the horse had been decorated with military equipment. The fourth hooden horse that Maylam encountered was owned by the men who worked at George Goodson's farm in Fenland, Word, near Sandwich. They informed him that it had been made by a farm hand in Cleve, Monkton, before being brought to Word when one of the Cleve farm workers relocated there.

Maylam believed that the custom—as a "natural and spontaneous observance" among the people—was clearly going to die out, expressing his hope that the hooden horses could be preserved in Kentish museums and brought out for specially arranged public processions so as to maintain their place in Kentish culture. In later life, Maylam focused his attentions on exploring his family history, privately publishing "Maylam Family Records" in 1932, before dying in 1939. In the century following his death, Maylam's book on hoodening became difficult to obtain and expensive to purchase, and so to mark the centenary of its first publication, it was republished in 2009 by The History Press, under the altered title of "The Kent Hooden Horse". Writing an introductory article for the second publication, Doel, a specialist in Kentish folklore, praised Maylam's book as a "classic study" which was "impressive for its separation of fact from speculation as to the origins and significance of the custom."

Writing in 1967, the folklorist Barnett Field claimed that at some point after Maylam's book was published, hoodening had "died out. The Horses were hung up in the stables, and when the tractors came, were taken out and burnt on the bonfire." Doel and Doel later suggested that it was the impact of the First World War which effectively ended the tradition. Field noted that the first revival of the custom after the war took place at the 1936 Kent District Folk-Dance Festival at Aylesford. A new horse was specially created for this festival, and was modelled on an older example that had been used at Sarre. The hobby horse had not previously had any connection with Morris dancing, although was adopted as a totem animal for several Morris sides after the Second World War. This revival in the usage of the horse was heavily influenced by Maylam's book. The Aylesford horse was adopted by the Ravensbourne Morris Men, a Morris troupe based in the West Kentish village of Keston, in 1947. The Ravensbourne Morris's hoodening tradition is the earliest known variant of the custom to exist in West Kent, although there are accounts of a hooden horse being located at Balgowan School in the West Kentish town of Beckenham during the 1930s. At the 1945 celebration marking British victory in the Second World War, a horse was brought out in Acol; this instance has been described as "a kind of missing link between tradition and revival" because the horse had been used as part of the historical hoodening tradition up until the mid-1920s.

Barnett Field (1912–2000) as born at Wych Cross in the Ashdown Forest and subsequently educated at Tunbridge Wells. He trained as a banker before working as manager of the Hythe and Folkestone branches of the Westminster Bank until his retirement in 1979. Field and his wife, Olive Ridley, had a keen interest in folk dances; she established the Folkestone National Folk Dance Group in 1950, and he founded the East Kent Morris Men in 1953. Field constructed a hooden horse for the group to use, based in large part on the Deal horse photographed for Maylam's book, and unveiled it at the Folkestone celebrations for the Coronation of Queen Elizabeth II in June 1953. After this, it came to be used by both the East Kent Morris Men and the Folkestone District National Dance Group's Handbell Ringers, who took it with them for performances in various parts of continental Europe, including Austria, the Netherlands, Yugoslavia, Sweden, and Czechoslovakia, developing what came to be known as "handbell hoodening". The Handbell Ringers also brought out the horse to accompany them as they went around in public collecting money for charity at Christmas time.

From 1954, the horse was also brought out for a Whitsun celebration in which it was paraded from Charing to the village green at Wye. A special service was held in the Charing Church, in which the Morris Men danced in the chancel and through the aisle, while the vicar put a bridle on the horse itself. The horse was also brought out for a July 1956 ceremony in which The Swan Inn, a pub at Wickhambreaux, was officially renamed as The Hooden Horse; present were the East Kent Morris Men, the Handbell Ringers, and the Ravensbourne Morris Men. This venture led to the groups establishing a new folk custom, "hop hoodening", which was derived in part from an older hop-picking ceremony found in the Weald area. Their new custom involved the different groups joining together on a tour around the villages of East Kent, beginning at Canterbury Cathedral and going through Ramsgate, Cliftonville, and Herne Bay before ending in a barn dance at Wickhambreaux.

In October 1957, Field was introduced to Jack Laming of Walmer, who as a boy had performed in a hoodening troupe earlier in the century. Laming taught Field more about the historical hoodening tradition, and together they unearthed an old hooden horse that was stored at Walmer's Coldblow Farm; this artefact was later placed on display at Deal Maritime and Local History Museum. In June 1961 Field and his wife established the first Folkestone International Folklore Festival as a biannual celebration of folk customs; it continued for 28 years.

Since the end of the Second World War, the hooden horse's use has been revived in Whitstable, where it is often brought out for the Jack in the Green festival each May, and is owned by a group called the Ancient Order of Hoodeners. Since 1981, the Tonbridge Mummers and Hoodeners have made use of a horse, incorporating it into a play specially written for the purpose by Doel and Nick Miller.
An annual conference of hoodeners was also established; initially meeting at the Marsh Gate Inn near Herne Bay, it subsequently moved to Simple Simon's in Canterbury. A member of the St. Nicholas-at-Wade hoodeners, Ben Jones, established a website devoted to the tradition. At the prompting of local residents, in December 2014 a pub named The Hungry Horse, located on the corner of Haine Road and Nash Road in Broadstairs, was renamed as The Hoodening Horse after the folk custom. Commenting on the Kentish revival of hoodening, Hutton suggested that its success was due largely to the desire of many Kentish folk to culturally distinguish themselves from neighbouring London.



</doc>
<doc id="308036" url="https://en.wikipedia.org/wiki?curid=308036" title="Ashton-under-Lyne">
Ashton-under-Lyne

Ashton-under-Lyne is a market town in Tameside, Greater Manchester, England. The population was 45,198 at the 2011 census. Historically in Lancashire, it is on the north bank of the River Tame, in the foothills of the Pennines, east of Manchester.

Evidence of Stone Age, Bronze Age, and Viking activity has been discovered in Ashton-under-Lyne. The "Ashton" part of the town's name probably dates from the Anglo-Saxon period, and derives from Old English meaning "settlement by ash trees". The origin of the "under-Lyne" suffix is less clear; it possibly derives from the British "lemo" meaning elm or from Ashton's proximity to the Pennines. In the Middle Ages, Ashton-under-Lyne was a parish and township and Ashton Old Hall was held by the de Asshetons, lords of the manor. Granted a Royal Charter in 1414, the manor spanned a rural area consisting of marshland, moorland, and a number of villages and hamlets.

Until the introduction of the cotton trade in 1769, Ashton was considered "bare, wet, and almost worthless". The factory system, and textile manufacture during the Industrial Revolution triggered a process of unplanned urbanisation in the area, and by the mid-19th century Ashton had emerged as an important mill town at a convergence of newly constructed canals and railways. Ashton-under-Lyne's transport network allowed for an economic boom in cotton spinning, weaving, and coal mining, which led to the granting of municipal borough status in 1847.

In the mid-20th century, imports of cheaper foreign goods led to the decline of Ashton's heavy industries but the town has continued to thrive as a centre of commerce and Ashton Market is one of the largest outdoor markets in the United Kingdom. The , two-floored Ashton Arcades shopping centre opened in 1995 and an IKEA store in 2006.

Evidence of prehistoric activity in the area comes from Ashton Moss – a peat bog – and is the only one of Tameside's 22 Mesolithic sites not located in the hilly uplands in the north east of the borough. A single Mesolithic flint tool has been discovered in the bog, along with a collection of nine Neolithic flints. There was further activity in or around the bog in the Bronze Age. In about 1911, an adult male skull was found in the moss; it was thought to belong to the Romano-British period – similar to the Lindow Man bog body – until radiocarbon dating revealed that it dated from 1,320–970 BC.

The eastern terminus of the early medieval linear earthwork Nico Ditch is in Ashton Moss (); it was probably used as an administrative boundary and dates from the 8th or 9th century. Legend claims it was built in a single night in 869 or 870 as a defence against Viking invaders. Further evidence of Dark Age activity in the area comes from the town's name. The "Ashton" part probably derives from the Anglo-Saxon meaning "settlement by ash trees", the origin of the "under-Lyne" element is less clear: it could derive from the British "lemo" meaning elm, or may refer to Ashton being "under the line" of the Pennines. This means that Ashton probably became a settlement some time after the Romans left Britain in the 5th century. An early form of the town's name, which included a "burh" element, indicates that in the 11th century Ashton and Bury were two of the most important towns in Lancashire. The "under Lyne" suffix was not widely used until the mid-19th century when it became useful for distinguishing the town from other places called Ashton.
The "Domesday Survey" of 1086 does not directly mention Ashton, perhaps because only a partial survey of the area had been taken. However, it is thought that St Michael's Church, mentioned in the Domesday entry for the ancient parish of Manchester, was in Ashton (also spelt Asheton, Asshton and Assheton). The town itself was first mentioned in the 12th century when the manor was part of the barony of Manchester. By the late 12th century, a family who adopted the name Assheton held the manor on behalf of the Gresleys, barons of Manchester. Ashton Old Hall was a manor house, the administrative centre of the manor, and the seat of the de Ashton or de Assheton family. With three wings, the hall was "one of the finest great houses in the North West" of the 14th century. It has been recognised as important for being one of the few great houses in south-east Lancashire and possibly one of the few halls influenced by French design in the country. The town was granted a Royal Charter in 1414, which allowed it to hold a fair twice a year, and a market on every Monday, making the settlement a market town.

According to popular tradition, Sir Ralph de Assheton, who was lord of the manor in the mid-14th century and known as the Black Knight, was an unpopular and cruel feudal lord. After his death, his unpopularity led the locals to parade an effigy of him around the town each Easter Monday and collect money. Afterwards the effigy would be hung up, shot, and set on fire, before being torn apart and thrown into the crowd. The first recorded occurrence of the event was in 1795, although the tradition may be older; it continued into the 1830s.

The manor remained in the possession of the Assheton family until 1514 when its male line terminated. The lordship of the manor passed to Sir George Booth, great-great grandson of Sir Thomas Ashton, devolving through the Booth family until the Earls of Stamford inherited it through marriage in 1758. The Booth-Greys then held the manor until the 19th century, whose patronage, despite being absentee lords, was probably the stimulus for Ashton's growth of a large-scale domestic-based textile industry in the 17th century. Pre-industrial Ashton was centred on four roads: Town Street, Crickets Lane, Old Street, and Cowhill Lane. In the late-18th and early-19th centuries, the town was re-planned, with a grid pattern of roads. As a result, very little remains of the previous town. In 1730 a workhouse was established which consisted of a house and two cottages; it later came to be used as a hospital. The Ashton Canal was constructed in the 1790s to transport coal from the area to Manchester, with a branch to the coal pits at Fairbottom.

Domestic fustian and woollen weaving have a long history in the town, dating back to at least the Early Modern period. Accounts dated 1626 highlight that Humphrey Chetham had dealings with clothworkers in Ashton. However, the introduction of the factory system in the 19th century, during the Industrial Revolution, changed Ashton from a market town to a mill town. Having previously been one of the two main towns in the Tame Valley, Ashton-under-Lyne became one of the "most famous mill towns in the North West". On Christmas Day 1826, workers in the town formed the Ashton Unity, a sickness and benefits society that was later renamed the "Loyal Order of Ancient Shepherds". From 1773 to 1905, 75 cotton mills were established in the town. On his tour of northern England in 1849, Scottish publisher Angus Reach said: 

The cotton industry in the area grew rapidly from the start of the 19th century until the Lancashire Cotton Famine of 1861–1865. The growth of the town's textile industry led to the construction of estates specifically for workers. Workers' housing in Park Bridge, on the border between Ashton and Oldham, was created in the 1820s. The iron works were founded in 1786 and were some of the earliest in the north west. The Oxford Mills settlement was founded in 1845 by local industrialist and mill-owner Hugh Mason who saw it as a model industrial community. The community was provided with a recreational ground, a gymnasium, and an institute containing public baths, a library, and a reading room. Mason estimated that establishing the settlement cost him around £10,000 and would require a further £1,000 a year to maintain (about £600,000 and £60,000 respectively as of 2019), and that its annual mortality rate was significantly lower than in the rest of the town.

A poor supply of fresh water and dwellings without adequate drainage led to a cholera outbreak in the town in 1832. The Ashton Poor Law Union was established in 1837 and covered most of what is now Tameside. A new workhouse was built in 1850 which provided housing for 500 people. It later became part of Tameside General Hospital. Construction on the Sheffield, Ashton-under-Lyne and Manchester Railway (SA&MR) began in 1837 to provide passenger transport between Manchester and Sheffield. Although a nine-arch viaduct in Ashton collapsed in April 1845, the line was fully opened on 22 December 1845. The SA&MR was amalgamated with the Sheffield and Lincolnshire Junction Railway, the Great Grimsby & Sheffield Railway, and the Grimsby Docks Company in 1847 to form the Manchester, Sheffield and Lincolnshire Railway (MS&LR). In 1890, the MS&LR bought the Old Hall and demolished it to make way for the construction of new sidings.
In the late 19th century, public buildings such as the market hall, town hall, public library and public baths were built. A donation from Hugh Mason funded the construction of the baths constructed in 1870–1871. The Ashton-under-Lyne Improvement Act was passed in 1886 which gave the borough influence over housing and allowed the imposition of minimum standards such as drainage. Coal mining was not as important to the town as the textile industry, but in 1882 the Ashton Moss Colliery had the deepest mine shaft in the world at . Ashton's textile industry remained constant between 1865 and the 1920s. Although some mills closed or merged, the number of spindles in use increased. With the collapse of the overseas market in the 1920s, the town's cotton industry went into decline, and by the 1930s most of the firms and mills in the area had closed.

At about 4.20 pm on Wednesday 13 June 1917, a fire in an ammunition factory producing TNT caused an explosion that demolished much of the west end of the town. Two gasometers exploded and the explosion destroyed the factory and threw heavy objects long distances. At least 41 people died and about 100 were injured. Sylvain Dreyfus, managing director of the works, helped to fight the fire but died in the subsequent explosion.

12-year-old John Kilbride, the second of the five Moors Murders victims, was lured away from the town's market on 23 November 1963 by Ian Brady and Myra Hindley before being murdered and buried on Saddleworth Moor. His body was found in October 1965, after police arrested Brady and Hindley on suspicion of murdering 17-year-old Edward Evans at their house in Hattersley, and found evidence among their possessions which led them to discover the bodies of John Kilbride and Lesley Ann Downey. His parents Patrick and Sheila Kilbride divorced a number of years later and both gave a number of newspaper and television interviews as part of the campaign to prevent Myra Hindley from being released on parole. Patrick Kilbride died in May 1999, and Sheila Kilbride in July 2002; just four months before Myra Hindley's death after 36 years in prison.

Ashton became a part of the newly formed Metropolitan Borough of Tameside in 1974. In May 2004, a massive fire ravaged the Victorian market hall, and a temporary building called "The Phoenix Market Hall" was built on Old Cross Street on the opposite side of the Old Market hall. Described as the "heart of Ashton", the market was rebuilt and officially opened on 1 December 2008.

Lying within the historic county boundaries of Lancashire since the early 12th century, Ashton anciently constituted a "single parish-township", but was divided into four divisions (sometimes each styled townships): Ashton Town, Audenshaw, Hartshead, and Knott Lanes. Ashton Town was granted a Royal Charter in 1414, granting it the right to hold a market. All four divisions lay within the Hundred of Salford, an ancient division of the county of Lancashire.
In 1827, police commissioners were established for Ashton Town, tasked with bringing about social and economic improvement. In 1847, this area was incorporated under the Municipal Corporations Act 1835, as a municipal borough with the name "Ashton-under-Lyne", giving it borough status. When the administrative county of Lancashire was created by the Local Government Act 1888, the borough fell under the newly created Lancashire County Council. The borough's boundaries changed during the late 19th century through small exchanges of land with the neighbouring districts of Oldham, Mossley, Dukinfield, and Stalybridge. In the early 20th century, the Borough of Ashton-under-Lyne grew; Hurst Urban District was added in 1927, parts of Hartshead and Alt civil parishes in 1935, and parts of Limehurst Rural District in 1954. Since 1956, Ashton has been twinned with Chaumont, France.

Under the Local Government Act 1972, the town's borough status was abolished, and Ashton has, since 1 April 1974, formed part of the Metropolitan Borough of Tameside, within the metropolitan county of Greater Manchester. Ashton-under-Lyne is divided into four wards: Ashton Hurst, Ashton St. Michaels, Ashton St Peters and Ashton Waterloo. As of the 2012 local elections, all twelve seats are held by Labour councillors.

Since the Reform Act 1832 the town has been represented in Parliament as part of the Ashton-under-Lyne parliamentary constituency. During its early years the constituency was represented in the House of Commons by members of the Liberal Party until the late 19th century, when it was broadly held by the Conservative Party. It has been held by the Labour Party since 1935; Angela Rayner has been the constituency's Member of Parliament since 2015.

At (53.4941°, −2.1032°), and north-northwest of London, Ashton-under-Lyne stands on the north bank of the River Tame, about above the river. Described in Samuel Lewis's "A Topographical Dictionary of England" (1848) as situated "on a gentle declivity", Ashton-under-Lyne lies on undulating ground by the Pennines, reaching a maximum elevation of about above sea level. It is east of Manchester city centre, and is bound on all sides by other towns: Audenshaw, Droylsden, Dukinfield, Mossley, Oldham and Stalybridge, with little or no green space between them. Ashton experiences a temperate maritime climate, like much of the British Isles.
Generally the bedrock of the west of the town consists of coal measures, which were exploited by the coal mining industry, while the east is mainly millstone grit. Overlying the bedrock are deposits of glacial sand and gravel, clay, and some alluvial deposits. Ashton Moss, a peat bog, lies to the west of the town and was originally much larger. The River Tame forms part of the southern boundary, dividing the town from Stalybridge and Dukinfield, and the River Medlock runs to the west.

Ashton's built environment is similar to the urban structure of most towns in England, consisting of residential dwellings centred on a market square and high street in the town centre, which is the local centre of commerce. There is a mixture of low-density urban areas, suburbs, semi-rural and rural locations in Ashton-under-Lyne, but overwhelmingly the land use in the town is residential; industrial areas and terraced houses give way to suburbs and rural greenery as the land rises out of the town in the east. The older streets are narrow and irregular, but those built more recently are spacious, lined by "substantial and handsome houses". Areas and suburbs of Ashton-under-Lyne include Cockbrook, Crowhill, Guide Bridge, Hartshead, Hazelhurst, Hurst, Limehurst, Ryecroft, Taunton and Waterloo.

As of the 2001 UK census, Ashton-under-Lyne had a population of 43,236. The 2001 population density was 12,374 per mi² (4,777 per km²), with a 100 to 96.1 female-to-male ratio. Of those over 16 years old, 30.9% were single (never married) and 50.0% married. Ashton-under-Lyne's 18,347 households included 33.2% one-person, 33.0% married couples living together, 8.9% were co-habiting couples, and 12.4% single parents with their children; these figures were similar to those of Tameside, however both Tameside and Ashton have higher rates of single parents than England (9.5%). Of those aged 16–74, 37.0% had no academic qualifications, similar to that of 35.2% in all of Tameside but significantly higher than the 28.9% in all of England, and 11.9% had an educational qualification such as first degree, higher degree, qualified teacher status, qualified medical doctor, qualified dentist, qualified nurse, midwife, health visitor, etc. compared to 20% nationwide.

In 1931, 10.2% of Ashton's population was middle class compared with 14% in England and Wales, and by 1971, this had increased steadily to 17.3% compared with 24% nationally. In the same time frame, there was the decline of the working class population. In 1931, 33.8% were working class compared with 36% in England and Wales; by 1971, this had decreased to 29.2% in Ashton and 26% nationwide. The rest of the population was made up of clerical workers and skilled manual workers.

In 1700, the population of Ashton, the Tame Valley's main urban area, was an estimated 550. The town's 18th-century growth was fuelled by an influx of people from the countryside attracted by the prospect of work in its new industries, mirroring the rest of the region. In the early 19th century, Irish immigrants escaping from the Great Irish Famine were also drawn to the area by the new jobs created, The availability of jobs created by the growth of the textile industry in the town led to Ashton's population increasing by more than 400% between 1801 and 1861, from 6,500 to 34,886. The population dropped by 9% during the 1860s as a consequence of the cotton famine caused by the American Civil War. The table below details the population change since 1851, including the percentage change since the last census.

St Michael and All Angels' Church is a Grade I listed building that dates back to at least 1262, although it was rebuilt in the 15th, 16th and 19th centuries. In 1795 it was the only church in the town, and one of only two in Tameside. There was a great increase in the number of chapels and religious buildings in the area during the 19th century, and by the end of the century there were 44 Anglican churches and 138 chapels belonging to other denominations. The most common denomination amongst the chapels were Catholic, Congregationalist, and Methodist.

The 19th-century evangelist John Wroe attempted to turn Ashton-under-Lyne into a "new Jerusalem". He founded the Christian Israelite Church, and from 1822 to 1831 Ashton-under-Lyne was the religion's headquarters. Wroe intended to build a wall around the town with four gateways, and although the wall was never constructed, the four gatehouses were. Popular opinion in the town turned against Wroe when he was accused of indecent behaviour in 1831, but the charges were dismissed. The Church spread to Australia, where it is still active.

As of the 2001 UK census, 68.5% of Ashton residents reported themselves as being Christian, 6.1% Muslim, 5.0% Hindu, and 0.2% Buddhist. The census recorded that 11.4% had no religion, 0.2% had an alternative religion, and 8.7% did not state their religion. The proportion of Hindus in the town was much higher than the average for the borough and the whole of England 1.4% and 1.1% respectively. The percentage of Muslims in Ashton-under-Lyne was nearly double the national average of 3.1%, and was higher than the average of 2.5% for Tameside. In Ashton-under-Lyne are located 6 mosques (October 2013), including on Hillgate Street in Penny Meadow (Ashton Central Mosque, formerly known as Markazi Jamia Mosque) and on Katherine Street in West End (Masjid Hamza Mosque).

In the medieval period, farming was important in Ashton, particularly arable farming. By the 18th century, textiles had also become more to the town's economy; in the 1700s, 33.2% of those with jobs worked in textiles and 36% in agriculture. With the advent of the Industrial Revolution in the second half of the 18th century, the textile industry in the town boomed. It continued to expand until the cotton famine of 1861–1865, after which the industry was steady until it collapsed after the overseas markets shut down in the 1920s.

Coal has been mined in Ashton since at least the 17th century. In the late 18th and early 19th centuries demand for coal increased, which led to an expansion of the town's coal industry. The produce of the collieries was transported by canal to Manchester. The industry began to decline during the late 19th century, and by 1904 only the Ashton Moss Colliery was still operational, the last colliery to be opened in the area.

Ashton town centre, which is the largest in Tameside, developed in the Victorian period. Many of the original buildings have survived, and as a result, the town centre is protected by Tameside Council as a conservation area. As well as being populated by leading high-street names, Ashton has an outdoor market which was established in the medieval period. It is made up of about 180 stalls, and is open six days a week. The farmers' market, with over 70 stalls, is the largest in the region, as is the weekday flea market. Ashton Market Hall underwent a £15M restoration after it was damaged by fire. The Ashton Renewal Area project has attracted investment in the town centre, encouraging conservation and economic development.

The , two-floored Ashton Arcades shopping centre opened in 1995. Permission has been granted for a £40 million extension yet no work on this project has begun, on the nearby Lord Sheldon Way development of the new Golf Course is in its early stages, Tameside Hospital is under regeneration and there are preliminary stages being taken to welcome the Metrolink to Ashton. These four projects are currently the biggest in Ashton.
In 2006, after failing twice to gain permission, IKEA announced plans to build its first town centre-store in Ashton-under-Lyne. The store is expected to create 500 new jobs as well as attract other businesses to the area. The store opened on 19 October 2006 and covers . At the time of its creation, the store was the tallest in Britain.

Amongst the facilities provided by Ashton Leisure Park are a 14-screen cinema, a bowling alley, and several restaurants. The St Petersfield area of Ashton underwent a £42M redevelopment and provided 2,000 jobs. The aim of the investment was to create a business district in the town and bring life to a neglected area of Ashton. The development provided of office space and of retail and leisure space. Pennine Care NHS Trust relocated its headquarters to the St Petersfield area in 2006. Until then a popular nightspot, in 2002 several night clubs were brought to the brink of closure after a downturn in trade caused by four murders in three months.

According to the 2001 UK census, the industry of employment of residents aged 16–74 was 22.7% manufacturing, 18.6% retail and wholesale, 11.3% health and social work, 9.8% property and business services, 6.7% construction, 6.5% transport and communications, 5.8% education, 5.6% public administration, 4.3% hotels and restaurants, 3.8% finance, 0.4% agriculture, 0.7% energy and water supply, and 3.9% other. Compared with national figures, the town had a relatively low percentage working in agriculture, public administration, and property which was also below the national average, and high rates of employment in construction at more than triple the national rate (6.8%). The census recorded the economic activity of residents aged 16–74, 2.0% students were with jobs, 3.8% students without jobs, 6.4% looking after home or family, 9.5% permanently sick or disabled, and 3.9% economically inactive for other reasons. Ashton's 4.1% unemployment rate was above the national rate of 3.3%.

Curzon Ashton F.C. play at the Tameside Stadium. They are currently in National League North, the highest level in the club's history, following two consecutive promotions, beating town rivals Ashton United F.C. in the playoffs.

Ashton United was the first team in the Manchester Football Association to win an FA Cup tie, when they beat Turton 3–0 in 1883. In 1885, they were the first winners of the Manchester Senior Cup, beating Newton Heath (who later became Manchester United) in the final. Ashton United play at Hurst Cross.

Other sporting venues include the Richmond Park Athletics Stadium, which has an all-weather running track with facilities for field events and is home to the East Cheshire Harriers, Tameside Athletics Club and Ashton Cricket Club, which has won the Central Lancashire Cricket League's first and second division twice each, and the Wood Cup four times.

After the Ashton Canal closed in the 1960s, it was decided to turn the Portland Basin warehouse into a museum. In 1985, the first part of the Heritage Centre and Museum opened on the first floor of the warehouse. The restoration of building was complete in 1999; the museum details Tameside's social, industrial, and political history. The basin next to the warehouse is the point at which the Ashton Canal, the Huddersfield Narrow Canal and the Peak Forest Canal meet. It has been used several times as a filming location for Coronation Street, including a scene where the character Richard Hillman drove into the canal.

The earliest parts of Ashton Town Hall, which was the first purpose-built town hall in what is now Tameside, date to 1840 when it was opened. It has classical features such as the Corinthian columns on the entrance facade. Enlarged in 1878, the hall provides areas for administrative purposes and public functions. Meanwhile, the Old Street drill hall was completed in 1887.
There are five parks in the town, three of which have Green Flag Awards. The first park opened in Ashton-under-Lyne was Stamford Park on the border with Stalybridge. The park opened in 1873, following a 17-year campaign by local cotton workers; the land was bought from a local mill-owner for £15,000 (£ as of 2019) and further land was donated by George Grey, 7th Earl of Stamford. A crowd of between 60,000 and 80,000 turned out to see the Earl of Stamford formally open the new facility on 12 July 1873. It now includes a boating lake, and a memorial to Joseph Rayner Stephens, commissioned by local factory workers to commemorate his work promoting fair wages and improved working conditions. A conservatory was opened in 1907, and Coronation gates installed at both the Ashton-under-Lyne and Stalybridge entrances in 1953.

Hartshead Pike is a stone tower on top of Hartshead Hill overlooking Ashton and Oldham. The current building was constructed in 1863 although there has been a building on the site since at least the mid-18th century, although the original purpose is obscure. The pike may have been the site of a beacon in the late 16th century. It has a visitor centre and from the top of the hill it is possible to see the Jodrell Bank Observatory in Cheshire, the Welsh hills, and the Holme Moss transmitter in West Yorkshire.
The Witchwood public house, in the St Petersfield area of the town, has been a music venue since the 1960s, hosting acts such as Muse, The Coral, and Lost Prophets. In 2004 The Witchwood came under threat when the area was being redeveloped, but was saved from demolition after a campaign by locals and led by Tom Hingley, drawing support from musicians such as Bert Jansch, The Fall, and The Chameleons.

The main Ashton-under-Lyne War Memorial, in Memorial Gardens, consists of a central cenotaph on plinth, surmounted by sculpted wounded soldier and the figure of "Peace who is taking the sword of honour" from his hand. It commemorates the 1,512 people from the town who died in the First World War and the 301 who died in the Second World War. The cenotaph is flanked on both sides by two bronze lions. The plinth is decorated with military equipment representing the services, as well as bronze tablets listing the Roll of Honour from World War I. Commissioned by the Ashton War Memorial Committee, the statue was sculpted between 1919 and 1922 by John Ashton Floyd, and unveiled on 16 September 1922 by General Sir Ian Hamilton.

The tablet on the front of the memorial reads:

Erected in honour of the men of Ashton-under-Lyne and district who fought for King and Empire in The Great War, especially those who sacrificed their lives, and whose names are recorded hereon 1914–1919

Ashton is served by the M60 motorway, which cuts through the west end of Ashton (Junction 23).

In 1732, an Act of Parliament was passed which permitted the construction of a turnpike from Manchester, then in Lancashire, to Salters Brook in Cheshire. The road passed through Ashton-under-Lyne as well as Audenshaw, Mottram-in-Longdendale, and Stalybridge. A Turnpike Trust was responsible for collecting tolls from traffic; the proceeds were used for road maintenance. The Trust for Manchester to Salters Brook was one of over 400 established between 1706 and 1750, a period in which turnpikes became popular. It was the first turnpike to be opened in Tameside, and driven by economic growth, more turnpikes were opened in the area in the late 18th and early 19th centuries. Acts of Parliaments were passed in 1765, 1793, and 1799 permitting the construction turnpikes from Ashton-under-Lyne to Doctor Lane Head in Saddleworth, Standedge in Saddleworth, and Oldham respectively. Towards the end of the 19th century, many Turnpike Trusts were wound up as they were superseded by local government; the last in Tameside to close was the Ashton-under-Lyne to Salters Brook road in 1884.

The town of Ashton-under-Lyne became the focus of three canals which were constructed in Tameside in the 1790s because it was an important centre of coal mining in the Lancashire coalfield. The 1790s has been characterised as a period of mania for canal building in England. The first of the three to be built was the Ashton Canal, which was constructed between 1792 and 1797. Connecting Manchester to Ashton-under-Lyne, with a branch to Oldham, it cost about £170,000 (£ as of 2019). The Peak Forest Canal was constructed from 1794 to 1805, and was originally planned as a branch of the Ashton Canal. It connected the Portland Basin with the Peak District and cost £177,000 (£ as of 2019). The Huddersfield Narrow Canal was built between 1794 and 1811, to enable cross-Pennine trade between Manchester and Kingston upon Hull; the cost of construction was £400,000.

The advent of the railways in the 19th century signalled the decline of the canal system. The new railways were quicker and more economical than the canals, and the waterways declined. The Huddersfield Canal was bought by the Huddersfield and Manchester Railway in 1844. Along with the Ashton and Peak Forest canals, the Huddersfield canal was later bought by the Sheffield, Ashton-under-Lyne and Manchester Railway Company. The canals remained in use throughout the 19th century on a smaller scale than in their heyday, but by the mid-20th century all commercial traffic had ceased. Following an extended period of closure & dereliction, when the Huddersfield canal was in parts filled-in or built over, a complete restoration was undertaken resulting in the full reopening of the canal in 2001. They are now used for leisure craft and are still maintained and in good condition.
Ashton-under-Lyne railway station sees regular services on the Huddersfield Line between Manchester (Victoria) and Huddersfield.

The present station, known historically as "Ashton (Charlestown)" as was opened by the Ashton, Stalybridge and Liverpool Junction Railway (AS&LJR) on 13 April 1846. The AS&LJR was absorbed by the Manchester and Leeds Railway in 1847, which was then renamed the Lancashire and Yorkshire Railway (LYR). The LYR renamed it "Ashton (Charlestown)" in 1874. The LYR amalgamated with the London and North Western Railway at the start of 1922, and these in turn amalgamated with several other companies on 1 January 1923, to form the London, Midland and Scottish Railway during the 1923 Grouping. It then passed to the London Midland Region of British Railways on nationalisation in 1948. The station was renamed "Ashton-under-Lyne" on 6 May 1968.

There were once three stations in the town: Charlestown, Park Parade (closed 1956) and Oldham Road (closed 1959) on the Oldham, Ashton and Guide Bridge Railway. Also, Guide Bridge, a few miles away, was known as "Ashton & Hooley Hill" and then "Ashton" in its earliest years.
The Sheffield, Ashton-under-Lyne and Manchester Railway Company was founded in 1836 with the purpose of building a line linking Manchester and Sheffield. The line was opened in stages and by 1845 was complete. It included a branch to the nearby town of Stalybridge, the former Ashton Park Parade station was included on this branch.

In 1881, a tramway with horse-drawn tramcars was opened between Stalybridge and Audenshaw, through Ashton-under-Lyne. The first tramway of its kind in Tameside, it was later extended to Manchester. The Oldham, Ashton and Hyde Electric Tramway Company, founded in 1899, operated of tram lines with electric tramcars. It was the first line around Manchester to use electricity. A line from Stalybridge to Ashton-under-Lyne was opened in 1903 and operated by the Stalybridge, Hyde, Mossley & Dukinfield Tramways & Electricity Board. The first bus service from Ashton-under-Lyne ran in 1923 and the 1920s saw a period of decline for the tramways as they suffered from the competition from buses. The last electric tram service in the town ran in 1938.

After a 75-year absence, trams returned to Ashton in October 2013, when the Manchester Metrolink tram system opened the East Manchester Line to the town: Ashton-under-Lyne tram stop in the town centre, lies alongside Ashton-under-Lyne bus station and is the terminus for the East Manchester Line, which runs to Manchester Piccadilly station and Manchester city-centre. Away from the town centre towards Manchester there is also Ashton West tram stop and Ashton Moss tram stop.

There are eight nursery schools, fifteen primary schools, and two secondary schools in Ashton-under-Lyne. In 2006, the council began a scheme to develop education in the borough by opening six new secondary schools. Among the changes proposed as part of the £160M scheme was the closure of Hartshead Sports College and Stamford Community High School, to be replaced by a 1,350-pupil academy with 300 members of sixth form. The new school is named New Charter Academy after its sponsor, the New Charter Housing Trust. In 2007, Hartshead Sports College was placed on "special measures" after it failed to achieve its targets for General Certificate of Secondary Education results and was criticised by Ofsted for its teaching standard. Originally expected to open in September 2009, the academy opened in September 2008.

The other secondary school in the town is St Damian's RC Science College, which was founded in 1963, and provides education for 800 pupils aged 11–16. As part of the BSF Project, they created plans for a new school building (built by Carillion) and the pupils moved into this new building in May 2011. Dale Grove School has 60 pupils and offers education for pupils aged 5–16 with special needs. Ashton Sixth Form College is a centre for further education with 1,650 pupils aged 16–18. Tameside College also provides opportunities for further education and operates in Ashton-under-Lyne, Droylsden, and Hyde. Founded in 1954 and expanded in 1957 and 1964, it was originally called Ashton College.

In the early 19th century, Ashton-under-Lyne's growth made it necessary to find a new water supply. Before the introduction of piped water the town's inhabitants drew water from wells and the nearby River Tame. Industrial processes had polluted the river however, and the wells could not sustain a rapidly expanding population. From 1825, a private company was responsible for piping water from reservoirs, but there were still many homes without proper drainage or water supply. Today, waste management is co-ordinated by the local authority via the Greater Manchester Waste Disposal Authority.
The first power station in Tameside was built in 1899, providing power for the area. Ashton's Distribution Network Operator for electricity is United Utilities; there are no power stations in the town. United Utilities also manages the drinking and waste water.

Home Office policing in Ashton-under-Lyne is provided by the Greater Manchester Police. The force's Tameside Division have their divisional headquarters for policing Tameside in the town. Public transport in the area is co-ordinated by Transport for Greater Manchester. Statutory emergency fire and rescue service is provided by the Greater Manchester Fire and Rescue Service, which has one station on Slate Lane. The Tameside General Hospital is a large NHS hospital on the outskirts of the town, administrated by Tameside Hospital NHS Foundation Trust. The North West Ambulance Service provides emergency patient transport.


Notes
Bibliography


</doc>
<doc id="309106" url="https://en.wikipedia.org/wiki?curid=309106" title="Disco Demolition Night">
Disco Demolition Night

Disco Demolition Night was an ill-fated baseball promotion on July 12, 1979 at Comiskey Park in Chicago, Illinois. At the climax of the event, a crate filled with disco records was blown up on the field between games of the twi-night doubleheader between the Chicago White Sox and the Detroit Tigers. Many of those in attendance had come to see the explosion rather than the games and rushed onto the field after the detonation. The playing field was so damaged by the explosion and by the fans that the White Sox were required to forfeit the second game to the Tigers.

In the late 1970s, dance-oriented disco music was popular in the United States, particularly after being featured in hit films such as "Saturday Night Fever" (1977). Disco sparked a backlash from rock music fans. This opposition was prominent enough that the White Sox, seeking to fill seats at Comiskey Park during a lackluster season, engaged Chicago shock jock and anti-disco campaigner Steve Dahl for the promotion at the July 12 doubleheader. Dahl's sponsoring radio station was 97.9 WLUP, so attendees would pay 98 cents and bring a disco record; between games, Dahl would destroy the collected vinyl in an explosion.

White Sox officials had hoped for a crowd of 20,000, about 5,000 more than usual. Instead, at least 50,000—including tens of thousands of Dahl's adherents—packed the stadium, and thousands more continued to sneak in after gates were closed. Many of the records were not collected by staff and were thrown like flying discs from the stands. After Dahl blew up the collected records, thousands of fans stormed the field and remained there until dispersed by riot police.

The second game was initially postponed, but forfeited by the White Sox the next day by order of American League president Lee MacPhail. Disco Demolition Night preceded, and may have helped precipitate, the decline of disco in late 1979; some scholars and disco artists have described the event as expressive of racism and homophobia. Disco Demolition Night remains well known as one of the most extreme promotions in major league history.

Disco, named for its popularity in , evolved in the early 1970s in inner-city New York clubs, where disc jockeys played imported dance music. With roots in African-American and Latin American music and gay culture, even white artists associated with more sedate music had disco-influenced hits, such as Barry Manilow with "Copacabana". By 1977, disco was popular in the United States, especially after the release that year of the hit movie "Saturday Night Fever". The fact that its star John Travolta and musical performers the Bee Gees were white and presented a heterosexual image helped popularize disco. As Al Coury, president of RSO Records (which had released the bestselling soundtrack album for the film) put it, "Saturday Night Fever" "kind of took disco out of the closet."

Some felt disco was too mechanical; "Time" magazine deemed it a "diabolical thump-and-shriek". Others hated the music for the lifestyle associated with it, feeling that in the disco scene, personal appearance and style of dress were too important. The media emphasized its roots in gay culture. According to historian Gillian Frank, "by the time of the Disco Demolition in Comiskey Park, the media commonly emphasized that disco was gay and cultivated a widespread perception that disco was taking over." Performers who cultivated a gay image, such as the Village People (described by "Rolling Stone" as "the face of disco") did nothing to efface these perceptions, and fears that rock music would die out increased after disco albums dominated the 21st Grammy Awards in February 1979.

In 1978, New York's WKTU-FM, a low-rated rock station, switched to disco and became the most popular station in the country; this led other stations to try to emulate its success. In Chicago, Dahl, then 24, was working as a disc jockey for local radio station WDAI when he was fired on Christmas Eve 1978 as part of the station's switch from rock to disco. He was hired by rival album-rock station WLUP, the Loop. Sensing an incipient anti-disco backlash and playing off the publicity surrounding his firing (he frequently mocked WDAI's "Disco DAI" slogan on the air as "Disco DIE"), Dahl created a mock organization, the "Insane Coho Lips", an anti-disco army consisting of his listeners. According to Andy Behrens of ESPN, Dahl and his broadcast partner Garry Meier "organized the Cohos around a simple and surprisingly powerful idea: Disco Sucks".

According to Dahl, in 1979, the Cohos were locked in a war "dedicated to the eradication of the dreaded musical disease known as DISCO". In the weeks leading up to Disco Demolition Night, Dahl promoted a number of anti-disco public events, several of which became unruly. When a in Linwood, Indiana, switched from disco to rock in June, Dahl arrived, as did several thousand Cohos, and the police were called. Later that month, Dahl and several thousand Cohos occupied a teen disco in the Chicago suburbs. At the end of June, Dahl urged his listeners to throw marshmallows at a WDAI promotional van at a shopping mall where a teen disco had been built. The Cohos chased the van and driver and cornered them in a local park, though the situation ended without violence. On July 1, a near-riot occurred in Hanover Park, Illinois, when hundreds of Cohos could not enter a sold-out promotional event, and fights broke out. Some 50 police officers were needed to control the situation. When disco star Van McCoy died suddenly on July 6, Dahl marked the occasion by destroying one of his records, "The Hustle", on the air.

Dahl and Meier regularly mocked disco records on the radio. Dahl also recorded his own song, "Do Ya Think I'm Disco?", a parody of Rod Stewart's disco-oriented hit "Da Ya Think I'm Sexy?". The song characterized as populated by effeminate men and frigid women. The protagonist, named Tony after Travolta's character in "Saturday Night Fever", is unable to attract a woman until he abandons the disco scene, selling his three-piece white suit at a garage sale and melting down his gold chains for a Led Zeppelin belt buckle.

A number of anti-disco incidents took place elsewhere in the first half of 1979, showing that "the Disco Demolition was not an isolated incident or an aberration." In Seattle, hundreds of rock fans attacked a mobile dance floor, while in Portland, Oregon, a disc jockey destroyed a stack of disco records with a chainsaw as thousands cheered. In New York, a rock DJ played Donna Summer's disco hit "Hot Stuff" and received protests from listeners.

Since the 1940s, Chicago White Sox owner Bill Veeck had been noted for using promotions to attract fan interest; he stated "you can draw more people with a losing team plus bread and circuses than with a losing team and a long, still silence". His son, Mike, was the promotions director for the White Sox in 1979. Mike Veeck wrote in a letter to a fan before the season that team management intended to make sure that whether the White Sox won or lost, the fans would have fun.

Early in the 1979 season, on May 2, the Tigers–White Sox game at Comiskey Park was rained out. Officials rescheduled it as part of a twi-night doubleheader on July 12. Already scheduled for the evening of July 12 was a promotion aimed at teenagers, who could purchase tickets at half the regular price.

The White Sox had had a "Disco Night" at Comiskey Park in 1977; Mike Veeck, WLUP Sales Manager Jeff Schwartz, and WLUP Promotions Director Dave Logan discussed the possibility of an anti-disco night promotion after Schwartz mentioned that the White Sox were looking to do a promotion with the station. The matter had also been brought up early in the 1979 season when Schwartz told Mike Veeck of Dahl and his plans to blow up a crate of disco records while live on the air from a shopping mall. During a meeting at WLUP, Dahl was asked if he would be interested in blowing up records at Comiskey Park on July 12. Since the radio frequency of WLUP was 97.9, the promotion for July 12, "Disco Demolition Night" (in addition to the offer for teenagers) was that anyone who brought a disco record to the ballpark would be admitted for 98 cents. Dahl was to blow up the collected records between games of the doubleheader.

In the weeks before the event Dahl invited his listeners to bring records they wanted to see destroyed to Comiskey Park. He feared that the promotion would fail to draw people to the ballpark, and that he would be humiliated. The previous night's attendance had been 15,520, and Comiskey Park had a capacity of 44,492. The White Sox were not having a good year, and were  going into the July 12 doubleheader. The White Sox and WLUP hoped for a crowd of 20,000, and Mike Veeck hired enough security for 35,000.

Owner Bill Veeck was concerned the promotion might become a disaster and checked himself out of the hospital, where he had been undergoing tests. His fears were substantiated when he saw the people walking towards the ballpark that afternoon; many carried signs that described disco in profane terms.

The doubleheader sold out, leaving at least 20,000 people outside the ballpark. Some leapt turnstiles, climbed fences, and entered through open windows. The attendance was officially reported as 47,795, though Bill Veeck estimated that there were anywhere from 50,000 to 55,000 in the park—easily the largest crowd of his second stint as White Sox owner. The Chicago Police Department closed off-ramps from the Dan Ryan Expressway near the stadium. Attendees were supposed to deposit their records into a large box, some tall; once the box was overflowing, many people brought their discs to their seats.

The first game was to begin at 6 pm CDT, with the second game to follow. Lorelei, a model who did public appearances for WLUP and who was popular in Chicago that summer for her sexually provocative poses in the station's advertisements, threw out the first pitch. As the first game began, Mike Veeck got word that thousands of people were trying to get into the park without tickets, and sent his security personnel to the stadium gates to keep them at bay. This left the field unattended, and fans began throwing the uncollected disco LPs and singles from the stands. Tigers designated hitter Rusty Staub remembered that the records would slice through the air, and land sticking out of the ground. He urged teammates to wear batting helmets when playing their positions, "It wasn't just one, it was many. Oh, God almighty, I've never seen anything so dangerous in my life." Attendees also threw firecrackers, empty liquor bottles, and lighters onto the field. The game was stopped several times because of the rain of foreign objects.

Dozens of hand-painted banners with such slogans as "Disco sucks" were hung from the ballpark's seating decks. White Sox broadcaster Harry Caray could see groups of people, who were clearly music rather than baseball fans, wandering through the stadium. Others sat intently in their seats, awaiting the explosion. Mike Veeck recalled an odor of marijuana in the grandstand and said of the attendees, "This is the Woodstock they never had." The miasma permeated the press box, which Caray and his broadcast partner, Jimmy Piersall, commented on over the air. The crowds outside the stadium threw records as well, or gathered them and burned them in bonfires. Detroit won the first game, 4–1.

The first game ended at 8:16 pm; at 8:40 Dahl, dressed in army fatigues and a helmet, emerged onto the playing surface together with Meier and Lorelei. They circled the field in a Jeep, showered (according to Dahl, lovingly) by his troops with firecrackers and beer, then proceeded to center field where the box containing the records awaited, rigged with explosives. Dahl and Meier warmed up the crowd, leading attendees in a chant of "disco sucks". Lorelei recalled that the view from center field was surreal. On the mound, White Sox pitcher Ken Kravec, scheduled to start the second game, began to warm up. Other White Sox, in the dugout and wearing batting helmets, looked out upon the scene. Fans who felt events were getting out of control and who wished to leave the ballpark had difficulty doing so; in an effort to deny the intruders entry, security had padlocked all but one gate.

Dahl told the crowd:

Dahl set off the explosives, destroying the records and tearing a large hole in the outfield grass. With most of the security personnel still watching the gates per Mike Veeck's orders, there was almost no one guarding the playing surface. Soon, the first of 5,000 to 7,000 attendees rushed onto the field, causing Kravec to flee the mound and join his teammates in a barricaded clubhouse. Some climbed the foul poles, while others set records on fire or ripped up the grass. The batting cage was destroyed, and the bases were pulled up and stolen. Among those taking to the field was 21-year-old aspiring actor Michael Clarke Duncan; during the melee, Duncan slid into third base, had a silver belt buckle stolen, and went home with a bat from the dugout. As Bill Veeck stood with a microphone near where home plate had been, begging people to return to the stands, a bonfire raged in center field.

Years later, Lorelei remembered that she had been waving to the crowd when she was grabbed by two of the bodyguards who had accompanied the Jeep, who placed her back in the vehicle. The party was unable to return to home plate because of the rowdy fans, so the Jeep was driven out of the stadium and through the surrounding streets, to the delight of the many Cohos outside the stadium, who recognized the occupants. They were driven to the front of the stadium, ushered back inside, and taken up to the press room where they had spent most of the first game.

Caray unsuccessfully attempted to restore order by the public address system. The scoreboard, flashing "PLEASE RETURN TO YOUR SEATS", was ignored, as was the playing of "Take Me Out to the Ball Game". Some attendees danced in circles around the burning vinyl shards. Dahl offered his help to get the rowdy fans to leave, but it was declined.

At 9:08 pm, Chicago police in full riot gear arrived, to the applause of the baseball fans remaining in the stands. Those on the field hastily dispersed upon seeing the police. Thirty-nine people were arrested for disorderly conduct; estimates of injuries to those at the event range from none to over thirty.

Bill Veeck wanted the teams to play the second game once order was restored. However, the field was so badly torn up that umpiring crew chief Dave Phillips felt that it was still not playable, even after White Sox groundskeepers spent an hour clearing away debris. Tigers manager Sparky Anderson refused to allow his players to take the field in any event due to safety concerns. Phillips called American League president Lee MacPhail, who postponed the second game to Sunday after hearing a report on conditions. Anderson, however, demanded that the game be forfeited to the Tigers. He argued that under baseball's rules, a game can only be postponed due to an act of God, and that, as the home team, the White Sox were responsible for field conditions. The next day, MacPhail forfeited the second game to the Tigers 9–0. In a ruling that largely upheld Anderson's arguments, MacPhail stated that the White Sox had failed to provide acceptable playing conditions.

The day after the event, Dahl began his regular morning broadcast by reading the indignant headlines in the local papers. He mocked the coverage, saying: "I think for the most part everything was wonderful. Some maniac Cohos got wild, went down on the field. Which you shouldn't have done. Bad little Cohos." Tigers manager Anderson said of the events: "Beer and baseball go together, they have for years. But I think those kids were doing things other than beer." Columnist David Israel of the "Chicago Tribune" said on July 12 that he was not surprised by the events, writing: "It would have happened any place 50,000 teenagers got together on a sultry summer night with beer and reefer." White Sox pitcher Rich Wortham, a Texan, said: "This wouldn't have happened if they had country and western night."

Although Bill Veeck took much of the public criticism for the fiasco, his son Mike suffered repercussions as the front-office promoter. Mike Veeck remained with the White Sox until late 1980, when he resigned; his father sold the team to Jerry Reinsdorf soon afterward. He was unable to find another job in baseball for some time and claimed that he had been blackballed. For several years, he worked for a jai-alai fronton in Florida, battling alcoholism. As Mike Veeck said: "The second that first guy shimmied down the outfield wall, I knew my life was over!" Mike Veeck has since become an owner of minor league baseball teams. In July 2014 the Charleston RiverDogs, of whom Veeck is president, held a promotion involving the destruction of Justin Bieber and Miley Cyrus merchandise. Dahl is still a radio personality in Chicago and also releases podcasts.

The popularity of disco declined significantly in late 1979 and 1980. Many disco artists continued, but record companies began labeling their recordings as dance music. Dahl stated in a 2004 interview that by 1979 disco was "probably on its way out. But I think [Disco Demolition Night] hastened its demise". According to Frank, "the Disco Demolition triggered a nationwide expression of anger against disco that caused disco to recede quickly from the American cultural landscape".

"Rolling Stone" critic Dave Marsh described Disco Demolition Night as "your most paranoid fantasy about where the ethnic cleansing of the rock radio could ultimately lead". Marsh was one who, at the time, deemed the event an expression of bigotry, writing in a year-end 1979 feature that "white males, eighteen to thirty-four are the most likely to see disco as the product of homosexuals, blacks, and Latins, and therefore they're the most likely to respond to appeals to wipe out such threats to their security. It goes almost without saying that such appeals are racist and sexist, but broadcasting has never been an especially civil-libertarian medium."

Nile Rodgers, producer and guitarist for the disco-era band Chic, likened the event to Nazi book burning. Gloria Gaynor, who had a huge disco hit with "I Will Survive", stated, "I've always believed it was an economic decision—an idea created by someone whose economic bottom line was being adversely affected by the popularity of disco music. So they got a mob mentality going."

University of East London professor Tim Lawrence states, "Following the unexpected commercial success of "Saturday Night Fever", major record companies had started to invest heavily in a sound that their white straight executive class did not care for, and when the overproduction of disco coincided with a deep recession, the homophobic (and also in many respects sexist and racist) 'disco sucks' campaign culminated with a record burning rally that was staged at the home of the Chicago White Sox in July 1979."

Dahl denies that prejudice was his motivation for the event. "The worst thing is people calling Disco Demolition homophobic or racist. It just wasn't ... We weren't thinking like that." In a 2014 op-ed for "Crain's Chicago Business", Dahl defended the event as "a romp, not of major cultural significance". He wrote that it had been "reframed" as prejudiced by a 1996 VH1 documentary about the 1970s, in a move he described as "a cheap shot made without exploration".

In response to Dahl's op-ed, NBC Chicago political journalist Mark W. Anderson, who attended Disco Demolition aged 15, described the fear that white neighborhoods would be taken over by blacks and the anxiety around shifting pop culture trends. He wrote: 

The unplayed second game remains the last American League game to be forfeited. The last National League game to be forfeited was on August 10, 1995, when a baseball giveaway promotion at Dodger Stadium went awry, forcing the Los Angeles Dodgers to concede the game to the St. Louis Cardinals. According to baseball analyst Jeremiah Graves, "To this day Disco Demolition Night stands in infamy as one of the most ill-advised promotions of all-time, but arguably one of the most successful as 30 years later we're all still talking about it."

Game 1:

Game 2 forfeited to Detroit, 9–0.





</doc>
<doc id="309803" url="https://en.wikipedia.org/wiki?curid=309803" title="Remain in Light">
Remain in Light

Remain in Light is the fourth studio album by American rock band Talking Heads, released on October 8, 1980 by Sire Records. It was recorded at Compass Point Studios in the Bahamas and Sigma Sound Studios in Philadelphia between July and August 1980 and produced by longtime collaborator Brian Eno. Following the release of their previous album "Fear of Music" in 1979, the quartet and Eno sought to dispel notions of the band as a mere vehicle for frontman and lyricist David Byrne. Drawing on the influence of Nigerian musician Fela Kuti, the band experimented with African polyrhythms, funk, and electronics, recording instrumental tracks as a series of looping grooves. The sessions incorporated a variety of side musicians, including guitarist Adrian Belew, singer Nona Hendryx, and trumpet player Jon Hassell.

Byrne struggled with writer's block, but adopted a scattered, stream-of-consciousness lyrical style inspired by early rap and academic literature on Africa. The artwork for the album was conceived by bassist Tina Weymouth and drummer Chris Frantz, and was crafted with the help of the Massachusetts Institute of Technology's computers and design company M&Co. The band expanded to nine members for a promotional tour, and following its completion, they went on hiatus for several years, leaving the individual members to pursue a variety of side projects. The album was the last of the band's collaborations with Eno, although Eno and Byrne's "My Life in the Bush of Ghosts" was released the following year.

"Remain in Light" was widely acclaimed by critics, who praised its sonic experimentation, rhythmic innovations, and cohesive merging of disparate genres. The album peaked at number nineteen on the US "Billboard" 200 and number 21 on the UK Albums Chart, and spawned the singles "Once in a Lifetime" and "Houses in Motion". It has been featured in several publications' lists of the best albums of the 1980s and of all time, and is often considered Talking Heads' magnum opus. In 2017, the Library of Congress deemed the album "culturally, historically, or artistically significant", and selected it for preservation in the National Recording Registry.

In January 1980, the members of Talking Heads returned to New York City after the tours in support of their 1979 critically acclaimed third album, "Fear of Music", and took time off to pursue personal interests. Singer David Byrne worked with Brian Eno, the record's producer, on an experimental album, "My Life in the Bush of Ghosts". Keyboardist Jerry Harrison produced an album for soul singer Nona Hendryx at the Sigma Sound Studios branch in New York City; Hendryx and the studio were used during the "Remain in Light" recording on Harrison's advice.

Drummer Chris Frantz and bassist Tina Weymouth, a married couple, discussed leaving Talking Heads after Weymouth suggested that Byrne was too controlling. Frantz did not want to leave, and the two took a long vacation in the Caribbean to ponder the state of the band and their marriage. They became involved in Haitian Vodou religious ceremonies, practised native percussion instruments, and socialised with the reggae rhythm section of Sly and Robbie.

Frantz and Weymouth ended their holiday by purchasing an apartment above Compass Point Studios in Nassau, the Bahamas, where Talking Heads had recorded their second album, "More Songs About Buildings and Food". Byrne joined the duo and Harrison there in early 1980. The band members realised that it had been solely up to Byrne to craft songs even though they were performed as a quartet. They had tired of the notion of a singer leading a backup band; the ideal they aimed for, according to Byrne, was "sacrificing our egos for mutual cooperation". Byrne additionally wanted to escape "the psychological paranoia and personal torment" he had been writing and feeling in New York. Instead of the band writing music to Byrne's lyrics, Talking Heads performed instrumental jams, using the "Fear of Music" song "I Zimbra" as a starting point.

Eno arrived in the Bahamas three weeks after Byrne. He was reluctant to work with the band again after collaborating on the previous two albums. He changed his mind after being excited by the instrumental demo tapes. The band and Eno experimented with the communal African way of making music, in which individual parts mesh as polyrhythms. "Afrodisiac", the 1973 Afrobeat record by Nigerian musician Fela Kuti, became the template for the album. Weymouth said that the beginnings of hip-hop music made Talking Heads realise that the musical landscape was changing. Before the studio sessions began, longtime friend David Gans instructed the band that "the things one doesn't intend are the seeds for a more interesting future". He encouraged them to experiment, improvise and make use of "mistakes".

Recording sessions started at Compass Point Studios in July 1980. The album's creation required the use of additional musicians, particularly percussionists. Talking Heads used the working title "Melody Attack" throughout the studio process after watching a Japanese game show of the same name. Harrison said the ambition was to blend rock and African genres, rather than simply imitate African music. Eno's production techniques and personal approach were key to the record's conception. The process was geared to promote the expression of instinct and spontaneity without overtly focusing on the sound of the final product. Eno compared the creative process to "looking out to the world and saying, 'What a fantastic place we live in. Let's celebrate it.'"

Sections and instrumentals were recorded one at a time in a discontinuous process. Loops played a key part at a time when computers could not yet adequately perform such functions. Talking Heads developed "Remain in Light" by recording jams, isolating the best parts, and learning to play them repetitively. The basic tracks focused wholly on rhythms and were all performed in a minimalist method using only one chord. Each section was recorded as a long loop to enable the creation of compositions through the positioning or merging of loops in different ways. Byrne likened the process to modern sampling: "We were human samplers."

After a few sessions in the Bahamas, engineer Rhett Davies left following an argument with the producer over the fast speed of recording. Steven Stanley, who since the age of 17 had engineered for musicians such as Bob Marley, stepped in to cover the workload. He is credited by Frantz with helping create "Once in a Lifetime", which was released as a single. A Lexicon 224 digital reverb effects unit, obtained by engineer and mixer Dave Jerden, was used on the album. The machine was one of the first of its kind and able to simulate environments such as echo chambers and rooms through interchangeable programs. Like Davies, Jerden was unhappy with the fast pace at which Eno wanted to record sonically complicated compositions, but did not complain.

The tracks made Byrne rethink his vocal style and he tried singing to the instrumental songs, but sounded "stilted". Few vocal sections were recorded in the Bahamas. The writing process for the lyrics occurred when the band returned to the US and was split between New York City and California. Harrison booked Talking Heads into Sigma Sound, which focused primarily on R&B music, after convincing the owners that the band's work could bring them a new type of clientele. In New York City, Byrne struggled with writer's block. Harrison and Eno spent their time tweaking the compositions recorded in the Bahamas, while Frantz and Weymouth often did not show up at the studio. Doubts began to surface about whether the album would be completed. The recording sessions only built up pace after the recruitment of guitarist Adrian Belew at the request of Byrne, Harrison and Eno. He was advised to add guitar solos to the Compass Point tracks, making use of a Roland guitar synthesiser.

Byrne recorded all the tracks, as they were after Belew had performed on them, to a cassette and looked to Africa to break his writer's block. He realised that, when African musicians forget words, they often improvise and make new ones up. He used a portable tape recorder and tried to create onomatopoeic rhymes in the style of Eno, who believed that lyrics were never the center of a song's meaning. Byrne continuously listened to his recorded scatting until convinced that he was no longer "hearing nonsense". After he was satisfied, Harrison invited Nona Hendryx to Sigma Sound to record backing vocals for the album. She was advised extensively on her vocal delivery by Byrne, Frantz, and Weymouth, and often sang in a trio with Byrne and Eno. The voice sessions were followed by the overdubbing process. Brass player Jon Hassell, who had been working on parts of "My Life in the Bush of Ghosts", was hired to perform trumpet and horn sections. In August 1980, half of the album was mixed by Eno and engineer John Potoker in New York City with the assistance of Harrison, while the other half was mixed by Byrne and Jerden at Eldorado Studios in Los Angeles.

"Remain in Light" features new wave, post-punk, worldbeat, dance-rock, and different types of funk, specifically afrofunk and avant-funk. Critic Stephen Thomas Erlewine described the album as a "dense amalgam of African percussion, funk bass and keyboards, pop songs, and electronics." It contains eight songs that possess a "striking free-associative feel" according to psychoanalyst Michael A. Brog, in that there is no long-lasting coherent thought process that can be followed in the stream-of-consciousness lyrics. David Gans instructed Byrne to be freer with his lyrical content by advising him that "rational thinking has its limits". The frontman included a bibliography with the album press kit along with a statement that explained how the album was inspired by African mythologies and rhythms. The release stressed that the major inspiration to the lyrics was Professor John Miller Chernoff's "African Rhythm and African Sensibility", which examined the musical enhancement of life in the continent's rural communities. The academic travelled to Ghana in 1970 to study native percussion and wrote about how Africans have complicated conversations through drum patterns. One of the songs, "The Great Curve", exemplifies the African theme by including the line "The world moves on a woman's hips", which Byrne used after reading Professor Robert Farris Thompson's book "African Art in Motion". He additionally studied straight speech, from John Dean's Watergate testimony to the stories of African American former slaves.

Like all the other tracks, album opener "Born Under Punches (The Heat Goes On)" borrows from "preaching, shouting and ranting". The expression "And the Heat Goes On", used in the title and repeated in the chorus, is based on a "New York Post" headline Eno read in the summer of 1980 whilst Byrne rewrote the song title "Don't Worry About the Government" from Talking Heads' debut album, "", into the lyric "Look at the hands of a government man". The "rhythmical rant" in "Crosseyed and Painless"—"Facts are simple and facts are straight. Facts are lazy and facts are late."—is influenced by old school rap, specifically Kurtis Blow's "The Breaks" given to Byrne by Frantz. "Once in a Lifetime" borrows heavily from preachers' diatribes. Some critics have suggested that the song is "a kind of prescient jab at the excesses of the 1980s". Byrne disagreed with the categorisation and commented that its lyrics are meant to be taken literally; he stated, "We're largely unconscious. You know, we operate half awake or on autopilot and end up, whatever, with a house and family and job and everything else, and we haven't really stopped to ask ourselves, 'How did I get here?'."

Byrne has described the album's final mix as a "spiritual" piece of work, "joyous and ecstatic and yet it's serious"; he has pointed out that, in the end, there was "less Africanism in "Remain in Light" that we implied ... but the African ideas were far more important to get across than specific rhythms". According to Eno, the record uniquely blends funk and punk rock or new wave music. None of the compositions include chord changes and instead rely on the use of different harmonics and notes. "Spidery riffs" and layered tracks of bass and percussion are used extensively throughout the album. The first side contains the more rhythmic songs recorded—"Born Under Punches (The Heat Goes On)", "Crosseyed and Painless", and "The Great Curve"—which include long instrumental interludes. The last-named track contains extended synthesiser-treated guitar solos from Adrian Belew.

The second side of "Remain in Light" features more introspective songs. "Once in a Lifetime" pays homage to early rap techniques and the music of art rock band The Velvet Underground. The track was originally called "Weird Guitar Riff Song" because of its composition. It was conceived as a single riff before the band added a second, boosted riff over the top of the first. Eno alternated eight bars of each riff with corresponding bars of its counterpart. "Houses in Motion" incorporates lengthy brass performances from Jon Hassell, while "Listening Wind" features Arabic music elements. The final track on the album, "The Overload," was Talking Heads' attempt to emulate the sound of British post-punk band Joy Division. The song was made despite no band member having heard the music of Joy Division; rather, it was based on an idea of what the British quartet "might" sound like based on descriptions in the music press. The track features "tribal-cum-industrial" beats created primarily by Harrison and Byrne.

The cover art was conceived by Weymouth and Frantz with the help of Massachusetts Institute of Technology researcher Walter Bender and his MIT Media Lab team. Using "Melody Attack" as inspiration, the couple created a collage of red warplanes flying in formation over the Himalayas. The planes are an artistic depiction of Grumman Avenger planes in honour of Weymouth's father, Ralph Weymouth, who was a US Navy Admiral. The idea for the back cover included simple portraits of the band members. Weymouth attended MIT regularly during the summer of 1980 and worked with Bender's colleague, Scott Fisher, on the computer renditions of the ideas. The process was tortuous because computer power was limited in the early 1980s and the mainframe alone took up several rooms. Weymouth and Fisher shared a passion for masks and used the concept to experiment with the portraits. The faces (except for eyes, noses and mouths) were blotted out with blocks of red colour. Weymouth considered superimposing Eno's face on top of all four portraits to insinuate his egotism—the producer wanted to be on the cover art together with Talking Heads—but decided against it in the end.

The rest of the artwork and the liner notes were crafted by the graphic designer Tibor Kalman and his company M&Co. Kalman was a fervent critic of formalism and professional design in art and advertisements. He offered his services for free to create publicity, and discussed using unconventional materials such as sandpaper and velour for the LP sleeve. Weymouth, who was sceptical of hiring a designing firm, vetoed Kalman's ideas and held firm on the MIT computerised images. The designing process made the band members realise that the title "Melody Attack" was "too flippant" for the music recorded, and they adopted "Remain in Light" instead. Byrne has noted, "Besides not being all that melodic, the music had something to say that at the time seemed new, transcendent, and maybe even revolutionary, at least for funk rock songs." The image of the warplanes was relegated to the back of the sleeve and the doctored portraits became the front cover. Kalman later suggested that the planes were not removed altogether because they seemed appropriate during the Iranian hostage crisis of 1979–81.

Weymouth advised Kalman that she wanted simple typography in a bold sans serif font. M&Co. followed the instructions and came up with the idea of inverting the "A"s in "TALKING HEADS". Weymouth and Frantz decided to use the joint credit acronym C/T for the artwork, while Bender and Fisher used initials and code names because the project was not an official MIT venture. The design credits read "HCL, JPT, DDD, WALTER GP, PAUL, C/T". The final mass-produced version of "Remain in Light" boasted one of the first computer-designed record jackets. Psychoanalyst Michael A. Brog has called its front cover a "disarming image, which suggests both splitting and obliteration of identity" and which introduces the listener to the album's recurring theme of "identity disturbance"; he states, "The image is in bleak contrast to the title with the obscured images of the band members unable to 'remain in light'."

Talking Heads and Eno originally agreed to credit all songs in alphabetical order to "David Byrne, Brian Eno, Chris Frantz, Jerry Harrison and Tina Weymouth" after failing to devise an accurate mathematical formula for the split, but the album was released with the label credit: "all songs written by David Byrne & Brian Eno (except "Houses In Motion" and 'The Overload", written by David Byrne, Brian Eno & Jerry Harrison)". Frantz, Harrison, and Weymouth disputed Byrne and Eno's attempt to claim sole credits, especially for a process they had partly funded. According to Weymouth, Byrne told Kalman to doctor the credits on Eno's advice. Later editions rectified the error. In 2009, Frantz recalled, "we felt very burnt by the credits dispute".

Brian Eno advised Talking Heads that the music on "Remain in Light" was too dense for a quartet to perform. The band expanded to nine musicians for the tours in support of the album. The augmenting members recruited by Harrison were Belew, Funkadelic keyboardist Bernie Worrell, bassist Busta "Cherry" Jones, Ashford & Simpson percussionist Steven Scales, and backing vocalist Dolette MacDonald. The larger group performed soundchecks in Frantz and Weymouth's loft by following the rhythms established by Worrell, who had studied at the New England Conservatory and Juilliard School.

The expanded band's first appearance was on August 23, 1980 at the Heatwave festival in Canada in front of 70,000 people; Robert Hilburn of the "Los Angeles Times" called the band's new music a "rock-funk sound with dramatic, near show-stopping force". On August 27, the expanded Talking Heads performed a showcase of tracks to an audience of 125,000 at the Wollman Rink in New York City's Central Park. The Canada and New York gigs were the only ones initially planned, but Sire Records decided to support the nine-member band on an extended tour. Following the promotional tour, the band went on hiatus for several years, leaving the individual members to pursue a variety of side projects.

"Remain in Light" was released worldwide on October 8, 1980. "Remain in Light" received its world premiere airing in its entirety on October 10, 1980 on WDFM. According to writer David Sheppard, "it was received as a great cultural event as much as a vivid art-pop record." It was certified Gold by the Canadian Recording Industry Association in February 1981 after shipping 50,000 copies, and by Recording Industry Association of America in September 1985 after shipping 500,000 copies. Over one million copies have been sold worldwide.

The album attained widespread acclaim from media outlets. Ken Tucker of "Rolling Stone" felt it was a brave and absorbing attempt to locate a common ground in the early 1980s divergent and often hostile musical genres; he concluded, ""Remain in Light" yields scary, funny music to which you can dance and think, think and dance, dance and think, "ad infinitum"." Robert Christgau, writing in "The Village Voice", described the record as one "in which David Byrne conquers his fear of music in a visionary Afrofunk synthesis—clear-eyed, detached, almost mystically optimistic". Michael Kulp of the "Daily Collegian" commented that the album deserves the tag "classic" like each of the band's three previous full-length releases, while John Rockwell, writing in "The New York Times", suggested that it confirmed Talking Heads' position as "America's most venturesome rock band". Sandy Robertson of "Sounds" praised the record's innovation, while "Billboard" wrote, "Just about every LP Talking Heads has released in the last four years has wound up on virtually every critics' best of list. "Remain in Light" should be no exception."

AllMusic's William Ruhlmann wrote that Talking Heads' musical transition, first witnessed in "Fear of Music", came to full fruition in "Remain in Light"; he stated, "Talking Heads were connecting with an audience ready to follow their musical evolution, and the album was so inventive and influential." In the 1995 "Spin Alternative Record Guide", Eric Weisbard praised Eno's production effort which helped rein in any excessive appropriations of African music by Talking Heads. In 2004, "Slant Magazine"s Barry Walsh labelled its results as "simply magical" after the band turned rock music into a more global entity in terms of its musical and lyrical scope. In a 2008 review, Sean Fennessey of "Vibe" concluded, "Talking Heads took African polyrhythms to NYC and made a return trip with elegant, alien post-punk in tow."

"Remain in Light" was named the best album of 1980 by "Sounds", ahead of The Skids' "The Absolute Game", and by "Melody Maker", while "The New York Times" included it in its unnumbered shortlist of the 10 best records issued that year. It figured highly in other end-of-year best album lists, notably at number two, behind The Clash's "London Calling", by Robert Christgau, and at number six by "NME". It featured at number three—behind "London Calling" and Bruce Springsteen's "The River"—in "The Village Voice"s 1980 Pazz & Jop critics' poll, which aggregates the votes of hundreds of prominent reviewers.
In 1989, "Rolling Stone" named "Remain in Light" as the fourth best album of the decade. In 1993, it was included at number 11 in "NME"s list of The 50 Greatest Albums Of The '80s, and at number 68 in the publication's Greatest Albums Of All Time list. In 1997, "The Guardian" collated worldwide data from renowned critics, artists, and radio DJs, which placed the record at number 43 in the list of the 100 Best Albums Ever. In 1999, it was included by "Vibe" as one of its 100 Essential Albums Of The 20th Century. In 2002, Pitchfork Media featured "Remain in Light" at number two behind Sonic Youth's "Daydream Nation" in its Top 100 Albums Of The 1980s list. In 2003, VH1 named the record at number 88 during its 100 Greatest Albums countdown, while "Slant" magazine included it in its unnumbered shortlist of 50 Essential Pop Albums. "Rolling Stone" placed it at number 129 in its December 2015 issue of "The 500 Greatest Albums of All Time", higher than three other Talking Heads releases. In 2006, "Q" ranked "Remain in Light" at number 27 in its list of the 40 Best Albums of the 80s. In 2012, "Slant" listed the album at number six on its list of the "Best Albums of the 1980s".

In 2018, Beninese singer Angelique Kidjo released a song-for-song cover of "Remain in Light" (produced by Jeff Bhasker and released on his Kravenworks label), describing herself as a longtime fan of the song "Once in a Lifetime" and wanting to pay tribute to the album by emphasizing its inspiration from African music.

Notes

Those involved in the making of "Remain in Light" were:

Talking Heads

Additional musicians

Design

Production





</doc>
<doc id="310171" url="https://en.wikipedia.org/wiki?curid=310171" title="Harmon Killebrew">
Harmon Killebrew

Harmon Clayton Killebrew, Jr.(; June 29, 1936 – May 17, 2011), nicknamed "The Killer" and "Hammerin' Harmon", was an American professional baseball first baseman, third baseman, and left fielder. During his 22-year career in Major League Baseball (MLB), primarily with the Minnesota Twins, Killebrew was a prolific power hitter who, at the time of his retirement, had the fourth most home runs in major league history. He was second only to Babe Ruth in American League (AL) home runs, and was the AL career leader in home runs by a right-handed batter . Killebrew was inducted into the National Baseball Hall of Fame in 1984.

Killebrew was a stocky tall, hitter with a compact swing that generated tremendous power. He became one of the AL's most feared power hitters of the 1960s, hitting 40 home runs in a season eight times. In 1965, he played in the World Series with the Twins, who lost to the Los Angeles Dodgers. His finest season was 1969, when he hit 49 home runs, recorded 140 runs batted in (RBIs), and won the AL Most Valuable Player Award. Killebrew led the league six times in home runs and three times in RBIs, and was named to thirteen All-Star teams.

With quick hands and exceptional upper body strength, Killebrew was known not just for the frequency of his home runs but also for their distance. He hit the longest measured home runs at Minnesota's Metropolitan Stadium, , and Baltimore's Memorial Stadium, , and was the first of just four batters to hit a baseball over the left field roof at Detroit's Tiger Stadium. Despite his nicknames and his powerful style of play, Killebrew was considered by his colleagues to be a quiet, kind man. Asked once what hobbies he had, Killebrew replied, "Just washing the dishes, I guess."

After retiring from baseball, Killebrew became a television broadcaster for several baseball teams from 1976 to 1988, and also served as a hitting instructor for the Oakland Athletics. 

Born and raised in Payette, Idaho, Killebrew was youngest of four children of Harmon Clayton, Sr. and Katherine Pearl (May) Killebrew. His father, a painter and sheriff, was a member of an undefeated Millikin College football team who was later named an All-American under eventual Pro Football Hall of Fame coach Greasy Neale. According to family legend, Harmon Killebrew's grandfather was the strongest man in the Union Army, winning every available heavyweight wrestling championship. Clayton encouraged Harmon and his brothers to stay active in various sports before his sudden death in 1953 at age 59.

As a child, Killebrew played baseball at Walter Johnson Memorial Field, named after the Hall of Fame pitcher who spent part of his childhood in Idaho. He worked as a farmworker in his youth, where he lifted ten-gallon milk cans, each weighing about . Killebrew earned twelve letters in various sports and was named an All-American quarterback at Payette High School; his uniform number was later retired by the school. He was offered an athletic scholarship by the University of Oregon, but declined the offer.

In the early 1950s, Senator Herman Welker of Idaho told Washington Senators owner Clark Griffith about Killebrew, who was hitting for an .847 batting average for a semi-professional baseball team at the time. Griffith told his farm director Ossie Bluege about the tip and Bluege flew to Idaho to watch Killebrew play. The Boston Red Sox also expressed interest but Bluege succeeded in signing him to a $50,000 ($ today) contract on June 19, 1954.

Killebrew signed his contract under Major League Baseball (MLB)'s Bonus Rule, which required that he spend two full seasons on the major league roster. Making his major league debut four days after signing and six days from his 18th birthday (becoming the youngest active player in the majors at the time), Killebrew was called on to run for Clyde Vollmer, who had been hit by a pitch, with the bases loaded, by Chicago White Sox starter Jack Harshman while pinch hitting for Senators reliever Chuck Stobbs. On August 23, 1954, Killebrew made his first start in the second game of a doubleheader against the Philadelphia Athletics, hitting two singles and a double as the Senators won the game, 10–3. A year and one day after making his major league debut, Killebrew hit his first major league home run on June 24, 1955 in the 5th inning off Detroit Tigers starter Billy Hoeft, five days shy of his 19th birthday. In his first two seasons, Killebrew struck out 34 times in only 93 at bats, contributing to a .215 batting average with four home runs. Killebrew also had defensive difficulties at third base, where he played behind veteran Eddie Yost.
When Killebrew's bonus period expired in 1956, he was sent to the Senators' minor league affiliate in Charlotte of the South Atlantic League. He returned to the majors in early May. On May 29, after being forced into action when regular second baseman Pete Runnels was injured early in the game, Killebrew hit two home runs in the game, including only the second ball ever hit over a wire barrier in Memorial Stadium's center field. Killebrew had a .115 average through June 16, and as a result was sent back to Charlotte; he finished the season there with a .325 batting average and 15 home runs in 70 games. Killebrew spent most of the 1957 season with the Southern Association's Chattanooga Lookouts, where he hit a league-high 29 home runs with 101 RBIs and was named to the All-Star Game. While in Chattanooga, Killebrew became the only player to hit a home run over the center field wall at Engel Stadium, from home plate. In 1958, he was briefly promoted to Indianapolis of the American Association but struggled and was sent back to Chattanooga for most of the season. Killebrew finished the season with 38 games played in Indianapolis and 86 in Chattanooga, where he hit .308 with 17 home runs. He also played a combined 22 games for the Senators in 1957 and 1958.

Calvin Griffith took over the Senators after his uncle Clark Griffith died in 1955, and decided Killebrew was ready to become the Senators' regular third baseman. Griffith traded the 32-year-old Eddie Yost to the Detroit Tigers on December 6, 1958, and Killebrew became the starting third baseman. From May 1 to May 17, he had five multi-home run games and his first five-RBI game on May 12. With 28 home runs by mid-season, he started the first 1959 All-Star Game and was a reserve in the second. Killebrew attracted so much attention in Washington that he was visited by President of the United States Dwight D. Eisenhower, who frequently attended games, and Griffith turned down a $500,000 offer for Killebrew from the Cincinnati Reds. Killebrew finished the season with 42 home runs to tie for the American League lead; it also tied the Senator's single-season record set by his teammate Roy Sievers two years earlier. Although 1959 proved his breakout season, he was ineligible for the Rookie of the Year Award because of his previous sparse experience. Instead, the award went to teammate Bob Allison.

Killebrew was bothered by injury early in the 1960 season. In March, he had surgery for nasal irritation, and a recurring hamstring injury caused him to miss most of May. On his return, he remained in the lineup for the rest of the season, finishing the year with 31 home runs in 124 games. Killebrew's arrival and home runs did little to improve the Senators' record, as they finished in the second division of the American League every year he played for Washington, including four years in last place. Following the 1960 season, the Senators moved to Minnesota and became the Minnesota Twins.

For the franchise's first year in Minnesota, Killebrew was named team captain by manager Cookie Lavagetto. He responded by hitting 46 home runs, breaking the franchise record he had tied two years earlier. Among his other accomplishments over the course of the season, Killebrew accumulated a team-leading 122 RBIs, achieved a career-best batting average of .288 and had a slugging percentage of over .600 for the only time in his career. In addition, he had a career-high seven triples, tying for the team lead, and led his team in runs, total bases and walks. On June 12, 1961, Killebrew had the only five-hit game of his career in a losing effort by the Twins. Killebrew was named to both 1961 All-Star games. He did not play in the second game, but in the first game, he hit a pinch hit home run in the sixth inning. After the season ended, Killebrew took part in a home run hitting contest with Jim Gentile and Roger Maris, whose 61 home runs that year broke the single-season record; Killebrew hit 20 to win the contest.

After his seven-triple season, his speed began to decrease and he could no longer regularly score triples due to pulling his quadriceps during the 1962 season. Killebrew moved to left field, where he started off the season slowly. He hit under .200 in both April and June, and because of this Killebrew was not selected to play in either 1962 All-Star Game, the last season he was not named an All-Star before 1972. On July 18 in a game against the Cleveland Indians, Killebrew and Bob Allison became the first teammates since 1890 to hit grand slams in the same inning as the Twins scored 11 runs in the first. Over the course of the season, Killebrew hit 48 home runs, 126 RBIs, and had 107 walks, all career highs at the time. No one else in the AL managed even 40 home runs and he also led the league in RBIs. Killebrew's 48 home runs also broke the franchise record for the second year in a row. Not all of his stats were positive; Killebrew's batting average dropped from .288 in 1961 to .243 and he struck out a career-worst 142 times, leading the AL.

Killebrew's efforts were rewarded in 1963 when he agreed to a contract for about $40,000 ($ today). He started the season off slowly, and he missed the second half of April and early May due to a right knee injury that was slow to heal. Killebrew continued his hitting prowess for the Twins upon his return, and at one point led them on a six-game winning streak. On September 21, Killebrew hit three home runs in a game for the only time in his career in the first game of a doubleheader against the Boston Red Sox. Killebrew finished the season with a .258 batting average, 45 home runs, and 96 RBI, and led the league in home runs and slugging percentage (.555). He had surgery on his troublesome right knee after the season ended.
Having played left field for the previous three years with a below-average throwing arm, the additional complication of Killebrew's knee surgery necessitated a move to the infield. For the remainder of his career, he played only 19 games in the outfield. He finished the 1964 season with a .270 batting average, 49 home runs, and 111 RBI; he led the AL in home runs for the third consecutive year.

The Twins finally won the American League pennant during the 1965 season. On July 11, the day before the All-Star break, defending AL champion Yankees had a one-run lead over the Twins going into the bottom of the 9th inning, but Killebrew hit a two-run home run for the win. Two days later, Killebrew started the All-Star Game at his home field, Metropolitan Stadium, and hit a game-tying two-run home run, erasing what had been a 5–0 National League lead. Elected to play first base on his fifth All-Star team, Killebrew became the first player in All-Star game history to be elected at three different positions, having previously been selected to play third base (1959 and 1961) and left field (1963 and 1964).

Killebrew drove in the tying or winning run seven times in 1965 before suffering an injury on August 2. During a game against the Orioles, Twins third baseman Rich Rollins made a poor throw to first and while trying to save the play, Killebrew collided with the runner and dislocated his elbow, putting him out of action until mid-September. Despite his absence, the Twins had a win-loss record of 28–19 and even extended their first place lead. Killebrew ended the regular season with 25 home runs and 75 RBI, his lowest numbers in a full season due to the injury. In the 1965 World Series against the Los Angeles Dodgers, Killebrew and Zoilo Versalles led the Twins with .286 batting averages, and Killebrew hit a home run off Don Drysdale in Game 4. Overall, Minnesota was shut out in three games and the Dodgers won the series in seven games.

At the start of the 1966 season, Killebrew hit few home runs; halfway through May, he had only hit two home runs, his lowest total at that point of a season since 1960, when he had missed the first two months of the season. He later increased his tally to 39 and finished the season with a .281 batting average and 110 RBIs. He led the AL with 103 walks and finished 4th in Most Valuable Player Award (MVP) voting to Frank Robinson, Brooks Robinson, and Boog Powell.

During the 1967 season, Killebrew showed his ability to hit long home runs when, on June 3, 1967, he struck the longest home run recorded at Metropolitan Stadium, a shot off Lew Burdette in the 4th inning that landed in the second deck of the bleachers. The Twins, led by Killebrew, were in the pennant race throughout the season, and had a one-game lead as the final two games of the season began against the Boston Red Sox. Having to win only once to clinch the pennant, Killebrew hit a home run in the first game and recorded two hits in each game, but Boston won twice and Minnesota finished in a second place tie with the Detroit Tigers. Killebrew finished the season with a .269 batting average and 113 RBIs, and led the AL with 44 home runs (tied with Carl Yastrzemski) and 131 walks. He also finished a distant second in MVP voting to Boston's Triple Crown winner Carl Yastrzemski.

Killebrew started the 1968 season in a different venue; he served as a prosecution witness in a case where his name was being used to sell stocks in Idaho, unknown to him. Despite this, the season was unsuccessful for Killebrew, whose batting average barely passed .200 most of the year; after a strong start, he hit below .200 in both May and June and his average stood at .204 with 13 home runs going into the all-star break. Even so, he was selected as the starting first baseman in the All-Star Game and Killebrew stated that, owing to his poor start, he was "surprised" and "embarrassed" by the selection. In the All-Star Game itself, in the third inning he stretched for a ball thrown by shortstop Jim Fregosi and his foot slipped and he did the splits, rupturing his left medial hamstring. He was carried from the field by a stretcher. At the time, the injury was considered career-threatening, but after missing about six weeks, he returned to limited action in September.

After enduring seven months of rehabilitation for his injury, Killebrew remained in pain but rebounded to have his best season in 1969. On July 5, Killebrew set a career-high with six RBIs in a game against the Oakland Athletics. That personal best lasted barely two months: on September 7 he hit a three-run home run and a grand slam for seven RBIs, all in the first two innings, to defeat the Athletics again. Killebrew led the best offense in the league and rookie manager Billy Martin's Twins won the new American League West division as a result.

For the season, Killebrew set career highs in RBIs, runs, walks and on-base percentage, tied his career high with 49 home runs, and even registered eight of his 19 career stolen bases, en route to winning his only Most Valuable Player Award. He led the AL in home runs, RBIs, on-base percentage, walks, and intentional walks and knocked in the winning run 20 times while playing in all 162 games. As of 2011, Killebrew's home run, RBI, and walk totals from 1969 remain team records, and his 145 walks are tied for the 20th highest single season total in MLB history and 7th highest for a right-handed batter. In the 1969 American League Championship Series, the Baltimore Orioles used their pitching staff, the best in the league, to defeat Minnesota and win the series three games to none. Baltimore avoided Killebrew by walking him six times in the three games to avoid pitching to him, which was as many times as they walked the rest of the Twins team.

After his MVP season, Killebrew signed a new contract with the Twins worth $90,000 ($ today). He was set to lead a team that had undergone a lot of change; Killebrew was one of only four Twins remaining from the 1965 pennant-winning club. He spent most of the season's first half continuing his success, and found Baltimore's Brooks Robinson rivalling him for the third base spot during the All-Star voting process; the two were neck-and-neck throughout. He continued his success through the second half of the year, and at season's end Killebrew had hit 41 home runs with 113 RBIs and finished third in MVP voting behind teammate and runner-up Tony Oliva and Baltimore's Boog Powell. The Twins again faced Powell and the Orioles in the 1970 American League Championship Series, a rematch of the previous season. The Twins were again swept, though Killebrew's performance improved as he hit two home runs in three games.

Killebrew reached the 40 home runs for the final time in 1970 and also made his last appearance in the postseason. His contract continued to grow in value though, and before the 1971 season began he was awarded the first $100,000 ($ today) contract in Twins' history. Killebrew appeared in his last All-Star Game in 1971, hitting a two-run home run off Ferguson Jenkins to provide the margin of victory for the AL. He finished the season with a .254 batting average, 114 walks, 119 RBI, the latter two of which led the league, and 28 home runs. Killebrew hit his 498th home run on June 22, 1971, but a sprained right toe made his run to milestone number 500 a slow one. He hit number 499 more than a month later and finally hit number 500 off a Mike Cuellar slow curveball in the first inning of an August 10 home game; at the time, he was the 10th player in history to hit 500 home runs. He then wasted no time in hitting number 501, knocking a Cuellar fastball over the fences later in the same game.
In 1972, Killebrew showed signs of slowing down. He missed his first All-Star Game since 1962, but instead of expressing disappointment in his streak ending, he noted that Twins shortstop Danny Thompson should have had the opportunity to play instead; Thompson mentioned the same thing about Killebrew. Despite not making the team, Killebrew's home run total continued to climb, and by the end of July he had Jimmie Foxx and Mickey Mantle career marks in his sights; he went on to pass both in August. Killebrew finished the season with a .231 batting average, 26 home runs, and 74 RBIs. There were questions about Killebrew's health as the 1973 season began, as he had surgery twice during the offseason to fix leg problems. He played through the first half of the season, but an injury to his left knee on June 25 sidelined him. A month later, the injury had not cleared up, and he underwent surgery to remove some torn cartilage; he did not return to the lineup until mid-September. Killebrew only played in 69 games that season, hitting five home runs.

Fully recovered for the 1974 season, Killebrew made his mark early on, hitting two home runs in a May 5 match against the Detroit Tigers; the second was career home run number 550. In his honor, the Twins held a Harmon Killebrew Day in August, where it was announced that they would retire his number; Killebrew responded by leading the Twins to a 5–4 victory over the Orioles. He finished the season with a .222 batting average, 13 home runs, and 54 RBIs. In December 1974, he was given the option of staying with the Twins as a coach and batting instructor, managing the AAA Tacoma Twins, or being released. He chose to be released, ending his 21-season tenure with the Twins.

On January 24, 1975, eight days after getting his release from the Twins, Killebrew signed a one-year contract with the Kansas City Royals. During his return to Minnesota in early May, the Twins formally retired his No. 3 jersey. In that game, Killebrew hit a home run against his former teammates and received a standing ovation from the crowd. In 106 games with the Royals, he had a batting average of .199, 14 home runs, and 44 RBIs. At the end of the season, the Royals decided to release Killebrew. In March 1976, he formally announced his retirement and stated that he would become an announcer and color commentator for Twins games. At the time of his retirement, he was fifth all-time on the home run list.

Killebrew was first eligible for the Hall of Fame in 1981 and received 239 votes, or 59.6% of the vote; 75% of the vote is required for induction. While he did hit 573 home runs (5th all-time when he left the game), he amassed a relatively low hit total (2086), given the years he played, combined with a high number of strikeouts (1699), and a .256 batting average. In 1982, Killebrew received 59.3% of the vote, taking a backseat to Hank Aaron and Frank Robinson, who made it in their first year of eligibility. After receiving 71.9% of the vote in 1983, Killebrew said that not getting in that year was more difficult to accept than the previous two times, and asked "Why do the writers feel there only has to be a certain number inducted each time?" In 1984, Killebrew received 83.1% of the vote and was elected to the Hall in his fourth year of eligibility, joining Luis Aparicio and Don Drysdale as electees.

In his career, Killebrew hit 573 home runs, which as of 2015 is currently 11th all-time, 1,584 RBIs, 1,559 walks, which is currently 15th all-time, and he easily holds the all-time home run record among players born in the state of Idaho with 573; Vance Law is second with 71. He also finished with the record of having the most plate appearances (9,831) in his career without a sacrifice hit (since broken by Frank Thomas with 10,074 plate appearances).

Reggie Jackson once said, "If Harmon Killebrew isn't the league's best player, I've never seen one. The street along the south side of the Mall of America, the former site of Metropolitan Stadium, in Bloomington, Minnesota was named "Killebrew Drive" in his honor. Banners that hung above the Metrodome's outfield upper deck, resembling baseball cards, showed the retired numbers: Killebrew (3), Rod Carew (29), Tony Oliva (6), Kent Hrbek (14) and Kirby Puckett (34). In 1999, he was ranked 69th on The Sporting News list of the 100 Greatest Baseball Players and was nominated as a finalist for Major League Baseball's All-Century Team. When the Twins moved into Target Field in 2010, Gate 3 on the southeast (centerfield) side of the stadium was named in his honor. There are also corresponding gates for the team's other retired numbers. Killebrew Canyon at Heavenly Mountain Resort is also named after the baseball star, who skied the outer limits of the resort after his retirement from baseball.

Despite rumors that Killebrew was the player depicted in the Major League Baseball logo, according to the creator, Jerry Dior, it was not patterned after Killebrew or any other specific player. Killebrew is the model for the Major League Baseball Players Alumni Association, an organization which Killebrew helped found in 1982.

Killebrew was known as an all-around gentleman during his playing career. He's one of the greatest of all time." He was even noted as being kind to the umpires:

Killebrew was known for his quick hands and exceptional upper-body strength, demonstrated by frequent "tape measure" home runs that he hit in the prime of his career. Killebrew said that his first home run in the Majors was his favorite, coming off Billy Hoeft at Griffith Stadium. He said of it, "Frank House was the catcher. When I came to the plate, he said, 'Kid, we're going to throw you a fastball.' I didn't know whether to believe him or not. I hit it out. It was one of the longest home runs I ever hit. As I crossed the plate, House said, 'That's the last time I ever tell you what pitch is coming'."

On August 3, 1962, he was the first batter ever to hit a baseball over the left field roof at Tiger Stadium, a seldom-reached target as contrasted with the old ballpark's smaller right field area. Only three others accomplished this feat during the next 37 seasons before the stadium was closed.
On May 24, 1964, Harmon hit the longest measured homer at Baltimore's Memorial Stadium, to deep left center. The ball landed in the far reaches of the bleachers. The only player to hit one completely out of the Orioles' stadium was Frank Robinson in 1966; his blast was reported as about , or about less than Killebrew's. On June 3, 1967, Killebrew hit a home run, the longest measured home run ever hit at Metropolitan Stadium and, as of 2011, the longest in Twins history. That event is commemorated at the Mall of America in Bloomington, which includes a plaque marking home plate, and one red-painted seat from the Met which was placed at the location and elevation of the landing spot of the home run. The new Target Field has a statue of a Gold Glove outside Gate 34 and it is exactly from Target Field's home plate.

Following his retirement, Killebrew was a television broadcaster for the Twins at WTCN TV from 1976 to 1978, the Oakland Athletics from 1979 to 1982, the California Angels in 1983 and back with Minnesota from 1984 to 1988. While with Oakland, he also served as a major- and minor-league hitting instructor. In the late 1980s, Killebrew had financial problems. In July 1988, his house went into foreclosure and, in 1989, the "Minneapolis Star Tribune" reported that he had fallen $700,000 into debt. He also divorced his first wife of over 30 years, Elaine, who he had married in 1955. Soon after, Killebrew's health failed. In May 1990, he was rushed to the hospital with a collapsed lung and damaged esophagus. Together with a subsequent abscess and staph infection, Killebrew endured three surgeries and nearly died. He used a wheelchair for some time post-surgery. By December 1990, his health was improved and he was remarried to Nita.

Killebrew was involved in a Boise, Idaho insurance and securities business. He moved to Scottsdale, Arizona in 1990, where he chaired the Harmon Killebrew Foundation, which he created in 1998. Killebrew founded the Danny Thompson Memorial Golf Tournament, now titled the Killebrew-Thompson Memorial in 1977 with former Idaho congressman Ralph Harding, which is played annually in late August in Sun Valley, Idaho, and has donated more than $15.6 million to leukemia and cancer research. Thompson was a Twins teammate who continued his major league career while suffering from leukemia; he died in December 1976 at the age of 29.

Despite his nicknames and style of play, Killebrew was considered by his colleagues to be a quiet, kind man. While still an active major leaguer, Killebrew became a member of The Church of Jesus Christ of Latter-Day Saints, and never smoked or drank. He was once asked in an interview what hobbies he had, to which he replied, "Just washing the dishes, I guess." 

On December 29, 2010, Killebrew announced that he had been diagnosed with esophageal cancer and started treatment. On May 13, 2011, a Minnesota Twins press release reported he was ceasing treatment and entering hospice care, because his illness had progressed beyond his doctors' expectation of cure. To honor Killebrew, the Twins wore their 1961 throwback alternate jerseys at home for the remainder of the 2011 season; he was also honored by the Washington Nationals, who hung a jersey with Killebrew's name and number 3 in
their home dugout. Killebrew died on May 17, 2011 at his home in Scottsdale, Arizona at the age of 74, a month and a half short of his 75th birthday. He was interred at Riverside Cemetery in Payette, Idaho. Following his death, the Twins released a statement:




</doc>
<doc id="311144" url="https://en.wikipedia.org/wiki?curid=311144" title="Margaret Fuller">
Margaret Fuller

Sarah Margaret Fuller Ossoli (May 23, 1810 – July 19, 1850), commonly known as Margaret Fuller, was an American journalist, editor, critic, and women's rights advocate associated with the American transcendentalism movement. She was the first full-time American female book reviewer in journalism. Her book "Woman in the Nineteenth Century" is considered the first major feminist work in the United States.

Born Sarah Margaret Fuller in Cambridge, Massachusetts, she was given a substantial early education by her father, Timothy Fuller. She later had more formal schooling and became a teacher before, in 1839, she began overseeing her Conversations series: classes for women meant to compensate for their lack of access to higher education. She became the first editor of the transcendentalist journal "The Dial" in 1840, before joining the staff of the "New York Tribune" under Horace Greeley in 1844. By the time she was in her 30s, Fuller had earned a reputation as the best-read person in New England, male or female, and became the first woman allowed to use the library at Harvard College. Her seminal work, "Woman in the Nineteenth Century", was published in 1845. A year later, she was sent to Europe for the "Tribune" as its first female correspondent. She soon became involved with the revolutions in Italy and allied herself with Giuseppe Mazzini. She had a relationship with Giovanni Ossoli, with whom she had a child. All three members of the family died in a shipwreck off Fire Island, New York, as they were traveling to the United States in 1850. Fuller's body was never recovered.

Fuller was an advocate of women's rights and, in particular, women's education and the right to employment. She also encouraged many other reforms in society, including prison reform and the emancipation of slaves in the United States. Many other advocates for women's rights and feminism, including Susan B. Anthony, cite Fuller as a source of inspiration. Many of her contemporaries, however, were not supportive, including her former friend Harriet Martineau. She said that Fuller was a talker rather than an activist. Shortly after Fuller's death, her importance faded; the editors who prepared her letters to be published, believing her fame would be short-lived, censored or altered much of her work before publication.

Sarah Margaret Fuller was born on May 23, 1810, in Cambridgeport, Massachusetts, the first child of Congressman Timothy Fuller and Margaret Crane Fuller. She was named after her paternal grandmother and her mother, but by age nine she dropped "Sarah" and insisted on being called "Margaret." The Margaret Fuller House, in which she was born, is still standing. Her father taught her to read and write at the age of three and a half, shortly after the couple's second daughter, Julia Adelaide, died at 14 months old. He offered her an education as rigorous as any boy's at the time and forbade her to read the typical feminine fare of the time, such as etiquette books and sentimental novels. He incorporated Latin into his teaching shortly after the birth of the couple's son Eugene in May 1815, and soon Margaret was translating simple passages from Virgil. Later in life Margaret blamed her father's exacting love and his valuation of accuracy and precision for her childhood nightmares and sleepwalking. During the day Margaret spent time with her mother, who taught her household chores and sewing. In 1817, her brother William Henry Fuller was born, and her father was elected as a representative in the United States Congress. For the next eight years, he spent four to six months a year in Washington, D.C. At age ten, Fuller wrote a cryptic note which her father saved: "On 23 May 1810, was born one foredoomed to sorrow and pain, and like others to have misfortunes."

Fuller began her formal education at the Port School in Cambridgeport in 1819 before attending the Boston Lyceum for Young Ladies from 1821 to 1822. In 1824, she was sent to the School for Young Ladies in Groton, on the advice of aunts and uncles, though she resisted the idea at first. While she was there, Timothy Fuller did not run for re-election, in order to help John Quincy Adams with his presidential campaign in 1824; he hoped Adams would return the favor with a governmental appointment. On June 17, 1825, Fuller attended the ceremony at which the American Revolutionary War hero Marquis de Lafayette laid the cornerstone of the Bunker Hill Monument 50 years after the battle. 15-year-old Fuller introduced herself to Lafayette in a letter which concluded: "Should we both live, and it is possible to a female, to whole the avenues of glory are seldom accessible, I will recal my name to your recollection." Early on, Fuller sensed herself to be a significant person and thinker. Fuller left the Groton school after two years and returned home at 16. At home she studied the classics and trained herself in several modern languages and read world literature. By this time, she realized she did not fit in with other young women her age. She wrote, "I have felt that I was not born to the common womanly lot." Eliza Farrar, wife of Harvard professor John Farrar and author of "The Young Lady's Friend" (1836), attempted to train her in feminine etiquette until the age of 20, but was never wholly successful.

Fuller was an avid reader. By the time she was in her 30s, she had earned a reputation as the best-read person, male or female, in New England. She used her knowledge to give private lessons based on the teaching style of Elizabeth Palmer Peabody. Fuller hoped to earn her living through journalism and translation; her first published work, a response to historian George Bancroft, appeared in November 1834 in the "North American Review". When she was 23, her father's law practice failed and he moved the family to a farm in Groton. On February 20, 1835, Frederic Henry Hedge and James Freeman Clarke asked her to contribute to each of their periodicals. Clarke helped her publish her first literary review in the "Western Messenger" in June: criticisms of recent biographies on George Crabbe and Hannah More. In the fall of that year, she suffered a terrible migraine with a fever that lasted nine days. Fuller continued to experience such headaches throughout her life. While she was still recovering, her father died of cholera on October 2, 1835. She was deeply affected by his death: "My father's image follows me constantly", she wrote. She vowed to step in as the head of the family and take care of her widowed mother and younger siblings. Her father had not left a will, and two of her uncles gained control of his property and finances, later assessed at $18,098.15, and the family had to rely on them for support. Humiliated by the way her uncles were treating the family, Fuller wrote that she regretted being "of the softer sex, and never more than now".
Around this time, Fuller was hoping to prepare a biography of Johann Wolfgang von Goethe, but felt that she could work on it only if she traveled to Europe. Her father's death and her sudden responsibility for her family caused her to abandon this idea. In 1836, Fuller was given a job teaching at Bronson Alcott's Temple School in Boston, where she remained for a year. She then accepted an invitation to teach under Hiram Fuller (no relation) at the Greene Street School in Providence, Rhode Island, in April 1837 with the unusually high salary of $1,000 per year. Her family sold the Groton farm and Fuller moved with them to Jamaica Plain, Massachusetts. On November 6, 1839, Fuller held the first of her Conversations, discussions among local women who met in the Boston home of the Peabodys. Fuller intended to compensate for the lack of women's education with discussions and debates focused on subjects including the fine arts, history, mythology, literature, and nature. Serving as the "nucleus of conversation", Fuller also intended to answer the "great questions" facing women and encourage women "to question, to define, to state and examine their opinions". She asked her participants, "What were we born to do? How shall we do it? Which so few ever propose to themselves 'till their best years are gone by". In Conversations, Fuller was finally finding equal intellectual companions among her female contemporaries. A number of significant figures in the women's rights movement attended these gatherings, including Sophia Dana Ripley, Caroline Sturgis, and Maria White Lowell.

In October 1839, Ralph Waldo Emerson was seeking an editor for his transcendentalist journal "The Dial". After several declined the position, he offered it to Fuller, referring to her as "my vivacious friend." Emerson had met Fuller in Cambridge in 1835; of that meeting, he admitted: "she made me laugh more than I liked." The next summer, Fuller spent two weeks at Emerson's home in Concord. Fuller accepted Emerson's offer to edit "The Dial" on October 20, 1839, and began work in the first week of 1840. She edited the journal from 1840 to 1842, though her promised annual salary of $200 was never paid. Because of her role, she was soon recognized as one of the most important figures of the transcendental movement and was invited to George Ripley's Brook Farm, a communal experiment. Fuller never officially joined the community but was a frequent visitor, often spending New Year's Eve there. In the summer of 1843, she traveled to Chicago, Milwaukee, Niagara Falls, and Buffalo, New York; while there, she interacted with several Native Americans, including members of the Ottawa and the Chippewa tribes. She reported her experiences in a book called "Summer on the Lakes", which she completed writing on her 34th birthday in 1844. The critic Evert Augustus Duyckinck called it "the only genuine book, I can think of, this season." Fuller used the library at Harvard College to do research on the Great Lakes region, and became the first woman allowed to use Harvard's library.

Fuller's "The Great Lawsuit" was written in serial form for "The Dial". She originally intended to name the work "The Great Lawsuit: Man 'versus' Men, Woman 'versus' Women"; when it was expanded and published independently in 1845, it was entitled "Woman in the Nineteenth Century". After completing it, she wrote to a friend: "I had put a good deal of my true self in it, as if, I suppose I went away now, the measure of my footprint would be left on earth." The work discussed the role that women played in American democracy and Fuller's opinion on possibilities for improvement. It has since become one of the major documents in American feminism. It is considered the first of its kind in the United States. Soon after the American publication of "Woman in the Nineteenth Century", it was pirated and published by H.G. Clarke in England. Despite never receiving commissions due to a lack of international copyright laws, Fuller was "very glad to find it will be read by women" around the world.

Fuller left "The Dial" in 1844 in part because of ill health but also because of her disappointment with the publication's dwindling subscription list. She moved to New York that autumn and joined Horace Greeley's "New York Tribune" as a literary critic, becoming the first full-time book reviewer in American journalism and, by 1846, the publication's first female editor. Her first article, a review of a collection of essays by Emerson, appeared in the December 1, 1844, issue. At this time, the "Tribune" had some 50,000 subscribers and Fuller earned $500 a year for her work. In addition to American books, she reviewed foreign literature, concerts, lectures, and art exhibits. During her four years with the publication, she published more than 250 columns, most signed with a "*" as a byline. In these columns, Fuller discussed topics ranging from art and literature to political and social issues such as the plight of slaves and women's rights. She also published poetry; her poems, styled after the work of Emerson, do not have the same intellectual vigor as her criticism.

Around this time, she was also involved in a scandal involving fellow literary critic Edgar Allan Poe, who had been carrying on a public flirtation with the married poet Frances Sargent Osgood. Another poet, Elizabeth F. Ellet, had become enamored of Poe and jealous of Osgood and suggested the relationship between Poe and Osgood was more than an innocent flirtation. Osgood then sent Fuller and Anne Lynch Botta to Poe's cottage on her behalf to request that he return the personal letters she had sent him. Angered by their interference, Poe called them "Busy-bodies". A public scandal erupted and continued until Osgood's estranged husband Samuel Stillman Osgood stepped in and threatened to sue Ellet.

In 1846 the "New York Tribune" sent Fuller to Europe, specifically England and Italy, as its first female foreign correspondent. She traveled from Boston to Liverpool in August on the "Cambria", a vessel that used both sail and steam to make the journey in ten days and sixteen hours. Over the next four years she provided the "Tribune" with thirty-seven reports. She interviewed many prominent writers including George Sand and Thomas Carlyle—whom she found disappointing because of his reactionary politics, among other things. George Sand had previously been an idol of hers, but Fuller was disappointed when Sand chose not to run for the French National Assembly, saying that women were not ready to vote or to hold political office. Fuller was also given a letter of introduction to Elizabeth Barrett by Cornelius Mathews, but did not meet her at that time, because Barrett had just eloped with Robert Browning.

In England in the spring of 1846, she met Giuseppe Mazzini, who had been in exile there from Italy since 1837. Fuller also met the Italian revolutionary Giovanni Angelo Ossoli, a marquis who had been disinherited by his family because of his support for Mazzini. Fuller and Ossoli moved in together in Florence, Italy, likely before they were married, though whether they ever married is uncertain. Fuller was originally opposed to marrying him, in part because of the difference in their religions; she was Protestant and he was Roman Catholic. Emerson speculated that the couple was "married perhaps in Oct. Nov. or Dec" of 1847, though he did not explain his reasoning. Biographers have speculated that the couple married on April 4, 1848, to celebrate the anniversary of their first meeting but one biographer provided evidence they first met on April 1 during the ceremony called "Lavanda degli Altari" (Altars Lavage). By the time the couple moved to Florence, they were referred to as husband and wife, though it is unclear if any formal ceremony took place. It seems certain that at the time their child was born, they were not married. By New Year's Day 1848, she suspected that she was pregnant but kept it from Ossoli for several weeks. Their child, Angelo Eugene Philip Ossoli, was born in early September 1848 and nicknamed Angelino. The couple was very secretive about their relationship but, after Angelino suffered an unnamed illness, they became less so. Fuller informed her mother about Ossoli and Angelino in August 1849 in a letter that explained that she had kept silent so as not to upset her "but it has become necessary, on account of the child, for us to live publicly and permanently together." Her mother's response makes it clear that she was aware that the couple was not legally married. Even so, she was happy for her daughter, writing: "I send my first kiss with my fervent blessing to my grandson."

The couple supported Giuseppe Mazzini's revolution for the establishment of a Roman Republic in 1849. Ossoli fought in the struggle while Fuller volunteered at a supporting hospital. When the republicans they supported met defeat, they had to flee Italy and decided to move to the United States. En route, they returned to Paris, where she finally met Elizabeth Barrett Browning. Fuller used her experience in Italy to begin a book about the history of the Roman Republic—a work she may have begun as early as 1847— and hoped to find an American publisher after a British one rejected it. She believed the work would be her most important, referring to it in a March 1849 letter to her brother Richard as, "something good which may survive my troubled existence."

In the beginning of 1850, Fuller wrote to a friend: "It has long seemed that in the year 1850 I should stand on some important plateau in the ascent of life ... I feel however no marked and important change as yet." Also that year, Fuller wrote: "I am absurdly fearful and various omens have combined to give me a dark feeling ... It seems to me that my future upon earth will soon close ... I have a vague expectation of some crisis—I know not what". A few days after writing this, Fuller, Ossoli, and their child began a five-week return voyage to the United States aboard the ship "Elizabeth", an American merchant freighter carrying cargo that included mostly marble from Carrara. They set sail on May 17. At sea, the ship's captain, Seth Hasty, died of smallpox. Angelino contracted the disease and recovered.

Possibly because of the inexperienced first mate, now serving as captain, the ship slammed into a sandbar less than 100 yards from Fire Island, New York, on July 19, 1850, around Many of the other passengers and crew members abandoned ship. The first mate, Mr. Bangs, urged Fuller and Ossoli to try to save themselves and their child as he himself jumped overboard, later claiming he believed Fuller had wanted to be left behind to die. On the beach, people arrived with carts hoping to salvage any cargo washed ashore. None made any effort to rescue the crew or passengers of the "Elizabeth", though they were only 50 yards from shore. Most of those aboard attempted to swim to shore, leaving Fuller and Ossoli and Angelino some of the last on the ship. Ossoli was thrown overboard by a massive wave and, after the wave had passed, a crewman who witnessed the event said Fuller could not be seen.

Henry David Thoreau traveled to New York, at the urging of Emerson, to search the shore but neither Fuller's body nor that of her husband was ever recovered. Angelino's had washed ashore. Few of their possessions were found other than some of the child's clothes and a few letters. Fuller's manuscript on the rise and fall of the 1849 Roman Republic, which she described as, "what is most valuable to me if I live of any thing", was also lost. A memorial to Fuller was erected on the beach at Fire Island in 1901 through the efforts of Julia Ward Howe. A cenotaph to Fuller and Ossoli, under which Angelino is buried, is in Mount Auburn Cemetery, Cambridge, Massachusetts. The inscription reads, in part:

Within a week after her death, Horace Greeley suggested to Emerson that a biography of Fuller, to be called "Margaret and Her Friends", be prepared quickly "before the interest excited by her sad decease has passed away". Many of her writings were soon collected together by her brother Arthur as "At Home and Abroad" (1856) and "Life Without and Life Within" (1858). He also edited a new version of "Woman in the Nineteenth Century" in 1855. In February 1852, "The Memoirs of Margaret Fuller Ossoli" was published, edited by Emerson, James Freeman Clarke, and William Henry Channing, though much of the work was censored or reworded. It left out details about her love affair with Ossoli and an earlier relationship with a man named James Nathan. The three editors, believing the public interest in Fuller would be short-lived and that she would not survive as a historical figure, were not concerned about accuracy. For a time, it was the best-selling biography of the decade and went through thirteen editions before the end of the century. The book focused on her personality rather than her work. Detractors of the book ignored her status as a critic and instead criticized her personal life and her "unwomanly" arrogance.

Fuller was an early proponent of feminism and especially believed in providing education to women. Once equal educational rights were afforded women, she believed, women could push for equal political rights as well. She advocated that women seek any employment they wish, rather than catering to the stereotypical "feminine" roles of the time, such as teaching. She once said, "If you ask me what office women should fill, I reply—any ... let them be sea captains if you will. I do not doubt that there are women well fitted for such an office". She had great confidence in all women but doubted that a woman would produce a lasting work of art or literature in her time and disliked the popular female poets of her time. Fuller also warned women to be careful about marriage and not to become dependent on their husbands. As she wrote, "I wish woman to live, "first" for God's sake. Then she will not make an imperfect man for her god and thus sink to idolatry. Then she will not take what is not fit for her from a sense of weakness and poverty". By 1832, she had made a personal commitment to stay single. Fuller also questioned a definitive line between male and female: "There is no wholly masculine man ... no purely feminine" but that both were present in any individual. She suggested also that within a female were two parts: the intellectual side (which she called the Minerva) and the "lyrical" or "Femality" side (the Muse). She admired the work of Emanuel Swedenborg, who believed men and women shared "an angelic ministry", as she wrote, as well as Charles Fourier, who placed "Woman on an entire equality with Man". Unlike several contemporary women writers, including "Mrs. Sigourney" and "Mrs. Stowe", she was familiarly referred to in a less formal manner as "Margaret".

Fuller also advocated reform at all levels of society, including prison. In October 1844, she visited Sing Sing and interviewed the women prisoners, even staying overnight in the facility. Sing Sing was developing a more humane system for its women inmates, many of whom were prostitutes. Fuller was also concerned about the homeless and those living in dire poverty, especially in New York. She also admitted that, though she was raised to believe "that the Indian obstinately refused to be civilized", her travels in the American West made her realize that the white man unfairly treated the Native Americans; she considered Native Americans an important part of American heritage. She also supported the rights of African-Americans, referring to "this cancer of slavery", and suggested that those who were interested in the abolition movement follow the same reasoning when considering the rights of women: "As the friend of the Negro assumes that one man cannot by right hold another in bondage, so should the Friend of Woman assume that Man cannot by right lay even well-meant restrictions on Woman." She suggested that those who spoke against the emancipation of slaves were similar to those who did not support the emancipation of Italy.

Fuller agreed with the transcendental concern for the psychological well-being of the individual, though she was never comfortable being labeled a transcendentalist. Even so, she wrote, if being labeled a transcendentalist means "that I have an active mind frequently busy with large topics I hope it is so". She criticized people such as Emerson, however, for focusing too much on individual improvement and not enough on social reform. Like other members of the so-called Transcendental Club, she rebelled against the past and believed in the possibility of change. However, unlike others in the movement, her rebellion was not based on religion. Though Fuller occasionally attended Unitarian congregations, she did not entirely identify with that religion. As biographer Charles Capper has noted, she "was happy to remain on the Unitarian margins."

Margaret Fuller was especially known in her time for her personality and, in particular, for being overly self-confident and having a bad temper. This personality was the inspiration for the character Hester Prynne in Nathaniel Hawthorne's novel "The Scarlet Letter", specifically her radical thinking about "the whole race of womanhood". She may also be the basis for the character Zenobia in another of Hawthorne's works, "The Blithedale Romance". Hawthorne and his then-fiancée Sophia had first met Fuller in October 1839.

She was also an inspiration to poet Walt Whitman, who believed in her call for the forging of a new national identity and a truly American literature. Elizabeth Barrett Browning was also a strong admirer, but believed that Fuller's unconventional views were unappreciated in the United States and, therefore, she was better off dead. She also said that Fuller's history of the Roman Republic would have been her greatest work: "The work she was preparing upon Italy would probably have been more equal to her faculty than anything previously produced by her pen (her other writings being curiously inferior to the impressions her conversation gave you)". An 1860 essay collection, "Historical Pictures Retouched", by Caroline Healey Dall, called Fuller's "Woman in the Nineteenth Century" "doubtless the most brilliant, complete, and scholarly statement ever made on the subject". Despite his personal issues with Fuller, the typically harsh literary critic Edgar Allan Poe wrote of the work as "a book which few women in the country could have written, and no woman in the country would have published, with the exception of Miss Fuller", noting its "independence" and "unmitigated radicalism". Thoreau also thought highly of the book, suggesting that its strength came in part from Fuller's conversational ability. As he called it, it was "rich extempore writing, talking with pen in hand".

Another admirer of Fuller was Susan B. Anthony, a pioneer of women's rights, who wrote that Fuller "possessed more influence on the thought of American women than any woman previous to her time". Fuller's work may have partially inspired the Seneca Falls Convention in 1848. Anthony, along with Elizabeth Cady Stanton and Matilda Joslyn Gage wrote in their "History of Woman Suffrage" that Fuller "was the precursor of the Women's Rights agitation". Modern scholars have suggested "Woman in the Nineteenth Century" was the first major women's rights work since Mary Wollstonecraft's "A Vindication of the Rights of Woman" (1792), though an early comparison between the two women came from George Eliot in 1855. It is unclear if Fuller was familiar with Wollstonecraft's works; in her childhood, her father prevented her from reading them. In 1995, Fuller was inducted into the National Women's Hall of Fame.

Fuller, however, was not without her critics. A one-time friend, the English writer Harriet Martineau was one of her harshest detractors after Fuller's death. Martineau said that Fuller was a talker rather than an activist, that she had "shallow conceits" and often "looked down upon persons who acted instead of talking finely ... and despised those who, like myself, could not adopt her scale of valuation". The influential editor Rufus Wilmot Griswold, who believed she went against his notion of feminine modesty, referred to "Woman in the Nineteenth Century" as "an eloquent expression of her discontent at having been created female". New York writer Charles Frederick Briggs said that she was "wasting the time of her readers", especially because she was an unmarried woman and therefore could not "truly represent the female character". English writer and critic Matthew Arnold scoffed at Fuller's conversations as well, saying, "My G–d, what rot did she and the other female dogs of Boston talk about Greek mythology!" Sophia Hawthorne, who had previously been a supporter of Fuller, was critical of her after "Woman of the Nineteenth Century" was published:
Fuller had angered fellow poet and critic James Russell Lowell when she reviewed his work, calling him "absolutely wanting in the true spirit and tone of poesy ... his verse is stereotyped, his thought sounds no depth; and posterity will not remember him." In response, Lowell took revenge in his satirical "A Fable for Critics", first published in October 1848. At first, he considered excluding her entirely but ultimately gave her what was called the "most wholly negative characterization" in the work. Referring to her as Miranda, Lowell wrote that she stole old ideas and presented them as her own, she was genuine only in her spite and "when acting as censor, she privately blows a censer of vanity 'neath her own nose".

Shortly after Fuller's death, her importance faded. Her obituary in the newspaper she had once edited, the "Daily Tribune", said that her works had a few great sentiments, "but as a whole they must commend themselves mainly by their vigor of thought and habitual fearlessness rather than freedom of utterance". As biographer Abby Slater wrote, "Margaret had been demoted from a position of importance in her own right to one in which her only importance was in the company she kept". Years later, Hawthorne's son Julian wrote, "The majority of readers will, I think, not be inconsolable that poor Margaret Fuller has at last taken her place with the numberless other dismal frauds who fill the limbo of human pretension and failure." In the twentieth century, American writer Elizabeth Hardwick, former wife of Robert Lowell, wrote an essay called "The Genius of Margaret Fuller" (1986). She compared her own move from Boston to New York to Fuller's, saying that Boston was not a good place for intellectuals, despite the assumption that it was the best place for intellectuals.

In 1995, Fuller was inducted into the National Women's Hall of Fame.

On June 21, 2016, a historical marker in honor of Fuller was placed in Polhill Park in Beacon, NY, to commemorate her staying at Van Vliet boarding house. For the dedication ceremony, Fuller's poem, "Truth and Form," was set to music by Debra Kaye and performed by singer, Kelly Ellenwood.

Posthumous editions




Biographical information
Works
Other


</doc>
<doc id="311455" url="https://en.wikipedia.org/wiki?curid=311455" title="Order of the Bath">
Order of the Bath

The Most Honourable Order of the Bath (formerly the Most Honourable Military Order of the Bath) is a British order of chivalry founded by George I on 18 May 1725. The name derives from the elaborate medieval ceremony for appointing a knight, which involved bathing (as a symbol of purification) as one of its elements. The knights so created were known as "Knights of the Bath". George I "erected the Knights of the Bath into a regular Military Order". He did not (as is commonly believed) revive the Order of the Bath, since it had never previously existed as an Order, in the sense of a body of knights who were governed by a set of statutes and whose numbers were replenished when vacancies occurred.

The Order consists of the Sovereign (currently Queen Elizabeth II), the (currently The Prince of Wales), and three Classes of members:
Members belong to either the Civil or the Military Division. Prior to 1815, the order had only a single class, Knight Companion (KB), which no longer exists. Recipients of the Order are now usually senior military officers or senior civil servants. Commonwealth citizens who are not subjects of the Queen and foreign nationals may be made Honorary Members.

The Order of the Bath is the fourth-most senior of the British Orders of Chivalry, after The Most Noble Order of the Garter, The Most Ancient and Most Noble Order of the Thistle, and The Most Illustrious Order of St Patrick (dormant).

In the Middle Ages, knighthood was often conferred with elaborate ceremonies. These usually involved the knight-to-be taking a bath (possibly symbolic of spiritual purification) during which he was instructed in the duties of knighthood by more senior knights. He was then put to bed to dry. Clothed in a special robe, he was led with music to the chapel where he spent the night in a vigil. At dawn he made confession and attended Mass, then retired to his bed to sleep until it was fully daylight. He was then brought before the King, who after instructing two senior knights to buckle the spurs to the knight-elect's heels, fastened a belt around his waist, then struck him on the neck (with either a hand or a sword), thus making him a knight. It was this accolade which was the essential act in creating a knight, and a simpler ceremony developed, conferring knighthood merely by striking or touching the knight-to-be on the shoulder with a sword, or "dubbing" him, as is still done today. In the early medieval period the difference seems to have been that the full ceremonies were used for men from more prominent families.
From the coronation of Henry IV in 1399 the full ceremonies were restricted to major royal occasions such as coronations, investitures of the Prince of Wales or Royal dukes, and royal weddings, and the knights so created became known as "Knights of the Bath". Knights Bachelor continued to be created with the simpler form of ceremony. The last occasion on which Knights of the Bath were created was the coronation of Charles II in 1661.

From at least 1625, and possibly from the reign of James I, Knights of the Bath were using the motto "Tria juncta in uno" (Latin for "Three joined in one"), and wearing as a badge three crowns within a plain gold oval. These were both subsequently adopted by the Order of the Bath; a similar design of badge is still worn by members of the Civil Division. Their symbolism however is not entirely clear. The 'three joined in one' may be a reference to the kingdoms of England, Scotland and either France or Ireland, which were held (or claimed in the case of France) by English and, later, British monarchs. This would correspond to the three crowns in the badge. Another explanation of the motto is that it refers to the Holy Trinity. Nicolas quotes a source (although he is sceptical of it) who claims that prior to James I the motto was "Tria numina juncta in uno" (three powers/gods joined in one), but from the reign of James I the word "numina" was dropped and the motto understood to mean "Tria [regna] juncta in uno" (three kingdoms joined in one).

The prime mover in the establishment of the Order of the Bath was John Anstis, Garter King of Arms, England's highest heraldic officer. Sir Anthony Wagner, a recent holder of the office of Garter, wrote of Anstis's motivations:

It was Martin Leake's opinion that the trouble and opposition Anstis met with in establishing himself as Garter so embittered him against the heralds that when at last in 1718 he succeeded, he made it his prime object to aggrandise himself and his office at their expense. It is clear at least that he set out to make himself indispensable to the Earl Marshal, which was not hard, their political principles being congruous and their friendship already established, but also to Sir Robert Walpole and the Whig ministry, which can by no means have been easy, considering his known attachment to the Pretender and the circumstances under which he came into office ... The main object of Anstis's next move, the revival or institution of the Order of the Bath was probably that which it in fact secured, of ingratiating him with the all-powerful Prime Minister Sir Robert Walpole.

The use of honours in the early eighteenth century differed considerably from the modern honours system in which hundreds, if not thousands, of people each year receive honours on the basis of deserving accomplishments. The only honours available at that time were hereditary (not life) peerages and baronetcies, knighthoods and the Order of the Garter (or the Order of the Thistle for Scots), none of which were awarded in large numbers (the Garter and the Thistle are limited to 24 and 16 living members respectively.) The political environment was also significantly different from today:

The Sovereign still exercised a power to be reckoned with in the eighteenth century. The Court remained the centre of the political world. The King was limited in that he had to choose Ministers who could command a majority in Parliament, but the choice remained his. The leader of an administration still had to command the King's personal confidence and approval. A strong following in Parliament depended on being able to supply places, pensions, and other marks of Royal favour to the government's supporters.

The attraction of the new Order for Walpole was that it would provide a source of such favours to strengthen his political position. He made sure that most of the 36 new honorees were peers and MPs who would provide him with useful connections. George I having agreed to Walpole's proposal, Anstis was commissioned to draft statutes for the Order of the Bath. As noted above, he adopted the motto and badge used by the Knights of the Bath, as well as the colour of the riband and mantle, and the ceremony for creating a knight. The rest of the statutes were mostly based on those of the Order of the Garter, of which he was an officer (as Garter King of Arms). The Order was founded by letters patent under the Great Seal dated 18 May 1725, and the statutes issued the following week.

The Order initially consisted of the Sovereign, a Prince of the blood Royal as Principal Knight, a Great Master and thirty-five Knights Companion. Seven officers (see below) were attached to the Order. These provided yet another opportunity for political patronage, as they were to be sinecures at the disposal of the Great Master, supported by fees from the knights. Despite the fact that the Bath was represented as a military Order, only a few military officers were among the initial appointments (see List of Knights Companion of the Order of the Bath). They may be broken down into categories as follows (note that some are classified in more than one category):

The majority of the new Knights Companions were knighted by the King and invested with their ribands and badges on 27 May 1725. Although the statutes set out the full medieval ceremony which was to be used for creating knights, this was not performed, and indeed was possibly never intended to be, as the original statutes contained a provision allowing the Great Master to dispense Knights Companion from these requirements. The original knights were dispensed from all the medieval ceremonies with the exception of the Installation, which was performed in the Order's Chapel, the Henry VII Chapel in Westminster Abbey, on 17 June. This precedent was followed until 1812, after which the Installation was also dispensed with, until its revival in the twentieth century. The ceremonies however remained part of the Statutes until 1847.

Although the initial appointments to the Order were largely political, from the 1770s appointments to the Order were increasingly made for naval, military or diplomatic achievements. This is partly due to the conflicts Britain was engaged in over this period. The Peninsular War resulted in so many deserving candidates for the Bath that a statute was issued allowing the appointment of "Extra Knights" in time of war, who were to be additional to the numerical limits imposed by the statutes, and whose number was not subject to any restrictions. Another statute, this one issued some 80 years earlier, had also added a military note to the Order. Each knight was required, under certain circumstances, to supply and support four men-at-arms for a period not exceeding 42 days in any year, to serve in any part of Great Britain. This company was to be captained by the Great Master, who had to supply four trumpeters, and was also to appoint eight officers for this body, however the statute was never invoked.

In January 1815, after the end of the Peninsular War, the Prince Regent (later George IV) expanded the Order of the Bath "to the end that those Officers who have had the opportunities of signalising themselves by eminent services during the late war may share in the honours of the said Order, and that their names may be delivered down to remote posterity, accompanied by the marks of distinction which they have so nobly earned."

The Order was now to consist of three classes: Knights Grand Cross, Knights Commander, and Companions. The existing Knights Companion (of which there were 60) became Knight Grand Cross; this class was limited to 72 members, of which twelve could be appointed for civil or diplomatic services. The military members had to be of the rank of at least Major-General or Rear Admiral. The Knights Commander were limited to 180, exclusive of foreign nationals holding British commissions, up to ten of whom could be appointed as honorary Knights Commander. They had to be of the rank of Lieutenant-Colonel or Post-Captain. The number of Companions was not specified, but they had to have received a medal or been mentioned in despatches since the start of the war in 1803. A list of about 500 names was subsequently published. Two further officers were appointed, an "Officer of arms attendant on the Knights Commanders and Companions", and a "Secretary appertaining to the Knights Commanders and Companions" The large increase in numbers caused some complaints that such an expansion would reduce the prestige of the Order.

In 1847, Queen Victoria issued new statutes eliminating all references to an exclusively military Order. As well as removing the word 'Military' from the full name of the Order, this opened up the grades of Knight Commander and Companion to civil appointments, and the Military and Civil Divisions of the Order were established. New numerical limits were imposed, and the opportunity also taken to regularise the 1815 expansion of the Order. The 1847 statutes also abolished all the medieval ritual, however they did introduce a formal Investiture ceremony, conducted by the Sovereign wearing the Mantle and insignia of the Order, attended by the Officers and as many GCBs as possible, in their Mantles.

In 1859 a further edition of the Statutes was issued; the changes related mainly to the costs associated with the Order. Prior to this date it had been the policy that the insignia (which were provided by the Crown) were to be returned on the death of the holder; the exception had been foreigners who had been awarded honorary membership. In addition foreigners had usually been provided with stars made of silver and diamonds, whereas ordinary members had only embroidered stars. The decision was made to award silver stars to all members, and only require the return of the Collar. The Crown had also been paying the fees due to the officers of the Order for members who had been appointed for the services in the recent war. The fees were abolished and replaced with a salary of approximately the same average value. The offices of Genealogist and Messenger were abolished, and those of Registrar and Secretary combined.

In 1910, after his accession to the throne, George V ordered the revival of the Installation ceremony, perhaps prompted by the first Installation ceremony of the more junior Order of St Michael and St George, held a few years earlier, and the building of a new chapel for the Order of the Thistle in 1911. The Installation ceremony took place on 22 July 1913 in the Henry VII Chapel, and Installations have been held at regular intervals since.

Prior to the 1913 Installation it was necessary to adapt the chapel to accommodate the larger number of members. An appeal was made to the members of the Order, and following the Installation a surplus remained. A Committee was formed from the Officers to administer the 'Bath Chapel Fund', and over time this committee has come to consider other matters than purely financial ones.

Another revision of the statutes of the Order was undertaken in 1925, to consolidate the 41 additional statutes which had been issued since the 1859 revision.

Women were admitted to the Order in 1971. In the 1971 New Year Honours, Jean Nunn became the first woman admitted to the order. In 1975, Princess Alice, Duchess of Gloucester, an aunt of Elizabeth II, became the first (and to date only) woman to reach the highest rank, Dame Grand Cross. Princess Alice (née Douglas-Montagu-Scott) was a direct descendant of the Order's first Great Master, and her husband, who had died the previous year, had also held that office.

The British Sovereign is the Sovereign of the Order of the Bath.
As with all honours except those in the Sovereign's personal gift, the Sovereign makes all appointments to the Order on the advice of the Government.

The next-most senior member of the Order is the Great Master, of which there have been nine:

Originally a Prince of the Blood Royal, as the Principal Knight Companion, ranked next after the sovereign. This position was joined to that of the Great Master in the statutes of 1847. The Great Master and Principal Knight is now either a descendant of George I or "some other exalted personage"; the holder of the office has custody of the seal of the order and is responsible for enforcing the statutes.

The statutes also provide for the following:


Regular membership is limited to citizens of the United Kingdom and of other Commonwealth countries of which the Queen is Sovereign. Appointees are usually officers of the armed forces or senior civil servants, such as permanent secretaries.

Members appointed to the Civil Division must "by their personal services to [the] crown or by the performance of public duties have merited ... royal favour." Appointments to the Military Division are restricted by the minimum rank of the individual. GCBs hold the rank of Admiral in the Royal Navy, General in the British Army or Royal Marines, or Air Chief Marshal in the Royal Air Force. KCBs must at least hold the rank of vice admiral, lieutenant general in the Army or Marines, or Air Marshal. CBs tend be of the rank of Rear Admiral, Major General in the Army, Royal Navy or Royal Marines, or Air Vice Marshal in the Royal Air Force, and in addition must have been Mentioned in Despatches for distinction in a command position in a combat situation, although the latter is no longer a requirement. Non-line officers (e.g. engineers, medics) may be appointed only for meritorious service in wartime.

Commonwealth citizens not subjects of the Queen and foreigners may be made Honorary Members. Queen Elizabeth II has established the custom of awarding an honorary GCB to visiting (republican) heads of state, for example Gustav Heinemann and Josip Broz Tito (in 1972), Ronald Reagan (in 1989), Lech Wałęsa (in 1991), Censu Tabone, President of Malta, in 1992, Fernando Henrique Cardoso, George H. W. Bush (in 1993), Nicolas Sarkozy in March 2008, in 2012, former Indonesian President Susilo Bambang Yudhoyono. Turkish President Abdullah Gül, Slovenian President Dr Danilo Türk Mexican President Felipe Calderón, and South African President Jacob Zuma (Royal Heads of State are instead usually made Stranger Companions of the Order of the Garter). Foreign generals are also often given honorary appointments to the Order, for example: Marshal Ferdinand Foch and Marshal Joseph Joffre during World War I; Marshal Georgy Zhukov, King Abdul-Aziz of Saudi Arabia, General Dwight D. Eisenhower and General Douglas MacArthur during World War II; and General Norman Schwarzkopf and General Colin Powell after the Gulf War. A more controversial member of the Order was Robert Mugabe, whose honour was stripped by the Queen, on the advice of the Foreign Secretary, David Miliband, on 25 June 2008 "as a mark of revulsion at the abuse of human rights and abject disregard for the democratic process in Zimbabwe over which President Mugabe has presided."

Honorary members do not count towards the numerical limits in each class. In addition the statutes allow the Sovereign to exceed the limits in time of war or other exceptional circumstances.

The Order of the Bath now has six officers:

The office of Dean is held by the Dean of Westminster. The King of Arms, responsible for heraldry, is known as Bath King of Arms; he is not, however, a member of the College of Arms, like many heralds. The Order's Usher is known as the Gentleman Usher of the Scarlet Rod; he does not, unlike his Order of the Garter equivalent (the Gentleman Usher of the Black Rod) perform any duties in the House of Lords.

There were originally seven officers, each of whom was to receive fees from the Knights Companion both on appointment and annually thereafter. The office of Messenger was abolished in 1859. The office of Genealogist was abolished at the same time, but revived in 1913. The offices of Registrar and Secretary were formally merged in 1859, although the two positions had been held concurrently for the previous century. An Officer of Arms and a Secretary for the Knights Commander and Companions were established in 1815, but abolished in 1847. The office of Deputy Secretary was created in 1925.

Under the Hanoverian kings certain of the officers also held heraldic office. The office of Blanc Coursier Herald of Arms was attached to that of the Genealogist, Brunswick Herald of Arms to the Gentleman Usher, and Bath King of Arms was also made Gloucester King of Arms with heraldic jurisdiction over Wales. This was the result of a move by Anstis to give the holders of these sinecures greater security; the offices of the Order of the Bath were held at the pleasure of the Great Master, while appointments to the heraldic offices were made by the King under the Great Seal and were for life.

Members of the Order wear elaborate costumes on important occasions (such as its quadrennial installation ceremonies and coronations), which vary by rank:

The "mantle", worn only by Knights and Dames Grand Cross, is made of crimson satin lined with white taffeta. On the left side is a representation of the star (see below). The mantle is bound with two large tassels.

The "hat", worn only by Knights and Dames Grand Cross and Knights and Dames Commander, is made of black velvet; it includes an upright plume of feathers.

The "collar", worn only by Knights and Dames Grand Cross, is made of gold and weighs 30 troy ounces (933 g). It consists of depictions of nine imperial crowns and eight sets of flowers (roses for England, thistles for Scotland and shamrocks for Ireland), connected by seventeen silver knots.

On lesser occasions, simpler insignia are used:
The "star" is used only by Knights and Dames Grand Cross and Knights and Dames Commander. Its style varies by rank and division; it is worn pinned to the left breast:

The star for "military Knights and Dames Grand Cross" consists of a Maltese Cross on top of an eight-pointed silver star; the star for "military Knights and Dames Commander" is an eight-pointed silver cross pattée. Each bears in the centre three crowns surrounded by a red ring bearing the motto of the Order in gold letters. The circle is flanked by two laurel branches and is above a scroll bearing the words "Ich dien" (older German for "I serve") in gold letters.

The star for "civil Knights and Dames Grand Cross" consists of an eight-pointed silver star, "without" the Maltese cross; the star for "civil Knights and Dames Commander" is an eight-pointed silver cross pattée. The design of each is the same as the design of the military stars, except that the laurel branches and the words "Ich dien" are excluded.

The "badge" varies in design, size and manner of wearing by rank and division. The Knight and Dame Grand Cross' badge is larger than the Knight and Dame Commander's badge, which is in turn larger than the Companion's badge; however, these are all suspended on a crimson ribbon. Knights and Dames Grand Cross wear the badge on a riband or sash, passing from the right shoulder to the left hip. Knights Commander and male Companions wear the badge from a ribbon worn around the neck. Dames Commander and female Companions wear the badge from a bow on the left side:

The "military badge" is a gold Maltese Cross of eight points, enamelled in white. Each point of the cross is decorated by a small gold ball; each angle has a small figure of a lion. The centre of the cross bears three crowns on the obverse side, and a rose, a thistle and a shamrock, emanating from a sceptre on the reverse side. Both emblems are surrounded by a red circular ring bearing the motto of the Order, which are in turn flanked by two laurel branches, above a scroll bearing the words "Ich dien" in gold letters.

The "civil badge" is a plain gold oval, bearing three crowns on the obverse side, and a rose, a thistle and a shamrock, emanating from a sceptre on the reverse side; both emblems are surrounded by a ring bearing the motto of the Order.

On certain "collar days" designated by the Sovereign, members attending formal events may wear the Order's collar over their military uniform or eveningwear. When collars are worn (either on collar days or on formal occasions such as coronations), the badge is suspended from the collar.

The collars and badges of Knights and Dames Grand Cross are returned to the Central Chancery of the Orders of Knighthood upon the decease of their owners. All other insignia may be retained by their owners.

The Chapel of the Order is the Henry VII Lady Chapel in Westminster Abbey. Every four years, an installation ceremony, presided over by the Great Master, and a religious service are held in the Chapel; the Sovereign attends every alternate ceremony. The last such service was Thursday, 24 May 2018, in the Order's 293rd year, and was presided over by the Prince of Wales The Sovereign and each knight who has been installed is allotted a stall in the choir of the chapel.

As there are a limited number of stalls in the Chapel, only the most senior Knights and Dames Grand Cross are installed. A stall made vacant by the death of a military Knight Grand Cross is offered to the next most senior uninstalled military GCB, and similarly for vacancies among civil GCBs. Waits between admission to the Order and installation may be very long; for instance, Marshal of the Air Force Lord Craig of Radley was created a Knight Grand Cross in 1984, but was not installed until 2006.

Above each stall, the occupant's heraldic devices are displayed. Perched on the pinnacle of a knight's stall is his helm, decorated with a mantling and topped by his crest. Under English heraldic law, women other than monarchs do not bear helms or crests; instead, the coronet appropriate to the dame's rank (if she is a peer or member of the Royal family) is used.

Above the crest or coronet, the knight's or dame's heraldic banner is hung, emblazoned with his or her coat of arms. At a considerably smaller scale, to the back of the stall is affixed a piece of brass (a "stall plate") displaying its occupant's name, arms and date of admission into the Order.

Upon the death of a Knight, the banner, helm, mantling and crest (or coronet or crown) are taken down. The stall plates, however, are not removed; rather, they remain permanently affixed somewhere about the stall, so that the stalls of the chapel are festooned with a colourful record of the Order's Knights (and now Dames) throughout history.

When the grade of Knight Commander was established in 1815 the regulations specified that they too should have a banner and stall plate affixed in the chapel. This was never implemented (despite some of the KCBs paying the appropriate fees) primarily due to lack of space, although the 1847 statutes allow all three classes to request the erection of a plate in the chapel bearing the member's name, date of nomination, and (for the two higher classes) optionally the coat of arms.

Members of the Order of the Bath are assigned positions in the order of precedence. Wives of male members also feature on the order of precedence, as do sons, daughters and daughters-in-law of Knights Grand Cross and Knights Commander; relatives of female members, however, are not assigned any special precedence. Generally, individuals can derive precedence from their fathers or husbands, but not from their mothers or wives. (See order of precedence in England and Wales for the exact positions.)

Knights Grand Cross and Knights Commander prefix "Sir", and Dames Grand Cross and Dames Commander prefix "Dame", to their forenames. Wives of Knights may prefix "Lady" to their surnames, but no equivalent privilege exists for husbands of Dames. Such forms are not used by peers and princes, except when the names of the former are written out in their fullest forms. Furthermore, honorary foreign members and clergymen do not receive the accolade of knighthood, and so are not entitled to the prefix "Sir", unless the former subsequently become Commonwealth citizens.

Knights and Dames Grand Cross use the post-nominal "GCB"; Knights Commander use "KCB"; Dames Commander use "DCB"; Companions use "CB".

Knights and Dames Grand Cross are also entitled to receive heraldic supporters. Furthermore, they may encircle their arms with a depiction of the circlet (a red circle bearing the motto) with the badge pendant thereto and the collar; the former is shown either outside or on top of the latter.

Knights and Dames Commander and Companions may display the circlet, but not the collar, around their arms. The badge is depicted suspended from the collar or circlet. Members of the Military division may encompass the circlet with "two laurel branches issuant from an escrol azure inscribed "Ich dien"", as appears on the badge. Members of the Order of the Bath and their children are able to be married in Westminster Abbey in London.

It is possible for membership in the Order to be revoked. Under the 1725 statutes the grounds for this were heresy, high treason, or fleeing from battle out of cowardice. Knights Companion could in such cases be degraded at the next Chapter meeting. It was then the duty of the Gentleman Usher to "pluck down the escocheon [i.e. stallplate] of such knight and spurn it out of the chapel" with "all the usual marks of infamy".

Only two people were ever degraded – Lord Cochrane in 1813 and General Sir Eyre Coote in 1816, both for political reasons, rather than any of the grounds given in the statute. Lord Cochrane was subsequently reinstated, but Coote died a few years after his degradation.

Under Queen Victoria's 1847 statutes a member "convicted of treason, cowardice, felony, or any infamous crime derogatory to his honour as a knight or gentleman, or accused and does not submit to trial in a reasonable time, shall be degraded from the Order by a special ordinance signed by the sovereign". The Sovereign was to be the sole judge, and also had the power to restore such members.

The situation today is that membership may be cancelled or annulled, and the entry in the register erased, by an ordinance signed by the Sovereign and sealed with the seal of the Order, on the recommendation of the appropriate Minister. Such cancellations may be subsequently reversed.

In 1923 the Italian dictator Benito Mussolini was made an honorary Knight Grand Cross, by King George V. Mussolini was stripped of his GCB in 1940, after he had declared war on the UK.

William Pottinger, a senior civil servant, lost both his status of CB and Commander of the Royal Victorian Order (CVO) in 1975 when he was gaoled for corruptly receiving gifts from the architect John Poulson.

Romanian president Nicolae Ceauşescu was stripped of his honorary GCB status by Queen Elizabeth II on 24 December 1989, the day before his execution. Robert Mugabe, the President of Zimbabwe, was stripped of his honorary GCB status by the Queen, on the advice of the Foreign Secretary, David Miliband, on 25 June 2008 "as a mark of revulsion at the abuse of human rights and abject disregard for the democratic process in Zimbabwe over which President Mugabe has presided."

Vicky Pryce, former wife of Chris Huhne, was stripped of her CB by Queen Elizabeth II on 30 July 2013, following her conviction for perverting the course of justice.


For people who have been appointed to the Order of the Bath, see the following categories:

In his 1978 novel "Desolation Island," Patrick O'Brian wrote that Capt. Jack Aubrey had named to the Order of the Bath.




</doc>
<doc id="312641" url="https://en.wikipedia.org/wiki?curid=312641" title="Queen Elizabeth Way">
Queen Elizabeth Way

The Queen Elizabeth Way (QEW) is a 400-series highway in the Canadian province of Ontario linking Toronto with the Niagara Peninsula and Buffalo, New York. The freeway begins at the Peace Bridge in Fort Erie and travels around the western shore of Lake Ontario, ending at Highway 427. The physical highway, however, continues as the Gardiner Expressway into downtown Toronto. The QEW is one of Ontario's busiest highways, with an average of close to 200,000 vehicles per day on some sections. Major highway junctions are at Highway 420 in Niagara Falls, Highway 405 in Niagara-on-the-Lake, Highway 406 in St. Catharines, the Red Hill Valley Parkway in Hamilton, Highway 403 and Highway 407 in Burlington, Highway 403 at the Oakville–Mississauga boundary, and Highway 427 in Etobicoke. Within the Regional Municipality of Halton, between its two junctions with Highway 403, the QEW is signed concurrently with Highway 403.

The history of the QEW dates back to 1931, when work began to widen the Middle Road in a similar fashion to the nearby Dundas Highway and Lakeshore Road as a relief project during the Great Depression. Following the 1934 provincial election, Ontario Minister of Highways Thomas McQuesten and his deputy minister Robert Melville Smith changed the design to be similar to the autobahns of Germany, dividing the opposite directions of travel and using grade-separated interchanges at major crossroads. When opened to traffic in 1937, it was the first intercity divided highway in North America and featured the longest stretch of consistent illumination in the world. While not a true freeway at the time, it was gradually upgraded, widened, and modernized beginning in the 1950s, more or less taking on its current form by 1975. Since then, various projects have continued to widen the route. In 1997, the provincial government turned over the responsibility for the section of the QEW between Highway 427 and the Humber River to the City of Toronto. This section was subsequently redesignated as part of the Gardiner Expressway.
The Queen Elizabeth Way was named for the wife of King George VI who would later become known as Queen Elizabeth The Queen Mother. It is sometimes referred to as the Queen E.
In 1939, the royal couple toured Canada and the United States in part to bolster support for the United Kingdom in anticipation of war with Nazi Germany, and also to mark George VI's coronation. The highway received its name to commemorate the visit; it was unveiled on June 7 as the King and Queen ceremonially opened the highway at a site near the Henley Bridge in St. Catharines. Originally, the highway featured stylized light standards with the letters ""ER"", the Royal Cypher for "Elizabeth Regina", the Latin equivalent to "Queen Elizabeth." While mostly removed, they remain on three bridges along the highway: in Mississauga over the Credit River, in Oakville over Bronte Creek, and in St. Catharines over Twelve Mile Creek. A short section of Highway 420 in Niagara Falls and its extension, Falls Avenue, had replicas of these light standards installed in 2002.

The markers identifying the QEW have always used blue lettering on a yellow background instead of the black-on-white scheme other provincial highway markers use. They originally showed the highway's full name only in small letters, with the large script letters "ER" placed where the highway number is on other signs. In 1955, these were changed to the current design, with the lettering "QEW." Although the QEW has no posted highway number, it is considered to be part of the Province of Ontario's 400-series highway network.
The Ministry of Transportation of Ontario designates the QEW as Highway 451 for internal, administrative purposes.

A monument was originally in the highway median at the Toronto terminus of the highway, dedicated to the 1939 visit of King George VI and Queen Elizabeth and known as the "Lucky Lion." The column, with a crown at the top and a lion at the base, was designed by W. L. Somerville and sculptors Frances Loring and Florence Wyle for $12,000 (equivalent to $ in ). The monument was removed in 1972 in order to accommodate widening of the original QEW, and relocated in August 1975 to the nearby Sir Casimir Gzowski Park along Lake Ontario, on the east side of the Humber River.

The QEW is a route that travels from the Peace Bridge – which connects Fort Erie with Buffalo, New York – to Toronto, the economic hub of the province. The freeway circles the western lakehead of Lake Ontario, cutting through Niagara Falls, St. Catharines, Hamilton, Burlington, Oakville, and Mississauga en route. A portion of the freeway is signed concurrently with Highway 403. Unlike other provincial highways in Ontario, the QEW is directionally signed using locations along the route as opposed to cardinal directions. Driving towards Toronto, the route is signed as "QEW Toronto" throughout its length. In the opposing direction, it is signed as "QEW Hamilton," "QEW Niagara," and "QEW Fort Erie" depending on the location.

The Queen Elizabeth Way begins at the foot of the Peace Bridge, which crosses the United States border and connects with I-190 in Buffalo, New York. A customs booth is between the bridge and the freeway, beyond which a toll is charged to Canada-bound drivers. West of there, access is provided to nearby Highway 3 and the Niagara Parkway. Through customs, the freeway proper begins, immediately curving northwest. Within Fort Erie, interchanges provide access to and from the QEW at Central Avenue, Concession Road, Thompson Road, Gilmore Road, and Bowen Road. While there is some urban development at the beginning of the freeway, the majority of the first are within lowland forests. Numerous creeks flow through these forests, often flooding them. The Willoughby Marsh Conservation Area lies southwest of the freeway, approximately south of Niagara Falls. After an interchange with Lyons Creek Road, the freeway turns northward.

After crossing the Welland River, the original route of the Welland Canal, the freeway exits the forests and enters agricultural land surrounding the suburbs of Niagara Falls, which the highway enters north of the McLeod Road interchange. Within the city, Highway 420 meets the QEW at a large stack interchange, which replaced the former Lundy's Lane / Highway 20 interchange. Exiting the northern fringe of Niagara Falls, the freeway again curves northwest and begins to descend through the Niagara Escarpment, a World Biosphere Reserve. Highway 405 merges with the QEW along the short rural stretch between Niagara Falls and St. Catharines. While there is no Toronto-bound access to Highway 405, Niagara-bound drivers can follow this short freeway to the Lewiston–Queenston Bridge, which crosses the U.S. border into Lewiston, New York. The QEW continues west into St. Catharines.

As the Queen Elizabeth Way enters St. Catharines, it ascends the Garden City Skyway to cross the Welland Canal. This structure replaced the lift bridge south of it, one of two major bottlenecks prior to the early 1960s, and is one of two high-level skyways along the route. As the QEW was the first long distance freeway in North America, several modern engineering concepts were not considered, and further expansion of the highway is inhibited by the proximity of properties throughout most of its length. Consequently, most of the route beyond the Welland Canal is wedged between service roads which provide access to and from the QEW as well as to local businesses and residences. After passing the Ontario Street (Regional Road 42) interchange, the freeway crosses Martindale Pond, which forms the mouth of Twelve Mile Creek. West of the crossing is an interchange with Highway 406, which travels south to Welland, after which the QEW crosses out of St. Catharines and into the town of Lincoln at Fifteen Mile Creek.

Throughout Lincoln, the QEW travels along the Lake Ontario shoreline through the Niagara Fruit Belt; numerous wineries line the south side of the freeway. Interchanges at Victoria Road (Regional Road 24) and Ontario Street (Regional Road 18) provide access to the communities of Vineland and Beamsville, respectively. The latter encroaches upon the south side of the QEW, interrupting the otherwise agricultural surroundings of the highway in Lincoln. Immediately east of the Bartlett Avenue interchange, the freeway enters Grimsby, where it becomes sandwiched between the Niagara Escarpment and Lake Ontario. The route passes under three overpasses that have remained unchanged since the highway was built: Maple Avenue, Ontario Street, and Christie Street, all served by a single diamond interchange. South of the 50 Point Conservation Area, the freeway exits the Niagara Region and enters the city of Hamilton.

Within Hamilton, the highway passes almost entirely within an industrial park, with interchanges at 50 Road, Fruitland Road, and Centennial Parkway (formerly Highway 20). The third of these is intertwined with the Red Hill Valley Parkway interchange, completed in 2009. From here, the freeway curves northwest onto Burlington Beach and begins to ascend the Burlington Bay James N. Allan Skyway, the second high-level bridge along the route. As it crosses over the entrance to Hamilton Harbour, the freeway enters the Regional Municipality of Halton and descends into the city of Burlington.

After descending into Burlington, the QEW crosses former Highway 2 before it encounters the Freeman Interchange, opened in 1958 to allow construction of Highway 403 and expanded in 1999 to accommodate Highway 407. The freeway turns to the east, becoming concurrent with Highway 403 through Burlington and Oakville. The two routes travel straight though a commercial office area. Service roads reappear through this stretch to serve businesses fronting the highway. The segment includes high-occupancy vehicle lanes (HOV lanes), opened in 2011, which required the construction of a second structure over Sixteen Mile Creek. In the eastern end of Oakville, the route curves northeast, passing the Ford Motor Assembly Plant. Highway 403 then diverges north while the QEW turns back to the east, entering Mississauga and the Peel Region.

Within Mississauga, the freeway encounters its narrowest right-of-way, wedged between residential subdivisions on either side that prevent further expansion. It crosses the Credit River valley, where a second bridge is under construction. The segment east of the Credit River is being examined for expansion possibilities, but like the previous section, there is little room for more lanes without property acquisition. After crossing Etobicoke Creek, which forms the boundary between Mississauga / Peel Region and Toronto, the route terminates at a sprawling interchange with Highway 427. The QEW formerly continued beyond this interchange to the Old Toronto city limits at the Humber River; this section was downloaded from provincial to municipal ownership on April 1, 1997 and became part of the Gardiner Expressway.

As automobile use in southern Ontario grew in the early 20th century, road design and construction advanced significantly. A major issue faced by planners was the improvement of the routes connecting Toronto and Hamilton, which were consistently overburdened by the growing traffic levels.
Following frequent erosion of the former macadamized Lakeshore Road,
a cement road known as the "Toronto–Hamilton Highway" was proposed in January 1914.
The highway was designed to run along the lake shore, instead of Dundas Street to the north, because the numerous hills encountered along Dundas would have increased costs without improving accessibility. Middle Road, a dirt lane named because of its position between the two, was not considered since Lakeshore and Dundas were both overcrowded and in need of serious repairs. Construction began on November 8, 1914, but dragged on throughout the ongoing war. It was formally opened on November 24, 1917, wide and nearly long. It was the first concrete road in Ontario, as well as one of the longest stretches of concrete road between two cities in the world. Though many minor improvements in alignment were made, the original highway was without modern bridges for the crossings of the Credit River and Bronte, Etobicoke, and Mimico Creeks. Modern concrete arch bridges for all crossings except Bronte Creek were completed in 1919.

Over the next decade, vehicle usage increased substantially, and by 1920 Lakeshore Road was again highly congested on weekends.
In response, the Department of Highways examined improving another road between Toronto and Hamilton. The road was to be more than twice the width of Lakeshore Road at and would carry two lanes of traffic in either direction.
Construction on what was then known as the "Queen Street Extension" west of Toronto began in early 1931 as a Great Depression relief project.

Before the highway could be completed, Thomas McQuesten was appointed the new minister of the Department of Highways, with Robert Melville Smith as deputy minister, following the 1934 provincial elections.
Smith, inspired by the German autobahns—new "dual-lane divided highways"—modified the design for Ontario roads,
and McQuesten ordered that the Middle Road be converted into this new form of highway.
A right-of-way was purchased along the Middle Road and construction began to convert the existing sections to a divided highway. Work also began on Canada's first interchange at Highway 10.

By the end of 1937, the Middle Road was open between Toronto and Burlington, and would soon connect with what was first known as the "Hamilton–Niagara Falls Highway". When it opened, it was the first intercity divided highway in North America
and boasted the longest continuous stretch of illumination in the world until World War II.
It soon came time to name the new highway, and an upcoming visit by King George VI and Queen Elizabeth proved to be the focal point for a dedication ceremony. On June 7, 1939, the two royal family members drove along the highway (which now connected to Niagara Falls) and passed through a light beam near the Henley Bridge in St. Catharines. This caused two Union Jacks to swing out, revealing a sign which read "The Queen Elizabeth Way".

However, the ceremony only designated the highway between St. Catharines and Niagara Falls. The remainder of the road was known by various names, including the "Toronto–Burlington/Hamilton Highway" and "The New Middle Road Highway".

McQuesten also foresaw the financial opportunities that came with cross-border tourism and opening the "Ontario frontier" to Americans. In 1937, construction began on a new dual highway along the bottom of the Niagara Escarpment. This route was originally known as the New Niagara Falls Highway, but it was intended to connect with the Middle Road on the opposing shore of Lake Ontario. Work began at the end of March to grade the route between Stoney Creek and Jordan.
The prospect of removing hundreds of acres of farmland did not sit well with many, especially farmers in the path of the new highway. Rumours spread the prices paid for land were to be well below market value, and local protests erupted throughout the summer. However, the purpose of the new highway was to replace the congested, winding and hilly route of Highway 8 along the escarpment; several groups of collisions that summer gradually persuaded the public to support the new highway. By the autumn, of fruitland were cleared to make way for the route.

Over the next two years, numerous bridges and cloverleaf interchanges along the new highway were constructed. In addition, a large traffic circle was built in Stoney Creek to connect with Highway 20. The majority of this structural work was completed before the royal visit in 1939. However, despite being opened to traffic between Stoney Creek and Jordan, the majority of the new route was gravelled. Over a ten-week period in the late spring and early summer of 1940, were paved, completing the four-lane highway between Hamilton and Niagara Falls. On August 23, 1940, McQuesten cut a ribbon at the Henley Bridge in St. Catharines and officially declared the Queen Elizabeth Way open between Toronto and Niagara Falls. Construction towards Fort Erie continued, but the ongoing war delayed its completion. As an interim measure, the unpaved highway was opened during the summer of 1941. Two lanes of pavement were laid in 1946, but the four-lane highway was not fully paved until 1956. The completed QEW was officially opened on October 14 of that year, completing the envisioned highway 25 years after work had begun.

Despite some modern infrastructure, including traffic circles, interchanges, and some grade-separations, the majority of the new superhighway was not controlled-access. This meant existing farmers and homeowners along several segments that were once concession roads were permitted to build driveways and entrances onto the road. In addition, the majority of the crossroads encountered along the route were at-grade intersections. This, combined with the ever-increasing number of automobiles, traffic jams, accidents, and deteriorating pavement, led the Department of Highways to state it had begun "salvaging" the QEW in its 1953 annual report.

The first new interchange opened at Dixie Road in 1953, beginning a seven-year program to make the Hamilton–Toronto section into a full-fledged freeway.
Over the next three years, the route was improved west to Highway 10 (Hurontario Street). This work was completed in early 1956. Service roads were installed and 13 intersections eliminated, resulting in a 50% reduction of the accident rate along that section.
In Toronto, work began in 1955 to construct the Gardiner Expressway, which would tie in with the end of the QEW. The first section of the Gardiner, connecting the QEW to Jameson Avenue, was officially opened by Mayor Fred Gardiner and Premier Leslie Frost on August 8, 1958.
Work was also underway on the Toronto Bypass, involving the upgrade of Highway 27 to a freeway between the QEW and the new Highway 401. Construction began in 1953,
and included an upgrade of the cloverleaf interchange with the QEW with larger loop ramps. This interchange would become one of the worst bottlenecks in the province a decade after its completion, according to Highways Minister Charles MacNaughton.
On September 11, 1957, construction began to widen the QEW to six lanes between Highway 27 and the Humber River. It was completed by December 1958,
as were interchanges with Mississauga Road and Kerr Street.
Service roads allowed engineers to separate local access from the highway and avoid space-consuming interchanges in many places. Therefore, interchanges were only opened at Bronte Road (then Highway 25), Kerr Street, Royal Windsor Drive (then Highway 122), Southdown Road (now Erin Mills Parkway north of the interchange), Mississauga Road, Hurontario Street (then Highway 10), Cawthra Road, Dixie Road, and Highway 27.

Two major projects were ongoing near Burlington at this point. On April 29, 1952, the "W.E. Fitzgerald" struck the two-lane lift bridge at the entrance to Hamilton Harbour.
Damage to the crossing resulted in the QEW's closure until a temporary bridge was erected. To remedy what was becoming a major delay and hazard, the Department of Highways began planning a high-level bridge to cross the shipping channel. Construction also began on the "Freeman Diversion" interchange to provide better access to this new structure as well as the proposed Chedoke Expressway, bypassing the old trumpet interchange and creating a new three-level stack. Work on both proceeded over the next six years.
The Freeman Diversion opened to traffic in August 1958,
with the old route becoming an eastward extension of Plains Road.
Premier Frost opened the , four-lane skyway two months later on October 30. Although it greatly reduced traffic delays, it was not without controversy due to its height, cost, tolling, and most especially its name. Residents in Burlington demanded it be named the Burlington Skyway, while Hamilton residents countered with the Hamilton Skyway. As a compromise, the Thomas B. McQuesten Skyway was proposed. However, the provincial government had the final say in the matter, and opted to name it the Burlington Bay Skyway. Tolls were collected beginning on November 10.

Elsewhere, in St. Catharines, planning was already advanced on a second skyway to cross the Welland Canal. The Homer Lift Bridge, a longstanding feature along Highway 8, was another point where the QEW narrowed to two lanes and traffic faced regular delays. Construction of the Homer Skyway, as it was tentatively known, began in July 1960 and progressed over the following three years. The $20 million (in 1963, $ adjusted for inflation) structure was officially opened by Premier John Robarts on November 15, 1963. However, traffic had already been flowing on the bridge since October 18.
As with the Burlington Bay Skyway, tolls were collected on the new bridge. However, the name was almost unanimously chosen by St. Catharines residents to be the Garden City Skyway. The collection of tolls on both skyways continued until December 28, 1973.

On September 15, 1960, the Shook's Hill interchange, a unique rotary junction, was completed at what is now Erin Mills Parkway. It was opened to traffic the following day, and completed the program to make the QEW a freeway between Burlington and Toronto.
A final project, to reconstruct the intersection with Brant Street into an interchange, was carried out in 1964 and made the QEW a freeway between Hamilton and Toronto.

By 1963, work was underway to improve the Niagara Falls–Hamilton stretch of the QEW into a controlled-access highway.
At the end of 1966, the QEW was six lanes wide through Mississauga and Toronto, as well as between the Freeman Interchange and east of Brant Street.
This six-laning was extended west from Ninth Line to Kerr Street by 1968. The remaining section of four-lane highway along the Burlington to Toronto stretch, between Brant Street and Kerr Street, was reconstructed beginning in 1970 and completed by 1972.

The late 1960s and early 1970s also saw the complete reconstruction of three important interchanges: the Rainbow Bridge Approach (later Highway 420) in Niagara Falls, Highway 20 (Centennial Parkway) in Hamilton, and Highway 27 in Toronto. The former two were traffic circles in place since the QEW was opened in 1940; the third was a large cloverleaf interchange that had become outdated with the expansion of Highway 27 to ten lanes throughout the 1960s. The connections with the Rainbow Bridge Approach and with Highway 27 required new massive high-speed interchanges to accommodate freeway-to-freeway traffic movements.
The junction with Highway 27 was built over and required the construction of 19 bridges and the equivalent of of two-lane roadway. Construction began in September 1968, although preliminary work had been ongoing since 1966;
the interchange opened to traffic on November 14, 1969, and included an expansion of the QEW to ten lanes between what would become known as Highway 427 and Lake Shore Boulevard.
Construction of the three-level stack interchange between the QEW and Rainbow Bridge Approach began in 1971, removing the two traffic circles along the approach at the QEW and Dorchester Road.
The interchange between the QEW and Lundy's Lane (Highway 20) was also removed; instead, the new stack interchange provided access to Montrose Road.
The work was completed by April 1972, at which point the Rainbow Bridge Approach was designated as Highway 420.
Planning for the removal of the Stoney Creek traffic circle was completed by 1970, and reconstruction began in 1974.
This involved the removal of a rail line which crossed through the circle, and was the demise of one of two major features along the route. The new interchange opened in 1978,
completing the transformation of the QEW into a controlled-access highway.

During the late 1970s, construction was carried out on several new interchanges between Hamilton and Toronto. A new interchange at Dorval Drive and Trafalgar Road replaced the one at Kerr Street. In Mississauga, work commenced at Cawthra Road, while in Burlington a new interchange was built at Appleby Line.

Now functioning as a freeway, the QEW was already overburdened by the ever-increasing number of vehicles. The Burlington Bay Skyway, the lone four-lane link on the route between Hamilton and Toronto, was initially designed to handle 50,000 vehicles daily, but by 1973 there were 60,000 vehicles crossing it. Preliminary work on a second parallel structure began a decade later in 1983. In July of that year, Transportation Minister James Snow broke ground for the new bridge. Construction was carried out over two years, and the twinned structure was opened on October 11, 1985. It was named the James N. Allan Skyway, in honour of James Allan, Minister of Highways during construction of the original skyway. The new name was not well received by locals, and debate erupted once again whilst the original bridge was closed and repaired for several years. It reopened on August 22, 1988, with Toronto-bound traffic crossing the original bridge. The twin structure was renamed the Burlington Bay James N. Allan Skyway, though it is commonly referred to as simply the Burlington Skyway.

Alongside the twinning of the skyway, the QEW was widened to eight lanes between Burlington Street in Hamilton and Northshore Boulevard (then Highway 2) in Burlington, and to six lanes north to the Freeman Interchange and south to Centennial Parkway. A variable lighting system, changeable message signs and traffic cameras were added to create a new traffic-management system called COMPASS. Modern interchanges were constructed with Burlington Street, Northshore Boulevard, Fairview Street and Brant Street, and the interchange with Plains Road was removed. Eastport Drive was built at the same time to relieve traffic on Beach Boulevard. This work was completed between late 1984 and 1990.
With the expanded capacity of the skyway, and the unanticipated traffic volumes on Highway 403, the Freeman Interchange was now faced with a capacity problem. To resolve this, the renamed Ministry of Transportation began planning on Highway 403 between Burlington and Mississauga;
this right-of-way would be sold to the 407 ETR consortium in 1995 and built as part of that route.
Work began in August 1991 to rebuild the interchange and add a fourth leg. The rebuilt interchange was opened on October 23, 1993; the first sod for what would open as Highway 407 was turned that day.

Budgetary restraints in the 1990s forced the provincial government to sell off or download many highways to lower levels of government, or, in the case of Highway 407, to a private consortium.
As part of recommendations, the QEW east of Highway 427 to the Humber River was transferred to the responsibility of the City of Toronto. The transfer took place on April 1, 1997.
The city subsequently renamed it as part of the Gardiner Expressway.

Beginning in May 1999, the grade-separated traffic circle junction with Erin Mills Parkway and Southdown Road, which dated back to the early 1960s, was completely reconstructed as a standard parclo A4 interchange; it was reopened in 2001.
The nearby Hurontario Street interchange was upgraded from a cloverleaf to a parclo A4 on the south side and a diamond interchange on the north side. Work was completed in 2010.

The Red Hill Valley Parkway project, which opened on November 16, 2007, added a significant new interchange to the QEW.
The ramp to the southbound parkway did not open until December 2008.
As part of this project, the Burlington Street and Centennial Parkway interchanges were reconstructed, and the QEW widened to eight lanes from Burlington Street to Centennial Parkway. Construction was completed in 2009.

The highway was widened to permit an additional HOV lane in either direction between Guelph Line and Trafalgar Road starting in 2007. These lanes were opened to traffic on November 29, 2010.
In 2005,
work began to widen the QEW through St. Catharines from Highway 406 to the Garden City Skyway. This work was completed on August 26, 2011, at a cost of $186 million.

On December 7, 2015, Ontario's Transportation Ministry announced it was working on a plan to create permanent high-occupancy toll lanes (HOT) on a stretch, in both ways, between Trafalgar Road in Oakville and Guelph Line in Burlington starting on September 15, 2016. This would require vehicles with a single occupant to purchase a permit for such use. (A portion of Highway 427 would also have HOT lanes.) Vehicles classified as environmentally-friendly and denoted with a green license plate would not be required to pay when using the HOT lanes. Prices for the permits had not yet been determined for this plan, described as a pilot project, said Transportation Minister Steven Del Duca during a press conference.

The following table lists the exits along the QEW. Exits are numbered from Fort Erie to Toronto.

!scope="col"|Division
!scope="col"|Location
!scope="col"|km
!scope="col"|mi
!scope="col"|Exit
!scope="col"|Destinations
!scope="col"|Notes

As the principal travel route between Toronto and Buffalo, whenever sports teams from the two cities face each other (particularly the Sabres and Maple Leafs in the National Hockey League) the game or series is called as .




</doc>
<doc id="313380" url="https://en.wikipedia.org/wiki?curid=313380" title="William Sterndale Bennett">
William Sterndale Bennett

Sir William Sterndale Bennett (13 April 18161 February 1875) was an English composer, pianist, conductor and music educator. At the age of ten Bennett was admitted to the London Royal Academy of Music (RAM), where he remained for ten years. By the age of twenty, he had begun to make a reputation as a concert pianist, and his compositions received high praise. Among those impressed by Bennett was the German composer Felix Mendelssohn, who invited him to Leipzig. There Bennett became friendly with Robert Schumann, who shared Mendelssohn's admiration for his compositions. Bennett spent three winters composing and performing in Leipzig.

In 1837 Bennett began to teach at the RAM, with which he was associated for most of the rest of his life. For twenty years he taught there, later also teaching at Queen's College, London. Amongst his pupils during this period were Arthur Sullivan, Hubert Parry, and Tobias Matthay. Throughout the 1840s and 1850s he composed little, although he performed as a pianist and directed the Philharmonic Society for ten years. He also actively promoted concerts of chamber music. From 1848 onwards his career was punctuated by antagonism between himself and the conductor Michael Costa.

In 1858 Bennett returned to composition, but his later works, though popular, were considered old-fashioned and did not arouse as much critical enthusiasm as his youthful compositions had done. He was Professor of Music at the University of Cambridge from 1856 until 1875. In 1866 he became Principal of the RAM, rescuing it from closure, and remained in this position until his death. He was knighted in 1871. He died in London in 1875 and was buried in Westminster Abbey.

Bennett had a significant influence on English music, not solely as a composer but also as a teacher, as a promoter of standards of musical education and as an important figure in London concert life. In recent years, appreciation of Bennett's compositions has been rekindled and a number of his works, including a symphony, his piano concerti, some vocal music and many of his piano compositions, have been recorded. In his bicentenary year of 2016, several concerts of his music and other related events took place.

Bennett was born in Sheffield, Yorkshire, the third child and only son of Robert Bennett, the organist of Sheffield parish church, and his wife Elizabeth, "née" Donn. In addition to his duties as an organist, Robert Bennett was a conductor, composer and piano teacher; he named his son after his friend William Sterndale, some of whose poems the elder Bennett had set to music. His mother died in 1818, aged 27, and his father, after remarrying, died in 1819. Thus orphaned at the age of three, Bennett was brought up in Cambridge by his paternal grandfather, John Bennett, from whom he received his first musical education. John Bennett was a professional bass, who sang as a lay clerk in the choirs of King's, St John's and Trinity colleges. The young Bennett entered the choir of King's College Chapel in February 1824 where he remained for two years. In 1826, at the age of ten, he was accepted into the Royal Academy of Music (RAM), which had been founded in 1822. The examiners were so impressed by the child's talent that they waived all fees for his tuition and board.

Bennett was a pupil at the RAM for the next ten years. At his grandfather's wish his principal instrumental studies were at first as a violinist, under Paolo Spagnoletti and later Antonio James Oury. He also studied the piano under W. H. Holmes, and after five years, with his grandfather's agreement, he took the piano as his principal study. He was a shy youth and was diffident about his skill in composition, which he studied under the principal of the RAM, William Crotch, and then under Cipriani Potter, who took over as principal in 1832. Amongst the friends Bennett made at the Academy was the future music critic J. W. Davison. Bennett did not study singing, but when the RAM mounted a student production of "The Marriage of Figaro" in 1830, Bennett, aged fourteen, was cast in the mezzo-soprano role of the page boy Cherubino (usually played by a woman "en travesti"). This was among the few failures of his career at the RAM. "The Observer" wryly commented, "of the page... we will not speak", but acknowledged that Bennett sang pleasingly and to the satisfaction of the audience. "The Harmonicon", however, called his performance "in every way a blot on the piece".

Among Bennett's student compositions were a piano concerto (No. 1 in D minor, Op. 1), a symphony and an overture to "The Tempest". The concerto received its public premiere at an orchestral concert in Cambridge on 28 November 1832, with Bennett as soloist. Performances soon followed in London and, by royal command, at Windsor Castle, where Bennett played in April 1833 for King William IV and Queen Adelaide. The RAM published the concerto at its own expense as a tribute. A further London performance was given in June 1833. The critic of "The Harmonicon" wrote of this concert:
[T]he most complete and gratifying performance was that of young Bennett, whose composition would have conferred honour on any established master, and his execution of it was really surprising, not merely for its correctness and brilliancy, but for the feeling he manifested, which, if he proceed as he has begun, must in a few years place him very high in his profession.
In the audience was Felix Mendelssohn, who was sufficiently impressed to invite Bennett to the Lower Rhenish Music Festival in Düsseldorf. Bennett asked, "May I come to be your pupil?" Mendelssohn replied, "No, no. You must come to be my friend".

In 1834 Bennett was appointed organist of St Ann's, Wandsworth, London, a chapel of ease to Wandsworth parish church. He held the post for a year, after which he taught private students in central London and at schools in Edmonton and Hendon. Although by common consent the RAM had little more to teach him after his seventh or eighth year, he was permitted to remain as a free boarder there until 1836, which suited him well, as his income was small. In May 1835 Bennett made his first appearance at the Philharmonic Society of London, playing the premiere of his Second Piano Concerto (in E-flat major, Op. 4), and in the following year he gave there the premiere of his Third Concerto (in C minor, Op. 9). Bennett was also a member of the Society of British Musicians, founded in 1834 to promote specifically British musicians and compositions. Davison wrote in 1834 that Bennett's overture named for Lord Byron's "Parisina" was "the best thing that has been played at the Society's concerts".

In May 1836 Bennett travelled to Düsseldorf in the company of Davison to attend the Lower Rhenish Music Festival for the first performance of Mendelssohn's oratorio "St Paul". Bennett's visit was enabled by a subsidy by the piano-making firm of John Broadwood & Sons. Inspired by his journey up the Rhine, Bennett began work on his overture "The Naiads" (Op. 15). After Bennett left for home, Mendelssohn wrote to their mutual friend, the English organist and composer Thomas Attwood, "I think him the most promising young musician I know, not only in your country but also here, and I am convinced if he does not become a very great musician, it is not God's will, but his own".

After Bennett's first visit to Germany there followed three extended visits to work in Leipzig. He was there from October 1836 to June 1837, during which time he made his debut at the Gewandhaus as the soloist in his Third Piano Concerto with Mendelssohn conducting. He later conducted his "Naiads" overture. During this visit he also arranged the first cricket match ever played in Germany, ("as fitting a Yorkshireman" as the musicologist Percy M. Young comments). At this time Bennett wrote to Davison:[Mendelssohn] took me to his house and gave me the printed score of [his overture] 'Melusina', and afterwards we supped at the 'Hôtel de Bavière', where all the musical clique feed ... The party consist[ed] of Mendelssohn, [Ferdinand] David, Stamity [sic] ... and a Mr. Schumann, a musical editor, who expected to see me a "fat" man with "large black whiskers." 

Bennett had been at first slightly in awe of Mendelssohn, but no such formality ever attached to Bennett's friendship with Robert Schumann, with whom he went on long country walks by day and visited the local taverns by night. Each dedicated a large-scale piano work to the other: in August 1837 Schumann dedicated his "Symphonic Studies" to Bennett, who reciprocated the dedication a few weeks later with his "Fantasie", Op. 16. Schumann was eloquently enthusiastic about Bennett's music; in 1837 he devoted an essay to Bennett in the "Neue Zeitschrift für Musik", praising amongst other works Bennett's Op. 10 "Musical Sketches" for piano, "three of Bennett's loveliest pictures". The essay ends: "For some time now he has been peering over my shoulder, and for the second time he has asked 'But what are you writing?' Dear friend, I shall write no more than: 'If only you knew!'" Bennett however had from the outset some reservations about Schumann's music, which, he told Davison in 1837, he thought "rather too eccentric".

On Bennett's return to London he took up a teaching post at the RAM which he held until 1858. During his second long stay in Germany, from October 1838 to March 1839, he played his Fourth Piano Concerto (Op. 19, in F minor) and the "Wood Nymphs" Overture, Op. 20. Returning to England, he wrote to his Leipzig publisher Friedrich Kistner in 1840, bemoaning the difference between England and Germany (and hoping that a German would redress the situation): You know what a dreadful place England is for music; and in London I have nobody who I can talk to about such things, all the people are mad with [Sigismond] Thalberg and [Johann] Strauss [I], and I have not heard a single Symphony or Overture in one concert since last June. I sincerely hope that Prince Albert ... will do something to improve our taste.

On Bennett's third trip, from January to March 1842, in which he also visited Kassel, Dresden and Berlin, he played his "Caprice" for piano and orchestra, Op. 22, in Leipzig. Despite his then-pessimistic view of music in England, Bennett missed his chance to establish himself in Germany. The musicologist Nicholas Temperley writes One might guess that the early loss of both parents produced in Bennett an exceptionally intense need for reassurance and encouragement. England could not provide this for a native composer in his time. He found it temporarily in German musical circles; yet, when the opportunity came to claim his earned place as a leader in German music, he was not quite bold enough to grasp it.

Bennett returned to London in March 1842, and continued his teaching at the RAM. The next year the post of professor of music at the University of Edinburgh became vacant. With Mendelssohn's strong encouragement Bennett applied for the position. Mendelssohn wrote to the principal of the university, "I beg you to use your powerful influence on behalf of that candidate whom I consider in every respect worthy of the place, a true ornament to his art and his country, and indeed one of the best and most highly gifted musicians now living: Mr. Sterndale Bennett." Despite this advocacy Bennett's application was unsuccessful.

Bennett had been impressed in Leipzig with the concept of chamber music concerts, which had been, apart from string quartet recitals, a rarity in London. He began in 1843 a series of such concerts including piano trios of Louis Spohr and Ludwig van Beethoven, works for piano solo, and string sonatas by Mendelssohn and others. Amongst those taking part in these recitals were the piano virtuoso Alexander Dreyschock and Frédéric Chopin's pupil, the 13-year old Carl Filtsch.

In 1844 Bennett married Mary Anne Wood (1824–1862), the daughter of a naval commander. Composition gave way to a ceaseless round of teaching and musical administration. The writer and composer Geoffrey Bush sees the marriage as marking a break in Bennett's career; "from 1844 to 1856 [Bennett] was a freelance teacher, conductor and concert organiser; a very occasional pianist and a still more occasional composer." Clara Schumann noted that Bennett spent too much time giving private lessons to keep up with changing trends in music: "His only chance of learning new music is in the carriage on the way from one lesson to another."

From 1842 Bennett had been a director of the Philharmonic Society of London. He helped to relieve the society's perilous finances by persuading Mendelssohn and Spohr to perform with the Society's orchestra, attracting full houses and much-needed income. In 1842 the orchestra, under the composer's baton, gave the London premiere of Mendelssohn's Third ("Scottish") Symphony, two months after its world premiere in Leipzig. In 1844 Mendelssohn conducted the last six concerts of the society's season, in which among his own works and those of many others he included music by Bennett. From 1846 to 1854 the Society's conductor was Michael Costa, of whom Bennett disapproved; Costa was too devoted to Italian opera and not a partisan of the German masters, as was Bennett. Bennett wrote to Mendelssohn on 24 July, displaying some querulousness, "The Philharmonic Directors have engaged Costa ... with which I am not very well pleased, but I could not persuade them to the contrary, and am tired of quarrelling with them. They are a worse set this year than we have ever had."

In May 1848, on the opening of Queen's College, London, Bennett, as one of the Founding Directors, delivered an inaugural lecture and joined the staff, while continuing his work at the RAM and private teaching. He wrote the thirty "Preludes and Lessons", Op. 33, for his piano students at the college; they were published in 1853 and remained in widespread use by music students well into the twentieth century. In a profile of Bennett published in 1903 F. G. Edwards noted that Bennett's duties as a teacher severely reduced his opportunity to compose, although he maintained his reputation as a soloist in annual chamber music and piano recitals at the Hanover Square Rooms, which included chamber music and concerti by Johann Sebastian Bach and Beethoven's "An die ferne Geliebte", "then almost novelties". Over the years he gave over forty concerts at this venue, and amongst those who took part were the violinists Henri Vieuxtemps and Heinrich Ernst, the pianists Stephen Heller, Ignaz Moscheles and Clara Schumann, and the cellist Carlo Piatti (for whom Bennett wrote his Sonata Duo); composers represented included—apart from Bennett's favourite classical masters and Mendelssohn—Domenico Scarlatti, Fanny Mendelssohn and Schumann.

As well as the demands of his work as a teacher and pianist, there were other factors that may have contributed to Bennett's long withdrawal from large-scale composition. Charles Villiers Stanford writes that the death of Mendelssohn in 1847 came to Bennett as "an irreparable loss". In the following year Bennett severed his hitherto close ties with the Philharmonic Society, which had presented many of his most successful compositions. This break resulted from an initially minor disagreement with Costa over his interpretation at the final rehearsal of Bennett's overture "Parisina". The intransigence of both parties inflated this into a furious row, and began a breach between them which was to last throughout Bennett's career. Bennett was disgusted at the Society's failure to back him up, and resigned.

From this point in his life Bennett was ever increasingly involved in the burdens of musical organization. In the opinion of Percy Young, he became "the prototype of the modern administrative musician ... he eventually built for himself an impregnable position, but in doing so destroyed his once considerable creative talent." Bennett became a victim as well as a beneficiary of a trend towards professionalization in the music industry in Britain; "The Principal and the Professor became powerful, whereas the status of the composer and the executant (unless foreign) was implicitly downgraded."

In 1849 Bennett became the founding president of the Bach Society in London, whose early members included Sir George Smart, John Pyke Hullah, William Horsley, Potter and Davison. Under his direction the Society gave the first English performance of Bach's "St Matthew Passion" on 6 April 1854. Further performances of the "Passion" were given by the Society in 1858 and 1862, the latter coinciding with the publication of Bennett's own edition of the work, with a translation of the text into English by his pupil Helen Johnston.

For the 1851 Great Exhibition Bennett was appointed a Metropolitan Local Commissioner, Musical Juror and superintendent for the music at the opening Royal ceremony.

In June 1853 Bennett made his last public appearance as a soloist with orchestra in his own Fourth Piano Concerto. This performance was given with a new organization, the Orchestral Union, and followed a snub from Costa, who had refused to conduct the pianist Arabella Goddard (Davison's wife) in Bennett's Third Concerto at the Philharmonic Society. In the same year Bennett declined an invitation to become the conductor of the Leipzig Gewandhaus Orchestra. He was greatly tempted by the offer, but felt it his duty to remain in England, as the offer came too late for Bennett to make alternative arrangements for some of his pupils, and he refused to let them down. After the controversial 1855 season of the Philharmonic Society at which Richard Wagner conducted, Bennett was elected to take over the conductorship in 1856, a post which he held for ten years. At his first concert, on 14 April 1856, the piano soloist in Beethoven's "Emperor" Concerto was Clara Schumann, wife of his old friend. It was her first appearance in England.

Bennett's stewardship of the Philharmonic Society orchestra was not entirely happy, and the historian of the orchestra, Cyril Ehrlich, notes "a sense of drift and decline". Many leading members of the orchestra were also in the orchestra of the Italian Opera House in London (and therefore partisans of the displaced Costa), and, in addition, Bennett proved unable to resolve personal animosities amongst his leading players. Costa took to arranging schedules for his musicians which made rehearsals (and sometimes performances) for the Society impractical. This gave an "impression that [Bennett] was capable of exerting only waning authority amongst professionals". Moreover, comparing London with other centres around the mid-century, Ehrlich notes "Verdi was in Milan, Wagner in Dresden, Meyerbeer in Paris, Brahms in Vienna, and Liszt in Weimar. London had the richest of audiences, and was offered Sterndale Bennett." He instances the London premiere of Schumann's "Paradise and the Peri" in the 1856 season, which, by engaging Jenny Lind as soloist, and with Prince Albert in the audience, brought in a substantial subscription, but was musically disastrous (and was not helped by the chaos of a seriously overcrowded venue). One member of the audience thought Lind's voice was "worn and strained" and that there would have been "vehement demonstrations of derision had not the audience been restrained in the presence of Royalty". Newspaper critics were scarcely more complimentary.

Temperley writes: "After 1855 [Bennett] was spurred by belated honours, and occasional commissions, to compose a respectable number of significant and substantial works, though it was too late to recapture his early self-confidence." Works from his later years included the cello Sonata Duo for Piatti; a pastoral cantata, "The May Queen", Op. 39, for the opening of the Leeds Town Hall in 1858; an Ode (Op. 40) with words by Alfred, Lord Tennyson for the opening of the 1862 International Exhibition in London; an "Installation Ode for Cambridge University" (Op. 41) with words by Charles Kingsley, which included a lament for the late Prince Albert; a symphony in G minor (Op. 43); a sacred cantata,"The Woman of Samaria" for the Birmingham Triennial Music Festival of 1867; and finally a second Piano Sonata ("The Maid of Orleans", Op. 46). Many of these works were composed during his summer holidays which were spent at Eastbourne. The Ode for the Exhibition was the cause of a further imbroglio with Costa, who although in charge of music for the Exhibition refused to conduct anything by Bennett. Eventually it was conducted by Prosper Sainton, between works by Meyerbeer and Daniel Auber also commissioned for the occasion. The affair leaked into the press, and Costa was widely condemned for his behaviour.

In March 1856 Bennett, while still teaching at the RAM and Queen's College, was elected Professor of Music at the University of Cambridge. He modernised the system of awarding music degrees, instituting "viva voce" examinations and requiring candidates for doctorates to first take the degree of Bachelor of Music. Two years later on 8 June 1868 the newly formed (later Royal) College of Organists awarded him an Honorary Fellowship.

In 1858 came yet another clash involving Costa, when the autocratic Earl of Westmorland, the original founder of the RAM, saw fit to arrange a subscription concert for the Academy to include a Mass of his own composition, to be conducted by Costa and using the orchestra and singers of the Opera, over the heads of the Academy directors. Bennett resigned from the RAM at this overbearing behaviour, and was not to return until 1866. Towards the end of 1862 Bennett's wife died after a painful illness. His biographer W. B. Squire suggests that "he never recovered from the effects of Mrs. Bennett's death, and that henceforward a painful change in him became apparent to his friends." In 1865 Bennett again visited Leipzig where he was reunited with old friends including Ferdinand David, and his Op. 43 Symphony was performed.

In 1866 Charles Lucas, the Principal of the RAM, announced his retirement. The position was first offered to Costa, who demanded a higher salary than the directors of the RAM could contemplate, and then to Otto Goldschmidt, who was then professor of piano at the RAM. He declined and urged the directors to appoint Bennett. Lind, who was Goldschmidt's wife, wrote that Bennett "is certainly the only man in England who ought to raise that institution from its present decay".

Bennett was to find that heading a leading music college was incompatible with a career as a composer. The post of Principal was traditionally not arduous. He was contractually required to attend for only six hours a week, teaching composition and arranging class-lists. But Bennett had not only to run the RAM but to save it from imminent dissolution. The RAM had been temporarily saved from bankruptcy by grants from the government, authorised by Gladstone as Chancellor of the Exchequer, in 1864 and 1865. The following year Gladstone was out of office, and the new Chancellor, Disraeli, refused to renew the grant. The directors of the RAM decided to close it, over the head of Bennett as Principal. Bennett, with the support of the faculty and the students, assumed the Chairmanship of the board of directors.

In Stanford's words, "As Chairman he succeeded, after the Government had withdrawn its annual grant, in winning it back, restored the financial credit of the house, and during seven years bore the harassing anxiety of complex negotiations with various public bodies of great influence who were discussing schemes for the advance of national musical education." The schemes referred to were two proposals which would have undoubtedly undermined the viability and influence of the RAM, one to merge it in a proposed National School of Music, backed by the Royal Society of Arts under Henry Cole, the other to relocate it (without security of tenure) in the premises of the Royal Albert Hall.

The RAM in 1866 was in poor shape in terms of influence and reputation as well as financially. The critic Henry Chorley published data in that year showing that only 17 per cent of orchestral players in Britain had studied there. No alumni of the RAM were members of the orchestra at Covent Garden opera house. Chorley added, "I cannot remember one great instrumental player the Academy has turned out during the last 25 years." Bennett himself was not entirely in accord with the emphasis Chorley placed on instrumental training for the RAM; he was concerned (and with reason) that such a policy could mean supply oustripping demand for graduates. Bennett himself taught composition at the RAM; this was undoubtedly where his greatest interests lay at this period, and it appears that the examples he gave to his pupils concentrated on his own 'conservative' favourites of Mendelssohn, Beethoven and Mozart. Nonetheless, the reputation and popularity of the RAM increased markedly under his stewardship. The number of pupils, which had dropped catastrophically at the time when the directors had proposed closing the institution, rose steadily. At the end of 1868 there had been 66 students. By 1870 the number was 121, and by 1872 it was 176.

Bennett received honorary degrees from the universities of Cambridge (1867) and Oxford (1870). The Philharmonic Society awarded him its Beethoven gold medal in 1867. In 1871 he was knighted by Queen Victoria (two years after his old antagonist Costa had been accorded the same honour), and in 1872 he received a public testimonial before a large audience at St James's Hall, London. The money subscribed at this event founded a scholarship and prize at the RAM, which is still awarded. An English Heritage blue plaque has been placed at the house in 38 Queensborough Terrace, London, where Bennett lived during many of his later years.

Bennett died aged 58 on 1 February 1875 at his house in St John's Wood, London. According to his son the cause was "disease of the brain"; unable to rise one morning, he had fallen into a decline and died within a week. He was buried on 6 February, close to the tomb of Henry Purcell, in Westminster Abbey. The a cappella quartet, "God is a Spirit", from his cantata "The Woman of Samaria", was sung to accompany the obsequies. The first concert of the Philharmonic Society's season, on 18 March, began with a tribute to its sometime conductor: pieces from his unfinished music for Sophocles's tragedy "Ajax", and the complete "The Woman of Samaria", for which the choir was provided by the RAM. These were followed by Mendelssohn's Violin Concerto, for which the soloist was Joseph Joachim, to whom Mendelssohn had introduced Bennett at Joachim's London debut in 1844. The final concert of the season (5 July) included an "Idyll" in memory of Bennett composed by his old associate George Alexander Macfarren.

Bennett's son James Robert Sterndale Bennett (1847–1928) wrote a biography of his father. Many of the composer's descendants became musicians or performers, including his grandsons Robert (1880–1963), director of music at Uppingham School, Rutland; Tom (T.C.) (1882–1944), composer and singer, whose daughter Joan Sterndale-Bennett (1914–1996) was a well known West End actress; and Ernest Sterndale Bennett (1884–1982), a theatre director in Canada. and Charlie Simpson b.1985, of Busted and Fightstar.

Stanford wrote of Bennett: He maintained his British characteristics throughout his life ...The English take a kind of pride in concealing their feelings and emotions, and this is reflected in their folk-song. The Thames has no rapids and no falls; it winds along under its woods in a gentle stream, never dry and never halting; it is the type of the spirit of English folkmusic ... England is as remote from Keltic fire and agony, as the Thames is from the Spey. Bennett was a typical specimen of this English characteristic. He was a poet, but of the school of Wordsworth rather than of Byron and Shelley.

W. B. Squire wrote in 1885: 
Temperley suggests that, despite his reverence for Mendelssohn, Bennett took Mozart as his model. Geoffrey Bush agrees that "[h]is best work, like his piano playing, was full of passion none the less powerful for being Mozartian (that is to say, perfectly controlled)", and characterizes him as "essentially a composer for the piano, a composer of the range (not necessarily the stature) of Chopin".
It would appear that Bennett displayed and aroused greater emotion through his piano technique than from his compositions. Stanford writes that "his playing ... was undoubtedly remarkable and had a fire and energy in it which does not appear on the gentle surface of his music", and notes that Bennett's performances were eulogized by, amongst others, John Field, Clara Schumann, and Ferdinand Hiller.

Bennett's attitudes to the music of his continental contemporaries, aside from that of Mendelssohn, were cautious. Arthur Sullivan claimed that Bennett was "bitterly prejudiced against the new school, as he called it. He would not have a note of Schumann; and as for Wagner, he was outside the pale of criticism." In Bennett's 1858 lecture on "The visits of illustrious foreign musicians to England", the latest mention is of Mendelssohn, bypassing Chopin, Wagner, Verdi and Hector Berlioz, (who all only came to England after Mendelssohn's last visit); Liszt (who visited London in 1827) is omitted. In a subsequent lecture he opined that Verdi was "immeasurably inferior" to Gioachino Rossini, and could only say in favour of Berlioz that he "must be allowed the character of a successful and devoted artist ... it cannot be doubted that his treatment of a great orchestra is masterly in the extreme." Of Wagner, "the hero of the so-called 'music of the future'", Bennett noted "I have no intention of treating him disrespectfully; that I entirely misunderstand him and his musical opinions may be my fault and not his. At any rate he possesses an influence at this moment over musical life, which it would be impossible to overlook."

Bennett's early period of composition was fruitful and includes those of his works which are most esteemed today. By the time of his first visit to Germany (1836) he had already written, amongst other works, five symphonies and three piano concerti. John Caldwell assesses his early songs as "exquisitely judged essentially Mendelssohnian affairs ... the integration and coherence of their accompaniments is a strong feature."

Firman writes that Bennett's finest works are those for the piano: "Rejecting the superficial virtuosity of many of his contemporaries, he developed a style ... peculiarly his own, essentially classical in nature, but with reference to a multiplicity of influences from his own performance repertory." The early piano works were all praised by Robert Schumann, and Temperley points out how Schumann himself was influenced by them, with (as examples) clear traces of Bennett's Op. 16 "Fantasie" (1837) (in effect a sonata) on Schumann's "Novelette", Op. 21 no. 7 (1838), and parallels between Bennett's Op. 12 Impromptus (1836) and Schumann's Op. 18 "Arabesque" (1838).

Temperley feels that the early symphonies are the weakest works of this period, but he suggests that "few piano concertos between Beethoven and Brahms are as successful as Bennett's in embodying the Classical spirit, not in a stiff frame to deck with festoons of virtuosity, but in a living form capable of organic growth, and even of structural surprise."

Bennett's style did not develop after his early years. In 1908 the musicologist W. H. Hadow assessed his later work as follows: "[W]hen "The May Queen" appeared [1858] the idiom of music had changed and he had not changed with it. ... He was too conservative to move with the times. ... [His last works] might all have been written in the forties; they are survivals of an earlier method, not developments but restatements of a tradition." Firman comments that later popular, and more superficial, pieces such as "Genevieve" (1839) came to overshadow the more innovative works of his earlier period such as the Sonata Op. 13, and the "Fantasia" Op. 16.

Young suggests that the cantatas "The May Queen" and "The Woman of Samaria" enjoyed in their hey-day "a popularity that was in inverse relation to their intrinsic merit". Caldwell notes that "The Woman of Samaria" shows that "Bennett was a good craftsman whose only fault was a dread of the operatic ... One would probably tolerate the narrative recitative more readily if the inserted movements showed any spark of life." As regards "The May Queen", Caldwell praises the overture (a Mendelssohn-style work originally written as a concert piece in 1844) "but the rest of the work is tame stuff". He comments that "both works received immense longstanding popularity and may be considered as the narrative prototype for the later Victorian secular and sacred forms ... conforming to the current standards of taste and respectability", anticipating such works as Arthur Sullivan's "Kenilworth" (1864).

Bennett edited some of the keyboard works of Beethoven and Handel and co-edited the "Chorale Book for England" with Otto Goldschmidt (1863), based on German hymns collected by Catherine Winkworth. He supervised the first British printed edition of the "St Matthew Passion". A full vocal score (with piano accompaniment) was adapted from the German edition prepared by Adolf Bernhard Marx (Berlin 1830), which followed Mendelssohn's revival of the work; this was revised with reference to the score published by the Leipzig Bach Society in 1862. Bennett's additional tempo and dynamic markings were shown in parentheses for distinction. He provided harmonies for the figured bass both in the solo music sections (based on the Leipzig full score) and elsewhere. Bennett also produced editions of Bach's "The Well-Tempered Clavier" and Handel's masque "Acis and Galatea".

Bennett lectured both at Cambridge and the London Institute; texts of his lectures were edited and published in 2006. At a Sheffield lecture in 1859 he also played works of the composers he discussed, and "so may be regarded as the founder of the lecture-recital".

As a composer Bennett was acknowledged in his time in both Britain and (particularly in the first half of the century) in Germany, although many British music lovers and several leading critics remained reluctant to acknowledge the possibility that an English composer could be of the same stature as a German one. The Leipzig public, which had initially held that view, had been rapidly converted. Mendelssohn wrote to Bennett "... [M]y Countrymen became aware that music is the same in England as in Germany and everywhere, and so by your successes you have destroyed that prejudice which nobody could ever have destroyed but a true Genius."

Bennett's son, in his biography of his father, juxtaposes as illustrations English and German reviews of the overture "The Wood Nymphs". The London critic William Ayrton wrote:

Schumann, by contrast, wrote:
"The overture is charming; indeed, save Spohr and Mendelssohn, what other living composer is so completely master of his pencil, or bestows with it such tenderness and grace of colour, as Bennett? ... Essay measure after measure; what a firm, yet delicate web it is from beginning to end!"

Outside these countries, Bennett remained almost unknown as a musician, although his reputation as a conductor led Berlioz to invite him to join his "Société Philharmonique", and the Dutch composer Johannes Verhulst solicited his support for the Netherlands "Society for Encouragement of Music". Davison's attempts to interest the French composer Charles Gounod in Bennett's music led to polite but sardonic responses.

Sir John Betjeman, in a 1975 lecture, rated Bennett as "Queen Victoria's Senior Musical Knight". Temperley assesses Bennett as the most distinguished British composer of the early Victorian era, "the only plausible rivals being Samuel Sebastian Wesley (1810–76) and Michael William Balfe (1808–70)".

The novelist Elizabeth Sara Sheppard portrayed Bennett as 'Starwood Burney' in her popular eulogy of Mendelssohn, the 1853 novel "Charles Auchester". Although Bennett's reputation in Germany did not notably survive the 1840s, his English pupils had significant influence on British music of the later 19th and earlier 20th century Britain. Among his pupils at the RAM and elsewhere were Arthur Sullivan, Joseph Parry, Alice Mary Smith, W. S. Rockstro, Hubert Parry, Tobias Matthay, Francis Edward Bache, Eaton Faning and William Cusins. Bennett's contributions to elevating musical training standards at Cambridge and the RAM were part of a trend in England in the latter part of the 19th century whose "cumulative effect ... prior to World War I was incalculable", according to Caldwell.

Through his concert initiatives at the Hanover Rooms Bennett introduced a variety of chamber music to London audiences. His championship also significantly changed British opinion of the music of JS Bach. His "promotion of Bach was a story of perseverance against a contemporary perception that Bach's music was ... too difficult to listen to." Newspaper reviews of the chamber concerts in which he included the music of Bach would initially describe the music in terms such as "grandeur there is, but no beauty" (1847) or "somewhat antiquated ... [but] extremely interesting" (1854). A significant turning point was the attendance of Prince Albert at Bennett's 1858 performance of the "St. Matthew Passion".

Bennett left a substantial music library, a large proportion of which is owned by his great-great-grandson Barry Sterndale Bennett (b. 1939) and is on deposit at the Bodleian Library in Oxford. Of his total of some 130 compositions, about a third have been recorded for CD; among these are symphonies, overtures, piano concerti, chamber music, songs and piano solo music. During his bicentenary year of 2016, several concerts and events dedicated to Bennett's works were performed, including concerts and seminars at the RAM. From April 11 to April 15, 2016 he was featured as 'Composer of the Week' on BBC Radio 3.

Notes
References



</doc>
<doc id="314510" url="https://en.wikipedia.org/wiki?curid=314510" title="Dire wolf">
Dire wolf

The dire wolf ("Canis dirus", "fearsome dog") is an extinct species of the genus "Canis". It is one of the most famous prehistoric carnivores in North America, along with its extinct competitor, the sabre-toothed cat "Smilodon fatalis". The dire wolf lived in the Americas during the Late Pleistocene and Early Holocene epochs (125,000–9,440 years ago). The species was named in 1858, four years after the first specimen had been found. Two subspecies are recognized: "Canis dirus guildayi" and "Canis dirus dirus". The dire wolf probably evolved from Armbruster's wolf ("Canis armbrusteri") in North America. The largest collection of its fossils has been obtained from the Rancho La Brea Tar Pits in Los Angeles.

Dire wolf remains have been found across a broad range of habitats including the plains, grasslands, and some forested mountain areas of North America, and in the arid savannah of South America. The sites range in elevation from sea level to . Dire wolf fossils have rarely been found north of 42°N latitude; there have been only five unconfirmed reports above this latitude. This range restriction is thought to be due to temperature, prey, or habitat limitations imposed by proximity to the Laurentide and Cordilleran ice sheets that existed at the time.

The dire wolf was about the same size as the largest modern gray wolves ("Canis lupus"): the Yukon wolf and the northwestern wolf. "C.d.guildayi" weighed on average and "C.d.dirus" was on average . Its skull and dentition matched those of "C.lupus", but its teeth were larger with greater shearing ability, and its bite force at the canine tooth was the strongest of any known "Canis" species. These characteristics are thought to be adaptations for preying on Late Pleistocene megaherbivores, and in North America its prey are known to have included horses, ground sloths, mastodons, bison, and camels. As with other large "Canis" hypercarnivores today, the dire wolf is thought to have been a pack hunter. Its extinction occurred during the Quaternary extinction event along with most of the American megafauna of the time, including a number of other carnivores, that occurred soon after the appearance of humans in the New World. Its reliance on megaherbivores has been proposed as the cause of its extinction, along with climate change and competition with other species, but the cause remains controversial. Dire wolves lived as recently as 9,440 years ago, according to dated remains.

From the 1850s, the fossil remains of extinct large wolves were being found in the United States, and it was not immediately clear that these all belonged to one species. The first specimen of what would later become associated with "Canis dirus" was found in mid-1854 in the bed of the Ohio River near Evansville, Indiana. The fossilized jawbone with cheek-teeth was obtained by the geologist Joseph Granville Norwood from an Evansville collector, Francis A. Linck. The paleontologist Joseph Leidy determined that the specimen represented an extinct species of wolf and reported it under the name of "Canis primaevus". Norwood's letters to Leidy are preserved along with the type specimen (the first of a species that has a written description) at the Academy of Natural Sciences of Philadelphia. In 1857, while exploring the Niobrara River valley in Nebraska, Leidy found the vertebrae of an extinct "Canis" species that he reported the following year under the name "C.dirus". The name "C.primaevus" (Leidy 1854) was later renamed "Canis indianensis" (Leidy 1869) when Leidy found out that the name "C.primaevus" had previously been used by the British naturalist Brian Houghton Hodgson for the dhole.

In 1876 the zoologist Joel Asaph Allen discovered the remains of "Canis mississippiensis" (Allen 1876) and associated these with "C.dirus" (Leidy 1858) and "Canis indianensis" (Leidy 1869). As so little was found of these three specimens, Allen thought it best to leave each specimen listed under its provisional name until more material could be found to reveal their relationship. In 1908 the paleontologist John Campbell Merriam began retrieving numerous fossilized bone fragments of a large wolf from the Rancho LaBrea tar pits. By 1912 he had found a skeleton sufficiently complete to be able to formally recognize these and the previously found specimens under the name "C.dirus" (Leidy 1858). Because the rules of nomenclature stipulated that the name of a species should be the oldest name ever applied to it, Merriam therefore selected the name of Leidy's 1858 specimen, "C.dirus". In 1915 the paleontologist Edward Troxell indicated his agreement with Merriam when he declared "C.indianensis" a synonym of "C.dirus". In 1918, after studying these fossils, Merriam proposed consolidating their names under the separate genus "Aenocyon" (from "Aenos", terrible and "cyon", wolf) to become "Aenocyon dirus", but not everyone agreed with this extinct wolf being placed in a new genus separate from the genus "Canis". "Canis ayersi" (Sellards 1916) and "Aenocyon dirus" (Merriam 1918) were recognized as synonyms of "C.dirus" by the paleontologist Ernest Lundelius in 1972. All of the above taxa were declared synonyms of "C.dirus" in 1979, according to the paleontologist Ronald M. Nowak.

In 1984 a study by Björn Kurten recognized a geographic variation within the dire wolf populations and proposed two subspecies: "Canis dirus guildayi" (named by Kurten in honor of the paleontologist John E. Guilday) for specimens from California and Mexico that exhibited shorter limbs and longer teeth, and "Canis dirus dirus" for specimens east of the North American Continental Divide that exhibited longer limbs and shorter teeth. Kurten designated a maxilla found in Hermit's Cave, New Mexico as representing the nominate subspecies "C. d. dirus".

Both the canid family and its genus "Canis" are thought to have originated in North America, roughly 40 and 6 million years ago, respectively. Members of both radiations subsequently emigrated to the Old World. Wolf-like species of "Canis" apparently originated there, and then returned to North America.

In 1974 RobertA.Martin proposed that the large North American wolf "C.armbrusteri" (Armbruster's wolf) was "C.lupus". Nowak, Kurten, and Annalisa Berta proposed that "C.dirus" was not derived from "C.lupus". In 1987, a new hypothesis proposed that a mammal population could give rise to a larger form called a hypermorph during times when food was abundant, but when food later became scarce the hypermorph would either adapt to a smaller form or go extinct. This hypothesis might explain the large body sizes found in many Late Pleistocene mammals compared to their modern counterparts. Both extinction and speciationa process by which a new species splits from an older onecould occur together during periods of climatic extremes. Gloria D. Goulet agreed with Martin, proposing further that this hypothesis might explain the sudden appearance of "C.dirus" in North America and, judging from the similarities in their skull shapes, that "C.lupus" had given rise to the "C.dirus" hypermorph due to an abundance of game, a stable environment, and large competitors.

The three paleontologists Xiaoming Wang, Richard H. Tedford, and Ronald M. Nowak have proposed that "C.dirus" evolved from "Canis armbrusteri", with Nowak stating that specimens found in Cumberland Cave, Maryland, appear to be "C.armbrusteri" diverging into "C.dirus". The early wolf from China, "Canis chihliensis", may have been the ancestor of both "C.armbrusteri" and the gray wolf "C.lupus". The sudden appearance of "C.armbrusteri" in North America during the Early Pleistocene suggests that this was an immigrant from Asia, as was "C.lupus" later in the Pleistocene. In 2010 Francisco Prevosti proposed that "C.dirus" was a sister taxon to "C.lupus".

"Canis dirus" lived in the late Pleistocene to the early Holocene (125,000–10,000 years before present or YBP) in North and South America (although no members of "Canis" survive in the latter continent). The majority of fossils from the eastern "C.d.dirus" have been dated 125,000–75,000YBP, but the western "C.d.guildayi" fossils are not only smaller in size but more recent; thus it has been proposed that "C.d.guildayi" derived from "C.d.dirus". However, there are disputed specimens of "C.dirus" that date to 250,000YBP. Fossil specimens of "C.dirus" discovered at four sites in the Hay Springs area of Sheridan County, Nebraska, were named "Aenocyon dirus nebrascensis" (Frick 1930, undescribed), but Frick did not publish a description of them. Nowak later referred to this material as "C.armbrusteri"; then, in 2009, Tedford formally published a description of the specimens and noted that, although they exhibited some morphological characteristics of both "C.armbrusteri" and "C.dirus", he referred to them only as "C.dirus". These Nebraskan fossil specimens may represent the earliest record of "C.dirus".

A fossil discovered in the Horse Room of the Salamander Cave in the Black Hills of South Dakota may possibly be "C.dirus"; if so, this fossil is one of the earliest specimens on record. It was catalogued as "Canis cf. C.dirus" (where cf. in Latin means confer, uncertain). The fossil of a horse found in the Horse Room provided a uranium-series dating of 252,000 yearsYBP and the "Canis cf. dirus" specimen was assumed to be from the same period. "C.armbrusteri" and "C.dirus" share some characteristics (synapomorphies) that imply the latter's descent from the former. The fossil record suggests "C.dirus" originated around 250,000YBP in the open terrain of the mid-continent before expanding eastward and displacing its ancestor "C.armbrusteri". The first appearance of "C.dirus" would therefore be 250,000YBP in California and Nebraska, and later in the rest of the United States, Canada, Mexico, Venezuela, Ecuador, Bolivia, and Peru, but the identity of these earliest fossils is not confirmed.

In South America, "C.dirus" specimens dated to the Late Pleistocene were found along the north and west coasts, but none have been found in Argentina, an area that was inhabited by "Canisgezi" and "Canis nehringi". One study found that "C.dirus" was the most evolutionarily derived "Canis" species in the New World, and compared to "C.nehringi" was larger in the size and construction of its lower molars for more efficient predation. For this reason, some researchers have proposed that "C.dirus" may have originated in South America. In 2009 a proposal was made that "C.armbrusteri" was the common ancestor for both the North and South American wolves. The following year, a study yielded evidence that led to the conclusion that "C.dirus" and "C.nehringi" were the same species and thus that "C.dirus" had migrated from North America into South America, making it a late participant in the Great American Interchange.

In 1992 an attempt was made to extract a mitochondrial DNA sequence from the skeletal remains of "C.d.guildayi" to compare its relationship to other "Canis" species. The attempt was unsuccessful because these remains had been removed from the LaBrea pits and tar could not be removed from the bone material. In 2014 an attempt to extract DNA from a Columbian mammoth from the tar pits also failed, with the study concluding that organic compounds from the asphalt permeate the bones of all ancient samples from the LaBrea pits, hindering the extraction of DNA samples.

The age of most dire wolf localities is determined solely by biostratigraphy, but biostratigraphy is an unreliable indicator within asphalt deposits. Some sites have been radiocarbon dated, with "C.dirus" specimens from LaBrea pits dated in calendar years as follows: 82 specimens dated 13,000–14,000YBP; 40 specimens dated 14,000–16,000YBP; 77 specimens dated 14,000–18,000YBP; 37 specimens dated 17,000–18,000YBP; 26 specimens dated 21,000–30,000YBP; 40 specimens dated 25,000–28,000YBP; and 6specimens dated 32,000–37,000YBP. A specimen from Powder Mill Creek Cave, Missouri, was dated at 13,170YBP.

The dire wolf is the largest species of the genus "Canis" known to have existed. Its shape and proportions were similar to those of two modern North American wolves: the Yukon wolf ("Canis lupus pambasileus") and the Northwestern wolf ("Canis lupus occidentalis"). The largest northern wolves today have a shoulder height of and a body length of . Some dire wolf specimens from Rancho LaBrea are smaller than this, and some are larger.

The dire wolf had smaller feet and a larger head when compared with a northern wolf of the same body size. The skull length could reach up to or longer, with a broader palate, frontal region, and zygomatic arches compared with the Yukon wolf. These dimensions make the skull very massive. Its sagittal crest was higher, with the inion showing a significant backward projection, and with the rear ends of the nasal bones extending relatively far back into the skull. A connected skeleton of a dire wolf from Rancho LaBrea is difficult to find because the tar allows the bones to disassemble in many directions. Parts of a vertebral column have been assembled, and it was found to be similar to that of the modern wolf, with the same number of vertebrae.

Geographic differences in dire wolves were not detected until 1984, when a study of skeletal remains showed differences in a few cranio-dental features and limb proportions between specimens from California and Mexico ("C.d.guildayi") and those found from the east of the Continental Divide ("C.d.dirus"). A comparison of limb size shows that the rear limbs of "C.d.guildayi" were 8% shorter than the Yukon wolf due to a significantly shorter tibia and metatarsus, and that the front limbs were also shorter due to their slightly shorter lower bones. With its comparatively lighter and smaller limbs and massive head, "C.d.guildayi" was not as well adapted for running as timber wolves and coyotes. "C.d.dirus" possessed significantly longer limbs than "C.d.guildayi". The forelimbs were 14% longer than "C.d.guildayi" due to 10% longer humeri, 15% longer radii, and 15% longer metacarpals. The rear limbs were 10% longer than "C.d.guildayi" due to 10% longer femora and tibiae, and 15% longer metatarsals. "C.d.dirus" is comparable to the Yukon wolf in limb length. The largest "C.d.dirus" femur was found in Carroll Cave, Missouri, and measured .

"C.d.guildayi" is estimated to have weighed on average , and "C.d.dirus" weighed on average with some specimens being larger, but these could not have exceeded due to skeletal limits. In comparison, the average weight of the Yukon wolf is for males and for females. Individual weights for Yukon wolves can vary from to , with one Yukon wolf weighing . These figures show the average dire wolf to be similar in size to the largest modern gray wolf.

The remains of a complete male "C. dirus" are sometimes easy to identify compared to other "Canis" specimens because the baculum (penis bone) of the dire wolf is very different from that of all other living canids.

Ecological factors such as habitat type, climate, prey specialization, and predatory competition have been shown to greatly influence gray wolf craniodental plasticity, which is an adaptation of the cranium and teeth due to the influences of the environment. Similarly, the dire wolf was a hypercarnivore, with a skull and dentition adapted for hunting large and struggling prey; the shape of its skull and snout changed across time, and changes in the size of its body have been correlated to climate fluctuations.

The last glacial period, commonly referred to as the "Ice Age", spanned 125,000–14,500YBP and was the most recent glacial period within the current ice age, which occurred during the last years of the Pleistocene era. The Ice Age reached its peak during the Last Glacial Maximum, when ice sheets began advancing from 33,000YBP and reached their maximum limits 26,500YBP. Deglaciation commenced in the Northern Hemisphere approximately 19,000YBP and in Antarctica approximately 14,500 yearsYBP, which is consistent with evidence that glacial meltwater was the primary source for an abrupt rise in sea level 14,500YBP. Access into northern North America was blocked by the Wisconsin glaciation. The fossil evidence from the Americas points to the extinction mainly of large animals, termed Pleistocene megafauna, near the end of the last glaciation.

Coastal southern California from 60,000YBP to the end of the Last Glacial Maximum was cooler and with a more balanced supply of moisture than today. During the Last Glacial Maximum, the mean annual temperature decreased from down to degrees, and annual precipitation had decreased from down to . This region was unaffected by the climatic effects of the Wisconsin glaciation, and is thought to have been an Ice Age refugium for animals and cold-sensitive plants. By 24,000YBP, the abundance of oak and chaparral decreased, but pines increased, creating open parklands similar to today's coastal montane/juniper woodlands. After 14,000YBP, the abundance of conifers decreased, and those of the modern coastal plant communities, including oak woodland, chaparral, and coastal sage scrub, increased. The Santa Monica Plain lies north of the city of Santa Monica and extends along the southern base of the Santa Monica Mountains, and 28,000–26,000YBP it was dominated by coastal sage scrub, with cypress and pines at higher elevations. The Santa Monica Mountains supported a chaparral community on its slopes and isolated coast redwood and dogwood in its protected canyons, along with river communities that included willow, red cedar, and sycamore. These plant communities suggest a winter rainfall similar to that of modern coastal southern California, but the presence of coast redwood now found to the north indicates a cooler, moister, and less seasonal climate than today. This environment supported large herbivores that were prey for dire wolves and their competitors.

A range of animal and plant specimens that became entrapped and were then preserved in tar pits have been removed and studied so that researchers can learn about the past. The Rancho LaBrea tar pits located near Los Angeles in southern California are a collection of pits of sticky asphalt deposits that differ in deposition time from 40,000 to 12,000YBP. Commencing 40,000YBP, trapped asphalt has been moved through fissures to the surface by methane pressure, forming seeps that can cover several square meters and be deep. The dire wolf has been made famous because of the large number of its fossils recovered there. Over 200,000 specimens (mostly fragments) have been recovered from the tar pits, with the remains ranging from "Smilodon" to squirrels, invertebrates, and plants. The time period represented in the pits includes the Last Glacial Maximum when global temperatures were lower than today, the Pleistocene–Holocene transition (Bølling-Allerød interval), the Oldest Dryas cooling, the Younger Dryas cooling from 12,800 to 11,500YBP, and the American megafaunal extinction event 12,700YBP when 90 genera of mammals weighing over became extinct.

Isotope analysis can be used to identify some chemical elements, allowing researchers to make inferences about the diet of the species found in the pits. An isotope analysis of bone collagen extracted from LaBrea specimens provides evidence that the dire wolf, "Smilodon", and the American lion ("Panthera leo atrox") competed for the same prey. Their prey included "yesterday's camel" ("Camelops hesternus"), the Pleistocene bison ("Bison antiquus"), the "dwarf" pronghorn ("Capromeryx minor"), the western horse ("Equus occidentalis"), and the "grazing" ground sloth ("Paramylodon harlani") native to North American grasslands. The Columbian mammoth ("Mammuthus columbi") and the American mastodon ("Mammut americanum") were rare at LaBrea. The horses remained mixed feeders and the pronghorns mixed browsers, but at the Last Glacial Maximum and its associated shift in vegetation the camels and bison were forced to rely more heavily on conifers.

A study of isotope data of La Brea dire wolf fossils dated 10,000YBP provides evidence that the horse was an important prey species at the time, and that sloth, mastodon, bison, and camel were less common in the dire wolf diet. This indicates that the dire wolf was not a prey specialist, and at the close of the late Pleistocene before its extinction it was hunting or scavenging the most available herbivores.

A study of "Canis" dentition concluded that the dire wolf was the most advanced, or evolutionary derived, "Canis" species in the Americas. The dire wolf could be identified separately from all other "Canis" species by its possession of: "P2 with a posterior cusplet; P3 with two posterior cusplets; M1 with a mestascylid, entocristed, entoconulid, and a transverse crest extending from the metaconid to the hyperconular shelf; M2 with entocristed and entoconulid."

A study of the estimated bite force at the canine teeth of a large sample of living and fossil mammalian predators, when adjusted for the body mass, found that for placental mammals the bite force at the canines (in newtons/kilogram of body weight) was greatest in the dire wolf (163), followed among the modern canids by the four hypercarnivores that often prey on animals larger than themselves: the African hunting dog (142), the gray wolf (136), the dhole (112), and the dingo (108). The bite force at the carnassials showed a similar trend to the canines. A predator's largest prey size is strongly influenced by its biomechanical limits. The morphology of the dire wolf was similar to that of its living relatives, and assuming that the dire wolf was a social hunter, then its high bite force relative to living canids suggests that it preyed on relatively large animals. The bite force rating of the bone-consuming spotted hyena (117) challenged the common assumption that high bite force in the canines and the carnassials was necessary to consume bone.

A study of the cranial measurements and jaw muscles of dire wolves found no significant differences with modern gray wolves in all but 4 of 15 measures. Upper dentition was the same except that the dire wolf had larger dimensions, and the P4 had a relatively larger, more massive blade that enhanced slicing ability at the carnassial. The jaw of the dire wolf had a relatively broader and more massive temporalis muscle, able to generate slightly more bite force than the gray wolf. Due to the jaw arrangement, the dire wolf had less temporalis leverage than the gray wolf at the lower carnassial (m1) and lower p4, but the functional significance of this is not known. The lower premolars were relatively slightly larger than those of the gray wolf, and the dire wolf m1 was much larger and had more shearing ability. The dire wolf canines had greater bending strength than those of living canids of equivalent size and were similar to those of hyenas and felids. All these differences indicate that the dire wolf was able to deliver stronger bites than the gray wolf, and with its flexible and more rounded canines was better adapted for struggling with its prey.

At La Brea, predatory birds and mammals were attracted to dead or dying herbivores that had become mired, and then these predators became trapped themselves. Herbivore entrapment was estimated to have occurred once every fifty years, and for every instance of herbivore remains found in the pits there were an estimated ten carnivores. "C.d.guildayi" is the most common carnivoran found at LaBrea, followed by "Smilodon". Remains of dire wolves outnumber remains of gray wolves in the tar pits by a ratio of five to one. During the Last Glacial Maximum, coastal California, with a climate slightly cooler and wetter than today, is thought to have been a refuge, and a comparison of the frequency of dire wolves and other predator remains at LaBrea to other parts of California and North America indicates significantly greater abundances; therefore, the higher dire wolf numbers in the LaBrea region did not reflect the wider area. Assuming that only a few of the carnivores that were feeding became trapped, it is likely that fairly sizeable groups of dire wolves fed together on these occasions.
The difference between the male and female of a species apart from their sex organs is called sexual dimorphism, and in this regard little variance exists among the canids. A study of dire wolf remains dated 15,360–14,310YBP and taken from one pit that focused on skull length, canine tooth size, and lower molar length showed little dimorphism, similar to that of the gray wolf, indicating that dire wolves lived in monogamous pairs. Their large size and highly carnivorous dentition supports the proposal that the dire wolf was a predator that fed on large prey. To kill ungulates larger than themselves, the African wild dog, the dhole, and the gray wolf depend on their jaws as they cannot use their forelimbs to grapple with prey, and they work together as a pack consisting of an alpha pair and their offspring from the current and previous years. It can be assumed that dire wolves lived in packs of relatives that were led by an alpha pair. Large and social carnivores would have been successful at defending carcasses of prey trapped in the tar pits from smaller solitary predators, and thus the most likely to become trapped themselves. The many "C.d.guildayi" and "Smilodon" remains found in the tar pits suggests that both were social predators.

All social terrestrial mammalian predators prey mostly on terrestrial herbivorous mammals with a body mass similar to the combined mass of the social group members attacking the prey animal. The large size of the dire wolf provides an estimated prey size in the range. Stable isotope analysis of dire wolf bones provides evidence that they had a preference for consuming ruminants such as bison rather than other herbivores but moved to other prey when food became scarce, and occasionally scavenged on beached whales along the Pacific coast when available. A pack of timber wolves can bring down a moose that is their preferred prey, and a pack of dire wolves bringing down a bison is conceivable. Although some studies have suggested that because of tooth breakage, the dire wolf must have gnawed bones and may have been a scavenger, its widespread occurrence and the more gracile limbs of "C.d.dirus" indicate a predator. Like the gray wolf today, the dire wolf probably used its post-carnassial molars to gain access to marrow, but the dire wolf's larger size enabled it to crack larger bones.

Tooth breakage is related to a carnivore's behavior. A study of nine modern carnivores found that one in four adults had suffered tooth breakage and that half of these breakages were of the canine teeth. The most breakage occurred in the spotted hyena that consumes all of its prey including the bone; the least breakage occurred in the African wild dog, and the gray wolf ranked in between these two. The eating of bone increases the risk of accidental fracture due to the relatively high, unpredictable stresses that it creates. The most commonly broken teeth are the canines, followed by the premolars, carnassial molars, and incisors. Canines are the teeth most likely to break because of their shape and function, which subjects them to bending stresses that are unpredictable in both direction and magnitude. The risk of tooth fracture is also higher when killing large prey.

A study of the fossil remains of large carnivores from LaBrea pits dated 36,000–10,000YBP shows tooth breakage rates of 5–17% for the dire wolf, coyote, American lion, and "Smilodon", compared to 0.5–2.7% for ten modern predators. These higher fracture rates were across all teeth, but the fracture rates for the canine teeth were the same as in modern carnivores. The dire wolf broke its incisors more often when compared to the modern gray wolf; thus, it has been proposed that the dire wolf used its incisors more closely to the bone when feeding. Dire wolf fossils from Mexico and Peru show a similar pattern of breakage. A 1993 study proposed that the higher frequency of tooth breakage among Pleistocene carnivores compared with living carnivores was not the result of hunting larger game, something that might be assumed from the larger size of the former. When there is low prey availability, the competition between carnivores increases, causing them to eat faster and thus consume more bone, leading to tooth breakage. As their prey became extinct around 10,000 years ago, so did these Pleistocene carnivores, except for the coyote (which is an omnivore).

A later La Brea pits study compared tooth breakage of dire wolves in two time periods. One pit contained fossil dire wolves dated 15,000YBP and another dated 13,000YBP. The results showed that the 15,000YBP dire wolves had three times more tooth breakage than the 13,000YBP dire wolves, whose breakage matched those of nine modern carnivores. The study concluded that between 15,000–14,000YBP prey availability was less or competition was higher for dire wolves, and that by 13,000YBP, as the prey species moved towards extinction, predator competition had declined and therefore the frequency of tooth breakage in dire wolves had also declined.

Carnivores include both pack hunters and solitary hunters. The solitary hunter depends on a powerful bite at the canine teeth to subdue their prey, and thus exhibits a strong mandibular symphysis. In contrast, a pack hunter, which delivers many shallower bites, has a comparably weaker mandibular symphysis. Thus, researchers can use the strength of the mandibular symphysis in fossil carnivore specimens to determine what kind of hunter it wasa pack hunter or a solitary hunterand even how it consumed its prey. The mandibles of canids are buttressed behind the carnassial teeth to enable the animals to crack bones with their post-carnassial teeth (molars M2 and M3). A study found that the mandible buttress profile of the dire wolf was lower than that of the gray wolf and the red wolf, but very similar to the coyote and the African hunting dog. The dorsoventrally weak symphyseal region (in comparison to premolars P3 and P4) of the dire wolf indicates that it delivered shallow bites similar to its modern relatives and was therefore a pack hunter. This suggests that the dire wolf may have processed bone but was not as well adapted for it as was the gray wolf. The fact that the incidence of fracture for the dire wolf reduced in frequency in the late Pleistocene to that of its modern relatives suggests that reduced competition had allowed the dire wolf to return to a feeding behavior involving a lower amount of bone consumption, a behavior for which it was best suited.

The results of a study of dental microwear on tooth enamel for specimens of the carnivore species from LaBrea pits, including dire wolves, suggest that these carnivores were not food-stressed just before their extinction. The evidence also indicated that the extent of carcass utilization (i.e., amount consumed relative to the maximum amount possible to consume, including breakup and consumption of bones) was less than among large carnivores today. These finding indicates that tooth breakage was related to hunting behavior and the size of prey.

Past studies proposed that changes in dire wolf body size correlated with climate fluctuations. A later study compared dire wolf craniodental morphology from four LaBrea pits, each representing four different time periods. The results are evidence of a change in dire wolf size, dental wear and breakage, skull shape, and snout shape across time. Dire wolf body size had decreased between the start of the Last Glacial Maximum and near its ending at the warm Allerød oscillation. Evidence of food stress (food scarcity leading to lower nutrient intake) is seen in smaller body size, skulls with a larger cranial base and shorter snout (shape neoteny and size neoteny), and more tooth breakage and wear. Dire wolves dated 17,900YBP showed all of these features, which indicates food stress. Dire wolves dated 28,000YBP also showed to a degree many of these features but were the largest wolves studied, and it was proposed that these wolves were also suffering from food stress and that wolves earlier than this date were even bigger in size. Nutrient stress is likely to lead to stronger bite forces to more fully consume carcasses and to crack bones, and with changes to skull shape to improve mechanical advantage. North American climate records reveal cyclic fluctuations during the glacial period that included rapid warming followed by gradual cooling, called Dansgaard–Oeschger events. These cycles would have caused increased temperature and aridity, and at LaBrea would have caused ecological stress and therefore food stress. A similar trend was found with the gray wolf, which in the Santa Barbara basin was originally massive, robust, and possibly convergent with the dire wolf, but was replaced by more gracile forms by the start of the Holocene.

Just before the appearance of the dire wolf, North America was invaded by the genus "Xenocyon" (ancestor of the Asian dhole and the African hunting dog) that was as large as the dire wolf and more hypercarnivorous. The fossil record shows them as rare, and it is assumed that they could not compete with the newly derived dire wolf. Stable isotope analysis provides evidence that the dire wolf, "Smilodon", and the American lion competed for the same prey. Other large carnivores included the extinct North American giant short-faced bear ("Arctodus simus"), the modern cougar ("Puma concolor"), the Pleistocene coyote ("Canis latrans"), and the Pleistocene gray wolf that was more massive and robust than today. These predators may have competed with humans who hunted for similar prey.

Specimens that have been identified by morphology as Beringian wolves ("C.lupus") and radiocarbon dated 25,800–14,300 YBP have been found in the Natural Trap Cave at the base of the Bighorn Mountains in Wyoming, in the western United States. The location is directly south of what would at that time have been a division between the Laurentide Ice Sheet and the Cordilleran Ice Sheet. A temporary channel between the glaciers may have existed that allowed these large, Alaskan direct competitors of the dire wolf, which were also adapted for preying on megafauna, to come south of the ice sheets. Dire wolves were absent north of 42°Nlatitude in the Late Pleistocene; therefore, this region would have been available for Beringian wolves to expand south along the glacier line. How widely they were then distributed is not known. These also became extinct at the end of the Late Pleistocene, as did the dire wolf.

Dire wolf remains have been found across a broad range of habitats including the plains, grasslands, and some forested mountain areas of North America, and in the arid savannah of South America. The sites range in elevation from sea level to . The location of these fossil remains suggests that dire wolves lived predominantly in the open lowlands along with its prey the large herbivores. Dire wolf remains do not occur at high latitudes, unlike its close relative the gray wolf.

In the United States, dire wolf fossils have been reported in Arizona, California, Florida, Idaho, Indiana, Kansas, Kentucky, Missouri, Nebraska, New Mexico, Oregon, Pennsylvania, South Carolina, South Dakota, Texas, Utah, Virginia, West Virginia, Wyoming, and Nevada. The identity of fossils reported farther north than California is not confirmed. There have been five reports of unconfirmed dire wolf fossils north of 42°Nlatitude at Fossil Lake, Oregon (125,000–10,000YBP), American Falls Reservoir, Idaho (125,000–75,000YBP), Salamander Cave, South Dakota (250,000YBP), and four closely grouped sites in northern Nebraska (250,000YBP). This suggests a range restriction on dire wolves due to temperature, prey, or habitat. The major fossil-producing sites for "C.d.dirus" are located east of the Rocky Mountains and include Friesenhahn Cave, near San Antonio, Texas; Carroll Cave, near Richland, Missouri; and Reddick, Florida.

Localities in Mexico where dire wolf remains have been collected include ElCedazo in Aguascalientes, Comondú Municipality in Baja California Sur, ElCedral in San Luis Potosí, ElTajo Quarry near Tequixquiac, state of Mexico, Valsequillo in Puebla, Lago de Chapala in Jalisco, Loltun Cave in Yucatán, Potrecito in Sinaloa, San Josecito Cave near Aramberri in Nuevo León and Térapa in Sonora. The specimens from Térapa were confirmed as "C.d.guildayi". The finds at San Josecito Cave and ElCedazo have the greatest number of individuals from a single locality.

In South America, dire wolves have been dated younger than 17,000 YBP and reported from only three localities: Muaco in Falcón state, Venezuela; Talara Province in Peru; and Tarija Department in Bolivia. If the dire wolf originated in North America, the species likely dispersed into South America via the Andean corridor, a proposed pathway for temperate mammals to migrate from Central to South America because of the favorable cool, dry, and open habitats that characterized the region at times. This most likely happened during a glacial period because the pathway then consisted of open, arid regions and savanna, whereas during inter-glacial periods it would have consisted of tropical rain forest.

During the American megafaunal extinction event around 12,700YBP, 90genera of mammals weighing over became extinct. The extinction of the large carnivores and scavengers is thought to have been caused by the extinction of the megaherbivore prey upon which they depended. The cause of the extinction of the megafauna is debated but has been attributed to the impact of climate change, competition with other species including overexploitation by newly arrived human hunters, or a combination of both. One study proposes that several extinction models should be investigated because so little is known about the biogeography of the dire wolf and its potential competitors and prey, nor how all these species interacted and responded to the environmental changes that occurred at the time of extinction.

Ancient DNA and radiocarbon data indicates that local genetic populations were replaced by others within the same species or by others within the same genus. Both the dire wolf and the Beringian wolf went extinct in North America, leaving only the less carnivorous and more gracile form of the wolf to thrive, which may have outcompeted the dire wolf. Dire wolf remains having the youngest geological ages are dated at 9,440YBP at Brynjulfson Cave, Boone County, Missouri, 9,860YBP at Rancho La Brea, California, and 10,690YBP at La Mirada, California. Dire wolf remains have been radiocarbon dated to 8,200YBP from Whitewater Draw in Arizona, However, one author has stated that radiocarbon dating of bone carbonate is known to be unreliable, and that while many dire wolf remains are found in fossil assemblages dated to the terminal Pleistocene, there are no confirmed Holocene finds.



</doc>
<doc id="314843" url="https://en.wikipedia.org/wiki?curid=314843" title="Campaign history of the Roman military">
Campaign history of the Roman military

From its origin as a city-state on the peninsula of Italy in the 8th century BC, to its rise as an empire covering much of Southern Europe, Western Europe, the Middle East and North Africa to its fall in the 5th century AD, the political history of Ancient Rome was closely entwined with its military history. The core of the campaign history of the Roman military is an aggregate of different accounts of the Roman military's land battles, from its initial defense against and subsequent conquest of the city's hilltop neighbors on the Italian peninsula, to the ultimate struggle of the Western Roman Empire for its existence against invading Huns, Vandals and Germanic tribes. These accounts were written by various authors throughout and after the history of the Empire. Following the First Punic War, naval battles were less significant than land battles to the military history of Rome due to its encompassment of lands of the periphery and its unchallenged dominance of the Mediterranean Sea.

The Roman army battled first against its tribal neighbours and Etruscan towns within Italy, and later came to dominate the Mediterranean and at its height the provinces of Britannia and Asia Minor. As with most ancient civilizations, Rome's military served the triple purpose of securing its borders, exploiting peripheral areas through measures such as imposing tribute on conquered peoples, and maintaining internal order. From the outset, Rome's military typified this pattern, and the majority of Rome's campaigns were characterised by one of two types. The first is the territorial expansionist campaign, normally begun as a counter-offensive, in which each victory brought subjugation of large areas of territory and allowed Rome to grow from a small town to a population of 55 million in the early empire when expansion was halted. The second is the civil war, which plagued Rome from its foundation to its eventual demise.

Roman armies were not invincible, despite their formidable reputation and host of victories, Romans "produced their share of incompetents" who led Roman armies into catastrophic defeats. Nevertheless, it was generally the fate of even the greatest of Rome's enemies, such as Pyrrhus and Hannibal, to win the battle but lose the war. The history of Rome's campaigning is, if nothing else, a history of obstinate persistence overcoming appalling losses.

Knowledge of Roman history stands apart from other civilizations in the ancient world. Its chronicles, military and otherwise, document the city's very foundation to its eventual demise. Although some histories have been lost, such as Trajan's account of the Dacian Wars, and others, such as Rome's earliest histories, are at least semi-apocryphal, the extant histories of Rome's military history are extensive.

Rome's earliest history, from the time of its founding as a small tribal village, to the downfall of its kings, is the least well preserved. Although the early Romans were literate to some degree, this void may be due to the lack of will to record their history at that time, or such histories as they did record were lost.

Although the Roman historian Livy (59 BC – 17 AD) lists a series of seven kings of early Rome in his work "Ab urbe condita", from its establishment through its earliest years, the first four kings (Romulus, Numa, Tullus Hostilius and Ancus Marcius) may be apocryphal. A number of points of view have been proposed. Grant and others argue that prior to the establishment of the Etruscan kingdom of Rome under the traditional fifth king, Tarquinius Priscus, Rome would have been led by a religious leader of some sort. Very little is known of Rome's military history from this era, and what history has come down to us is more of a legendary than of factual nature. Traditionally, Romulus, after founding the city, fortified the Palatine Hill, and shortly thereafter, Rome was ""equal to any of the surrounding cities in her prowess in war"".

The first of the campaigns fought by the Romans in this legendary account are the wars with various Latin cities and the Sabines. According to Livy, the Latin village of Caenina responded to the event of the abduction of the Sabine women by invading Roman territory, but were routed and their village captured. The Latins of Antemnae and those of Crustumerium were defeated next in a similar fashion. The remaining main body of the Sabines attacked Rome and briefly captured the citadel, but were then convinced to conclude a treaty with the Romans under which the Sabines became Roman citizens.

There was a further war in the 8th century BC against Fidenae and Veii. In the 7th century BC there was a war with Alba Longa, a second war with Fidenae and Veii and a second Sabine War. Ancus Marcius led Rome to victory against the Latins and, according to the Fasti Triumphales, over the Veientes and Sabines also.

Lucius Tarquinius Priscus' first war was waged against the Latins. Tarquinius took the Latin town of Apiolae by storm and took great booty from there back to Rome. According to the "Fasti Triumphales", the war occurred prior to 588 BC.

His military ability was tested by an attack from the Sabines. Tarquinius doubled the numbers of equites to help the war effort, and defeat the Sabines. In the peace negotiations that followed, Tarquinius received the town of Collatia and appointed his nephew, Arruns Tarquinius, also known as "Egerius", as commander of the garrison which he stationed in that city. Tarquinius returned to Rome and celebrated a triumph for his victories that, according to the "Fasti Triumphales", occurred on 13 September 585 BC.

Subsequently, the Latin cities of Corniculum, old Ficulea, Cameria, Crustumerium, Ameriola, Medullia and Nomentum were subdued and became Roman.

Early in his reign, Servius Tullius warred against Veii and the Etruscans. He is said to have shown valour in the campaign, and to have routed a great army of the enemy. The war helped him to cement his position at Rome. According to the "Fasti Triumphales", Servius celebrated three triumphs over the Etruscans, including on 25 November 571 BC and 25 May 567 BC (the date of the third triumph is not legible on the "Fasti").

Early in his reign Tarquinius Superbus, Rome's seventh and final king, called a meeting of the Latin leaders at which he persuaded them to renew their treaty with Rome and become her allies rather than her enemies, and it was agreed that the troops of the Latins would attend at a grove sacred to the goddess Ferentina on an appointed day to form a united military force with the troops of Rome. This was done, and Tarquin formed combined units of Roman and Latin troops.

Tarquin next began a war against the Volsci. He took the wealthy town of Suessa Pometia, with the spoils of which he commenced the erection of the Temple of Jupiter Optimus Maximus which his father had vowed. He also celebrated a triumph for his victory.

He was next engaged in a war with Gabii, one of the Latin cities, which had rejected the Latin treaty with Rome. Unable to take the city by force of arms, Tarquin had his son, Sextus Tarquinius, infiltrate the city, gain the trust of its people and command of its army. In time he killed or exiled the city's leaders, and handed control of the city over to his father.

Tarquin also agreed to a peace with the Aequi, and renewed the treaty of peace between Rome and the Etruscans. According to the Fasti Triumphales, Tarquin also won a victory over the Sabines.

Tarquinius later went to war with the Rutuli. According to Livy, the Rutuli were, at that time, a very wealthy nation. Tarquinius was desirous of obtaining the booty which would come with victory over the Rutuli. Tarquin unsuccessfully sought to take the Rutulian capital, Ardea, by storm, and subsequently began an extensive siege of the city. The war was interrupted by the revolution which overthrew the Roman monarchy. The Roman army, camped outside Ardea, welcomed Lucius Junius Brutus as their new leader, and expelled the king's sons. It is unclear what was the outcome of the siege, or indeed the war.

The first non-apocryphal Roman wars were wars of both expansion and defence, aimed at protecting Rome itself from neighbouring cities and nations and establishing its territory in the region. Florus writes that at this time "their neighbours, on every side, were continually harassing them, as they had no land of their own ... and as they were situated, as it were, at the junction of the roads to Latium and Eturia, and, at whatever gate they went out, were sure to meet a foe."

In the semi-legendary period of the early republic, sources record Rome was twice attacked by Etruscan armies. About 509 BC war with Veii and Tarquinii was said to have been instigated by the recently overthrown king Tarquinius Superbus. Again in 508 BC Tarquin persuaded the king of Clusium, Lars Porsenna, to wage war on Rome, resulting in a siege of Rome and afterwards a peace treaty.

Initially, Rome's immediate neighbours were either Latin towns and villages on a tribal system similar to that of Rome, or else tribal Sabines from the Apennine hills beyond. One by one, Rome defeated both the persistent Sabines and the local cities that were either under Etruscan control or else Latin towns that had cast off their Etruscan rulers, as had Rome. Rome defeated the Lavinii and Tusculi in the Battle of Lake Regillus in 496 BC, were defeated by the Veientes in the Battle of the Cremera in 477 BC, the Sabines in an unnamed battle in 449 BC, the Aequi in the Battle of Mount Algidus in 458 BC, the Aequi and Volsci in 446 BC, in the Battle of Corbio, in 446 BC the Aurunci in the Battle of Aricia, the Capture of Fidenae in 435 BC and the Siege of Veii in 396 BC, and the Capture of Antium in 377 BC. After defeating the Veientes, the Romans had effectively completed the conquest of their immediate Etruscan neighbours, as well as secured their position against the immediate threat posed by the tribespeople of the Apennine hills.

However, Rome still controlled only a very limited area and the affairs of Rome were minor even to those in Italy and Rome's affairs were only just coming to the attention of the Greeks, the dominant cultural force at the time. At this point the bulk of Italy remained in the hands of Latin, Sabine, Samnite and other peoples in the central part of Italy, Greek colonies to the south, and the Celtic people, including the Gauls, to the north.

By 390 BC, several Gallic tribes had begun invading Italy from the north as their culture expanded throughout Europe. Most of this was unknown to the Romans at this time, who still had purely local security concerns, but the Romans were alerted when a particularly warlike tribe, the Senones, invaded the Etruscan province of Siena from the north and attacked the town of Clusium, not far from Rome's sphere of influence. The Clusians, overwhelmed by the size of the enemy in numbers and ferocity, called on Rome for help. Perhaps unintentionally the Romans found themselves not just in conflict with the Senones, but their primary target. The Romans met them in pitched battle at the Battle of the Allia around 390–387 BC. The Gauls, under their chieftain Brennus, defeated the Roman army of around 15,000 troops and proceeded to pursue the fleeing Romans back to Rome itself and partially sacked the town before being either driven off or bought off.

Now that the Romans and Gauls had blooded one another, intermittent Roman-Gallic wars were to continue between the two in Italy for more than two centuries, including the Battle of Lake Vadimo, the Battle of Faesulae in 225 BC, the Battle of Telamon in 224 BC, the Battle of Clastidium in 222 BC, the Battle of Cremona in 200 BC, the Battle of Mutina in 194 BC, the Battle of Arausio in 105 BC, and the Battle of Vercellae in 101 BC. The Celtic problem would not be resolved for Rome until the final subjugation of all Gaul following the Battle of Alesia in 52 BC.

After swiftly recovering from the sack of Rome, the Romans immediately resumed their expansion within Italy. Despite their successes, their mastery of the whole of Italy was by no means assured. The Samnites were a people just as martial and as rich as the Romans and had the objective of their own to secure more lands in the fertile Italian plains on which Rome itself lay. The First Samnite War of between 343 BC and 341 BC that followed widespread Samnite incursions into Rome's territory was a relatively short affair: the Romans beat the Samnites in both the Battle of Mount Gaurus in 342 BC and the Battle of Suessula in 341 BC but were forced to withdraw from the war before they could pursue the conflict further due to the revolt of several of their Latin allies in the Latin War.

Rome was therefore forced to contend by around 340 BC against both Samnite incursions into their territory and, simultaneously, in a bitter war against their former allies. Rome bested the Latins in the Battle of Vesuvius and again in the Battle of Trifanum, after which the Latin cities were obliged to submit to Roman rule. Perhaps due to Rome's lenient treatment of their defeated foe, the Latins submitted largely amicably to Roman rule for the next 200 years.

The Second Samnite War, from 327 BC to 304 BC, was a much longer and more serious affair for both the Romans and Samnites, running for over twenty years and incorporating twenty-four battles that led to massive casualties on both sides. The fortunes of the two sides fluctuated throughout its course: the Samnites seized Neapolis in the Capture of Neapolis in 327 BC, which the Romans then re-captured before losing at the Battle of the Caudine Forks and the Battle of Lautulae. The Romans then proved victorious at the Battle of Bovianum and the tide turned strongly against the Samnites from 314 BC onwards, leading them to sue for peace with progressively less generous terms. By 304 BC the Romans had effectively annexed the greater degree of the Samnite territory, founding several colonies. This pattern of meeting aggression in force and so inadvertently gaining territory in strategic counter-attacks was to become a common feature of Roman military history.

Seven years after their defeat, with Roman dominance of the area looking assured, the Samnites rose again and defeated the Romans at the Battle of Camerinum in 298 BC, to open the Third Samnite War. With this success in hand they managed to bring together a coalition of several previous enemies of Rome, all of whom were probably keen to prevent any one faction dominating the entire region. The army that faced the Romans at the Battle of Sentinum in 295 BC included Samnites, Gauls, Etruscans and Umbrians. When the Roman army won a convincing victory over these combined forces it must have become clear that little could prevent Roman dominance of Italy and in the Battle of Populonia (282 BC) Rome destroyed the last vestiges of Etruscan power in the region.

By the beginning of the 3rd century, Rome had established itself in 282 BC as a major power on the Italian Peninsula, but had not yet come into conflict with the dominant military powers in the Mediterranean at the time: Carthage and the Greek kingdoms. Rome had all but completely defeated the Samnites, mastered its fellow Latin towns, and greatly reduced Etruscan power in the region. However, the south of Italy was controlled by the Greek colonies of Magna Grecia who had been allied to the Samnites, and continued Roman expansion brought the two into inevitable conflict.

In the naval Battle of Thurii, Tarentum appealed for military aid to Pyrrhus, ruler of Epirus. Motivated by his diplomatic obligations to Tarentum, and a personal desire for military accomplishment, Pyrrhus landed a Greek army of some 25,000 men and a contingent of war elephants on Italian soil in 280 BC, where his forces were joined by some Greek colonists and a portion of the Samnites who revolted against Roman control, taking up arms against Rome for the fourth time in seventy years.

The Roman army had not yet seen elephants in battle, and their inexperience turned the tide in Pyrrhus' favour at the Battle of Heraclea in 280 BC, and again at the Battle of Ausculum in 279 BC. Despite these victories, Pyrrhus found his position in Italy untenable. Rome steadfastly refused to negotiate with Pyrrhus as long as his army remained in Italy. Furthermore, Rome entered into a treaty of support with Carthage, and Pyrrhus found that despite his expectations, none of the other Italic peoples would defect to the Greek and Samnite cause. Facing unacceptably heavy losses with each encounter with the Roman army, and failing to find further allies in Italy, Pyrrhus withdrew from the peninsula and campaigned in Sicily against Carthage, abandoning his allies to deal with the Romans.

When his Sicilian campaign was also ultimately a failure, and at the request of his Italian allies, Pyrrhus returned to Italy to face Rome once more. In 275 BC, Pyrrhus again met the Roman army at the Battle of Beneventum. This time the Romans had devised methods to deal with the war elephants, including the use of javelins, fire and, one source claims, simply hitting the elephants heavily on the head. While Beneventum was indecisive, Pyrrhus realised that his army had been exhausted and reduced by years of foreign campaigns, and seeing little hope for further gains, he withdrew completely from Italy.

The conflicts with Pyrrhus would have a great effect on Rome. It had shown that it was capable of pitting its armies successfully against the dominant military powers of the Mediterranean, and further showed that the Greek kingdoms were incapable of defending their colonies in Italy and abroad. Rome quickly moved into southern Italia, subjugating and dividing Magna Grecia. Effectively dominating the Italian peninsula, and with a proven international military reputation, Rome now began to look to expand from the Italian mainland. Since the Alps formed a natural barrier to the north, and Rome was none too keen to meet the fierce Gauls in battle once more, the city's gaze turned to Sicily and the islands of the Mediterranean, a policy that would bring it into direct conflict with its former ally Carthage.

Rome first began to make war outside the Italian peninsula during the Punic wars against Carthage, a former Phoenician colony that had established on the north coast of Africa and developed into a powerful state. These wars, starting in 264 BC were probably the largest conflicts of the ancient world yet and saw Rome become the most powerful state of the Western Mediterranean, with territory in Sicily, North Africa, Iberia, and with the end of the Macedonian wars (which ran concurrently with the Punic wars) Greece as well. After the defeat of the Seleucid Emperor Antiochus III the Great in the Roman-Syrian War (Treaty of Apamea, 188 BC) in the eastern sea, Rome emerged as the dominant Mediterranean power and the most powerful city in the classical world.

The First Punic War began in 264 BC when settlements on Sicily began to appeal to the two powers between which they lay – Rome and Carthage – in order to solve internal conflicts. The willingness of both Rome and Carthage to become embroiled on the soil of a third party may indicate a willingness to test each other's power without wishing to enter a full war of annihilation; certainly there was considerable disagreement within Rome about whether to prosecute the war at all. The war saw land battles in Sicily early on, such as the Battle of Agrigentum, but the theatre shifted to naval battles around Sicily and Africa. For the Romans, naval warfare was a relatively unexplored concept. Before the First Punic War in 264 BC there was no Roman navy to speak of, as all previous Roman wars had been fought on land in Italy. The new war in Sicily against Carthage, a great naval power, forced Rome to quickly build a fleet and train sailors.

Rome took to naval warfare "like a brick to water" and the first few naval battles of the First Punic War such as the Battle of the Lipari Islands were catastrophic disasters for Rome, as might fairly be expected from a city that had no real prior experience of naval warfare. However, after training more sailors and inventing a grappling engine known as a Corvus, a Roman naval force under C. Duillius was able to roundly defeat a Carthaginian fleet at the Battle of Mylae. In just four years, a state without any real naval experience had managed to better a major regional maritime power in battle. Further naval victories followed at the Battle of Tyndaris and the Battle of Cape Ecnomus.

After having won control of the seas, a Roman force landed on the African coast under Marcus Regulus, who was at first victorious, winning the Battle of Adys and forcing Carthage to sue for peace. However, the terms of peace that Rome proposed were so heavy that negotiations failed, and in response, the Carthaginians hired Xanthippus of Carthage, a mercenary from the martial Greek city-state of Sparta, to reorganise and lead their army. Xanthippus managed to cut off the Roman army from its base by re-establishing Carthaginian naval supremacy and then defeated and captured Regulus at the Battle of Tunis.

Despite being defeated on African soil, the Romans with their newfound naval abilities, roundly beat the Carthaginians in naval battle again – largely through the tactical innovations of the Roman fleet – at the Battle of the Aegates Islands. Carthage was left without a fleet or sufficient coin to raise a new one. For a maritime power, the loss of their access to the Mediterranean stung financially and psychologically, and the Carthaginians again sued for peace, during which negotiations, Rome battled the "Ligures" tribe in the Ligurian War and the "Insubres" in the Gallic War.

Continuing distrust led to the renewal of hostilities in the Second Punic War when Hannibal Barca, a member of the Barcid family of Carthaginian nobility, attacked Saguntum, a city with diplomatic ties to Rome. Hannibal then raised an army in Iberia and famously crossed the Italian Alps with elephants to invade Italy. In the first battle on Italian soil at Ticinus in 218 BC Hannibal defeated the Romans under Scipio the Elder in a small cavalry fight. Hannibal's success continued with victories in the Battle of the Trebia, the Battle of Lake Trasimene, where he ambushed an unsuspecting Roman army, and the Battle of Cannae, in what is considered one of the great masterpieces of tactical art, and for a while "Hannibal seemed invincible", able to beat Roman armies at will.

In the three battles of Nola, Roman general Marcus Claudius Marcellus managed to hold off Hannibal but then Hannibal smashed a succession of Roman consular armies at the First Battle of Capua, the Battle of the Silarus, the Second Battle of Herdonia, the Battle of Numistro and the Battle of Asculum. By this time Hannibal's brother Hasdrubal Barca sought to cross the Alps into Italy and join his brother with a second army. Despite being defeated in Iberia in the Battle of Baecula, Hasdrubal managed to break through into Italy only to be defeated decisively by Gaius Claudius Nero and Marcus Livius Salinator on the Metaurus River.

Unable to defeat Hannibal himself on Italian soil, and with Hannibal savaging the Italian countryside but unwilling or unable to destroy Rome itself, the Romans boldly sent an army to Africa with the intention of threatening the Carthaginian capital. In 203 BC at the Battle of Bagbrades the invading Roman army under Scipio Africanus Major defeated the Carthaginian army of Hasdrubal Gisco and Syphax and Hannibal was recalled to Africa. At the famous Battle of Zama Scipio decisively defeated – perhaps even "annihilated" – Hannibal's army in North Africa, ending the Second Punic War.

Carthage never managed to recover after the Second Punic War and the Third Punic War that followed was in reality a simple punitive mission to raze the city of Carthage to the ground. Carthage was almost defenceless and when besieged offered immediate surrender, conceding to a string of outrageous Roman demands. The Romans refused the surrender, demanding as their further terms of surrender the complete destruction of the city and, seeing little to lose, the Carthaginians prepared to fight. In the Battle of Carthage the city was stormed after a short siege and completely destroyed, its culture "almost totally extinguished".

Rome's conflict with the Carthaginians in the Punic Wars led them into expansion in the Iberian peninsula of modern-day Spain and Portugal. The Punic empire of the Carthaginian Barcid family consisted of territories in Iberia, many of which Rome gained control of during the Punic Wars. Italy remained the main theatre of war for much of the Second Punic War, but the Romans also aimed to destroy the Barcid Empire in Iberia and prevent major Punic allies from linking up with forces in Italy.

Over the years, Rome had expanded along the southern Iberian coast until in 211 BC it captured the city of Saguntum. Following two major military expeditions to Iberia, the Romans finally crushed Carthaginian control of the peninsula in 206 BC, at the Battle of Ilipa, and the peninsula became a Roman province known as Hispania. From 206 BC onwards the only opposition to Roman control of the peninsula came from within the native Celtiberian tribes themselves, whose disunity prevented their security from Roman expansion. Following two small-scale rebellions in 197 BC, in 195–194 BC war broke out between the Romans and the Lusitani people in the Lusitanian War, in modern-day Portugal. By 179 BC, the Romans had mostly succeeded in pacifying the region and bringing it under their control.

About 154 BC, a major revolt was re-ignited in Numantia, which is known as the First Numantine War, and a long war of resistance was fought between the advancing forces of the Roman Republic and the Lusitani tribes of Hispania. The praetor Servius Sulpicius Galba and the proconsul Lucius Licinius Lucullus arrived in 151 BC and began the process of subduing the local population. In 150 BC, Galba betrayed the Lusitani leaders he had invited to peace talks and had them killed, ingloriously ending the first phase of the war.

The Lusitani revolted again in 146 BC under a new leader called Viriathus, invading Turdetania (southern Iberia) in a guerrilla war. The Lusitanians were initially successful, defeating a Roman army at the Battle of Tribola and going on to sack nearby Carpetania, and then besting a second Roman army at the First Battle of Mount Venus in 146 BC, again going on to sack another nearby city. In 144 BC, the general Quintus Fabius Maximus Aemilianus campaigned successfully against the Lusitani, but failed in his attempts to arrest Viriathus.

In 144 BC, Viriathus formed a league against Rome with several Celtiberian tribes and persuaded them to rise against Rome too, in the Second Numantine War. Viriathus' new coalition bested Roman armies at the Second Battle of Mount Venus in 144 BC and again at the failed Siege of Erisone. In 141 BC, Viriathus enjoyed his greatest victory when he surrounded a consular army and forced it to surrender on condition that its men did not fight in Spain again. No sooner were they free than the Romans reneged on the agreement and returned to the attack. In 139 BC, Viriathus was finally killed in his sleep by three of his companions who had been promised gifts by Rome. The Celtiberians continued to resist, forcing the surrender of another Roman army at Numantia in 137 BC. In 134 BC, the Consul Scipio Aemilianus finally succeeded in suppressing the rebellion following the successful Siege of Numantia. In 105 BC, the Celtiberians still retained enough of their native vigour and ferocity to drive the Cimbri and Teutones from Spain, though these had crushed Roman arms in Narbonese Gaul, inflicting 80,000 casualties on the Roman army which opposed them.

Since the Roman invasion of the Iberian peninsula had begun in the south in the territories around the Mediterranean controlled by the Barcids, the last region of the peninsula to be subdued lay in the far north. The Cantabrian Wars or Astur-Cantabrian Wars, from 29 BC to 19 BC, occurred during the Roman conquest of these northern provinces of Cantabria and Asturias. Iberia was fully occupied by 25 BC and the last revolt put down by 19 BC—but at heavy cost and severe losses.

Rome's preoccupation with its war with Carthage provided an opportunity for Philip V of the kingdom of Macedon in northern Greece to attempt to extend his power westward. Philip sent ambassadors to Hannibal's camp in Italy, to negotiate an alliance as common enemies of Rome. However, Rome discovered the agreement when Philip's emissaries, along with emissaries from Hannibal, were captured by a Roman fleet. Desiring to prevent Philip from aiding Carthage in Italy and elsewhere, Rome sought out land allies in Greece to fight a proxy war against Macedon on its behalf and found partners in the Aetolian League of Greek city-states, the Illyrians to the north of Macedon and the kingdom of Pergamon and the city-state of Rhodes, which lay across the Aegean from Macedon.

The First Macedonian War saw the Romans involved directly in only limited land operations. When the Aetolians sued for peace with Philip, Rome's small expeditionary force, with no more allies in Greece, was ready to make peace. Rome had achieved its objective of pre-occupying Philip and preventing him from aiding Hannibal. A treaty was drawn up between Rome and Macedon at Phoenice in 205 BC which promised Rome a small indemnity, formally ending the First Macedonian War.

Macedon began to encroach on territory claimed by several other Greek city states in 200 BC and these pleaded for help from their newfound ally Rome. Rome gave Philip an ultimatum that he must submit Macedonia to being essentially a Roman province. Philip, unsurprisingly, refused and, after initial internal reluctance for further hostilities, Rome declared war against Philip in the Second Macedonian War. In the Battle of the Aous Roman forces under Titus Quinctius Flamininus defeated the Macedonians, and in a second larger battle under the same opposing commanders in 197 BC, in the Battle of Cynoscephalae, Flamininus again beat the Macedonians decisively. Macedonia was forced to sign the Treaty of Tempea, in which it lost all claim to territory in Greece and Asia, and had to pay a war indemnity to Rome.

Between the second and third Macedonian wars Rome faced further conflict in the region due to a tapestry of shifting rivalries, alliances and leagues all seeking to gain greater influence. After the Macedonians had been defeated in the Second Macedonian War in 197 BC, the Greek city-state of Sparta stepped into the partial power vacuum in Greece. Fearing the Spartans would take increasing control of the region, the Romans drew on help from allies to prosecute the Roman-Spartan War, defeating a Spartan army at the Battle of Gythium in 195 BC. They also fought their former allies the Aetolian League in the Aetolian War, against the Istrians in the Istrian War, against the Illyrians in the Illyrian War, and against Achaia in the Achaean War.

Rome now turned its attentions to Antiochus III of the Seleucid Empire to the east. After campaigns as far abroad as Bactria, India, Persia and Judea, Antiochus moved to Asia Minor and Thrace to secure several coastal towns, a move that brought him into conflict with Roman interests. A Roman force under Manius Acilius Glabrio defeated Antiochus at the Battle of Thermopylae and forced him to evacuate Greece: the Romans then pursued the Seleucids beyond Greece, beating them again in naval battles at the Battle of the Eurymedon and Battle of Myonessus, and finally in a decisive engagement of the Battle of Magnesia.

In 179 BC Philip died and his talented and ambitious son, Perseus of Macedon, took his throne and showed a renewed interest in Greece. He also allied himself with the warlike Bastarnae, and both this and his actions in Greece possibly violated the treaty signed with the Romans by his father or, if not, certainly was not "behaving as [Rome considered] a subordinate ally should". Rome declared war on Macedonia again, starting the Third Macedonian War. Perseus initially had greater military success against the Romans than his father, winning the Battle of Callicinus against a Roman consular army. However, as with all such ventures in this period, Rome responded by simply sending another army. The second consular army duly defeated the Macedonians at the Battle of Pydna in 168 BC and the Macedonians, lacking the reserve of the Romans and with King Perseus captured, duly capitulated, ending the Third Macedonian War.

The Fourth Macedonian War, fought from 150 BC to 148 BC, was the final war between Rome and Macedon and began when Andriscus usurped the Macedonian throne. The Romans raised a consular army under Quintus Caecilius Metellus, who swiftly defeated Andriscus at the Second battle of Pydna.

Under Lucius Mummius, Corinth was destroyed following a siege in 146 BC, leading to the surrender and thus conquest of the Achaean League (see Battle of Corinth).

Rome had, in the earlier Punic Wars, gained large tracts of territory in Africa, which they consolidated in the following centuries. Much of that land had been granted to the kingdom of Numidia, a kingdom on the north African coast approximating to modern Algeria, in return for its past military assistance. The Jugurthine War of 111–104 BC was fought between Rome and Jugurtha of Numidia and constituted the final Roman pacification of Northern Africa, after which Rome largely ceased expansion on the continent after reaching natural barriers of desert and mountain. In response to Jugurtha's usurpation of the Numidian throne, a loyal ally of Rome since the Punic Wars, Rome intervened. Jugurtha impudently bribed the Romans into accepting his usurpation and was granted half the kingdom. Following further aggression and further bribery attempts, the Romans sent an army to depose him. The Romans were defeated at the Battle of Suthul but fared better at the Battle of the Muthul and finally defeated Jugurtha at the Battle of Thala, the Battle of Mulucha, and the Battle of Cirta (104 BC). Jugurtha was finally captured not in battle but by treachery, ending the war.

Memories of the sack of Rome by Celtic tribes from Gaul in 390/387 BC, had been made into a legendary account that was taught to each generation of Roman youth, were still prominent despite their historical distance. In 121 BC, Rome came into contact with the Celtic tribes of the Allobroges and the Arverni, both of which they defeated with apparent ease in the First Battle of Avignon near the Rhone river and the Second Battle of Avignon, the same year.

The Cimbrian War (113–101 BC) was a far more serious affair than the earlier clashes of 121 BC. The Germanic tribes of the "Cimbri" and the "Teutons" or "Teutones" migrated from northern Europe into Rome's northern territories, where they clashed with Rome and her allies. The Cimbrian War was the first time since the Second Punic War that Italia and Rome itself had been seriously threatened, and caused great fear in Rome. The opening action of the Cimbrian War, the Battle of Noreia in 112 BC, ended in defeat and near disaster for the Romans. In 105 BC the Romans were defeated at the Battle of Arausio and was the costliest Rome had suffered since the Battle of Cannae. After the Cimbri inadvertently granted the Romans a reprieve by diverting to plunder Iberia, Rome was given the opportunity to carefully prepare for and successfully meet the Cimbri and Teutons in the Battle of Aquae Sextiae (102 BC) and the Battle of Vercellae (101 BC) where both tribes were virtually annihilated, ending the threat.

The extensive campaigning abroad by Rome, and the rewarding of soldiers with plunder from those campaigns, led to the trend of soldiers becoming increasingly loyal to their commanders rather than to the state, and a willingness to follow their generals in battle against the state. Rome was plagued by several slave uprisings during this period, in part because in the past century vast tracts of land had been given to veterans who farmed by use of slaves and who came to greatly outnumber their Roman masters. In the last century BC, at least twelve civil wars and rebellions occurred. This pattern did not break until Octavian (later "Caesar Augustus") ended it by becoming a successful challenger to the Senate's authority, and was made "princeps" (emperor).

Between 135 BC and 71 BC there were three Servile Wars against the Roman state; the third, and most serious, may have involved the revolution of 120,000 to 150,000 slaves. Additionally, in 91 BC the Social War broke out between Rome and its former allies in Italy, collectively known as the "Socii", over the grievance that they shared the risk of Rome's military campaigns, but not its rewards. Despite defeats such as the Battle of Fucine Lake, Roman troops defeated the Italian militias in decisive engagements, notably the Battle of Asculum. Although they lost militarily, the "Socii" achieved their objectives with the legal proclamations of the "Lex Julia" and "Lex Plautia Papiria", which granted citizenship to more than 500,000 Italians.

The internal unrest reached its most serious stage in the two civil wars or marches upon Rome by the consul Lucius Cornelius Sulla at the beginning of 82 BC. In the Battle of the Colline Gate at the very door of the city of Rome, a Roman army under Sulla bested an army of the Roman senate and its Samnite allies. Whatever the merits of his grievances against those in power of the state, his actions marked a watershed of the willingness of Roman troops to wage war against one another that was to pave the way for the wars of the triumvirate, the overthrowing of the Senate as the "de facto" head of the Roman state, and the eventual endemic usurpation of power by contenders for the emperor-ship in the later Empire.

Mithridates the Great was the ruler of Pontus, a large kingdom in Asia Minor, from 120 to 63 BC. He is remembered as one of Rome's most formidable and successful enemies who engaged three of the most prominent generals of the late Roman Republic: Sulla, Lucullus, and Pompey the Great. In a pattern familiar from the Punic Wars, the Romans came into conflict with him after the two states' spheres of influence began to overlap. Mithridates antagonised Rome by seeking to expand his kingdom, and Rome for her part seemed equally keen for war and the spoils and prestige that it might bring. After conquering western Anatolia (modern Turkey) in 88 BC, Roman sources claim that Mithridates ordered the killing of the majority of the 80,000 Romans living there. In the subsequent First Mithridatic War, the Roman general Lucius Cornelius Sulla forced Mithridates out of Greece proper after the Battle of Chaeronea and later Battle of Orchomenus but then had to return to Italy to answer the internal threat posed by his rival Marius; consequently, Mithridates VI was defeated but not destroyed. A peace was made between Rome and Pontus, but this proved only a temporary lull.

The Second Mithridatic War began when Rome tried to annex Bithynia as a province. In the Third Mithridatic War, first Lucius Licinius Lucullus and then Pompey the Great were sent against Mithridates. Mithridates was finally defeated by Pompey in the night-time Battle of the Lycus. After defeating Mithridates, Pompey invaded Caucacus, subjugated the Kingdom of Iberia and established Roman control over Colchis.

The Mediterranean had at this time fallen into the hands of pirates, largely from Cilicia. Rome had destroyed many of the states that had previously policed the Mediterranean with fleets, but had failed to step into the gap created. The pirates had seized the opportunity of a relative power vacuum and had not only strangled shipping lanes but had plundered many cities on the coasts of Greece and Asia, and had even made descents upon Italy itself. After the Roman admiral Marcus Antonius Creticus (father of the triumvir Marcus Antonius) failed to clear the pirates to the satisfaction of the Roman authorities, Pompey was nominated his successor as commander of a special naval task force to campaign against them. It supposedly took Pompey just forty days to clear the western portion of the western Mediterranean of pirates, and restore communication between Iberia, Africa, and Italy. Plutarch describes how Pompey first swept their craft from the Mediterranean in a series of small actions and through the promise of honouring the surrender of cities and craft. He then followed the main body of the pirates to their strongholds on the coast of Cilicia, and destroyed them there in the naval Battle of Korakesion.

During a term as praetor in Iberia, Pompey's contemporary Julius Caesar of the Roman Julii clan defeated the Calaici and Lusitani in battle. Following a consular term, he was then appointed to a five-year term as Proconsular Governor of Transalpine Gaul (current southern France) and Illyria (the coast of Dalmatia). Not content with an idle governorship, Caesar strove to find reason to invade Gaul, which would give him the dramatic military success he sought. To this end he stirred up popular nightmares of the first sack of Rome by the Gauls and the more recent spectre of the Cimbri and Teutones. When the Helvetii and Tigurini tribes began to migrate on a route that would take them near (not into) the Roman province of Transalpine Gaul, Caesar had the barely sufficient excuse he needed for his Gallic Wars, fought between 58 BC and 49 BC. After slaughtering the Helvetii tribe, Caesar prosecuted a "long, bitter and costly" campaign against other tribes across the breadth of Gaul, many of whom had fought alongside Rome against their common enemy the Helvetii, and annexed their territory to that of Rome. Although "fierce and able" the Gauls were handicapped by internal disunity and fell in a series of battles over the course of a decade.

Caesar defeated the "Helvetii" in 58 BC at the Battle of the Arar and Battle of Bibracte, the Belgic confederacy known as the "Belgae" at the Battle of the Axona, the "Nervii" in 57 BC at the Battle of the Sabis, the "Aquitani", "Treviri", "Tencteri", "Aedui" and "Eburones" in unknown battles, and the "Veneti" in 56 BC. In 55 and 54 BC he made two expeditions to Britain. In 52 BC, following the Siege of Avaricum and a string of inconclusive battles, Caesar defeated a union of Gauls led by Vercingetorix at the Battle of Alesia, completing the Roman conquest of Transalpine Gaul. By 50 BC, the entirety of Gaul lay in Roman hands. Caesar recorded his own accounts of these campaigns in "Commentarii de Bello Gallico" ("Commentaries on the Gallic War").

According to Plutarch and the writings of scholar Brendan Woods, the whole campaign resulted in 800 conquered cities, 300 subdued tribes, one million men sold into slavery, and another three million dead in battle.

Gaul never regained its Celtic identity, never attempted another nationalist rebellion, and remained loyal to Rome until the fall of the Western Empire in 476 AD. However, although Gaul itself was to thereafter remain loyal, cracks were appearing in the political unity of Rome's governing figures – partly over concerns over the loyalty of Caesar's Gallic troops to his person rather than the state – that were soon to drive Rome into a lengthy series of civil wars.

By 59 BC an unofficial political alliance known as the First Triumvirate was formed between Gaius Julius Caesar, Marcus Licinius Crassus, and Gnaeus Pompeius Magnus to share power and influence. It was always an uncomfortable alliance given that Crassus and Pompey intensely disliked one another. In 53 BC, Crassus launched a Roman invasion of the Parthian Empire. After initial successes, he marched his army deep into the desert; but here his army was cut off deep in enemy territory, surrounded and slaughtered at the Battle of Carrhae in "the greatest Roman defeat since Hannibal" in which Crassus himself perished. The death of Crassus removed some of the balance in the Triumvirate and, consequently, Caesar and Pompey began to move apart. While Caesar was fighting against Vercingetorix in Gaul, Pompey proceeded with a legislative agenda for Rome that revealed that he was at best ambivalent towards Caesar and perhaps now covertly allied with Caesar's political enemies. In 51 BC, some Roman senators demanded that Caesar would not be permitted to stand for Consul unless he turned over control of his armies to the state, and the same demands were made of Pompey by other factions. Relinquishing his army would leave Caesar defenceless before his enemies. Caesar chose Civil War over laying down his command and facing trial. The triumvirate was shattered and conflict was inevitable.

Pompey initially assured Rome and the senate that he could defeat Caesar in battle should he march on Rome. However, by the spring of 49 BC, when Caesar crossed the Rubicon river with his invading forces and swept down the Italian peninsula towards Rome, Pompey ordered the abandonment of Rome. Caesar's army was still under-strength, with certain units remaining in Gaul, but on the other hand Pompey himself only had a small force at his command, and that with uncertain loyalty having served under Caesar. Tom Holland attributes Pompey's willingness to abandon Rome to waves of panicking refugees as an attempt to stir ancestral fears of invasions from the north. Pompey's forces retreated south towards Brundisium, and then fled to Greece. Caesar first directed his attention to the Pompeian stronghold of Iberia but following campaigning by Caesar in the Siege of Massilia and Battle of Ilerda he decided to attack Pompey in Greece. Pompey initially defeated Caesar at the Battle of Dyrrachium in 48 BC but failed to follow up on the victory. Pompey was decisively defeated in the Battle of Pharsalus in 48 BC despite outnumbering Caesar's forces two to one. Pompey fled again, this time to Egypt, where he was murdered in an attempt to ingratiate the country with Caesar and avoid a war with Rome.

Pompey's death did not see the end of the civil wars since initially Caesar's enemies were manifold and Pompey's supporters continued to fight on after his death. In 46 BC Caesar lost perhaps as much as a third of his army when his former commander Titus Labienus, who had defected to the Pompeians several years earlier, defeated him at the Battle of Ruspina. However, after this low point Caesar came back to defeat the Pompeian army of Metellus Scipio in the Battle of Thapsus, after which the Pompeians retreated yet again to Iberia. Caesar defeated the combined forces of Titus Labienus and Gnaeus Pompey the Younger at the Battle of Munda in Iberia. Labienus was killed in the battle and the Younger Pompey captured and executed.

Despite his military success, or probably because of it, fear spread of Caesar, now the primary figure of the Roman state, becoming an autocratic ruler and ending the Roman Republic. This fear drove a group of senators naming themselves The Liberators to assassinate him in 44 BC. Further civil war followed between those loyal to Caesar and those who supported the actions of the Liberators. Caesar's supporter Mark Antony condemned Caesar's assassins and war broke out between the two factions. Antony was denounced as a public enemy, and Octavian was entrusted with the command of the war against him. In the Battle of Forum Gallorum Antony, besieging Caesar's assassin Decimus Brutus in Mutina, defeated the forces of the consul Pansa, who was killed, but Antony was then immediately defeated by the army of the other consul, Hirtius. At the Battle of Mutina Antony was again defeated in battle by Hirtius, who was killed. Although Antony failed to capture Mutina, Decimus Brutus was murdered shortly thereafter.

Octavian betrayed his party, and came to terms with Caesarians Antony and Lepidus and on 26 November 43 BC the Second Triumvirate was formed, this time in an official capacity. In 42 BC Triumvirs Mark Antony and Octavian fought the indecisive Battle of Philippi with Caesar's assassins Marcus Brutus and Cassius. Although Brutus defeated Octavian, Antony defeated Cassius, who committed suicide. Brutus also committed suicide shortly afterwards.

Civil war flared again when the Second Triumvirate of Octavian, Lepidus and Mark Antony failed just as the first had almost as soon as its opponents had been removed. The ambitious Octavian built a power base and then launched a campaign against Mark Antony. Together with Lucius Antonius, Mark Antony's wife Fulvia raised an army in Italy to fight for Antony's rights against Octavian but she was defeated by Octavian at the Battle of Perugia. Her death led to partial reconciliation between Octavian and Antony who went on to crush the army of Sextus Pompeius, the last focus of opposition to the second triumvirate, in the naval Battle of Naulochus.

As before, once opposition to the triumvirate was crushed, it started to tear at itself. The triumvirate expired on the last day of 33 BC and was not renewed in law and in 31 BC, war began again. At the Battle of Actium, Octavian decisively defeated Antony and Cleopatra in a naval battle near Greece, using fire to destroy the enemy fleet.

Octavian went on to become Emperor under the name Augustus and, in the absence of political assassins or usurpers, was able to greatly expand the borders of the Empire.

Secure from interior enemies, Rome achieved great territorial gains in both the East and the West. In the West, following humiliating defeats at the hands of the Sugambri, Tencteri and Usipetes tribes in 16 BC, Roman armies pushed north and east out of Gaul to subdue much of Germania. The Pannonian revolt in 6 AD forced the Romans to cancel their plan to cement their conquest of Germania. Despite the loss of a large army almost to the man of Varus' famous defeat at the hands of the Germanic leader Arminius in the Battle of the Teutoburg Forest in 9 AD, Rome recovered and continued its expansion up to and beyond the borders of the known world. Roman armies under Germanicus pursued several more campaigns against the Germanic tribes of the Marcomanni, Hermunduri, Chatti, Cherusci, Bructeri, and Marsi. Overcoming several mutinies in the armies along the Rhine, Germanicus defeated the Germanic tribes of Arminius in a series of battles culminating in the Battle of the Weser River.

After Caesar's preliminary low-scale invasions of Britain, the Romans invaded in force in 43 AD, forcing their way inland through several battles against British tribes, including the Battle of the Medway, the Battle of the Thames, the Battle of Caer Caradoc and the Battle of Mona. Following a general uprising in which the Britons sacked Colchester, St Albans and London, the Romans suppressed the rebellion in the Battle of Watling Street and went on to push as far north as central Scotland in the Battle of Mons Graupius. The Britons fought with determination and resilience, but faced a superior, professional army, and it is likely that between 100,000 and 250,000 may have perished in the conquest period.

Tribes in modern-day Scotland and Northern England repeatedly rebelled against Roman rule and two military bases were established in Britannia to protect against rebellion and incursions from the north, from which Roman troops built and manned Hadrian's Wall.

On the continent, the extension of the Empire's borders beyond the Rhine hung in the balance for some time, with the emperor Caligula apparently poised to invade Germania in 39 AD, and Cnaeus Domitius Corbulo crossing the Rhine in 47 AD and marching into the territory of the Frisii and Chauci. Caligula's successor, Claudius, ordered the suspension of further attacks across the Rhine, setting what was to become the permanent limit of the Empire's expansion in this direction.

Further east, Trajan turned his attention to Dacia, an area north of Macedon and Greece and east of the Danube that had been on the Roman agenda since before the days of Caesar when they had beaten a Roman army at the Battle of Histria. In 85 AD, the Dacians had swarmed over the Danube and pillaged Moesia and initially defeated an army the Emperor Domitian sent against them, but the Romans were victorious in the Battle of Tapae in AD 88 and a truce was drawn up.

Emperor Trajan recommenced hostilities against Dacia and, following an uncertain number of battles, defeated the Dacian general Decebalus in the Second Battle of Tapae in 101 AD. With Trajan's troops pressing towards the Dacian capital Sarmizegethusa, Decebalus once more sought terms. Decebalus rebuilt his power over the following years and attacked Roman garrisons again in 105 AD. In response Trajan again marched into Dacia, besieging the Dacian capital in the Siege of Sarmizethusa, and razing it to the ground. With Dacia quelled, Trajan subsequently invaded the Parthian empire to the east, his conquests taking the Roman Empire to its greatest extent. Rome's borders in the east were indirectly governed through a system of client states for some time, leading to less direct campaigning than in the west in this period.

The Kingdom of Armenia between the Black Sea and Caspian Sea became a focus of contention between Rome and the Parthian Empire, and control of the region was repeatedly gained and lost. The Parthians forced Armenia into submission from 37 AD but in 47 AD the Romans retook control of the kingdom and offered it client kingdom status. Under Nero, the Romans fought a campaign between 55 and 63 AD against the Parthian Empire, which had again invaded Armenia. After gaining Armenia once more in 60 AD and subsequently losing it again in 62 AD, the Romans sent Gnaeus Domitius Corbulo in 63 AD into the territories of Vologases I of Parthia. Corbulo succeeded in returning Armenia to Roman client status, where it remained for the next century.

In 69 AD, Marcus Salvius Otho, governor of Lusitania, had the Emperor Galba murdered and claimed the throne for himself. However, Vitellius, governor of the province of Germania Inferior, had also claimed the throne and marched on Rome with his troops. Following an inconclusive battle near Antipolis, Vitellius' troops attacked the city of Placentia in the Assault of Placentia, but were repulsed by the Othonian garrison.

Otho left Rome on March 14, and marched north towards Placentia to meet his challenger. In the Battle of Locus Castorum the Othonians had the better of the fighting, and Vitellius' troops retreated to Cremona. The two armies met again on the Via Postunia, in the First Battle of Bedriacum, after which the Othonian troops fled back to their camp in Bedriacum, and the next day surrendered to the Vitellian forces. Otho decided to commit suicide rather than fight on.

Meanwhile, the forces stationed in the Middle East provinces of Judaea and Syria had acclaimed Vespasian as emperor and the Danubian armies of the provinces of Raetia and Moesia also acclaimed Vespasian as emperor. Vespasian's and Vitellius' armies met in the Second Battle of Bedriacum, after which the Vitellian troops were driven back into their camp outside Cremona, which was taken. Vespasian's troops then attacked Cremona itself, which surrendered.

Under pretence of siding with Vespasian, Civilis of Batavia had taken up arms and induced the inhabitants of his native country to rebel. The rebelling Batavians were immediately joined by several neighbouring German tribes including the Frisii. These forces drove out the Roman garrisons near the Rhine and defeated a Roman army at the Battle of Castra Vetera, after which many Roman troops along the Rhine and in Gaul defected to the Batavian cause. However, disputes soon broke out amongst the different tribes, rendering co-operation impossible; Vespasian, having successfully ended the civil war, called upon Civilis to lay down his arms, and on his refusal his legions met him in force, defeating him in the Battle of Augusta Treverorum.

The first Jewish-Roman War, sometimes called The Great Revolt, was the first of three major rebellions by the Jews of Judaea Province against the Roman Empire. Judea was already a troubled region with bitter violence among several competing Jewish sects and a long history of rebellion The Jews' anger turned on Rome following robberies from their temples and Roman insensitivity – Tacitus says disgust and repulsion – towards their religion. The Jews began to prepare for armed revolt. Early successes, including the repulse of the First Siege of Jerusalem and the Battle of Beth-Horon, only attracted greater attention from Rome and Emperor Nero appointed general Vespasian to crush the rebellion. Vespasian led his forces in a methodical clearance of the areas in revolt. By the year 68 AD, Jewish resistance in the North had been crushed. A few towns and cities held out for a few years before falling to the Romans, leading to the Siege of Masada in 73 AD and the Second Siege of Jerusalem. Jerusalem was sacked and much of the population killed or dispersed. Josephus claims that 1,100,000 people were killed during the siege, of which a majority were Jewish. 97,000 were captured and enslaved, including Simon bar Giora and John of Giscala.

In 115 AD, revolt broke out again in the province, leading to the second Jewish-Roman war known as the Kitos War, and again in 132 AD in what is known as Bar Kokhba's revolt. Both were brutally crushed.

By the 2nd century AD the territories of Persia were controlled by the Arsacid dynasty and known as the Parthian Empire. Due in large part to their employment of powerful heavy cavalry and mobile horse archers, Parthia was the most formidable enemy of the Roman Empire in the east. As early as 53 BC, the Roman general Crassus had invaded Parthia, but he was killed and his army was defeated at the Battle of Carrhae. In the years following Carrhae, the Romans were divided in civil war and hence unable to campaign against Parthia. Trajan also campaigned against the Parthians from 114–117 AD and briefly captured their capital Ctesiphon, putting the puppet ruler Parthamaspates on the throne. However, rebellions in Babylonia and the Jewish revolts in Judea made it difficult to maintain the captured province and the territories were abandoned.

A revitalised Parthian Empire renewed its assault in 161 AD, defeating two Roman armies and invading Armenia and Syria. Emperor Lucius Verus and general Gaius Avidius Cassius were sent in 162 AD to counter the resurgent Parthia. In this war, the Parthian city of Seleucia on the Tigris was destroyed and the palace at the capital Ctesiphon was burned to the ground by Avidius Cassius in 164 AD. The Parthians made peace but were forced to cede western Mesopotamia to the Romans.

In 197 AD, Emperor Septimius Severus waged a brief and successful war against the Parthian Empire in retaliation for the support given to a rival for the imperial throne Pescennius Niger. The Parthian capital Ctesiphon was sacked by the Roman army, and the northern half of Mesopotamia was restored to Rome.

Emperor Caracalla, the son of Severus, marched on Parthia in 217 AD from Edessa to begin a war against them, but he was assassinated while on the march. In 224 AD, the Parthian Empire was crushed not by the Romans but by the rebellious Persian vassal king Ardashir I, who revolted, leading to the establishment of Sassanid Empire of Persia, which replaced Parthia as Rome's major rival in the East.

Throughout the Parthian wars, tribal groups along the Rhine and Danube took advantage of Rome's preoccupation with the eastern frontier (and the plague that the Romans suffered from after bringing it back from the east) and launched a series of incursions into Roman territories, including the Marcomannic Wars.

After Varus' defeat in Germania in the 1st century, Rome had adopted a largely defensive strategy along the border with Germania, constructing a line of defences known as "limes" along the Rhine. Although the exact historicity is unclear, since the Romans often assigned one name to several distinct tribal groups, or conversely applied several names to a single group at different times, some mix of Germanic peoples, Celts, and tribes of mixed Celto-Germanic ethnicity were settled in the lands of Germania from the 1st century onwards. The Cherusci, Bructeri, Tencteri, Usipi, Marsi, and Chatti of Varus' time had by the 3rd century either evolved into or been displaced by a confederacy or alliance of Germanic tribes collectively known as the Alamanni, first mentioned by Cassius Dio describing the campaign of Caracalla in 213 AD.

In around 166 AD, several Germanic tribes pushed across the Danube, striking as far as Italy itself in the Siege of Aquileia in 166 AD, and the heartland of Greece in the Sack of Eleusis.

Although the essential problem of large tribal groups on the frontier remained much the same as the situation Rome faced in earlier centuries, the 3rd century saw a marked increase in the overall threat, although there is disagreement over whether external pressure increased, or Rome's ability to meet it declined. The Carpi and Sarmatians whom Rome had held at bay were replaced by the Goths and likewise the Quadi and Marcomanni that Rome had defeated were replaced by the greater confederation of the Alamanni.

The assembled warbands of the Alamanni frequently crossed the "limes", attacking Germania Superior such that they were almost continually engaged in conflicts with the Roman Empire, whilst Goths attacked across the Danube in battles such as the Battle of Beroa and Battle of Philippopolis in 250 AD and the Battle of Abrittus in 251 AD, and both Goths and Heruli ravaged the Aegean and, later, Greece, Thrace and Macedonia. However, their first major assault deep into Roman territory came in 268 AD. In that year the Romans were forced to denude much of their German frontier of troops in response to a massive invasion by another new Germanic tribal confederacy, the Goths, from the east. The pressure of tribal groups pushing into the Empire was the end result of a chain of migrations with its roots far to the east: Huns from the Russian steppe attacked the Goths, who in turn attacked the Dacians, Alans and Sarmatians at or within Rome's borders. The Goths first appeared in history as a distinct people in this invasion of 268 AD when they swarmed over the Balkan peninsula and overran the Roman provinces of Pannonia and Illyricum and even threatened Italia itself.

The Alamanni seized the opportunity to launch a major invasion of Gaul and northern Italy. However, the Visigoths were defeated in battle that summer near the modern Italian-Slovenian border and then routed in the Battle of Naissus that September by Gallienus, Claudius and Aurelian, who then turned and defeated the Alemanni at the Battle of Lake Benacus. Claudius' successor Aurelian defeated the Goths twice more in the Battle of Fanum Fortunae and the Battle of Ticinum. The Goths remained a major threat to the Empire but directed their attacks away from Italy itself for several years after their defeat. By 284 AD, Gothic troops were serving on behalf of the Roman military as federated troops.

The Alamanni on the other hand resumed their drive towards Italy almost immediately. They defeated Aurelian at the Battle of Placentia in 271 AD but were beaten back for a short time after they lost the battles of Fano and Pavia later that year. They were beaten again in 298 AD at the battles of Lingones and Vindonissa but fifty years later they were resurgent again, making incursions in 356 AD at the Battle of Reims, in 357 AD at the Battle of Strasbourg, in 367 AD at the Battle of Solicinium and in 378 AD at Battle of Argentovaria. In the same year the Goths inflicted a crushing defeat on the Eastern Empire at the Battle of Adrianople, in which the Eastern Emperor Valens was massacred along with tens of thousands of Roman troops.

At the same time, Franks raided through the North Sea and the English Channel, Vandals pressed across the Rhine, Iuthungi against the Danube, Iazyges, Carpi and Taifali harassed Dacia, and Gepids joined the Goths and Heruli in attacks round the Black Sea. At around the same time, lesser-known tribes such as the Bavares, Baquates and Quinquegentanei raided Africa.

At the start of the 5th century, the pressure on Rome's western borders was growing intense. However, it was not only the western borders that were under threat: Rome was also under threat both internally and on its eastern borders.

An army that was often willing to support its general over its emperor, meant that if commanders could establish sole control of their army, they could usurp the imperial throne from that position. The so-called Crisis of the Third Century describes the turmoil of murder, usurpation and in-fighting that followed the murder of the Emperor Alexander Severus in 235 AD. However, Cassius Dio marks the wider imperial decline as beginning in 180 AD with the ascension of Commodus to the throne, a judgement with which Gibbon concurred, and Matyszak states that "the rot ... had become established long before" even that.

Although the crisis of the 3rd century was not the absolute beginning of Rome's decline, it nevertheless did impose a severe strain on the empire as Romans waged war on one another as they had not done since the last days of the Republic. Within the space of a single century, twenty-seven military officers declared themselves emperors and reigned over parts of the empire for months or days, all but two meeting with a violent end. The time was characterized by a Roman army that was as likely to be attacking itself as it was an outside invader, reaching a low point around 258 AD. Ironically, while it was these usurpations that led to the breakup of the Empire during the crisis, it was the strength of several frontier generals that helped reunify the empire through force of arms.

The situation was complex, often with three or more usurpers in existence at once. Septimius Severus and Pescennius Niger, both rebel generals declared to be emperors by the troops they commanded, clashed for the first time in 193 AD at the Battle of Cyzicus, in which Niger was defeated. However, it took two further defeats at the Battle of Nicaea later that year and the Battle of Issus the following year, for Niger to be destroyed. Almost as soon as Niger's usurpation had been ended, Severus was forced to deal with another rival for the throne in the person of Clodius Albinus, who had originally been allied to Severus. Albinus was proclaimed emperor by his troops in Britain and, crossing over to Gaul, defeated Severus' general Virius Lupus in battle, before being in turn defeated and killed in the Battle of Lugdunum by Severus himself.

After this turmoil, Severus faced no more internal threats for the rest of his reign, and the reign of his successor Caracalla passed uninterrupted for a while until he was murdered by Macrinus, who proclaimed himself emperor. Despite Macrinus having his position ratified by the Roman senate, the troops of Varius Avitus declared him to be emperor instead, and the two met in battle at the Battle of Antioch in 218 AD, in which Macrinus was defeated. However, Avitus himself, after taking the imperial name Elagabalus, was murdered shortly afterwards and Alexander Severus was proclaimed emperor by both the Praetorian Guard and the senate who, after a short reign, was murdered in turn. His murderers were working on behalf of the army who were unhappy with their lot under his rule and who raised in his place Maximinus Thrax. However, just as he had been raised by the army, Maximinus was also brought down by them and despite winning the Battle of Carthage against the senate's newly proclaimed Gordian II, he too was murdered when it appeared to his forces as though he would not be able to best the next senatorial candidate for the throne, Gordian III.

Gordian III's fate is not certain, although he may have been murdered by his own successor, Philip the Arab, who ruled for only a few years before the army again raised a general, Decius, by their proclamation to emperor, who then defeated Philip in the Battle of Verona. Several succeeding generals avoided battling usurpers for the throne by being murdered by their own troops before battle could commence. The lone exception to this rule was Gallienus, emperor from 260 to 268 AD, who confronted a remarkable array of usurpers, most of whom he defeated in pitched battle. The army was mostly spared further infighting until around 273 AD, when Aurelian defeated the Gallic usurper Tetricus in the Battle of Chalons. The next decade saw an incredible number of usurpers, sometimes three at the same time, all vying for the imperial throne. Most of the battles are not recorded, due primarily to the turmoil of the time, until Diocletian, a usurper himself, defeated Carinus at the Battle of the Margus and become emperor.

Some small measure of stability again returned at this point, with the empire split into a Tetrarchy of two greater and two lesser emperors, a system that staved off civil wars for a short time until 312 AD. In that year, relations between the tetrarchy collapsed for good and Constantine I, Licinius, Maxentius and Maximinus jostled for control of the empire. In the Battle of Turin Constantine defeated Maxentius, and in the Battle of Tzirallum, Licinius defeated Maximinus. From 314 AD onwards, Constantine defeated Licinius in the Battle of Cibalae, then the Battle of Mardia, and then again at the Battle of Adrianople, the Battle of the Hellespont and the Battle of Chrysopolis.

Constantine then turned upon Maxentius, beating him in the Battle of Verona and the Battle of Milvian Bridge in the same year. Constantine's son Constantius II inherited his father's rule and later defeated the usurper Magnentius in first the Battle of Mursa Major and then the Battle of Mons Seleucus.

Successive emperors Valens and Theodosius I also defeated usurpers in, respectively, the Battle of Thyatira, and the battles of the Save and the Frigidus.

After overthrowing the Parthian confederacy, the Sassanid Empire that arose from its remains pursued a more aggressive expansionist policy than their predecessors and continued to make war against Rome. In 230 AD, the first Sassanid emperor attacked Roman territory first in Armenia and then in Mesopotamia but Roman losses were largely restored by Severus within a few years. In 243 AD, Emperor Gordian III's army retook the Roman cities of Hatra, Nisibis and Carrhae from the Sassanids after defeating the Sassanids at the Battle of Resaena but what happened next is unclear: Persian sources claim that Gordian was defeated and killed in the Battle of Misikhe but Roman sources mention this battle only as an insignificant setback and suggest that Gordian died elsewhere.

Certainly, the Sassanids had not been cowed by the previous battles with Rome and in 253 AD the Sassanids under Shapur I penetrated deeply into Roman territory several times, defeating a Roman force at the Battle of Barbalissos and conquering and plundering Antiochia in 252 AD following the Siege of Antiochia. The Romans recovered Antioch by 253 AD, and Emperor Valerian gathered an army and marched eastward to the Sassanid borders. In 260 AD at the Battle of Edessa the Sassanids defeated the Roman army and captured the Roman Emperor Valerian.

By the late 3rd century, Roman fortunes on the eastern frontier improved dramatically. During a period of civil upheaval in Persia, emperor Carus led a successful campaign into Persia essentially uncontested, sacking Ctesiphon in 283 AD. During the reign of the Tetrarchy, emperors Diocletian and Galerius brought a decisive conclusion to the war, sacking Ctesiphon in 299 AD and expanding the Roman eastern frontier dramatically with the Treaty of Nisibis. The treaty brought lasting peace between Rome and the Sassanids for almost four decades until the end of Constantine the Great's reign. In 337 AD, Shapur II broke the peace and began a 26-year conflict, attempting with little success to conquer Roman fortresses in the region. After early Sassanid successes including the Battle of Amida in 359 AD and the Siege of Pirisabora in 363 AD, Emperor Julian met Shapur in 363 AD in the Battle of Ctesiphon outside the walls of the Persian capital. The Romans were victorious but were unable to take the city, and were forced to retreat due to their vulnerable position in the middle of hostile territory. Julian was killed in the Battle of Samarra during the retreat, possibly by one of his own men.

There were several future wars, although all brief and small-scale, since both the Romans and the Sassanids were forced to deal with threats from other directions during the 5th century. A war against Bahram V in 420 AD over the persecution of the Christians in Persia led to a brief war that was soon concluded by treaty and in 441 AD a war with Yazdegerd II was again swiftly concluded by treaty after both parties battled threats elsewhere.

Many theories have been advanced in way of explanation for decline of the Roman Empire, and many dates given for its fall, from the onset of its decline in the 3rd century to the fall of Constantinople in 1453. Militarily, however, the Empire finally fell after first being overrun by various non-Roman peoples and then having its heart in Italy seized by Germanic troops in a revolt. The historicity and exact dates are uncertain, and some historians do not consider that the Empire fell at this point.

The Empire became gradually less Romanised and increasingly Germanic in nature: although the Empire buckled under Visigothic assault, the overthrow of the last Emperor Romulus Augustus was carried out by federated Germanic troops from within the Roman army rather than by foreign troops. In this sense had Odoacer not renounced the title of Emperor and named himself "King of Italy" instead, the Empire might have continued in name. Its identity, however, was no longer Roman – it was increasingly populated and governed by Germanic peoples long before 476 AD. The Roman people were by the 5th century "bereft of their military ethos" and the Roman army itself a mere supplement to federated troops of Goths, Huns, Franks and others fighting on their behalf.

Rome's last gasp began when the Visigoths revolted around 395 AD. Led by Alaric I, they attempted to seize Constantinople, but were rebuffed and instead plundered much of Thrace in northern Greece. In 402 AD they besieged Mediolanum, the capital of Roman Emperor Honorius, defended by Roman Gothic troops. The arrival of the Roman Stilicho and his army forced Alaric to lift his siege and move his army towards Hasta (modern Asti) in western Italy, where Stilicho attacked it at the Battle of Pollentia, capturing Alaric's camp. Stilicho offered to return the prisoners in exchange for the Visigoths returning to Illyricum but upon arriving at Verona, Alaric halted his retreat. Stilicho again attacked at the Battle of Verona and again defeated Alaric, forcing him to withdraw from Italy.

In 405 AD, the Ostrogoths invaded Italy itself, but were defeated. However, in 406 AD an unprecedented number of tribes took advantage of the freezing of the Rhine to cross "en masse": Vandals, Suevi, Alans and Burgundians swept across the river and met little resistance in the Sack of Moguntiacum and the Sack of Treviri, completely overrunning Gaul. Despite this grave danger, or perhaps because of it, the Roman army continued to be wracked by usurpation, in one of which Stilicho, Rome's foremost defender of the period, was put to death.

It is in this climate that, despite his earlier setback, Alaric returned again in 410 AD and managed to sack Rome. The Roman capital had by this time moved to the Italian city of Ravenna, but some historians view 410 AD as an alternative date for the true fall of the Roman Empire. Without possession of Rome or many of its former provinces, and increasingly Germanic in nature, the Roman Empire after 410 AD had little in common with the earlier Empire. By 410 AD, Britain had been mostly denuded of Roman troops, and by 425 AD was no longer part of the Empire, and much of western Europe was beset "by all kinds of calamities and disasters", coming under barbarian kingdoms ruled by Vandals, Suebians, Visigoths and Burgundians.

The remainder of Rome's territory—if not its nature—was defended for several decades following 410 AD largely by Flavius Aëtius, who managed to play off each of Rome's barbarian invaders against one another. In 436 AD he led a Hunnic army against the Visigoths at the Battle of Arles, and again in 436 AD at the Battle of Narbonne. In 451 AD he led a combined army, including his former enemy the Visigoths, against the Huns at the Battle of the Catalaunian Plains, beating them so soundly that although they later sacked Concordia, Altinum, Mediolanum, Ticinum, and Patavium, they never again directly threatened Rome. Despite being the only clear champion of the Empire at this point Aëtius was slain by the Emperor Valentinian III's own hand, leading Sidonius Apollinaris to observe, "I am ignorant, sir, of your motives or provocations; I only know that you have acted like a man who has cut off his right hand with his left".

Carthage, the second largest city in the empire, was lost along with much of North Africa in 439 AD to the Vandals, and the fate of Rome seemed sealed. By 476 AD, what remained of the Empire was completely in the hands of federated Germanic troops and when they revolted, led by Odoacer and deposed the Emperor Romulus Augustus there was nobody to stop them. Odoacer happened to hold the part of the Empire around Italy and Rome but other parts of the Empire were ruled by Visigoths, Ostrogoths, Franks, Alans and others. The Empire in the West had fallen, and its remnant in Italy was no longer Roman in nature. The Eastern Roman Empire and the Goths continued to fight over Rome and the surrounding area for many years, though by this point Rome's importance was primarily symbolic.


 (print: "Penguin Books, 1987, ")

 (print: "John Carew Rolfe (tr.), "Sallust", Loeb Classical Library, 1940, ")

 (print: "Penguin Books, 1985, ")


</doc>
<doc id="315710" url="https://en.wikipedia.org/wiki?curid=315710" title="Mark Oliphant">
Mark Oliphant

Sir Marcus Laurence Elwin "Mark" Oliphant (8 October 1901 – 14 July 2000) was an Australian physicist and humanitarian who played an important role in the first experimental demonstration of nuclear fusion and in the development of nuclear weapons.

Born and raised in Adelaide, South Australia, Oliphant graduated from the University of Adelaide in 1922. He was awarded an 1851 Exhibition Scholarship in 1927 on the strength of the research he had done on mercury, and went to England, where he studied under Sir Ernest Rutherford at the University of Cambridge's Cavendish Laboratory. There, he used a particle accelerator to fire heavy hydrogen nuclei (deuterons) at various targets. He discovered the respective nuclei of helium-3 (helions) and of tritium (tritons). He also discovered that when they reacted with each other, the particles that were released had far more energy than they started with. Energy had been liberated from inside the nucleus, and he realised that this was a result of nuclear fusion.

Oliphant left the Cavendish Laboratory in 1937 to become the Poynting Professor of Physics at the University of Birmingham. He attempted to build a cyclotron at the university, but its completion was postponed by the outbreak of the Second World War in Europe in 1939. He became involved with the development of radar, heading a group at the University of Birmingham that included John Randall and Harry Boot. They created a radical new design, the cavity magnetron, that made microwave radar possible. Oliphant also formed part of the MAUD Committee, which reported in July 1941, that an atomic bomb was not only feasible, but might be produced as early as 1943. Oliphant was instrumental in spreading the word of this finding in the United States, thereby starting what became the Manhattan Project. Later in the war, he worked on it with his friend Ernest Lawrence at the Radiation Laboratory in Berkeley, California, developing electromagnetic isotope separation, which provided the fissile component of the Little Boy atomic bomb used in the atomic bombing of Hiroshima in August 1945.

After the war, Oliphant returned to Australia as the first director of the Research School of Physical Sciences and Engineering at the new Australian National University (ANU), where he initiated the design and construction of the world's largest (500 megajoule) homopolar generator. He retired in 1967, but was appointed Governor of South Australia on the advice of Premier Don Dunstan. He assisted in the founding of the Australian Democrats political party, and he was the chairman of the meeting in Melbourne in 1977 at which the party was launched. Late in life he witnessed his wife, Rosa, suffer before her death in 1987, and he became an advocate for voluntary euthanasia. He died in Canberra in 2000.

Marcus "Mark" Laurence Elwin Oliphant was born on 8 October 1901 in Kent Town, a suburb of Adelaide. His father was Harold George "Baron" Oliphant, a civil servant with the South Australian Engineering and Water Supply Department and part-time lecturer in Economics with the Workers' Educational Association. His mother was Beatrice Edith Fanny Oliphant, née Tucker, an artist. He was named after Marcus Clarke, the Australian author, and Laurence Oliphant, the British traveller and mystic. Most people called him Mark; this became official when he was knighted in 1959. He had four younger brothers, Roland, Keith, Nigel and Donald. His parents were theosophists, and as such were opposed to eating meat. Marcus became a lifelong vegetarian while a boy, after witnessing the slaughter of pigs on a farm. He was found to be completely deaf in one ear and he needed glasses for severe astigmatism and short-sightedness.

Oliphant was first educated at primary schools in Goodwood and Mylor, after the family moved there in 1910. He attended Unley High School in Adelaide, and, for his final year in 1918, Adelaide High School. After graduation he failed to obtain a bursary to attend university, and so got a job cleaning floors for a jewellery manufacturer. He then got a cadetship with the State Library of South Australia, which allowed him to take courses at the University of Adelaide at night.

In 1919, Oliphant began studying at the University of Adelaide. At first he was interested in a career in medicine, but later in the year Kerr Grant, the physics professor, offered him a cadetship in the Physics Department. It paid 10 shillings a week (), the same amount that Oliphant received for working at the State Library, but it allowed him to take any university course that did not conflict with his work for the department. He received his Bachelor of Science (BSc) degree in 1921 and then did honours the following year, supervised by Grant. Roy Burdon, who acted as head of the department when Grant went on sabbatical in 1925, worked with Oliphant to produce two papers in 1927 on the properties of mercury, "The Problem of the Surface Tension of Mercury and the Action of Aqueous Solutions on a Mercury Surface" and "Absorption of Gases on the Surface of Mercury". Oliphant later recalled that Burdon taught him "the extraordinary exhilaration there was in even minor discoveries in the field of physics".

Oliphant married Rosa Louise Wilbraham, who was also from Adelaide, on 23 May 1925. The two had known each other since they were teenagers. He made Rosa's wedding ring in the laboratory from a gold nugget (from the Coolgardie Goldfields) that his father had given him.

In 1925, Oliphant heard a speech given by the New Zealand physicist Sir Ernest Rutherford, and he decided he wanted to work for him – an ambition that he fulfilled by earning a position at the Cavendish Laboratory at the University of Cambridge in 1927. He applied for an 1851 Exhibition Scholarship on the strength of the research he had done on mercury with Burdon. It came with a living allowance of £250 per annum (). When word came through that he had been awarded a fellowship, he wired Rutherford and Trinity College, Cambridge. Both accepted him.
Rutherford's Cavendish Laboratory was carrying out some of the most advanced research into nuclear physics in the world at the time. Oliphant was invited to afternoon tea by Rutherford and Lady Rutherford. He soon got to meet other researchers at the Cavendish Laboratory, including Patrick Blackett, Edward Bullard, James Chadwick, John Cockcroft, Charles Ellis, Peter Kapitza, Philip Moon and Ernest Walton. There were two fellow Australians: Harrie Massey and John Keith Roberts. Oliphant would become especially close friends with Cockcroft. The laboratory had considerable talent but not a lot of money to spare, and tended to use a "string and sealing wax" approach to experimental equipment. Oliphant had to buy his own equipment, at one point spending £24 () of his allowance on a vacuum pump.

Oliphant submitted his PhD thesis on "The Neutralization of Positive Ions at Metal Surfaces, and the Emission of Secondary Electrons" in December 1929. For his "viva", he was examined by Rutherford and Ellis. Receiving his degree was the attainment of a major life goal, but it also meant the end of his 1851 Exhibition Scholarship. Oliphant secured an 1851 Senior Studentship, of which there were five awarded each year. It came with a living allowance of £450 per annum () for two years, with the possibility of a one-year extension in exceptional circumstances, which Oliphant was also awarded.

A son, Geoffrey Bruce Oliphant, was born 6 October 1930, but he died of meningitis on 5 September 1933, and was interred in an unmarked grave in the Ascension Parish Burial Ground in Cambridge alongside Timothy Cockcroft, the infant son of Sir John and Lady Elizabeth Cockcroft, who had died the year before. Unable to have more children, the Oliphants adopted a four-month-old boy, Michael John, in 1936, and a daughter, Vivian, in 1938.
In 1932 and 1933, the scientists at the Cavendish Laboratory made a series of ground-breaking discoveries. Cockcroft and Walton bombarded lithium with high energy protons and succeeded in transmuting it into energetic nuclei of helium. This was one of the earliest experiments to change the atomic nucleus of one element to another by artificial means. Then Chadwick devised an experiment that discovered a new, uncharged particle with roughly the same mass as the proton: the neutron. In 1933, Blackett discovered tracks in his cloud chamber that confirmed the existence of the positron and revealed the opposing spiral traces of positron–electron pair production.

Oliphant followed up the work by constructing a particle accelerator that could fire protons with up to 600,000 electronvolts of energy. He soon confirmed the results of Cockcroft and Walton on the artificial disintegration of the nucleus and positive ions. He produced a series of six papers over the following two years. In 1933, the Cavendish Laboratory received a gift from the American physical chemist Gilbert N. Lewis of a few drops of heavy water. The accelerator was used to fire heavy hydrogen nuclei ("deuterons", which Rutherford called "diplons") at various targets. Working with Rutherford and others, Oliphant thereby discovered the nuclei of helium-3 ("helions") and tritium ("tritons").

Oliphant used electromagnetic separation to separate the isotopes of lithium. He was the first to experimentally demonstrate nuclear fusion. He found that when deuterons reacted with nuclei of helium-3, tritium or with other deuterons, the particles that were released had far more energy than they started with. Binding energy had been liberated from inside the nucleus. Following Arthur Eddington's 1920 prediction that energy released by fusing small nuclei together could provide the energy source that powers the stars, Oliphant speculated that nuclear fusion reactions might be what powered the sun. With its higher cross section, the deuterium–tritium nuclear fusion reaction became the basis of a hydrogen bomb. Oliphant had not foreseen this development:

In 1934, Cockcroft arranged for Oliphant to become a fellow of St John's College, Cambridge, which paid about £600 a year. When Chadwick left the Cavendish Laboratory for the University of Liverpool in 1935, Oliphant and Ellis both replaced him as Rutherford's assistant director for research. The job came with a salary of £600 (). With the money from St John's, this gave him a comfortable income. Oliphant soon fitted out a new accelerator laboratory with a 1.23 MeV generator at a cost of £6,000 () while he designed an even larger 2 MeV generator. He was the first to conceive of the proton synchrotron, a new type of cyclic particle accelerator. In 1937, he was elected to the Royal Society. When he died he was its longest-serving fellow.

Samuel Walter Johnson Smith's imminent mandatory retirement at age 65 prompted a search for a new Poynting Professor of Physics at the University of Birmingham. The University wanted not just a replacement, but a well-known name, and was willing to spend lavishly in order to build up nuclear physics expertise at Birmingham. Neville Moss, its Professor of Mining Engineering and the Dean of its Faculty of Science approached Oliphant, who presented his terms. In addition to his salary of £1,300 (), he wanted the University to spend £2,000 () to upgrade the laboratory, and another £1,000 per annum () on it. And he did not wish to start until October 1937, to enable him to wrap up his work at the Cavendish Laboratory. Moss agreed to Oliphant's terms.

To obtain funding for the cyclotron that he wanted, Oliphant wrote to the British prime minister, Neville Chamberlain, who was from Birmingham. Chamberlain took up the matter with his friend Lord Nuffield, who provided £60,000 () for the project, enough for the cyclotron, a new building to house it, and a trip to Berkeley, California, so Oliphant could confer with Ernest Lawrence, the inventor of the cyclotron. Lawrence supported the project, sending Oliphant the plans of the cyclotron that he was constructing at Berkeley, and inviting Oliphant to visit him at the Radiation Laboratory. Oliphant sailed for New York on 10 December 1938, and met Lawrence in Berkeley. The two men got along very well, dining at "Trader Vic's" in Oakland. Oliphant was aware of the problems in building cyclotrons encountered by Chadwick at the University of Liverpool and Cockcroft at the Cavendish Laboratory, and intended to avoid these and get his cyclotron built on time and on budget by following Lawrence's specifications as closely as possible. He hoped that it would be running by Christmas 1939, but the outbreak of the Second World War quashed his hopes. The Nuffield Cyclotron would not be completed until after the war.

In 1938, Oliphant became involved with the development of radar, then still a secret. While visiting prototype radar stations, he realised that shorter-wavelength radio waves were needed urgently, especially if there was to be any chance of building a radar set small enough to fit into an aircraft. In August 1939, he took a small group to Ventnor, on the Isle of Wight, to examine the Chain Home system first hand. He obtained a grant from the Admiralty to develop radar systems with wavelengths less than ; the best available at the time was .

Oliphant's group at Birmingham worked on developing two promising devices, the klystron and the magnetron. Working with James Sayers, Oliphant managed to produce an improved version of the klystron capable of generating 400W. Meanwhile, two more members of his Birmingham team, John Randall and Harry Boot, worked on a radical new design, a cavity magnetron. By February 1940, they had an output of 400W with a wavelength of , just the kind of short wavelengths needed for good airborne radars. The magnetron's power was soon increased a hundred-fold, and Birmingham concentrated on magnetron development. The first operational magnetrons were delivered in August 1941. This invention was one of the key scientific breakthroughs during the war and played a major part in defeating the German U-boats, intercepting enemy bombers, and in directing Allied bombers.

In 1940, the Fall of France, and the possibility that Britain might be invaded, prompted Oliphant to send his wife and children to Australia. The Fall of Singapore in February 1942 led him to offer his services to John Madsen, the Professor of Electrical Engineering at the University of Sydney, and the head of the Radiophysics Laboratory at the Council for Scientific and Industrial Research, which was responsible for developing radar. He embarked from Glasgow for Australia on on 20 March. The voyage, part of a 46-ship convoy, was a slow one, with the convoy frequently zigzagging to avoid U-boats, and the ship did not reach Fremantle until 27 May.

The Australians were already preparing to produce radar sets locally. Oliphant persuaded Professor Thomas Laby to release Eric Burhop and Leslie Martin from their work on optical munitions to work on radar, and they succeeded in building a cavity magnetron in their laboratory at the University of Melbourne in May 1942. Oliphant worked with Martin on the process of moving the magnetrons for the laboratory to the production line. Over 2,000 radar sets were produced in Australia during the war.

At the University of Birmingham in March 1940, Otto Frisch and Rudolf Peierls examined the theoretical issues involved in developing, producing and using atomic bombs in a paper that became known as the Frisch–Peierls memorandum. They considered what would happen to a sphere of pure uranium-235, and found that not only could a chain reaction occur, but it might require as little as of uranium-235 to unleash the energy of hundreds of tons of TNT. The first person they showed their paper to was Oliphant, and he immediately took it to Sir Henry Tizard, the chairman of the Committee for the Scientific Survey of Air Warfare (CSSAW). As a result, a special subcommittee of the CSSAW known as the MAUD Committee was created to investigate the matter further. It was chaired by Sir George Thomson, and its original membership included Oliphant, Chadwick, Cockcroft and Moon. In its final report in July 1941, the MAUD Committee concluded that an atomic bomb was not only feasible, but might be produced as early as 1943.
Great Britain was at war and authorities there thought that the development of an atomic bomb was urgent, but there was much less urgency in the United States. Oliphant was one of the people who pushed the American program into motion. On 5 August 1941, Oliphant flew to the United States in a B-24 Liberator bomber, ostensibly to discuss the radar-development program, but was assigned to find out why the United States was ignoring the findings of the MAUD Committee. He later recalled: "the minutes and reports had been sent to Lyman Briggs, who was the Director of the Uranium Committee, and we were puzzled to receive virtually no comment. I called on Briggs in Washington [DC], only to find out that this inarticulate and unimpressive man had put the reports in his safe and had not shown them to members of his committee. I was amazed and distressed."

Oliphant then met with the Uranium Committee at its meeting in New York on 26 August 1941. Samuel K. Allison, a new member of the Committee, was an experimental physicist and a protégé of Arthur Compton at the University of Chicago. He recalled that Oliphant "came to a meeting and said 'bomb' in no uncertain terms. He told us we must concentrate every effort on the bomb, and said we had no right to work on power plants or anything but the bomb. The bomb would cost 25 million dollars, he said, and Britain did not have the money or the manpower, so it was up to us." Allison was surprised that Briggs had kept the committee in the dark. Oliphant then travelled to Berkeley, where he met his friend Lawrence on 23 September, giving him a copy of the Frisch–Peierls memorandum. Lawrence had Robert Oppenheimer check the figures, bringing him into the project for the first time. Oliphant found another ally in Oppenheimer, and he not only managed to convince Lawrence and Oppenheimer that an atomic bomb was feasible, but inspired Lawrence to convert his cyclotron into a giant mass spectrometer for electromagnetic isotope separation, a technique Oliphant had pioneered in 1934. Leo Szilard later wrote, "if Congress knew the true history of the atomic energy project, I have no doubt but that it would create a special medal to be given to meddling foreigners for distinguished services, and that Dr Oliphant would be the first to receive one."
On 26 October 1942, Oliphant embarked from Melbourne, taking Rosa and the children back with him. The wartime sea voyage on the French "Desirade" was again a slow one, and they did not reach Glasgow until 29 February 1943. He had to leave them behind once more in November 1943 after the British Tube Alloys effort was merged with the American Manhattan Project by the Quebec Agreement, and he left for the United States as part of the British Mission. Oliphant was one of the scientists whose services the Americans were most eager to secure. Oppenheimer, who was now the director of the Los Alamos Laboratory attempted to persuade him to join the team there, but Oliphant preferred to head a team assisting his friend Lawrence at the Radiation Laboratory in Berkeley to develop the electromagnetic uranium enrichment—a vital but less overtly military part of the project.

Oliphant secured the services of fellow Australian physicist Harrie Massey, who had been working for the Admiralty on magnetic mines, along with James Stayers and Stanley Duke, who had worked with him on the cavity magnetron. This initial group set out for Berkeley in a B-24 Liberator bomber in November 1943. Oliphant became Lawrence's "de facto" deputy, and was in charge of the Berkeley Radiation Laboratory when Lawrence was absent. Although based in Berkeley, he often visited Oak Ridge, Tennessee, where the separation plant was, and was an occasional visitor to Los Alamos. He made efforts to involve Australian scientists in the project, and had Sir David Rivett, the head of the Council for Scientific and Industrial Research, release Eric Burhop to work on the Manhattan Project. He briefed Stanley Bruce, the Australian High Commissioner to the United Kingdom, on the project, and urged the Australian government to secure Australian uranium deposits.

A meeting with Major General Leslie Groves, the director of the Manhattan Project, at Berkeley in September 1944, convinced Oliphant that the Americans intended to monopolise nuclear weapons after the war, restricting British research and production to Canada, and not permitting nuclear weapons technology to be shared with Australia. Characteristically, Oliphant bypassed Chadwick, the head of the British Mission, and sent a report direct to Wallace Akers, the head of the Tube Alloys Directorate in London. Akers summoned Oliphant back to London for consultation. En route, Oliphant met with Chadwick and other members of the British Mission in Washington, where the prospect of resuming an independent British project was discussed. Chadwick was adamant that the cooperation with the Americans should continue, and that Oliphant and his team should remain until the task of building an atomic bomb was finished. Akers sent Chadwick a telegram directing that Oliphant should return to the UK by April 1945. 

Oliphant returned to England in March 1945, and resumed his post as a professor of physics at the University of Birmingham. He was on holiday in Wales with his family when he first heard of the atomic bombing of Hiroshima and Nagasaki. He was later to remark that he felt "sort of proud that the bomb had worked, and absolutely appalled at what it had done to human beings". Oliphant became a harsh critic of nuclear weapons and a member of the Pugwash Conferences on Science and World Affairs, saying, "I, right from the beginning, have been terribly worried by the existence of nuclear weapons and very much against their use." His wartime work would have earned him a Medal of Freedom with Gold Palm, but the Australian government vetoed this honour, as government policy at the time was not to confer honours on civilians.

In April 1946, the Prime Minister, Ben Chifley, asked Oliphant if he would be a technical advisor to the Australian delegation to the newly formed United Nations Atomic Energy Commission (UNAEC), which was debating international control of nuclear weapons. Oliphant agreed, and joined the Minister for External Affairs, H. V. Evatt and the Australian Representative at the United Nations, Paul Hasluck, to hear the Baruch Plan. The attempt at international control was unsuccessful, and no agreement was reached.

Chifley, and the Minister for Post-War Reconstruction, Dr H. C. "Nugget" Coombs, also discussed with Oliphant a plan to create a new research institute that would attract the world's best scholars to Australia and lift the standard of university education nationwide. They hoped to start by attracting three of Australia's most distinguished expatriates: Oliphant, Howard Florey and Keith Hancock. It was academic suicide; Australia was far from the centres where the latest research was being carried out, and communications were much poorer at that time. But Oliphant accepted, and in 1950 returned to Australia as the first Director of the Research School of Physical Sciences and Engineering at the Australian National University. Within the school he created a Department of Particle Physics, which he headed himself, a Department of Nuclear Physics under Ernest Titterton, a Department of Geophysics under John Jaeger, a Department of Astronomy under Bart Bok, a Department of Theoretical Physics under Kenneth Le Couteur and a Department of Mathematics under Bernhard Neumann.
Oliphant was an advocate of nuclear weapons research. He served on the post-war Technical Committee that advised the British government on nuclear weapons, and publicly declared that Britain needed to develop its own nuclear weapons independent of the United States to "avoid the danger of becoming a lesser power". The establishment of a world-class nuclear physics research capability in Australia was intimately linked with the government's plans to develop nuclear power and weapons. Locating the new research institute in Canberra would place it close to the Snowy Mountains Scheme, which was planned to be the centrepiece of a new nuclear power industry. Oliphant hoped that Britain would assist with the Australian program, and the British were interested in cooperation because Australia had uranium ore and weapons testing sites, and there were concerns that Australia was becoming too closely aligned with the United States. Arrangements were made for Australian scientists to be seconded to the British Atomic Energy Research Establishment at Harwell, but the close cooperation he sought was stymied by security concerns arising from Britain's commitments to the United States.

Oliphant envisaged Canberra one day becoming a university town like Oxford or Cambridge. A threat to the future of the University arose in the wake of the 1949 election, when the Liberal Party of Australia led by Robert Menzies won. Many Liberals were opposed to the University, which they saw as an extravagance. Menzies defended it, but in 1954 he announced that it had entered a period of consolidation, with a funding ceiling, ending the possibility of successful competition with universities in Europe and North America. A further blow came in 1959, when the Menzies government amalgamated it with the Canberra University College. Henceforth, it would no longer be a research university, but a regular one, with responsibility for teaching undergraduates. Nonetheless, parts of the university stayed committed to the old mission, and the ANU remained a university where research is central to its activities. Despite the setbacks, by 2014 the vision of Canberra as a university town would be well on its way to becoming a reality.

In September 1951, Oliphant applied for a visa to travel to the United States for a nuclear physics conference in Chicago. The visa was not refused, nor was Oliphant accused of subversive activities, but neither was it issued. This was the height of the Red Scare. The American McCarran Act restricted travel to the United States, and in Australia the Menzies government was attempting to ban the Communist Party, and was not inclined to support Oliphant against the American government. A subsequent request to travel to Canada via Hawaii in September 1954 was refused by the United States Department of State. Although Oliphant was granted a special waiver that allowed him to transit the US, he preferred to cancel the trip rather than accept this humiliation. The Menzies government subsequently excluded him from participating in or observing the British nuclear tests at Maralinga, nor was he allowed access to classified nuclear information for fear of antagonising the US.

In 1955, Oliphant initiated the design and construction of a 500 megajoule homopolar generator (HPG), the world's largest. This massive machine contained three discs in diameter and weighing . He obtained £40,000 () initial funding from the Australian Atomic Energy Commission. Completed in 1963, the HPG was intended to be the power source for a synchrotron, but this was not built. Instead, it was used to power the LT-4 Tokamak and a large-scale railgun that was used as a scientific instrument for experiments with plasma physics. It was decommissioned in 1985.
Oliphant founded the Australian Academy of Science in 1954, teaming up with David Martyn to overcome the obstacles that had frustrated previous attempts. Oliphant was its president until 1956. Deciding that the Academy of Science should have its own special building, Oliphant raised the required money from donations. As chairman of the Building Design Committee, he selected and oversaw the construction of one of Canberra's most striking architectural designs. He also delivered the Academy of Science's 1961 Matthew Flinders Lecture, on the subject of "Faraday in his time and today".

Oliphant retired as Professor of Particle Physics in 1964, and was appointed Professor of Ionised Gases. In this chair he produced his first research papers since the 1930s. He was appointed Professor Emeritus in 1967. He was invited by the premier, Don Dunstan, to become the Governor of South Australia, a position he held from 1971 to 1976. During this period, he caused great concern to Dunstan when he strongly supported the decision of the Governor-General, Sir John Kerr, in the 1975 Australian constitutional crisis.

"The Age" reported in 1981 that "Sir Mark Oliphant warned the Dunstan Government of the 'grave dangers' of appointing an Australian Aborigine, Sir Douglas Nicholls, to succeed him as South Australia's Governor". Oliphant had secretly written, "[t]here is something inherent in the personality of the Aborigine which makes it difficult for him to adapt fully to the ways of the white man." The authors of Oliphant's biography noted that "that was the prevailing attitude of almost the entire white population of Australia until well after World War II".

Oliphant was created a Knight Commander of the Order of the British Empire (KBE) in 1959, and was made a Companion of the Order of Australia (AC) in 1977 "for eminent achievement and merit of the highest degree in the field of public service and in service to the crown".

Late in life Oliphant watched his wife, Rosa, suffer before her death in 1987, and he became an advocate for voluntary euthanasia. On 14 July 2000, he died in Canberra, at the age of 98. His body was cremated. He was survived by his adopted daughter Vivian, his son Michael having died from colon cancer in 1971.

Places and things named in honour of Oliphant include the Oliphant Building at the Australian National University, the Mark Oliphant Conservation Park, a South Australian high schools science competition, the Oliphant Wing of the Physics Building at the University of Adelaide, a school in Munno Para West, South Australia, and a bridge on Parkes Way in Canberra near his old laboratory at the ANU. His papers are in the Adolph Basser Library at the Australian Academy of Science, and the Barr Smith Library at the University of Adelaide. Oliphant's nephew, Pat Oliphant, is a Pulitzer Prize-winning cartoonist. His daughter-in-law, Monica Oliphant, is a distinguished Australian physicist specialising in the field of renewable energy, for which she was made an Officer of the Order of Australia in 2015.






</doc>
<doc id="318069" url="https://en.wikipedia.org/wiki?curid=318069" title="Goblin shark">
Goblin shark

The goblin shark ("Mitsukurina owstoni") is a rare species of deep-sea shark. Sometimes called a "living fossil", it is the only extant representative of the family Mitsukurinidae, a lineage some 125 million years old. This pink-skinned animal has a distinctive profile with an elongated, flattened snout, and highly protrusible jaws containing prominent nail-like teeth. It is usually between long when mature, though it can grow considerably larger. Goblin sharks inhabit upper continental slopes, submarine canyons, and seamounts throughout the world at depths greater than , with adults found deeper than juveniles.

Various anatomical features of the goblin shark, such as its flabby body and small fins, suggest that it is sluggish in nature. This species hunts for teleost fishes, cephalopods, and crustaceans both near the sea floor and in the middle of the water column. Its long snout is covered with ampullae of Lorenzini that enable it to sense minute electric fields produced by nearby prey, which it can snatch up by rapidly extending its jaws. Small numbers of goblin sharks are unintentionally caught by deepwater fisheries. The International Union for Conservation of Nature (IUCN) has assessed it as Least Concern, despite its rarity, citing its wide distribution and low incidence of capture.

American ichthyologist David Starr Jordan described the goblin shark in an 1898 issue of "Proceedings of the California Academy of Sciences", recognizing the peculiar fish not only as a new species, but also a new genus and family. He based his account on an immature male long caught in Sagami Bay near Yokohama, Japan. The specimen had been acquired by shipmaster and naturalist Alan Owston, who had given it to Professor Kakichi Mitsukuri at the University of Tokyo, who in turn had brought it to Jordan. Thus, Jordan named the shark "Mitsukurina owstoni" in honor of these two men. The common name "goblin shark" is a translation of its old Japanese name "tenguzame", a "tengu" being a Japanese mythical creature often depicted with a long nose and red face. Another name for this species is elfin shark.

Soon after Jordan's description was published, several scientists noted the similarity between "Mitsukurina" and the extinct Mesozoic shark "Scapanorhynchus". For a time, the prevailing opinion was to treat "Mitsukurina" as a junior synonym of "Scapanorhynchus". Eventually, more complete fossils revealed many anatomical differences between "Scapanorhynchus" and "Mitsukurina", causing modern authors to again regard them as distinct genera. Several goblin shark specimens were described as separate species from 1904 to 1937, none of which are now considered valid. This taxonomic confusion began because the specimens' jaws were fixed at varying degrees of protrusion during preservation, giving the appearance of proportional differences among the heads.

Phylogenetic studies based on morphology have generally classified the goblin shark as the most basal member of the order Lamniformes, known as mackerel sharks. Studies using genetic data have also confirmed a basal classification for this species. The family Mitsukurinidae, represented by "Mitsukurina", "Scapanorhynchus", and "Anomotodon", dates back to the Aptian age of the Cretaceous period ("c." 125–113 Ma). "Mitsukurina" itself first appears in the fossil record during the period Middle Eocene ("c." 49–37 Ma); extinct species include "M. lineata" and "M. maslinensis". "Striatolamia macrota", which lived in warm shallow waters during the Paleogene period ("c." 66–23 Ma), may also be a "Mitsukurina" species. As the last member of an ancient lineage, and one that retains several "primitive" traits, the goblin shark has been described as a "living fossil".

The goblin shark has a distinctively long and flat snout, resembling a sword blade. The proportional length of the snout decreases with age. The eyes are small and lack protective nictitating membranes; behind the eyes are spiracles. The large mouth is parabolic in shape. The jaws are very protrusible and can be extended almost to the end of the snout, though normally they are held flush against the underside of the head. It has 35–53 upper and 31–62 lower tooth rows. The teeth in the main part of the jaws are long and narrow, particularly those near the symphysis (jaw midpoint), and are finely grooved lengthwise. The rear teeth near the corners of the jaw are small and have a flattened shape for crushing. Much individual variation of tooth length and width occurs, as for whether the teeth have a smaller cusplet on each side of the main cusp, and regarding the presence of toothless gaps at the symphysis or between the main and rear teeth. The five pairs of gill slits are short, with the gill filaments inside partly exposed; the fifth pair is above the origin of the pectoral fins.

The body is fairly slender and flabby. The two dorsal fins are similar in size and shape, both being small and rounded. The pectoral fins are also rather small and rounded. The pelvic and anal fins have long bases and are larger than the dorsal fins. The caudal peduncle is flattened from side-to-side and lacks keels or notches. The asymmetric caudal fin has a long upper lobe with a shallow ventral notch near the tip, and an indistinct lower lobe. The soft, semitranslucent skin has a rough texture from a covering of dermal denticles, each shaped like a short upright spine with lengthwise ridges. Living sharks of this species are pink or tan due to visible blood vessels beneath the skin; the color deepens with age, and young sharks may be almost white. The fins' margins are translucent gray or blue, and the eyes are black with bluish streaks in the irises. After death, the coloration fades quickly to dull gray or brown. Adult sharks usually measure between long. However, the capture of an enormous female estimated at long during 2000 showed this species can grow far larger than suspected previously. The maximum weight recorded is for a 3.8-m-long shark.

The generic name honors Keigo Mitsukuri, a Japanese zoologist who studied at University College London during the 1860s. The specific name honors Alan Owston, an English collector of Asian wildlife.

The goblin shark has been caught in all three major oceans, indicating a wide global distribution. In the Atlantic Ocean, it has been recorded from the northern Gulf of Mexico, Suriname, French Guiana, and southern Brazil in the west, and France, Portugal, Madeira, and Senegal in the east. It has also been collected from seamounts along the Mid-Atlantic Ridge. In the Indo-Pacific and Oceania, it has been found off South Africa, Mozambique, Japan, Taiwan, Australia and New Zealand. This species has been recorded from off East Cape to Kaikoura Canyon and from the Challenger Plateau near New Zealand. A single eastern Pacific specimen is known, collected off southern California. This species is most often found over the upper continental slope at depths of . It has been caught as deep as , and a tooth has been found lodged in an undersea cable at a depth of . Adults inhabit greater depths than juveniles. Immature goblin sharks frequent the submarine canyons off southern Japan at depths of , with individuals occasionally wandering into inshore waters as shallow as . On the 19 April 2014 fishermen in Key West, Florida, while fishing in the Gulf of Mexico, caught a goblin shark in their fishing net, only the second one ever to be caught in the Gulf. The shark was photographed and released back into the water.

During July 2014, a goblin shark was found in a fishery net in Sri Lanka, near the eastern coast of Sri Lanka. The shark was about long and weighed about The shark was given to the NARA (National Aquatic Resource Research & Development Agency) for further research.

Although observations of living goblin sharks are scant, its anatomy suggests its lifestyle is inactive and sluggish. Its skeleton is reduced and poorly calcified, the muscle blocks along its sides (myomeres) are weakly developed, and its fins are soft and small. Its long caudal fin, held at a low angle, is also typical of a slow-swimming shark. The long snout appears to have a sensory function, as it bears numerous ampullae of Lorenzini that can detect the weak electric fields produced by other animals. Due to the snout's softness, it is unlikely to be used for stirring up prey from the bottom as has been proposed. Vision seems to be less important than other senses, considering the relatively small optic tectum in the shark's brain. Yet unlike most deep-sea sharks, it can change the size of its pupils, thus probably does use its sight in some situations. Goblin sharks may the prey of blue sharks ("Prionace glauca"). Parasites documented from this species include the copepod "Echthrogaleus mitsukurinae", and the tapeworms "Litobothrium amsichensis" and "Marsupiobothrium gobelinus".

The goblin shark feeds mainly on teleost fishes such as rattails and dragonfishes. It also consumes cephalopods and crustaceans, including decapods and isopods. Garbage has been recorded from the stomachs of some specimens. Its known prey includes bottom-dwelling species such as the blackbelly rosefish ("Helicolenus dactylopterus"), and midwater species such as the squid "Teuthowenia pellucida" and the ostracod "Macrocypridina castanea rotunda". Thus, the goblin shark appears to forage for food both near the sea floor and far above it.

Since it is not a fast swimmer, the goblin shark may be an ambush predator. Its low-density flesh and large oily liver make it neutrally buoyant, allowing it to drift towards its prey with minimal motions so as to avoid detection. Once prey comes into range, the shark's specialized jaws can snap forward to capture it. The protrusion of the jaw is assisted by two pairs of elastic ligaments associated with the mandibular joint, which are pulled taut when the jaws are in their normal retracted position; when the shark bites, the ligaments release their tension and essentially "catapult" the jaws forward. At the same time, the well-developed basihyal (analogous to a tongue) on the floor of the mouth drops, expanding the oral cavity and sucking in water and prey. Striking and prey capture events were videotaped and recorded for the first time during 2008 and 2011 and helped to confirm the use and systematics of the protrusible jaws of goblin sharks. The video evidence suggests that while the jaws are definitely unique, goblin sharks use ram feeding, a type of prey capture that is typical of many mackerel sharks. What makes the goblin shark unique is the kinematics of their jaw when feeding. The lower jaw seems to undergo more complex movements and is important in capturing the prey. The measured protrusions of the upper and lower jaw combined put the goblin shark jaws at 2.1–9.5 times more protrusible than other sharks. The lower jaw has a velocity about two times greater than the upper jaw because it not only protrudes forward, but also swings upward to capture the prey, and the maximum velocity of the jaws is 3.14 m/s. The goblin shark has a re-opening and re-closing pattern during the strike, a behavior that has never been seen in other sharks before and could be related to the extent with which the goblin shark protrudes its jaws. This “slingshot” style of feeding could be an adaptation to compensate for poor swimming ability by allowing the goblin shark to catch elusive, fast prey without having to chase the prey.

Little is known about goblin shark reproduction because a pregnant female has yet to be found and studied. It likely shares the reproductive characteristics of other mackerel sharks, which are viviparous with small litter sizes and embryos that grow during gestation by eating undeveloped eggs (oophagy). The birth size is probably close to , the length of the smallest known specimen. Males mature sexually at about long, while female maturation size is unknown. No data is available concerning growth and aging.

Given the depths at which it lives, the goblin shark poses little danger to humans. A few specimens have been collected alive and brought to public aquariums, though they only survived briefly. One was kept at Tokai University and lived for a week, while another was kept at Tokyo Sea Life Park and lived for two days. Its economic significance is minimal; the meat may be dried and salted, while the jaws fetch high prices from collectors. At one time, the Japanese also used it for liver oil and fertilizer. This shark is not targeted by any fisheries, but is occasionally found as bycatch in bottom gillnets and trawls, hooked on longlines, or entangled in fishing gear. Most captures are isolated incidents; one of the few areas where it is caught regularly is off southern Japan, where around 30 individuals (mostly juveniles) are taken each year. A black scabbardfish ("Aphanopus carbo") fishery off Madeira also takes two or three goblin sharks annually. During April 2003, more than a hundred goblin sharks were caught off northwestern Taiwan; the cause of the event was unknown, though observers noted it was preceded by a major earthquake. The species had never been recorded in the area before, nor has it been found in such numbers since. The International Union for Conservation of Nature (IUCN) has categorized the goblin shark as Least Concern. In addition to its wide range, most of its population is thought to reside in unfished environments because few adults are caught. Therefore, it is not believed to be threatened by human activity. However during June 2018 the New Zealand Department of Conservation classified the goblin shark as "At Risk – Naturally Uncommon" with the qualifiers "Data Poor" and "Secure Overseas" using the New Zealand Threat Classification System.



</doc>
<doc id="318482" url="https://en.wikipedia.org/wiki?curid=318482" title="Anne Hutchinson">
Anne Hutchinson

Anne Hutchinson (née Marbury; July 1591 – August 1643) was a Puritan spiritual adviser, mother of 15, and an important participant in the Antinomian Controversy which shook the infant Massachusetts Bay Colony from 1636 to 1638. Her strong religious convictions were at odds with the established Puritan clergy in the Boston area, and her popularity and charisma helped create a theological schism that threatened to destroy the Puritans' religious community in New England. She was eventually tried and convicted, then banished from the colony with many of her supporters.

Hutchinson was born in Alford, Lincolnshire, England, the daughter of Francis Marbury, an Anglican cleric and school teacher who gave her a far better education than most other girls received. She lived in London as a young adult, and there married her old friend from home William Hutchinson. The couple moved back to Alford where they began following dynamic preacher John Cotton in the nearby port of Boston, Lincolnshire. Cotton was compelled to emigrate in 1633, and the Hutchinsons followed a year later with their 11 children and soon became well established in the growing settlement of Boston in New England. Anne was a midwife and very helpful to those needing her assistance, as well as forthcoming with her personal religious understandings. Soon she was hosting women at her house weekly, providing commentary on recent sermons. These meetings became so popular that she began offering meetings for men as well, including the young governor of the colony Henry Vane.

She began to accuse the local ministers (except for Cotton and her husband's brother-in-law John Wheelwright) of preaching a "covenant of works" rather than a "covenant of grace," and many ministers began to complain about her increasingly blatant accusations, as well as certain theological teachings that did not accord with orthodox Puritan theology. The situation eventually erupted into what is commonly called the Antinomian Controversy, culminating in her 1637 trial, conviction, and banishment from the colony. This was followed by a March 1638 church trial in which she was put out of her congregation.

Hutchinson and many of her supporters established the settlement of Portsmouth with encouragement from Providence Plantations founder Roger Williams in what became the Colony of Rhode Island and Providence Plantations. After her husband's death a few years later, threats of Massachusetts taking over Rhode Island compelled Hutchinson to move totally outside the reach of Boston into the lands of the Dutch. Five of her older surviving children remained in New England or in England, while she settled with her younger children near an ancient landmark called Split Rock in what later became The Bronx in New York City. Tensions were high at the time with the Siwanoy Indian tribe. In August 1643, Hutchinson, six of her children, and other household members were massacred by Siwanoys during Kieft's War. The only survivor was her nine year-old daughter Susanna, who was taken captive.

Hutchinson is a key figure in the history of religious freedom in England's American colonies and the history of women in ministry, challenging the authority of the ministers. She is honored by Massachusetts with a State House monument calling her a "courageous exponent of civil liberty and religious toleration." She has been called the most famous—or infamous—English woman in colonial American history.

Anne Hutchinson was born Anne Marbury in Alford, Lincolnshire, England, and baptised there on 20 July 1591, the daughter of Francis Marbury and Bridget Dryden. Her father was an Anglican cleric in London with strong Puritan leanings, who felt strongly that clergy should be well educated and clashed with his superiors on this issue. Marbury's repeated challenges to the Anglican authorities led to his censure and imprisonment several years before Anne was born. In 1578, he was given a public trial, of which he made a transcript from memory during a period of house arrest. He later used this transcript to educate and amuse his children, he being the hero and the Bishop of London being portrayed as a buffoon. For his conviction of heresy, Marbury spent two years in Marshalsea Prison on the south side of the River Thames across from London. In 1580, at the age of 25, he was released and was considered sufficiently reformed to preach and teach. He moved to the remote market town of Alford in Lincolnshire, about north of London.

Anne's father was soon appointed curate (deputy vicar) of Saint Wilfrid's, the local church in Alford, and in 1585 he also became the schoolmaster at the Alford Free Grammar School, one of many such public schools, free to the poor and begun by Queen Elizabeth. About this time, Marbury married his first wife Elizabeth Moore, who bore three children, then died. Within a year of his first wife's death, Marbury married Bridget Dryden, about ten years younger than he and from a prominent Northampton family. Bridget's brother Erasmus was the grandfather of John Dryden, the famous playwright and Poet Laureate. Anne was the third of 15 children born to this marriage, 12 of whom survived early childhood. The Marburys lived in Alford for the first 15 years of Anne's life, and she received a better education than most girls of her time, with her father's strong commitment to learning, and she also became intimately familiar with scripture and Christian tenets. Education at that time was almost exclusively offered to boys and men. One possible reason why Marbury taught his daughters may have been that six of his first seven children were girls. Another reason may have been that the ruling class in Elizabethan England began realising that girls could be schooled, looking to the example of the queen, who spoke six foreign languages.

The family moved from Alford to the heart of London in 1605 when Anne was 15, where her father was given the position of vicar of the Church of Saint Martin's in the Vintry. Here his expression of puritan views was tolerated, though somewhat muffled, because of a shortage of pastors. Marbury took on additional work in 1608, preaching in the parish of Saint Pancras, several miles northwest of the city, travelling there by horseback twice a week. In 1610, he replaced that position with one much closer to home and became rector of Saint Margaret's on New Fish Street, only a short walk from Saint Martin in the Vintry. He was at a high point in his career, but he died suddenly at the age of 55 in February 1611, when Anne was 19 years old.

The year after her father's death, Anne Marbury, aged 21, married William Hutchinson, a familiar acquaintance from Alford who was a fabric merchant then working in London. The couple was married at St Mary Woolnoth Church in London on 9 August 1612, shortly after which they moved back to their hometown of Alford.

Soon they heard about an engaging minister named John Cotton who preached at Saints Botolph's Church in the large port of Boston, about from Alford. Cotton was installed as minister at Boston the year that the Hutchinsons were married, after having been a tutor at Emmanuel College in Cambridge. He was only 27 years old, yet he had gained a reputation as one of the leading Puritans in England. Once the Hutchinsons heard Cotton preach, the couple made the trip to Boston as often as possible, enduring the ride by horseback when the weather and circumstances allowed. Cotton's spiritual message was different from that of his fellow Puritans, as he placed less emphasis on one's behaviour to attain God's salvation and more emphasis on the moment of religious conversion "in which mortal man was infused with a divine grace." Anne Hutchinson was greatly attracted to Cotton's theology of "absolute grace", which caused her to question the value of "works" and to view the Holy Spirit as "indwelling in the elect saint". This allowed her to identify as a "mystic participant in the transcendent power of the Almighty"; such a theology was empowering to women, according to Eve LaPlante, whose status was otherwise determined by their husbands or fathers.

Another strong influence on Hutchinson was closer to her home in the nearby town of Bilsby. Her brother-in-law, the young minister John Wheelwright, preached a message like that of Cotton. As reformers, both Cotton and Wheelwright encouraged a sense of religious rebirth among their parishioners, but their weekly sermons did not satisfy the yearnings of some Puritan worshippers. This led to the rise of conventicles, which were gatherings of "those who had found grace" to listen to sermon repetitions, discuss and debate scripture, and pray. These gatherings were particularly important to women because they allowed women to take on roles of religious leadership that were otherwise denied them in a male-dominated church hierarchy, according to some modern scholars. Hutchinson was inspired by Cotton and by other women who ran conventicles, and she began holding meetings in her own home, where she reviewed recent sermons with her listeners, and provided her own explanations of the message.

The Puritans wanted to do away with the ceremony of the Church of England and govern their churches based on a consensus of the parishioners. They preferred to eliminate bishops appointed by the monarchs, choose their own church elders (or governors), and provide for a lay leader and two ministers—one a teacher in charge of doctrine, and the other a pastor in charge of people's souls. By 1633, Cotton's inclination toward such Puritan practices had attracted the attention of Archbishop William Laud, who was on a campaign to suppress any preaching and practices that did not conform to the practices of the established Anglican Church. In that year, Cotton was removed from his ministry, and he went into hiding. Threatened with imprisonment, he made a hasty departure for New England aboard the ship "Griffin", taking his pregnant wife. She gave birth to their child during the voyage to the colonies, whom they named Seaborn.

When Cotton left England, Anne Hutchinson described it as a "great trouble unto her," and said that she "could not be at rest" until she followed her minister to New England. Hutchinson believed that the Spirit instructed her to follow Cotton to America, "impressed by the evidence of divine providence". She was well into her 14th pregnancy, however, so she did not travel until after the baby was born. With the intention of soon going to New England, the Hutchinsons allowed their oldest son Edward to sail with Cotton before the remainder of the family made the voyage. In 1634, 43-year-old Anne Hutchinson set sail from England with her 48-year-old husband William and their other ten surviving children, aged about eight months to 19 years. They sailed aboard the "Griffin", the same ship that had carried Cotton and their oldest son a year earlier.

William Hutchinson was highly successful in his mercantile business and brought a considerable estate with him to New England, arriving in Boston in the late summer of 1634. The Hutchinson family purchased a half-acre lot on the Shawmut Peninsula, now downtown Boston. Here they had a house built, one of the largest on the peninsula, with a timber frame and at least two stories. (The house stood until October 1711, when it was consumed in the great fire of Boston, after which the Old Corner Bookstore was built on the site.) The Hutchinsons soon were granted Taylor's Island in the Boston harbour, where they grazed their sheep, and they also acquired 600 acres of land at Mount Wollaston, south of Boston in the area that later became Quincy. Once established, William Hutchinson continued to prosper in the cloth trade, and made land purchases and investments. He became a town selectman and deputy to the General Court. Anne Hutchinson likewise fit into her new home with ease, devoting many hours to those who were ill or in need. She became an active midwife, and while tending to women in childbirth, she provided them with spiritual advice. Magistrate John Winthrop noted that "her ordinary talke was about the things of the Kingdome of God," and "her usuall conversation was in the way of righteousness and kindnesse."

The Hutchinsons became members of the Boston church, the most important church in the colony. With its location and harbour, Boston was New England's centre of commerce, and its church was characterised by Winthrop as "the most publick, where Seamen and all Strangers came." The church membership had grown from 80 to 120 during Cotton's first four months there. In his journal, Winthrop proclaimed, "more were converted & added to that Churche, than to all the other Churches in the Baye." Historian Michael Winship noted in 2005 that the church seemed to approach the Puritan ideal of a Christian community. Early Massachusetts historian William Hubbard found the church to be "in so flourishing a condition as were scarce any where else to be paralleled." Winship considers it an exceptional twist of fate that the colony's most important church also had the most unconventional minister in John Cotton. The more extreme religious views of Hutchinson and Henry Vane, the colony's young governor, did not much stand out because of Cotton's divergence from the theology of his fellow ministers.

Hutchinson's visits to women in childbirth led to discussions along the lines of the conventicles in England. She soon began hosting weekly meetings at her home for women who wanted to discuss Cotton's sermons and hear her explanations and elaborations. Her meetings for women became so popular that she had to organise meetings for men, as well, and she was hosting 60 or more people per week. These gatherings brought women, as well as their husbands, "to enquire more seriously after the Lord Jesus Christ."

As the meetings continued, Hutchinson began offering her own religious views, stressing that only "an intuition of the Spirit" would lead to one's election by God, and not good works. Her theological interpretations began diverging from the more legalistic views found among the colony's ministers, and the attendance increased at her meetings and soon included Governor Vane. Her ideas that one's outward behaviour was not necessarily tied to the state of one's soul became attractive to those who might have been more attached to their professions than to their religious state, such as merchants and craftsmen. The colony's ministers became more aware of Hutchinson's meetings, and they contended that such "unauthorised" religious gatherings might confuse the faithful. Hutchinson responded to this with a verse from Titus, saying that "the elder women should instruct the younger."

Hutchinson's gatherings were seen as unorthodox by some of the colony's ministers, and differing religious opinions within the colony eventually became public debates. The resulting religious tension erupted into what has traditionally been called the Antinomian Controversy, but has more recently been labelled the Free Grace Controversy.

The Reverend Zechariah Symmes had sailed to New England on the same ship as the Hutchinsons. In September 1634, he told another minister that he doubted Anne Hutchinson's orthodoxy, based on questions that she asked him following his shipboard sermons. This issue delayed Hutchinson's membership to the Boston church by a week, until a pastoral examination determined that she was sufficiently orthodox to join the church.

In 1635, a difficult situation occurred when senior pastor John Wilson returned from a lengthy trip to England where he had been settling his affairs. Hutchinson was exposed to his teaching for the first time, and she immediately saw a big difference between her own doctrines and his. She found his emphasis on morality and his doctrine of "evidencing justification by sanctification" to be disagreeable. She told her followers that Wilson lacked "the seal of the Spirit." Wilson's theological views were in accord with all of the other ministers in the colony except for Cotton, who stressed "the inevitability of God's will" ("free grace") as opposed to preparation (works). Hutchinson and her allies had become accustomed to Cotton's doctrines, and they began disrupting Wilson's sermons, even finding excuses to leave when Wilson got up to preach or pray.

Thomas Shepard, the minister of Newtown (which later became Cambridge), began writing letters to Cotton as early as the spring of 1636. He expressed concern about Cotton's preaching and about some of the unorthodox opinions found among his Boston parishioners. Shepard went even further when he began criticising the Boston opinions to his Newtown congregation during his sermons. In May 1636, the Bostonians received a new ally when the Reverend John Wheelwright arrived from England and immediately aligned himself with Cotton, Hutchinson, and other "free grace" advocates. Wheelwright had been a close neighbor of the Hutchinsons in Lincolnshire, and his wife was a sister of Hutchinson's husband. Another boost for the free grace advocates came during the same month, when the young aristocrat Henry Vane was elected as the governor of the colony. Vane was a strong supporter of Hutchinson, but he also had his own ideas about theology that were considered not only unorthodox, but radical by some.

Hutchinson and the other free grace advocates continued to question the orthodox ministers in the colony. Wheelwright began preaching at Mount Wollaston, about ten miles south of the Boston meetinghouse, and his sermons began to answer Shepard's criticisms with his own criticism of the covenant of works. This mounting "pulpit aggression" continued throughout the summer, along with the lack of respect shown Boston's Reverend Wilson. Wilson endured these religious differences for several months before deciding that the affronts and errors were serious enough to require a response. He is the one who likely alerted magistrate John Winthrop, one of his parishioners, to take notice. On or shortly after 21 October 1636, Winthrop gave the first public warning of the problem that consumed him and the leadership of the Massachusetts Bay Colony for much of the next two years. In his journal he wrote, "One Mrs. Hutchinson, a member of the church at Boston, a woman of a ready wit and a bold spirit, brought over with her two dangerous errors: 1. That the person of the Holy Ghost dwells in a justified person. 2. That no sanctification can help to evidence to us our justification." He went on to elaborate these two points, and the Antinomian Controversy began with this journal entry.

On 25 October 1636, seven ministers gathered at the home of Cotton to confront the developing discord; they held a "private conference" which included Hutchinson and other lay leaders from the Boston church. Some agreement was reached, and Cotton "gave satisfaction to them [the other ministers], so as he agreed with them all in the point of sanctification, and so did Mr. Wheelwright; so as they all did hold, that sanctification did help to evidence justification." Another issue was that some of the ministers had heard that Hutchinson had criticised them during her conventicles for preaching a covenant of works and said that they were not able ministers of the New Testament. Hutchinson responded to this only when prompted, and only to one or two ministers at a time. She believed that her response, which was largely coaxed from her, was private and confidential. A year later, her words were used against her in a trial that resulted in her banishment from the colony.

By late 1636, as the controversy deepened, Hutchinson and her supporters were accused of two heresies in the Puritan church: antinomianism and familism. The word "antinomianism" literally means "against or opposed to the law"; in a theological context, it means "the moral law is not binding upon Christians, who are under the law of grace." According to this view, if one was under the law of grace, then moral law did not apply, allowing one to engage in immoral acts. Familism was named for a 16th-century sect called the Family of Love, and it involved one's perfect union with God under the Holy Spirit, coupled with freedom both from sin and from the responsibility for it. Hutchinson and her supporters were sometimes accused of engaging in immoral behaviour or "free love" in order to discredit them, but such acts were antithetical to their doctrine. Hutchinson, Wheelwright, and Vane all took leading roles as antagonists of the orthodox party, but theologically, it was Cotton's differences of opinion with the colony's other ministers that was at the centre of the controversy.

By winter, the theological schism had become great enough that the General Court called for a day of fasting to help ease the colony's difficulties. During the appointed fast-day on Thursday, 19 January 1637, Wheelwright preached at the Boston church in the afternoon. To the Puritan clergy, his sermon was "censurable and incited mischief." The colony's ministers were offended by the sermon, but the free grace advocates were encouraged, and they became more vociferous in their opposition to the "legal" ministers. Governor Vane began challenging the doctrines of the colony's divines, and supporters of Hutchinson refused to serve during the Pequot War of 1637 because Wilson was the chaplain of the expedition. Ministers worried that the bold stand of Hutchinson and her supporters began to threaten the "Puritan's holy experiment." Had they succeeded, historian Dunn believes that they would have profoundly changed the thrust of Massachusetts history.

By March, the political tide began to turn against the free grace advocates. Wheelwright was tried for contempt and sedition that month for his fast-day sermon and was convicted in a close vote, but not yet sentenced. During the election of May 1637, Henry Vane was replaced as governor by John Winthrop; in addition, all the other Boston magistrates who supported Hutchinson and Wheelwright were voted out of office. By the summer of 1637, Vane sailed back to England, never to return. With his departure, the time was ripe for the orthodox party to deal with the remainder of their rivals.

The autumn court of 1637 convened on 2 November and sentenced Wheelwright to banishment, ordering him to leave the colony within 14 days. Several of the other supporters of Hutchinson and Wheelwright were tried and given varied sentences. Following these preliminaries, it was Anne Hutchinson's turn to be tried.

Hutchinson was brought to trial on 7 November 1637, with Wheelwright banished and other court business taken care of. The trial was presided over by Governor John Winthrop, on the charge of "traducing [slandering] the ministers". Other charges against her were laid out by Winthrop, including being one who "troubled the peace of the commonwealth and churches", promoting and divulging opinions that had caused recent troubles, and continuing to hold meetings at her home despite a recent synod that had condemned them.

They found it difficult to charge her because she had never spoken her opinions in public, unlike Wheelwright and the other men who had been tried, nor had she ever signed any statements about them. Winthrop's first two lines of prosecution were to portray her as a co-conspirator of others who had openly caused trouble in the colony, and then to fault her for holding conventicles. Question by question, Hutchinson effectively stonewalled him in her responses, and Winthrop was unable to find a way to convert her known membership in a seditious faction into a convictable offence. Deputy governor Thomas Dudley had a substantial background in law, and he stepped in to assist the prosecution. Dudley questioned Hutchinson about her conventicles and her association with the other conspirators. With no answer by Hutchinson, he moved on to the charge of her slandering the ministers.

The remainder of the trial was spent on this last charge. The prosecution intended to demonstrate that Hutchinson had made disparaging remarks about the colony's ministers, and to use the October meeting as their evidence. Six ministers had presented to the court their written versions of the October conference, and Hutchinson agreed with the substance of their statements. Her defence was that she had spoken reluctantly and in private, that she "must either speak false or true in my answers" in the ministerial context of the meeting. In those private meetings, she had cited Proverbs 29:25, "The fear of man bringeth a snare: but whoso putteth his trust in the Lord shall be safe." The court was not interested in her distinction between public and private statements.

At the end of the first day of the trial, Winthrop recorded, "Mrs. Hutchinson, the court you see hath labored to bring you to acknowledge the error of your way that so you might be reduced. The time now grows late. We shall therefore give you a little more time to consider of it and therefore desire that you attend the court again in the morning." The first day had gone fairly well for Hutchinson, who had held her own in a battle of wits with the magistrates. Biographer Eve LaPlante suggests, "Her success before the court may have astonished her judges, but it was no surprise to her. She was confident of herself and her intellectual tools, largely because of the intimacy she felt with God."

During the morning of the second day of the trial, it appeared that Hutchinson had been given some legal counsel the previous evening, and she had more to say. She continued to criticise the ministers of violating their mandate of confidentiality. She said that they had deceived the court by not telling about her reluctance to share her thoughts with them. She insisted that the ministers testify under oath, which they were very hesitant to do. Magistrate Simon Bradstreet said that "she would make the ministers sin if they said something mistaken under oath", but she answered that if they were going to accuse her, "I desire it may be upon oath." As a matter of due process, the ministers would have to be sworn in, but would agree to do so only if the defence witnesses spoke first.

There were three such witnesses, all from the Boston church: deacon John Coggeshall, lay leader Thomas Leverett, and minister John Cotton. The first two witnesses made brief statements that had little effect on the court, but Cotton was grilled extensively. When Cotton testified, he tended to not remember many events of the October meeting, and attempted to soften the meaning of statements that Hutchinson was being accused of. He stressed that the ministers were not as upset about any Hutchinson remarks at the end of the October meeting as they appeared to be later. Dudley reiterated that Hutchinson had told the ministers that they were not able ministers of the New Testament; Cotton replied that he did not remember her saying that.

There was more parrying between Cotton and the court, but the exchanges were not picked up in the transcript of the proceedings. Hutchinson asked the court for leave to "give you the ground of what I know to be true." She then addressed the court with her own judgment:

This was the "dramatic high point of the most analyzed event of the free grace controversy", wrote historian Michael Winship. Historians have given a variety of reasons for this seemingly impulsive statement, including an "exultant impulse", "hysteria", "cracking under the strain of the inquest", and being "possessed of the Spirit". Winship, citing the work of historian Mary Beth Norton, suggests that Hutchinson consciously decided to explain why she knew that the divines of the colony were not able ministers of the New Testament. This was "not histrionics, but pedagogy," according to Winship; it was Hutchinson's attempt to teach the Court, and doing so was consistent with her character.

Hutchinson simplified the task of her opponents, whose prosecution had been somewhat shaky. Her revelation was considered not only seditious, but also in contempt of court. Cotton was pressed by Dudley on whether or not he supported Hutchinson's revelation; he said that he could find theological justification for it. Cotton may have still been angry over the zeal with which some opponents had come after the dissidents within his congregation. Winthrop was not interested in this quibbling, though; he was using Hutchinson's bold assertions to lead the court in the direction of rewriting history, according to the historical interpretations of Winship. Many of the Puritans had been convinced that there was a single destructive prophetic figure behind all of the difficulties that the colony had been having, and Hutchinson had just become the culprit. Winthrop addressed the court, "if therefore it be the mind of the court, looking at [her] as the principal cause of all our trouble, that they would now consider what is to be done with her."

The Bostonians made a final effort to slow the proceedings. William Coddington rose, asserting, "I do not see any clear witness against her, and you know it is a rule of the court that no man may be a judge and an accuser too," ending with, "Here is no law of God that she hath broken nor any law of the country that she hath broke, and therefore deserve no censure." The court wanted a sentence but could not proceed until some of the ministers spoke. Three of the ministers were sworn in, and each testified against Hutchinson. Winthrop moved to have her banished; in the ensuing tally, only the Boston deputies voted against conviction. Hutchinson challenged the sentence's legitimacy, saying, "I desire to know wherefore I am banished." Winthrop responded, "The court knows wherefore and is satisfied."

Hutchinson was called a heretic and an instrument of the devil, and was condemned to banishment by the Court "as being a woman not fit for our society". The Puritans sincerely believed that, in banishing Hutchinson, they were protecting God's eternal truth. Winthrop summed up the case with genuine feeling:

Following her civil trial, Hutchinson was put under house arrest and ordered to be gone by the end of the following March. In the interim, she was not allowed to return home, but was detained at the house of Joseph Weld, brother of the Reverend Thomas Weld, located in Roxbury, about two miles from her home in Boston. The distance was not great, yet Hutchinson was rarely able to see her children because of the weather, which was particularly harsh that winter. Winthrop referred to Hutchinson as "the prisoner" and was determined to keep her isolated so that others would not be inspired by her, according to LaPlante. She was frequently visited by various ministers, whose intent, according to LaPlante, was to reform her thinking but also to collect evidence against her. Thomas Shepard was there to "collect errors", and concluded that she was a dangerous woman. Shepard and the other ministers who visited her drew up a list of her theological errors and presented them to the Boston church, which decided that she should stand trial for these views.

Hutchinson was called to trial on Thursday, 15 March 1638, weary and in poor health following a four-month detention. The trial took place at her home church in Boston, though many of her supporters were gone. Her husband and other friends had already left the colony to prepare a new place to live. Her only family members present were her oldest son Edward and his wife, her daughter Faith and son-in-law Thomas Savage, and her sister Katherine with her husband Richard Scott.

The ministers intended to defend their orthodox doctrine and to examine Hutchinson's theological errors. Ruling elder Thomas Leverett was charged with managing the examination. He called Hutchinson and read the numerous errors with which she had been charged, and a nine-hour interrogation followed in which the ministers delved into some weighty points of theology. At the end of the session, only four of the many errors were covered, and Cotton was put in the uncomfortable position of delivering the admonition to his admirer. He said, "I would speake it to Gods Glory [that] you have bine an Instrument of doing some good amongst us… he hath given you a sharp apprehension, a ready utterance and abilitie to exprese yourselfe in the Cause of God." The ministers overwhelmingly concluded that Hutchinson's unsound beliefs outweighed all the good which she had done, and that she endangered the spiritual welfare of the community. 
Cotton continued,

Here Cotton was making a link between Hutchinson's theological ideas and the more extreme behaviour credited to the antinomians and familists. He concluded:
With this, Hutchinson was instructed to return in one week on the next lecture day.

Cotton had not yet given up on his parishioner. With the permission of the court, Hutchinson was allowed to spend the week at his home, where the recently arrived Reverend John Davenport was also staying. All week, the two ministers worked with her and, under their supervision, she wrote out a formal recantation of her unsound opinions that had formerly brought objection. Hutchinson stood at the next meeting on Thursday, 22 March and read her recantation in a subdued voice to the congregation. She admitted to having been wrong about the soul and spirit, wrong about the resurrection of the body, wrong in prophesying the destruction of the colony, and wrong in her demeanour toward the ministers, and she agreed that sanctification could be evidence of justification (what she called a "covenant of works") "as it flowes from Christ and is witnessed to us by the Spirit". Had the trial ended there, she would likely have remained in good standing with the Boston church, and had the possibility of returning some day.

Wilson explored an accusation made by Shepard at the end of the previous meeting, and new words brought on new assaults. The outcome of her trial was uncertain following the first day's grilling, but her downfall came when she would not acknowledge that she held certain theological errors before her four-month imprisonment. With this, she was accused of lying but, even at this point, Winthrop and a few of the ministers wanted her soul redeemed because of her significant evangelical work before she "set forth her owne stuffe". To these sentiments, Shepard vehemently argued that Hutchinson was a "Notorious Imposter" in whose heart there was never any grace. He admonished the "heinousness of her lying" during a time of supposed humiliation.

Shepard had swayed the proceedings, with Cotton signalling that he had given up on her, and her sentence was presented by Wilson:
Hutchinson was now banished from the colony and removed from the congregation, and her leading supporters had been given three months to leave the colony, including Coddington and Coggeshall, while others were disenfranchised or dismissed from their churches. The court in November had ordered that 58 citizens of Boston and 17 from adjacent towns be disarmed unless they repudiated the "seditious label" given them, and many of these people followed Hutchinson into exile.

During Hutchinson's imprisonment, several of her supporters prepared to leave the colony and settle elsewhere. One such group of men, including her husband Will, met on 7 March 1638 at the home of wealthy Boston merchant William Coddington. Ultimately, 23 men signed what is known as the Portsmouth Compact, forming themselves into a "Bodie Politick" and electing Coddington as their governor, but giving him the Biblical title of "judge". Nineteen of the signers initially planned to move to New Jersey or Long Island, but Roger Williams convinced them to settle in the area of his Providence Plantations settlement. Coddington purchased Aquidneck Island (later named Rhode Island) in the Narragansett Bay from the Narragansetts, and the settlement of Pocasset was founded (soon renamed Portsmouth). Anne Hutchinson followed in April, after the conclusion of her church trial.

Hutchinson, her children, and others accompanying her travelled for more than six days by foot in the April snow to get from Boston to Roger Williams' settlement at Providence. They took boats to get to Aquidneck Island, where many men had gone ahead of them to begin constructing houses. In the second week of April, she reunited with her husband, from whom she had been separated for nearly six months.

Hutchinson went into labour in May 1638, following the stress of her trial, her imprisonment all winter, and the difficult trip to Aquidneck Island. She delivered what her doctor John Clarke described as a handful of transparent grapes. This is known now as a hydatidiform mole, a condition occurring most often in women over 45, resulting from one or two sperm cells fertilising a blighted egg. Hutchinson had been ill most of the winter, with unusual weakness, throbbing headaches, and bouts of vomiting. Most writers on the subject agree that she had been pregnant during her trial. Historian Emery Battis, citing expert opinion, suggests that she may not have been pregnant at all during that time, but displaying acute symptoms of menopause. The following April after reuniting with her husband, she became pregnant, only to miscarry the hydatidiform mole. A woman could have suffered severe menopausal symptoms who had undergone a continuous cycle of pregnancies, deliveries, and lactations for 25 years, with the burdens of raising a large family and subjected to the extreme stress of her trials.

The Puritan leaders of the Massachusetts Bay Colony gloated over Hutchinson's suffering and also that of Mary Dyer, a follower who suffered the premature and stillbirth of a severely deformed infant. The leaders classified the women's misfortunes as the judgement of God. Winthrop wrote, "She brought forth not one, but thirty monstrous births or thereabouts", then continued, "see how the wisdom of God fitted this judgment to her sin every way, for look—as she had vented misshapen opinions, so she must bring forth deformed monsters." Massachusetts continued to persecute Hutchinson's followers who stayed in the Boston area. Laymen were sent from the Boston church to Portsmouth to convince Hutchinson of her errors; she shouted at them, "the Church at Boston? I know no such church, neither will I own it. Call it the whore and strumpet of Boston, but no Church of Christ!"

Less than a year after Pocasset was settled, it suffered rifts and civil difficulties. Coddington had openly supported Hutchinson following her trial, but he had become autocratic and began to alienate his fellow settlers. Early in 1639, Hutchinson became acquainted with Samuel Gorton, who attacked the legitimacy of the magistrates. On 28 April 1639, Gorton and a dozen other men ejected Coddington from power. Hutchinson may not have supported this rebellion, but her husband was chosen as the new governor. Two days later, over 30 men signed a document forming a new "civil body politic". Winthrop noted in his journal that at Aquidneck,
Coddington and several others left the colony, establishing the settlement of Newport at the south end of the island. The freemen of Pocasset changed the name of their town to Portsmouth. They adopted a new government which provided for trial by jury and separation of church and state. The men who accompanied Coddington to Newport tended to be the strongest leaders; several became presidents or governors of the entire united colony after 1646, such as Coggeshall, Nicholas Easton, William Brenton, Jeremy Clarke, and Henry Bull. On 12 March 1640, the towns of Portsmouth and Newport agreed to re-unite peacefully. Coddington became governor of the island, and William Hutchinson was chosen as one of his assistants. The towns were to remain autonomous with laws made by the citizens.

During her tenure in Portsmouth, Hutchinson developed a new philosophy concerning religion. She persuaded her husband to resign from his position as a magistrate, as Roger Williams put it, "because of the opinion, which she had newly taken up, of the unlawfulness of magistracy."

Hutchinson's husband William died some time after June 1641 at the age of 55, the same age at which Anne's father had died. He was buried in Portsmouth. No record of his death exists because there was no established church, which would have been the customary repository for such records.

Not long after the settlement of Aquidneck Island, the Massachusetts Bay Colony made some serious threats to take over the island and the entire Narragansett Bay area, causing Hutchinson and other settlers much anxiety. This compelled her to move totally out of the reach of the Bay colony and its sister colonies in Connecticut and New Haven and move into the jurisdiction of the Dutch. Hutchinson went to New Netherland some time after the summer of 1642 with seven of her children, a son-in-law, and several servants—16 total persons by several accounts. There they settled near an ancient landmark called Split Rock, not far from what became the Hutchinson River in northern Bronx, New York City. Other Rhode Island families were in the area, including the Throckmortons and the Cornells. By one account, Hutchinson bought her land from John Throckmorton (for whom Throggs Neck is named) who had earlier been a settler of Providence with Roger Williams, but was now living in New Netherland.

The Hutchinsons stayed temporarily in an abandoned house while a permanent house was being built with the help of James Sands, who had married Katherine Walker, a granddaughter of William Hutchinson's brother Edward. Sands later became a settler of Block Island (later New Shoreham, Rhode Island), and the Reverend Samuel Niles, another early settler of Block Island, recorded the following about Sands' experience in New Netherland:
Thus the natives gave overt clues that they were displeased with the settlement being formed there. The property had supposedly been secured by an agent of the Dutch West India Company in 1640, but the negotiation was transacted with members of the Siwanoy people in distant Norwalk, and the local natives likely had little to do with that transaction, if they even knew of it at all. Hutchinson was therefore taking a considerable risk in putting a permanent dwelling at this site.

The exact location of the Hutchinson house has been a source of great interest for several centuries. LaPlante hints in her biography of Hutchinson that the homestead was near the Indian Trail that went through modern-day Pelham Bay Park, on the east side of the Hutchinson River. Lockwood Barr offers another hypothesis, citing the extensive land title research of Otto Hufeland published by the Westchester Historical Society in 1929. He concluded that the site of the homestead was on the west side of the Hutchinson River in Eastchester. A map in Barr's book that appeared in the 1929 work shows the property bordering the river in an area that is now called Baychester, between two creeks called Rattlesnake Brook and Black Dog Brook. This area of the Bronx is now highly developed; Rattlesnake Brook is extant, mostly in underground culverts, but Black Dog Brook is defunct.

The Hutchinsons' settlement in this area coincided with the local unrest between the Colonists and the Indians. Governor Willem Kieft had aroused the ire of the Indians with his inhumanity and treachery, according to the opinion of some modern writers. Mrs. Hutchinson had a favorable relationship with the Narragansetts in Rhode Island, and she may have felt a false sense of safety among the Siwanoy of New Netherland. The Hutchinsons had been friendly to them, but the Indians destroyed the New Netherland colony in a series of incidents known as Kieft's War. The fate of the Hutchinson family was summarized by LaPlante:

The warriors then dragged the bodies into the house, along with the cattle, and burned the house to the ground. During the attack, Hutchinson's nine year-old daughter Susanna was out picking blueberries; she was found, according to legend, hidden in the crevice of Split Rock nearby. She is believed to have had red hair, which was unusual to the Indians, and perhaps because of this curiosity her life was spared. She was taken captive, was named "Autumn Leaf" by one account, and lived with the Indians for two to six years (accounts vary) until ransomed back to her family members, most of whom were living in Boston.

The exact date of the Hutchinson massacre is not known. The first definitive record of the occurrence was in John Winthrop's journal, where it was the first entry made for the month of September, though not dated. It took days or even weeks for Winthrop to receive the news, so the event almost certainly occurred in August 1643, and this is the date found in most sources.

The reaction in Massachusetts to Hutchinson's death was harsh. The Reverend Thomas Weld wrote, "The Lord heard our groans to heaven, and freed us from our great and sore affliction…. I never heard that the Indians in those parts did ever before this commit the like outrage upon any one family or families; and therefore God's hand is the more apparently seen herein, to pick out this woeful woman". Peter Bulkley, the pastor at Concord, wrote, "Let her damned heresies, and the just vengeance of God, by which she perished, terrify all her seduced followers from having any more to do with her leaven."

Wampage claimed to have slain Hutchinson, and legend has it that he assumed her name after the massacre, calling himself "Anne Hoeck" to be honored by using the name of his most famous victim. Eleven years after the event, he confirmed a deed transferring the Hutchinsons' property to Thomas Pell, with his name on the document being given as "Ann Hoeck alias Wampage."

Hutchinson claimed that she was a prophetess, receiving direct revelation from God. In this capacity, she prophesied during her trial that God would send judgment upon the Massachusetts Bay Colony and would wipe it from existence. She further taught her followers that personal revelation from God was as authoritative in a person's life as the Bible, a teaching that was strongly antithetical to Puritan theology. She also claimed that she could identify "the elect" among the colonists. These positions ultimately caused John Cotton, John Winthrop, and other former friends to view her as an antinomian heretic.

According to modern historian Michael Winship, Hutchinson is famous, not so much for what she did or said during the Antinomian Controversy, but for what John Winthrop made of her in his journal and in his account of the controversy called the "Short Story". According to Winship, Hutchinson became the reason in Winthrop's mind for all of the difficulties that the colony had gone through, though inaccurately portrayed and, with her departure, any other lingering issues were swept under the carpet. Winthrop's account has given Hutchinson near legendary status and, as with all legends, what exactly she stood for has shifted over the centuries. Winthrop described her as "a woman of ready wit and bold spirit". In the words of Winship, to Winthrop, Hutchinson was a "hell-spawned agent of destructive anarchy". The close relationship between church and state in Massachusetts Bay meant that a challenge to the ministers was quickly interpreted as challenge to established authority of all kinds. To 19th century America, she was a crusader for religious liberty, as the nation celebrated its new achievement of the separation of church and state. Finally, in the 20th century, she became a feminist leader, credited with terrifying the patriarchs, not because of her religious views but because she was an assertive, highly visible woman. According to feminist Amy Lang, Hutchinson failed to understand that "the force of the female heretic vastly exceeds her heresy". Lang argues that it was difficult for the court to pin a crime on her; her true crime in their eyes, according to Lang's interpretation, was the violation of her role in Puritan society, and she was condemned for undertaking the roles of teacher, minister, magistrate, and husband. (However, the Puritans themselves clearly stated that the threat which they perceived was entirely theological, and no direct mention was ever made to indicate that they were threatened by her gender.)

Winship calls Hutchinson "a prophet, spiritual adviser, mother of fifteen, and important participant in a fierce religious controversy that shook the infant Massachusetts Bay Colony from 1636 to 1638", upheld as a symbol of religious freedom, liberal thinking, and Christian feminism. Anne Hutchinson is a contentious figure, having been lionized, mythologized, and demonized by various writers. In particular, historians and other observers have interpreted and re-interpreted her life within the following frameworks: the status of women, power struggles within the Church, and a similar struggle within the secular political structure. As to her overall historical impact, Winship writes, "Hutchinson's well-publicized trials and the attendant accusations against her made her the most famous, or infamous, English woman in colonial American history."

In front of the State House in Boston, Massachusetts stands a statue of Anne Hutchinson with her daughter Susanna as a child. The statue, dedicated in 1922, has an inscription on the marble pediment that reads:

The memorial is featured on the Boston Women's Heritage Trail.

Another memorial to Hutchinson was erected south of Boston in Quincy, Massachusetts, at the corner of Beale Street and Grandview Avenue. This is near the location where the Hutchinsons owned a 600-acre farm with a house, and this is where they stayed for several days in early spring 1638 while making the trip from Boston to their new home on Aquidneck Island.

Anne Hutchinson was inducted into the National Women's Hall of Fame in 1994.

According to Hutchinson biographer Eve LaPlante, some literary critics trace the character of Hester Prynne in Nathaniel Hawthorne's "The Scarlet Letter" to Hutchinson's persecution in the Massachusetts Bay Colony. Historian Amy Lang wrote that Hester Prynne was the embodiment of a fictional Anne Hutchinson—a Hutchinson created by the early Puritan chroniclers. Lang notes that Hester was what orthodox Puritans said Hutchinson was, either in reality or at least spiritually. The parallel is that Hutchinson was the heretic who metaphorically seduced the Puritan community, while in Hawthorne's novel Hester Prynne literally seduced the minister of her community.

Anne Hutchinson and her political struggle with Governor Winthrop are depicted in the 1980 play "Goodly Creatures" by William Gibson. Other notable historical characters who appear in the play are Reverend John Cotton, Governor Harry Vane, and future Quaker martyr Mary Dyer. In January 2014, Dan Shore's opera "Anne Hutchinson", with libretto by William A. Fregosi and Fritz Bell, was performed twice in Boston, Massachusetts by the Intermezzo Opera Company. In February 2015, researcher Claire Bellerjeau discovered and positively identified a tribute poem to Anne Hutchinson written in 1770 by Jupiter Hammon, the first published Black American poet.

In southern New York, Hutchinson's most prominent namesakes are the Hutchinson River, one of the very few rivers named after a woman, and a highway, the Hutchinson River Parkway. Elementary schools are named for her, such as in the Westchester County towns of Pelham and Eastchester.

In Portsmouth, Rhode Island, Anne Hutchinson and her friend Mary Dyer, the Quaker martyr, have been remembered at Founders Brook Park with the Anne Hutchinson/Mary Dyer Memorial Herb Garden, a medicinal botanical garden set by a scenic waterfall and historical marker for the early settlement of Portsmouth. The garden was created by artist and herbalist Michael Steven Ford, who is a descendant of both women. The memorial was a grass roots effort by a local Newport organisation, the Anne Hutchinson Memorial Committee headed by Newport artist Valerie Debrule. The organization is called Friends of Anne Hutchinson; it meets annually at the memorial in Portsmouth on the Sunday nearest to 20 July, the date of Anne's baptism, to celebrate her life and the local colonial history of the women of Aquidneck Island. Hutchinson Hall, an underclassmen residence hall at the University of Rhode Island, is named in her honor.
Hutchinson is honoured together with Roger Williams with a feast day on the liturgical calendar of the Episcopal Church in the United States of America on 5 February.

In 1987, Massachusetts Governor Michael Dukakis pardoned Anne Hutchinson, revoking the order of banishment by Governor Winthrop 350 years earlier.

Anne and William Hutchinson had 15 children, all of them born and baptized in Alford except for the last child, who was baptized in Boston, Massachusetts. Of the 14 children born in England, 11 lived to sail to New England.

The oldest child Edward was baptized 28 May 1613. He signed the Portsmouth Compact and settled on Aquidneck Island with his parents, but he soon made peace with the Massachusetts authorities and returned to Boston. He was an officer in the colonial militia, and died from wounds received during King Philip's War. Susanna was baptised 4 September 1614 and died in Alford during the plague in 1630. Richard (baptized 8 December 1615) was admitted to the Boston church in 1634, but he returned to England and no further record has been found. Faith (baptized 14 August 1617) married Thomas Savage and lived in Boston, dying about 1651. Bridget (baptised 15 January 1618/9) married John Sanford and lived in Portsmouth, Rhode Island, where her husband was briefly governor of the island; she died by 1698.

Francis (baptized 24 December 1620) was the oldest of the children to perish in the massacre in New Netherland. Elizabeth (baptized 17 February 1621/2) died during the plague in Alford and was buried there on 4 October 1630. William (baptized 22 June 1623) died during infancy. Samuel (baptized 17 December 1624) lived in Boston, married, and had a child, but left behind few records. Anne (baptized 5 May 1626) married William Collins, and both of them went to New Netherland and perished in the massacre with her mother. Mary (baptized 22 February 1627/8), Katherine (baptized 7 February 1629/30), William (baptized 28 September 1631), and daughter Zuriel (baptized in Boston 13 March 1635/6) were all children when they went with their mother to New Netherland, and were killed during the Indian massacre in the late summer of 1643. Susanna was the 14th child of the Hutchinsons and the youngest born in England, baptized 15 November 1633. She survived the Indian attack in 1643, was taken captive, and eventually was traded to the English, after which she married John Cole and had 11 children with him.

Of Hutchinson's dozen or more siblings who survived childhood, only one other came to New England; her youngest sister, Katherine, the wife of Richard Scott, came to Boston and then Providence. With her husband, Katherine was a Puritan, Baptist, and then Quaker, and was whipped in Boston for supporting her future son-in-law Christopher Holder who had his right ear cut off for his Quaker evangelism.

A number of Anne Hutchinson's descendants have reached great prominence. Among them are United States Presidents Franklin D. Roosevelt, George H. W. Bush, and George W. Bush, as are presidential aspirants Stephen A. Douglas, George W. Romney, and Mitt Romney. Her grandson Peleg Sanford was a governor of the Colony of Rhode Island and Providence Plantations. Other descendants include Chief Justice of the United States Supreme Court Melville Weston Fuller and Associate Justice Oliver Wendell Holmes, Jr.; Lord Chancellor of England John Singleton Copley, Jr., who was the first Lord Lyndhurst; President of Harvard University Charles William Eliot; actor Ted Danson; and opera singer and socialite Madam Lillie Fay Moulton De Hegermann-Lindencrone. One descendant bearing the Hutchinson name was her ill-fated great-great-grandson Thomas Hutchinson, who was a loyalist Governor of the Province of Massachusetts Bay at the time of the Boston Tea Party, an event leading to the American Revolutionary War.

In 1914, John Champlin published the bulk of the currently known ancestry of Anne Hutchinson, showing her descent on her father's side of the family from Charlemagne and Alfred the Great. Gary Boyd Roberts and others have published her line of descent on her mother's side from Edward I of England, thus connecting her with Edward's great grandparents, Henry II of England and his wife, Eleanor of Aquitaine. Most of the material in the following ancestor chart is from Champlin, except for the Williamson line which was published in "The American Genealogist" by F. N. Craig in 1992.



"Online sources"



Anne Hutchinson was inducted into the National Women's Hall of Fame in 1994, and the Rhode Island Women's Hall of Fame in 1997:


</doc>
<doc id="318677" url="https://en.wikipedia.org/wiki?curid=318677" title="George W. Romney">
George W. Romney

George Wilcken Romney (July 8, 1907 – July 26, 1995) was an American businessman and Republican Party politician. He was chairman and president of American Motors Corporation from 1954 to 1962, the 43rd Governor of Michigan from 1963 to 1969, and the United States Secretary of Housing and Urban Development from 1969 to 1973. He was the father of Governor of Massachusetts, 2012 Republican presidential nominee and United States Senator from Utah Mitt Romney, husband of 1970 U.S. Senate candidate Lenore Romney, and grandfather of current Republican National Committee chair Ronna McDaniel.

Romney was born to American parents living in the Mormon colonies in Mexico; events during the Mexican Revolution forced his family to flee back to the United States when he was a child. The family lived in several states and ended up in Salt Lake City, Utah, where they struggled during the Great Depression. Romney worked in a number of jobs, served as a Mormon missionary in the United Kingdom, and attended several colleges in the U.S. but did not graduate from any of them. In 1939 he moved to Detroit and joined the American Automobile Manufacturers Association, where he served as the chief spokesman for the automobile industry during World War II and headed a cooperative arrangement in which companies could share production improvements. He joined Nash-Kelvinator in 1948, and became the chief executive of its successor, American Motors Corporation, in 1954. There he turned around the struggling firm by focusing all efforts on the compact Rambler car. Romney mocked the products of the "Big Three" automakers as "gas-guzzling dinosaurs" and became one of the first high-profile, media-savvy business executives. Devoutly religious, he presided over the Detroit Stake of The Church of Jesus Christ of Latter-day Saints.

Having entered politics by participating in a state constitutional convention to rewrite the Michigan Constitution during 1961–1962, Romney was elected Governor of Michigan in 1962. Re-elected by increasingly large margins in 1964 and 1966, he worked to overhaul the state's financial and revenue structure, greatly expanding the size of state government and introducing Michigan's first state income tax. Romney was a strong supporter of the American Civil Rights Movement. He briefly represented moderate Republicans against conservative Republican Barry Goldwater during the 1964 U.S. presidential election. He requested the intervention of federal troops during the 1967 Detroit riot.

Initially a front runner for the Republican nomination for President of the United States in the 1968 election, he proved an ineffective campaigner and fell behind Richard Nixon in polls. After a mid-1967 remark that his earlier support for the Vietnam War had been due to a "brainwashing" by U.S. military and diplomatic officials in Vietnam, his campaign faltered even more and he withdrew from the contest in early 1968. After Nixon's election as president, he appointed Romney as Secretary of Housing and Urban Development. Romney's ambitious plans for housing production increases for the poor, and for open housing to desegregate suburbs, were modestly successful but often thwarted by Nixon. Romney left the administration at the start of Nixon's second term in 1973. Returning to private life, he advocated volunteerism and public service, and headed the National Center for Voluntary Action and its successor organizations from 1973 through 1991. He also served as a regional representative of the Twelve within his church.

Romney's grandparents were polygamous Mormons who fled the United States with their children owing to the federal government's prosecution of polygamy. His maternal grandfather was Helaman Pratt (1846–1909), who presided over the Mormon mission in Mexico City before moving to the Mexican state of Chihuahua and who was the son of original Mormon apostle Parley P. Pratt (1807–1857). In the 1920s, Romney's uncle Rey L. Pratt (1878–1931) played a major role in the preservation and expansion of the Mormon presence in Mexico and in its introduction to South America. A more distant kinsman was George Romney (1734–1802), a noted portrait painter in Britain during the last quarter of the 18th century.

Romney's parents, Gaskell Romney (1871–1955) and Anna Amelia Pratt (1876–1926), were United States citizens and natives of the Territory of Utah. They married in 1895 in Mexico and lived in Colonia Dublán in Galeana in the state of Chihuahua (one of the Mormon colonies in Mexico), where George was born on July 8, 1907. They practiced monogamy (polygamy having been abolished by the 1890 Manifesto, although it persisted in places, especially Mexico). George had three older brothers, two younger brothers, and a younger sister. Gaskell Romney was a successful carpenter, house builder, and farmer who headed the most prosperous family in the colony, which was situated in an agricultural valley below the Sierra Madre Occidental. The family chose U.S. citizenship for their children, including George.

The Mexican Revolution broke out in 1910 and the Mormon colonies were endangered in 1911–1912 by raids from marauders, including "Red Flaggers" Pascual Orozco and José Inés Salazar. Young George heard the sound of distant gunfire and saw rebels walking through the village streets. The Romney family fled and returned to the United States in July 1912, leaving their home and almost all of their property behind. Romney later said, "We were the first displaced persons of the 20th century."

In the United States, Romney grew up in humble circumstances. The family subsisted with other Mormon refugees on government relief in El Paso, Texas, benefiting from a $100,000 fund for refugees that the U.S. Congress had set up. After a few months they moved to Los Angeles, California, where Gaskell Romney worked as a carpenter. In kindergarten, other children mocked Romney's national origin by calling him "Mex".
In 1913, the family moved to Oakley, Idaho, and bought a farm, where they grew and subsisted largely on Idaho potatoes. The farm was not on good land and failed when potato prices fell. The family moved to Salt Lake City, Utah, in 1916, where Gaskell Romney resumed construction work, but the family remained generally poor. In 1917, they moved to Rexburg, Idaho, where Gaskell became a successful home and commercial builder in a growing area due to high World War I commodities prices.

George started working in wheat and sugar beet fields at the age of eleven and was the valedictorian at his grammar school graduation in 1921 (by the sixth grade he had attended six different schools). The Depression of 1920–21 brought a collapse in prices, and local building was abandoned. His family returned to Salt Lake City in 1921, and while his father resumed construction work, George became skilled at lath-and-plaster work. The family was again prospering when the Great Depression hit in 1929 and ruined them. George watched his parents fail financially in Idaho and Utah and having to take a dozen years to pay off their debts. Seeing their struggles influenced his life and business career.

In Salt Lake City, Romney worked while attending Roosevelt Junior High School and, beginning in 1922, Latter-day Saints High School. There he played halfback on the football team, guard on the basketball team, and right field on the baseball team, all with more persistence than talent, but in an effort to uphold the family tradition of athleticism, he earned varsity letters in all three sports. In his senior year, he and junior Lenore LaFount became high school sweethearts; she was from a more well-assimilated Mormon family. Academically, Romney was steady but undistinguished. He graduated from high school in 1925; his yearbook picture caption was "Serious, high minded, of noble nature – a real fellow."

Partly to stay near Lenore, Romney spent the next year as a junior college student at the co-located Latter-day Saints University, where he was elected student body president. He was also president of the booster club and played on the basketball team that won the Utah–Idaho Junior College Tournament.

After becoming an elder, Romney earned enough money working to fund himself as a Mormon missionary. In October 1926, he sailed to Great Britain and was first assigned to preach in a slum in Glasgow, Scotland. The abject poverty and hopelessness he saw there affected him greatly, but he was ineffective in gaining converts and temporarily suffered a crisis of faith.

In February 1927, he was shifted to Edinburgh and in February 1928 to London, where he kept track of mission finances. He worked under renowned Quorum of the Twelve Apostles intellectuals James E. Talmage and John A. Widtsoe; the latter's admonitions to "Live mightily today, the greatest day of all time is today" made a lasting impression on him. Romney experienced British sights and culture and was introduced to members of the peerage and the Oxford Group.

In August 1928, Romney became president of the Scottish missionary district. Operating in a whisky-centric region was difficult, and he developed a new "task force" approach of sending more missionaries to a single location at a time; this successfully drew local press attention and several hundred new recruits. Romney's frequent public proselytizing – from Edinburgh's Mound and in London from soap boxes at Speakers' Corner in Hyde Park and from a platform at Trafalgar Square – developed his gifts for debate and sales, which he would use the rest of his career. Three decades later, Romney said that his missionary time had meant more to him in developing his career than any other experience.

Romney returned to the U.S. in late 1928 and studied briefly at the University of Utah and LDS Business College. He followed LaFount to Washington, D.C., in fall 1929, after her father, Harold A. Lafount, had accepted an appointment by President Calvin Coolidge to serve on the Federal Radio Commission. He worked for Massachusetts Democratic U.S. Senator David I. Walsh during 1929 and 1930, first as a stenographer using speedwriting, then, when his abilities at that proved limited, as a staff aide working on tariffs and other legislative matters. Romney researched aspects of the proposed Smoot-Hawley tariff legislation and sat in on committee meetings; the job was a turning point in his career and gave him lifelong confidence in dealing with Congress.

With one of his brothers, Romney opened a dairy bar in nearby Rosslyn, Virginia, during this time. The business soon failed, in the midst of the Great Depression. He also attended George Washington University at night. Based upon a connection he made working for Walsh, Romney was hired as an apprentice for Alcoa in Pittsburgh in June 1930.

When LaFount, an aspiring actress, began earning bit roles in Hollywood movies, Romney arranged to be transferred to Alcoa's Los Angeles office for training as a salesman. There he took night classes at the University of Southern California. (Romney did not attend for long, or graduate from, any of the colleges in which he was enrolled, accumulating only 2½ years of credits; instead he has been described as an autodidact.) LaFount had the opportunity to sign a $50,000, three-year contract with Metro-Goldwyn-Mayer studios, but Romney convinced her to return to Washington with him as he was assigned a position there with Alcoa as a lobbyist. She later said she had never had a choice of both marriage and an acting career, because the latter would have upstaged him, but expressed no regrets about having chosen the former. Romney would later consider wooing her his greatest sales achievement.

The couple married on July 2, 1931, at Salt Lake City Temple. They would have four children: Margo Lynn (born 1935), Jane LaFount (born 1938), George Scott (born 1941), and Willard Mitt (born 1947). The couple's marriage reflected aspects of their personalities and courtship. George was devoted to Lenore, and tried to bring her a flower every day, often a single rose with a love note. George was also a strong, blunt personality used to winning arguments by force of will, but the more self-controlled Lenore was unintimidated and willing to push back against him. The couple quarreled so much as a result that their grandchildren would later nickname them "the Bickersons", but in the end, their closeness would allow them to settle arguments amicably.

As a lobbyist, Romney frequently competed on behalf of the aluminum industry against the copper industry, and defended Alcoa against charges of being a monopoly. He also represented the Aluminum Wares Association. In the early 1930s, he helped get aluminum windows installed in the U.S. Department of Commerce Building, at the time the largest office building in the world.

Romney joined the National Press Club and the Burning Tree and Congressional Country Clubs; one reporter watching Romney hurriedly play golf at the last said, "There is a young man who knows where he is going." Lenore's cultural refinement and hosting skills, along with her father's social and political connections, helped George in business, and the couple met the Hoovers, the Roosevelts, and other prominent Washington figures. He was chosen by Pyke Johnson, a Denver newspaperman and automotive industry trade representative he met at the Press Club, to join the newly formed Trade Association Advisory Committee to the National Recovery Administration. The committee's work continued even after the agency was declared unconstitutional in 1935. During 1937 and 1938, Romney was also president of the Washington Trade Association Executives.

After nine years with Alcoa, Romney's career had stagnated; there were many layers of executives to climb through and a key promotion he had wanted was given to someone with more seniority. Pyke Johnson was vice president of the Automobile Manufacturers Association, which needed a manager for its new Detroit office. Romney got the job and moved there with his wife and two daughters in 1939. An association study found Americans using their cars more for short trips and convinced Romney that the trend was towards more functional, basic transportation. In 1942, he was promoted to general manager of the association, a position he held until 1948. Romney also served as president of the Detroit Trade Association in 1941.

In 1940, as World War II raged overseas, Romney helped start the Automotive Committee for Air Defense, which coordinated planning between the automobile and aircraft industries. Immediately following the December 1941 attack on Pearl Harbor that drew the U.S. into the war, Romney helped turn that committee into, and became managing director of, the Automotive Council for War Production. This organization established a cooperative arrangement in which companies could share machine tools and production improvements, thus maximizing the industry's contribution to the war production effort. It embodied Romney's notion of "competitive cooperative capitalism".

With labor leader Victor Reuther, Romney led the Detroit Victory Council, which sought to improve conditions for Detroit workers under wartime stress and deal with the causes of the Detroit race riot of 1943. Romney successfully appealed to the Federal Housing Administration to make housing available to black workers near the Ford Willow Run plant. He also served on the labor-management committee of the Detroit section of the War Manpower Commission.

Romney became the chief spokesman of the automobile industry, often testifying before Congressional hearings about production, labor, and management issues; he was mentioned or quoted in over 80 stories in "The New York Times" during this time. By war's end, 654 manufacturing companies had joined the Automotive Council for War Production, and produced nearly $29 billion in output for the Allied military forces. This included over 3 million motorized vehicles, 80 percent of all tanks and tank parts, 75 percent of all aircraft engines, half of all diesel engines, and a third of all machine guns. Between a fifth and a quarter of all U.S. wartime production was accounted for by the automotive industry.

As peacetime production began, Romney persuaded government officials to forgo complex contract-termination procedures, thus freeing auto plants to quickly produce cars for domestic consumption and avoid large layoffs. Romney was director of the American Trade Association Executives in 1944 and 1947, and managing director of the National Automobile Golden Jubilee Committee in 1946. From 1946 to 1949, he represented U.S. employers as a delegate to the Metal Trades Industry conference of the International Labor Office. By 1950, Romney was a member of the Citizens Housing and Planning Council, and criticized racial segregation in Detroit's housing program when speaking before the Detroit City Council. Romney's personality was blunt and intense, giving the impression of a "man in a hurry", and he was considered a rising star in the industry.

As managing director of the Automobile Manufacturers Association, Romney became good friends with then-president George W. Mason. When Mason became chairman of the manufacturing firm Nash-Kelvinator in 1948, he invited Romney along "to learn the business from the ground up" as his roving assistant, and the new executive spent a year working in different parts of the company. At an inefficient Detroit refrigerator plant of the Kelvinator appliance division, Romney battled the Mechanics Educational Society of America union to institute a new industrial–labor relations program that forestalled the whole facility being shut down. He appealed to the workers by saying, "I am no college man. I've laid floors, I've done lathing. I've thinned beets and shocked wheat." As Mason's protégé, Romney assumed executive assignment for the development of the Rambler.

Mason had long sought a merger of Nash-Kelvinator with one or more other companies, and on May 1, 1954, it merged with Hudson Motor Car to become the American Motors Corporation (AMC). It was the largest merger in the history of the industry, and Romney became an executive vice president of the new firm. In October 1954, Mason suddenly died of acute pancreatitis and pneumonia. Romney was named AMC's president and chairman of the board the same month.

When Romney took over, he reorganized upper management, brought in younger executives, and pruned and rebuilt AMC's dealer network. Romney believed that the only way to compete with the "Big Three" (General Motors, Ford, and Chrysler) was to stake the future of AMC on a new smaller-sized car line. Together with chief engineer Meade Moore, by the end of 1957 Romney had completely phased out the Nash and Hudson brands, whose sales had been lagging. The Rambler brand was selected for development and promotion, as AMC pursued an innovative strategy: manufacturing only compact cars. The company struggled badly at first, losing money in 1956, more in 1957, and experiencing defections from its dealer network. Romney instituted company-wide savings and efficiency measures, and he and other executives reduced their salaries by up to 35 percent.

Though AMC was on the verge of being taken over by corporate raider Louis Wolfson in 1957, Romney was able to fend him off. Then sales of the Rambler finally took off, leading to unexpected financial success for AMC. It posted its first quarterly profit in three years in 1958, was the only car company to show increased sales during the recession of 1958, and moved from thirteenth to seventh place among worldwide auto manufacturers.
In contrast with the Hudson's NASCAR racing success in the early 1950s, the Ramblers were frequent winners in the coast-to-coast Mobil Economy Run, an annual event on U.S. highways. Sales remained strong during 1960 and 1961; the Rambler was America's third most popular car both years.

A believer in "competitive cooperative consumerism", Romney was effective in his frequent appearances before Congress. He discussed what he saw as the twin evils of "big labor" and "big business", and called on Congress to break up the Big Three. As the Big Three automakers introduced ever-larger models, AMC undertook a "gas-guzzling dinosaur fighter" strategy, and Romney became the company spokesperson in print advertisements, public appearances, and commercials on the "Disneyland" television program. Known for his fast-paced, shirt-sleeved management style that ignored organization charts and levels of responsibility, he often wrote the ad copy himself.

Romney became what automotive writer Joe Sherman termed "a folk hero of the American auto industry" and one of the first high-profile media-savvy business executives. His focus on small cars as a challenge to AMC's domestic competitors, as well as the foreign-car invasion, was documented in the April 6, 1959, cover story of "Time" magazine, which concluded that "Romney has brought off singlehanded one of the most remarkable selling jobs in U.S. industry." A full biography of him was published in 1960; the company's resurgence made Romney a household name. The Associated Press named Romney its Man of the Year in Industry for four consecutive years, 1958 through 1961.

The company's stock rose from $7 per share to $90 per share, making Romney a millionaire from stock options. However, whenever he felt his salary and bonus was excessively high for a year, he gave the excess back to the company. After initial wariness, he developed a good relationship with United Automobile Workers leader Walter Reuther, and AMC workers also benefited from a then-novel profit-sharing plan. Romney was one of only a few Michigan corporate chiefs to support passage and implementation of the state Fair Employment Practices Act.

Religion was a paramount force in Romney's life. In a 1959 essay for the "Detroit Free Press" he said, "My religion is my most precious possession. ... Except for my religion, I easily could have become excessively occupied with industry, social and recreational activities. Sharing personal responsibility for church work with my fellow members has been a vital counterbalance in my life." Following LDS Church practices, he did not drink alcohol or caffeinated beverages, smoke, or swear. Romney and his wife tithed, and from 1955 to 1965, gave 19 percent of their income to the church and another 4 percent to charity.

Romney was a high priest in the Melchizedek priesthood of the LDS, and beginning in 1944 he headed the Detroit church branch (which initially was small enough to meet in a member's house). By the time he was AMC chief, he presided over the Detroit Stake, which included not only all of Metro Detroit, Ann Arbor, and the Toledo area of Ohio but also the western edge of Ontario along the Michigan border. In this role, Romney oversaw the religious work of some 2,700 church members, occasionally preached sermons, and supervised the construction of the first stake tabernacle east of the Mississippi River in 100 years. Because the stake covered part of Canada, he often interacted with Canadian Mission President Thomas S. Monson. Romney's rise to a leadership role in the church reflected the church's journey from a fringe pioneer religion to one that was closely associated with mainstream American business and values. Due in part to his prominence, the larger Romney family tree would become viewed as "LDS royalty".

Romney and his family lived in affluent Bloomfield Hills, having moved there from Detroit around 1953. He became deeply active in Michigan civic affairs. He was on the board of directors of the Children's Hospital of Michigan and the United Foundation of Detroit, and was chairman of the executive committee of the Detroit Round Table of Catholics, Jews, and Protestants. In 1959, he received the Anti-Defamation League of B'nai's Americanism award.

Starting in 1956, Romney headed a citizen-based committee for improved educational programs in Detroit's public schools. The 1958 final report of the Citizens Advisory Committee on School Needs was largely Romney's work and received considerable public attention; it made nearly 200 recommendations for economy and efficiency, better teacher pay, and new infrastructure funding. Romney helped a $90-million education-related bond issue and tax increase win an upset victory in an April 1959 statewide referendum. He organized Citizens for Michigan in 1959, a nonpartisan group that sought to study Detroit's problems and build an informed electorate. Citizens for Michigan built on Romney's belief that assorted interest groups held too much influence in government, and that only the cooperation of informed citizens acting for the benefit of all could counter them.

Based on his fame and accomplishments in a state where automobile making was a central topic of conversation, Romney was seen as a natural to enter politics. He first became directly involved in politics in 1959, when he was a key force in the petition drive calling for a constitutional convention to rewrite the Michigan Constitution. Romney's sales skills made Citizens for Michigan one of the most effective organizations among those calling for the convention. Previously unaffiliated politically, Romney declared himself a member of the Republican Party and gained election to the convention. By early 1960, many in Michigan's somewhat moribund Republican Party were touting Romney as a possible candidate for governor, U.S. senator, or even U.S. vice president.

Also in early 1960, Romney served on the Fair Campaign Practices Committee, a group also having Jewish, Catholic, mainline and evangelical Protestant, and Orthodox Christian members. It issued a report whose guiding principles were that no candidate for elected office should be supported or opposed due to their religion and that no campaign for office should be seen as an opportunity to vote for one religion against another. This statement helped pave the way for John F. Kennedy's famous speech on religion and public office later that year. Romney briefly considered a run in the 1960 Senate election, but instead became a vice president of the constitutional convention that revised the Michigan constitution during 1961 and 1962.

After a period of pained indecision and a 24-hour prayer fast, Romney stepped down from AMC in February 1962 to enter electoral politics (given an indefinite leave of absence, he was succeeded as president of AMC by Roy Abernethy).
Romney's position as the leader of the moderate Republicans at the constitutional convention helped gain him the Republican nomination for Governor of Michigan.
He ran against incumbent Democratic Governor John B. Swainson in the general election. Romney campaigned on revising the state's tax structure, increasing its appeal to businesses and the general public, and getting it "rolling again". Romney decried both the large influence of labor unions within the Democratic Party and the similarly large influence of big business within the Republican Party. His campaign was among the first to exploit the capabilities of electronic data processing.

Romney won by some 80,000 votes and ended a fourteen-year stretch of Democratic rule in the state executive spot. His win was attributed to his appeal to independent voters and to those from the increasingly influential suburbs of Detroit, who by 1962 were more likely to vote Republican than the heavily Democratic residents of the city itself. Additionally, Romney had appeal to labor union members that was unusual for a Republican. Democrats won all the other statewide executive offices in the election, including Democratic incumbent T. John Lesinski in the separate election for Lieutenant Governor of Michigan. Romney's success caused immediate mention of him as a presidential possibility for 1964, and President John F. Kennedy said privately in 1963 that, "The one fellow I don't want to run against is Romney."

Romney was sworn in as governor on January 1, 1963. His initial concern was the implementation of the overhaul of the state's financial and revenue structure that had been authorized by the constitutional convention. In 1963, he proposed a comprehensive tax revision package that included a flat-rate state income tax, but general economic prosperity alleviated pressure on the state budget and the Michigan Legislature rejected the measure. Romney's early difficulties with the legislature helped undermine an attempted push that year of Romney as a national political figure by former Richard Nixon associates. One Michigan Democrat said of Romney, "He has not yet learned that things in government are not necessarily done the moment the man at the top gives an order. He is eager and sometimes impatient." But over his first two years in office, Romney was able to work with Democrats – who often had at least partial control of the legislature – and an informal bipartisan coalition formed which allowed Romney to accomplish many of his goals and initiatives.

Romney held a series of Governor's Conferences, which sought to find new ideas from public services professionals and community activists who attended. He opened his office in the Michigan State Capitol to visitors, spending five minutes with every citizen who wanted to speak with him on Thursday mornings, and was always sure to shake the hands of schoolchildren visiting the capitol. He almost always eschewed political activities on Sunday, the Mormon Sabbath. His blunt and unequivocal manner sometimes caused friction, and family members and associates used the idiom "bull in a china shop" to describe him. He took a theatrical approach to governance, staging sudden appearances in settings where he might be politically unwelcome. One former aide later said that "willful" was too weak a word to describe him, and chose "messianic" instead. Romney saw a moral dimension in every issue and his political views were held with as much fervor as religious ones; writer Theodore H. White said "the first quality that surfaced, as one met and talked with George Romney over a number of years, was a sincerity so profound that, in conversation, one was almost embarrassed."

Romney supported the American Civil Rights Movement while governor. Although he belonged to a church that did not allow black people in its lay clergy, Romney's hardscrabble background and subsequent life experiences led him to support the movement. He reflected, "It was only after I got to Detroit that I got to know Negroes and began to be able to evaluate them and I began to recognize that some Negroes are better and more capable than lots of whites." During his first State of the State address in January 1963, Romney declared that "Michigan's most urgent human rights problem is racial discrimination—in housing, public accommodations, education, administration of justice, and employment." Romney helped create the state's first civil rights commission.
When Martin Luther King Jr. came to Detroit in June 1963 and led the 120,000-strong Great March on Detroit, Romney designated the occasion Freedom March Day in Michigan, and sent state senator Stanley Thayer to march with King as his emissary, but did not attend himself because it was on Sunday. Romney did participate in a much smaller march protesting housing discrimination the following Saturday in Grosse Pointe, after King had left. Romney's advocacy of civil rights brought him criticism from some in his own church; in January 1964, Quorum of the Twelve Apostles member Delbert L. Stapley wrote him that a proposed civil rights bill was "vicious legislation" and telling him that "the Lord had placed the curse upon the Negro" and men should not seek its removal. Romney refused to change his position and increased his efforts towards civil rights. Regarding the church policy itself, Romney was among those liberal Mormons who hoped the church leadership would revise the theological interpretation that underlay it, but Romney did not believe in publicly criticizing the church, subsequently saying that fellow Mormon Stewart Udall's 1967 published denunciation of the policy "cannot serve any useful religious purpose".
In the 1964 U.S. presidential election, Senator Barry Goldwater quickly became the likely Republican Party nominee. Goldwater represented a new wave of American conservatism, of which the moderate Romney was not a part. Romney also felt that Goldwater would be a drag on Republicans running in all the other races that year, including Romney's own (at the time, Michigan had two-year terms for its governor). Finally, Romney disagreed strongly with Goldwater's views on civil rights; he would later say, "Whites and Negroes, in my opinion, have "got" to learn to know each other. Barry Goldwater didn't have any background to understand this, to fathom them, and I couldn't get through to him."

During the June 1964 National Governors' Conference, 13 of 16 Republican governors present were opposed to Goldwater; their leaders were Jim Rhodes of Ohio, Nelson Rockefeller of New York (whose own campaign had just stalled out with a loss to Goldwater in the California primary), William Scranton of Pennsylvania, and Romney. In an unusual Sunday press conference, Romney declared, "If [Goldwater's] views deviate as indicated from the heritage of our party, I will do everything within my power to keep him from becoming the party's presidential nominee." Romney had, however, previously vowed to Michigan voters that he would not run for president in 1964. Detroit newspapers indicated they would not support him in any such bid, and Romney quickly decided to honor his pledge to stay out of the contest. Scranton entered instead, but Goldwater prevailed decisively at the 1964 Republican National Convention. Romney's name was entered into nomination as a favorite son by U.S. Representative Gerald Ford of Michigan (who had not wanted to choose between candidates during the primary campaign) and he received the votes of 41 delegates in the roll call (40 of Michigan's 48 and one from Kansas).
At the convention, Romney fought for a strengthened civil rights plank in the party platform that would pledge action to eliminate discrimination at the state, local, and private levels, but it was defeated on a voice vote. He also failed to win support for a statement that condemned both left- and right-wing extremism without naming any organizations, which lost a standing vote by a two-to-one margin. Both of Romney's positions were endorsed by former President Dwight Eisenhower, who had an approach to civic responsibilities similar to Romney's. As the convention concluded, Romney neither endorsed nor repudiated Goldwater and vice presidential nominee William E. Miller, saying he had reservations about Goldwater's lack of support for civil rights and the political extremism that Goldwater embodied.

For the fall 1964 elections, Romney cut himself off from the national ticket, refusing to even appear on the same stage with them and continuing to feud with Goldwater privately. He campaigned for governor in mostly Democratic areas, and when pressed at campaign appearances about whether he supported Goldwater, he replied, "You know darn well I'm not!" Romney was re-elected in 1964 by a margin of over 380,000 votes over Democratic Congressman Neil Staebler, despite Goldwater's landslide defeat to President Lyndon B. Johnson that swept away many other Republican candidates. Romney won 15 percent of Michigan's black vote, compared to Goldwater's two percent.

In 1965, Romney visited South Vietnam for 31 days and said that he was continuing his strong support for U.S. military involvement there.
During 1966, while son Mitt was away in France on missionary work, George Romney guided Mitt's fiancée Ann Davies in her conversion to Mormonism. Governor Romney continued his support of civil rights; after violence broke out during the Selma to Montgomery marches in 1965, he marched at the front of a Detroit parade in solidarity with the marchers. In 1966, Romney had his biggest electoral success, winning re-election again by some 527,000 votes over Democratic lawyer Zolton Ferency (this time to a four-year term, after a change in Michigan law). His share of the black vote rose to over 30 percent, a virtually unprecedented accomplishment for a Republican.

By 1967, a looming deficit prompted the legislature to overhaul Michigan's tax structure. Personal and corporate state income taxes were created while business receipts and corporation franchise taxes were eliminated. Passage of an income levy had eluded past Michigan governors, no matter which party controlled of the legislature. Romney's success convincing Democratic and Republican factions to compromise on the details of the measure was considered a key test of his political ability.

The massive 12th Street riot in Detroit began during the predawn hours of July 23, 1967, precipitated by a police raid of a speakeasy in a predominantly black neighborhood. As the day wore on and looting and fires got worse, Romney called in the Michigan State Police and the Michigan National Guard. At 3 a.m. on July 24, Romney and Detroit Mayor Jerome Cavanagh called U.S. Attorney General Ramsey Clark and requested that federal troops be sent. Clark indicated that to do so, Romney would have to declare a state of civil insurrection, which the governor was loath to do from fear that insurance companies would seize upon it as a reason to not cover losses owing to the riot. Elements of the 82nd and 101st U.S. Army Airborne Divisions were mobilized outside of the city.
As the situation in Detroit worsened, Romney told Deputy Secretary of Defense Cyrus Vance, "We gotta move, man, we gotta move." Near midnight on July 24, President Johnson authorized thousands of paratroopers to enter Detroit. Johnson went on national television to announce his actions and made seven references to Romney's inability to control the riot using state and local forces. Thousands of arrests took place and the rioting continued until July 27. The final toll was the largest of any American civil disturbance in fifty years: 43 dead, over a thousand injured, 2,500 stores looted, hundreds of homes burned, and some $50 million overall in property damage.

There were strong political implications in the handling of the riot, as Romney was seen as a leading Republican contender to challenge Johnson's presidential re-election the following year; Romney believed the White House had intentionally slowed its response and he charged Johnson with having "played politics" in his actions. The riot notwithstanding, by the end of Romney's governorship the state had made strong gains in civil rights related to public employment, government contracting, and access to public accommodations. Lesser improvements were made in combating discrimination in private employment, housing, education, and law enforcement. Considerable state and federal efforts were made during this time to improve the lot of Michigan's migrant farm workers and Native Americans, without much progress for either.

Romney greatly expanded the size of state government while governor. His first state budget, for fiscal year 1963, was $550 million, a $20 million increase over that of his predecessor Swainson. Romney had also inherited an $85 million budget deficit, but left office with a surplus. In the following fiscal years, the state budget increased to $684 million for 1964, $820 million for 1965, $1 billion for 1966, $1.1 billion for 1967, and was proposed as $1.3 billion for 1968. Romney led the way for a large increase in state spending on education, and Michigan began to develop one of the nation's most comprehensive systems of higher education. There was a significant increase in funding support for local governments and there were generous benefits for the poor and unemployed. Romney's spending was enabled by the that generated continued government surpluses and by a consensus of both parties in Michigan to maintain extensive state bureaucracies and expand public sector services.

The bipartisan coalitions that Romney worked with in the state legislature enabled him to reach most of his legislative goals. His record as governor continued his reputation for having, as writer Theodore H. White said, "a knack for getting things done." Noted University of Michigan historian Sidney Fine assessed him as "a highly successful governor".

Romney's wide margin of re-election as governor in November 1966 thrust him to the forefront of national Republicans. In addition to his political record, the tall, square-jawed, handsome, graying Romney matched what the public thought a president should look like. Republican governors were determined not to let a Goldwater-sized loss recur, and neither Rockefeller nor Scranton wanted to run again; the governors quickly settled on Romney as their favorite for the Republican presidential nomination in the 1968 U.S. presidential election.
Former Congressman and Republican National Committee chair Leonard W. Hall became Romney's informal campaign manager. A Gallup Poll after the November elections showed Romney as favored among Republicans over former Vice President Richard Nixon for the Republican nomination, 39 percent to 31 percent; a Harris Poll showed Romney besting President Johnson among all voters by 54 percent to 46 percent. Nixon considered Romney his chief opponent. Romney announced an exploratory phase for a possible campaign in February 1967, beginning with a visit to Alaska and the Rocky Mountain states.

Romney's greatest weakness was a lack of foreign policy expertise and a need for a clear position on the Vietnam War. The press coverage of the trip focused on Vietnam and reporters were frustrated by Romney's initial reluctance to speak about it. The qualities that helped Romney as an industry executive worked against him as a presidential candidate; he had difficulty being articulate, often speaking at length and too forthrightly on a topic and then later correcting himself while maintaining he was not. Reporter Jack Germond joked that he was going to add a single key on his typewriter that would print, "Romney later explained ..." "Life" magazine wrote that Romney "manages to turn self-expression into a positive ordeal" and that he was no different in private: "nobody can sound more like the public George Romney than the real George Romney let loose to ramble, inevitably away from the point and toward some distant moral precept."

The perception grew that Romney was gaffe-prone. The campaign, beset by internal rivalries, soon went through the first of several reorganizations. By then, Nixon had already overtaken Romney in Gallup's Republican preference poll, a lead he would hold throughout the rest of the campaign. The techniques that had brought Romney victories in Michigan, such as operating outside established partisan formulas and keeping a distance from Republican Party organizational elements, proved ineffective in a party nominating contest.
Romney's national poll ratings continued to erode, and by May he had lost his edge over Johnson. The Detroit riots of July 1967 did not change his standing among Republicans, but did give him a bounce in national polls against the increasingly unpopular president.

Questions were occasionally asked about Romney's eligibility to run for President owing to his birth in Mexico, given the ambiguity in the United States Constitution over the phrase "natural-born citizen". Romney would depart the race before the matter could be more definitively resolved, although the preponderance of opinion then and since has been that he was eligible.

Romney was also the first Mormon to stage a credible run for the presidency. By this time, he was well known as a Mormon and perhaps the most nationally visible one since Brigham Young. But his membership in the LDS Church was scarcely mentioned at all during the campaign. What indirect discussion there was helped bring to national attention the church's policy regarding blacks, but the contrast of Romney's pro-civil rights stance deflected any criticism of him and indirectly benefited the image of the church. Some historians and Mormons suspected then and later that had Romney's campaign lasted longer and been more successful, his religion might have become a more prominent issue. Romney's campaign did often focus on his core beliefs; a Romney billboard in New Hampshire read "The Way To Stop Crime Is To Stop Moral Decay". Dartmouth College students gave a bemused reaction to his morals message, displaying signs such as "God Is Alive and Thinks He's George Romney". A spate of books were published about Romney, more than for any other candidate, and included a friendly campaign biography, an attack from a former staffer, and a collection of Romney's speeches.

On August 31, 1967, in a taped interview with locally influential (and nationally syndicated) talk show host Lou Gordon of WKBD-TV in Detroit, Romney stated: "When I came back from Viet Nam [in November 1965], I'd just had the greatest brainwashing that anybody can get." He then shifted to opposing the war: "I no longer believe that it was necessary for us to get involved in South Vietnam to stop Communist aggression in Southeast Asia." Decrying the "tragic" conflict, he urged "a sound peace in South Vietnam at an early time." Thus Romney disavowed the war and reversed himself from his earlier stated belief that the war was "morally right and necessary".

The "brainwashing" reference had been an offhand, unplanned remark that came at the end of a long, behind-schedule day of campaigning. By September 7, it found its way into prominence at "The New York Times". Eight other governors who had been on the same 1965 trip as Romney said no such activity had taken place, and one of them, Philip H. Hoff of Vermont, said Romney's remarks were "outrageous, kind of stinking ... Either he's a most naïve man or he lacks judgment." The connotations of brainwashing, following the experiences of American prisoners of war (highlighted by the 1962 film "The Manchurian Candidate"), made Romney's comment devastating, especially as it reinforced the negative image of Romney's abilities that had already developed. The topic of brainwashing quickly became newspaper editorial and television talk show fodder, and Romney bore the brunt of the topical humor. Senator Eugene McCarthy, running against Johnson for the Democratic nomination, said that in Romney's case, "a light rinse would have been sufficient." Republican Congressman Robert T. Stafford of Vermont sounded a common concern: "If you're running for the presidency, you are supposed to have too much on the ball to be brainwashed." After the remark was aired, Romney's poll ratings nosedived, going from 11 percent behind Nixon to 26 percent behind.

He nonetheless persevered, staging a three-week, 17-city tour of the nation's ghettos and disadvantaged areas that none of his advisors thought politically worthwhile. He sought to engage militants in dialogue, found himself exposed to the harsh realities and language of ghetto areas, and had an unusual encounter with hippies and The Diggers in San Francisco's Haight-Ashbury.

Romney formally announced on November 18, 1967, at Detroit's Veterans Memorial Building, that he had "decided to fight for and win the Republican nomination and election to the Presidency of the United States." His subsequent release of his federal tax returns – twelve years' worth going back to his time as AMC head – was groundbreaking and established a precedent that many future presidential candidates would have to contend with. He spent the following months campaigning tirelessly, focusing on the New Hampshire primary, the first of the season, and doing all the on-the-ground activities known to that state: greeting workers at factory gates before dawn, having neighborhood meetings in private homes, and stopping at bowling alleys. He returned to Vietnam in December 1967 and made speeches and proposals on the subject, one of which presaged Nixon's eventual policy of Vietnamization. For a while, he got an improved response from voters.
Two weeks before the March 12 primary, an internal poll showed Romney losing to Nixon by a six-to-one margin in New Hampshire. Rockefeller, seeing the poll result as well, publicly maintained his support for Romney but said he would be available for a draft; the statement made national headlines and embittered Romney (who would later claim it was Rockefeller's entry, and not the "brainwashing" remark, that doomed him). Seeing his cause was hopeless, Romney announced his withdrawal as a presidential candidate on February 28, 1968. Romney wrote his son Mitt, still away on missionary work: "Your mother and I are not personally distressed. As a matter of fact, we are relieved. ... I aspired, and though I achieved not, I am satisfied."

Nixon went on to gain the nomination. At the 1968 Republican National Convention in Miami Beach, Romney refused to release his delegates to Nixon, something Nixon did not forget. Romney finished a weak fifth, with only 50 votes on the roll call (44 of Michigan's 48, plus six from Utah). When party liberals and moderates and others expressed dismay at Nixon's choice of Spiro Agnew as his running mate, Romney's name was placed into nomination for vice president by Mayor of New York John Lindsay and pushed by several delegations. Romney said he did not initiate the move, but he made no effort to oppose it. Nixon saw the rebellion as a threat to his leadership and actively fought against it; Romney lost to Agnew 1,119–186. Romney, however, worked for Nixon's eventually successful campaign in the fall, which did earn him Nixon's gratitude.

Presidential historian Theodore H. White wrote that during his campaign Romney gave "the impression of an honest and decent man simply not cut out to be President of the United States." Governor Jim Rhodes of Ohio more memorably said, "Watching George Romney run for the presidency was like watching a duck try to make love to a football."

After the election, Nixon named Romney to be Secretary of Housing and Urban Development (HUD). The president-elect made the announcement as part of a nationally televised presentation of his new cabinet on December 11, 1968. Nixon praised Romney for his "missionary zeal" and said that he would also be tasked with mobilizing volunteer organizations to fight poverty and disease within the United States. In actuality, Nixon distrusted Romney politically, and appointed him to a liberally oriented, low-profile federal agency partly to appease Republican moderates and partly to reduce Romney's potential to challenge for the 1972 Republican presidential nomination.

Romney was confirmed by the Senate without opposition on January 20, 1969, the day of Nixon's inauguration, and was sworn into office on January 22, with Nixon at his side. Romney resigned as Governor of Michigan that same day, and was succeeded by Lieutenant Governor William G. Milliken. Milliken continued Romney's model of downplaying party label and ideology, and Republicans held onto the governorship for three more terms until 1983, though Michigan was one of the nation's most blue-collar states.

As secretary, Romney conducted the first reorganization of the department since its 1966 creation. His November 1969 plan brought programs with similar functions together under unified, policy-based administration at the Washington level, and created two new assistant secretary positions. At the same time, he increased the number of regional and area offices and decentralized program operations and locality-based decisions to them.

The Fair Housing Act of 1968 mandated a federal commitment towards housing desegregation, and required HUD to orient its programs in this direction. Romney, filled with moral passion, wanted to address the widening economic and geographic gulf between whites and blacks by moving blacks out of inner-city ghettos into suburbs. Romney proposed an open housing scheme to facilitate desegregation, dubbed "Open Communities"; HUD planned it for many months without keeping Nixon informed.
When the open housing proposal became public, local reaction was often hostile. Such was the reaction of many residents in Warren, Michigan, a predominately white blue-collar suburb of Detroit. While it had no formal discriminatory laws, most blacks were excluded by zoning practices, refusals to sell to them, and intimidatory actions of white property owners, many of whom were ethnic Polish and Catholic and had moved to the suburb as part of white flight. By this time, Detroit was 40–50 percent black. HUD made Warren a prime target for Open Communities enforcement and threatened to halt all federal assistance to the town unless it took a series of actions to end racial discrimination there; town officials said progress was being made and that their citizens resented forced integration. Romney rejected this response, partly because when he was governor, Warren residents had thrown rocks and garbage and yelled obscenities for days at a biracial couple who moved into town. Now the secretary said, "The youth of this nation, the minorities of this nation, the discriminated of this nation are not going to wait for 'nature to take its course.' What is really at issue here is responsibility – moral responsibility."

Romney visited Warren in July 1970, where he addressed leaders from it and around 40 nearby suburbs. He emphasized that the government was encouraging affirmative action rather than forced integration, but the local populace saw little difference and Romney was jeered as a police escort took him away from the meeting place. Nixon saw what happened in Warren and had no interest in the Open Communities policy in general, remarking to domestic adviser John Ehrlichman that, "This country is not ready at this time for either forcibly integrated housing or forcibly integrated education." The Open Communities policy conflicted with Nixon's use of the Southern strategy of gaining political support among traditionally white southern Democrats, and his own views on race. Romney was forced to back down on Warren and release federal monies to them unconditionally.

When Black Jack, Missouri, subsequently resisted a HUD-sponsored plan for desegregated lower- and middle-income housing, Romney appealed to U.S. Attorney General John Mitchell for Justice Department intervention. In September 1970, Mitchell refused and Romney's plan collapsed. Under Romney, HUD did establish stricter affirmative racial guidelines in relation to new public housing projects, but overall administration implementation of the Fair Housing Act was lacking. Some of the responsibility lay with Romney's inattentiveness to gaining political backing for the policy, including the failure to rally natural allies such as the NAACP. Salisbury University historian Dean J. Kotlowski writes that, "No civil rights initiative developed on Nixon's watch was as sincerely devised or poorly executed as open communities."

Another of Romney's initiatives was "Operation Breakthrough," which was intended to increase the amount of housing available to the poor and which initially had Nixon's support. Based on his automotive industry experience, Romney thought that the cost of housing could be significantly reduced if in-factory modular construction techniques were used. HUD officials believed that introduction of this technique could help bring about desegregation; Romney said, "We've got to put an end to the idea of moving to suburban areas and living only among people of the same economic and social class". This aspect of the program brought about strong opposition at the local suburban level and lost support in the White House as well. Over half of HUD's research funds during this time were spent on Operation Breakthrough, and it was modestly successful in its building goals. It did not revolutionize home construction, and was phased out once Romney left HUD. But it resulted indirectly in more modern and consistent building codes and introduction of technological advances such as the smoke alarm.

In any case, using conventional construction methods, HUD set records for the amount of construction of assisted housing for low- and moderate-income families. Toward the end of his term, Romney oversaw demolition of the infamous Pruitt–Igoe housing project in St. Louis, which had become crime-ridden, drug-infested, and largely vacant.
Romney was largely outside the president's inner circle and had minimal influence within the Nixon administration. His intense, sometimes bombastic style of making bold advances and awkward pullbacks lacked adequate guile to succeed in Washington. Desegregation efforts in employment and education had more success than in housing during the Nixon administration, but HUD's many missions and unwieldy structure, which sometimes worked at cross-purposes, made it institutionally vulnerable to political attack. Romney also failed to understand or circumvent Nixon's use of counsel Ehrlichman and White House Chief of Staff H. R. Haldeman as policy gatekeepers, resulting in "de facto" downgrading of the power of cabinet officers. Romney was used to being listened to and making his own decisions; he annoyed Nixon by casually interrupting him at meetings. At one point, Nixon told Haldeman, "Just keep [Romney] away from me." A statement by Romney that he would voluntarily reduce his salary to aid the federal budget was viewed by Nixon as an "ineffective grandstand play".

By early 1970, Nixon had decided he wanted Romney removed from his position. Nixon, who hated to fire people and was, as Ehrlichman later described, "notoriously inadept" at it, instead hatched a plot to get Romney to run in the 1970 U.S. Senate race in Michigan. Instead, Romney proposed that his wife Lenore run, and she received the backing of some state Republicans. There was also resistance to her candidacy and an initial suspicion that it was just a stalking horse for keeping his options open. She barely survived a primary against a conservative opponent, then lost badly in the general election to incumbent Democrat Philip A. Hart. Romney blamed others for his wife having entered the race, when he had been the major force behind it.

In late 1970, after opposition to Open Communities reached a peak, Nixon again decided that Romney should go. Still reluctant to dismiss him, Nixon tried to get Romney to resign by forcing him to capitulate on a series of policy issues. Romney surprised both Nixon and Haldeman by agreeing to back off his positions, and Nixon kept him as HUD secretary. Nixon remarked privately afterwards, "[Romney] talks big but folds under pressure." Puzzled by Nixon's lack of apparent ideological consistency across different areas of the government, Romney told a friend, "I don't know what the president believes in. Maybe he doesn't believe in anything," an assessment shared by others both inside and outside the administration.

In spring 1972, the Federal Housing Administration (FHA), an agency within HUD, was struck by scandal. Since passage of the Housing and Urban Development Act of 1968 and the creation of the Government National Mortgage Association (Ginnie Mae), it had been responsible for helping the poor buy homes in inner-city areas via government-backed mortgages. These were financed by mortgage-backed securities, the first issues of which Romney had announced in 1970. A number of FHA employees, along with a number of real estate firms and lawyers, were indicted for a scheme in which the value of cheap inner city homes was inflated and they were sold to black buyers who could not really afford them, based on using those government-backed mortgages. The government was stuck for the bad loans when owners defaulted, as the properties were overvalued and could not be resold at the inflated prices. Romney conceded that HUD had been unprepared to deal with speculators and had not been alert to earlier signs of illegal activity at the FHA. The FHA scandal gave Nixon the ability to shut down HUD's remaining desegregation efforts with little political risk; by January 1973, all federal housing funds had been frozen.

In August 1972, Nixon announced Romney would inspect Hurricane Agnes flood damage in Wilkes-Barre, Pennsylvania, but neglected to tell Romney first. Much of the area lacked shelter six weeks after the storm, residents were angry, and Romney got into a three-way shouting match with Governor Milton J. Shapp and a local citizens' representative. Romney denounced Shapp's proposal that the federal government pay off the mortgages of victims as "unrealistic and demagogic", and the representative angrily said to Romney, "You don't give a damn whether we live or die." The confrontation received wide media attention, damaging Romney's public reputation. Feeling very frustrated, Romney wanted to resign immediately, but Nixon, worried about the fallout to his 1972 re-election campaign, insisted that Romney stay on. Romney agreed, although he indicated to the press that he would leave eventually.

Romney finally turned in his resignation on November 9, 1972, following Nixon's re-election. His departure was announced on November 27, 1972, as part of the initial wave of departures from Nixon's first-term cabinet. Romney said he was unhappy with presidential candidates who declined to address "the real issues" facing the nation for fear they would lose votes, and said he would form a new national citizens' organization that would attempt to enlighten the public on the most vital topics. He added that he would stay on as secretary until his successor could be appointed and confirmed, and did stay until Nixon's second inauguration on January 20, 1973. Upon his departure, Romney said he looked forward "with great enthusiasm" to his return to private life.

"The Boston Globe" later termed Romney's conflicts with Nixon a matter that "played out with Shakespearean drama". Despite all the setbacks and frustrations, University at Buffalo political scientist Charles M. Lamb concluded that Romney pressed harder to achieve suburban integration than any prominent federal official in the ensuing 1970s through the 1990s. In 2008, Lehman College sociology professor Christopher Bonastia assessed the Romney-era HUD as having come "surprisingly close to implementing unpopular antidiscrimination policies" but finally being unable to produce meaningful alterations in American residential segregation patterns, with no equivalent effort having happened since then or likely to in the foreseeable future.

Romney was known as an advocate of public service, and volunteerism was a passion of his. He initiated several volunteer programs while Governor of Michigan, and at the beginning of the Nixon administration chaired the Cabinet Committee on Voluntary Action. Out of this the National Center for Voluntary Action was created: an independent, private, non-profit organization intended to encourage volunteerism on the part of American citizens and organizations, to assist in program development for voluntary efforts, and to make voluntary action an important force in American society. Romney's long interest in volunteerism stemmed from the Mormon belief in the power of institutions to transform the individual, but also had a secular basis. At the National Center's first meeting on February 20, 1970, he said:

Americans have four basic ways of solving problems that are too big for individuals to handle by themselves. One is through the federal government. A second is through state governments and the local governments that the states create. The third is through the private sector – the economic sector that includes business, agriculture, and labor. The fourth method is the independent sector – the voluntary, cooperative action of free individuals and independent association. Voluntary action is the most powerful of these, because it is uniquely capable of stirring the people themselves and involving their enthusiastic energies, because it is their own – voluntary action is the people's action. ... As Woodrow Wilson said, "The most powerful force on earth is the spontaneous cooperation of a free people." Individualism makes cooperation worthwhile – but cooperation makes freedom possible.

In 1973, after he left the cabinet, Romney became chair and CEO of the National Center for Voluntary Action. In 1979, this organization merged with the Colorado-based National Information Center on Volunteerism and became known as ; Romney headed the new organization. The organization simplified its name to in 1984 and to the National Volunteer Center in 1990. Romney remained as chair of these organizations throughout this time.

Within the LDS Church, Romney remained active and prominent, serving as patriarch of the Bloomfield Hills Stake and holding the office of regional representative of the Twelve, covering Michigan and northern Ohio. As part of a longtime habit of playing golf daily, he had long ago concocted a "compact 18" format in which he played three balls on each of six holes, or similar formulations depending upon the amount of daylight. During the early part of the Reagan administration, Romney served on the President's Task Force for Private Sector Initiatives along with LDS leader Monson. In 1987, he held a four-generation extended family reunion in Washington, where he showed the places and recounted the events of his life which had occurred there. Looking back on his and some other failed presidential bids, he once concluded, "You can't be right too soon and win elections."

President George H. W. Bush's Points of Light Foundation was created in 1990, also to encourage volunteerism. Romney received the Points of Light Foundation's inaugural Lifetime Achievement Award from President Bush in April 1991. The Bush administration wanted to tap Romney to chair the new foundation, but he reportedly refused to head two organizations doing the same thing and suggested they merge. They did so in September 1991, and Romney became one of the founding directors of the Points of Light Foundation & Volunteer Center National Network.
In the early 1990s, Romney was also involved in helping to set up the Commission on National and Community Service, one of the predecessors to the later Corporation for National and Community Service. He gave speeches emphasizing the vital role of people helping people, and in 1993 inspired the first national meeting of volunteer centers.

For much of his final two decades, Romney had been out of the political eye, but he re-emerged to the general public when he campaigned for his son, Mitt Romney, during the younger Romney's bid to unseat Senator Edward M. Kennedy in the 1994 U.S. Senate election in Massachusetts. Romney had urged Mitt to enter the race and moved into his son's house for its duration, serving as an unofficial advisor. Romney was a vigorous surrogate for his son in public appearances and at fundraising events. When Kennedy's campaign sought to bring up the LDS Church's past policy on blacks, Romney interrupted Mitt's press conference and said loudly, "I think it is absolutely wrong to keep hammering on the religious issues. And what Ted is trying to do is bring it into the picture." The father counseled the son to be relaxed in appearance and to pay less attention to his political consultants and more to his own instincts, a change that the younger Romney made late in the ultimately unsuccessful campaign.

That same year, Ronna Romney, Romney's ex-daughter-in-law (formerly married to G. Scott Romney), decided to seek the Republican nomination for the U.S. Senate from Michigan. While Mitt and G. Scott endorsed Ronna Romney, George Romney had endorsed her opponent and the eventual winner, Spencer Abraham, during the previous year when Ronna was considering a run but had not yet announced. A family spokesperson said that George Romney had endorsed Abraham before knowing Ronna Romney would run and could not go back on his word, although he did refrain from personally campaigning on Abraham's behalf.

By January 1995, amid press criticism of the Points of Light Foundation engaging in ineffective, wasteful spending, Romney expressed concern that the organization had too high a budget. Active to the end, in July 1995, four days before his death, Romney proposed a presidential summit to encourage greater volunteerism and community service, and the night before his death he drove to a meeting of another volunteer organization.

On July 26, 1995, Romney died of a heart attack at the age of 88 while he was doing his morning exercising on a treadmill at his home in Bloomfield Hills, Michigan; he was discovered by his wife Lenore but it was too late to save him. He was buried at the Fairview Cemetery in Brighton, Michigan. In addition to his wife and children, Romney was survived by 23 grandchildren and 33 great-grandchildren.

The Presidents' Summit For America's Future took place in Philadelphia in 1997, manifesting Romney's last volunteerism proposal, with the organization America's Promise coming out of it.
For many years, the Points of Light Foundation (and its predecessor organization) has given out an annual Lenore and George W. Romney Citizen Volunteer Award (later retitled the George and Lenore Romney Citizen Volunteer Award); the inaugural such award in 1987 went to George Romney himself. The Points of Light Foundation and the Corporation for National and Community Service also give out a George W. Romney Volunteer Center Excellence Award (later the George W. Romney Excellence Award) at the annual National Conference on Community Volunteering and National Service (later the National Conference on Volunteering and Service). The George W. Romney Volunteer Center itself is sponsored by the United Way for Southeastern Michigan, and began during Romney's lifetime.

Founded in 1998 with a grant from Romney's immediate family, the George W. Romney Institute of Public Management in the Marriott School of Management at Brigham Young University honors the legacy left by Romney. Its mission is to develop people of high character who are committed to service, management, and leadership in the public sector and in non-profit organizations throughout the world.

The building housing the main offices of the Governor of Michigan in Lansing is known as the George W. Romney Building following a 1997 renaming. The Governor George Romney Lifetime Achievement Award is given annually by the State of Michigan, to recognize citizens who have demonstrated a commitment to community involvement and volunteer service throughout their lifetimes. In 2010, Adrian College in Michigan announced the opening of its George Romney Institute for Law and Public Policy. Its purpose is to explore the interdisciplinary nature of law and public policy and encourage practitioners, academics, and students to work together on issues in this realm.





</doc>
<doc id="319149" url="https://en.wikipedia.org/wiki?curid=319149" title="Burning of Parliament">
Burning of Parliament

The Palace of Westminster, the medieval royal palace used as the home of the British parliament, was largely destroyed by fire on 16 October 1834. The blaze was caused by the burning of small wooden tally sticks which had been used as part of the accounting procedures of the Exchequer until 1826. The sticks were disposed of carelessly in the two furnaces under the House of Lords, which caused a chimney fire in the two flues that ran under the floor of the Lords' chamber and up through the walls.

The resulting fire spread rapidly throughout the complex and developed into the biggest conflagration in London between the Great Fire of 1666 and the Blitz of the Second World War; the event attracted large crowds which included several artists who provided pictorial records of the event. The fire lasted for most of the night and destroyed a large part of the palace, including the converted St Stephen's Chapel—the meeting place of the House of Commons—the Lords Chamber, the Painted Chamber and the official residences of the Speaker and the Clerk of the House of Commons.

The actions of Superintendent James Braidwood of the London Fire Engine Establishment ensured that Westminster Hall and a few other parts of the old Houses of Parliament survived the blaze. In 1836 a competition for designs for a new palace was won by Charles Barry. Barry's plans, developed in collaboration with Augustus Pugin, incorporated the surviving buildings into the new complex. The competition established Gothic Revival as the predominant national architectural style and the palace has since been categorised as a UNESCO World Heritage Site, of outstanding universal value.

The Palace of Westminster originally dates from the early eleventh century when Canute the Great built his royal residence on the north side of the River Thames. Successive kings added to the complex: Edward the Confessor built Westminster Abbey; William the Conqueror began building a new palace; his son, William Rufus, continued the process, which included Westminster Hall, started in 1097; Henry III built new buildings for the Exchequer—the taxation and revenue gathering department of the country—in 1270 and the Court of Common Pleas, along with the Court of King's Bench and Court of Chancery. By 1245 the King's throne was present in the palace, which signified that the building was at the centre of English royal administration.

In 1295 Westminster was the venue for the Model Parliament, the first English representative assembly, summoned by Edward I; during his reign he called sixteen parliaments, which sat either in the Painted Chamber or the White Chamber. By 1332 the barons (representing the titled classes) and burgesses and citizens (representing the commons) began to meet separately, and by 1377 the two bodies were entirely detached. In 1512 a fire destroyed part of the royal palace complex and Henry VIII moved the royal residence to the nearby Palace of Whitehall, although Westminster still retained its status as a royal palace. In 1547 Henry's son, Edward VI, provided St Stephen's Chapel for the Commons to use as their debating chamber. The House of Lords met in the medieval hall of the Queen's Chamber, before moving to the Lesser Hall in 1801. Over the three centuries from 1547 the palace was enlarged and altered, becoming a warren of wooden passages and stairways.

St Stephen's Chapel remained largely unchanged until 1692 when Sir Christopher Wren, at the time the Master of the King's Works, was instructed to make structural alterations. He lowered the roof, removed the stained glass windows, put in a new floor and covered the original gothic architecture with wood panelling. He also added galleries from which the public could watch proceedings. The result was described by one visitor to the chamber as "dark, gloomy, and badly ventilated, and so small ... when an important debate occurred ... the members were really to be pitied". When the future Prime Minister William Ewart Gladstone remembered his arrival as a new MP in 1832, he recounted "What I may term corporeal conveniences were ... marvellously small. I do not think that in any part of the building it afforded the means of so much as washing the hands." The facilities were so poor that, in debates in 1831 and 1834, Joseph Hume, a Radical MP, called for new accommodation for the House, while his fellow MP William Cobbett asked "Why are we squeezed into so small a space that it is absolutely impossible that there should be calm and regular discussion, even from circumstance alone ... Why are 658 of us crammed into a space that allows each of us no more than a foot and a half square?"

By 1834 the palace complex had been further developed, firstly by John Vardy in the middle of the eighteenth century, and in the early nineteenth century by James Wyatt and Sir John Soane. Vardy added the Stone Building, in a Palladian style to the West side of Westminster Hall; Wyatt enlarged the Commons, moved the Lords into the Court of Requests and rebuilt the Speaker's House. Soane, taking on responsibility for the palace complex on Wyatt's death in 1813, undertook rebuilding of Westminster Hall and constructed the Law Courts in a Neoclassical style. Soane also provided a new royal entrance, staircase and gallery, as well as committee rooms and libraries.

The potential dangers of the building were apparent to some, as no fire stops or party walls were present in the building to slow the progress of a fire. In the late eighteenth century a committee of MPs predicted that there would be a disaster if the palace caught fire. This was followed by a 1789 report from fourteen architects warning against the possibility of fire in the palace; signatories included Soane and Robert Adam. Soane again warned of the dangers in 1828, when he wrote that "the want of security from fire, the narrow, gloomy and unhealthy passages, and the insufficiency of the accommodations in this building are important objections which call loudly for revision and speedy amendment." His report was again ignored.
Since medieval times the Exchequer had used tally sticks, pieces of carved, notched wood, normally willow, as part of their accounting procedures. The parliamentary historian Caroline Shenton has described the tally sticks as "roughly as long as the span of an index finger and thumb". These sticks were split in two so that the two sides to an agreement had a record of the situation. Once the purpose of each tally had come to an end, they were routinely destroyed. By the end of the eighteenth century the usefulness of the tally system had likewise come to an end, and a 1782 Act of Parliament stated that all records should be on paper, not tallies. The Act also abolished sinecure positions in the Exchequer, but a clause in the act ensured it could only take effect once the remaining sinecure-holders had died or retired. The final sinecure-holder died in 1826 and the act came into force, although it took until 1834 for the antiquated procedures to be replaced. The novelist Charles Dickens, in a speech to the Administrative Reform Association, described the retention of the tallies for so long as an "obstinate adherence to an obsolete custom"; he also mocked the bureaucratic steps needed to implement change from wood to paper. He said that "all the red tape in the country grew redder at the bare mention of this bold and original conception." By the time the replacement process had finished there were two cart-loads of old tally sticks awaiting disposal.

In October 1834 Richard Weobley, the Clerk of Works, received instructions from Treasury officials to clear the old tally sticks while parliament was adjourned. He decided against giving the sticks away to parliamentary staff to use as firewood, and instead opted to burn them in the two heating furnaces of the House of Lords, directly below the peers' chambers. The furnaces had been designed to burn coal—which gives off a high heat with little flame—and not wood, which burns with a high flame. The flues of the furnaces ran up the walls of the basement in which they were housed, under the floors of the Lords' chamber, then up through the walls and out through the chimneys.

The process of destroying the tally sticks began at dawn on 16 October and continued throughout the day; two Irish labourers, Joshua Cross and Patrick Furlong, were assigned the task. Weobley checked in on the men throughout the day, claiming subsequently that, on his visits, both furnace doors were open, which allowed the two labourers to watch the flames, while the piles of sticks in both furnaces were only ever high. Another witness to the events, Richard Reynolds, the firelighter in the Lords, later reported that he had seen Cross and Furlong throwing handfuls of tallies onto the fire—an accusation they both denied.

Those tending the furnaces were unaware that the heat from the fires had melted the copper lining of the flues and started a chimney fire. With the doors of the furnaces open, more oxygen was drawn into the furnaces, which ensured the fire burned more fiercely, and the flames driven farther up the flues than they should have been. The flues had been weakened over time by having footholds cut in them by the child chimney sweeps. Although these footholds would have been repaired as the child exited on finishing the cleaning, the fabric of the chimney was still weakened by the action. In October 1834 the chimneys had not yet had their annual sweep, and a considerable amount of clinker had built up inside the flues.

A strong smell of burning was present in the Lords' chambers during the afternoon of 16 October, and at 4:00 pm two gentlemen tourists visiting to see the Armada tapestries that hung there were unable to view them properly because of the thick smoke. As they approached Black Rod's box in the corner of the room, they felt heat from the floor coming through their boots. Shortly after 4:00 pm Cross and Furlong finished work, put the last few sticks into the furnaces—closing the doors as they did so—and left to go to the nearby Star and Garter public house.

Shortly after 5:00 pm, heat and sparks from a flue ignited the woodwork above.The first flames were spotted at 6:00 pm, under the door of the House of Lords, by the wife of one of the doorkeepers; she entered the chamber to see Black Rod's box alight, and flames burning the curtains and wood panels, and raised the alarm. For 25 minutes the staff inside the palace initially panicked and then tried to deal with the blaze, but they did not call for assistance, or alert staff at the House of Commons, at the other end of the palace complex.

At 6:30 pm there was a flashover, a giant ball of flame that "The Manchester Guardian" reported "burst forth in the centre of the House of Lords, ... and burnt with such fury that in less than half an hour, the whole interior ... presented ... one entire mass of fire." The explosion, and the resultant burning roof, lit up the skyline, and could be seen by the royal family in Windsor Castle, away. Alerted by the flames, help arrived from nearby parish fire engines; as there were only two hand-pump engines on the scene, they were of limited use. They were joined at 6:45 pm by 100 soldiers from the Grenadier Guards, some of whom helped the police in forming a large square in front of the palace to keep the growing crowd back from the firefighters; some of the soldiers assisted the firemen in pumping the water supply from the engines.

The London Fire Engine Establishment (LFEE)—an organisation run by several insurance companies in the absence of a publicly run brigade—was alerted at about 7:00 pm, by which time the fire had spread from the House of Lords. The head of the LFEE, James Braidwood, brought with him 12 engines and 64 firemen, even though the Palace of Westminster was a collection of uninsured government buildings, and therefore fell outside the protection of the LFEE. Some of the firefighters ran their hoses down to the Thames. The river was at low tide and it meant a poor supply of water for the engines on the river side of the building.

By the time Braidwood and his men had arrived on the scene, the House of Lords had been destroyed. A strong south-westerly breeze had fanned the flames along the wood-panelled and narrow corridors into St Stephen's Chapel. Shortly after his arrival the roof of the chapel collapsed; the resultant noise was so loud that the watching crowds thought there had been a Gunpowder Plot-style explosion. According to "The Manchester Guardian", "By half-past seven o'clock the engines were brought to play upon the building both from the river and the land side, but the flames had by this time acquired such a predominance that the quantity of water thrown upon them produced no visible effect." Braidwood saw it was too late to save most of the palace, so elected to focus his efforts on saving Westminster Hall, and he had his firemen cut away the part of the roof that connected the hall to the already burning Speaker's House, and then soak the hall's roof to prevent it catching fire. In doing so he saved the medieval structure at the expense of those parts of the complex already ablaze.

The glow from the burning, and the news spreading quickly round London, ensured that crowds continued to turn up in increasing numbers to watch the spectacle. Among them was a reporter for "The Times", who noticed that there were "vast gangs of the light-fingered gentry in attendance, who doubtless reaped a rich harvest, and [who] did not fail to commit several desperate outrages". The crowds were so thick that they blocked Westminster Bridge in their attempts to get a good view, and many took to the river in whatever craft they could find or hire in order to watch better. A crowd of thousands congregated in Parliament Square to witness the spectacle, including the Prime Minister—Lord Melbourne—and many of his cabinet. Thomas Carlyle, the Scottish philosopher, was one of those present that night, and he later recalled that:

This view was doubted by Sir John Hobhouse, the First Commissioner of Woods and Forests, who oversaw the upkeep of royal buildings, including the Palace of Westminster. He wrote that "the crowd behaved very well; only one man was taken up for huzzaing when the flames increased. ... on the whole, it was impossible for any large assemblage of people to behave better." Many of the MPs and peers present, including Lord Palmerston, the Secretary of State for Foreign Affairs, helped break down doors to rescue books and other treasures, aided by passers-by; the Deputy Serjeant-at-Arms had to break into a burning room to save the parliamentary mace.

At 9:00 pm three Guards regiments arrived on the scene. Although the troops assisted in crowd control, their arrival was also a reaction of the authorities to fears of a possible insurrection, for which the destruction of parliament could have signalled the first step. The three European revolutions of 1830—the French, Belgian and Polish actions—were still of concern, as were the unrest from the Captain Swing riots, and the recent passing of the Poor Law Amendment Act 1834, which altered the relief provided by the workhouse system.

At around 1:30 am the tide had risen enough to allow the LFEE's floating fire engine to arrive on the scene. Braidwood had called for the engine five hours previously, but the low tide had hampered its progress from its downriver mooring at Rotherhithe. Once it arrived it was effective in bringing under control the fire that had taken hold in the Speaker's House.

Braidwood regarded Westminster Hall as safe from destruction by 1:45 am, partly because of the actions of the floating fire engine, but also because a change in the direction of the wind kept the flames away from the Hall. Once the crowd realised that the hall was safe they began to disperse, and had left by around 3:00 am, by which time the fire near the Hall was nearly out, although it continued to burn towards the south of the complex. The firemen remained in place until about 5:00 am, when they had extinguished the last remaining flames and the police and soldiers had been replaced by new shifts.

The House of Lords, as well as its robing and committee rooms, were all destroyed, as was the Painted Chamber, and the connecting end of the Royal Gallery. The House of Commons, along with its library and committee rooms, the official residence of the Clerk of the House and the Speaker's House, were devastated. Other buildings, such as the Law Courts, were badly damaged. The buildings within the complex which emerged relatively unscathed included Westminster Hall, the cloisters and undercroft of St Stephen's, St Mary Undercroft Chapel, the Jewel Tower and Soane's new buildings to the south. The British standard measurements, the yard and pound, were both lost in the blaze; the measurements had been created in 1496. Also lost were most of the procedural records for the House of Commons, which dated back as far as the late 15th century. The original Acts of Parliament from 1497 survived, as did the Lords' Journals, all of which were stored in the Jewel Tower at the time of the fire. In the words of Shenton, the fire was "the most momentous blaze in London between the Great Fire of 1666 and the Blitz" of the Second World War. Despite the size and ferocity of the fire, there were no deaths, although there were nine casualties during the night's events that were serious enough to require hospitalisation.

The day after the fire the Office of Woods and Forests issued a report outlining the damage, stating that "the strictest enquiry is in progress as to the cause of this calamity, but there is not the slightest reason to suppose that it has arisen from any other than accidental causes." "The Times" reported on some of the possible causes of the fire, but indicated that it was likely that the burning of the Exchequer tallies was to blame. The same day the cabinet ministers who were in London met for an emergency cabinet meeting; they ordered a list of witnesses to be drawn up, and on 22 October a committee of the Privy Council sat to investigate the fire.

The committee, which met in private, heard numerous theories as to the causes of the fire, including the lax attitude of plumbers working in the Lords, carelessness of the servants at Howard's Coffee House—situated inside the palace—and a gas explosion. Other rumours began to circulate; the Prime Minister received an anonymous letter claiming that the fire was an arson attack. The committee issued its report on 8 November, which identified the burning of the tallies as the cause of the fire. The committee thought it unlikely that Cross and Furlong had been as careful in filling the furnaces as they had claimed, and the report stated that "it is unfortunate that Mr Weobley did not more effectively superintend the burning of the tallies".
King William IV offered Buckingham Palace as a replacement to parliament; the proposal was declined by MPs who considered the building "dingy". Parliament still needed somewhere to meet, and the Lesser Hall and Painted Chamber were re-roofed and furnished for the Commons and Lords respectively for the State Opening of Parliament on 23 February 1835. The opening included a statement from the King, read by Lord Brougham, the Lord Chancellor, that prorogued parliament until 25 November 1835.

Although the architect Robert Smirke was appointed in December 1834 to design a replacement palace, pressure from the former MP Lieutenant Colonel Sir Edward Cust to open the process up to a competition gained popularity in the press and led to the formation in 1835 of a Royal Commission. This body determined in which style the new construction should be built, and in June they decided that either Elizabethan or gothic styles should be used. The commission also decided that although competitors would not be required to follow the outline of the original palace, the surviving buildings of Westminster Hall, the Undercroft Chapel and the Cloisters of St Stephen's should all be incorporated into the new complex.

There were 97 entries to the competition, which closed in November 1835; each entry was to be identifiable only by a pseudonym or symbol. The commission presented their recommendation in February 1836; the winning entry, which brought a prize of £1,500, was number 64, identified by a portcullis—the symbol chosen by the architect Charles Barry. Uninspired by any English secular Elizabethan or Gothic buildings, Barry had visited Belgium to view examples of Flemish civic architecture prior to drafting his design; to complete the necessary pen and ink drawings, which are now lost, he employed Augustus Pugin, a 23-year-old architect who was, in the words of the architectural historian Nikolaus Pevsner, "the most fertile and passionate of the Gothicists". Thirty four of the competitors petitioned parliament against the selection of Barry, who was a friend of Cust, but their plea was rejected, and the former prime minister Sir Robert Peel defended Barry and the selection process.

Barry planned an enfilade, or what Christopher Jones, the former BBC political editor, has called "one long spine of Lords' and Commons' Chambers" which enabled the Speaker of the House of Commons to look through the line of the building to see the Queen's throne in the House of Lords. Laid out around 11 courtyards, the building included several residences with accommodation for about 200 people, and comprised a total of 1,180 rooms, 126 staircases and of corridors. Between 1836 and 1837 Pugin made more detailed drawings on which estimates were made for the palace's completion; reports of the cost estimates vary from £707,000 to £725,000, with six years until completion of the project.

In June 1838 Barry and colleagues undertook a tour of Britain to locate a supply of stone for the building, eventually choosing Magnesian Limestone from the Anston quarry of the Duke of Leeds. Work started on building the river frontage on 1 January 1839, and Barry's wife laid the foundation stone on 27 April 1840. The stone was badly quarried and handled, and with the polluted atmosphere in London it proved to be problematic, with the first signs of deterioration showing in 1849, and extensive renovations required periodically.

Although there was a setback in progress with a stonemasons' strike between September 1841 and May 1843, the House of Lords had its first sitting in the new chamber in 1847. In 1852 the Commons was finished, and both Houses sat in their new chambers for the first time; Queen Victoria first used the newly completed royal entrance. In the same year, while Barry was appointed a Knight Bachelor, Pugin suffered a mental breakdown and, following incarceration at Bethlehem Pauper Hospital for the Insane, died at the age of 40.

The clock tower was completed in 1858, and the Victoria Tower in 1860; Barry died in May that year, before the building work was completed. The final stages of the work were overseen by his son, Edward, who continued working on the building until 1870. The total cost of the building came to around £2.5 million.

In 1836 the Royal Commission on Public Records was formed to look into the loss of the parliamentary records, and make recommendations on the preservation of future archives. Their published recommendations in 1837 led to the Public Record Act (1838), which set up the Public Record Office, initially based in Chancery Lane.
The fire became the "single most depicted event in nineteenth-century London ... attracting to the scene a host of engravers, watercolourists and painters". Among them were J.M.W. Turner, the landscape painter, who later produced two pictures of the fire, and the Romantic painter John Constable, who sketched the fire from a hansom cab on Westminster Bridge.

The destruction of the standard measurements led to an overhaul of the British weights and measures system. An inquiry that ran from 1838 to 1841 considered the two competing systems used in the country, the avoirdupois and troy measures, and decided that avoirdupois would be used forthwith; troy weights were retained solely for gold, silver and precious stones. The destroyed weights and measures were recast by William Simms, the scientific instrument maker, who produced the replacements after "countless hours of tests and experiments to determine the best metal, the best shape of bar, and the corrections for temperature".

The Palace of Westminster has been a UNESCO World Heritage Site since 1987, and is classified as being of outstanding universal value. UNESCO describe the site as being "of great historic and symbolic significance", in part because it is "one of the most significant monuments of neo-Gothic architecture, as an outstanding, coherent and complete example of neo-Gothic style". The decision to use the Gothic design for the palace set the national style, even for secular buildings.

In 2015 the chairman of the House of Commons Commission, John Thurso, stated that the palace was in a "dire condition". The Speaker of the House of Commons, John Bercow, agreed and said that the building was in need of extensive repairs. He reported that parliament "suffers from flooding, contains a great deal of asbestos and has fire safety issues", which would cost £3 billion to fix.



</doc>
<doc id="319196" url="https://en.wikipedia.org/wiki?curid=319196" title="Tripura">
Tripura

Tripura () is a state in northeastern India. The third-smallest state in the country, it covers and is bordered by Bangladesh to the north, south, and west, and the Indian states of Assam and Mizoram to the east. In 2011 the state had 3,671,032 residents, constituting 0.3% of the country's population.

The area of modern 'Tripura' was ruled for several centuries by the Tripuri dynasty. It was the independent princely state of the Tripuri Kingdom under the protectorate of the British Empire which was known as Hill Tippera while the area annexed and ruled directly by British India was known as Tippera District (present Comilla District). The independent Tripuri Kingdom (or Hill Tippera) joined the newly independent India in 1949. Ethnic strife between the indigenous Tripuri people and the migrant Bengali population due to large influx of Bengali Hindu refugees and settlers from Bangladesh led to tension and scattered violence since its integration into the country of India, but the establishment of an autonomous tribal administrative agency and other strategies have led to peace.

Tripura lies in a geographically disadvantageous location in India, as only one major highway, the National Highway 8, connects it with the rest of the country. Five mountain ranges—Boromura, Atharamura, Longtharai, Shakhan and Jampui Hills—run north to south, with intervening valleys; Agartala, the capital, is located on a plain to the west. The state has a tropical savanna climate, and receives seasonal heavy rains from the south west monsoon. Forests cover more than half of the area, in which bamboo and cane tracts are common. Tripura has the highest number of primate species found in any Indian state. Due to its geographical isolation, economic progress in the state is hindered. Poverty and unemployment continue to plague Tripura, which has a limited infrastructure. Most residents are involved in agriculture and allied activities, although the service sector is the largest contributor to the state's gross domestic product.

According to 2011 census, Tripura is one of the most literate states in India with a literacy rate of 87.75%. Mainstream Indian cultural elements coexist with traditional practices of the ethnic groups, such as various dances to celebrate religious occasions, weddings and festivities; the use of locally crafted musical instruments and clothes; and the worship of regional deities. The sculptures at the archaeological sites Unakoti, Pilak and Devtamura provide historical evidence of artistic fusion between organised and tribal religions. The Great Chinmoy in Agartala was the former royal abode of the Tripuri king.

The Sanskrit name of the state is linked to the Hindu goddess of beauty; Tripura Sundari, the presiding deity of the Tripura Sundari Temple at Udaipur, one of the 51 "Shakti Peethas" (pilgrimage centres of "Shaktism"), and to the legendary tyrant king Tripur, who reigned in the region. Tripur was the 39th descendant of Druhyu, who belonged to the lineage of Yayati, a king of the Lunar Dynasty.

There have been suggestions to the effect that the origin of the name Tripura is doubtful, raising the possibility that the Sanskritic form is just due to a folk etymology of a Tibeto-Burman (Kokborok) name. Variants of the name include "Tripra", "Tuipura" and "Tippera". A Kokborok etymology from "twi" (water) and "pra" (near) has been suggested; the boundaries of Tripura extended to the Bay of Bengal when the kings of the Tripra Kingdom held sway from the Garo Hills of Meghalaya to Arakan, the present Rakhine State of Burma; so the name may reflect vicinity to the sea.

Although there is no evidence of lower or middle Paleolithic settlements in Tripura, Upper Paleolithic tools made of fossil wood have been found in the Haora and Khowai valleys. The Indian epic, the "Mahabharata"; ancient religious texts, the "Puranas"; and the Edicts of Ashoka – stone pillar inscriptions of the emperor Ashoka dating from the third century BCE – all mention Tripura. An ancient name of Tripura is "Kirat Desh" (English: "The land of Kirat"), probably referring to the Kirata Kingdoms or the more generic term Kirata. However, it is unclear whether the extent of modern Tripura is coterminous with "Kirat Desh". The region was under the rule of the Twipra Kingdom for centuries, although when this dates from is not documented. The "Rajmala", a chronicle of Tripuri kings which was first written in the 15th century, provides a list of 179 kings, from antiquity up to Krishna Kishore Manikya (1830–1850), but the reliability of the "Rajmala" has been doubted.
The boundaries of the kingdom changed over the centuries. At various times, the borders reached south to the jungles of the Sundarbans on the Bay of Bengal; east to Burma; and north to the boundary of the Kamarupa kingdom in Assam. There were several Muslim invasions of the region from the 13th century onward, which culminated in Mughal dominance of the plains of the kingdom in 1733, although their rule never extended to the hill regions. The Mughals had influence over the appointment of the Tripuri kings.

Tripura became a princely state during British rule in India. The kings had an estate in British India, known as Tippera district or Chakla Roshnabad (now the Comilla district of Bangladesh), in addition to the independent area known as Hill Tippera, the present-day state. Udaipur, in the south of Tripura, was the capital of the kingdom, until the king Krishna Manikya moved the capital to Old Agartala in the 18th century. It was moved to the new city of Agartala in the 19th century. Bir Chandra Manikya (1862–1896) modelled his administration on the pattern of British India, and enacted reforms including the formation of Agartala Municipal Corporation. In 1926,it became a part of Pakokku Hill Tracts Districts of British Burma until 1948,January 4.

Following the independence of India in 1947, Tippera district – the estate in the plains of British India – became a part of East Pakistan, and Hill Tippera remained under a regency council until 1949. The Maharani Regent of Tripura signed the Tripura Merger Agreement on 9 September 1949, as a result of which Tripura became a Part C state of India. It became a Union Territory, without a legislature, in November 1956 and an elected ministry was installed in July 1963. The geographic partition that coincided with the independence of India resulted in major economic and infrastructural setbacks for the state, as road transport between the state and the major cities of India had to follow a more circuitous route. The road distance between Kolkata and Agartala before the partition was less than , and increased to , as the route now avoided East Pakistan. The geo-political isolation was aggravated by an absence of rail transport.

Some parts of the state were shelled by the Pakistan Army during the Indo-Pakistani War of 1971. Following the war, the Indian government reorganised the North East region to ensure effective control of the international borders – three new states came into existence on 21 January 1972: Meghalaya, Manipur, and Tripura. Since the partition of India, many Hindu Bengalis have migrated to Tripura as refugees from East Pakistan; settlement by Hindu Bengalis increased at the time of the Bangladesh Liberation War of 1971. Hindu Bengalis migrated to Tripura after 1949 to escape religious persecution in Muslim majority East Pakistan. Before independence, most of the population was indigenous;. Ethnic strife between the Tripuri tribe and the predominantly immigrant Bengali community led to scattered violence, and an insurgency spanning decades. This gradually abated following the establishment of a tribal autonomous district council and the use of strategic counter-insurgency operations. Tripura remains peaceful, as of 2016.

Tripura is a landlocked state in North East India, where the seven contiguous states – Arunachal Pradesh, Assam, Manipur, Meghalaya, Mizoram, Nagaland and Tripura – are collectively known as the Seven Sister States. Spread over , Tripura is the third-smallest among the 29 states in the country, behind Goa and Sikkim. It extends from 22°56'N to 24°32'N, and 91°09'E to 92°20'E. Its maximum extent measures about from north to south, and east to west. Tripura is bordered by the country of Bangladesh to the west, north and south; and the Indian states of Assam to the north east; and Mizoram to the east. It is accessible by national highways passing through the Karimganj district of Assam and Mamit district of Mizoram.

The physiography is characterised by hill ranges, valleys and plains. The state has five anticlinal ranges of hills running north to south, from Boromura in the west, through Atharamura, Longtharai and Shakhan, to the Jampui Hills in the east. The intervening synclines are the Agartala–Udaipur, Khowai–Teliamura, Kamalpur–Ambasa, Kailasahar–Manu and Dharmanagar–Kanchanpur valleys. At an altitude of , Betling Shib in the Jampui range is the state's highest point. The small isolated hillocks interspersed throughout the state are known as "tillas", and the narrow fertile alluvial valleys, mostly present in the west, are called "lungas". A number of rivers originate in the hills of Tripura and flow into Bangladesh. The Khowai, Dhalai, Manu, Juri and Longai flow towards the north; the Gumti to the west; and the Muhuri and Feni to the south west.

The lithostratigraphy data published by the Geological Survey of India dates the rocks, on the geologic time scale, between the Oligocene epoch, approximately 34 to 23 million years ago, and the Holocene epoch, which started 12,000 years ago. The hills have red laterite soil that is porous. The flood plains and narrow valleys are overlain by alluvial soil, and those in the west and south constitute most of the agricultural land. According to the Bureau of Indian Standards, on a scale ranging from in order of increasing susceptibility to earthquakes, the state lies in seismic zone V.

The state has a tropical savanna climate, designated "Aw" under the Köppen climate classification. The undulating topography leads to local variations, particularly in the hill ranges. The four main seasons are winter, from December to February; pre-monsoon or summer, from March to April; monsoon, from May to September; and post-monsoon, from October to November. During the monsoon season, the south west monsoon brings heavy rains, which cause frequent floods. The average annual rainfall between 1995 and 2006 ranged from . During winter, temperatures range from , while in the summer they fall between . According to a United Nations Development Programme report, the state lies in "very high damage risk" zone from wind and cyclones.

Like most of the Indian subcontinent, Tripura lies within the Indomalaya ecozone. According to the Biogeographic classification of India, the state is in the "North-East" biogeographic zone. In 2011 forests covered 57.73 per cent of the state. Tripura hosts three different types of ecosystems: mountain, forest and freshwater. The evergreen forests on the hill slopes and the sandy river banks are dominated by species such as "Dipterocarpus", "Artocarpus", "Amoora", "Elaeocarpus", "Syzygium" and "Eugenia". Two types of moist deciduous forests comprise majority of the vegetation: moist deciduous mixed forest and Sal ("Shorea robusta")-predominant forest. The interspersion of bamboo and cane forests with deciduous and evergreen flora is a peculiarity of Tripura's vegetation. Grasslands and swamps are also present, particularly in the plains. Herbaceous plants, shrubs, and trees such as "Albizia", "Barringtonia", "Lagerstroemia" and "Macaranga" flourish in the swamps of Tripura. Shrubs and grasses include "Schumannianthus dichotoma" ("shitalpati"), "Phragmites" and "Saccharum" (sugarcane).

According to a survey in 1989–90, Tripura hosts 90 land mammal species from 65 genera and 10 orders, including such species as elephant ("Elephas maximus"), bear ("Melursus ursinus"), binturong ("Arctictis binturong"), wild dog ("Cuon alpinus"), porcupine ("Artherurus assamensis"), barking deer ("Muntiacus muntjak"), sambar ("Cervus unicolor"), wild boar ("Sus scrofa"), gaur ("Bos gaurus"), leopard ("Panthera pardus"), clouded leopard ("Neofelis nebulosa"), and many species of small cats and primates. Out of 15 free ranging primates of India, seven are found in Tripura; this is the highest number of primate species found in any Indian state. The wild buffalo ("Bubalus arnee") is extinct now. There are nearly 300 species of birds in the state.

Wildlife sanctuaries of the state are Sipahijola, Gumti, Rowa and Trishna wildlife sanctuaries. National parks of the state are Clouded Leopard National Park and Rajbari National Park. These protected areas cover a total of . Gumti is also an Important Bird Area. In winter, thousands of migratory waterfowl throng Gumti and Rudrasagar lakes.

In January 2012, major changes were implemented in the administrative divisions of Tripura. Beforehand, there had been four districts – Dhalai (headquarters Ambassa), North Tripura (headquarters Dharmanagar), South Tripura (headquarters Udaipur, Tripura), and West Tripura (headquarters Agartala). Four new districts were carved out of the existing four in January 2012 – Khowai, Unakoti, Sipahijala and Gomati. Six new subdivisions and five new blocks were also added. Each is governed by a district collector or a district magistrate, usually appointed by the Indian Administrative Service. The subdivisions of each district are governed by a sub-divisional magistrate and each subdivision is further divided into blocks. The blocks consist of "Panchayat"s (village councils) and town municipalities. As of 2012, the state had eight districts, 23 subdivisions and 58 development blocks. National census and state statistical reports are not available for all the new administrative divisions, as of March 2013. Agartala, the capital of Tripura, is the most populous city. Other major towns with a population of 10,000 or more (as per 2015 census) are Sabroom, Dharmanagar, Jogendranagar, Kailashahar, Pratapgarh, Udaipur, Amarpur, Belonia, Gandhigram, Kumarghat, Khowai, Ranirbazar, Sonamura, Bishalgarh, Teliamura, Mohanpur, Melaghar, Ambassa, Kamalpur, Bishramganj, Kathaliya, Santirbazar and Baxanagar.

Tripura is governed through a parliamentary system of representative democracy, a feature it shares with other Indian states. Universal suffrage is granted to residents. The Tripura government has three branches: executive, legislature and judiciary. The Tripura Legislative Assembly consists of elected members and special office bearers that are elected by the members. Assembly meetings are presided over by the Speaker or the Deputy Speaker in case of Speaker's absence. The Assembly is unicameral with 60 Members of the Legislative Assembly (MLA). The members are elected for a term of five years, unless the Assembly is dissolved prior to the completion of the term. The judiciary is composed of the Tripura High Court and a system of lower courts. Executive authority is vested in the Council of Ministers headed by the Chief Minister. The Governor, the titular head of state, is appointed by the President of India. The leader of the party or a coalition of parties with a majority in the Legislative Assembly is appointed as the Chief Minister by the Governor. The Council of Ministers are appointed by the Governor on the advice of the Chief Minister. The Council of Ministers reports to the Legislative Assembly.

Tripura sends two representatives to the Lok Sabha (the lower house of the parliament of India) and one representative to the Rajya Sabha (parliament's upper house). "Panchayats" (local self-governments) elected by local body elections are present in many villages for self-governance. Tripura also has a unique tribal self-governance body, the Tripura Tribal Areas Autonomous District Council. This council is responsible for some aspects of local governance in 527 villages with high density of the scheduled tribes.

The main political parties are the Bharatiya Janata Party (BJP), the Left Front, the All India Trinamool Congress and Indian National Congress along with regional parties like IPFT and INPT. Until 1977, the state was governed by the Indian National Congress. The Left Front was in power from 1978 to 1988, and then again from 1993 to 2018. During 1988–1993, the Congress and Tripura Upajati Juba Samiti were in a ruling coalition. In the Tripura Legislative Assembly election, 2013, the Left Front won 50 out of 60 seats in the Assembly.. The 2018 assembly election resulted in loss for the Left Front. The Bharatiya Janata Party won an overall majority in the state, resulting in the end of the Communist Party's uninterrupted twenty-five year rule. BJP won 44 out of 60 seats in the Assembly by coalition with IPFT. CPI (M) only got 16 seats and Indian National Congress lost by huge margins in all constituencies. 

Communism in the state had its beginnings in the pre-independence era, inspired by freedom struggle activities in Bengal, and culminating in regional parties with communist leanings. It capitalised on the tribal dissatisfaction with the mainstream rulers, and has been noted for connection with the "sub-national or ethnic searches for identity".
Since the 1990s, there is an ongoing irredentist Tripura rebellion, involving militant outfits such as the National Liberation Front of Tripura and the All Tripura Tiger Force (ATTF); terrorist incidents involving the ATTF claimed a recorded number of 389 victims in the seven-year period of 1993 to 2000. The Armed Forces (Special Powers) Act, 1958 (AFSPA) was first enforced in Tripura on 16 February 1997 when terrorism was at its peak in the state. Ever since it was enforced in Tripura, the Act, as per its provisions, was reviewed and extended after every six months. However, in view of the improvement in the situation and fewer terrorist activities being reported, the Tripura government in June 2013 reduced operational areas of the AFSPA to 30 police station areas. The last six-month extension to AFSPA was given in November 2014, and after about 18 years of operation, it was repealed on 29 May 2015. The Twipra Students Federation (TSF) demanded that AFSPA be revoked in the state.

The state has one autonomous council.

Tripura's gross state domestic product for 2010–11 was at constant price (2004–05), recording 5.71 per cent growth over the previous year. In the same period, the GDP of India was , with a growth rate of 8.55 per cent. Annual per capita income at current price of the state was , compared to the national per capita income . In 2009, the tertiary sector of the economy (service industries) was the largest contributor to the gross domestic product of the state, contributing 53.98 per cent of the state's economy compared to 23.07 per cent from the primary sector (agriculture, forestry, mining) and 22.95 per cent from the secondary sector (industrial and manufacturing). According to the Economic Census of 2005, after agriculture, the maximum number of workers were engaged in retail trade (28.21 per cent of total non-agricultural workforce), followed by manufacturing (18.60 per cent), public administration (14.54 per cent), and education (14.40 per cent).

Tripura is an agrarian state with more than half of the population dependent on agriculture and allied activities. However, due to hilly terrain and forest cover, only 27 per cent of the land is available for cultivation. Rice, the major crop of the state, is cultivated in 91 per cent of the cropped area. According to the Directorate of Economics & Statistics, Government of Tripura, in 2009–10, potato, sugarcane, mesta, pulses and jute were the other major crops cultivated in the state. Jackfruit and pineapple top the list of horticultural products. Traditionally, most of the indigenous population practised "jhum" method (a type of slash-and-burn) of cultivation. The number of people dependent on "jhum" has declined over the years.

Pisciculture has made significant advances in the state. At the end of 2009–10, the state produced a surplus of 104.3 million fish seeds, primarily carp. Rubber and tea are the important cash crops of the state. Tripura ranks second to Kerala in the production of natural rubber in the country. The state is known for its handicraft, particularly hand-woven cotton fabric, wood carvings, and bamboo products. High quality timber including sal, garjan, teak and gamar are found abundantly in the forests of Tripura. Tata Trusts signed a pact with Government of Tripura in July 2015 to improve fisheries and dairy in the state.

The industrial sector of the state continues to be highly underdeveloped – brickfields and tea industry are the only two organised sectors. Tripura has considerable reservoirs of natural gas. According to estimates by Oil and Natural Gas Corporation (ONGC), the state has 400 billion metres reserves of natural gas, with 16 billion metres is recoverable. ONGC produced 480 million metres natural gas in the state, in 2006–07. In 2011 and 2013, new large discoveries of natural gas were announced by ONGC. Tourism industry in the state is growing – the revenue earned in tourism sector crossed for the first time in 2009–10, and surpassed in 2010–11. Although Bangladesh is in a trade deficit with India, its export to Tripura is significantly more than import from the state; a report in the newspaper "The Hindu" estimated Bangladesh exported commodities valued at about to the state in 2012, as opposed to "very small quantity" of import. Alongside legal international trade, unofficial and informal cross-border trade is rampant. In a research paper published by the Institute of Developing Economies in 2004, the dependence of Tripura's economy on that of Bangladesh was emphasised.

The economy of Tripura can be characterised by high rate of poverty, low capital formation, inadequate infrastructure facilities, geographical isolation and communication bottlenecks, inadequate exploration and use of forest and mineral resources, slow industrialisation and high unemployment. More than 50% of the population depends on agriculture for sustaining their livelihood. However agriculture and allied activities to Gross State Domestic Production (GSDP) is only 23%, this is primarily because of low capital base in the sector. Despite the inherent limitation and constraints coupled with severe resources for investing in basic infrastructure, this has brought consistence progress in quality of life and income of people cutting across all sections of society. The state government through its Tripura Industrial Policy and Tripura Industrial Incentives Scheme, 2012, has offered heavy subsidies in capital investment and transport, preferences in government procurement, waivers in tender processes and fees, yet the impact has been not much significant beyond a few industries being set up in the Bodhjungnagar Industrial Growth Center.

The Planning Commission estimates the poverty rate of all North East Indian states by using head count ratio of Assam (the second largest state in North East India after Arunachal Pradesh ). According to 2001 Planning Commission assessment, 22 per cent of Tripura's rural residents were below the poverty line. However, Tripura government's independent assessment, based on consumption distribution data, reported that, in 2001, 55 per cent of the rural population was below the poverty line. Geographic isolation and communication bottleneck coupled with insufficient infrastructure have restricted economic growth of the state. High rate of poverty and unemployment continues to be prevalent.

Air<br>

Agartala Airport, located 12 km northwest of Agartala at Singerbhil, is the second busiest airport in northeast India after Guwahati. There are direct flights to Kolkata, Imphal, Delhi, Shillong, Guwahati, Bangalore, Chennai, Ahmedabad and Mumbai. The major airlines are Air India and Indigo Airlines. Passenger helicopter services are available between the capital and major towns (Kailashahar, Dharmanagar) as well as to more remote areas such as Kanchanpur, Belonia and Gandacherra.

Railway<br>

Agartala, came on India's railway map with the advent of the railways in the subcontinent in 1853 but the link was broken when India was partitioned in 1947. Railway service was established in Tripura in 1964 by constructing track from Lumding in Assam to Dharmanagar and Kailasahar in Tripura but the track did not connect the state capital Agartala. Rail transport was absent in the state until 2008–09 when the railway track was extended to the capital Agartala. The metre gauge rail track was connected to broad gauge at Lumding. The major railways stations in this line are in Agartala, Dharmanagar, and Kumarghat. This metre gauge track was converted to broad gauge in 2016 and now trains run from Agartala to Calcutta and Delhi. The total length of this railway track in Tripura state is 153 km. It is a single line without electrification.

Extension of the railway line from Agartala to the southernmost town of Sabroom at Bangladesh border is in progress. The 43 km long track from Agartala to Udaipur-Tripura railway station (station code UDPU) near Mata Tripura Sundari Temple has been commissioned and two trains run on this section. The 70 km long section from Udaipur-Tripura to Sabroom on the bank of Feni River, which separates Tripura from Bangladesh, is being constructed as of 2017.

A new railway line is being laid westwards from Agartala to Akhaura in Bangladesh. This will reduce the distance between Agartala and Calcutta by over 1000 km and provide rail access to Chittagong port.

Road<br>

Only one major road, the National Highway 8 (NH-8), connects Tripura to the rest of India. Starting at Sabroom in southern Tripura, it heads north to the capital Agartala, turns east and then north-east to enter the state of Assam. Locally known as "Assam Road", the NH-8 is often called the lifeline of Tripura. However, the highway is single lane and of poor quality; often landslides, rains or other disruptions on the highway cut the state off from its neighbours. Another National Highway, NH 108, connects the town Panisagar in North Tripura District with Aizawl, Mizoram. The Tripura Road Transport Corporation is the government agency overlooking public transport on road. A hilly and land-locked state, Tripura is dependent mostly on roads for transport. The total length of roads in the state is of which national highways constitute and state highways , as of 2009–10. Residents in rural areas frequently use waterways as a mode of transport.

Tripura has an long international border with Bangladesh, of which is fenced, as of 2012. Several locations along the border serve as bilateral trading points between India and Bangladesh, such as Akhaura near Agartala, Raghna, Srimantpur, Belonia, Khowai and Kailasahar. A bus service exists between Agartala and Dhaka, the capital of Bangladesh. In 2013, the two countries signed an agreement to establish a railway link between Agartala and the Akhaura junction of Bangladesh. Citizens of both countries need visa to legally enter the other country; however, illegal movement and smuggling across the border are widespread.

Doordarshan (DD) has a television station in Agartala.
Akash Tripura, is one of the first television channels in Agartala. It is a full-time Agartala-based news channel. Other full-time based channels are Headlines Tripura, News Vanguard, Prime Television Network.

As of 2014, 56 daily and weekly newspapers are published in Tripura. Most of the newspapers are published in Bengali, except for one Kokborok daily ("Hachukni Kok"), one Manipuri weekly ("Marup"), two English dailies and three bilingual weeklies. Notable dailies include "Ajkal Tripura", "Daily Desher Katha", "Dainik Sambad" and "Syandan Patrika". and popular news portal www.tripurachronicle.in In a study by Indian Institute of Mass Communication in 2009, 93 per cent of the sampled in Tripura rated television as very effective for information and mass education. In the study, 67 per cent of the sampled listened to radio and 80–90 per cent read newspaper. Most of the major Indian telecommunication companies are present in the state, such as Airtel, Aircel, Vodafone, Reliance, Jio, Idea and BSNL. Mobile connections outnumber landline connections by a wide margin. As of 2011, the state-controlled BSNL has 57,897 landline subscribers and GSM mobile service connections. There are 84 telephone exchanges (for landlines) and 716 post offices in the state, as of 2011.

Till 2014, Tripura was a power deficit state. In late 2014, Tripura reached surplus electricity production capacity by using its recently discovered natural gas resources, and installing high efficiency gas turbine power plants. The state has many power-generating stations. These are owned by Tripura State Electricity Corporation (TSECL), natural gas-powered thermal power stations at Rokhia and Baramura, and the ONGC Tripura Power Company in Palatana. The ONGC plant has a capacity of 726.6 MW, with the second plant's commissioning in November 2014. It is the largest individual power plant in the northeast region.

The state also has a hydro power station on the Gumti River. The combined power generation from these three stations is 100–105 MW. The North Eastern Electric Power Corporation (NEEPCO) operates the 84 MW Agartala Gas Turbine Power Plant near Agartala. As of November 2014, another thermal power plant is being built at Monarchak.

With the newly added power generation capacity, Tripura has with enough capacity to supply all seven sister states of northeast India, as well export power to neighbouring countries such as Bangladesh. With recent discoveries, the state has abundant natural gas reserves to support many more power generation plants, but lacks pipeline and transport infrastructure to deliver the fuel or electricity to India's national grid.

As of 2011, of land in Tripura cultivable, of which has the potential to be covered by irrigation projects. However, only is irrigated. The state lacks major irrigation projects; it depends on medium-sized projects sourced from Gumti, Khowai (at Chakmaghat) and Manu rivers, and minor projects administered by village-level governing bodies that utilise tube wells, water pumps, tanks and lift irrigation.

ONGC and Chambal Fertilizers & Chemicals are jointly building a fertiliser plant to leverage ONGC's natural gas discoveries in Tripura. Expected to be in operation by 2017, the 1.3 million tonnes per year plant will supply the northeastern states.

Drinking Water and Sanitation (DWS) wing of Public Works Department manages the drinking water supply in the state. Schools and Anganwadi Centers have been specifically targeted to improve drinking water supply as well as attendance to these institutions. Many areas of Tripura have the problem of excessive iron content in groundwater requiring the installation of Iron Removal Plants (IRP). Tripura State has received the best State Award for Water & Sanitation under the category of Small States in the IBN7 Diamond State Award function for doing commendable work to provide drinking water supply to the people with the sparsely distributed tribal population in hamlets of hilly region of the State. However, a study by the DWS Department found depleting water table and excessive contamination. Still, packaged drinking water under brands "Tribeni", "Eco Freshh", "Blue Fina", "Life Drop" and "Aqua Zoom" among others is manufactured and sold in the state. Filters of many types and brands, in addition to locally manufactured ceramic type filters, are sold in the state although their acceptance in rural areas is less.

Tripura has high incidence of open defecation, especially in the interior hilly and forest areas. The state has extensively implemented Nirmal Bharat Abhiyan and currently the Swachh Bharat Abhiyan and convergence with MGNREGS to address this problem. Schools and Anganwadi Center are focussed to provide with urinals and latrines, separate for boys and girls aling with baby friendly toilets in Anganwadi Centers to inculcate the habit of using sanitary latrines in young age. However many toilets lie dysfuncational due to lack of maintenance and damage. Earlier schemes of providing plastic squatting plates, free of cost to people, has not produced results as most of them lie unused as many people cannot afford to construct a toilet. Open defecation has created problems of diarrhoea and vulnerability to malaria. The Chief Minister of Tripura has envisioned to make the state Open Defecation Free (ODF) by 2017.

Per 2011 census, the literacy rate of Tripura was 87.75 percent, the fourth-highest in India (which had a national literacy rate of 74.04 percent). A state government survey in 2013 announced that Tripura has the highest literacy rate in India at 94.65 percent. Schools in Tripura are run by the state government, TTAADC or private organisations, which include religious institutions. Instruction in schools is mainly in Bengali or English, though Kokborok and other regional languages are also used. Some of the special schools include Jawahar Navodaya Vidyalaya, Kasturba Gandhi Balika Vidyalaya, residential schools run by Tripura Tribal Welfare Residential Educational Institutions Society (TTWREIS), missionary organisations like St. Paul's,
St. Arnold's, Holy Cross, Don Bosco, and St. John's. The schools are affiliated to the Council for the Indian School Certificate Examinations (CISCE), the Central Board for Secondary Education (CBSE), the National Institute of Open Schooling (NIOS) or the Tripura Board of Secondary Education. Under the 10+2+3 plan, after completing secondary school, students typically enroll for two years in a junior college or in a higher secondary school affiliated either to the Tripura Board of Secondary Education or to other central boards. Students choose from one of the three streams—liberal arts, commerce or science. As in the rest of India, after passing the Higher Secondary Examination (the grade 12 examination), students may enroll in general degree programs such as bachelor's degree in arts, commerce or science, or professional degree programs such as engineering, law or medicine.

According to the Economic Review of Tripura 2010–11, Tripura has a total of 4,455 schools, of which 2,298 are primary schools. The total enrolment in all schools of the state is 767,672. Tripura has one Central University (Tripura University), one State University (M. B. B. University) and one private university (a branch of the Institute of Chartered Financial Analysts of India). There are 15 general colleges, three engineering colleges (Tripura Institute of Technology, National Institute of Technology, Agartala and NIEILT, Agartala), two medical colleges (Agartala Government Medical College and Tripura Medical College), three nursing or paramedical colleges, three polytechnic colleges, one law college, one Government Music College, one College of Fisheries, Institute of Advance Studies in Education, one Regional College of Physical Education at Panisagar and one art college. Tripura University also houses the IGNOU Agartala Regional Center.

Healthcare in Tripura features a universal health care system run by the Ministry of Health & Family Welfare of the Government of Tripura. The health care infrastructure is divided into three tiers – the primary health care network, a secondary care system comprising district and sub-divisional hospitals and tertiary hospitals providing speciality and super speciality care. As of 2010–11, there are 17 hospitals, 11 rural hospitals and community health centres, 79 primary health centres, 635 sub-centres/dispensaries, 7 blood banks and 7 blood storage centres in the state. Homeopathic and Ayurvedic styles of medicine are also popular in the state. The National Family Health Survey – 3 conducted in 2005–06 revealed that 20 per cent of the residents of Tripura do not generally use government health facilities, and prefers private medical sector. This is overwhelmingly less compared to the national level, where 65.6 per cent do not rely on government facilities. As in the rest of India, Tripura residents also cite poor quality of care as the most frequent reason for non-reliance over public health sector. Other reasons include distance of the public sector facility, long waiting time, and inconvenient hours of operation. As of 2010, the state's performance in major public health care indices, such as birth rate, infant mortality rate and total fertility rate is better than the national average. The state is vulnerable to epidemics of malaria, diarrhea, Japanese encephalitis and meningitis. In summer 2014 the state witnessed a major malaria outbreak.

Tripura ranks second to Assam as the most populous state in North East India. According to the provisional results of 2011 census of India, Tripura has a population of 3,671,032 with 1,871,867 males and 1,799,165 females. It constitutes 0.3 per cent of India's population. The sex ratio of the state is 961 females per thousand males, higher than the national ratio 940. The density of population is 350 persons per square kilometre. The literacy rate of Tripura in 2011 was 87.75 per cent, higher than the national average 74.04 per cent, and third best among all the states.

Tripura ranked 6th in Human Development Index (HDI) among 35 states and union territories of India, according to 2006 estimate by India's Ministry of Women and Child Development; the HDI of Tripura was 0.663, better than the all-India HDI 0.605.

In 2011, the police in Tripura recorded 5,803 cognisable offences under the Indian Penal Code, a number second only to Assam (66,714) in North East India. The crime rate in the state was 158.1 per 100,000 people, less than the all-India average of 192.2. However, 2010 reports showed that the state topped all the states for crime against women, with a rate of 46.5 per 100,000 people, significantly more than the national rate of 18.

In the 2001 census of India, Bengalis represented almost 70 per cent of Tripura's population while the Tripuri population amounted to 30 per cent. The state's "scheduled tribes", historically disadvantaged groups of people recognised by the country's constitution, consist of 19 ethnic groups and many as sub-groups, with diverse languages and cultures. In 2001, the largest such group was the Kokborok-speaking Tripuris, which had a population of 543,848, representing 17.0 per cent of the state's population and 54.7 per cent of the "scheduled tribe" population. The other major groups, in descending order of population, were the Reang (16.6 per cent of the indigenous population), Jamatia (7.5 per cent), Chakma (6.5 per cent), Halam (4.8 per cent), Mog (3.1 per cent), Munda (1.2 per cent), Kuki (1.2 per cent) and Garo (1.1 per cent).

Bengali is the most widely spoken language. Kokborok is a prominent language among the Tripura tribes. Several other languages such as Mog, Odia, Bishnupriya Manipuri, Manipuri, Halam, Kuki, Garo and Chakma belonging to Indo-European and Sino-Tibetan families are spoken in the state. Saimar, a nearly extinct language, is spoken by only four people in one village, as of 2012.

According to 2011 census, Hinduism is the majority religion in the state, followed by 83.40 per cent of the population. Muslims make up 8.60 per cent of the population, Christians 4.35 per cent, and Buddhists 3.41 per cent. The indigenous people of the state i.e., ethnic Tripuris are mostly Hindu. Mogs (Barua & Mutsuddy also comes under Mog community) and Chakmas (who were indigenous people of Chindwin valley in Arakan Roma) are the followers of Theravada Buddhism in Tripura.

Christianity is chiefly followed by members of the Lushai, Kuki, Garo, Tripuri, Halam tribes and as per 2017 census has 159,882 adherents.

The diverse ethno-linguistic groups of Tripura have given rise to a composite culture. The dominant ethnic groups are Bengali, Tripuri (Debbarma, Tripura, Jamatia, Reang, Noatia, Koloi, Murasing, Chakma, Halam, Garo, Kuki, Mizo, Uchoi, Dhamai, Roaza, Mogh), and other tribal groups such as Munda, Oraon and Santhal who migrated in Tripura as a tea labourers. Bengali people represent the largest ethno-linguist community of the state. Bengali culture, as a result, is the main non-indigenous, non-Tripura culture. The Tripuri Maharajas were great patrons of Bengali culture, especially literature; Bengali language replaced Kokborok as the language of the court. Elements of Bengali culture, such as Bengali literature, Bengali music, and Bengali cuisine are widespread, particularly in the urban areas of the state.

Tripura is noted for bamboo and cane handicrafts. Bamboo, wood and cane are used to create an array of furniture, utensils, hand-held fans, replicas, mats, baskets, idols and interior decoration materials. Music and dance are integral to the culture of the state. Some local musical instruments are the "sarinda", "chongpreng" (both string instruments), and "sumui" (a type of flute). Each indigenous community has its own repertoire of songs and dances performed during weddings, religious occasions, and other festivities. The Tripuri and Jamatia people perform goria dance during the Goria puja. Jhum dance (also called tangbiti dance), lebang dance, mamita dance, and mosak sulmani dance are other Tripuri dance forms. Reang community, the second largest scheduled tribe of the state, is noted for its hojagiri dance that is performed by young girls balanced on earthen pitchers. Bizhu dance is performed by the Chakmas during the Bizhu festival (the last day of the month of "Chaitra" in Hindu calendar). Other dance forms include wangala dance of the Garo people, hai-hak dance of the Halam branch of Kuki people, and sangrai dance and owa dance of the Mog. Alongside such traditional music, mainstream Indian musical elements such as Indian classical music and dance, Rabindra Sangeet are also practised. Sachin Dev Burman, a member of the royal family, was a maestro in the filmi genre of Indian music.
Hindus believe that "Tripura Sundari" is the patron goddess of Tripura and an aspect of "Shakti". Durga Puja, Kali Puja, Dolyatra, Ashokastami and the worship of the "Chaturdasha" deities are important festivals in the state. Some festivals represent confluence of different regional traditions, such as Ganga puja, Garia puja, Kharchi puja and Ker puja. Unakoti, Pilak and Devtamura are historic sites where large collections of stone carvings and rock sculptures are noted. Like Neermahal is a cultural Water Palace of this state. Sculptures are evidence of the presence of Buddhist and Brahmanical orders for centuries, and represent a rare artistic fusion of traditional organised religions and tribal influence.
The State Museum in the Ujjayanta Palace in Agartala has impressive galleries that depict the history and culture of Tripura through pictures, videos and other installations.

Football and cricket are the most popular sports in the state. On 16 December 2018 T10 Cricket night league named DTL going to organise in Dharmanagar, North Tripura.The state capital Agartala has its own club football championships every year in which many local clubs compete in a league and knockout format. The Tripura cricket team participates in the Ranji Trophy, the Indian domestic cricket competition. The state is a regular participant of the Indian National Games and the North Eastern Games.In 2016, Dipa Karmakar from Agartala became the first ever female gymnast from India to qualify for the Olympics when she qualified for the women's artistic gymnastics event of 2016 Summer Olympics.




General information


</doc>
<doc id="319522" url="https://en.wikipedia.org/wiki?curid=319522" title="Cattle egret">
Cattle egret

The cattle egret ("Bubulcus ibis") is a cosmopolitan species of heron (family Ardeidae) found in the tropics, subtropics, and warm-temperate zones. It is the only member of the monotypic genus Bubulcus, although some authorities regard two of its subspecies as full species, the western cattle egret and the eastern cattle egret. Despite the similarities in plumage to the egrets of the genus "Egretta", it is more closely related to the herons of "Ardea". Originally native to parts of Asia, Africa, and Europe, it has undergone a rapid expansion in its distribution and successfully colonised much of the rest of the world in the last century.

It is a white bird adorned with buff plumes in the breeding season. It nests in colonies, usually near bodies of water and often with other wading birds. The nest is a platform of sticks in trees or shrubs. Cattle egrets exploit drier and open habitats more than other heron species. Their feeding habitats include seasonally inundated grasslands, pastures, farmlands, wetlands, and rice paddies. They often accompany cattle or other large mammals, catching insect and small vertebrate prey disturbed by these animals. Some populations are migratory and others show postbreeding dispersal.

The adult cattle egret has few predators, but birds or mammals may raid its nests, and chicks may be lost to starvation, calcium deficiency, or disturbance from other large birds. This species maintains a special relationship with cattle, which extends to other large grazing mammals; wider human farming is believed to be a major cause of their suddenly expanded range. The cattle egret removes ticks and flies from cattle and consumes them. This benefits both species, but it has been implicated in the spread of tick-borne animal diseases.

The cattle egret was first described in 1758 by Linnaeus in his "Systema naturae" as "Ardea ibis", but was moved to its current genus by Charles Lucien Bonaparte in 1855. Its genus name "Bubulcus" is Latin for herdsman, referring, like the English name, to this species' association with cattle. "Ibis" is a Latin and Greek word which originally referred to another white wading bird, the sacred ibis, but was applied to this species in error.

The cattle egret has two geographical races, which are sometimes classified as full species, the western cattle egret, "B. ibis", and eastern cattle egret, "B. coromandus". The two forms were split by McAllan and Bruce, but were regarded as conspecific by almost all other recent authors until the publication of the influential "Birds of South Asia". The eastern subspecies "B. (i.) coromandus", described by Pieter Boddaert in 1783, breeds in Asia and Australasia, and the western nominate form occupies the rest of the species range, including the Americas. Some authorities recognise a third Seychelles subspecies, "B. i. seychellarum", which was first described by Finn Salomonsen in 1934.

Despite superficial similarities in appearance, the cattle egret is more closely related to the genus "Ardea", which comprises the great or typical herons and the great egret ("A. alba"), than to the majority of species termed egrets in the genus "Egretta". Rare cases of hybridization with little blue herons "Egretta caerulea", little egrets "Egretta garzetta" and snowy egrets "Egretta thula" have been recorded.

The cattle egret is a stocky heron with an wingspan; it is long and weighs . It has a relatively short, thick neck, a sturdy bill, and a hunched posture. The nonbreeding adult has mainly white plumage, a yellow bill, and greyish-yellow legs. During the breeding season, adults of the nominate western subspecies develop orange-buff plumes on the back, breast, and crown, and the bill, legs, and irises become bright red for a brief period prior to pairing. The sexes are similar, but the male is marginally larger and has slightly longer breeding plumes than the female; juvenile birds lack coloured plumes and have a black bill.

"B. i. coromandus" differs from the nominate subspecies in breeding plumage, when the buff colour on its head extends to the cheeks and throat, and the plumes are more golden in colour. This subspecies' bill and tarsus are longer on average than in "B. i. ibis". "B. i. seychellarum" is smaller and shorter-winged than the other forms. It has white cheeks and throat, like "B. i. ibis", but the nuptial plumes are golden, as with "B. i. coromandus". Individuals with abnormally grey, melanistic plumages have been recorded.

The positioning of the egret's eyes allows for binocular vision during feeding, and physiological studies suggest that the species may be capable of crepuscular or nocturnal activity. Adapted to foraging on land, they have lost the ability possessed by their wetland relatives to accurately correct for light refraction by water.

This species gives a quiet, throaty "rick-rack" call at the breeding colony, but is otherwise largely silent.

The cattle egret has undergone one of the most rapid and wide-reaching natural expansions of any bird species. It was originally native to parts of southern Spain and Portugal, tropical and subtropical Africa, and humid tropical and subtropical Asia. At the end of the 19th century, it began expanding its range into southern Africa, first breeding in the Cape Province in 1908. Cattle egrets were first sighted in the Americas on the boundary of Guiana and Suriname in 1877, having apparently flown across the Atlantic Ocean. In the 1930s, the species is thought to have become established in that area.

The species first arrived in North America in 1941 (these early sightings were originally dismissed as escapees), bred in Florida in 1953, and spread rapidly, breeding for the first time in Canada in 1962. It is now commonly seen as far west as California. It was first recorded breeding in Cuba in 1957, in Costa Rica in 1958, and in Mexico in 1963, although it was probably established before then. In Europe, the species had historically declined in Spain and Portugal, but in the latter part of the 20th century, it expanded back through the Iberian Peninsula, and then began to colonise other parts of Europe, southern France in 1958, northern France in 1981, and Italy in 1985. Breeding in the United Kingdom was recorded for the first time in 2008, only a year after an influx seen in the previous year. In 2008, cattle egrets were also reported as having moved into Ireland for the first time. This trend has continued and cattle egrets have become more numerous in southern Britain with influxes in some numbers during the nonbreeding seasons of 2007/08 and 2016/17. They bred in Britain again in 2017, following an influx in the previous winter, and may become established there.

In Australia, the colonisation began in the 1940s, with the species establishing itself in the north and east of the continent. It began to regularly visit New Zealand in the 1960s. Since 1948, the cattle egret has been permanently resident in Israel. Prior to 1948, it was only a winter visitor.

The massive and rapid expansion of the cattle egret's range is due to its relationship with humans and their domesticated animals. Originally adapted to a commensal relationship with large grazing and browsing animals, it was easily able to switch to domesticated cattle and horses. As the keeping of livestock spread throughout the world, the cattle egret was able to occupy otherwise empty niches. Many populations of cattle egrets are highly migratory and dispersive, and this has helped the species' range expansion. The species has been seen as a vagrant in various sub-Antarctic islands, including South Georgia, Marion Island, the South Sandwich Islands, and the South Orkney Islands. A small flock of eight birds was also seen in Fiji in 2008.

In addition to the natural expansion of its range, cattle egrets have been deliberately introduced into a few areas. The species was introduced to Hawaii in 1959, and to the Chagos Archipelago in 1955. Successful releases were also made in the Seychelles and Rodrigues, but attempts to introduce the species to Mauritius failed. Numerous birds were also released by Whipsnade Zoo in England, but the species was never established.

Although the cattle egret sometimes feeds in shallow water, unlike most herons it is typically found in fields and dry grassy habitats, reflecting its greater dietary reliance on terrestrial insects rather than aquatic prey.

Some populations of cattle egrets are migratory, others are dispersive, and distinguishing between the two can be difficult. In many areas, populations can be both sedentary and migratory. In the Northern Hemisphere, migration is from cooler climes to warmer areas, but cattle egrets nesting in Australia migrate to cooler Tasmania and New Zealand in the winter and return in the spring. Migration in western Africa is in response to rainfall, and in South America, migrating birds travel south of their breeding range in the nonbreeding season. Populations in southern India appear to show local migrations in response to the monsoons. They move north from Kerala after September. During winter, many birds have been seen flying at night with flocks of Indian pond herons ("Ardeola grayii") on the south-eastern coast of India and a winter influx has also been noted in Sri Lanka.

Young birds are known to disperse up to from their breeding area. Flocks may fly vast distances and have been seen over seas and oceans including in the middle of the Atlantic.
This species has a large range, with an estimated global extent of occurrence of . Its global population estimated to be 3.8–6.7 million individuals. For these reasons, the species is evaluated as least concern. The expansion and establishment of the species over large ranges, though, has led it to be classed as an invasive species (although little, if any impact has been noted yet).

The cattle egret nests in colonies, which are often found around bodies of water. The colonies are usually found in woodlands near lakes or rivers, in swamps, or on small inland or coastal islands, and are sometimes shared with other wetland birds, such as herons, egrets, ibises, and cormorants. The breeding season varies within South Asia. Nesting in northern India begins with the onset of monsoons in May. The breeding season in Australia is November to early January, with one brood laid per season. The North American breeding season lasts from April to October. In the Seychelles, the breeding season of "B.i. seychellarum" is April to October.

The male displays in a tree in the colony, using a range of ritualised behaviours, such as shaking a twig and sky-pointing (raising his bill vertically upwards), and the pair forms over 3–4 days. A new mate is chosen in each season and when renesting following nest failure. The nest is a small, untidy platform of sticks in a tree or shrub constructed by both parents. Sticks are collected by the male and arranged by the female, and stick-stealing is rife. The clutch size can be one to five eggs, although three or four is most common. The pale bluish-white eggs are oval-shaped and measure . Incubation lasts around 23 days, with both sexes sharing incubation duties. The chicks are partly covered with down at hatching, but are not capable of fending for themselves; they become capable of regulating their temperature at 9–12 days and are fully feathered in 13–21 days. They begin to leave the nest and climb around at 2 weeks, fledge at 30 days and become independent at around the 45th day.

The cattle egret engages in low levels of brood parasitism, and a few instances have been reported of cattle egret eggs being laid in the nests of snowy egrets and little blue herons, although these eggs seldom hatch. Also, evidence of low levels of intraspecific brood parasitism has been found, with females laying eggs in the nests of other cattle egrets. As much as 30% extra-pair copulations has been noted.

The dominant factor in nesting mortality is starvation. Sibling rivalry can be intense, and in South Africa, third and fourth chicks inevitably starve. In the dryer habitats with fewer amphibians, the diet may lack sufficient vertebrate content and may cause bone abnormalities in growing chicks due to calcium deficiency. In Barbados, nests were sometimes raided by vervet monkeys, and a study in Florida reported the fish crow and black rat as other possible nest raiders. The same study attributed some nestling mortality to brown pelicans nesting in the vicinity, which accidentally, but frequently, dislodged nests or caused nestlings to fall. In Australia, Torresian crows, wedge-tailed eagles, and white-bellied sea eagles take eggs or young, and tick infestation and viral infections may also be causes of mortality.

The cattle egret feeds on a wide range of prey, particularly insects, especially grasshoppers, crickets, flies (adults and maggots), and moths, as well as spiders, frogs, and earthworms. In a rare instance, they have been observed foraging along the branches of a banyan tree for ripe figs. The species is usually found with cattle and other large grazing and browsing animals, and catches small creatures disturbed by the mammals. Studies have shown that cattle egret foraging success is much higher when foraging near a large animal than when feeding singly. When foraging with cattle, it has been shown to be 3.6 times more successful in capturing prey than when foraging alone. Its performance is similar when it follows farm machinery, but it is forced to move more. In urban situations, cattle egrets have also been observed foraging in peculiar situations such as railway lines.

A cattle egret will weakly defend the area around a grazing animal against others of the same species, but if the area is swamped by egrets, it will give up and continue foraging elsewhere. Where numerous large animals are present, cattle egrets selectively forage around species that move at around 5–15 steps per minute, avoiding faster and slower moving herds; in Africa, cattle egrets selectively forage behind plains zebras, waterbuck, blue wildebeest and Cape buffalo. Dominant birds feed nearest to the host, and thus obtain more food.

The cattle egret sometimes shows versatility in its diet. On islands with seabird colonies, it will prey on the eggs and chicks of terns and other seabirds. During migration, it has also been reported to eat exhausted migrating landbirds. Birds of the Seychelles race also indulge in some kleptoparasitism, chasing the chicks of sooty terns and forcing them to disgorge food.

A conspicuous species, the cattle egret has attracted many common names. These mostly relate to its habit of following cattle and other large animals, and it is known variously as cow crane, cow bird or cow heron, or even elephant bird or rhinoceros egret. Its Arabic name, "abu qerdan", means "father of ticks", a name derived from the huge number of parasites such as avian ticks found in its breeding colonies. The Maasai people consider the presence of large numbers of cattle egrets as an indicator of impending drought and use it to decide on moving their cattle herds.

The cattle egret is a popular bird with cattle ranchers for its perceived role as a biocontrol of cattle parasites such as ticks and flies. A study in Australia found that cattle egrets reduced the number of flies that bothered cattle by pecking them directly off the skin. It was the benefit to stock that prompted ranchers and the Hawaiian Board of Agriculture and Forestry to release the species in Hawaii.

Not all interactions between humans and cattle egrets are beneficial. The cattle egret can be a safety hazard to aircraft due to its habit of feeding in large groups in the grassy verges of airports, and it has been implicated in the spread of animal infections such as heartwater, infectious bursal disease, and possibly Newcastle disease.



</doc>
<doc id="320401" url="https://en.wikipedia.org/wiki?curid=320401" title="Barton Fink">
Barton Fink

Barton Fink is a 1991 American period film written, produced, directed and edited by the Coen brothers. Set in 1941, it stars John Turturro in the title role as a young New York City playwright who is hired to write scripts for a film studio in Hollywood, and John Goodman as Charlie, the insurance salesman who lives next door at the run-down Hotel Earle.

The Coens wrote the screenplay for "Barton Fink" in three weeks while experiencing difficulty during the writing of "Miller's Crossing". They began filming the former soon after "Miller's Crossing" was finished. The film is influenced by works of several earlier directors, particularly Roman Polanski's "Repulsion" (1965) and "The Tenant" (1976).

"Barton Fink" had its premiere at the Cannes Film Festival in May 1991. In a rare sweep, it won the Palme d'Or, as well as awards for Best Director and Best Actor (Turturro). Although the film was a box office disappointment, only grossing $6 million against its $9 million budget, it received positive reviews and was nominated for 3 Academy Awards. Prominent themes of "Barton Fink" include the writing process; slavery and conditions of labor in creative industries; superficial distinctions between high culture and low culture; and the relationship of intellectuals with "the common man".

The diverse elements of the film have led it to defy efforts at genre classification, with the work being variously referred to as a film noir, a horror film, a "Künstlerroman", and a buddy film. It contains various literary allusions and religious overtones, as well as references to many real-life people and events – most notably the writers Clifford Odets and William Faulkner, of whom the characters of Barton Fink and W. P. Mayhew, respectively, are often seen as fictional representations. Several features of the film's narrative, particularly an image of a woman at the beach which recurs throughout, have sparked much commentary, with the Coens acknowledging some intentional symbolic elements while denying an attempt to communicate any single message in the film. Despite disagreement over certain details of the work, "Barton Fink" continues to be positively received, with screenwriter Charlie Kaufman among its admirers.

In 1941, Barton Fink's first Broadway play, "Bare Ruined Choirs", has achieved critical and popular success. His agent informs him that Capitol Pictures in Hollywood has offered him a thousand dollars per week to write film scripts. Barton hesitates, worried that moving to California would separate him from "the common man", his focus as a writer. He accepts the offer, however, and checks into the Hotel Earle, a large and unusually deserted building. His room is sparse and draped in subdued colors; its only decoration is a small painting of a woman on the beach, arm raised to block the sun.

In his first meeting with Capitol Pictures boss Jack Lipnick, Barton explains that he chose the Earle because he wants lodging that is (as Lipnick says) "less Hollywood". Lipnick promises that his only concern is Barton's writing ability and assigns his new employee to a wrestling film. Back in his room, however, Barton is unable to write. He is distracted by sounds coming from the room next door, and he phones the front desk to complain. His neighbor, Charlie Meadows, is the source of the noise and visits Barton to apologize, insisting on sharing some alcohol from a hip flask to make amends. As they talk, Barton proclaims his affection for "the common man", and Charlie describes his life as an insurance salesman. Later, Barton falls asleep, but is awakened by the incessant whine of a mosquito.

Still unable to proceed beyond the first lines of his script, Barton consults producer Ben Geisler for advice. Irritated, the frenetic Geisler takes him to lunch and orders him to consult another writer for assistance. While in the men's room, Barton meets the novelist William Preston (W.P.) "Bill" Mayhew, who is vomiting in the next stall. They briefly discuss movie writing and arrange a second meeting later in the day. When Barton arrives, Mayhew is drunk and yelling wildly. His secretary, Audrey Taylor, reschedules the meeting and confesses to Barton that she and Mayhew are in love. When they finally meet for lunch, Mayhew, Audrey, and Barton discuss writing and drinking. Before long, Mayhew argues with Audrey, slaps her, and wanders off, drunk. Rejecting Barton's offer of consolation, Audrey explains that she feels sorry for Mayhew since he is married to another woman who is "disturbed".
With one day left before his meeting with Lipnick to discuss the movie, Barton phones Audrey and begs her for assistance. She visits him at the Earle, and after she admits that she wrote most of Mayhew's scripts, they apparently have sex; Barton later confesses to Charlie they did so. When Barton awakens the next morning, he, again, hears the sound of the mosquito, finds it on Audrey's back, and slaps it dead. When Audrey does not respond, Barton turns her onto her side only to find that she has been violently murdered. He has no memory of the night's events. Horrified, he summons Charlie and asks for help. Charlie is repulsed but disposes of the body and orders Barton to avoid contacting the police. After a meeting with an unusually supportive Lipnick, Barton tries writing again and is interrupted by Charlie, who announces he is going to New York for several days. Charlie leaves a package with Barton and asks him to watch it.

Soon afterward, Barton is visited by two police detectives, who inform him that Charlie's real name is Karl "Madman" Mundt. Mundt is a serial killer wanted for several murders; after shooting his victims, they explain, he decapitates them and keeps the heads. Stunned, Barton returns to his room and examines the box. Placing it on his desk without opening it, he begins writing and produces the entire script in one sitting. After a night of celebratory dancing, Barton returns to find the detectives in his room, who, after handcuffing Barton to the bed, reveal they've found evidence of Mundt's latest murders. Each of the men notes how hot it is, before Charlie returns as the hotel is engulfed in flames. Running through the hallway, screaming "I'll show you the life of the mind!", Charlie shoots the policemen with a shotgun. As the hallway burns, Charlie speaks with Barton about their lives and the hotel, breaks the bed frame to which Barton is handcuffed (thus freeing him), then retires to his own room, saying as he goes that he paid a visit to Barton's parents and uncle in New York. Barton leaves the still-burning hotel, carrying the box and his script. Shortly thereafter he attempts to telephone his family, but there is no answer.

In a final meeting, a disappointed Lipnick, in uniform (as he attempts to secure an Army Reserve commission), angrily chastises Barton for writing "a fruity movie about suffering" then informs him that he is to remain in Los Angeles; although Barton will remain under contract, Capitol Pictures will not produce anything he writes so he can be ridiculed as a loser around the studio while Lipnick is in the war. Dazed, Barton wanders onto a beach, still carrying the package. He meets a woman who looks just like the one in the picture on his wall at the Earle, and she asks about the box. He tells her he does not know what it contains nor who owns it. She then assumes the pose from the picture.

In 1989, filmmakers Joel and Ethan Coen began writing the script for a film eventually released as "Miller's Crossing". The many threads of the story became complicated, and after four months they found themselves lost in the process. Although biographers and critics later referred to it as writer's block, the Coen brothers rejected this description. "It's not really the case that we were suffering from writer's block," Joel said in a 1991 interview, "but our working speed had slowed, and we were eager to get a certain distance from "Miller's Crossing"." They went from Los Angeles to New York and began work on a different project.
In three weeks, the Coens wrote a script with a title role written specifically for actor John Turturro, with whom they'd been working on "Miller's Crossing". The new film, "Barton Fink", was set in a large, seemingly abandoned hotel. This setting, which they named the "Hotel Earle", was a driving force behind the story and mood of the new project. While filming their 1984 film "Blood Simple" in Austin, Texas, the Coens had seen a hotel which made a significant impression: "We thought, 'Wow, Motel Hell.' You know, being condemned to live in the weirdest hotel in the world."

The writing process for "Barton Fink" was smooth, they said, suggesting that the relief of being away from "Miller's Crossing" may have been a catalyst. They also felt satisfied with the overall shape of the story, which helped them move quickly through the composition. "Certain films come entirely in one's head; we just sort of burped out "Barton Fink"." While writing, the Coens created a second leading role with another actor in mind: John Goodman, who had appeared in their 1987 comedy "Raising Arizona". His new character, Charlie, was Barton's next-door neighbor in the cavernous hotel. Even before writing, the Coens knew how the story would end, and wrote Charlie's final speech at the start of the writing process.

The script served its diversionary purpose, and the Coens put it aside: ""Barton Fink" sort of washed out our brain and we were able to go back and finish "Miller's Crossing"." Once production of the first film was finished, the Coens began to recruit staff to film "Barton Fink". Turturro looked forward to playing the lead role, and spent a month with the Coens in Los Angeles to coordinate views on the project: "I felt I could bring something more human to Barton. Joel and Ethan allowed me a certain contribution. I tried to go a little further than they expected."

As they designed detailed storyboards for "Barton Fink", the Coens began looking for a new cinematographer, since their associate Barry Sonnenfeld – who had filmed their first three films – was occupied with his own directorial debut, "The Addams Family". The Coens had been impressed with the work of English cinematographer Roger Deakins, particularly the interior scenes of the 1988 film "Stormy Monday". After screening other films he had worked on (including "Sid and Nancy" and "Pascali's Island"), they sent a script to Deakins and invited him to join the project. His agent advised against working with the Coens, but Deakins met with them at a café in Notting Hill and they soon began working together on "Barton Fink".

Filming began in June 1990 and took eight weeks (a third less time than required by "Miller's Crossing"), and the estimated final budget for the film was US$9 million. The Coens worked well with Deakins, and they easily translated their ideas for each scene onto film. "There was only one moment we surprised him," Joel Coen recalled later. An extended scene called for a tracking shot out of the bedroom and into a sink drain "plug hole" in the adjacent bathroom as a symbol of sexual intercourse. "The shot was a lot of fun and we had a great time working out how to do it," Joel said. "After that, every time we asked Roger to do something difficult, he would raise an eyebrow and say, 'Don't be having me track down any plug-holes now.'"

Three weeks of filming were spent in the Hotel Earle, a set created by art director Dennis Gassner. The film's climax required a huge spreading fire in the hotel's hallway, which the Coens originally planned to add digitally in post-production. When they decided to use real flames, however, the crew built a large alternative set in an abandoned aircraft hangar at Long Beach. A series of gas jets were installed behind the hallway, and the wallpaper was perforated for easy penetration. As Goodman ran through the hallway, a man on an overhead catwalk opened each jet, giving the impression of a fire racing ahead of Charlie. Each take required a rebuild of the apparatus, and a second hallway (sans fire) stood ready nearby for filming pick-up shots between takes. The final scene was shot near Zuma Beach, as was the image of a wave crashing against a rock.

The Coens edited the film themselves, as is their custom. "We prefer a hands-on approach," Joel explained in 1996, "rather than sitting next to someone and telling them what to cut." Because of rules for membership in film production guilds, they are required to use a pseudonym; "Roderick Jaynes" is credited with editing "Barton Fink". Only a few filmed scenes were removed from the final cut, including a transition scene to show Barton's movement from New York to Hollywood. (In the film, this is shown enigmatically with a wave crashing against a rock.) Several scenes representing work in Hollywood studios were also filmed, but edited out because they were "too conventional".

There is a sharp contrast between Fink's living quarters and the polished, pristine environs of Hollywood, especially the home of Jack Lipnick. The spooky, inexplicably empty feel of the Hotel Earle was central to the Coens' conception of the film. "We wanted an art deco stylization", Joel explained in a 1991 interview, "and a place that was falling into ruin after having seen better days". Barton's room is sparsely furnished with two large windows facing another building. The Coens later described the hotel as a "ghost ship floating adrift, where you notice signs of the presence of other passengers, without ever laying eyes on any". In the film, residents' shoes are an indication of this unseen presence; another rare sign of other inhabitants is the sound from adjacent rooms. Joel said: "You can imagine it peopled by failed commercial travelers, with pathetic sex lives, who cry alone in their rooms".

Heat and moisture are other important elements of the setting. The wallpaper in Barton's room peels and droops; Charlie experiences the same problem and guesses heat is the cause. The Coens used green and yellow colors liberally in designing the hotel "to suggest an aura of putrefaction".

The atmosphere of the hotel was meant to connect with the character of Charlie. As Joel explained: "Our intention, moreover, was that the hotel function as an exteriorization of the character played by John Goodman. The sweat drips off his forehead like the paper peels off the walls. At the end, when Goodman says that he is a prisoner of his own mental state, that this is like some kind of hell, it was necessary for the hotel to have already suggested something infernal." The peeling wallpaper and the paste which seeps through it also mirror Charlie's chronic ear infection and the resultant pus.

When Barton first arrives at the Hotel Earle, he is asked by the friendly bellhop Chet (Steve Buscemi) if he is "a trans or a res" – transient or resident. Barton explains that he isn't sure but will be staying "indefinitely". The dichotomy between permanent inhabitants and guests reappears several times, notably in the hotel's motto, "A day or a lifetime", which Barton notices on the room's stationery. This idea returns at the end of the film, when Charlie describes Barton as "a tourist with a typewriter". His ability to leave the Earle (while Charlie remains) is presented by critic Erica Rowell as evidence that Barton's story represents the process of writing itself. Barton, she says, represents an author who is able to leave a story, while characters like Charlie cannot.
In contrast, the offices of Capitol Pictures and Lipnick's house are pristine, lavishly decorated, and extremely comfortable. The company's rooms are bathed in sunlight, and Ben Geisler's office faces a lush array of flora. Barton meets Lipnick in one scene beside an enormous, spotless swimming pool. This echoes his position as studio head, as he explains: "...you can't always be honest, not with the sharks swimming around this town ... if I'd been totally honest, I wouldn't be within a mile of this pool – unless I was cleaning it." In his office, Lipnick showcases another trophy of his power: statues of Atlas, the Titan of Greek mythology who declared war on the gods of Mount Olympus and was severely punished.

Barton watches dailies from another wrestling film being made by Capitol Pictures; the date on the clapperboard is December 9, two days after the attack on Pearl Harbor. Later, when Barton celebrates the completed script by dancing at a USO show, he is surrounded by soldiers. In Lipnick's next appearance, he wears a colonel's uniform, which is really a costume from his company. Lipnick has not actually entered the military but declares himself ready to fight the "little yellow bastards". Originally, this historical moment just after the United States entered World War II was to have a significant impact on the Hotel Earle. As the Coens explained: "[W]e were thinking of a hotel where the lodgers were old people, the insane, the physically handicapped, because all the others had left for the war. The further the script was developed, the more this theme got left behind, but it had led us, in the beginning, to settle on that period."

The picture in Barton's room of a woman at the beach is a central focus for both the character and camera. He examines it frequently while at his desk, and after finding Audrey's corpse in his bed he goes to stand near it. The image is repeated at the end of the film, when he meets an identical-looking woman at an identical-looking beach, who strikes an identical pose. After complimenting her beauty, he asks her: "Are you in pictures?" She blushes and replies: "Don't be silly."

The Coens decided early in the writing process to include the picture as a key element in the room. "Our intention," Joel explained later, "was that the room would have very little decoration, that the walls would be bare and that the windows would offer no view of any particular interest. In fact, we wanted the only opening on the exterior world to be this picture. It seemed important to us to create a feeling of isolation."

Later in the film, Barton places into the frame a small picture of Charlie, dressed in a fine suit and holding a briefcase. The juxtaposition of his neighbor in the uniform of an insurance salesman and the escapist image of the woman on the beach leads to a confusion of reality and fantasy for Barton. Critic Michael Dunne notes: "[V]iewers can only wonder how 'real' Charlie is. ... In the film's final shot ... viewers must wonder how 'real' [the woman] is. The question leads to others: How real is Fink? Lipnick? Audrey? Mayhew? How real are films anyway?"

The picture's significance has been the subject of broad speculation. "Washington Post" reviewer Desson Howe said that despite its emotional impact, the final scene "feels more like a punchline for punchline's sake, a trumped-up coda". In her book-length analysis of the Coen brothers' films, Rowell suggests that Barton's fixation on the picture is ironic, considering its low culture status and his own pretensions toward high culture (speeches to the contrary notwithstanding). She further notes that the camera focuses on Barton himself as much as the picture while he gazes at it. At one point, the camera moves past Barton to fill the frame with the woman on the beach. This tension between objective and subjective points of view appears again at the end of the film, when Barton finds himself – in a sense – inside the picture.

Critic M. Keith Booker calls the final scene an "enigmatic comment on representation and the relationship between art and reality". He suggests that the identical images point to the absurdity of art which reflects life directly. The film transposes the woman directly from art to reality, prompting confusion in the viewer; Booker asserts that such a literal depiction therefore leads inevitably to uncertainty.

Many critics noted that "The Law of Non-Contradiction", an episode of the Coen-produced TV series "Fargo" based on their eponymous 1996 film, features a reference to the picture, as the episode's main character Gloria sits at the beach in shot and position similar to the picture's. The episode's themes were also compared to "Barton Fink"'s.

The Coens are known for making films that defy simple classification. Although they refer to their first film, "Blood Simple" (1984), as a relatively straightforward example of detective fiction, the Coens wrote their next script, "Raising Arizona" (1987), without trying to fit a particular genre. They decided to write a comedy but intentionally added dark elements to produce what Ethan calls "a pretty savage film". Their third film, "Miller's Crossing" (1990), reversed this order, mixing bits of comedy into a crime film. Yet it also subverts single-genre identity by using conventions from melodrama, love stories, and political satire.

This trend of mixing genres continued and intensified with "Barton Fink" (1991); the Coens insist the film "does not belong to any genre". Ethan has described it as "a buddy movie for the '90s". It contains elements of comedy, film noir, and horror, but other film categories are present. Actor Turturro referred to it as a coming of age story, while literature professor and film analyst R. Barton Palmer calls it a "Künstlerroman", highlighting the importance of the main character's evolution as a writer. Critic Donald Lyons describes the film as "a retro-surrealist vision".

Because it crosses genres, fragments the characters' experiences, and resists straightforward narrative resolution, "Barton Fink" is often considered an example of postmodernist film. In his book "Postmodern Hollywood", Booker says the film renders the past with an impressionist technique, not a precise accuracy. This technique, he notes, is "typical of postmodern film, which views the past not as the prehistory of the present but as a warehouse of images to be raided for material". In his analysis of the Coens' films, Palmer calls "Barton Fink" a "postmodern pastiche" which closely examines how past eras have represented themselves. He compares it to "The Hours" (2002), a film about Virginia Woolf and two women who read her work. He asserts that both films, far from rejecting the importance of the past, add to our understanding of it. He quotes literary theorist Linda Hutcheon: the kind of postmodernism exhibited in these films "does not deny the "existence" of the past; it does question whether we can ever "know" that past other than through its textualizing remains".

Certain elements in "Barton Fink" highlight the veneer of postmodernism: the writer is unable to resolve his modernist focus on high culture with the studio's desire to create formulaic high-profit films; the resulting collision produces a fractured story arc emblematic of postmodernism. The Coens' cinematic style is another example; when Barton and Audrey begin making love, the camera pans away to the bathroom, then moves toward the sink and down its drain. Rowell calls this a "postmodern update" of the notorious sexually suggestive image of a train entering a tunnel, used by director Alfred Hitchcock in his film "North by Northwest" (1959).

"Barton Fink" uses several stylistic conventions to accentuate the story's mood and give visual emphasis to particular themes. For example, the opening credits roll over the Hotel Earle's wallpaper, as the camera moves downward. This motion is repeated many times in the film, especially pursuant to Barton's claim that his job is to "plumb the depths" while writing. His first experiences in the Hotel Earle continue this trope; the bellhop Chet emerges from beneath the floor, carrying a shoe (which he has presumably been polishing) suggesting the real activity is underground. Although Barton's floor is presumably six floors above the lobby, the interior of the elevator is shown only while it is descending. These elements – combined with many dramatic pauses, surreal dialogue, and implied threats of violence – create an atmosphere of extreme tension. The Coens explained that "the whole movie was supposed to feel like impending doom or catastrophe. And we definitely wanted it to end with an apocalyptic feeling".

The style of "Barton Fink" is also evocative – and representative – of films of the 1930s and 1940s. As critic Michael Dunne points out: "Fink's heavy overcoat, his hat, his dark, drab suits come realistically out of the Thirties, but they come even more out of the films of the Thirties." The style of the Hotel Earle and atmosphere of various scenes also reflect the influence of pre-World War II filmmaking. Even Charlie's underwear matches that worn by his filmic hero Jack Oakie. At the same time, camera techniques used by the Coens in "Barton Fink" represent a combination of the classic with the original. Careful tracking shots and extreme close-ups distinguish the film as a product of the late 20th century.

From the start, the film moves continuously between Barton's subjective view of the world and one which is objective. After the opening credits roll, the camera pans down to Barton, watching the end of his play. Soon we see the audience from his point of view, cheering wildly for him. As he walks forward, he enters the shot and the viewer is returned to an objective point of view. This blurring of the subjective and objective returns in the final scene.

The shifting point of view coincides with the film's subject matter: filmmaking. The film begins with the end of a play, and the story explores the process of creation. This metanarrative approach is emphasized by the camera's focus in the first scene on Barton (who is mouthing the words spoken by actors offscreen), not on the play he is watching. As Rowell says: "[T]hough we listen to one scene, we watch another. ... The separation of sound and picture shows a crucial dichotomy between two 'views' of artifice: the world created by the protagonist (his play) and the world outside it (what goes into creating a performance)".

The film also employs numerous foreshadowing techniques. Signifying the probable contents of the package Charlie leaves with Barton, the word "head" appears 60 times in the original screenplay. In a grim nod to later events, Charlie describes his positive attitude toward his "job" of selling insurance: "Fire, theft and casualty are not things that only happen to other people."

Much has been written about the symbolic meanings of "Barton Fink". Rowell proposes that it is "a figurative head swelling of ideas that all lead back to the artist". The proximity of the sex scene to Audrey's murder prompts Lyons to insist: "Sex in "Barton Fink" is death". Others have suggested that the second half of the film is an extended dream sequence.

The Coens, however, have denied any intent to create a systematic unity from symbols in the film. "We never, ever go into our films with anything like that in mind", Joel said in a 1998 interview. "There's never anything approaching that kind of specific intellectual breakdown. It's always a bunch of instinctive things that feel right, for whatever reason". The Coens have noted their comfort with unresolved ambiguity. Ethan said in 1991: ""Barton Fink" does end up telling you what's going on to the extent that it's important to know ... What isn't crystal clear isn't intended to become crystal clear, and it's fine to leave it at that." Regarding fantasies and dream sequences, he said:

The homoerotic overtones of Barton's relationship with Charlie are not unintentional. Although one detective demands to know if they had "some sick sex thing", their intimacy is presented as anything but deviant, and cloaked in conventions of mainstream sexuality. Charlie's first friendly overture toward his neighbor, for example, comes in the form of a standard pick-up line: "I'd feel better about the damned inconvenience if you'd let me buy you a drink". The wrestling scene between Barton and Charlie is also cited as an example of homoerotic affection. "We consider that a sex scene", Joel Coen said in 2001.

Many of the sound effects in "Barton Fink" are laden with meaning. For example, Barton is summoned by a bell while dining in New York City; its sound is light and pleasant. By contrast, the eerie sustained bell of the Hotel Earle rings endlessly through the lobby, until Chet silences it. The nearby rooms of the hotel emit a constant chorus of guttural cries, moans, and assorted unidentifiable noises. These sounds coincide with Barton's confused mental state and punctuate Charlie's claim that "I hear everything that goes on in this dump". The applause in the first scene foreshadows the tension of Barton's move west, mixed as it is with the sound of an ocean wave crashing – an image which is shown onscreen soon thereafter.
Another symbolic sound is the hum of a mosquito. Although his producer insists that these parasites don't live in Los Angeles (since "mosquitos breed in swamps; this is a desert"), its distinctive sound is heard clearly as Barton watches a bug circle overhead in his hotel room. Later, he arrives at meetings with mosquito bites on his face. The insect also figures prominently into the revelation of Audrey's death; Barton slaps a mosquito feeding on her corpse and suddenly realizes she has been murdered. The high pitch of the mosquito's hum is echoed in the high strings used for the film's score. During filming, the Coens were contacted by an animal rights group who expressed concern about how mosquitoes would be treated.

The score was composed by Carter Burwell, who has worked with the Coens since their first film. Unlike earlier projects, however – the Irish folk tune used for "Miller's Crossing" and an American folk song as the basis for "Raising Arizona" – Burwell wrote the music for "Barton Fink" without a specific inspiration. The score was released in 1996 on a compact disc, combined with the score for the Coens' film "Fargo" (1996).

Several songs used in the film are laden with meaning. At one point Mayhew stumbles away from Barton and Audrey, drunk. As he wanders, he hollers the folk song "Old Black Joe" (1853). Composed by Stephen Foster, it tells the tale of an elderly slave preparing to join his friends in "a better land". Mayhew's rendition of the song coincides with his condition as an oppressed employee of Capitol Pictures, and it foreshadows Barton's own situation at the film's end.

When he finishes writing his script, Barton celebrates by dancing at a United Service Organizations (USO) show. The song used in this scene is a rendition of "Down South Camp Meeting", a swing tune. Its lyrics (unheard in the film) state: "Git ready (Sing) / Here they come! The choir's all set". These lines echo the title of Barton's play, "Bare Ruined Choirs". As the celebration erupts into a melee, the intensity of the music increases, and the camera zooms into the cavernous hollow of a trumpet. This sequence mirrors the camera's zoom into a sink drain just before Audrey is murdered earlier in the film.

Inspiration for the film came from several sources, and it contains allusions to many different people and events. For example, the title of Barton's play, "Bare Ruined Choirs", comes from line four of Sonnet 73 by William Shakespeare. The poem's focus on aging and death connects to the film's exploration of artistic difficulty.

Later, at one point in the picnic scene, as Mayhew wanders drunkenly away from Barton and Audrey, he calls out: "Silent upon a peak in Darien!" This is the last line from John Keats's sonnet "On First Looking into Chapman's Homer" (1816). The literary reference not only demonstrates the character's knowledge of classic texts, but the poem's reference to the Pacific Ocean matches Mayhew's announcement that he will "jus' walk on down to the Pacific, and from there I'll ... improvise".

Other academic allusions are presented elsewhere, often with extreme subtlety. For example, a brief shot of the title page in a Mayhew novel indicates the publishing house of "Swain and Pappas". This is likely a reference to Marshall Swain and George Pappas, philosophers whose work is concerned with themes explored in the film, including the limitations of knowledge and nature of being. One critic notes that Barton's fixation on the stain across the ceiling of his hotel room matches the protagonist's behavior in Flannery O'Connor's short story "The Enduring Chill". 

Critics have suggested that the film indirectly references the work of writers Dante Alighieri (through the use of "Divine Comedy" imagery) and Johann Wolfgang von Goethe (through the presence of Faustian bargains). Confounding bureaucratic structures and irrational characters, like those in the novels of Franz Kafka, appear in the film, but the Coens insist the connection was not intended. "I have not read him since college", admitted Joel in 1991, "when I devoured works like "The Metamorphosis". Others have mentioned "The Castle" and "In the Penal Colony", but I've never read them."

The character of Barton Fink is loosely based on Clifford Odets, a playwright from New York who in the 1930s joined the Group Theatre, a gathering of dramatists which included Harold Clurman, Cheryl Crawford, and Lee Strasberg. Their work emphasized social issues and employed Stanislavski's system of acting to recreate human experience as truthfully as possible. Several of Odets' plays were successfully performed on Broadway, including "Awake and Sing!" and "Waiting for Lefty" (both in 1935). When public tastes turned away from politically engaged theatre and toward the familial realism of Eugene O'Neill, Odets had difficulty producing successful work, so he moved to Hollywood and spent 20 years writing film scripts.
The Coens wrote with Odets in mind; they imagined Barton Fink as "a serious dramatist, honest, politically engaged, and rather naive". As Ethan said in 1991: "It seemed natural that he comes from Group Theater and the decade of the thirties." Like Odets, Barton believes that the theatre should celebrate the trials and triumphs of everyday people; like Barton, Odets was highly egotistical. In the film, a review of Barton's play "Bare Ruined Choirs" indicates that his characters face a "brute struggle for existence ... in the most squalid corners". This wording is similar to the comment of biographer Gerald Weales that Odets' characters "struggle for life amidst petty conditions". Lines of dialogue from Barton's work are reminiscent of Odets' play "Awake and Sing!". For example, one character declares: "I'm awake now, awake for the first time". Another says: "Take that ruined choir. Make it sing".

However, many important differences exist between the two men. Joel Coen said: "Both writers wrote the same kind of plays with proletarian heroes, but their personalities were quite different. Odets was much more of an extrovert; in fact he was quite sociable even in Hollywood, and this is not the case with Barton Fink!" Although he was frustrated by his declining popularity in New York, Odets was successful during his time in Hollywood. Several of his later plays were adapted – by him and others – into films. One of these, "The Big Knife" (1955), matches Barton's life much more than Odets'. In it, an actor becomes overwhelmed by the greed of a film studio which hires him and eventually commits suicide. Another similarity to Odets' work is Audrey's death, which mirrors a scene in "Deadline at Dawn" (1946), a film noir written by Odets. In that film, a character awakens to find that the woman he bedded the night before has been inexplicably murdered.

Odets chronicled his difficult transition from Broadway to Hollywood in his diary, published as "The Time Is Ripe: The 1940 Journal of Clifford Odets" (1988). The diary explored Odets' philosophical deliberations about writing and romance. He often invited women into his apartment, and he describes many of his affairs in the diary. These experiences, like the extended speeches about writing, are echoed in "Barton Fink" when Audrey visits and seduces Barton at the Hotel Earle. Turturro was the only member of the production who read Odets' "Journal", however, and the Coen brothers urge audiences to "take account of the difference between the character and the man".

Some similarities exist between the character of W.P. Mayhew and novelist William Faulkner. Like Mayhew, Faulkner became known as a preeminent writer of Southern literature and later worked in the film business. Like Faulkner, Mayhew is a heavy drinker and speaks contemptuously about Hollywood. Faulkner's name appeared in the Hollywood 1940s history book "City of Nets", which the Coens read while creating "Barton Fink". Ethan explained in 1998: "I read this story in passing that Faulkner was assigned to write a wrestling picture... That was part of what got us going on the whole "Barton Fink" thing." Faulkner worked on a wrestling film called "Flesh" (1932), which starred Wallace Beery, the actor for whom Barton is writing. The focus on wrestling was fortuitous for the Coens, as they participated in the sport in high school.

However, the Coens disavow a significant connection between Faulkner and Mayhew, calling the similarities "superficial". "As far as the details of the character are concerned," Ethan said in 1991, "Mayhew is very different from Faulkner, whose experiences in Hollywood were not the same at all." Unlike Mayhew's inability to write due to drink and personal problems, Faulkner continued to pen novels after working in the film business, winning several awards for fiction completed during and after his time in Hollywood.

Lerner's Academy Award-nominated character of studio mogul Jack Lipnick is a composite of several Hollywood producers, including Harry Cohn, Louis B. Mayer, and Jack L. Warner – three of the most powerful men in the film industry at the time in which "Barton Fink" is set. Like Mayer, Lipnick is originally from the Belarusian capital city Minsk. When World War II broke out, Warner pressed for a position in the military and ordered his wardrobe department to create a military uniform for him; Lipnick does the same in his final scene. Warner once referred to writers as "schmucks with Underwoods", leading to Barton's use in the film of an Underwood typewriter.

At the same time, the Coens stress that the labyrinth of deception and difficulty Barton endures is not based on their own experience. Although Joel has said that artists tend to "meet up with Philistines", he added: ""Barton Fink" is quite far from our own experience. Our professional life in Hollywood has been especially easy, and this is no doubt extraordinary and unfair". Ethan has suggested that Lipnick – like the men on which he is based – is in some ways a product of his time. "I don't know that that kind of character exists anymore. Hollywood is a little more bland and corporate than that now".

The Coens have acknowledged several cinematic inspirations for "Barton Fink". Chief among these are three films by Polish-French filmmaker Roman Polanski: "Repulsion" (1965), "Cul-de-Sac" (1966), and "The Tenant" (1976). These films employ a mood of psychological uncertainty coupled with eerie environments that compound the mental instability of the characters. Barton's isolation in his room at the Hotel Earle is frequently compared to that of Trelkovsky in his apartment in "The Tenant". Ethan said regarding the genre of "Barton Fink": "[I]t is kind of a Polanski movie. It is closer to that than anything else." By coincidence, Polanski was the head of the jury at the Cannes Film Festival in 1991, where "Barton Fink" premiered. This created an awkward situation. "Obviously", Joel Coen said later, "we have been influenced by his films, but at this time we were very hesitant to speak to him about it because we did not want to give the impression we were sucking up".

Other works cited as influences for "Barton Fink" include the film "The Shining" (1980), produced and directed by Stanley Kubrick, and the comedy "Sullivan's Travels" (1941), written and directed by Preston Sturges. Set in an empty hotel, Kubrick's film concerns a writer unable to proceed with his latest work. Although the Coens approve of comparisons to "The Shining", Joel suggests that Kubrick's film "belongs in a more global sense to the horror film genre". "Sullivan's Travels", released the year in which "Barton Fink" is set, follows successful director John Sullivan, who decides to create a film of deep social import – not unlike Barton's desire to create entertainment for "the common man". Sullivan eventually decides that comedic entertainment is a key role for filmmakers, similar to Jack Lipnick's assertion at the end of "Barton Fink" that "the audience wants to see action, adventure".

Additional allusions to films and film history abound in "Barton Fink". At one point a character discusses "Victor Soderberg"; the name is a reference to Victor Sjöström, a Swedish director who worked in Hollywood under the name Victor Seastrom. Charlie's line about how his troubles "don't amount to a hill of beans" is a probable homage to the film "Casablanca" (1942). Another similarity is that of "Barton Fink"'s beach scene to the final moment in "La Dolce Vita" (1960), wherein a young woman's final line of dialogue is obliterated by the noise of the ocean. The unsettling emptiness of the Hotel Earle has also been compared to the living spaces in "Key Largo" (1948) and "Sunset Boulevard" (1950).

Two of the film's central themes – the culture of entertainment production and the writing process – are intertwined and relate specifically to the self-referential nature of the work (as well as the work within the work). It is a film about a man who writes a film based on a play, and at the centre of Barton's entire opus is Barton himself. The dialogue in his play "Bare Ruined Choirs" (also the first lines of the film, some of which are repeated at the end of the film as lines in Barton's screenplay "The Burlyman") give us a glimpse into Barton's self-descriptive art. The mother in the play is named "Lil", which is later revealed to be the name of Barton's own mother. In the play, "The Kid" (a representation of Barton himself) refers to his home "six flights up" – the same floor where Barton resides at the Hotel Earle. Moreover, the characters' writing processes in "Barton Fink" reflect important differences between the culture of entertainment production in New York's Broadway district and Hollywood.

Although Barton speaks frequently about his desire to help create "a new, living theater, of and about and for the common man", he does not recognize that such a theater has already been created: the films. In fact, he disdains this authentically popular form. On the other hand, the world of Broadway theatre in "Barton Fink" is a place of high culture, where the creator believes most fully that his work embodies his own values. Although he pretends to disdain his own success, Barton believes he has achieved a great victory with "Bare Ruined Choirs". He seeks praise; when his agent Garland asks if he has seen the glowing review in the "Herald", Barton says "No", even though his producer had just read it to him. Barton feels close to the theatre, confident that it can help him create work that honors "the common man". The men and women who funded the production – "those people", as Barton calls them – demonstrate that Broadway is just as concerned with profit as Hollywood; but its intimacy and smaller scale allow the author to feel that his work has real value.
Barton does not believe Hollywood offers the same opportunity. In the film, Los Angeles is a world of false fronts and phony people. This is evident in an early line of the screenplay (filmed, but not included in the theatrical release); while informing Barton of Capitol Pictures' offer, his agent tells him: "I'm only asking that your decision be informed by a little realism – if I can use that word and Hollywood in the same breath". Later, as Barton tries to explain why he is staying at the Earle, studio head Jack Lipnick finishes his sentence, recognizing that Barton wants a place that is "less Hollywood". The assumption is that Hollywood is fake and the Earle is genuine. Producer Ben Geisler takes Barton to lunch at a restaurant featuring a mural of the "New York Cafe", a sign of Hollywood's effort to replicate the authenticity of the East Coast of the United States. Lipnick's initial overwhelming exuberance is also a façade. Although he begins by telling Barton: "The writer is king here at Capitol Pictures", in the penultimate scene he insists: "If your opinion mattered, then I guess I'd resign and let "you" run the studio. It doesn't, and you won't, and the lunatics are not going to run "this" particular asylum".

Deception in "Barton Fink" is emblematic of Hollywood's focus on low culture, its relentless desire to efficiently produce formulaic entertainment for the sole purpose of economic gain. Capitol Pictures assigns Barton to write a wrestling picture with superstar Wallace Beery in the leading role. Although Lipnick declares otherwise, Geisler assures Barton that "it's just a B picture". Audrey tries to help the struggling writer by telling him: "Look, it's really just a formula. You don't have to type your soul into it". This formula is made clear by Lipnick, who asks Barton in their first meeting whether the main character should have a love interest or take care of an orphaned child. Barton shows his iconoclasm by answering: "Both, maybe?" In the end, his inability to conform to the studio's norms destroys Barton.

A similar depiction of Hollywood appears in Nathanael West's novel "The Day of the Locust" (1939), which many critics see as an important precursor to "Barton Fink". Set in a run-down apartment complex, the book describes a painter reduced to decorating film sets. It portrays Hollywood as crass and exploitative, devouring talented individuals in its neverending quest for profit. In both West's novel and "Barton Fink", protagonists suffer under the oppressive industrial machine of the film studio.

The film contains further self-referential material, as a film about a writer having difficulty writing (written by the Coen brothers while they were having difficulty writing "Miller's Crossing"). Barton is trapped between his own desire to create meaningful art and Capitol Pictures' need to use its standard conventions to earn profits. Audrey's advice about following the formula would have saved Barton, but he does not heed it. However, when he puts the mysterious package on his writing desk (which might have contained her head), she might have been helping him posthumously, in other ways. The film itself toys with standard screenplay formulas. As with Mayhew's scripts, "Barton Fink" contains a "good wrestler" (Barton, it seems) and a "bad wrestler" (Charlie) who "confront" each other at the end. But in typical Coen fashion, the lines of good and evil are blurred, and the supposed hero in fact reveals himself to be deaf to the pleadings of his "common man" neighbor. By blurring the lines between reality and surreal experience, the film subverts the "simple morality tales" and "road maps" offered to Barton as easy paths for the writer to follow.

However, the filmmakers point out that "Barton Fink" is not meant to represent the Coens themselves. "Our life in Hollywood has been particularly easy", they once said. "The film isn't a personal comment". Still, universal themes of the creative process are explored throughout the film. During the picnic scene, for example, Mayhew asks Barton: "Ain't writin' peace?" Barton pauses, then says: "No, I've always found that writing comes from a great inner pain." Such exchanges led critic William Rodney Allen to call "Barton Fink" "an autobiography of the life of the Coens' minds, not of literal fact". Allen's comment is itself a reference to the phrase "life of the mind", used repeatedly in the film in wildly differing contexts.

Several of the film's elements, including the setting at the start of World War II, have led some critics to highlight parallels to the rise of fascism at the time. For example, the detectives who visit Barton at the Hotel Earle are named "Mastrionatti" and "Deutsch" – Italian and German names, evocative of the regimes of Benito Mussolini and Adolf Hitler. Their contempt for Barton is clear: "Fink. That's a Jewish name, isn't it? ... I didn't think this dump was restricted." Later, just before killing his last victim, Charlie says: "Heil Hitler". Jack Lipnick hails originally from the Belarusian capital city Minsk, which was occupied from 1941 by Nazi Germany, following Operation Barbarossa.

"[I]t's not forcing the issue to suggest that the Holocaust hovers over "Barton Fink"", writes biographer Ronald Bergan. Others see a more specific message in the film, particularly Barton's obliviousness to Charlie's homicidal tendencies. Critic Roger Ebert wrote in his 1991 review that the Coens intended to create an allegory for the rise of Nazism. "They paint Fink as an ineffectual and impotent left-wing intellectual, who sells out while telling himself he is doing the right thing, who thinks he understands the 'common man' but does not understand that, for many common men, fascism had a seductive appeal". However, he goes on to say: "It would be a mistake to insist too much on this aspect of the movie..."

Other critics are more demanding. M. Keith Booker writes: For their part, the Coens deny any intention of presenting an allegorical message. They chose the detectives' names deliberately, but "we just wanted them to be representative of the Axis world powers at the time. It just seemed kind of amusing. It's a tease. All that stuff with Charlie – the "Heil Hitler!" business – sure, it's all there, but it's kind of a tease." In 2001, Joel responded to a question about critics who provide extended comprehensive analysis: "That's how they've been trained to watch movies. In "Barton Fink", we may have encouraged it – like teasing animals at the zoo. The movie is intentionally ambiguous in ways they may not be used to seeing".

Although subdued in dialogue and imagery, the theme of slavery appears several times in the film. Mayhew's crooning of the parlor song "Old Black Joe" depicts him as enslaved to the film studio, not unlike the song's narrator who pines for "my friends from the cotton fields away". One brief shot of the door to Mayhew's workspace shows the title of the film he is supposedly writing: "Slave Ship". This is a reference to a 1937 movie written by Mayhew's inspiration William Faulkner and starring Wallace Beery, for whom Barton is composing a script in the film.

The symbol of the slave ship is furthered by specific set designs, including the round window in Ben Geisler's office which resembles a porthole, as well as the walkway leading to Mayhew's bungalow, which resembles the boarding ramp of a watercraft. Several lines of dialogue make clear by the film's end that Barton has become a slave to the studio: "[T]he contents of your head", Lipnick's assistant tells him, "are the property of Capitol Pictures". After Barton turns in his script, Lipnick delivers an even more brutal punishment: "Anything you write will be the property of Capitol Pictures. And Capitol Pictures will not produce anything you write". This contempt and control is representative of the opinions expressed by many writers in Hollywood at the time. As Arthur Miller said in his review of "Barton Fink": "The only thing about Hollywood that I am sure of is that its mastication of writers can never be too wildly exaggerated".

During the first third of the film, Barton speaks constantly of his desire to write work which centers on and appeals to "the common man". In one speech he declares: "The hopes and dreams of the common man are as noble as those of any king. It's the stuff of life – why shouldn't it be the stuff of theater? Goddamnit, why should that be a hard pill to swallow? Don't call it "new" theater, Charlie; call it "real" theater. Call it "our" theater." Yet, despite his rhetoric, Barton is totally unable (or unwilling) to appreciate the humanity of the "common man" living next door to him. Later in the film, Charlie explains that he has brought various horrors upon him because "you "don't listen"!" In his first conversation with Charlie, Barton constantly interrupts Charlie just as he is saying "I could tell you some stories-", demonstrating that despite his fine words he really is not interested in Charlie's experiences; in another scene, Barton symbolically demonstrates his deafness to the world by stuffing his ears with cotton to block the sound of his ringing telephone.

Barton's position as screenwriter is of particular consequence to his relationship with "the common man". By refusing to listen to his neighbor, Barton cannot validate Charlie's existence in his writing – with disastrous results. Not only is Charlie stuck in a job which demeans him, but he cannot (at least in Barton's case) have his story told. More centrally, the film traces the evolution of Barton's understanding of "the common man": At first he is an abstraction to be lauded from a vague distance. Then he becomes a complex individual with fears and desires. Finally he shows himself to be a powerful individual in his own right, capable of extreme forms of destruction and therefore feared and/or respected.

The complexity of "the common man" is also explored through the oft-mentioned "life of the mind". While expounding on his duty as a writer, Barton drones: "I gotta tell you, the life of the mind ... There's no road map for that territory ... and exploring it can be painful. The kind of pain most people don't know anything about." Barton assumes that he is privy to thoughtful creative considerations while Charlie is not. This delusion shares the film's climax, as Charlie runs through the hallway of the Earle, shooting the detectives with a shotgun and screaming: ""Look upon me! I'll show you the life of the mind!!"" Charlie's "life of the mind" is no less complex than Barton's; in fact, some critics consider it more so.

Charlie's understanding of the world is depicted as omniscient, as when he asks Barton about "the two lovebirds next door", despite the fact that they are several doors away. When Barton asks how he knows about them, Charlie responds: "Seems like I hear everything that goes on in this dump. Pipes or somethin'." His total awareness of the events at the Earle demonstrate the kind of understanding needed to show real empathy, as described by Audrey. This theme returns when Charlie explains in his final scene: "Most guys I just feel sorry for. Yeah. It tears me up inside, to think about what they're going through. How trapped they are. I understand it. I feel for 'em. So I try to help them out."

Themes of religious salvation and allusions to the Bible appear only briefly in "Barton Fink", but their presence pervades the story. While Barton is experiencing his most desperate moment of confusion and despair, he opens the drawer of his desk and finds a Gideon Bible. He opens it "randomly" to , and reads from it: "And the king, Nebuchadnezzar, answered and said to the Chaldeans, I recall not my dream; if ye will not make known unto me my dream, and its interpretation, ye shall be cut in pieces, and of your tents shall be made a dunghill." This passage reflects Barton's inability to make sense of his own experiences (wherein Audrey has been "cut in pieces"), as well as the "hopes and dreams" of "the common man". "Nebuchadnezzar" is also the title of a novel that Mayhew gives to Barton as a "little entertainment" to "divert you in your sojourn among the Philistines".

Mayhew alludes to "the story of Solomon's mammy", a reference to Bathsheba, who gave birth to Solomon after her lover David had her husband Uriah killed. Although Audrey cuts Mayhew off by praising his book (which Audrey herself may have written), the reference foreshadows the love triangle which evolves among the three characters of "Barton Fink". Rowell points out that Mayhew is murdered (presumably by Charlie) soon after Barton and Audrey have sex. Another Biblical reference comes when Barton flips to the front of the Bible in his desk drawer and sees his own words transposed into the Book of Genesis. This is seen as a representation of his hubris as a self-conceived omnipotent master of creation, or alternatively, as a playful juxtaposition demonstrating Barton's hallucinatory state of mind.

"Barton Fink" premiered in May 1991 at the Cannes Film Festival. Beating competition which included Jacques Rivette's "La Belle Noiseuse", Spike Lee's "Jungle Fever", and David Mamet's "Homicide", the Coen brothers' film won three awards: Best Director, Best Actor, and the top prize "Palme d'Or". This sweep of awards in major categories at Cannes was extremely rare, and some critics felt the jury was too generous to the exclusion of other worthy entries. Worried that the triple victory could set a precedent which would undervalue other films, Cannes decided after the 1991 festival to limit each movie to a maximum of two awards.

"Barton Fink" was also nominated for three Academy Awards: Best Actor in a Supporting Role (Lerner), Best Art Direction (Dennis Gassner, Nancy Haigh), and Best Costume Design (Richard Hornung). Lerner lost to Jack Palance for the latter's role in "City Slickers"; the awards for Art Direction (Gassner and Haigh won by beating themselves) and Costume Design went to "Bugsy".

The film was also nominated for the prestigious Grand Prix of the Belgian Syndicate of Cinema Critics.

"Barton Fink" received positive reviews from critics. On Rotten Tomatoes, the film has a 90% "Certified Fresh" rating, based on 58 reviews, with an average rating of 7.7/10. The site's critical consensus reads: "Twisty and unsettling, the Coen brothers' satirical tale of a 1940s playwright struggling with writer's block is packed with their trademark sense of humor and terrific performances from its cast." On Metacritic, the film has a score of 69 out of 100, based on 19 critics, indicating "generally favorable reviews".

"The Washington Post" critic Rita Kempley described "Barton Fink" as "certainly one of the year's best and most intriguing films". "The New York Times" critic Vincent Canby called it "an unqualified winner" and "a fine dark comedy of flamboyant style and immense though seemingly effortless technique". Critic Jim Emerson called "Barton Fink" "the Coen brothers' most deliciously, provocatively indescribable picture yet".

Some critics disliked the abstruse plot and deliberately enigmatic ending. "Chicago Reader" critic Jonathan Rosenbaum warned of the Coens' "adolescent smarminess and comic-book cynicism", and described "Barton Fink" as "a midnight-movie gross-out in Sunday-afternoon art-house clothing".

In a 1994 interview, Joel dismissed criticism of unclear elements in their films: "People have a problem dealing with the fact that our movies are not straight-ahead. They would prefer that the last half of "Barton Fink" just be about a screenwriter's writing-block problems and how they get resolved in the real world". Talk show host Larry King expressed approval of the movie, despite its uncertain conclusion. He wrote in "USA Today": "The ending is something I'm still thinking about and if they accomplished that, I guess it worked." In a 2016 interview, screenwriter Charlie Kaufman said after being asked which film he would want with him on a deserted island, "A movie I really love is "Barton Fink". I don't know if that’s the movie I'd take to a desert island, but I feel like there's so much in there, you could watch it again and again. That's important to me, especially if that was the only movie I'd have with me for the rest of my life."

"Barton Fink" was ranked by Greg Cwik of IndieWire as the Coens' fifth best film. It was voted the 11th best film of the 1990s in a poll of "The A.V. Club" contributors, and was described as "one of [the Coens'] most profound, and painful" works.

The film opened in the United States on eleven screens on August 23, 1991, and earned $268,561 during its opening weekend. During its theatrical release, "Barton Fink" grossed $6,153,939 in the United States. That the film failed to recoup the expenses of production amused film producer Joel Silver, with whom the Coens would later work in "The Hudsucker Proxy" (1994): "I don't think it made $5 million, and it cost $9 million to make. [The Coen brothers have] a reputation for being weird, off-center, inaccessible."

The film was released in VHS home video format on March 5, 1992, and a DVD edition was made available on May 20, 2003. The DVD contains a gallery of still photos, theatrical trailers, and eight deleted scenes. The film is also available on Blu-ray Disc, in the UK, in a region-free format that will work in any Blu-ray player.

The Coen brothers have expressed interest in making a sequel to "Barton Fink" called "Old Fink", which would take place in the 1960s. "It's the summer of love and [Fink is] teaching at Berkeley. He ratted on a lot of his friends to the House Un-American Activities Committee", said Joel Coen. The brothers have stated that they have had talks with John Turturro about reprising his role as Fink, but they were waiting "until he was actually old enough to play the part".

Speaking to "The A.V. Club" in June 2011, Turturro suggested the sequel would be set in the 1970s, and Fink would be a hippie with a large Jewfro. He said "you'll have to wait another 10 years for that, at least".




</doc>
<doc id="321401" url="https://en.wikipedia.org/wiki?curid=321401" title="Pigeon guillemot">
Pigeon guillemot

The pigeon guillemot ("Cepphus columba") is a species of bird in the auk family, Alcidae. One of three species in the genus "Cepphus", it is most closely related to the spectacled guillemot. There are five subspecies of the pigeon guillemot; all subspecies, when in , are dark brown with a black iridescent sheen, with a distinctive wing patch broken by a brown-black wedge. Its has a mottled grey and black and white . The long bill is black, as are the claws. The legs, feet, and inside of the mouth are red. It closely resembles the black guillemot, which is slightly smaller and lacks the dark wing wedge present in the pigeon guillemot. Combined, the two form a superspecies.

This seabird is found on North Pacific coastal waters, from Siberia through California to Alaska. The pigeon guillemot breeds and sometimes roosts on rocky shores, cliffs, and islands close to shallow water. In the winter, some birds move slightly south in the northern-most part of their range in response to advancing ice and migrate slightly north in the southern part of their range, generally preferring more sheltered areas.

This species feeds on small fish and marine invertebrates, mostly near the sea floor, that it catches by pursuit diving. Pigeon guillemots are monogamous breeders, nesting in small colonies close to the shore. They defend small territories around a nesting cavity, in which they lay one or two eggs. Both parents incubate the eggs and feed the chicks. After leaving the nest the young bird is completely independent of its parents. Several birds and other animals prey on the eggs and chicks.

The pigeon guillemot is considered to be a least concern species by the International Union for Conservation of Nature. This is due to its large, stable population and wide range. Threats to this bird include climate change, introduced mammalian predators, and oil spills.

The pigeon guillemot is one of three species of auk in the genus "Cepphus", the other two being the black guillemot of the Atlantic Ocean and the spectacled guillemot from the Eastern Pacific. It was described in 1811 by Peter Simon Pallas in the second volume of his "Zoographia Rosso-Asiatica". A 1996 study looking at the mitochondrial DNA of the auk family found that the genus "Cepphus" is most closely related to the murrelets from the genus "Synthliboramphus". An alternative arrangement, proposed in 2001 using genetic and morphological comparisons, found them as a sister clade to the murres, razorbill, little auk and great auk. Within the genus, the pigeon guillemot and spectacled guillemot are sister species, and the black guillemot is basal within the genus. The pigeon guillemot and the black guillemot form a superspecies.

There are five recognised subspecies of the pigeon guillemot:


In the binomial name, the genus, "Cepphus", is derived from the Greek "kepphos", referring to an unknown pale waterbird mentioned by Aristotle among other classical writers, later variously identified as types of seabirds, including gulls, auks and gannets. The specific epithet, "columba", is derived both from the Icelandic "klumba", meaning "auk", and the Latin "columba", meaning "pigeon". Pallas noted in his description of this species that the common name for the related black guillemot was Greenland dove. "Snowi" is dedicated to Captain Henry James Snow, a British seaman and hunter. The name of the subspecies "kaiurka" is derived from the Russian "kachurka", meaning "petrel". "Adiantus" is derived from the Greek "adiantos", "unwetted". The trinomial epithet of the subspecies "C. c. eureka" is from the motto of the state of California, which is derived from the Greek "heurēka", meaning "I have found it".

The pigeon guillemot is a medium-sized auk, in length and weighing . Both sexes are alike in appearance and mass, except for Californian birds where females were found to have larger bills than males. The summer or of the adult is mostly dark brown with a black sheen, with a white wing patch broken by a brown-black wedge. In winter, the are iridescent black, often with black fringes giving a scalloped appearance, and the and rump are white. The forehead, , , eye line and ear coverts are black with white tips, sometimes the tips are narrow and the head looks black. In all plumages, the are plain and dark. Adults moult into their winter or between August and October, taking around a month to complete and leaving the bird unable to fly for around four weeks. Birds moult into their breeding plumage between January and March. The legs and feet are red, with black claws. The iris is brown and the eye is surrounded by a thin unbroken white eye-ring. The bill is long and black and the inside of the mouth is red.
The juvenile pigeon guillemot resembles a winter adult but has underpart feathers tipped in brown, giving the appearance of barring, more brown feathers in the upperparts and its wing patch is smaller. Its legs are a grey-brown in color. It loses the brown underpart feathers after its first moult two to three months after fledging. Its moult to its first summer plumage is later than adults, happening between March and May, and first summer birds lack the glossy sheen of adults.

The differences between the subspecies are based on body measurements such as the and wing length. These are larger in southern subspecies and smaller further north. The amount of white on the outer and increases in northern subspecies, except for "Cepphus columba snowi", where the white is reduced or entirely absent.

The pigeon guillemot walks well and habitually has an upright posture. When sitting it frequently rests on its tarsi. The wings of the pigeon guillemot are shorter and rounder than other auks, reflecting greater adaptation towards diving than flying. It has difficulty taking off in calm conditions without a runway, but once in the air it is faster than the black guillemot, having been recorded at , about faster than the black guillemot. In the water it is a strong swimmer on the surface using its feet. When diving, propulsion is provided both by the wings, which beat at a rate of 2.1/s, but unusually for auks also by the feet. Pigeon guillemots have been recorded travelling horizontally on dives.

The pigeon guillemot is similar to the related black guillemot, but can be distinguished by its larger size, and in the breeding season by its dusky-grey underwing and the dark brown wedge on the white wing patch.

The pigeon guillemot ranges across the Northern Pacific, from the Kuril Islands and the Kamchatka Peninsula in Siberia to coasts in western North America from Alaska to California. This bird's wintering range is more restricted than its breeding season range, the pigeon guillemot usually wintering at sea or on the coasts, from the Pribilof and Aleutian Islands to Hokkaido and southern California. In Alaska, some migrate south because of advancing sea-ice, although others remain in ice leads or ice holes some distance from the edge of the ice sheet. Further south, birds banded in the Farallon Islands in central California have been recorded moving north, as far as Oregon and even British Columbia. It generally is philopatric, meaning it returns to the colony where it hatched to breed, but it sometimes moves long distances after fledging before settling, for example a chick ringed in the Farallones was recorded breeding in British Columbia.

This bird's breeding habitats are rocky shores, cliffs, and islands close to shallow water less than deep. It is flexible about its breeding site location, the important factor being protection from predators, and it is more commonly found breeding on offshore islands than coastal sea cliffs. In the winter it forages along rocky coasts, often in sheltered coves. Sandy-bottomed water is avoided, presumably because this does not provide the right habitat to feed in. It occasionally can be found further offshore, as far as the continental shelf break. In the Bering Sea and Alaska, it feeds in openings in ice sheets.

Pigeon guillemots are generally diurnal, but have been recorded feeding before dawn and after sunset. They typically sleep in loose groups in sheltered waters or on shore close to water. They typically rest spaced apart, but mated pairs rest close together. Bathing and preening can also happen on shore or at sea.

The pigeon guillemot usually lays its eggs in rocky cavities near water, but it often nests in any available cavity, including caves, disused burrows of other seabirds, and even old bomb casings. It is noted that pigeon guillemots do not inhabit nests with gull eggs, specifically those of the western gull. This guillemot usually retains its nest site, meaning that nest sites are generally used multiple times, although it does not display this behaviour if its mate does not return to breed. The nests are found at a wide range of heights, from about above sea-level. Nesting sites are defended by established pairs, as is a small territory around the nest entrance of between . Both sexes defend the nesting site, although most defence is done by the male.

Foreign eggs in this guillemot's nest are generally removed. Nest competition with Cassin's auklet is occasional, the pigeon guillemot almost always just removing the eggs, and rarely pithing before removal. On the other hand larger auk species, tufted puffins and rhinoceros auklets, have been reported evicting pigeon guillemots from their nesting crevices.

This guillemot nests at a variety of densities, ranging from a single individual to dense colonies. The nesting density is generally not affected by predation, although on a very local scale, nesting closer to neighbors has a slight advantage. Colonies are attended during the day and, except for birds incubating or brooding, adults do not remain in the colony at night. Birds usually arrive in the colony in the morning, with counts decreasing after early afternoon, when high tide is. Colony attendance is affected by the tide, more appearing when the tide is higher and less when the tide is lower, probably because the prey this bird feeds on is more accessible during low tide, thus more birds are away from the colony. The counts vary the most before laying, while they are relatively stable during incubation and egg laying.

Pigeon guillemots form long-term pair bonds, the pairs usually reuniting each year, although occasionally pairs divorce. The formation of the pair bond is poorly understood. It is thought that form of play known as "water games", which involves chasing of birds on and under the water at sea, and duet-trilling may have a function in maintaining the pair bond or act as a prelude to copulation. The red colour of the mouth may also be a sexual signal.

Usually arriving at its breeding range 40 to 50 days before laying starts, the pigeon guillemot breeds from late April to September. During this time, it generally lays a clutch of one or two eggs. The eggs have grey and brown blotches near the larger end of the egg and range in colour from creamy to pale blue-green. They measure on average, but become longer when laid later in the breeding season. Incubated by both sexes, the eggs usually hatch after 26 to 32 days. The chick is continuously by both parents for three days, and then at intervals for another two to four days, after which it is able to control its own body temperature. Both parents are responsible for feeding the chicks, and bring single fish held in the bill throughout the day, but most frequently in the morning.
The chicks usually fledge 34 to 42 days after hatching, although the time taken to fledge has been known to take anywhere from 29 to 54 days. Chicks fledge by leaving the colony and flying to sea, after which they are independent of their parents and receive no post-fledging care. After this, the adult also leaves the colony. Young birds do not breed until at least three years after fledging, with most first breeding at four years of age. While they may not return to breed, two or three year old birds may start attending the breeding colony before they reach sexual maturity, arriving in the colony after the breeding birds. Pigeon guillemots that reach adulthood have an average life-expectancy of 4.5 years, and the oldest recorded individual lived for 14 years.

The pigeon guillemot is a very vocal bird, particularly during the breeding season, and makes several calls, some of which are paired with displays, to communicate with others of its kind. One such display call pairing is the conspicuous hunch-whistle, where the tail is slightly raised, the wings held slightly out and the head thrown back 45-90° while whistling, before snapping back to horizontal. The function of this call is to advertise ownership of a territory. Another call, the trill, denotes ownership over larger distances. Trills can be performed singly or as duets between pairs; if performed as a duet then the call also functions to help reinforce pair bond. Trills are usually given from a resting position, except for the trill-waggle, which has the bird raising its tail, opening its wings and ruffling the feathers of its neck and head, followed by a waggling of its outstretched neck and head. This display is antagonistic in a context where pigeon guillemots are in a group and often is the precursor to an attack. Low whistles are made by unpaired males attempting to attract a mate, and are deeper than hunch-whistles and involve less movement of the head. Other calls made include seeps and cheeps made between mates and screams made in the presence of predators.

The pigeon guillemot forages by itself or in small groups, diving underwater for food, usually close to shore and during the breeding season within of the colony. It forages at depths from , but it prefers depths between . The dives can range from 10 to 144 seconds, and usually average 87 seconds, with an intermission between dives lasting around 98 seconds. Dives of two to ten seconds are typical when feeding on shoals of sandlance at the water's surface. Smaller prey are probably consumed underwater, but larger organisms are brought to the surface to eat after capture.

The pigeon guillemot mostly feeds on benthic prey found at the lowest level in a body of water close to the sea floor, but it also takes some prey from higher in the water column. It mainly eats fish and other aquatic animals. Fish taken include sculpins, sandfish, cod, and capelin; invertebrates include shrimp and crabs like the pygmy rock crab, and even rarely polychaete worms, gastropods, bivalves and squid. The diet varies greatly, based on where the individual bird is, the season, and also from year to year, as ocean conditions change prey availability. For example, invertebrates are more commonly taken in winter. The foraging method used by this species differs from that of auks in other genera. It hangs upside down above the seafloor, probing with its head for prey and using its feet and wings to maintain position. The chick's diet varies slightly, with more fish than invertebrates, particularly rockfish (family Sebastidae). Specialization in the prey taken by a pigeon guillemot when foraging for its chicks generally results in greater reproductive success, with a high-lipid diet allowing for more growth.

The adult pigeon guillemot requires about 20% of its own weight, or of food each day. It doubles its rate of fishing when feeding the nestlings. As the nestlings get older, they are fed more, until 11 days after hatching, when the food generally levels out. The food they get, although, starts to decrease about 30 days after hatching.

Avian predation is the most common cause of egg loss in the pigeon guillemot. Species that prey on the nests include the northwestern crow, a common predator of both eggs and chicks, as well as glaucous-winged gulls, stoats and garter snakes. Raccoons are also common predators, preying on eggs, chicks, and adults. Adults are sometimes hunted by bald eagles, peregrine falcons, great horned owls and northern goshawks. In the water, they have been reported to be taken by orca and giant Pacific octopuses.

This bird, especially its chicks, is vulnerable to "Aspergillus fumigatus", a fungal disease, while in captivity. It is also vulnerable to the cestode "Alcataenia campylacantha". Ticks ("Ixodes uriae") and fleas ("Ceratophyllus") have been recorded on chicks as well.

The pigeon guillemot is considered to be a least concern species by the International Union for Conservation of Nature. This is due to multiple factors, including its large population, estimated at 470,000 individuals, its stable population, and its large range, as this bird is thought to occur over a range of . This bird is vulnerable to introduced mammalian predators, such as raccoons. The removal of introduced predators from breeding islands allows the species to recover. Climate change has a negative effect on this bird, and reproductive performance decreases with increased temperatures. It is also particularly vulnerable to oil, and adults near oiled shores display symptoms of hepatocellular injury, where elevated levels of aspartate aminotransferase can be found in the liver. Otherwise, the effects of oil spills on the pigeon guillemot are unclear. Unlike some seabirds, ingestion of plastic does not seem to be a problem for this species.


</doc>
<doc id="321495" url="https://en.wikipedia.org/wiki?curid=321495" title="Bill O'Reilly (cricketer)">
Bill O'Reilly (cricketer)

William Joseph "Tiger" O'Reilly (20 December 19056 October 1992) was an Australian cricketer, rated as one of the greatest bowlers in the history of the game. Following his retirement from playing, he became a well-respected cricket writer and broadcaster.

O'Reilly was one of the best spin bowlers ever to play cricket. He delivered the ball from a two-fingered grip at close to medium pace with great accuracy, and could produce leg breaks, googlies, and top spinners, with no discernible change in his action. A tall man for a spinner (around 188 cm, 6 ft 2 in), he whirled his arms to an unusual extent and had a low point of delivery that meant it was very difficult for the batsman to read the flight of the ball out of his hand. When O'Reilly died, Sir Donald Bradman said that he was the greatest bowler he had ever faced or watched. In 1935, "Wisden" wrote of him: "O'Reilly was one of the best examples in modern cricket of what could be described as a 'hostile' bowler." In 1939, "Wisden" reflected on Bill O'Reilly's successful 1938 Ashes tour of England: "He is emphatically one of the greatest bowlers of all time."

As a batsman, O'Reilly was a competent right-hander, usually batting well down the order. O'Reilly's citation as a Wisden Cricketer of the Year in 1935 said: "He had no pretensions to grace of style or any particular merit, but he could hit tremendously hard and was always a menace to tired bowlers."

As well as his skill, O'Reilly was also known for his competitiveness, and bowled with the aggression of a paceman. In a short biographical essay on O'Reilly for the "Barclays World of Cricket" book, his contemporary, the England cricketer Ian Peebles, wrote that "any scoring-stroke was greeted by a testy demand for the immediate return of the ball rather than a congratulatory word. Full well did he deserve his sobriquet of 'Tiger'."

Of Irish descent, O'Reilly's paternal grandfather Peter emigrated from County Cavan, Ulster in 1865. Arriving in Sydney, he had been a policeman for four years in Ireland and continued in this line of work in New South Wales. He was sent to Deniliquin in the Riverina, where he settled and married another Irish immigrant Bridget O'Donoghue from Ballinasloe, County Galway. O'Reilly's father, Ernest, was a school teacher and moved around the areas surrounding the Murray River to study and teach. O'Reilly's mother Mina (née Welsh) was of mixed Irish and English descent, of a third generation family from Adelaide. O'Reilly was born in the opal mining town of White Cliffs, New South Wales. Ernest had been appointed to open the first school in the town, and had helped to build the school and its furniture himself. Bill was the fourth child in the family, with two elder brothers and a sister.

O'Reilly's cricket skills were largely self-taught; his family moved from town to town whenever his father was posted to a different school, he had little opportunity to attend coaching. He learned to play with his brothers, playing with a "gum-wood bat and a piece of banksia root chiselled down to make a ball." He learned to bowl because his older brothers dominated the batting rights. His bowling action was far from the classic leg spin bowler's run-up and delivery, indeed, according to "Wisden", "he was asked to make up the numbers in a Sydney junior match and, with a method that at first made everyone giggle, whipped out the opposition". From a young age, O'Reilly was a tall and gangly player.

In January 1908, shortly after Bill had turned two, the family moved to Murringo, after Ernest was appointed the headmaster. O'Reilly said in his autobiography "Tiger" that the move played no vital part in his cricket education. The area had much more vegetation than the desolate White Cliffs, and an Irish Australian majority. O'Reilly later described the period as the happiest of his life. There the children played tennis on a court on their property and took up cricket. During this time, O'Reilly's mother gave birth to another son and two more daughters. In 1917, at the age of 12, the family moved to the town of Wingello. Ernest made the decision because there were no high schools near Murringo and his older children were about to finish primary school. Nevertheless, there was no high school in Wingello where Ernest had been appointed headmaster, so O'Reilly had to catch a train to Goulburn—50 km away—to study at the local public secondary school, where his elder brother Tom had been awarded a scholarship. Wingello was a cricket town and "everyone was a cricket crank" according to O'Reilly. It was here that he developed a passion for the game. O'Reilly played in the town's team and also won the regional tennis championships. O'Reilly bowled with an action reminiscent of the windmill that his family erected in the town. However, school life was difficult, especially in the winter, as the Southern Tablelands were harsh and cold. The O'Reilly children had to leave Wingello at 7.45 am by rail and caught a slow goods train that delivered them home at 7 pm; these vehicles did not provide protection against the weather, and the boys did not participate in any school sport as the only train home left after the end of classes.

In the early 1920s, O'Reilly's eldest brother Jack moved to Sydney. One afternoon, Jack watched spin bowler Arthur Mailey in the North Sydney practice nets and managed to describe the famous bowler's 'Bosie' action in a letter to Bill. O'Reilly claims to have perfected the action of changing the spin from anticlockwise to clockwise without any discernible hand movement within a couple of days. O'Reilly said that "The bosie became my most prized possession. I practised day in, day out". 
Ernest decided that the train journeys and frozen limbs were too much for his son, so he sent Bill to St Patrick's College, Goulburn as a boarder in 1921, where he quickly showed his athletic flair by becoming a member of the school's rugby league, tennis, athletics and cricket teams. He held a state record for the triple jump. At the same time, he also represented the town team. During his time at St Patrick's, O'Reilly developed his ruthless and parsimonious attitude towards bowling. After three years at the Irish Catholic school, funded by a scholarship, O'Reilly completed his Leaving Certificate.

O'Reilly won a scholarship to the Sydney Teachers College at Sydney University, to train as a schoolmaster. However, the financial assistance was only for two years and merely sufficient for O'Reilly's rent at Glebe Point. When he was in Sydney, O'Reilly received an invitation to join an athletics club based on his performances in Goulburn, but was only able to join after the secretary Dick Corish waived his membership fee. Jumping 47 feet, he came second in a triple jump competition behind Nick Winter, who went on to win gold in the event at the 1924 Summer Olympics with a world record of 50 ft. O'Reilly also placed second in a high jumping competition, clearing six feet. Corish was also a cricket administrator and invited O'Reilly to play in a David Jones Second XI. Not knowing anything of his new recruit's abilities, Corish did not allow O'Reilly to bowl until he explicitly complained of only being allowed to field. O'Reilly promptly finished off the opposition's innings by removing the middle and lower order. After an encounter with journalist Johnny Moyes, who wrote glowingly about O'Reilly's skills.

While training as a teacher, O'Reilly joined the Sydney University Regiment, a unit of the Militia Forces (Army Reserve). He did not enjoy his time in the military, and along with most of his peers, regarded the commanding officer as inept. O'Reilly was a non-conformist who did not enjoy taking orders, and was unimpressed with the firearm drills, because the recruits were armed only with wooden sticks. However, he signed up for a second year to raise money for his education. Fed up with military routines he considered to be pointless, O'Reilly volunteered to be a kitchen hand.

During a vacation, O'Reilly caught the train from Sydney back to Wingello, which stopped at Bowral mid-journey. There, Wingello were playing the host town in a cricket match, and O'Reilly was persuaded to interrupt his journey to help his teammates. This match marked his first meeting with Bowral's 17-year-old Don Bradman, later to become his Test captain. O'Reilly himself later described thus:
The wicket ended a period of suffering for O'Reilly at the hands of Bradman, who had hit many fours and sixes from him. Bradman's counter-attack came after he had been dropped twice from O'Reilly's bowling before reaching 30 by Wingello's captain Selby Jeffery. On the first occasion, the ball hit Jeffery in the chest while he was lighting his pipe; soon after the skipper failed to see the ball "in a dense cloud of bluish smoke" as he puffed on his tobacco. The match was the start of a long on-field relationship between the pair, who were to regard one another as the best in the world in their fields. O'Reilly recalled that Bradman "knew what the game was all about".

O'Reilly did not enjoy his time at the overcrowded Sydney Teachers College (STC), decrying the lack of practical training and the predominance of pedagogical theory. Regarding it as a waste of time, he happily accepted an offer of work experience from Major Cook-Russell, the head of physical education at STC, to help at Naremburn College instead of attending lectures. This angered Professor Alexander Mackie, the head of STC, whom both Cook-Russell and O'Reilly regarded as incompetent.

O'Reilly's initial posting after abandoning his training was to a government school in Erskineville, a inner-city suburb in Sydney. At the time, the suburb was slum-like and impoverished, with many unruly students. Many of the pupils were barely clothed and tested O'Reilly's ability to discipline. He said that he learned more in three months there under Principal Jeremiah Walsh than he would have in ten years at STC. Major Cook-Russell then started a military cadet program in New South Wales schools; O'Reilly started such a program at Erskineville and his students won the statewide competition "in a canter". O'Reilly's time at Erskineville also marked the start of work-sport conflicts that hampered his cricket career. He joined North Sydney Cricket Club in 1926–27 and was selected at short notice to play in an invitational match under retired Australian captain Monty Noble at the Sydney Cricket Ground. As the education department required a week's notice for leave requests, O'Reilly declined, but was then ordered by the Chief Inspector of Schools to play after turning up at school on the morning of the match. Having taken six wickets, the match was then washed out, and O'Reilly then had his pay deducted, much to his chagrin.

O'Reilly was selected for the New South Wales practice squad based on his performance in a single match for North Sydney against Gordon in 1927–28. In this game, he bowled Moyes—a state selector—with a medium paced leg break. At state training, O'Reilly's new teammate and Test leg spinner Arthur Mailey advised him to adopt a more conventional grip, but the 19th century Test bowler Charles Turner, known as "Terror Turner" and famous for his unorthodox ways, told O'Reilly to back his self-styled technique. O'Reilly decided to listen to Turner.

After taking a total of 3/88 in a Second XI match against Victoria, O'Reilly made his first-class debut in the 1927–28 season, playing in three matches and taking seven wickets. In his first match, against New Zealand, O'Reilly took 2/37 and 1/53. He then played in what would be his only Sheffield Shield match for several years, going wicketless against Queensland, before returning figures of 4/35 against Tasmania.

In 1928, O'Reilly was transferred by the New South Wales Education Department to Griffith, New South Wales, an outback town in the south-west of the state, and he was unable to play first-class cricket. Over the next three years he moved around the country, including postings to Rylstone and Kandos.
Teaching duties may have cost O'Reilly an early entry into Test cricket, as many young players were introduced in the 1928–29 home series against England following a large number of retirements of older players.
In the meantime, O'Reilly taught English to primary school children in Griffith, as well as singing—most of the pieces were Irish. At Rylstone he taught book-keeping and business, and he was promoted to the high school at Kandos. During this time he supplemented his income by travelling from town to town, playing in one-off cricket matches at the expense of the host's club. He worked on his bosie during the period and regularly dismissed outclassed opposition batsmen. O'Reilly regarded his cricketing isolation as highly beneficial as he regarded coaches to be ill-advised and detrimental to development.

In late 1930, O'Reilly was posted to Kogarah Intermediate High School in the southern Sydney suburb of Kogarah, where he taught English, history, geography and business. O'Reilly resumed playing for North Sydney, confident that with an improved bosie, he was much more potent than before his rural teaching stint. As he only arrived back in Sydney in the second half of the 1930–31 season, O'Reilly was not considered for first-class selection, but he took 29 wickets at 14.72 for North Sydney. 

In the 1931–32 season he emerged as the successor to Mailey in the New South Wales side. Within half a dozen games, he was one of several young players introduced to the Australian cricket team for the Fourth Test in a badly one-sided series against South Africa. However, matters could have been rather different. O'Reilly had broken into the team for New South Wales' away matches against South Australia and Victoria while the Test players were on international duty. He totaled only 2/81 in the first match and was then informed that he would be dropped after the second fixture. O'Reilly responded by bowling with a more attacking strategy, taking 5/22 and 2/112. At the end of the match, New South Wales' stand-in captain, the leg spinning all rounder Reginald Bettington, declared O'Reilly "the greatest bowler in the world", and although few agreed with this claim, Bettington made himself unavailable for selection so that O'Reilly would not be dropped. The reprieved leg spinner took a total of 8/204 in his next two matches, and while the figures were not overwhelming, they were enough to ensure a Test berth; with an unassailable 3–0 lead, the selectors wanted to blood new players.

O'Reilly took four wickets on his debut at the Adelaide Oval, two in each innings, supporting the senior leg-spinner, Clarrie Grimmett, who took 14 wickets in the match and with Bradman scoring 299 not out, Australia won the match. O'Reilly retained his place when the selectors kept the winning side for the final match of the Test series at the MCG. On a pitch made treacherous by rain, he did not bowl at all when South Africa were bowled out for just 36 in the first innings, and came on only towards the end of the second innings, when he took three wickets as the touring side subsided to 45 all out. He ended his first Test series with seven wickets at 24.85. In Sheffield Shield cricket in the 1931–32 season, O'Reilly took 25 wickets at an average of 21 runs per wicket, highlighted by his maiden ten-wicket haul, 5/68 and 5/59 in a home match against South Australia after the Tests were over as New South Wales took out the title.
The following year he was more successful, taking 31 wickets at just 14 runs each. New South Wales won the competition in both seasons.

O'Reilly became a regular member of the Australian Test side in the 1932–33 season and he played in all five Tests against England in the infamous Bodyline series. The Australian selectors perceived that O'Reilly would be their key bowler, and as he had never played against the English, omitted him from the early tour matches so that the tourists would not be able to decode his variations. As a result, he missed the Australian XI match against the Englishmen in Melbourne. In two Shield matches ahead of the Tests, he took 14 wickets, including a total of 9/66 in an innings win over Queensland. Although the national selectors had hidden him from the Englishmen, New South Wales declined to do so, and he played for his state a week ahead of the Tests. The hosts were bombarded with short-pitched bowling and heavily beaten by an innings; O'Reilly took 4/86 as the visitors amassed 530, dismissing leading English batsman Wally Hammond in the first of many battles between the pair.

The Tests started at the SCG and O'Reilly was the team's leading wicket-taker for the series with 27 wickets. O'Reilly not only took most wickets but he also bowled by some distance the most overs on either side, and he achieved a bowling economy of less than two runs from each of his 383 eight-ball overs. In the first match, he took 3/117 from 67 overs as England amassed 530 and took a ten-wicket victory. While his figures suggested that he bowled poorly—none of his wickets were those of batsmen—he beat the batsmen repeatedly. Between Tests, O'Reilly took 11 wickets in two Shield matches.

In the Second Test in Melbourne, O'Reilly opened the bowling as Australia opted to use only one pace bowler on a turning pitch. After Australia had made only 228, O'Reilly trapped Bob Wyatt leg before wicket (lbw) before bowling both the Nawab of Pataudi and Maurice Leyland to leave England at 4/98. He later took two tail-end wickets to end with 5/63 and secure Australia a first innings lead. Defending a target of 251, O'Reilly bowled the leading English opener Herbert Sutcliffe for 33 with a textbook perfect leg break that pitched on leg stump and clipped the top of the off stump. According to English team manager Plum Warner, Sutcliffe had never been defeated so comprehensively. O'Reilly also removed Hammond on the way to ending with 5/66 and securing a 111-run win. The ten-wicket haul was O'Reilly's first at Test level and the start of his strong career record over the English. However, Australia were not to taste further success. The controversial "fast leg theory" bowling used by England under newly appointed captain Douglas Jardine brought the touring team victories in the last three matches: Australia were handicapped not only by the tactics, but also by a lack of quality fast bowlers; O'Reilly also opened the bowling in both the Third and Fourth Tests in Adelaide and Brisbane respectively due to the selection of only one paceman. He was hindered by a decline in the form of Grimmett, who was dropped after the Third Test. O'Reilly took 2/83 and 4/79 in Adelaide, collecting the wicket of Sutcliffe for single figures in the first innings of a match overshadowed by near-riots after captain Bill Woodfull was struck in the heart. Australia were crushed by 338 runs, and lost the series in Brisbane. After O'Reilly had taken 4/101—including Sutcliffe and Jardine—in the first innings to keep Australia's first innings deficit to 16, the hosts collapsed to be 175 all out. O'Reilly took one wicket in the second innings of a six-wicket loss. The final Test in Sydney took a similar course; O'Reilly took 4/111 in the first innings including Sutcliffe and Jardine again, as the tourists took a 14-run lead before completing an eight-wicket win after another Australian collapse. O'Reilly was wicketless in the second innings and bowled 72 overs in total in the match. Reflecting on the performance of O'Reilly in the series, R Mason said "here we saw the first flexing of that most menacing genius".

In the 1933–34 season, with no Test series in Australia, O'Reilly finished top of the Sheffield Shield bowling averages, taking 33 wickets at an average of 18.30, but he had an inconsistent run. He started the season with 6/58 and 7/53 in an innings win over Queensland. After managing only three wickets across two consecutive testimonial matches, O'Reilly went wicketless against South Australia. He was angered by the subsequent comments in newspapers that he had already passed his zenith, and returned to form against Victoria at the MCG. After claiming 3/92 in the first innings, he took 9/50 in the second innings. The nine wickets included six Test players, including leading batsmen Woodfull and Bill Ponsford. Given his heavy workload in the previous season, it was decided to keep O'Reilly fresh for the subsequent tour of England, so he played in only two of the last three matches, with a reduced bowling load, taking eight wickets. During the season, Bradman moved to North Sydney from St George Cricket Club to captain the team, and it was the only summer in which O'Reilly played alongside Bradman at grade level. The following year, O'Reilly moved to St George, which was near Kogarah, as they were obliged to play for a team in their area of residence.

O'Reilly was selected for the tour of England in 1934, where he and Grimmett were the bowling stars as Australia regained the Ashes. They began by taking 19 of the 20 England wickets to fall in a comfortable victory in the First Test at Trent Bridge. O'Reilly's match figures were 11 wickets for 129 runs, and taking seven for 54 in his second innings was to produce his best Test figures.

England then won the Second Test at Lord's, aided by the weather and Australia's inability to force the issue by avoiding the follow on. The hosts batted first and made 440, O'Reilly removing Walters. In reply, Australia were 2/192 when rain struck on the second evening and the sun turned the pitch into a sticky wicket the next day. When O'Reilly came in at 8/273, only 17 runs were needed to avoid the follow on, but he misjudged the flight of a Hedley Verity delivery and was bowled, thinking the ball to be fuller than it was and missing a lofted drive. Australia fell six runs short and were forced to bat again when the pitch was at its worst. They were bowled out again on the same afternoon as Verity took 14 wickets in a day. O'Reilly always regretted his dismissal, as he believed that if he had helped to avoid the follow on, he would have taken "six wickets without removing his waistcoat" and that Australia could have then chased the target in better conditions on the fourth day.

O'Reilly shook English confidence in the Third Test, played on a placid surface at Old Trafford, by taking three wickets in four balls. Cyril Walters, who up to that point had been untroubled, failed to pick the bosie and thus inside edged the ball to short leg. Bob Wyatt came in and was clean bowled for a golden duck, bringing Hammond in to face the hat-trick ball. The new batsman inside edged the ball past the stumps and through the legs of wicket-keeper Bert Oldfield, but the next delivery clean bowled him. This left England at 3/72, and O'Reilly removed Sutcliffe soon after, but the batsmen settled down and the next wicket did not come until Hendren fell just before the end of the first day's play. England were 5/355 and O'Reilly had taken each wicket. The next day, the hosts ended on 9/627, despite a relentless 59 overs from O'Reilly, who ended with 7/189 and was the only bowler to challenge the batsmen. The high-scoring match never looked likely to produce a result, except when Australia were in danger of being forced to follow on. They were 55 runs away from the follow on mark of 478 at the end of the third day with two wickets in hand, and O'Reilly was on one. The next day Arthur Chipperfield fell with 24 runs still needed and O'Reilly and Wall saw them to 491 before the latter fell. O'Reilly ended with 30 not out after an innings in which he was lucky not to be caught off an edge multiple times.

A further draw at Headingley, with England saved by rain after a Bradman triple century, set up a match to decide the series at The Oval. As the series was still alive, the match was timeless, rather than the customary five-day contest. After Australia made 701, O'Reilly took 2/93 to help dismiss the hosts for 321. The visitors then made 327 to set a target of 708 for victory. O'Reilly claimed 2/58, including Hammond, while Grimmett, with a total of eight wickets, proved the decisive bowler as Australia regained The Ashes with victory by 562 runs, which, more than 70 years on, is still the second largest margin of victory in terms of runs in any Test match.

O'Reilly was the leading Australian bowler of the tour, taking 28 Test wickets at an average of less than 25, while Grimmett took 25 wickets at just under 27 runs apiece. Australia's other Test bowlers took only 18 wickets between them. On the tour as a whole, O'Reilly headed the tourists' averages, with 109 wickets at 17.04, which meant that he also topped the averages for the whole English cricket season. In the matches against the English counties, he took 11 wickets in each of the games against Leicestershire and Glamorgan, and in the match against Somerset, after Hans Ebeling took the first wicket, he took the remaining nine for 38 runs, and that proved to be the best innings figures of his career. He was named as one of the Wisden Cricketers of the Year in 1935 for his deeds on tour.

The tour ended with two non-first-class matches in Scotland against the hosts, and O'Reilly top-scored in a match for Australia for the only time, in the first of the two games. Having been allowed to open the innings after complaining about his lack of opportunities, he top-scored with 47 ahead of McCabe's 16. He found the tour to be a happy and healing experience after the acrimony of the Bodyline series.
O'Reilly played little state cricket for New South Wales in 1934–35; at the time, his first child was born and he took time off to ponder his future employment. He played in only one Shield match, against arch-rivals Victoria, and in the testimonial match for the retiring Woodfull and Ponsford. He took a total of eight wickets at 31.37 in these matches.

O'Reilly played no Shield cricket the following season, when he was selected for the Australian tour to South Africa. Although Bradman had been vice-captain under Woodfull in 1934, he did not travel to South Africa on grounds of ill health, but played a full domestic season despite this. The team was captained by Victor Richardson, and O'Reilly publicly described it as the happiest tour he had been on—he was one of several players who did not get along with Bradman.

The tour was another triumph for the leg-spin attack of O'Reilly and Grimmett, but O'Reilly was slightly overshadowed by his teammate in the Tests. With 44 wickets, Grimmett set a new record for the number of wickets by an Australian in a Test series, and he raised his Test career total to 216 wickets, beating the then world record of 189 by Englishman Sydney Barnes. O'Reilly took 27 Test wickets at an average of just over 17 runs each: the other bowlers in the Australian team took 27 wickets between them. On the tour as a whole, O'Reilly came out ahead of Grimmett, with 95 wickets against Grimmett's 92, and an average of 13.56 against 14.80. O'Reilly also revealed hitherto undiscovered batting talents, making an undefeated 56 in the Fourth Test in Johannesburg, and putting on 69 for the last wicket with Ernie McCormick. It was the only time in his first-class cricket career that he passed 50. During the tour, O'Reilly developed his leg trap; the opening batsmen Jack Fingleton and Bill Brown were used in these positions.

With Bradman's appointment as captain of the Australian team after the South African tour, Clarrie Grimmett was dropped, leaving O'Reilly as the hub of the Australian bowling attack for the MCC Ashes tour in 1936–37.

O'Reilly was strongly aggrieved by the removal of his long-time bowling partner, and maintained that it was an "unpardonable" error that heavily weakened Australia's bowling attack. However, he remained vague about why he thought Grimmett had been removed, even though suspicion dogged Bradman. Grimmett continued to dominate the wicket-taking on domestic cricket, while his replacements struggled in the international arena.

O'Reilly responded by becoming the leading Australian wicket-taker in the series taking 25, with Bill Voce taking 26 for England. However, he almost failed to take to the field; O'Reilly and several players had threatened to withdraw after vice-captain Stan McCabe's wife was forbidden from sitting in the Members' Stand in the First Test. The Australian Board of Control backed down, but it was the start of a tumultuous season.

O'Reilly's wickets were at increased cost—his average increased to 22 runs per wicket—and he took five wickets in an innings only once, in the First Test at the 'Gabba in Brisbane, which England won convincingly. The circumstances of the series determined O'Reilly's role: after England won the first two Tests, O'Reilly appeared to have been given the job not just of bowling the opposition out, but also of containing them, and he was criticised in "Wisden" for defensive bowling. "Wisden" even went as far as to describe it as "leg theory". If the intention was to stifle England batsman Wally Hammond in particular, then it appears to have worked, but O'Reilly's figures for the series suggest he was consistent but not always penetrative. Morris Sievers, from fewer matches, outperformed his average; Leslie Fleetwood-Smith, a slow left-arm spinner, got more eye-catching individual figures, including 10 wickets in the victory at Adelaide. Whatever the methods, they were successful: having lost the first two Tests, Australia proceeded to win the final three to retain The Ashes they had regained in England in 1934, and O'Reilly's five for 51 and three for 58 were the best figures in the decisive Fifth Test in Melbourne.

In the 1937–38 season, O'Reilly returned to more regular state cricket, and New South Wales duly won the Sheffield Shield for the first time in five seasons. He took 33 wickets at an average of just over 14 runs each, and against South Australia at Adelaide he repeated his feat against Somerset in 1934, taking the last nine wickets of the first innings at a cost of 41 runs. This time, he followed up with five for 57 in the second innings.

O'Reilly's second and final Ashes tour to England as a player in 1938 again saw him as the most effective bowler in the team. His final record of 22 wickets at an average of 27.72 in the four Tests—the Third Test was rained off without a ball being bowled—was marginally less than 1934, and in all matches he took 104 wickets at 16.59. In its report of the tour, however, "Wisden"<nowiki>'</nowiki>s 1939 edition noted that "it was nothing short of remarkable that despite the moderate support accorded to him he bowled so consistently well and so effectively." Again, O'Reilly was often used defensively where there was no help from the wicket, but, "Wisden" added, "when... the wicket gave him the least encouragement he robbed the greatest batsmen of initiative, and was most destructive".

O'Reilly took 3/164 on a batting paradise in the First Test at Trent Bridge as England scored 8/658 and forced Australia to follow on and hold on for a draw. In the Second Test at Lord's O'Reilly took 4/93 in the first innings and trapped Eddie Paynter for 99 to end a 222-run partnership with Hammond. In reply to England's 494, Australia were in danger of being forced to follow on; O'Reilly came in and made 42, featuring in a partnership of 85 in only 46 minutes with Bill Brown that enabled Australia to save the match: having been dropped by Paynter, he hit Hedley Verity for consecutive sixes to take Australia past the follow-on mark. Brown recalled "It was a nice day, and a nice wicket. O'Reilly came in, and I told him I'd take the quicks—Wellard and Farnes—and Tiger [O'Reilly] took Verity." Australia reached 422 and O'Reilly took 2/53 in the second innings as the match petered into a draw.

In an otherwise high-scoring series, O'Reilly's greatest triumph was in the low-scoring Fourth Test at Headingley, where he exploited a difficult pitch to take five wickets in each innings as Australia secured the victory that enabled them to retain the Ashes. With the series level at 0–0, England captain Hammond elected to bat first; O'Reilly's 5/66 was largely responsible for ending England's innings at 223. He removed Hammond, who had top-scored with 76, Bill Edrich and Denis Compton, all bowled in quick succession. England were 1/73 on the third day, an overall lead of 54, when O'Reilly began a new spell after Bradman had switched his ends. Joe Hardstaff junior hooked him for four and the next ball was no-balled by the umpire. O'Reilly was reported to have become visibly enraged; he bowled Hardstaff next ball and then removed Hammond for a golden duck. This precipitated an English collapse to 123 all out, and O'Reilly ended with 5/56 and a total of 10/122. O'Reilly effort proved to be crucial as Australia scraped home by five wickets just 30 minutes before black clouds brought heavy rain, which would have made batting treacherous. The victory ensured the retention of the Ashes, and O'Reilly ranked it as his finest performance, alongside his ten wickets in the Second Bodyline Test of 1932–33.

Australia had retained the Ashes, but England struck back at The Oval, where they posted the then-record Test score of 7/903. Early on, O'Reilly trapped Edrich lbw for 12, to secure his 100th Test wicket against England. In a timeless match, Len Hutton made a world record Test score of 364 in a fastidious and watchful innings of 13 hours, surpassing Bradman's 334. When he was on 333, O'Reilly deliberately bowled two no-balls in an attempt to break Hutton's concentration by tempting him to hit out, but the Englishman blocked them with a straight bat.

O'Reilly eventually removed Hutton and ended with 3/178 off 85 overs. Nevertheless, these compared favourably with Fleetwood-Smith's 1/298 off 87 overs. O'Reilly was the only Australian to take more than a solitary wicket, and rated Hutton's knock as the finest innings played against him. Australia collapsed to lose by an innings and 579 runs, the heaviest defeat in Test history. O'Reilly's lack of success went with The Oval Test in 1934, when he took a total of 4/151.

O'Reilly scaled back his participation in Sheffield Shield cricket in the 1938–39 season, making himself unavailable for most of the campaign to spend time with his newborn son after half a year in England; he played in only two matches, against South Australia and arch-rivals Victoria. He took a ten-wicket haul in the latter match, but his figures of 6/152 and 4/60 were not enough to prevent defeat. Both teams were at full strength and eight of O'Reilly's victims were Test players, including batsman Lindsay Hassett twice. O'Reilly's only other match was for Bradman's XI against Rigg's XI in a match to commemorate the centenary of the Melbourne Cricket Club, in which he took a total of 7/129, to end the season with 19 wickets at 23.16.

He resumed regular service for New South Wales in the next season, taking 55 wickets at 15.12 in seven matches. He took 8/23 and 6/22 to set up an innings win over Queensland and 6/77 and 4/62 in another victory over South Australia. The two matches against Victoria were shared as O'Reilly took 17 wickets. In the second of the matches, in Sydney, Hassett became the only person to score centuries in both innings of match involving O'Reilly. Despite Hassett's feat, New South Wales won the match; O'Reilly took a total of 8/157. 

O'Reilly continued his strong run in 1940–41, taking 55 wickets at 12.43 in eight matches. He took nine wickets in three consecutive matches, once for McCabe's XI in a match against Bradman's XI, which his team won by an innings, and in both matches against Victoria, which were split between the two states. First-class cricket was ended after one match in 1941–42; O'Reilly took a total of 9/124 in a loss to Queensland before the attack on Pearl Harbor signaled the start of World War II in the Pacific. In the meantime, O'Reilly continued to play for St George and topped the grade competition's bowling averages for years from 1941–42 onwards. He averaged between 8 and 9 in all these seasons, and took more than 100 wickets in three consecutive summers, peaking with 147 in 1943–44. O'Reilly had tried to enlist in the military in 1941, but after presenting himself for the medical, was informed that his employer was deemed a "protected undertaking", so their workers were not allowed to enlist.

First-class cricket resumed in Australia in 1945–46 after the end of the war, although the Shield competition was not held that season. O'Reilly captained New South Wales at the age of 40, and although the emergence of Ray Lindwall and Ernie Toshack in the state side indicated a shift in emphasis away from spin and towards faster bowling, O'Reilly maintained his pre-war standards. He took 33 wickets at 14.36 in six matches and New South Wales were undefeated; they won four matches and drew both fixtures against Victoria. He took at least two wickets in every innings and claimed his innings best of 6/43 against Queensland. O'Reilly also took a match total of 7/94 in an innings win over the Australian Services team, which had drawn a series against a full-strength England team.

O'Reilly's final first-class cricket came on a four-match tour by an Australian team to New Zealand in early 1946. O'Reilly was the vice-captain of the team, which was led by Bill Brown. The main fixture during the tour was a four-day match against a representative New Zealand side in Wellington, retrospectively designated as the first Test between the two countries in 1948. The uncertain nature of the tour saw the Australians wear blazers labeled ABC for Australian Board of Control, rather than the usual coat of arms. New Zealand were outclassed; after winning the toss and electing to bat on a rain-affected pitch, they made 42 in their first innings and 54 in their second to lose by an innings and 103 runs. O'Reilly took 5/14 in the first innings, and 3/19 in the second, dominating with Toshack. It was his last Test and his last first-class game. O'Reilly dominated in the other tour games as well; he took match totals of 9/103 and 8/128 against Auckland and Otago respectively, and ended with 28 wickets at 10.60 for the tour. Having only decided to tour New Zealand after much consideration, O'Reilly retired at the end of the Test, throwing his boots out of the dressing room window.

Despite the mutual admiration between Bradman and O'Reilly for their cricket skills, personal relations between the pair were strained. In Australian society at the time, sectarian tension existed between Catholics, mostly of Irish descent, of whom O'Reilly was one, and Protestants, like Bradman. Bradman was a non-drinker and a reserved character, often preferring to read quietly, rather than socialize or drink with his teammates. Coupled with his on-field dominance, this led to perceptions that Bradman was cocky and distant from his teammates. In the late 1930s, the Australian Board of Control summoned O'Reilly, Stan McCabe, Leo O'Brien and Chuck Fleetwood-Smith, all Catholics of Irish descent to a meeting to discuss the apparent schism in the team. Jack Fingleton, a trained journalist, was not invited to the meeting, but after the deaths of both Fingleton and O'Reilly, Bradman penned a letter in which he accused the former of being the ringleader. O'Reilly's eventual departure also raised speculation that a purge had occurred. In 1995, after both Fingleton and O'Reilly had died, Bradman wrote: "With these fellows out of the way, the loyalty of my 1948 side was a big joy and made a big contribution to the outstanding success of that tour"; the Australians went through the 1948 English summer undefeated.

O'Reilly became a journalist, and together with Fingleton, he often criticized Bradman. They were in the press box when Bradman was bowled for a duck in his final Test innings, when they were reported to have become hysterical with laughter. Nevertheless, O'Reilly kept most of his strongest feelings about Bradman to himself and suppressed them from his autobiography; he would say of Bradman that "You don't piss on statues". Before his death, O'Reilly gave a series of interviews to the National Library of Australia, in which he accused Bradman of purging Grimmett from the team because Grimmett had joked that Bradman had ensured his own dismissal in a match against Victoria, to avoid facing the express pace of Ernie McCormick.

According to cricket historian Gideon Haigh, "O'Reilly was a man of embedded prejudices". In retirement, O'Reilly complained to a board member that "You have to play under a Protestant to know what it's like". The Test umpire Col Egar recalled that O'Reilly never talked to him in their decades in cricket until a third party informed the bowler that Egar was a Catholic.

Despite their conflicts, a few years before his death O'Reilly wrote that, compared with Bradman, batsmen like Greg Chappell and Allan Border were mere "child's play".

In 1933, O'Reilly married Mary Agnes "Molly" Herbert, after less than six months of courtship. Of Irish stock, Molly had been introduced to O'Reilly through one of his teaching colleagues at Kogarah, who married Molly's elder sister the following year. The couple then moved to the southern Sydney suburb of Hurstville. The couple had two children, a girl followed by a boy.

O'Reilly continued to work as a school teacher after he broke into international cricket, but at the end of 1934, after missing more than six months of the year in England, he resigned from his government post, reasoning that his career could not progress if he was going to be overseas so often. However, he had not made any plans for his future employment. Soon after, O'Reilly received an offer to work as a sportsgoods salesman for the department store David Jones with sporting leave entitlements. The Premier of New South Wales, Bertram Stevens, tried to coax O'Reilly into staying in the government education system, offering him a post at Sydney Boys High School if he returned to STC to complete the Bachelor of Arts that he had abandoned a decade before.

In 1935, O'Reilly took up an appointment at Sydney Grammar School, one of the leading private schools in the state, having been offered 50% paid leave for his cricket commitments. There he taught English, history and business. In 1939 he took a job in the sports store of close friend, teammate and fellow Irish Catholic Stan McCabe, which was located on George Street, the city centre's main thoroughfare. O'Reilly was a financial partner in the business, but following the outbreak of World War II, the sales revenue began to suffer and O'Reilly left as the store would not be able to support two stakeholders.

O'Reilly then accepted a position as a manager of the Lion Tile Company at Auburn, in Sydney's western suburbs. He remained in the position until 1976. O'Reilly was responsible for the financial and accounting affairs of the firm, which expanded to employ more than 200 workers. He was held in high regard and granted full paid leave when he thrice went overseas for six months to cover tours of England as a journalist. Doc Evatt, a leading Australian Labor Party politician attempted to recruit O'Reilly into politics, but was unsuccessful.

During the late-1930s, O'Reilly mentored the then-teenaged Arthur Morris and Ray Lindwall at St. George. He converted Morris from a left arm unorthodox spinner into an opening batsman, and exhorted Lindwall to become a specialist express paceman. Both had long Test careers and captained their country and are regarded as all-time Australian greats in the fields that O'Reilly chose for them—both were chosen with O'Reilly in the ACB Team of the Century. The pair credited O'Reilly as being the main influence in their careers, and Lindwall made his Test debut in O'Reilly's last Test in 1946.

In 1956–57, McCabe and O'Reilly were given a testimonial match by the New South Wales Cricket Association. The match was between Harvey's XI and Lindwall's XI and acted as a trial for the non-Test tour of New Zealand. It raised 7,500 pounds, which was split between McCabe and O'Reilly and would have bought two average-sized homes in Sydney at the time.

On retirement as a player, O'Reilly became a cricket columnist for "The Sydney Morning Herald", remaining in that position until his health declined in 1988. His first engagement was England's tour of Australia in 1946–47, and during this season he began a partnership with the "Daily Express" of London, going on to cover several Ashes series for them. O'Reilly's articles for "The Sydney Morning Herald" were reproduced in its sister publication, "The Age" of Melbourne. Later, his writing was syndicated to newspapers in India, South Africa and New Zealand. His style was described by "Wisden" as "muscular, very Australian... flavoured with wit and imagery ('You can smell the gum-leaves off him', he wrote of one country boy just starting with Queensland)." Jack McHarg said that "The clarity, wit and pungency of his writing, together with almost infallible judgment, never deserted him", even as his health began to restrict him. He was a highly respected and forthright pundit, who hated one-day cricket, describing it as "hit and giggle". He condemned the omission of Keith Miller in 1949–50 and said that to call it "a complete surprise would be a cowardly way of describing a botch". Reacting to the selection of the dour batting all rounder Ken Mackay, he wrote "words fail...to express adequately my contempt for this howler". In 1952 he had a falling-out with Lindwall after condemning his protégé for bowling five consecutive bouncers at Everton Weekes in a Test. In comparison with his illustrious contemporary on-field and on paper, "while Sir Donald walked the corridors of cricketing power O'Reilly was the rumbustious backbencher." In 1956, O'Reilly strongly criticised Australian captain Ian Johnson, a Melburnian, for his leadership during the 1956 Ashes tour. "The Age" took exception to this and asked their sister publication to rein in their pundit. O'Reilly refused to shy away from his opinions and was dropped by the Melbourne publication. In the 1980s, when Bob Simpson became the first coach of Australia, O'Reilly, himself self-taught, spoke out against the creation of such posts. He was a strong critic of the breakaway World Series Cricket, the commercialization of the sport and the erosion of the social norms that were followed during his playing career.

Aside from his autobiography, O'Reilly wrote two books; "Cricket Conquest: The Story of the 1948 Test Tour", published in 1949, and "Cricket Task Force", published in 1951. They were accounts of the "Invincibles" tour of England in 1948 and England's Ashes tour to Australia in 1950–51.

Upon retiring from "The Sydney Morning Herald", O'Reilly wrote in a column
O'Reilly was honored with several accolades late in his life. In 1980, he was awarded an Order of the British Empire for his services to cricket as a player and writer. In 1985, the oval in Wingello was renamed in his honor, and in 1988, a grandstand at the SCG was named the Bill O'Reilly Stand. In the same year, the oval in White Cliffs was renamed, and "The Sydney Morning Herald" renamed the medal they awarded to the best player in grade cricket in O'Reilly's honour. During the celebrations for the Australian Bicentenary, O'Reilly was named among the 200 people, and only 21 living, who had contributed the most to the country since European settlement.

O'Reilly's later years were troubled with poor health, including the loss of a leg. In late 1988, he suffered a major heart attack and was hospitalized for two months. He died in hospital in Sutherland in 1992, 75 days short of his 87th birthday. O'Reilly lamented the decline of spin during his twilight years, and in the 1980s he was often derided by younger people who felt that his advocacy of spin bowling—which they deemed to be obsolete—was misplaced. He died just months before Shane Warne revived the art of leg spin on the international stage.

In 1996, O'Reilly was posthumously inducted into the Australian Cricket Hall of Fame as one of the ten inaugural members. In 2000, O'Reilly was named in the Australian Cricket Board Team of the Century, and in 2009 he was named among the 55 inaugural inductees of the International Cricket Council's Hall of Fame, being formally inducted in January 2010.

In his 18-season first-class career, O'Reilly took 774 wickets at an average of 16.60. In his 27 Test matches, O'Reilly took 144 wickets at 22.59, 102 of them in his 19 Ashes Tests against England.

It has been retrospectively calculated by the International Cricket Council's LG Ratings that he was the best bowler in the world for much of his career.



</doc>
<doc id="322139" url="https://en.wikipedia.org/wiki?curid=322139" title="Eve (U.S. TV series)">
Eve (U.S. TV series)

Eve is an American television sitcom, created by Meg DeLoatch, which originally aired for three seasons on United Paramount Network (UPN) from September 15, 2003 to May 11, 2006. Featuring an ensemble cast consisting of Eve, Jason George, Ali Landry, Natalie Desselle-Reid, Brian Hooks, and Sean Maguire, the show revolves around two sets of male and female friends attempting to navigate relationships with the opposite sex. The executive producers were Robert Greenblatt and David Janollari; the series was produced by The Greenblatt/Janollari Studio and Mega Diva Inc. in association with Warner Bros. Television for UPN.

The series was developed as a vehicle for Eve under the working title "The Opposite Sex"; UPN executives approached the rapper about a television project after the success of fellow musician Brandy in another of the network's sitcoms—"Moesha". Eve's series was created as part of the network's attempt to appeal to a younger audience. After being picked up, the show was renamed "Eve" to attract the rapper's fans. The series was set in Miami, but filmed at Sunset Gower Studios in Hollywood, Los Angeles. Eve said that she was intimidated at first by the process of preparing for and filming a sitcom, and she would later regret not fully committing to her character. The show was distributed by UPN in its original run, and later by TV One. UPN had promoted "Eve" as part of its new comedy block, one of four new comedies developed by the network.

"Eve" suffered from low viewership in spite of its high ratings among young African American women; it was canceled following UPN's merger with The WB Television Network (The WB) to launch The CW in 2006. The series' cancellation, along with that of other black sitcoms, was criticized by media outlets for reducing representation of African American characters and the number of roles for African American actors on television. Critical response to "Eve" was mixed; some praised its inclusion as a part of UPN's line-up of black sitcoms, but others felt Eve lacked charisma, and that the series was inferior to other black sitcoms. Despite the negative reception, the show and Eve received several award nominations. The series was released on the iTunes Store and Amazon Video.

"Eve" revolves around Miami fashion designer Shelly Williams (Eve), "a woman whose fashion career is on the move [but whose] her love life is a work in progress". At the start of the series, Shelly has been unable to find a suitable partner for ten months. She begins an on and off relationship with physical therapist J.T. Hunter (Jason George), which is nearly derailed when he cries while they watch "Casablanca" on their first date. Both characters turn to two of their close friends for advice on the opposite sex, love, and relationships. Shelly frequently looks for advice from former model Rita Lefleur (Ali Landry) and married friend Janie Egins (Natalie Desselle-Reid), while J.T. finds support in his best friends nightclub manager Donovan Brink (Sean Maguire) and IRS worker Nick Dalaney (Brian Hooks).

Episodes typically depict the friends' comedic and romantic adventures and career issues, such as Shelly, Rita, and Janie working together at their Miami-based fashion boutique DivaStyle and J.T. applying to colleges. The six characters each have many dates and serious relationships, and the series can be viewed as an extension of the concept of "the battle of the sexes" for its equal representation of both male and female viewpoints on the matter. Janie serves as Shelly's voice of reason, while Rita encourages her to be more impulsive with dating. They often disagree with one another on the best way for Shelly to approach her love life. Rita, Janie, Nick, and Donovan are typically shown caught in the middle of Shelly and J.T.'s miscommunications.

Even though Shelly and J.T.'s relationship is the predominant storyline, the series does explore the relationships of its supporting cast; Donovan and Rita date each other, and the quite selective Nick attempts to find the perfect partner. Donovan owns the Z Lounge, which is described as "one of Miami's hottest clubs" and serves as one of the places where the group often meets. Other frequently recurring characters include Shelly's younger love interest Grant (Sharif Atkins), Janie's husband Marty (Reggie Gaskins), and Shelly's mother Beverly (Penny Johnson Jerald). Several celebrities also make cameo appearances on the show, including Queen Latifah, Missy Elliott, Brooke Burke, Vivica A. Fox, and Cedric the Entertainer.

<onlyinclude></onlyinclude>

The first season introduces the six main characters: Shelly, J.T., Rita, Janie, Nick, and Donovan. Shelly runs the fashion boutique DivaStyle with her friends Janie and Rita. She pursues a relationship with J.T., only to discover he is afraid of commitment and exhibits some chauvinistic behavior. Their relationship is often tested by frequent misunderstandings. Nick wants to find his ideal partner, but his attempts are typically thwarted as he is very particular about women. Even though his relationship with a woman named Dani appears to be successful, they soon break up. Donovan finds himself romantically attracted to Rita, but he resists the temptation out of fear of ruining their friendship.

Shelly and J.T. break up at the beginning of the second season and pursue a friends with benefits relationship. After discovering that she is bankrupt, Rita moves in with Janie to save money. She also begins a relationship with Donovan. When Janie becomes annoyed with Rita for staying at her home for a long time, Rita persuades J.T. and Nick to let her stay with them instead. Shelly finds herself attracted to a younger man, and J.T. becomes jealous realizing that he is in love with her. In the season finale, both men propose to Shelly. At the same time, Donovan's application for residency is rejected and the friends prepare for his return to England.

In the third-season premiere, Shelly accepts J.T.'s marriage proposal. Donovan gets a work visa after finding a job selling makeup products for a British company. Shelly and J.T. break up again, resolving to remain just friends. J.T. pursues a career in medicine and enrolls in the Miami State Medical School. He finds out that college is more difficult than he first thought, and struggles with his classes and finances. During the spring, Rita reignites her relationship with Donovan and buys her own apartment. In the series' finale, Beverly finally admits to Yusef, Shelly's father, that she is carrying his child; Shelly questions his ability to be a father again. The series ends in a cliffhanger, with Janie, Rita, and Donovan arrested for illegally selling BOTOX at DivaStyle.

United Paramount Network (UPN) executives approached Eve about developing a television project following her performance of her rap single "Gangsta Lovin'" (2002) at an event marking the channel's 2002 season premieres. The network had pitched the idea to her prior to her appearances in the 2002 films "XXX" and "Barbershop". Following their release, UPN renewed its interest in pursuing a series with Eve. She had developed the main premise behind the sitcom, in which she would star as a fashion designer with a supporting multi-ethnic ensemble. The show's creation was credited to television producer Meg DeLoatch. UPN executives designed the series as a vehicle for Eve following the positive response to fellow musician Brandy in another UPN sitcom, "Moesha".

Eve accepted the role as a way to showcase a different side of her personality that was unexplored in her music. Her co-star Jason George commented that the show allowed the audience to see Eve as more than a hardcore rap artist, saying: "The part that people know the least about her comes across most in this show: There's a seriously girlie girl side to her." DeLoach emphasized the difference between Eve and her character Shelly Williams by saying: "She's bringing so much of herself to the role of Shelly but she's playing a character. Some of the things Shelly does aren't necessarily what Eve would do." To further distinguish herself as an actor, Eve decided against singing the show's theme song.

Publicized as the "Untitled Eve Project" in an early press release, the series had the working title "The Opposite Sex" before it was changed to reflect Eve's status as the star. Eve initially resisted the change and felt that "The Opposite Sex" was a stronger choice, but described it as a "corporate decision". According to her, UPN executives explained that the title would better attract the rapper's fans. They also felt that the audience would not be confused by the title "Eve", despite Eve playing a character named Shelly. After the title was established, the show's premise was modified slightly, but remained centered around male and female friends discussing their love lives, and navigating their relationships with the opposite sex. While Eve described the series as "the PG version of "Sex and the City"", DeLoatch promoted "Eve" as unique for incorporating both male and female perspectives on dating and love. She further described the sitcom as "focus[ing] on one relationship and follow[ing] all of the ups and downs in it" with the purpose of "showing the male and female points of view". To achieve this goal, DeLoatch included male writers in the discussions of potential episodes and storylines to hear their input.

Production was handled by The Greenblatt/Janollari Studio, Mega Diva Inc, and Warner Bros. Television. Robert Greenblatt and David Janollari served as the series' executive producers. DeLoatch, Troy Carter, David Duclon, and Eve also contributed to the series as co-executive producers. Rapper Missy Elliott wrote and performed the theme song, which was produced by Soul Diggaz. "Eve" was one of four new comedies developed by UPN for the 2003–04 television season, as part of a "new comedy block" including "All of Us", "Rock Me Baby," and "The Mullets". A writer from "Today" described UPN's enlistment of Eve into a comedy as an example of the network's attempt to form its own identity through targeting a younger, multi-ethnic audience. In his book "TV-a-Go-Go: Rock on TV from American Bandstand to American Idol", Jake Austen identified "Eve" as part of a trend in which musicians were prominently featured as the stars of television programs; he cited Brandy's role in "Moesha" and Queen Latifah on "Living Single" as two other examples.

By the time the series was officially announced during UPN's broadcast upfront presentations, Ali Landry, Natalie Desselle-Reid, and Brian Hooks were confirmed to be playing Rita, Janie, and Nick respectively. Bumper Robinson was originally scheduled to portray J.T., but was later replaced by Jason George for undisclosed reasons. The role of Donovan was also recast, with the original actor Eddie McClintock removed in favor of Sean Maguire. The supporting cast of Landry, Desselle-Reid, Hooks, and Maguire were described by Tom Jicha of the "Sun-Sentinel" as "peripheral" since they were written to "servic[e] the highs and lows of the romance between Shelly and J.T." With Shelly and J.T.'s relationship as the heart of the sitcom, Janollari expressed hopes that the episodes would follow them "from their meeting in the pilot, through the steps of a normal relationship, all the way, hopefully to marriage". In the fall of 2006, TV One began broadcasting the series as part of an agreement with Warner Bros. Domestic Cable Distribution. Along with "All of Us", "Eve" was the first time in which the channel acquired the rights for shows that were currently airing on network television.

Even though the show was set in Miami, filming took place at Sunset Gower Studios in Hollywood, Los Angeles. Stock exterior shots of Miami were used for the opening credits and transitions between scenes. The series was filmed with a multiple-camera setup, with each episode last roughly 20 to 22 minutes excluding commercials. Eve said she was initially intimidated by the amount of work required to prepare for and film a television series. During an interview with "Billboard", she explained that while filming the first season she felt like she "just wanted to leave because there was so much to learn, it's just a different world". Since she found comedy to be challenging due to the "certain beats you have to learn", Eve hired two acting coaches to help improve her timing. One of her coaches was Chip Fields, who visited the show's set to offer Eve acting advice. During the development of the second season, Eve viewed the set as her home, and felt the process was easier, having grown closer to the cast and crew. In a 2016 interview with "Grazia", she revealed her regret at not fully committing herself to her character and the series. She explained: "I was the youngest person on set and was clubbing in between being on set and learning my lines. I look back and wish I was more dedicated. But I learned from it."

The show, as well as a majority of UPN's programs, was officially canceled when the network merged with The WB Television Network (The WB) to form The CW in 2006. Fern Gillespie of "The Crisis" was critical of UPN's decision to cancel the series given how the network "in one swoop, wiped out five of its eight African American comedies" with the creation of The CW. Gillespie expressed disappointment at the lack of African American sitcoms on the three major networks, saying: "Without that opportunity for some of the younger artists to hone and develop their skills, it will potentially have a generational impact." IndieWire's Dara T. Mathis identified "Eve" as an example of UPN's notable black sitcoms and equated the cancellations of a majority of UPN's comedies as a sign that the genre was in a state of decline. Critic Tim Goodman noted that "Eve" was one of six shows "geared for an African American audience", featuring "an African American lead actress" that were canceled during the merger. He viewed these cancellations as a sign of networks "eliminat[ing] niche programming". Julian Kimble of "Complex" included "Eve" on a list of programs that "are often forgotten about", alongside other UPN sitcoms "Half & Half" and "All of Us". The series has not been made available on Blu-ray or DVD, but it was released on the iTunes Store and Amazon Video.

"Eve" has received mixed feedback since its first broadcast. Melanie McFarland of the "Seattle Post-Intelligencer" praised the changes made during the show's development and highlighted Maguire as the standout. In reference to its transformation from the original pilot, she described "Eve" as the "Eliza Doolittle of UPN comedies". The supporting cast was praised by David Hinckely of the "New York Daily News", who wrote that they "form an entertaining and appropriately neurotic chorus behind Eve's relationship dance". "Eve" was compared to the UPN comedy "Girlfriends" by "The New York Times" Alessandra Stanley, who regarded Eve as an appropriate lead with "an appealingly tough edge that matches the paw-print tattoos on her chest". Brian Josephs of "Spin" shared positive memories of African-American television shows on UPN, identifying Monday nights on the network as the place "where Eve transformed from Ruff Ryder to sitcom actress". "Eve" was listed by scholar Jake Austen as one of the shows "that emerged in the wake of the civil rights era" that served as "a dynamic showcase for black creativity". Tom Jicha provided a less enthusiastic review, stating that "Eve" was "just another cookie-cutter sitcom".

"Eve" drew criticism for its formulaic writing, and the lead's poor performance. The show was included on a list by "Ebony"'s Kevin L. Clark profiling the top ten worst black television shows of all time. Clark was critical of the episodes' titles, such as "Condom Mania", "She Snoops to Conquer" and "Porn Free", and wrote that they indicated an overuse of "outrageous clichés that boob-tube audiences would come to know and love once reality TV hit its boon". Arianna Davis of Refinery29 negatively compared "Eve" to 1990s black sitcoms, and determined that it was a part of the "rollout of campy shows [...] that felt less like purposeful programming and more like cheap attempts at copying a successful advertising model". The "Los Angeles Times" Mimi Avins felt that the show lacked the spark and the writing quality of "Sex and the City", identifying Eve as its weakest link. She felt that Eve did not show "the acting ability or high-voltage charisma that vaulted Will Smith from rapper to television star" in "The Fresh Prince of Bel-Air". During her review of the original pilot, Melanie McFarland wrote that the sitcom lacked any potential due to Eve's poor performance on top of the "[t]errible scenery, cheap costumes and a few glaring miscasts". Eve's decision to distance the series from her identity as a rapper was questioned by Roger Catlin of the "Hartford Courant", who felt that the character of Shelly could have used "the personality charge" from Eve's life. Despite finding Eve a charismatic presence, Catlin felt that her acting, along with that of Ali Landry, was poorly-developed. Echoing Catlin's assessment, the "San Francisco Gate"s Tim Goodman was critical of Eve and Landry's performance. Goodman also wrote that the show was an example of "the worst writing on television", citing its homophobic jokes and its reliance on clichés.

In spite of the mixed reception from television critics, the show, and Eve's performance, received several award nominations. In 2004, the show was nominated for the Teen Choice Award for Choice Breakout TV Show. Eve was also nominated for Choice TV Actress – Comedy in the same year. Eve was nominated again for the Teen Choice Award for Choice TV Actress: Comedy in 2005. She also received two nominations for the Blimp Award for Favorite Television Actress during the 2005 and 2006 Kid's Choice Awards. Eve earned a nomination for the 2005 Image Award for Outstanding Actress in a Comedy Series, and the 2005 BET Awards Comedy Award for Outstanding Lead Actress in a Comedy Series.

The table below shows "Eve"s ratings in the United States. "Rank" refers to how well "Eve" rated compared to other television series that aired during prime time hours of the corresponding television season. It is shown in relation to the total number of series airing on the then-six major English-language networks in a given season. "Viewers" refers to the average number of viewers for all original episodes, broadcast during the television season in the series' regular time slot. The "season premiere" is the date that the first episode of the season aired, and the "season finale" is the date that the final episode of the season aired.
According to the Nielsen Company, the show achieved high ratings among "Latina adolescents Ages 12–17" and earned 3.8 million viewers in that demographic in 2005. It was the second-highest UPN sitcom in the category, with only "Everybody Hates Chris" ranking above it in this demographic.




</doc>
<doc id="322159" url="https://en.wikipedia.org/wiki?curid=322159" title="Prince George of Denmark">
Prince George of Denmark

Prince George of Denmark and Norway, Duke of Cumberland (; 2 April 165328 October 1708), was the husband of Queen Anne, who reigned over Great Britain from 1702 to 1714.

His marriage to Anne was arranged in the early 1680s with a view to developing an Anglo-Danish alliance to contain Dutch maritime power. As a result, George was unpopular with his Dutch brother-in-law, William III of Orange, who was married to Anne's elder sister, Mary. William and Mary became joint monarchs of Britain, with Anne as their heir presumptive, in 1689 after the "Glorious Revolution" deposed James II and VII, the father of both Anne and Mary.

William excluded George from active military service, and neither George nor Anne wielded any great influence until after the deaths of Mary and then William, at which point Anne became queen. During his wife's reign, George occasionally used his influence in support of his wife, even when privately disagreeing with her views. He had an easy-going manner and little interest in politics; his appointment as Lord High Admiral in 1702 was largely honorary.

Anne's seventeen pregnancies by George resulted in twelve miscarriages or stillbirths, four infant deaths, and a chronically sick son, William, who died at the age of eleven. Despite the history of their children, George and Anne's marriage was a strong one. George died aged 55 from a recurring and chronic lung disease, much to the devastation of his wife, and he was buried in Westminster Abbey.

George was born in Copenhagen Castle, and was the younger son of Frederick III, King of Denmark and Norway, and Sophie Amalie of Brunswick-Lüneburg. His mother was the sister of Ernest Augustus, Duke of Brunswick-Lüneburg, later Elector of Hanover. From 1661, his governor was Otto Grote, later Hanoverian minister to Denmark. Grote was "more courtier and statesman than educator" and when he left for the Hanoverian court in 1665, he was replaced by the more effective Christen Lodberg. George received military training, and undertook a Grand Tour of Europe, spending eight months in 1668–69 in France and mid-1669 in England. His father died in 1670, while George was in Italy, and George's elder brother, Christian V, inherited the Danish throne. George returned home through Germany. He travelled through Germany again in 1672–73, to visit two of his sisters, Anna Sophia and Wilhelmine Ernestine, who were married to the electoral princes of Saxony and the Palatinate.

In 1674, George was a candidate for the Polish elective throne, for which he was backed by King Louis XIV of France. George's staunch Lutheranism was a barrier to election in Roman Catholic Poland, and John Sobieski was chosen instead. In 1677, George served with distinction with his elder brother Christian in the Scanian War against Sweden. His brother was captured by the Swedes at the Battle of Landskrona, and George "cut his way through the enemies' numbers, and rescued him at the imminent danger of his own life."

As a Protestant, George was considered a suitable partner for the niece of King Charles II of England, Lady Anne. They were distantly related (second cousins once removed; they were both descended from King Frederick II of Denmark), and had never met. George was hosted by Charles II in London in 1669, but Anne had been in France at the time of George's visit. Both Denmark and Britain were Protestant, and Louis XIV was keen on an Anglo-Danish alliance to contain the power of the Dutch Republic. Anne's uncle Laurence Hyde, 1st Earl of Rochester, and the English Secretary of State for the Northern Department, Robert Spencer, 2nd Earl of Sunderland, negotiated a marriage treaty with the Danes in secret, to prevent the plans leaking to the Dutch. Anne's father, James, Duke of York, welcomed the marriage because it diminished the influence of his other son-in-law, Dutch Stadtholder William III of Orange, who was naturally unhappy with the match.

George and Anne were married on 28 July 1683 in the Chapel Royal at St James's Palace, London, by Henry Compton, Bishop of London. The guests included King Charles II, Queen Catherine, and the Duke and Duchess of York. Anne was voted a parliamentary allowance of £20,000 a year, while George received £10,000 a year from his Danish estates, although payments from Denmark were often late or incomplete. King Charles gave them a set of buildings in the Palace of Whitehall known as the Cockpit (near the site of what is now Downing Street in Westminster) as their London residence.

George was not ambitious, and hoped to live a quiet life of domesticity with his wife. He wrote to a friend: "We talk here of going to tea, of going to Winchester, and everything else except sitting still all summer, which was the height of my ambition. God send me a quiet life somewhere, for I shall not be long able to bear this perpetual motion."

Within months of the marriage, Anne was pregnant but the baby, a girl, was stillborn in May. Anne recovered at the spa town of Tunbridge Wells, and over the next two years, she gave birth to two daughters in quick succession, Mary and Anne Sophia. In early 1687, within a matter of days, George and his two young daughters caught smallpox, and Anne suffered another miscarriage. George recovered, but both his daughters died. Lady Rachel Russell wrote that George and Anne had "taken [the deaths] very heavily. The first relief of that sorrow proceeded from the threatening of a greater, the Prince being so ill of a fever. I never heard any relation more moving than that of seeing them together. Sometimes they wept, sometimes they mourned in words; then sat silent, hand in hand; he sick in bed, and she the carefullest nurse to him that can be imagined." He returned to Denmark for a two-month visit in mid-1687, while Anne remained in England. Later that year, after his return, Anne gave birth to another dead child, this time a son.

In February 1685, King Charles II died without legitimate issue, and George's father-in-law, the Roman Catholic Duke of York, became king as James II in England and Ireland and James VII in Scotland. George was appointed to the Privy Council and invited to attend Cabinet meetings, although he had no power to alter or affect decisions. William of Orange refused to attend James's coronation largely because George would take precedence over him. Although they were both sons-in-law of King James, George was also the son and brother of a king and so outranked William, who was an elected stadtholder of a republic.

Anne's older sister Mary had moved to the Netherlands after her marriage to William of Orange. Protestant opposition to James was therefore increasingly focused around Anne and George instead of Mary, who was heir presumptive. The social and political grouping centred on George and Anne was known as the "Cockpit Circle" after their London residence. On 5 November 1688, William invaded England in an action, known as the "Glorious Revolution", which ultimately deposed King James. George was forewarned by the Danish envoy in London, Frederick Gersdorff, that William was assembling an invasion fleet. George informed Gersdorff that James's army was disaffected, and as a result he would refuse any command under James, but only serve as an uncommissioned volunteer. Gersdorff's alternative plan to evacuate George and Anne to Denmark was rejected by George. George accompanied the King's troops to Salisbury in mid-November, but other nobles and their soldiers soon deserted James for William. At each defection, George apparently exclaimed, ""Est-il possible?"" (Is it possible?). He abandoned James on 24 November, and sided with William. "So 'Est-il possible' is gone too", James supposedly remarked. In his memoirs, James dismissed George's defection as trivial, saying the loss of one good trooper was of more consequence, but Gersdorff claimed the defection greatly perturbed the King. The defection of George and other nobles was instrumental in whittling away the King's support. In December, James fled to France, and early the following year William and Mary were declared joint monarchs, with Anne as heir presumptive.

In early April 1689, William assented to a bill naturalizing George as an English subject, and George was created Duke of Cumberland, Earl of Kendal and Baron of Okingham (Wokingham) by the new monarchs. He took his seat in the House of Lords on 20 April 1689, being introduced by the Dukes of Somerset and Ormonde.

The mistrust between George and William was set aside during the revolution of 1688–89 but dogged relations during the latter's reign. George held mortgages on Femern, Tremsbüttel and Steinhorst, Schleswig-Holstein, which he surrendered to the Duke of Holstein as part of the peace of Altona of 1689 negotiated by William between Denmark and Sweden. William agreed to pay George interest and the capital in compensation, but George remained unpaid. During the military campaign against James's supporters in Ireland, George accompanied the Williamite troops at his own expense, but was excluded from command, and was even refused permission to travel in his brother-in-law's coach. Snubbed from the army by William, George sought to join the navy, without rank, but was again thwarted by his brother-in-law. When William's Dutch guards failed to salute George, Anne assumed they were acting under orders. George and Anne retired from court. Some degree of reconciliation was achieved following Queen Mary's sudden and unexpected death from smallpox in 1694, which made Anne heir apparent. In November 1699, William finally recommended that Parliament pay the mortgage debt to George, and in early 1700, the debt was honoured.

By 1700, Anne had been pregnant at least seventeen times; twelve times, she miscarried or gave birth to stillborn children, and two of their five children born alive died within a day. The only one of the couple's children to survive infancy—Prince William, Duke of Gloucester—died in July 1700 at the age of 11. With Gloucester's death, Anne was the only person in the line of succession to the throne, as established by the "Glorious Revolution". To extend the line and secure the Protestant succession, Parliament passed the Act of Settlement 1701, which designated William and Anne's nearest Protestant cousins, the House of Hanover, as the next in line after Anne.

George did not play a senior role in government until his wife Anne succeeded as queen on William's death in 1702. George was the chief mourner at William's funeral. Anne appointed him generalissimo of all English military forces on 17 April, and Lord High Admiral, the official but nominal head of the Royal Navy, on 20 May. Actual power at the Admiralty was held by George Churchill, whose elder brother was John Churchill, 1st Duke of Marlborough, a great friend of Anne's and the captain-general of English land forces. Prince George had known the Churchills for years: another brother Charles Churchill, had been one of his gentlemen of the bedchamber in Denmark, and Marlborough had accompanied George on his journey from Denmark to England for his marriage to Anne in 1683. George's secretary in the 1680s was Colonel Edward Griffith, brother-in-law of the Duchess of Marlborough, who was Anne's close confidante and friend. George followed William III as Captain-General of the Honourable Artillery Company, and was made Lord Warden of the Cinque Ports. Anne failed, however, in her attempts to persuade the States General of the Netherlands to elect her husband captain-general of all Dutch forces, to maintain the unified command of the Maritime Powers that William had held.

Anne obtained a parliamentary allowance of £100,000 a year for George in the event of her death. The bill sped through the House of Commons easily but it was only narrowly passed by the House of Lords. Marlborough supported the bill, but one of the lords against was Marlborough's son-in-law, Charles Spencer, 3rd Earl of Sunderland. Marlborough dissuaded her from asking Parliament to make "her dearly loved husband King Consort".

Generally, during her reign, Anne and her husband spent the winter at Kensington and St James's Palaces, and the summer at Windsor Castle or Hampton Court Palace, where the air was fresher. George had recurrent asthma, and the cleaner air in the country was better for his breathing. They visited the spa town of Bath, Somerset, in mid-1702, on the advice of George's doctors, and again in mid-1703. They occasionally visited Newmarket, Suffolk, to view the horse racing. On one visit, Anne bought George a horse, Leeds, for the vast sum of a thousand guineas.

At the end of 1702, the Occasional Conformity Bill was introduced to Parliament. The bill aimed to disqualify Protestant Dissenters from public office by closing a loophole in the Test Acts, legislation that restricted public office to Anglican conformists. The existing law permitted nonconformists to take office if they took Anglican communion once a year. Anne was in favour of the measure, and forced George to vote for the bill in the House of Lords, even though, being a practising Lutheran, he was an occasional conformist himself. As he cast his vote, he reportedly told an opponent of the bill, "My heart is vid you" . The bill did not gather sufficient parliamentary support and was eventually dropped. The following year, the bill was revived, but Anne withheld support, fearing its reintroduction was a deliberate pretence to cause a quarrel between the two main political groups: the Tories (who supported the bill) and the Whigs (who opposed it). Once again it failed. George never became a member of the Church of England, which was headed by his wife throughout her reign. He remained Lutheran even after her accession, and had his own personal chapel.

In the first years of Anne's reign, the Whigs gained more power and influence at the expense of the Tories. In his capacity as Lord Warden of the Cinque Ports, George held influence in parliamentary boroughs on the south coast of England, which he used to support Whig candidates in the general election of 1705. In that year's election for Speaker of the House of Commons, George and Anne supported a Whig candidate, John Smith. George instructed his secretary, George Clarke, who was a Member of Parliament, to vote for Smith, but Clarke refused, instead supporting the Tory candidate William Bromley. Clarke was sacked, and Smith was elected.

In March and April 1706, George was seriously ill. There was blood in his sputum, but he seemed to recover, although he was too ill to attend a thanksgiving service at St Paul's Cathedral in June for a British victory in the Battle of Ramillies. He missed another thanksgiving service in May 1707, to celebrate the union of England and Scotland, as he was recuperating at Hampton Court.

The Scilly naval disaster of 1707, in which a fleet commanded by Sir Cloudesley Shovell foundered, highlighted mismanagement at the Admiralty, for which George was nominally responsible. Pressure grew to replace Admiral Churchill with someone more dynamic. By October 1708, five powerful politicians, known as the Whig Junto—Lords Somers, Halifax, Orford, Wharton and Sunderland—were clamouring for the removal of both Prince George and Churchill. Marlborough wrote to his brother telling him to resign, but Churchill refused, protected by Prince George.

Amid the political pressure, George was on his deathbed, suffering from severe asthma and dropsy. He died at 1:30 p.m. on 28 October 1708 at Kensington Palace. The Queen was devastated. James Brydges wrote to General Cadogan,

His death has flung the Queen into an unspeakable grief. She never left him till he was dead, but continued kissing him the very moment his breath went out of his body, and 'twas with a great deal of difficulty my Lady Marlborough prevailed upon her to leave him.

Anne wrote to her nephew, Frederick IV of Denmark, "the loss of such a husband, who loved me so dearly and so devotedly, is too crushing for me to be able to bear it as I ought." Anne was desperate to stay at Kensington with the body of her husband, but under pressure from the Duchess of Marlborough, she reluctantly left Kensington for St James's Palace. Anne resented the Duchess's intrusive actions, which included removing a portrait of George from the Queen's bedchamber and then refusing to return it in the belief that it was natural "to avoid seeing of papers or anything that belonged to one that one loved when they were just dead". Anne and the Duchess had been very close, but their friendship had become strained over political differences. The immediate aftermath of George's death damaged their relationship further. He was buried privately at midnight on 13 November in Westminster Abbey.

Anne refused initially to appoint a new Lord High Admiral, and insisted on carrying out the duties of the office herself, without appointing a member of the government to take George's place. She burst into tears on the first occasion she was brought papers to sign in George's stead. Undeterred, the Junto demanded the appointment of Lord Orford, a member of the Junto and one of Prince George's leading critics, as First Lord of the Admiralty. Admiral Churchill retired, and Anne appointed the moderate Tory Lord Pembroke to lead the Admiralty, instead of a Whig. The Junto Whigs Somers and Wharton, however, were appointed to the Cabinet in Pembroke's vacated posts of Lord President of the Council and Lord Lieutenant of Ireland. The Whigs were still dissatisfied, and continued to pressure Pembroke and the Queen. Pembroke resigned after less than a year in office. Another month of arguments followed before the Queen finally consented to put Orford in control of the Admiralty as First Lord in November 1709.

Charles II, Anne's uncle, famously said of Prince George, "I have tried him drunk, and I have tried him sober and there is nothing in him". He was quiet and self-effacing. John Macky thought him "of a familiar, easy disposition with a good sound understanding but modest in showing it ... very fat, loves news, his bottle & the Queen." In making fun of George's asthma, Lord Mulgrave said the Prince was forced to breathe hard in case people mistook him for dead and buried him. By the time of Queen Victoria, George had a reputation as a dullard, and was the target of disdain. Victoria hoped her own husband, Prince Albert, would never fill the "subordinate part played by the very stupid and insignificant husband of Queen Anne". In the 1930s, Winston Churchill said he "mattered very little", except to Anne.

He had little impact on the running of the navy, but he was interested enough in navigation and welfare at sea to sponsor the publication of John Flamsteed's "Observations" in 1704. He was not one of the most colourful political characters of his day—he was content to spend his time building model ships—but he was a loyal and supportive husband to Queen Anne. Their marriage was a devoted, loving and faithful one, though beset by personal tragedy.

The previous husband of a British queen regnant, William of Orange, had become king, refusing to take a subordinate rank to Mary. William and Mary had exemplified the traditional gender roles of seventeenth-century Europe: Mary was the dutiful wife and William held the power. George and Anne, however, reversed the roles: George was the dutiful husband and it was Anne who exercised the royal prerogatives. William had assumed incorrectly that George would use his marriage to Anne as a means of building a separate power base in Britain, but George never challenged his wife's authority and never strove to accrue influence. Anne occasionally used the image of wifely virtue to escape unpalatable situations by claiming, as a woman, she knew "nothing except what the prince tells me", but it was an artifice. Husbands had a legal right to their wife's property, and it was argued that it was unnatural and against the church's teachings for a man to be subject to his wife. George made no such claim or demand; he was content to remain a prince and duke. "I am her Majesty's subject", he said, "I shall do naught but what she commands me." In the words of historian Anne Somerset, "the fact that Prince George was widely regarded as a nonentity helped reconcile people to his anomalous status, and so, almost by accident, George achieved a major advance for feminism." Winston Churchill wrote that he

was a fine-looking man, tall, blond, and good-natured ... He was neither clever nor learned—a simple, normal man without envy or ambition, and disposed by remarkable appetite and thirst for all the pleasures of the table. Charles's well-known verdict ... does not do justice to the homely virtues and unfailing good-humour of his staid and trustworthy character.

The Prince of Denmark's March by Jeremiah Clarke was written in his honour, and Prince George's County, Maryland, was named after him in 1696. Portraits by Sir Godfrey Kneller are at the National Maritime Museum in Greenwich, Drumlanrig Castle in Dumfriesshire, and (in a double portrait with George Clarke) All Souls College, Oxford. Portraits in Denmark include one by Willem Wissing in the Reedtz-Thott collection and one by Karel van Mander in the national collection at Frederiksborg Palace.



The royal coat of arms of Denmark with a label of three points Argent, each with three Ermine points. The whole surmounted by a crown of a prince of Denmark. His crest was "out of a coronet Or, a demi-lion rampant guardant Azure, crowned of the first".




</doc>
<doc id="322239" url="https://en.wikipedia.org/wiki?curid=322239" title="European hare">
European hare

The European hare ("Lepus europaeus"), also known as the brown hare, is a species of hare native to Europe and parts of Asia. It is among the largest hare species and is adapted to temperate, open country. Hares are herbivorous and feed mainly on grasses and herbs, supplementing these with twigs, buds, bark and field crops, particularly in winter. Their natural predators include large birds of prey, canids and felids. They rely on high-speed endurance running to escape predation, having long, powerful limbs and large nostrils.

Generally nocturnal and shy in nature, hares change their behaviour in the spring, when they can be seen in broad daylight chasing one another around in fields. During this spring frenzy, they sometimes strike one another with their paws ("boxing"). This is usually not competition between males, but a female hitting a male, either to show she is not yet ready to mate or as a test of his determination. The female nests in a depression on the surface of the ground rather than in a burrow, and the young are active as soon as they are born. Litters may consist of three or four young and a female can bear three litters a year, with hares living for up to twelve years. The breeding season lasts from January to August.

The European hare is listed as being of least concern by the International Union for Conservation of Nature because it has a wide range and is moderately abundant. However, populations have been declining in mainland Europe since the 1960s, at least partly due to changes in farming practices. The hare has been hunted across Europe for centuries, with more than five million being shot each year; in Britain, it has traditionally been hunted by beagling and hare coursing, but these field sports are now illegal. The hare has been a traditional symbol of fertility and reproduction in some cultures, and its courtship behaviour in the spring inspired the English idiom "mad as a March hare".

The European hare was first described in 1778 by German zoologist Peter Simon Pallas. It shares the genus "Lepus" (Latin for "hare") with 31 other hare and jackrabbit species, jackrabbits being the name given to some species of hare native to North America. They are distinguished from other leporids (hares and rabbits) by their longer legs, wider nostrils and active (precocial) young. The Corsican hare, broom hare and Granada hare were at one time considered to be subspecies of the European hare, but DNA sequencing and morphological analysis support their status as separate species.

There is some debate as to whether the European hare and the Cape hare are the same species. A 2005 nuclear gene pool study suggested that they are, but a 2006 study of the mitochondrial DNA of these same animals concluded that they had diverged sufficiently widely to be considered separate species. A 2008 study claims that in the case of "Lepus" species, with their rapid evolution, species designation cannot be based solely on mtDNA but should also include an examination of the nuclear gene pool. It is possible that the genetic differences between the European and Cape hare are due to geographic separation rather than actual divergence. It has been speculated that in the Near East, hare populations are intergrading and experiencing gene flow. Another 2008 study suggests that more research is needed before a conclusion is reached as to whether a species complex exists; the European hare remains classified as a single species until further data contradicts this assumption.

Cladogenetic analysis suggests that European hares survived the last glacial period during the Pleistocene via refugia in southern Europe (Italian peninsula and Balkans) and Asia Minor. Subsequent colonisations of Central Europe appear to have been initiated by human-caused environmental changes. Genetic diversity in current populations is high with no signs of inbreeding. Gene flow appears to be biased towards males, but overall populations are matrilineally structured. There appears to be a particularly large degree of genetic diversity in hares in the North Rhine-Westphalia region of Germany. It is however possible that restricted gene flow could reduce genetic diversity within populations that become isolated.

Historically, up to 30 subspecies of European hare have been described, although their status has been disputed. These subspecies have been distinguished by differences in pelage colouration, body size, external body measurements, skull morphology and tooth shape.

Sixteen subspecies are listed in the IUCN red book, following Hoffmann and Smith (2005): 
Twenty-nine subspecies of "very variable status" are listed by Chapman and Flux in their book on lagomorphs, including the subspecies above (with the exceptions of "L. e. connori", "L. e. creticus", "L. e. cyprius", "L. e. judeae", "L. e. rhodius", and "L. e. syriacus") and additionally:
The European hare, like other members of the family Leporidae, is a fast-running terrestrial mammal; it has eyes set high on the sides of its head, long ears and a flexible neck. Its teeth grow continuously, the first incisors being modified for gnawing while the second incisors are peg-like and non-functional. There is a gap (diastema) between the incisors and the cheek teeth, the latter being adapted for grinding coarse plant material. The dental formula is 2/1, 0/0, 3/2, 3/3. The dark limb musculature of hares is adapted for high-speed endurance running in open country. By contrast, cottontail rabbits are built for short bursts of speed in more vegetated habitats. Other adaptions for high speed running in hares include wider nostrils and larger hearts. In comparison to the European rabbit, the hare has a proportionally smaller stomach and caecum.

This hare is one of the largest of the lagomorphs. Its head and body length can range from with a tail length of . The body mass is typically between . The hare's elongated ears range from from the notch to tip. It also has long hind feet that have a length of between . The skull has nasal bones that are short, but broad and heavy. The supraorbital ridge has well-developed anterior and posterior lobes and the lacrimal bone projects prominently from the anterior wall of the orbit.

The fur colour is grizzled yellow-brown on the back; rufous on the shoulders, legs, neck and throat; white on the underside and black on the tail and ear tips. The fur on the back is typically longer and more curled than on the rest of the body. The European hare's fur does not turn completely white in the winter as is the case with some other members of the genus, although the sides of the head and base of the ears do develop white areas and the hip and rump region may gain some grey.

European hares are native to much of continental Europe and part of Asia. Their range extends from northern Spain to southern Scandinavia, eastern Europe, and northern parts of Western and Central Asia. They have been extending their range into Siberia. They may have been introduced to Britain by the Romans (circa 2000 years ago) as there are no records of them from earlier sites. Undocumented introductions probably occurred in some Mediterranean Islands. They have also been introduced, mostly as game animals, to North America (in Ontario and New York State, and unsuccessfully in Pennsylvania, Massachusetts, and Connecticut), South America (Brazil, Chile, Argentina, Uruguay, Paraguay, Bolivia, Peru and the Falkland Islands), Australia, both islands of New Zealand and the south Pacific coast of Russia.

Hares primarily live in open fields with scattered brush for shelter. They are very adaptable and thrive in mixed farmland. According to a study done in the Czech Republic, the mean hare densities were highest at altitudes below , 40 to 60 days of annual snow cover, of annual precipitation, and a mean annual air temperature of around . With regards to climate, the study found that hare densities were highest in "warm and dry districts with mild winters". In Poland, hares are most abundant in areas with few forest edges, perhaps because foxes can use these for cover. They require cover, such as hedges, ditches and permanent cover areas, because these habitats supply the varied diet they require, and are found at lower densities in large open fields. Intensive cultivation of the land results in greater mortality of young hares (leverets).

In the United Kingdom, hares are seen most frequently on arable farms, especially those with fallow land, wheat and sugar beet crops. In mainly grass farms their numbers are raised when there are improved pastures, some arable crops and patches of woodland. They are seen less frequently where foxes are abundant or where there are many buzzards. They also seem to be fewer in number in areas with high European rabbit populations, although there appears to be little interaction between the two species and no aggression. Although hares are shot as game when they are plentiful, this is a self-limiting activity and is less likely to occur in localities where they are scarce.

Hares are primarily nocturnal and spend a third of their time foraging. During daytime, a hare hides in a depression in the ground called a "form" where it is partially hidden. Hares can run at and when confronted by predators they rely on outrunning them in the open. They are generally thought of as asocial but can be seen in both large and small groups. They do not appear to be territorial, living in shared home ranges of around . Hares communicate with each other by a variety of visual signals. To show interest they raise their ears, while lowering the ears warns others to keep away. When challenging a conspecific, a hare thumps its front feet; the hind feet are used to warn others of a predator. A hare squeals when hurt or scared and a female makes "guttural" calls to attract her young. Hares can live for as long as twelve years.

European hares are primarily herbivorous. They may forage for wild grasses and weeds but with the intensification of agriculture, they have taken to feeding on crops when preferred foods are not available. During the spring and summer, they feed on soy, clover and corn poppy as well as grasses and herbs. During autumn and winter, they primarily choose winter wheat, and are also attracted to piles of sugar beet and carrots provided for them by hunters. They also eat twigs, buds and the bark of shrubs and young fruit trees during winter. Cereal crops are usually avoided when other more attractive foods are available, the species appearing to prefer high energy foodstuffs over crude fibre. When eating twigs, hares strip off the bark to access the vascular tissues which store soluble carbohydrates. Compared to the European rabbit, food passes through the gut more rapidly in the hare, although digestion rates are similar. They sometimes eat their own green, faecal pellets to recover undigested proteins and vitamins. Two to three adult hares can eat more food than a single sheep.

European hares forage in groups. Group feeding is beneficial as individuals can spend more time feeding knowing that other hares are being vigilant. Nevertheless, the distribution of food affects these benefits. When food is well-spaced, all hares are able to access it. When food is clumped together, only dominant hares can access it. In small gatherings, dominants are more successful in defending food, but as more individuals join in, they must spend more time driving off others. The larger the group, the less time dominant individuals have in which to eat. Meanwhile, the subordinates can access the food while the dominants are distracted. As such, when in groups, all individuals fare worse when food is clumped as opposed to when it is widely spaced.

European hares have a prolonged breeding season which lasts from January to August. Females, or does, can be found pregnant in all breeding months and males, or bucks, are fertile all year round except during October and November. After this hiatus, the size and activity of the males' testes increase, signalling the start of a new reproductive cycle. This continues through December, January and February when the reproductive tract gains back its functionality. Matings start before ovulation occurs and the first pregnancies of the year often result in a single foetus, with pregnancy failures being common. Peak reproductive activity occurs in March and April, when all females may be pregnant, the majority with three or more foetuses.

The mating system of the hare has been described as both polygynous (single males mating with multiple females) and promiscuous. Females have six-weekly reproductive cycles and are receptive for only a few hours at a time, making competition among local bucks intense. At the height of the breeding season, this phenomenon is known as "March madness", when the normally nocturnal bucks are forced to be active in the daytime. In addition to dominant animals subduing subordinates, the female fights off her numerous suitors if she is not ready to mate. Fights can be vicious and can leave numerous scars on the ears. In these encounters, hares stand upright and attack each other with their paws, a practice known as "boxing", and this activity is usually between a female and a male and not between competing males as was previously believed. When a doe is ready to mate, she runs across the countryside, starting a chase that tests the stamina of the following males. When only the fittest male remains, the female stops and allows him to copulate. Female fertility continues through May, June and July, but testosterone production decreases in males and sexual behaviour becomes less overt. Litter sizes decrease as the breeding season draws to a close with no pregnancies occurring after August. The testes of males begin to regress and sperm production ends in September.

Does give birth in hollow depressions in the ground. An individual female may have three litters in a year with a 41- to 42-day gestation period. The young have an average weigh of around at birth. The leverets are fully furred and are precocial, being ready to leave the nest soon after they are born, an adaptation to the lack of physical protection relative to that afforded by a burrow. Leverets disperse during the day and come together in the evening close to where they were born. Their mother visits them for nursing soon after sunset; the young suckle for around five minutes, urinating while they do so, with the doe licking up the fluid. She then leaps away so as not to leave an olfactory trail, and the leverets disperse once more. Young can eat solid food after two weeks and are weaned when they are four weeks old. While young of either sex commonly explore their surroundings, natal dispersal tends to be greater in males. Sexual maturity occurs at seven or eight months for females and six months for males.

European hares are large leporids and adults can only be tackled by large predators such as canids, felids and the largest birds of prey. In Poland it was found that the consumption of hares by foxes was at its highest during spring, when the availability of small animal prey was low; at this time of year, hares may constitute up to 50% of the biomass eaten by foxes, with 50% of the mortality of adult hares being caused by their predation. In Scandinavia, a natural epizootic of sarcoptic mange which reduced the population of red foxes dramatically, resulted in an increase in the number of European hares, which returned to previous levels when the numbers of foxes subsequently increased. The golden eagle preys on the European hare in the Alps, the Carpathians, the Apennines and northern Spain. In North America, foxes and coyotes are probably the most common predators, with bobcats and lynx also preying on them in more remote locations.

European hares have both external and internal parasites. One study found that 54% of animals in Slovakia were parasitised by nematodes and over 90% by coccidia. In Australia, European hares were reported as being infected by four species of nematode, six of coccidian, several liver flukes and two canine tapeworms. They were also found to host rabbit fleas ("Spilopsyllus cuniculi"), stickfast fleas ("Echidnophaga myrmecobii"), lice ("Haemodipsus setoni" and "H. lyriocephalus"), and mites ("Leporacarus gibbus").

European brown hare syndrome (EBHS) is a disease caused by a calicivirus similar to that causing rabbit haemorrhagic disease (RHS) and can similarly be fatal, but cross infection between the two mammal species does not occur. Other threats to the hare are pasteurellosis, yersiniosis (pseudo-tuberculosis), coccidiosis and tularaemia, which are the principal sources of mortality.

In October 2018, it was reported that a mutated form of the myxomatosis virus may have jumped to hares in the UK. Normally rare in hares, a significant die-off from the virus has also occurred in Spain.

In Europe, the hare has been a symbol of sex and fertility since at least Ancient Greece. The Greeks associated it with the gods Dionysus, Aphrodite and Artemis as well as with satyrs and cupids. The Christian Church connected the hare with lustfulness and homosexuality, but also associated it with the persecution of the church because of the way it was commonly hunted.

In Northern Europe, Easter imagery often involves hares or rabbits. Citing folk Easter customs in Leicestershire, England, where "the profits of the land called Harecrop Leys were applied to providing a meal which was thrown on the ground at the 'Hare-pie Bank'", the 19th-century scholar Charles Isaac Elton proposed a possible connection between these customs and the worship of Ēostre. In his 19th-century study of the hare in folk custom and mythology, Charles J. Billson cites folk customs involving the hare around Easter in Northern Europe, and argues that the hare was probably a sacred animal in prehistoric Britain's festival of springtime. Observation of the hare's springtime mating behaviour led to the popular English idiom "mad as a March hare", with similar phrases from the sixteenth century writings of John Skelton and Sir Thomas More onwards. The mad hare reappears in "Alice's Adventures in Wonderland" by Lewis Carroll, in which Alice participates in a crazy tea party with the March Hare and the Mad Hatter.

Any connection of the hare to Ēostre is doubtful. John Andrew Boyle cites an etymology dictionary by A. Ernout and A. Meillet, who wrote that the lights of Ēostre were carried by hares, that Ēostre represented spring fecundity, love and sexual pleasure. Boyle responds that almost nothing is known about Ēostre, and that the authors had seemingly accepted the identification of Ēostre with the Norse goddess Freyja, but that the hare is not associated with Freyja either. Boyle adds that "when the authors speak of the hare as the 'companion of Aphrodite and of satyrs and cupids' and 'in the Middle Ages [the hare] appears beside the figure of [mythological] Luxuria', they are on much surer ground."

The hare is a character in some fables, such as "The Tortoise and the Hare" of Aesop. The story was annexed to a philosophical problem by Zeno of Elea, who created a set of paradoxes to support Parmenides' attack on the idea of continuous motion, as each time the hare (or the hero Achilles) moves to where the tortoise was, the tortoise moves just a little further away.
The German Renaissance artist Albrecht Dürer realistically depicted a hare in his 1502 watercolour painting "Young Hare".

Across Europe, over five million European hares are shot each year, making it probably the most important game mammal on the continent. This popularity has threatened regional varieties such as those of France and Denmark, through large-scale importing of hares from Eastern European countries such as Hungary. Hares have traditionally been hunted in Britain by beagling and hare coursing. In beagling, the hare is hunted with a pack of small hunting dogs, beagles, followed by the human hunters on foot. In Britain, the 2004 Hunting Act banned hunting of hares with dogs, so the 60 beagle packs now use artificial "trails", or may legally continue to hunt rabbits. Hare coursing with greyhounds was once an aristocratic pursuit, forbidden to lower social classes. More recently, informal hare coursing became a lower class activity and was conducted without the landowner's permission; it is also now illegal.

Hare is traditionally cooked by jugging: a whole hare is cut into pieces, marinated and cooked slowly with red wine and juniper berries in a tall jug that stands in a pan of water. It is traditionally served with (or briefly cooked with) the hare's blood and port wine. Hare can also be cooked in a casserole. The meat is darker and more strongly flavoured than that of rabbits. Young hares can be roasted; the meat of older hares becomes too tough for roasting, and may be slow-cooked.

The European hare has a wide range across Europe and western Asia and has been introduced to a number of other countries around the globe, often as a game species. In general it is considered moderately abundant in its native range, but declines in populations have been noted in many areas since the 1960s. These have been associated with the intensification of agricultural practices. The hare is an adaptable species and can move into new habitats, but it thrives best when there is an availability of a wide variety of weeds and other herbs to supplement its main diet of grasses. The hare is considered a pest in some areas; it is more likely to damage crops and young trees in winter when there are not enough alternative foodstuffs available.

The International Union for Conservation of Nature has evaluated the European hare's conservation status as being of least concern. However, at low population densities, hares are vulnerable to local extinctions as the available gene pool declines, making inbreeding more likely. This is the case in northern Spain and in Greece, where the restocking by hares brought from outside the region has been identified as a threat to regional gene pools. To counteract this, a captive breeding program has been implemented in Spain, and the relocation of some individuals from one location to another has increased genetic variety. The Bern Convention lists the hare under Appendix III as a protected species. Several countries, including Norway, Germany, Austria and Switzerland, have placed the species on their Red Lists as "near threatened" or "threatened".



</doc>
<doc id="322298" url="https://en.wikipedia.org/wiki?curid=322298" title="Battle of Quebec (1775)">
Battle of Quebec (1775)

The Battle of Quebec () was fought on December 31, 1775, between American Continental Army forces and the British defenders of Quebec City early in the American Revolutionary War. The battle was the first major defeat of the war for the Americans, and it came with heavy losses. General Richard Montgomery was killed, Benedict Arnold was wounded, and Daniel Morgan and more than 400 men were taken prisoner. The city's garrison, a motley assortment of regular troops and militia led by Quebec's provincial governor, General Guy Carleton, suffered a small number of casualties.

Montgomery's army had captured Montreal on November 13, and early in December they joined a force led by Arnold, whose men had made an arduous trek through the wilderness of northern New England. Governor Carleton had escaped from Montreal to Quebec, the Americans' next objective, and last-minute reinforcements arrived to bolster the city's limited defenses before the attacking force's arrival. Concerned that expiring enlistments would reduce his force, Montgomery made the end-of-year attack in a blinding snowstorm to conceal his army's movements. The plan was for separate forces led by Montgomery and Arnold to converge in the lower city before scaling the walls protecting the upper city. Montgomery's force turned back after he was killed by cannon fire early in the battle, but Arnold's force penetrated further into the lower city. Arnold was injured early in the attack, and Morgan led the assault in his place before he became trapped in the lower city and was forced to surrender. Arnold and the Americans maintained an ineffectual blockade of the city until spring, when British reinforcements arrived.

Shortly after the American Revolutionary War broke out in April 1775, a small enterprising force led by Ethan Allen and Benedict Arnold captured the key Fort Ticonderoga on May 10. Arnold followed up the capture with a raid on Fort Saint-Jean not far from Montreal, alarming the British leadership there.

These actions stimulated both British and rebel leaders to consider the possibility of an invasion of the Province of Quebec by the rebellious forces of the Second Continental Congress, and Quebec's governor, General Guy Carleton, began mobilizing the provincial defenses. The British forces in Canada consisted of three regiments, with the 8th Regiment holding various forts around the Great Lakes and the 7th and 26th regiments guarding the St. Lawrence river valley. Apart from these regiments, the only forces available to the Crown were about 15,000 men of the militia and the 8,500 or so warriors from the various Indian tribes in the northern district of the Department of Indian Affairs. The largely "Canadien" militia and many of the Indian tribes were regarded as lukewarm in their loyalty to the Crown.

Both the Americans and the British misunderstood the nature of "Canadien" (as French Canadians were then known) society. The feudal nature of "Canadien" society with the "seigneurs" and the Catholic Church owning the land led the British to assume the "habitants" – as the tenant farmers who made up the vast majority of Quebec's population were known – would deferentially obey their social superiors while the Americans believed that the "habitants" would welcome them as liberators from their feudal society. In fact, the "habitants", despite being tenant farmers, tended to display many of the same traits displayed by the farmers in the 13 colonies who mostly owned their land, being described variously as individualistic, stubborn, and spirited together with a tendency to be rude and disrespectful of authority figures if their actions were seen as unjust. Most of the "habitants" wanted to be neutral in the struggle between Congress vs. the Crown, just wanting to live their lives in peace. Carleton's romanticized view of "Canadien" society led him to exaggerate the willingness of the "habitants" to obey the "seigneurs" as he failed to understand that the "habitants" would only fight for a cause that they saw as being in their own interests. A large number of the "Canadiens" still clung to the hope that one day Louis XVI would reclaim his kingdom's lost colony of New France, but until then, they wanted to be left alone.

The memory of Pontiac's War in 1763 had made most of the Indians living in the Ohio River valley, the Great Lakes and the Mississippi River valley distrustful of all whites, and most of the Indians in the region had no desire to fight for either Congress or the Crown. Only the Haudenosaunee, or Iroquois, living in their homeland of Kaniekeh (modern upstate New York) were regarded as willing to fight for the Crown, and even then some of the Six Nations like the Oneida and the Tuscarora were already negotiating with the Americans. The Catholic Haudenosaunee living outside of Montreal—the so-called Seven Nations of Canada—were traditionally allies of the French and their loyalty to the British Crown was felt to be very shallow. Both Arnold and Allen argued to Congress that the British forces holding Canada were weak, that the "Canadiens" would welcome the Americans as liberators and an invasion would require only 2, 000 men. Taking Canada would eliminate any possibility of the British using it as a base to invade New England and New York.
After first rejecting the idea of an attack on Quebec, the Congress authorized the Continental Army's commander of its Northern Department, Major General Philip Schuyler, to invade the province if he felt it necessary. On 27 June 1775 approval for an invasion of Canada was given to Schuyler. As part of an American propaganda offensive, letters from Congress and the New York Provincial Assembly were circulated throughout the province, promising liberation from their oppressive government. Benedict Arnold, passed over for command of the expedition, convinced General George Washington to authorize a second expedition through the wilderness of what is now the state of Maine directly to Quebec City, capital of the province. The plan approved by Congress called for a two-pronged attack with 3,000 men under Schuyler going via Lake Champlain and the Richelieu River valley to take Montreal while 1,050 men under Arnold would march up the Kennebec River valley, over the Height of Land and then down the Chaudière River valley to take Quebec City.

The Continental Army began moving into Quebec in September 1775. Richard Montgomery, heading the American vanguard took Ile-aux-Noix on 2 September 1775. Its goal, as stated in a proclamation by General Schuyler, was to "drive away, if possible, the troops of Great Britain" that "under the orders of a despotic ministry ... aim to subject their fellow-citizens and brethren to the yoke of a hard slavery." On 16 September 1775, the sickly Schuyler handed over the command of his army to Montgomery. Brigadier General Richard Montgomery led the force from Ticonderoga and Crown Point up Lake Champlain, successfully besieging Fort St. Jean, and capturing Montreal on November 13. Arnold led a force of 1,100 men from Cambridge, Massachusetts on the expedition through Maine towards Quebec shortly after Montgomery's departure from Ticonderoga.

One significant expectation of the American advance into Quebec was that the large French Catholic Canadien population of the province and city would rise against British rule. Since the British took control of the province, during the French and Indian War in 1760, there had been difficulties and disagreements between the local French Catholics and the Protestant English-speaking British military and civilian administrations. However, these tensions had been eased by the passage of the Quebec Act of 1774, which restored land and many civil rights to the Canadiens (an act which had been condemned by the thirteen rebelling colonies). The English-speaking "Old Subjects" living in Montreal and Quebec City (in contrast to the French-speaking "New Subjects") came mostly from Scotland or the 13 colonies, and they tried to dominate the Quebec colony both politically and economically, clashing with the long-established "Canadien" elite. James Murray, the first Governor of Quebec, had described the "Old Subject" businessmen who arrived in his colony as "adventurers of mean education...with their fortunes to make and little Sollicitous about the means". Carleton for his part felt the complaints by the "Canadiens" about the "Old Subjects" as greedy and unscrupulous businessmen were largely merited. As a member of Ireland's Protestant Ascendancy, Carleton found much to admire in Quebec which reminded him of his native Ireland, as both places were rural, deeply conservative Catholic societies. The majority of Quebec's French inhabitants chose not to play an active role in the American campaign, in large part because, encouraged by their clergy, they had come to accept British rule with its backing of the Catholic Church and preservation of French culture.

Many of the "Old Subjects" saw the Quebec Act as a betrayal by the Crown as it granted equality to the "Canadiens", most notably by allowing Roman Catholic men to vote and hold office, which ended the hopes of the "Old Subjects" to dominate Quebec politically. Ironically, many of the English-speaking and Protestant "Old Subjects" were the ones who served as "fifth column" for the Americans rather than the French-speaking Roman Catholic "New Subjects" as the many "Old Subject" businessmen had decided that an American victory was the their best hope of establishing Anglo-Protestant supremacy in Quebec. Prominent "Old Subject" businessmen such as Thomas Walker, James Price, William Heywood and Joseph Bindon in Montreal together with John McCord, Zachary Macaulay, Edward Antill, John Dyer Mercier and Udnay Hay in Quebec City all worked for an American victory by providing intelligence and later money for the Continental Army. Much of the American assessment that Canada could be easily taken was based on letters from "Old Subject" businessmen asking for the Americans to liberate them from the rule of the Crown which given had the "Canadiens" equality, and somewhat contradictory also claiming that the "Canadiens" would rise up against the British if the American entered Quebec.

General Carleton had begun preparing the province's defenses immediately on learning of Arnold's raid on St. Jean. On 9 June 1775 Carleton proclaimed martial law and called out the militia. At Montreal, Carleton found that there were six hundred men of the 7th Foot Regiment fit for duty, but he complained that there were no warships on the St. Lawrence, the forts around Montreal in a state of disrepair and through the "seigneury" and the Catholic Church were loyal to the Crown, most of the "habitants" appeared indifferent. Although Carleton concentrated most of his modest force at Fort St. Jean, he left small garrisons of British regular army troops at Montreal and Quebec. To provide more manpower, Carleton raised the Royal Highland Emigrants Regiment, whom he recruited from the Scots immigrants in Quebec. The commander of the Royal Highland Emigrants, Allan Maclean, was a Highlander who may or may not have fought for the Jacobites in the rebellion of 1745, but turned out to be Carleton's most aggressive subordinate in the campaign of 1775–76. On 26 July 1775, Carleton met Guy Johnson, the superintendent of the northern district of the Indian Department together with an Indian Department official, Daniel Claus, and a Mohawk war chief Joseph Brant. Johnson, Claus and Brant had brought with them some 1, 600 warriors whom they proposed to lead into a raid into New England, arguing that this was the best way of keeping the Americans engaged and out of Canada. Carleton declined the offer and ordered most of the Indians home, saying he did not want the Indians involved in this war, whom he regarded as savages who he believed would commit all sorts of atrocities against the white population of New England. Despite his dislike of Indians, whom he considered to be undisciplined and prone to brutality, Carleton employed them at least 50 Indians as scouts to monitor the American forces as no one else could operate in the wilderness as scouts as well as the Indians could.

Carleton followed the American invasion's progress, occasionally receiving intercepted communications between Montgomery and Arnold. Lieutenant Governor Hector Cramahé, in charge of Quebec's defenses while Carleton was in Montreal, organized a militia force of several hundred to defend the town in September. He pessimistically thought they were "not much to be depended on", estimating that only half were reliable. Cramahé also made numerous requests for military reinforcements to the military leadership in Boston, but each of these came to nought. Several troop ships were blown off course and ended up in New York, and Vice Admiral Samuel Graves, the commander of the fleet in Boston, refused to release ships to transport troops from there to Quebec because the approaching winter would close the Saint Lawrence River. On 25 September 1775 an attempt by Ethan Allen to take Montreal in a surprise attack as the American sympathizer and prominent merchant Thomas Walker had promised he would open the city's gates was foiled. A mixed force of 34 men from the 26th Foot regiment, 120 "Canadien" volunteers and 80 "Old Subject" volunteers, 20 Indian Department employees and six Indians under the command of Major John Campbell stopped Allen's force on the outskirts of Montreal, killing 5 of the Americans and capturing 36. The victory caused 1, 200 "Canadiens" to finally respond to the militia summons, but Carleton, knowing only a large American force had entered Canada, chose to stay on the defensive under the grounds he was probably outnumbered. On 5 October, Carleton ordered Walker arrested on charges of high treason, which led to a shoot-out that left two soldiers wounded, Walker's house burned down, and Walker captured. On 15 October 1775, heavy guns arrived from Fort Ticonderoga, which finally allowed the American besiegers to start inflicting damage on Fort St. Jean and on 18 October, the fort at Chambly fell to the Americans.

The attempts of the Americans to recruit "Canadiens" (French-Canadians) for their cause were generally unsuccessful with Jeremy Duggan, an "Old Subject" Quebec City barber who had joined the Americans only recruiting 40 "Canadiens". The Roman Catholic clergy preached loyalty to the Crown, but the unwillingness of Carleton to take the offensive persuaded many "Canadiens" that the British cause was a lost one. Given the American numerical superiority, Carleton had decided to stay on the defensive, a decision which however justified under military grounds, proved to be politically damaging. On 2 November 1775, Montgomery took the Fort St. Jean, which the Americans had been besieging since September, causing Carleton to decide to pull back to Quebec City, which he knew that Arnold was also approaching. On 11 November, the British pulled out of Montreal and on 13 November 1775, the Americans took Montreal. Like Carleton, Montgomery was an Irishmen, and both generals had a certain understanding and respect for "Canadien" society, which was in many ways similar to Irish society, going out of their way to be tactful and polite in their dealings with "Canadiens". Montgomery insisted that his men display "brotherly affection" for the "Canadiens" at all times. However, the man that Montgomery placed in charge of Montreal, Brigadier General David Wooster, together with the newly freed Thomas Walker who served as Wooster's chief political adviser, displayed bigoted anti-Catholic and anti-French views, with Wooster shutting down all the "Mass houses" as he called Catholic churches just before Christmas Eve, a move that deeply offended the "Canadiens". The arbitrary and high-handed behavior of Wooster and Walker in Montreal together with their anti-Catholicism undercut their claims to be promoting "liberty" and did much to turn "Canadien" opinion against their self-proclaimed "liberators".

When definitive word reached Quebec on November 3 that Arnold's march had succeeded and that he was approaching the city, Cramahé began tightening the guard and had all boats removed from the south shore of the Saint Lawrence. Word of Arnold's approach resulted in further militia enlistments, increasing the ranks to 1,200 or more. Two ships arrived on November 3, followed by a third the next day, carrying militia volunteers from St. John's Island and Newfoundland that added about 120 men to the defense. A small convoy under the command of the frigate also arrived that day, from which a number of marines were added to the town's defenses.

On November 10, Lieutenant Colonel Allen Maclean, who had been involved in an attempt to lift the siege at St. Jean, arrived with 200 men of his Royal Highland Emigrants. They had intercepted communications from Arnold to Montgomery near Trois-Rivières, and hurried to Quebec to help with its defense. The arrival of this experienced force boosted the morale of the town militia, and Maclean immediately took charge of the defenses.

In the wake of the fall of Fort St. Jean, Carleton abandoned Montreal and returned to Quebec City by ship, narrowly escaping capture. Upon his arrival on November 19, he immediately took command. Three days later, he issued a proclamation that any able-bodied man in the town who did not take up arms would be assumed to be a rebel or a spy, and would be treated as such. Men not taking up arms were given four days to leave. As a result, about 500 inhabitants (including 200 British and 300 Canadians) joined the defense.

Carleton addressed the weak points of the town's defensive fortifications: he had two log barricades and palisades erected along the Saint Lawrence shoreline, within the area covered by his cannons; he assigned his forces to defensive positions along the walls and the inner defenses; and he made sure his inexperienced militia were under strong leadership.

The British believed that the forbidding landscape of upper Massachusetts (modern Maine) was impassable to a military force, but General Washington felt that the upper Massachusetts could be crossed in about 20 days. Arnold called for 200 bateaux (boats) and for "active woodsmen, well acquainted with bateaux". After recruiting 1,050 volunteers, Arnold departed for Quebec City on 5 September 1775. The men Arnold chose for his expedition were volunteers drawn from New England companies serving in the Siege of Boston. They were formed into two battalions for the expedition; a third battalion was composed of riflemen from Pennsylvania and Virginia under Captain Daniel Morgan's command. After landing in Georgetown on 20 September, Arnold began his voyage up the Kennebec river. Arnold thought it was only 180 miles to Quebec City, but actually the distance was 300 miles and the terrain was far more difficult than he expected.

The trek through the wilderness of Maine was long and difficult with icy rains, dysentery caused by drinking unclean waters, and rivers full of drowned trees all presenting problems. The conditions were wet and cold, and the journey took much longer than either Arnold or Washington had expected. Bad weather and wrecked boats spoiled much of the expedition's food stores, and about 500 men of the original 1,100 turned back or died. Those who turned back, including one of the New England battalions, took many of the remaining provisions with them. The men who continued on were starving by the time they reached the first French settlements in early November. By the time they reached the Chaudière river, Arnold's men were eating their leather shoes and belts, and upon encountering the first "habitant" settlements on 2 November, they were overjoyed to be offered meals of beef, oatmeal and mutton, through they complained that the "Canadiens" charged too well for their food. On 3 November, the frigate HMS "Lizard" arrived in Quebec City with 100 men from Newfoundland. On 8 November, Arnold could see for the first time the walls of Quebec City towering over the St. Lawrence. On November 9, the 600 survivors of Arnold's march from Boston to Quebec arrived at Point Levis, on the south shore of the Saint Lawrence opposite Quebec City. Despite the condition of his troops, Arnold immediately began to gather boats to make a crossing. Arnold was prepared to do so on the night of November 10, but a storm delayed him for three days. An Indian chief greeted Arnold, and agreed to provide him with canoes to cross the St. Lawrence together with some 50 men to serve as guides. On 12 November, MacLean with his Highlanders arrived in Quebec City. Starting about 9 pm on 13 November, the Americans crossed the St. Lawrence in canoes to land at Wolfe's Cove, and by 4 am, about 500 men had crossed over. Once on the other side of the Saint Lawrence, Arnold moved his troops onto the Plains of Abraham, about 1.5 miles (2 km) from the city walls.

The troops approaching Quebec's walls were significantly under-equipped. Arnold had no artillery, each of his men carried only five cartridges, more than 100 muskets were unserviceable, and the men's clothing had been reduced to rags. Despite being outnumbered two to one, Arnold demanded the city's surrender. Both envoys sent were shot at by British cannons, signifying that the demand had been rebuked. At a council of war called by Cramahé on 16 November, MacLean as the most senior military officer present advocated holding out. MacLean stated that Quebec City had a garrison of 1, 178 men and had enough food and firewood for both the garrison and the civilian population to last all through the winter. Arnold concluded that he could not take the city by force, so he blockaded the city on its west side. An inventory ordered by Arnold revealed that over 100 muskets had been so damaged by exposure to the elements during the trek through the wildness that they were now useless. On November 18, the Americans heard a (false) rumor that the British were planning to attack them with 800 men. At a council of war, they decided that the blockade could not be maintained, and Arnold began to move his men upriver to Pointe-aux-Trembles ("Aspen Point") to wait for Montgomery, who had just taken Montreal. Henry Dearborn, who later became U.S. Secretary of War under President Thomas Jefferson, was present at the battle and wrote his famous journal, " The Quebec Expedition", which outlined the long and difficult march to the battle and the events that occurred there.

On December 1, Montgomery arrived at Pointe-aux-Trembles. His force consisted of 300 men from the 1st, 2nd, and 3rd New York regiments, a company of artillery raised by John Lamb, about 200 men recruited by James Livingston for the 1st Canadian Regiment, and another 160 men led by Jacob Brown who were remnants of regiments disbanded due to expiring enlistments. These were supplemented several days later by a few companies detached by Major General David Wooster, whom Montgomery had left in command at Montreal. The artillery Montgomery brought included four cannons and six mortars, and he also brought winter clothing and other supplies for Arnold's men; the clothing and supplies were a prize taken when most of the British ships fleeing Montreal were captured. Arnold was unpopular with his men, and when Montgomery arrived, several of Arnold's captains asked that they be transferred over serving under Montgomery.

The commanders quickly turned towards Quebec, and put the city under siege on December 6. Montgomery sent a personal letter to Carleton demanding the city's surrender, employing a woman as the messenger. Carleton declined the request and burned the letter unread. Montgomery tried again ten days later, with the same result. The besiegers continued to send messages, primarily intended for the populace in the city, describing the situation there as hopeless, and suggesting that conditions would improve if they rose to assist the Americans. Carleton gave the command of his British Army soldiers, the Royal Marines and the Royal Highlanders to MacLean; the sailors to Captain John Hamilton of the Royal Navy; the English-speaking militiamen to Henry Caldwell and the "Canadien" militiamen to Noël Voyer. While the British began to fortify the Lower Town of Quebec City, Montgomery used his five mortars to begin bombarding Quebec City while American riflemen were assigned as snipers to gun down the soldiers patrolling the walls of Quebec City. Many of the enlistments of Montgomery's force expired on 31 December 1775, and despite his efforts to persuade his men to stay on, it was made clear by the Continental Army soldiers that they intended to go home once their enlistments ended. As December advanced, Montgomery was under increasing pressure to take Quebec City before 31 December.
On December 10, the Americans set up their largest battery of artillery from the walls. The frozen ground prevented the Americans from entrenching the artillery, so they fashioned a wall out of snow blocks. This battery was used to fire on the city, but the damage it did was of little consequence. Montgomery realized he was in a very difficult position, because the frozen ground prevented the digging of trenches, and his lack of heavy weapons made it impossible to breach the city's defenses. On 17 December, British cannons knocked out two of Montgomery's mortars, leading him to order the remaining three back. The enlistments of Arnold's men were expiring at the end of the year, and no ammunition was on the way from the colonies. Furthermore, it was very likely that British reinforcements would arrive in the spring, meaning he would either have to act or withdraw. Montgomery believed his only chance to take the city was during a snowstorm at night, when his men could scale the walls undetected. On Christmas Day, Montgomery announced in speech before his army his plans to take Quebec City.

While Montgomery planned the attack on the city, Christophe Pélissier, a Frenchman living near Trois-Rivières, came to see him. Pélissier was a political supporter of the American cause who operated the St. Maurice Ironworks. He and Montgomery discussed the idea of holding a provincial convention to elect representatives to Congress. Pélissier recommended against this until after Quebec City had been taken, as the habitants would not feel free to act in that way until their security was better assured. The two agreed that Pélissier's ironworks would provide munitions (ammunition, cannonballs, and the like) for the siege. This Pélissier did until the Americans retreated in May 1776, at which time he also fled, eventually returning to France.

A snowstorm arrived on the night of December 27, prompting Montgomery to prepare the troops for the attack. However, the storm subsided, and Montgomery called off the assault. That night, a sergeant from Rhode Island deserted, carrying the plan of attack to the British. Montgomery consequently drafted a new plan; this one called for two feints against Quebec's western walls, to be led by Jacob Brown and James Livingston, while two attacks would be mounted against the lower town. Arnold would lead one attack to smash through the defenses at the north end of the Lower town through the Sault au Matelot and Montgomery would follow along the Saint Lawrence south of the Lower Town. The two forces would meet in the lower town and then launch a combined assault on the upper town by scaling its walls, believing that the "Old Subject" merchants living in the Upper Town would force Carleton to surrender upon the Upper Town was entered. Much of the hope behind Montgomery's plan was their either the "Old Subject" merchants would force Carleton to surrender once the Americans entered the city and/or the threat of having the warehouses destroyed would lead to the city's merchants likewise compelling Carleton to surrender. The new plan was revealed only to the senior officers. On the afternoon of 30 December 1775, a "northeaster" storm came from the Atlantic, bringing in a heavy snowfall, and Montgomery knowing that much of his army would be leaving in two days' time, ordered his men to form up for an assault on Quebec City.

A storm broke out on December 30, and Montgomery once again gave orders for the attack. Brown and Livingston led their militia companies to their assigned positions that night: Brown by the Cape Diamond redoubt, and Livingston outside St. John's Gate (). When Brown reached his position between 4 am and 5 am, he fired flares to signal the other forces, and his men and Livingston's began to fire on their respective targets. Montgomery and Arnold, seeing the flares, set off for the lower town.

Montgomery led his men from Wolfe's Cove down the steep, snow-heaped path towards the outer defenses. The storm had turned into a blizzard, making the advance a struggle. As they advanced over the ice-covered rocky ground, the bells of the Notre-Dame-des-Victoires church began to ring, as sentries manning the walls of Quebec City saw the American lanterns in the blizzard, and ringing the church bells was a signal to the militiamen to arm themselves. Montgomery's men eventually arrived at the palisade of the outer defenses, where an advance party of carpenters sawed their way through the wall. Montgomery himself helped saw through the second palisade, and led 50 men down a street towards a two-story building. The building formed part of the city's defenses, and was in fact a blockhouse occupied by 39 Quebec militia and 9 sailors armed with muskets and cannons.

Montgomery unsheathed his sword as he led his men down the street as the blizzard raged. The defenders opened fire at close range, and Montgomery was killed instantly, shot through the head by a burst of grapeshot while most of the men standing beside him were either killed or wounded. The few men of the advance party who survived fled back towards the palisade; only Aaron Burr and a few others escaped unhurt. As the next two most senior officers, John Macpherson and Jacob Cheesemen, were also killed, command was assumed by the deputy quartermaster, Colonel Donald Campbell, who decided it was suicidal to try to advance again. Many of Montgomery's officers were injured in the attack; one of the few remaining uninjured officers led the survivors back to the Plains of Abraham, leaving Montgomery's body behind.

While Montgomery was making his advance, Arnold advanced with his main body towards the barricades of the Sault-au-Matelot at the northern end of the lower town. Leading Arnold's advance were 30 riflemen together with the artillerymen who attached a brass 6-pounder cannon to a sled. Behind them were the rest of the riflemen from Virginia and Pennsylvania, then the Continental Army volunteers from New England, and finally the rearguard consisted of those "Canadiens" and Indians from the Seven Nations of Canada who had decided to join the Americans.

They passed the outer gates and some British gun batteries undetected. However, as the advance party moved around the "Porte du Palais" (Palace Gate) (), heavy fire broke out from the city walls above them. The defenders opened fire with their muskets and hurled grenades down from the walls. The sled carrying the cannon was struck in a snowdrift in an attempt to avoid the hostile fire and was abandoned. The height of the walls made it impossible to return the defenders' fire, therefore Arnold ordered his men to run forward to the docks of Quebec City that were not behind the walls. In the process, the Americans became lost amid the unfamiliar streets of Quebec City and the raging blizzard.

They advanced down a narrow street, where they once again came under fire as they approached a barricade manned by 30 "Canadien" militiamen armed with three light cannons. Arnold had planned to use the cannon he brought with him, but since the gun was lost, he no choice but to order a frontal attack. As he was organizing his men in an attempt to take the barricade, Arnold received a deep wound in the leg from a musket ball that apparently ricocheted, and was carried to the rear after transferring command of his detachment to Daniel Morgan. Morgan, a tough Virginia frontiersman well respected by his men, personally led the assault, scaling a ladder up the barricade and was knocked down on his first attempt. On his second attempt, Morgan made to the top of the barricade, had to roll under one of the cannons to escape the bayonets of the defenders, but the rest of his men followed up. After a few minutes of fighting, the 30 militiamen surrendered while the Americans had lost 1 dead and six wounded.

Under Morgan's command, they captured the barricade, but had difficulty advancing further because of the narrow twisting streets and damp gunpowder, which prevented their muskets from firing. Moreover, despite Morgan's exhortations to advance, his men were afraid of being overpowered by their prisoners and wanted to wait for the rest of the Continental Army force to come up, leading to a 30-minute delay. Morgan and his men holed up in some buildings to dry out their powder and rearm, but they eventually came under increasing fire; Carleton had realized the attacks on the northern gates were feints and began concentrating his forces in the lower town.
Caldwell was speaking with Carleton when he learned of the assault on the "Porte du Palais", and took with him 30 Royal Highland Emigrants and 50 sailors as he headed out to stop the assault. At the second barricade, he found some 200 "Canadien" militiamen under Voyer and a company from the 7th Foot Regiment, who were confused about what was going on, whom he gave his orders to. Caldwell ordered the Royal Highlanders and the militia into the houses while ordering the British soldiers to form a double line behind 12 foot high barricade. As Morgan and his men advanced down the narrow streets of Quebec City, they were confronted by the sailors led by a man named Anderson who demanded their surrender. Morgan in reply shot Anderson dead while his sailors retreated; shouting "Quebec is ours!", Morgan then led a charge down the street. The Royal Highlanders and the militia opened fire from the windows in the houses. Despite the storm of bullets raining down on them, the Americans were able to place ladders against the barricades, but their attempts to scale it were all beaten back. An attempt to outflank the barricade by going through one of the houses led to a savage fight in the house with bayonet against bayonet, but was also repulsed. Under increasing heavy fire, Morgan ordered his men into the houses.

A British force of 500 sallied from the Palace Gate and reoccupied the first barricade, trapping Morgan and his men in the city. Captain George Laws led his 500 men, consisting of Royal Highlanders and sailors out of the Palace Gate, when they encountered an American force under Henry Dearborn who was coming up to aid Morgan. As Dearborn's men had their powder damp, they could not use their muskets and Dearborn and the rest of his men surrendered. Laws then turned against Morgan's group, who proved to be more stubborn. Laws himself was captured, but the attempts of the Americans to break out were blocked. As the fighting continued, the Americans ran out of ammunition and one by one, groups of Continental Army soldiers gave up the fight. With no avenue of retreat and under heavy fire, Morgan and his men surrendered. The battle was over by 10 am. Morgan was the last to surrender and rather than give up his sword to a British officer, he handed it to a Catholic priest who been sent under a flag of truce to ask for his surrender. Finally, Carleton ordered an assault on the battery outside the walls, which was captured, and afterwards the British withdrew back behind the safety of the walls. Found on the American corpses in the snow were paper streamers attached to their hats reading "Liberty or Death!".

This was the first defeat suffered by the Continental Army. Carleton reported 30 Americans killed and 431 taken prisoner, including about two-thirds of Arnold's force. He also wrote that "many perished on the River" attempting to get away. Allan Maclean reported that 20 bodies were recovered in the spring thaw the following May. Arnold reported about 400 missing or captured, and his official report to Congress claimed 60 killed and 300 captured. British casualties were comparatively light. Carleton's initial report to General William Howe mentioned only five killed or wounded, but other witness reports ranged as high as 50. Carleton's official report listed five killed and 14 wounded.

General Montgomery's body was recovered by the British on New Year's Day 1776 and was given a simple military funeral on January 4, paid for by Lieutenant Governor Cramahé. The body was returned to New York in 1818. Together with the losses taken in the battle and the expiring enlistments left Arnold with only 600 men as 1 January 1776 to besiege Quebec City. Arnold asked for David Wooster, commanding the Continental Army force in Montreal to sent him some of his men, but Wooster refused, saying he was afraid of a pro-British uprising if he were to send away any of his forces. An appeal to help for Schuyler led to the reply that he could spare no men as the problem of expiring enlistments led him short of men, and moreover, Guy Johnson had succeeded in persuading some of the Mohawk to fight for the Crown. General Washington complained that the refusal of Congress to offer long-term enlistments or even bounties to those whose enlistments were about to expire was threatening to hobble the rebellion, and led him to consider resigning.

Arnold refused to retreat; despite being outnumbered three to one, the sub-freezing temperature of the winter and the mass departure of his men after their enlistments expired, he laid siege to Quebec. The siege had relatively little effect on the city, which Carleton claimed had enough supplies stockpiled to last until May. Immediately after the battle, Arnold sent Moses Hazen and Edward Antill to Montreal, where they informed General Wooster of the defeat. They then travelled on to Philadelphia to report the defeat to Congress and request support. (Both Hazen and Antill, English-speakers originally from the Thirteen Colonies who had settled in Quebec, went on to serve in the Continental Army for the rest of the war.) In response to their report, Congress ordered reinforcements to be raised and sent north. During the winter months, small companies of men from hastily recruited regiments in New Hampshire, Massachusetts, and Connecticut made their way north to supplement the Continental garrisons at Quebec and Montreal. The journey to Quebec City in the winter left the reinforcements in poor health and many of their weapons unserviceable. Arnold used his remaining artillery to shell Quebec City, which caused some damage, but did little did to weaken Carleton's hold as Arnold only destroyed the homes of civilians. Carleton continued to build new blockhouses and trenches over the course of the winter and cut a trench in the frozen St. Lawrence to prevent an attempt to outflank the walls of Quebec City.

The presence of disease in the camp outside Quebec, especially smallpox, took a significant toll on the besiegers, as did a general lack of provisions. Smallpox ravaged Montgomery and Arnold's forces largely due to exposure to infected civilians released from Quebec. Governor Carleton condoned this practice, realizing it would severely weaken the American siege effort. Carleton is reported to have sent out several prostitutes infected with smallpox who in turn passed it on to the Continental Army. Arnold after using up all his gold could only pay for supplies with paper money, not coin, which proved to be problematic as the "habitants" wanted coins, and increasing the Americans had to take supplies at bayonet point. Together with the news of the anti-Catholic policies carried out by Wooster in Montreal, the requisitions of food and firewood made the besiegers more and more unpopular with the "habitants" who wanted the Americans to go home. In early April, Arnold was replaced by General Wooster, who was himself replaced in late April by General John Thomas.

Governor Carleton, despite appearing to have a significant advantage in manpower, chose not to attack the American camp, and remained within Quebec's walls. Montgomery, in analysing the situation before the battle, had observed that Carleton served under James Wolfe during the 1759 Siege of Quebec, and knew that the French General Louis-Joseph de Montcalm had paid a heavy price for leaving the city's defenses, ultimately losing the city and his life in the Battle of the Plains of Abraham. British General James Murray had also lost a battle outside the city in 1760; Montgomery judged that Carleton was unlikely to repeat their mistakes. On March 14, Jean-Baptiste Chasseur, a miller from the southern shore of the Saint Lawrence, reached Quebec City and informed Carleton there were 200 men on the south side of the river ready to act against the Americans. These men and more were mobilized to make an attack on an American gun battery at Point Levis, but an advance guard of this Loyalist militia was defeated in the March 1776 Battle of Saint-Pierre by a detachment of pro-American local militia. under Major Lewis Dubois On 2 April 1776, a new battery built by the Americans at Point Lévis started to shell Quebec City and ships in the St. Lawrence as the river thawed in the spring.

To rally support in Quebec, Congress sent a three-man commission consisting of Charles Carroll, Samuel Chase and Benjamin Franklin together with a pro-Patriot Catholic priest, Father John Carroll, and Fleury Mesplet, a French printer living in Philadelphia. On 29 April 1776, the commission arrived in Montreal and attempted to undo the damage done by Wooster, but found that public opinion had turned against them. Several "Canadien" leaders pointedly asked the commissioners that if the rebellion was justified because of "no taxation without representation", then why had Wooster imposed taxes on them in the name of Congress without their representation in Congress. Father Carroll talked extensively with his fellow Catholic priests in Quebec in a bid to win their support, but reported that the majority were satisfied with the Quebec Act, and were unwilling to support the rebellion. Through the Congressional commissioners rescinded Wooster's anti-Catholic decisions and allowed Catholic churches to re-open, by then the political damage could not be repaired.
When General Thomas arrived, the conditions in the camp led him to conclude that the siege was impossible to maintain, and he began preparing to retreat. On 3 May, the Americans sent a fireship down the St. Lawrence in an attempt to burn down the Queen's Wharf, but British artillery sank the fireship. The arrival on May 6 of a small British fleet carrying 200 regulars (the vanguard of a much larger invasion force), accelerated the American preparations to depart. Arriving in Quebec City were the frigates HMS "Surprise" and HMS "Isis" carrying the 29th Foot Regiment and Royal Marines. The retreat was turned into a near rout when Carleton marched these fresh forces, along with most of his existing garrison, out of the city to face the disorganized Americans. The American forces, ravaged by smallpox (which claimed General Thomas during the retreat), eventually retreated all the way back to Fort Ticonderoga. Carleton then launched a counteroffensive to regain the forts on Lake Champlain. Although he defeated the American fleet in the Battle of Valcour Island and regained control of the lake, the rear guard defense managed by Benedict Arnold prevented further action to capture Ticonderoga or Crown Point in 1776.

On May 22, even before the Americans had been completely driven from the province, Carleton ordered a survey to identify the Canadians who had helped the American expedition in and around Quebec City. François Baby, Gabriel-Elzéar Taschereau, and Jenkin Williams travelled the province and counted the Canadians who actively provided such help; they determined that 757 had done so. Carleton was somewhat lenient with minor offenders, and even freed a number of more serious offenders on the promise of good behaviour. However, once the Americans had been driven from the province, measures against supporters of the American cause became harsher, with a frequent punishment being forced labour to repair infrastructure destroyed by the Americans during their retreat. These measures had the effect of minimizing the public expression of support for the Americans for the rest of the war.

Between May 6 and June 1, 1776, nearly 40 British ships arrived at Quebec City. They carried more than 9,000 soldiers under the command of General John Burgoyne, including about 4,000 German auxiliaries from Brunswick and Hesse-Hanau (so-called Hessians) under the command of Baron Friedrich Adolf Riedesel. These forces, some of which having participated in Carleton's counteroffensive, spent the winter of 1776–77 in the province, putting a significant strain on the population, which numbered only about 80,000. Carleton told the "habitants" that the quartering of the British and Brunswick troops was punishment for their "disloyalty" in not coming out in greater numbers when he summoned the militia. The Canadian historian Desmond Morton described Carleton as having "wisely" avoided battle outside of Quebec City in 1775-76, but overall his command in the campaign of 1775–76 was "lack-lustre", which led to John Burgoyne being given command of the invasion of New York in 1777. Many of these troops were deployed in 1777 for Burgoyne's campaign for the Hudson Valley.

Following the American victory at the battle of Saratoga, Congress once again considered invading Canada and in January 1778 voted for another invasion to be commanded by the Marquis de La Fayette. However, La Fayette found the necessary supplies and horses to support an invasion were lacking once he reached Albany and he advised cancelling the operation, advice that Congress accepted in March 1778. The news that the British had strengthened the forts on the border together with the walls of Montreal and of Quebec City meant that an invasion of Canada would require a substantial number of men and resources that were not available owing to operations elsewhere. Quebec City's status as one of the strongest fortified cities in North America meant it would require a massive amount of force to take. The idea of invading Canada continued to be debated in Congress up to 1780, but no decision was ever made. During the peace negotiations in Paris in 1782–83 for ending the American Revolutionary War, the American delegation asked for the cession of Canada (at the time, the term Canada applied only to what is now southern Quebec and southern Ontario) to the United States. As the Americans did not have possession of Canada at the time, the British refused and the American diplomats did not press the point. Had the Americans been victorious at the battle of Quebec, and were still in possession of Canada at the time of the peace negotiations, the American diplomats in Paris might have been more successful in demanding what is now southern Ontario and southern Quebec become part of the United States.

Three current United States Army National Guard units (Company A of the 69th Infantry Regiment, the 181st Infantry Regiment, and the 182nd Infantry) trace their lineage to American units that participated in the Battle of Quebec.


https://www.britishbattles.com/war-of-the-revolution-1775-to-1783/battle-of-quebec-1775/




</doc>
<doc id="322460" url="https://en.wikipedia.org/wiki?curid=322460" title="History of biology">
History of biology

The history of biology traces the study of the living world from ancient to modern times. Although the concept of "biology" as a single coherent field arose in the 19th century, the biological sciences emerged from traditions of medicine and natural history reaching back to ayurveda, ancient Egyptian medicine and the works of Aristotle and Galen in the ancient Greco-Roman world. This ancient work was further developed in the Middle Ages by Muslim physicians and scholars such as Avicenna. During the European Renaissance and early modern period, biological thought was revolutionized in Europe by a renewed interest in empiricism and the discovery of many novel organisms. Prominent in this movement were Vesalius and Harvey, who used experimentation and careful observation in physiology, and naturalists such as Linnaeus and Buffon who began to classify the diversity of life and the fossil record, as well as the development and behavior of organisms. Antonie van Leeuwenhoek revealed by means of microscopy the previously unknown world of microorganisms, laying the groundwork for cell theory. The growing importance of natural theology, partly a response to the rise of mechanical philosophy, encouraged the growth of natural history (although it entrenched the argument from design).

Over the 18th and 19th centuries, biological sciences such as botany and zoology became increasingly professional scientific disciplines. Lavoisier and other physical scientists began to connect the animate and inanimate worlds through physics and chemistry. Explorer-naturalists such as Alexander von Humboldt investigated the interaction between organisms and their environment, and the ways this relationship depends on geography—laying the foundations for biogeography, ecology and ethology. Naturalists began to reject essentialism and consider the importance of extinction and the mutability of species. Cell theory provided a new perspective on the fundamental basis of life. These developments, as well as the results from embryology and paleontology, were synthesized in Charles Darwin's theory of evolution by natural selection. The end of the 19th century saw the fall of spontaneous generation and the rise of the germ theory of disease, though the mechanism of inheritance remained a mystery.

In the early 20th century, the rediscovery of Mendel's work led to the rapid development of genetics by Thomas Hunt Morgan and his students, and by the 1930s the combination of population genetics and natural selection in the "neo-Darwinian synthesis". New disciplines developed rapidly, especially after Watson and Crick proposed the structure of DNA. Following the establishment of the Central Dogma and the cracking of the genetic code, biology was largely split between "organismal biology"—the fields that deal with whole organisms and groups of organisms—and the fields related to "cellular and molecular biology". By the late 20th century, new fields like genomics and proteomics were reversing this trend, with organismal biologists using molecular techniques, and molecular and cell biologists investigating the interplay between genes and the environment, as well as the genetics of natural populations of organisms.

The word "biology" is formed by combining the Greek βίος (bios), meaning "life", and so the suffix '-logy', meaning "science of", "knowledge of", "study of", "about of", based on the Greek verb λέγειν, 'legein' "to select", "to gather" (cf. the noun λόγος, 'logos' "word"). The term "biology" in its modern sense appears to have been introduced independently by Thomas Beddoes (in 1799), Karl Friedrich Burdach (in 1800), Gottfried Reinhold Treviranus ("Biologie oder Philosophie der lebenden Natur", 1802) and Jean-Baptiste Lamarck ("Hydrogéologie", 1802). The word itself appears in the title of Volume 3 of Michael Christoph Hanow's "Philosophiae naturalis sive physicae dogmaticae: Geologia, biologia, phytologia generalis et dendrologia", published in 1766.

Before "biology", there were several terms used for the study of animals and plants. "Natural history" referred to the descriptive aspects of biology, though it also included mineralogy and other non-biological fields; from the Middle Ages through the Renaissance, the unifying framework of natural history was the "scala naturae" or Great Chain of Being. "Natural philosophy" and "natural theology" encompassed the conceptual and metaphysical basis of plant and animal life, dealing with problems of why organisms exist and behave the way they do, though these subjects also included what is now geology, physics, chemistry, and astronomy. Physiology and (botanical) pharmacology were the province of medicine. "Botany", "zoology", and (in the case of fossils) "geology" replaced "natural history" and "natural philosophy" in the 18th and 19th centuries before "biology" was widely adopted. To this day, "botany" and "zoology" are widely used, although they have been joined by other sub-disciplines of biology.

The earliest humans must have had and passed on knowledge about plants and animals to increase their chances of survival. This may have included knowledge of human and animal anatomy and aspects of animal behavior (such as migration patterns). However, the first major turning point in biological knowledge came with the Neolithic Revolution about 10,000 years ago. Humans first domesticated plants for farming, then livestock animals to accompany the resulting sedentary societies.

The ancient cultures of Mesopotamia, Egypt, the Indian subcontinent, and China, among others, produced renowned surgeons and students of the natural sciences such as Susruta and Zhang Zhongjing, reflecting independent sophisticated systems of natural philosophy. However, the roots of modern biology are usually traced back to the secular tradition of ancient Greek philosophy.

The Mesopotamians seem to have had little interest in the natural world as such, preferring to study how the gods had ordered the universe. Animal physiology was studied for divination, including especially the anatomy of the liver, seen as an important organ in haruspicy. Animal behavior too was studied for divinatory purposes. Most information about the training and domestication of animals was probably transmitted orally, but one text dealing with the training of horses has survived.

The ancient Mesopotamians had no distinction between "rational science" and magic. When a person became ill, doctors prescribed both magical formulas to be recited and medicinal treatments. The earliest medical prescriptions appear in Sumerian during the Third Dynasty of Ur ( 2112 – 2004 BCE). The most extensive Babylonian medical text, however, is the "Diagnostic Handbook" written by the "ummânū", or chief scholar, Esagil-kin-apli of Borsippa, during the reign of the Babylonian king Adad-apla-iddina (1069 – 1046 BCE). In East Semitic cultures, the main medicinal authority was an exorcist-healer known as an "āšipu". The profession was passed down from father to son and was held in high regard. Of less frequent recourse was the "asu", a healer who treated physical symptoms using remedies composed of herbs, animal products, and minerals, as well as potions, enemas, and ointments or poultices. These physicians, who could be either male or female, also dressed wounds, set limbs, and performed simple surgeries. The ancient Mesopotamians also practiced prophylaxis and took measures to prevent the spread of disease.

In ancient China, biological topics can be found dispersed across several different disciplines, including the work of herbologists, physicians, alchemists, and philosophers. The Taoist tradition of Chinese alchemy, for example, can be considered part of the life sciences due to its emphasis on health (with the ultimate goal being the elixir of life). The system of classical Chinese medicine usually revolved around the theory of yin and yang, and the five phases. Taoist philosophers, such as Zhuangzi in the 4th century BCE, also expressed ideas related to evolution, such as denying the fixity of biological species and speculating that species had developed differing attributes in response to differing environments.

One of the oldest organised systems of medicine is known from the Indian subcontinent in the form of Ayurveda which originated around 1500 BCE from Atharvaveda (one of the four most ancient books of Indian knowledge, wisdom and culture).

The ancient Indian Ayurveda tradition independently developed the concept of three humours, resembling that of the four humours of ancient Greek medicine, though the Ayurvedic system included further complications, such as the body being composed of five elements and seven basic tissues. Ayurvedic writers also classified living things into four categories based on the method of birth (from the womb, eggs, heat & moisture, and seeds) and explained the conception of a fetus in detail. They also made considerable advances in the field of surgery, often without the use of human dissection or animal vivisection. One of the earliest Ayurvedic treatises was the "Sushruta Samhita", attributed to Sushruta in the 6th century BCE. It was also an early materia medica, describing 700 medicinal plants, 64 preparations from mineral sources, and 57 preparations based on animal sources.

Over a dozen medical papyri have been preserved, most notably the Edwin Smith Papyrus (the oldest extant surgical handbook) and the Ebers Papyrus (a handbook of preparing and using materia medica for various diseases), both from the 16th century BCE.

Ancient Egypt is also known for developing embalming, which was used for mummification, in order to preserve human remains and forestall decomposition.

The pre-Socratic philosophers asked many questions about life but produced little systematic knowledge of specifically biological interest—though the attempts of the atomists to explain life in purely physical terms would recur periodically through the history of biology. However, the medical theories of Hippocrates and his followers, especially humorism, had a lasting impact.

The philosopher Aristotle was the most influential scholar of the living world from classical antiquity. Though his early work in natural philosophy was speculative, Aristotle's later biological writings were more empirical, focusing on biological causation and the diversity of life. He made countless observations of nature, especially the habits and attributes of plants and animals in the world around him, which he devoted considerable attention to categorizing. In all, Aristotle classified 540 animal species, and dissected at least 50. He believed that intellectual purposes, formal causes, guided all natural processes.

Aristotle, and nearly all Western scholars after him until the 18th century, believed that creatures were arranged in a graded scale of perfection rising from plants on up to humans: the "scala naturae" or Great Chain of Being. Aristotle's successor at the Lyceum, Theophrastus, wrote a series of books on botany—the "History of Plants"—which survived as the most important contribution of antiquity to botany, even into the Middle Ages. Many of Theophrastus' names survive into modern times, such as "carpos" for fruit, and "pericarpion" for seed vessel. Dioscorides wrote a pioneering and encyclopaedic pharmacopoeia, "De Materia Medica", incorporating descriptions of some 600 plants and their uses in medicine. Pliny the Elder, in his "Natural History", assembled a similarly encyclopaedic account of things in nature, including accounts of many plants and animals.

A few scholars in the Hellenistic period under the Ptolemies—particularly Herophilus of Chalcedon and Erasistratus of Chios—amended Aristotle's physiological work, even performing dissections and vivisections. Claudius Galen became the most important authority on medicine and anatomy. Though a few ancient atomists such as Lucretius challenged the teleological Aristotelian viewpoint that all aspects of life are the result of design or purpose, teleology (and after the rise of Christianity, natural theology) would remain central to biological thought essentially until the 18th and 19th centuries. Ernst W. Mayr argued that "Nothing of any real consequence happened in biology after Lucretius and Galen until the Renaissance." The ideas of the Greek traditions of natural history and medicine survived, but they were generally taken unquestioningly in medieval Europe.

The decline of the Roman Empire led to the disappearance or destruction of much knowledge, though physicians still incorporated many aspects of the Greek tradition into training and practice. In Byzantium and the Islamic world, many of the Greek works were translated into Arabic and many of the works of Aristotle were preserved.

During the High Middle Ages, a few European scholars such as Hildegard of Bingen, Albertus Magnus and Frederick II wrote on natural history. The rise of European universities, though important for the development of physics and philosophy, had little impact on biological scholarship.

The European Renaissance brought expanded interest in both empirical natural history and physiology. In 1543, Andreas Vesalius inaugurated the modern era of Western medicine with his seminal human anatomy treatise "De humani corporis fabrica", which was based on dissection of corpses. Vesalius was the first in a series of anatomists who gradually replaced scholasticism with empiricism in physiology and medicine, relying on first-hand experience rather than authority and abstract reasoning. Via herbalism, medicine was also indirectly the source of renewed empiricism in the study of plants. Otto Brunfels, Hieronymus Bock and Leonhart Fuchs wrote extensively on wild plants, the beginning of a nature-based approach to the full range of plant life. Bestiaries—a genre that combines both the natural and figurative knowledge of animals—also became more sophisticated, especially with the work of William Turner, Pierre Belon, Guillaume Rondelet, Conrad Gessner, and Ulisse Aldrovandi.

Artists such as Albrecht Dürer and Leonardo da Vinci, often working with naturalists, were also interested in the bodies of animals and humans, studying physiology in detail and contributing to the growth of anatomical knowledge. The traditions of alchemy and natural magic, especially in the work of Paracelsus, also laid claim to knowledge of the living world. Alchemists subjected organic matter to chemical analysis and experimented liberally with both biological and mineral pharmacology. This was part of a larger transition in world views (the rise of the mechanical philosophy) that continued into the 17th century, as the traditional metaphor of "nature as organism" was replaced by the "nature as machine" metaphor.

Systematizing, naming and classifying dominated natural history throughout much of the 17th and 18th centuries. Carl Linnaeus published a basic taxonomy for the natural world in 1735 (variations of which have been in use ever since), and in the 1750s introduced scientific names for all his species. While Linnaeus conceived of species as unchanging parts of a designed hierarchy, the other great naturalist of the 18th century, Georges-Louis Leclerc, Comte de Buffon, treated species as artificial categories and living forms as malleable—even suggesting the possibility of common descent. Though he was opposed to evolution, Buffon is a key figure in the history of evolutionary thought; his work would influence the evolutionary theories of both Lamarck and Darwin.

The discovery and description of new species and the collection of specimens became a passion of scientific gentlemen and a lucrative enterprise for entrepreneurs; many naturalists traveled the globe in search of scientific knowledge and adventure.

Extending the work of Vesalius into experiments on still living bodies (of both humans and animals), William Harvey and other natural philosophers investigated the roles of blood, veins and arteries. Harvey's "De motu cordis" in 1628 was the beginning of the end for Galenic theory, and alongside Santorio Santorio's studies of metabolism, it served as an influential model of quantitative approaches to physiology.

In the early 17th century, the micro-world of biology was just beginning to open up. A few lensmakers and natural philosophers had been creating crude microscopes since the late 16th century, and Robert Hooke published the seminal "Micrographia" based on observations with his own compound microscope in 1665. But it was not until Antonie van Leeuwenhoek's dramatic improvements in lensmaking beginning in the 1670s—ultimately producing up to 200-fold magnification with a single lens—that scholars discovered spermatozoa, bacteria, infusoria and the sheer strangeness and diversity of microscopic life. Similar investigations by Jan Swammerdam led to new interest in entomology and built the basic techniques of microscopic dissection and staining.
As the microscopic world was expanding, the macroscopic world was shrinking. Botanists such as John Ray worked to incorporate the flood of newly discovered organisms shipped from across the globe into a coherent taxonomy, and a coherent theology (natural theology). Debate over another flood, the Noachian, catalyzed the development of paleontology; in 1669 Nicholas Steno published an essay on how the remains of living organisms could be trapped in layers of sediment and mineralized to produce fossils. Although Steno's ideas about fossilization were well known and much debated among natural philosophers, an organic origin for all fossils would not be accepted by all naturalists until the end of the 18th century due to philosophical and theological debate about issues such as the age of the earth and extinction.

Up through the 19th century, the scope of biology was largely divided between medicine, which investigated questions of form and function (i.e., physiology), and natural history, which was concerned with the diversity of life and interactions among different forms of life and between life and non-life. By 1900, much of these domains overlapped, while natural history (and its counterpart natural philosophy) had largely given way to more specialized scientific disciplines—cytology, bacteriology, morphology, embryology, geography, and geology.

Widespread travel by naturalists in the early-to-mid-19th century resulted in a wealth of new information about the diversity and distribution of living organisms. Of particular importance was the work of Alexander von Humboldt, which analyzed the relationship between organisms and their environment (i.e., the domain of natural history) using the quantitative approaches of natural philosophy (i.e., physics and chemistry). Humboldt's work laid the foundations of biogeography and inspired several generations of scientists.

The emerging discipline of geology also brought natural history and natural philosophy closer together; the establishment of the stratigraphic column linked the spatial distribution of organisms to their temporal distribution, a key precursor to concepts of evolution. Georges Cuvier and others made great strides in comparative anatomy and paleontology in the late 1790s and early 19th century. In a series of lectures and papers that made detailed comparisons between living mammals and fossil remains Cuvier was able to establish that the fossils were remains of species that had become extinct—rather than being remains of species still alive elsewhere in the world, as had been widely believed. Fossils discovered and described by Gideon Mantell, William Buckland, Mary Anning, and Richard Owen among others helped establish that there had been an 'age of reptiles' that had preceded even the prehistoric mammals. These discoveries captured the public imagination and focused attention on the history of life on earth. Most of these geologists held to catastrophism, but Charles Lyell's influential "Principles of Geology" (1830) popularised Hutton's uniformitarianism, a theory that explained the geological past and present on equal terms.

The most significant evolutionary theory before Darwin's was that of Jean-Baptiste Lamarck; based on the inheritance of acquired characteristics (an inheritance mechanism that was widely accepted until the 20th century), it described a chain of development stretching from the lowliest microbe to humans. The British naturalist Charles Darwin, combining the biogeographical approach of Humboldt, the uniformitarian geology of Lyell, Thomas Malthus's writings on population growth, and his own morphological expertise, created a more successful evolutionary theory based on natural selection; similar evidence led Alfred Russel Wallace to independently reach the same conclusions.

The 1859 publication of Darwin's theory in "On the Origin of Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life" is often considered the central event in the history of modern biology. Darwin's established credibility as a naturalist, the sober tone of the work, and most of all the sheer strength and volume of evidence presented, allowed "Origin" to succeed where previous evolutionary works such as the anonymous "Vestiges of Creation" had failed. Most scientists were convinced of evolution and common descent by the end of the 19th century. However, natural selection would not be accepted as the primary mechanism of evolution until well into the 20th century, as most contemporary theories of heredity seemed incompatible with the inheritance of random variation.
Wallace, following on earlier work by de Candolle, Humboldt and Darwin, made major contributions to zoogeography. Because of his interest in the transmutation hypothesis, he paid particular attention to the geographical distribution of closely allied species during his field work first in South America and then in the Malay archipelago. While in the archipelago he identified the Wallace line, which runs through the Spice Islands dividing the fauna of the archipelago between an Asian zone and a New Guinea/Australian zone. His key question, as to why the fauna of islands with such similar climates should be so different, could only be answered by considering their origin. In 1876 he wrote "The Geographical Distribution of Animals", which was the standard reference work for over half a century, and a sequel, "Island Life", in 1880 that focused on island biogeography. He extended the six-zone system developed by Philip Sclater for describing the geographical distribution of birds to animals of all kinds. His method of tabulating data on animal groups in geographic zones highlighted the discontinuities; and his appreciation of evolution allowed him to propose rational explanations, which had not been done before.

The scientific study of heredity grew rapidly in the wake of Darwin's "Origin of Species" with the work of Francis Galton and the biometricians. The origin of genetics is usually traced to the 1866 work of the monk Gregor Mendel, who would later be credited with the laws of inheritance. However, his work was not recognized as significant until 35 years afterward. In the meantime, a variety of theories of inheritance (based on pangenesis, orthogenesis, or other mechanisms) were debated and investigated vigorously. Embryology and ecology also became central biological fields, especially as linked to evolution and popularized in the work of Ernst Haeckel. Most of the 19th century work on heredity, however, was not in the realm of natural history, but that of experimental physiology.

Over the course of the 19th century, the scope of physiology expanded greatly, from a primarily medically oriented field to a wide-ranging investigation of the physical and chemical processes of life—including plants, animals, and even microorganisms in addition to man. "Living things as machines" became a dominant metaphor in biological (and social) thinking.

Advances in microscopy also had a profound impact on biological thinking. In the early 19th century, a number of biologists pointed to the central importance of the cell. In 1838 and 1839, Schleiden and Schwann began promoting the ideas that (1) the basic unit of organisms is the cell and (2) that individual cells have all the characteristics of life, though they opposed the idea that (3) all cells come from the division of other cells. Thanks to the work of Robert Remak and Rudolf Virchow, however, by the 1860s most biologists accepted all three tenets of what came to be known as cell theory.

Cell theory led biologists to re-envision individual organisms as interdependent assemblages of individual cells. Scientists in the rising field of cytology, armed with increasingly powerful microscopes and new staining methods, soon found that even single cells were far more complex than the homogeneous fluid-filled chambers described by earlier microscopists. Robert Brown had described the nucleus in 1831, and by the end of the 19th century cytologists identified many of the key cell components: chromosomes, centrosomes mitochondria, chloroplasts, and other structures made visible through staining. Between 1874 and 1884 Walther Flemming described the discrete stages of mitosis, showing that they were not artifacts of staining but occurred in living cells, and moreover, that chromosomes doubled in number just before the cell divided and a daughter cell was produced. Much of the research on cell reproduction came together in August Weismann's theory of heredity: he identified the nucleus (in particular chromosomes) as the hereditary material, proposed the distinction between somatic cells and germ cells (arguing that chromosome number must be halved for germ cells, a precursor to the concept of meiosis), and adopted Hugo de Vries's theory of pangenes. Weismannism was extremely influential, especially in the new field of experimental embryology.

By the mid-1850s the miasma theory of disease was largely superseded by the germ theory of disease, creating extensive interest in microorganisms and their interactions with other forms of life. By the 1880s, bacteriology was becoming a coherent discipline, especially through the work of Robert Koch, who introduced methods for growing pure cultures on agar gels containing specific nutrients in Petri dishes. The long-held idea that living organisms could easily originate from nonliving matter (spontaneous generation) was attacked in a series of experiments carried out by Louis Pasteur, while debates over vitalism vs. mechanism (a perennial issue since the time of Aristotle and the Greek atomists) continued apace.

In chemistry, one central issue was the distinction between organic and inorganic substances, especially in the context of organic transformations such as fermentation and putrefaction. Since Aristotle these had been considered essentially biological ("vital") processes. However, Friedrich Wöhler, Justus Liebig and other pioneers of the rising field of organic chemistry—building on the work of Lavoisier—showed that the organic world could often be analyzed by physical and chemical methods. In 1828 Wöhler showed that the organic substance urea could be created by chemical means that do not involve life, providing a powerful challenge to vitalism. Cell extracts ("ferments") that could effect chemical transformations were discovered, beginning with diastase in 1833. By the end of the 19th century the concept of enzymes was well established, though equations of chemical kinetics would not be applied to enzymatic reactions until the early 20th century.

Physiologists such as Claude Bernard explored (through vivisection and other experimental methods) the chemical and physical functions of living bodies to an unprecedented degree, laying the groundwork for endocrinology (a field that developed quickly after the discovery of the first hormone, secretin, in 1902), biomechanics, and the study of nutrition and digestion. The importance and diversity of experimental physiology methods, within both medicine and biology, grew dramatically over the second half of the 19th century. The control and manipulation of life processes became a central concern, and experiment was placed at the center of biological education.

At the beginning of the 20th century, biological research was largely a professional endeavour. Most work was still done in the natural history mode, which emphasized morphological and phylogenetic analysis over experiment-based causal explanations. However, anti-vitalist experimental physiologists and embryologists, especially in Europe, were increasingly influential. The tremendous success of experimental approaches to development, heredity, and metabolism in the 1900s and 1910s demonstrated the power of experimentation in biology. In the following decades, experimental work replaced natural history as the dominant mode of research.

In the early 20th century, naturalists were faced with increasing pressure to add rigor and preferably experimentation to their methods, as the newly prominent laboratory-based biological disciplines had done. Ecology had emerged as a combination of biogeography with the biogeochemical cycle concept pioneered by chemists; field biologists developed quantitative methods such as the quadrat and adapted laboratory instruments and cameras for the field to further set their work apart from traditional natural history. Zoologists and botanists did what they could to mitigate the unpredictability of the living world, performing laboratory experiments and studying semi-controlled natural environments such as gardens; new institutions like the Carnegie Station for Experimental Evolution and the Marine Biological Laboratory provided more controlled environments for studying organisms through their entire life cycles.

The ecological succession concept, pioneered in the 1900s and 1910s by Henry Chandler Cowles and Frederic Clements, was important in early plant ecology. Alfred Lotka's predator-prey equations, G. Evelyn Hutchinson's studies of the biogeography and biogeochemical structure of lakes and rivers (limnology) and Charles Elton's studies of animal food chains were pioneers among the succession of quantitative methods that colonized the developing ecological specialties. Ecology became an independent discipline in the 1940s and 1950s after Eugene P. Odum synthesized many of the concepts of ecosystem ecology, placing relationships between groups of organisms (especially material and energy relationships) at the center of the field.

In the 1960s, as evolutionary theorists explored the possibility of multiple units of selection, ecologists turned to evolutionary approaches. In population ecology, debate over group selection was brief but vigorous; by 1970, most biologists agreed that natural selection was rarely effective above the level of individual organisms. The evolution of ecosystems, however, became a lasting research focus. Ecology expanded rapidly with the rise of the environmental movement; the International Biological Program attempted to apply the methods of big science (which had been so successful in the physical sciences) to ecosystem ecology and pressing environmental issues, while smaller-scale independent efforts such as island biogeography and the Hubbard Brook Experimental Forest helped redefine the scope of an increasingly diverse discipline.

1900 marked the so-called "rediscovery of Mendel": Hugo de Vries, Carl Correns, and Erich von Tschermak independently arrived at Mendel's laws (which were not actually present in Mendel's work). Soon after, cytologists (cell biologists) proposed that chromosomes were the hereditary material. Between 1910 and 1915, Thomas Hunt Morgan and the "Drosophilists" in his fly lab forged these two ideas—both controversial—into the "Mendelian-chromosome theory" of heredity. They quantified the phenomenon of genetic linkage and postulated that genes reside on chromosomes like beads on string; they hypothesized crossing over to explain linkage and constructed genetic maps of the fruit fly "Drosophila melanogaster", which became a widely used model organism.

Hugo de Vries tried to link the new genetics with evolution; building on his work with heredity and hybridization, he proposed a theory of mutationism, which was widely accepted in the early 20th century. Lamarckism also had many adherents. Darwinism was seen as incompatible with the continuously variable traits studied by biometricians, which seemed only partially heritable. In the 1920s and 1930s—following the acceptance of the Mendelian-chromosome theory— the emergence of the discipline of population genetics, with the work of R.A. Fisher, J.B.S. Haldane and Sewall Wright, unified the idea of evolution by natural selection with Mendelian genetics, producing the modern synthesis. The inheritance of acquired characters was rejected, while mutationism gave way as genetic theories matured.

In the second half of the century the ideas of population genetics began to be applied in the new discipline of the genetics of behavior, sociobiology, and, especially in humans, evolutionary psychology. In the 1960s W.D. Hamilton and others developed game theory approaches to explain altruism from an evolutionary perspective through kin selection. The possible origin of higher organisms through endosymbiosis, and contrasting approaches to molecular evolution in the gene-centered view (which held selection as the predominant cause of evolution) and the neutral theory (which made genetic drift a key factor) spawned perennial debates over the proper balance of adaptationism and contingency in evolutionary theory.

In the 1970s Stephen Jay Gould and Niles Eldredge proposed the theory of punctuated equilibrium which holds that stasis is the most prominent feature of the fossil record, and that most evolutionary changes occur rapidly over relatively short periods of time. In 1980 Luis Alvarez and Walter Alvarez proposed the hypothesis that an impact event was responsible for the Cretaceous–Paleogene extinction event. Also in the early 1980s, statistical analysis of the fossil record of marine organisms published by Jack Sepkoski and David M. Raup led to a better appreciation of the importance of mass extinction events to the history of life on earth.

By the end of the 19th century all of the major pathways of drug metabolism had been discovered, along with the outlines of protein and fatty acid metabolism and urea synthesis. In the early decades of the 20th century, the minor components of foods in human nutrition, the vitamins, began to be isolated and synthesized. Improved laboratory techniques such as chromatography and electrophoresis led to rapid advances in physiological chemistry, which—as "biochemistry"—began to achieve independence from its medical origins. In the 1920s and 1930s, biochemists—led by Hans Krebs and Carl and Gerty Cori—began to work out many of the central metabolic pathways of life: the citric acid cycle, glycogenesis and glycolysis, and the synthesis of steroids and porphyrins. Between the 1930s and 1950s, Fritz Lipmann and others established the role of ATP as the universal carrier of energy in the cell, and mitochondria as the powerhouse of the cell. Such traditionally biochemical work continued to be very actively pursued throughout the 20th century and into the 21st.

Following the rise of classical genetics, many biologists—including a new wave of physical scientists in biology—pursued the question of the gene and its physical nature. Warren Weaver—head of the science division of the Rockefeller Foundation—issued grants to promote research that applied the methods of physics and chemistry to basic biological problems, coining the term "molecular biology" for this approach in 1938; many of the significant biological breakthroughs of the 1930s and 1940s were funded by the Rockefeller Foundation.

Like biochemistry, the overlapping disciplines of bacteriology and virology (later combined as "microbiology"), situated between science and medicine, developed rapidly in the early 20th century. Félix d'Herelle's isolation of bacteriophage during World War I initiated a long line of research focused on phage viruses and the bacteria they infect.

The development of standard, genetically uniform organisms that could produce repeatable experimental results was essential for the development of molecular genetics. After early work with "Drosophila" and maize, the adoption of simpler model systems like the bread mold "Neurospora crassa" made it possible to connect genetics to biochemistry, most importantly with Beadle and Tatum's one gene-one enzyme hypothesis in 1941. Genetics experiments on even simpler systems like tobacco mosaic virus and bacteriophage, aided by the new technologies of electron microscopy and ultracentrifugation, forced scientists to re-evaluate the literal meaning of "life"; virus heredity and reproducing nucleoprotein cell structures outside the nucleus ("plasmagenes") complicated the accepted Mendelian-chromosome theory.

Oswald Avery showed in 1943 that DNA was likely the genetic material of the chromosome, not its protein; the issue was settled decisively with the 1952 Hershey–Chase experiment—one of many contributions from the so-called phage group centered around physicist-turned-biologist Max Delbrück. In 1953 James Watson and Francis Crick, building on the work of Maurice Wilkins and Rosalind Franklin, suggested that the structure of DNA was a double helix. In their famous paper "Molecular structure of Nucleic Acids", Watson and Crick noted coyly, "It has not escaped our notice that the specific pairing we have postulated immediately suggests a possible copying mechanism for the genetic material." After the 1958 Meselson–Stahl experiment confirmed the semiconservative replication of DNA, it was clear to most biologists that nucleic acid sequence must somehow determine amino acid sequence in proteins; physicist George Gamow proposed that a fixed genetic code connected proteins and DNA. Between 1953 and 1961, there were few known biological sequences—either DNA or protein—but an abundance of proposed code systems, a situation made even more complicated by expanding knowledge of the intermediate role of RNA. To actually decipher the code, it took an extensive series of experiments in biochemistry and bacterial genetics, between 1961 and 1966—most importantly the work of Nirenberg and Khorana.

In addition to the Division of Biology at Caltech, the Laboratory of Molecular Biology (and its precursors) at Cambridge, and a handful of other institutions, the Pasteur Institute became a major center for molecular biology research in the late 1950s. Scientists at Cambridge, led by Max Perutz and John Kendrew, focused on the rapidly developing field of structural biology, combining X-ray crystallography with Molecular modelling and the new computational possibilities of digital computing (benefiting both directly and indirectly from the military funding of science). A number of biochemists led by Frederick Sanger later joined the Cambridge lab, bringing together the study of macromolecular structure and function. At the Pasteur Institute, François Jacob and Jacques Monod followed the 1959 PaJaMo experiment with a series of publications regarding the "lac" operon that established the concept of gene regulation and identified what came to be known as messenger RNA. By the mid-1960s, the intellectual core of molecular biology—a model for the molecular basis of metabolism and reproduction— was largely complete.

The late 1950s to the early 1970s was a period of intense research and institutional expansion for molecular biology, which had only recently become a somewhat coherent discipline. In what organismic biologist E. O. Wilson called "The Molecular Wars", the methods and practitioners of molecular biology spread rapidly, often coming to dominate departments and even entire disciplines. Molecularization was particularly important in genetics, immunology, embryology, and neurobiology, while the idea that life is controlled by a "genetic program"—a metaphor Jacob and Monod introduced from the emerging fields of cybernetics and computer science—became an influential perspective throughout biology. Immunology in particular became linked with molecular biology, with innovation flowing both ways: the clonal selection theory developed by Niels Jerne and Frank Macfarlane Burnet in the mid-1950s helped shed light on the general mechanisms of protein synthesis.

Resistance to the growing influence of molecular biology was especially evident in evolutionary biology. Protein sequencing had great potential for the quantitative study of evolution (through the molecular clock hypothesis), but leading evolutionary biologists questioned the relevance of molecular biology for answering the big questions of evolutionary causation. Departments and disciplines fractured as organismic biologists asserted their importance and independence: Theodosius Dobzhansky made the famous statement that "nothing in biology makes sense except in the light of evolution" as a response to the molecular challenge. The issue became even more critical after 1968; Motoo Kimura's neutral theory of molecular evolution suggested that natural selection was not the ubiquitous cause of evolution, at least at the molecular level, and that molecular evolution might be a fundamentally different process from morphological evolution. (Resolving this "molecular/morphological paradox" has been a central focus of molecular evolution research since the 1960s.)

Biotechnology in the general sense has been an important part of biology since the late 19th century. With the industrialization of brewing and agriculture, chemists and biologists became aware of the great potential of human-controlled biological processes. In particular, fermentation proved a great boon to chemical industries. By the early 1970s, a wide range of biotechnologies were being developed, from drugs like penicillin and steroids to foods like "Chlorella" and single-cell protein to gasohol—as well as a wide range of hybrid high-yield crops and agricultural technologies, the basis for the Green Revolution.

Biotechnology in the modern sense of genetic engineering began in the 1970s, with the invention of recombinant DNA techniques. Restriction enzymes were discovered and characterized in the late 1960s, following on the heels of the isolation, then duplication, then synthesis of viral genes. Beginning with the lab of Paul Berg in 1972 (aided by "EcoRI" from Herbert Boyer's lab, building on work with ligase by Arthur Kornberg's lab), molecular biologists put these pieces together to produce the first transgenic organisms. Soon after, others began using plasmid vectors and adding genes for antibiotic resistance, greatly increasing the reach of the recombinant techniques.

Wary of the potential dangers (particularly the possibility of a prolific bacteria with a viral cancer-causing gene), the scientific community as well as a wide range of scientific outsiders reacted to these developments with both enthusiasm and fearful restraint. Prominent molecular biologists led by Berg suggested a temporary moratorium on recombinant DNA research until the dangers could be assessed and policies could be created. This moratorium was largely respected, until the participants in the 1975 Asilomar Conference on Recombinant DNA created policy recommendations and concluded that the technology could be used safely.

Following Asilomar, new genetic engineering techniques and applications developed rapidly. DNA sequencing methods improved greatly (pioneered by Frederick Sanger and Walter Gilbert), as did oligonucleotide synthesis and transfection techniques. Researchers learned to control the expression of transgenes, and were soon racing—in both academic and industrial contexts—to create organisms capable of expressing human genes for the production of human hormones. However, this was a more daunting task than molecular biologists had expected; developments between 1977 and 1980 showed that, due to the phenomena of split genes and splicing, higher organisms had a much more complex system of gene expression than the bacteria models of earlier studies. The first such race, for synthesizing human insulin, was won by Genentech. This marked the beginning of the biotech boom (and with it, the era of gene patents), with an unprecedented level of overlap between biology, industry, and law.

By the 1980s, protein sequencing had already transformed methods of scientific classification of organisms (especially cladistics) but biologists soon began to use RNA and DNA sequences as characters; this expanded the significance of molecular evolution within evolutionary biology, as the results of molecular systematics could be compared with traditional evolutionary trees based on morphology. Following the pioneering ideas of Lynn Margulis on endosymbiotic theory, which holds that some of the organelles of eukaryotic cells originated from free living prokaryotic organisms through symbiotic relationships, even the overall division of the tree of life was revised. Into the 1990s, the five domains (Plants, Animals, Fungi, Protists, and Monerans) became three (the Archaea, the Bacteria, and the Eukarya) based on Carl Woese's pioneering molecular systematics work with 16S rRNA sequencing.

The development and popularization of the polymerase chain reaction (PCR) in mid-1980s (by Kary Mullis and others at Cetus Corp.) marked another watershed in the history of modern biotechnology, greatly increasing the ease and speed of genetic analysis. Coupled with the use of expressed sequence tags, PCR led to the discovery of many more genes than could be found through traditional biochemical or genetic methods and opened the possibility of sequencing entire genomes.

The unity of much of the morphogenesis of organisms from fertilized egg to adult began to be unraveled after the discovery of the homeobox genes, first in fruit flies, then in other insects and animals, including humans. These developments led to advances in the field of evolutionary developmental biology towards understanding how the various body plans of the animal phyla have evolved and how they are related to one another.

The Human Genome Project—the largest, most costly single biological study ever undertaken—began in 1988 under the leadership of James D. Watson, after preliminary work with genetically simpler model organisms such as "E. coli", "S. cerevisiae" and "C. elegans". Shotgun sequencing and gene discovery methods pioneered by Craig Venter—and fueled by the financial promise of gene patents with Celera Genomics— led to a public–private sequencing competition that ended in compromise with the first draft of the human DNA sequence announced in 2000.

At the beginning of the 21st century, biological sciences converged with previously differentiated new and classic disciplines like Physics into research fields like Biophysics. Advances were made in analytical chemistry and physics instrumentation including improved sensors, optics, tracers, instrumentation, signal processing, networks, robots, satellites, and compute power for data collection, storage, analysis, modeling, visualization, and simulations. These technology advances allowed theoretical and experimental research including internet publication of molecular biochemistry, biological systems, and ecosystems science. This enabled worldwide access to better measurements, theoretical models, complex simulations, theory predictive model experimentation, analysis, worldwide internet observational data reporting, open peer-review, collaboration, and internet publication. New fields of biological sciences research emerged including Bioinformatics, Neuroscience, Theoretical biology, Computational genomics, Astrobiology and Synthetic Biology.





</doc>
<doc id="324230" url="https://en.wikipedia.org/wiki?curid=324230" title="Sinking of SS Princess Alice">
Sinking of SS Princess Alice

SS "Princess Alice, formerly PS "Bute, was a passenger paddle steamer that sank on 3 September 1878 after a collision with the collier "Bywell Castle" on the River Thames. Between 600 and 700 people died, all from "Princess Alice", the greatest loss of life of any British inland waterway shipping accident. No passenger list or headcount was made, so the exact figure of those who died has never been known.

Built in Greenock, Scotland, in 1865, "Princess Alice" was employed for two years in Scotland before being purchased by the Waterman's Steam Packet Co to carry passengers on the Thames. By 1878 she was owned by the London Steamboat Co and was captained by William R. H. Grinstead; the ship carried passengers on a stopping service from Swan Pier, near London Bridge, downstream to Sheerness, Kent, and back. On her homeward journey, at an hour after sunset on 3 September 1878, she passed Tripcock Point and entered Gallions Reach, she took the wrong sailing line and was hit by "Bywell Castle"; the point of the collision was the area of the Thames where of London's raw sewage had just been released. "Princess Alice" broke into three parts and sank quickly; her passengers drowned in the heavily polluted waters.

Grinstead died in the collision, so the subsequent investigations never established which course he thought he was supposed to take. The jury in the coroner's inquest considered both vessels at fault, but more blame was put on the collier; the inquiry run by the Board of Trade found that "Princess Alice" had not followed the right path and was culpable. In the aftermath of the sinking, changes were made to the release and treatment of sewage, and it was transported to, and released into, the sea. The Marine Police Force—the branch of the Metropolitan Police that had responsibility for policing the Thames—were provided with steam launches, after the rowing boats used up to that point had proved insufficient. Five years after the collision "Bywell Castle" sank in the Bay of Biscay with the loss of all 40 crew.

Caird & Company of Greenock, Scotland, launched the passenger paddle steamer "Bute" on 29 March 1865. She entered service on 1 July 1865. The ship was long and at the beam, and measured 432 gross registered tons. "Bute" had been built for the Wemyss Bay Railway Company, for whom she carried passengers between Wemyss Bay and Rothesay. In 1867 she was sold to the Waterman's Steam Packet Co. to travel on the River Thames; the company renamed the vessel "Princess Alice", after Queen Victoria's third child. In 1870 she was sold to the Woolwich Steam Packet Company and was operated as an excursion steamer; the company later changed its name to the London Steamboat Company. In 1873 the ship carried Naser al-Din Shah Qajar, the Shah of Persia up the Thames to Greenwich, and became known to many locals as "The Shah's boat".

When "Princess Alice" was acquired by the Woolwich Steam Packet Company, the company made several alterations to the ship, including the installation of new boilers and making the five bulkheads watertight. The vessel had been inspected and was passed as safe by the Board of Trade. In 1878 another survey by the Board of Trade allowed the ship to carry a maximum of 936 passengers between London and Gravesend in calm water.

The collier SS "Bywell Castle" was built in Newcastle in 1870 and was owned by Messrs Hall of Newcastle. Her gross registered tonnage was 1376, she was long and at the beam; her depth of hold was . The master was Captain Thomas Harrison.

On 3 September 1878 "Princess Alice" was making what was billed as a "Moonlight Trip" from Swan Pier, near London Bridge, downstream to Sheerness, Kent, and back. During the journey she called at Blackwall, North Woolwich and Rosherville Gardens; many of the Londoners on board were travelling to Rosherville to visit the pleasure gardens that had been built 40 years before. As the London Steamboat Co. owned several ships, passengers could use their tickets interchangeably on the day, stopping off to travel on or back on different vessels if they wanted; for tickets from Swan Pier to Rosherville, the cost was two shillings.

"Princess Alice" left Rosherville at about 6:30 pm on her return to Swan Pier; she was carrying close to her full capacity of passengers, although no lists were kept, and the exact number of people on board is unknown. The master of "Princess Alice", 47-year-old Captain William Grinstead, allowed his helmsman to stay at Gravesend, and replaced him with a passenger, a seaman named John Ayers. Ayers had little experience of the Thames, or of helming a craft such as "Princess Alice". Between 7:20 pm and 7:40 pm, "Princess Alice" had passed Tripcock Point, entered Gallions Reach and come within sight of the North Woolwich Pier—where many passengers were to disembark—when "Bywell Castle" was sighted. "Bywell Castle" usually carried coal to Africa, but had just been repainted at a dry dock. She was due to sail up to Newcastle to pick up coal bound for Alexandria, Egypt. Harrison was unfamiliar with the conditions, so employed Christopher Dix, an experienced Thames river pilot, though he was not obliged to do so. As "Bywell Castle" had a raised forecastle, Dix did not have a clear view in front of him, so a seaman was placed on lookout.
On leaving Millwall, "Bywell Castle" proceeded down river at five knots; she kept roughly to the middle of the river, except where other craft were in her way. Approaching Gallions Reach, Dix saw "Princess Alice"s red port light approaching on a course to pass starboard of them. Grinstead, travelling up the river against the tide, followed the normal watermen's practice of seeking the slack water on the south side of the river. He altered the ship's course, bringing her into the path of "Bywell Castle". Seeing the imminent collision, Grinstead shouted to the larger vessel "Where are you coming to! Good God! Where are you coming to!" Although Dix tried to manoeuvre his vessel out of a collision course, and ordered the engines to be put into "reverse full speed", it was too late. "Princess Alice" was struck on the starboard side just in front of the paddle box at an angle of 13 degrees; she split in two and sank within four minutes—her boilers separating from the structure as it sank.

The crew of "Bywell Castle" dropped ropes from their deck for the passengers of "Princess Alice" to climb; they also threw anything that would float into the water for people to hold. Other crew from "Bywell Castle" launched their lifeboat and rescued 14 people, and crews from boats moored nearby did the same. Residents from both banks of the Thames, particularly the boatmen of local factories, launched vessels to rescue who they could. Many of the passengers from "Princess Alice" were unable to swim; the long heavy dresses worn by women also hindered their efforts to stay afloat. "Princess Alice"s sister ship, "Duke of Teck", was steaming ten minutes behind her; she arrived too late to rescue anyone left in the water. Only two people who had been below decks or in the saloon survived the collision; a diver who later examined the saloon reported that the passengers were jammed together in the doorways, mostly still upright.

About 130 people were rescued from the collision, but several died later from ingesting the water. "Princess Alice" sank at the point where London's sewage pumping stations were sited. The twice-daily release of of raw sewage from the sewer outfalls Abbey Mills, at Barking, and the Crossness Pumping Station had occurred one hour before the collision. In a letter to "The Times" shortly after the collision, a chemist described the outflow as:

Two continuous columns of decomposed fermenting sewage, hissing like soda-water with baneful gases, so black that the water is stained for miles and discharging a corrupt charnel-house odour, that will be remembered by all ... as being particularly depressing and sickening.
The water was also polluted by the untreated output from Beckton Gas Works, and several local chemical factories. To add to the foulness of the water, a fire in Thames Street earlier that day had resulted in oil and petroleum entering the river.

"Bywell Castle" moored at Deptford to await the action of the authorities and the inquest. That night Harrison and Belding, the first mate, wrote the ship's log to describe the event:

At 6:30 left the West Dock, Millwall, in charge of Mr Dicks, pilot; proceeding slowly, the master and pilot being on the upper bridge ... Light air and weather little hazy. At 7:45 pm proceeding at half speed down Gallions Reach. Being about centre of the Reach, observed an excursion steamer coming up Barking Reach, showing her red and masthead lights, when we ported our helm to keep over towards Tripcock Point. As the vessel neared, observed that the other steamer had ported, and immediately afterwards saw that she had starboarded and was trying to cross our bows, showing her green light close under the port bow. Seeing collision inevitable, stopped our engines and reversed full speed, when the two vessels collided, the bow of "Bywell Castle" cutting into the other steamer, which was crowded with passengers, with a dreadful crash. Took immediate means for saving life by hauling up over the bows several men of the passengers, throwing rope's-ends over all round the ship, throwing over four lifebuoys, a hold ladder and several planks, and getting out three boats, keeping the whistle blowing loudly all the time for assistance, which was rendered by several boats from shore and a boat from a passing steamer. The excursion steamer, which turned out to be "Princess Alice", turning over and sinking under the bows. Succeeded in rescuing a great many passengers and anchored for the night. About 8:30 pm the steamer "Duke of Teck" came alongside and took off such passengers as had not been taken on shore in the boats.

News of the sinking was telegraphed back to the centre of London, and soon filtered through to those waiting at Swan Pier for the steamer's return. Relatives made their way to the London Steamboat offices near Blackfriars to wait for more news; many took the train from London Bridge to Woolwich. The crowds grew during the night and into the following day, as both relatives and sightseers travelled to Woolwich; additional police were drafted in to help control the crowds, and deal with the remains that were being landed. Reports came in of corpses being washed up as far upstream as Limehouse and down to Erith. When bodies were landed, they were stored locally for identification, rather than centrally, although most ended up at Woolwich Dockyard. Relatives had to travel between several locations on both sides of the Thames to search for missing family members. Local watermen were hired for £2 a day to search for bodies; they were paid a minimum of five shillings for each one they recovered, which sometimes led to fights over the corpses. One of those picked up was that of Grinstead, "Princess Alice"s captain.

Because of the pollution from the sewage and local industrial output, the bodies from the Thames were covered with slime, which was found difficult to clean off; the corpses began to rot at a faster pace than normal, and many of the corpses were unusually bloated. Victims' clothing also began to rot quickly and was discoloured after immersion in the polluted water. Sixteen of those who survived died within two weeks, and several others were ill.

On 4 September Charles Carttar, the coroner for West Kent, opened the inquest for his region. That day he took the jury to view the corpses at Woolwich Town Hall and Woolwich Pier. There were more bodies on the northern bank, but this lay outside his jurisdiction. Charles Lewis, the coroner for South Essex, visited the Board of Trade and the Home Office to try to have the remains in his jurisdiction moved to Woolwich to allow one inquest that could cover all the victims and hear the evidence in only one location, but the law meant that the deceased could not be moved until the inquest had been opened and adjourned. Instead, he opened his inquest to formally identify the bodies under his authority, then adjourned proceedings until after Carttar's case had come to a conclusion. He issued burial orders, and the remains were then transferred to Woolwich.
During low tide, part of "Princess Alice"s rail could be seen above the waterline. Plans to raise the ship began on 5 September with a diver examining the wreckage. He found the vessel had broken into three sections—the fore, aft and boilers. He reported back that there were still several bodies on board. Work began the following day to raise the larger fore section, which was long. This was beached at low tide—2:00 am on 7 September—at Woolwich; while she was being pulled ashore, "Bywell Castle" steamed past, leaving London, but without her captain, who remained. The following day large crowds visited Woolwich again to view the raised section of "Princess Alice". Fights broke out in places for the best vantage point, and people rowed up to the wreck to break off souvenirs. An additional 250 policemen were drafted in to help control the crowds. That evening, after most of the crowd had gone home, the larger aft section of the ship was raised and beached next to the bow.
Because of the accelerated rate of decomposition of many of the corpses, the burials of many of those still unidentified took place on 9 September at Woolwich cemetery in a mass grave; several thousand people were in attendance. The coffins all carried a police identification number, which was also attached to the clothing and personal items which were retained to aid later identification. The same day over 150 private funerals of victims took place.

The first two weeks of Carttar's inquest were given over to the formal identification of the bodies, and visits to the wreck site to examine the remains of "Princess Alice". From 16 September the proceedings began to examine the causes of the collision. Carttar began by bemoaning the media coverage of the event, which suggested strongly that "Bywell Castle" had been in error and should take the blame. He focussed his proceedings on William Beechley, the first body to have been positively identified; Carttar explained to the jury that whatever verdict they reached on Beechley would apply to the other victims. Numerous Thames boatmen appeared as witnesses, all who had been active in the area at the time; their stories of the path taken by "Princess Alice" differed considerably. Most pleasure craft coming upriver on the Thames would round Tripcock Point and head for the northern bank to take advantage of more favourable currents. Had "Princess Alice" done that, "Bywell Castle" would have gone clearly astern of her. Several witnesses stated that once "Princess Alice" rounded Tripcock Point she had been pushed into the centre of the river by currents; the ship then attempted to turn to port, which would have kept her close to the river's southern bank, but in doing so cut across the bows of "Bywell Castle". Several masters of other ships moored nearby who witnessed the collision agreed with this series of events. "Princess Alice"s chief mate denied that his ship had changed direction.

During the inquest evidence was taken from George Purcell, the stoker on "Bywell Castle", who, on the night of the sinking, had told several people that the captain and crew of the ship were drunk. Under oath he changed his claims, and stated that they were sober, and that he had no recollection of claiming that anyone was drunk. Evidence given by other members of "Bywell Castle"s crew showed it had been Purcell that had been drunk; one crewman said that "Purcell was like the generality of firemen. He was rather the worse for drink, but not so bad that he could not take his watch". Evidence was also taken concerning the state of the Thames at the point the ship sank, and of the construction and stability of "Princess Alice". On 14 November, after twelve hours of discussion, the inquest released its verdict; four members of the nineteen-member jury refused to sign the statement. Their verdict was:
That the death of the said William Beachey and others was occasioned by drowning in the waters of the River Thames from a collision that occurred after sunset between a steam vessel called the "Bywell Castle" and a steam vessel called the "Princess Alice" whereby the "Princess Alice" was cut in two and sunk, such collision not being wilful; that the "Bywell Castle" did not take the necessary precaution of easing, stopping and reversing her engines in time and that the "Princess Alice" contributed to the collision by not stopping and going astern; that all collisions in the opinion of the jury might in future be avoided if proper and stringent rules and regulations were laid down for all steam navigation on the River Thames.
Addenda:

Running at the same time as the coroner's inquest was a Board of Trade inquiry. Specific charges were laid against Captain Harrison, two of the crew members of "Bywell Castle", and against Long, the first mate of "Princess Alice"; all had their licences suspended at the start of the hearing. The Board of Trade proceedings began on 14 October 1878 and continued until 6 November. The board found that "Princess Alice" had breached Rule 29, Section (d) of the Board of Trade Regulations and the Regulations of the Thames Conservancy Board, 1872. This stated that if two ships are heading towards each other, they should pass on the port side of each other. As "Princess Alice" had not followed this procedure, the Board found "Princess Alice" to blame and that "Bywell Castle" could not avoid the collision.
The company that owned "Princess Alice" sued the owners of "Bywell Castle" for £20,000 compensation; the owners of "Bywell Castle" counter-sued for £2,000. The case was heard in the Admiralty Division of the High Court of Justice in late 1878. After two weeks, the judgment was that both vessels were to blame for the collision.

As no passenger list was kept on "Princess Alice"—or a record of the number of people on board—it was not possible to calculate the number of people who died: figures vary from 600 to 700. "The Times" reported that "the coroner believes that there are from 60 to 80 bodies unrecovered from the river. The total number of lives lost must thus have been from 630 to 650". Michael Foley, in his examination of disasters on the Thames, observes that "there was no proof of the final death toll. However, around 640 bodies were eventually recovered". The sinking was the worst inland disaster on water in the UK.

The Mansion House fund for the victims had been opened by the Lord Mayor of London in the aftermath of the sinking; by the time it closed it had raised £35,000, which was distributed among the victims' families.

During the 1880s London's Metropolitan Board of Works began to purify the sewage at Crossness and Beckton, rather than dumping the untreated waste into the river, and a series of six sludge boats were ordered to ship effluent into the North Sea for dumping. The first boat commissioned in June 1887 was named "Bazalgette"—after Joseph Bazalgette, who had rebuilt London's sewer system. The practice of dumping at sea continued until December 1998.

Until "Princess Alice" sank, the Marine Police Force—the branch of the Metropolitan Police that had responsibility for policing the Thames—relied on rowing boats for their work. The inquest into the sinking of "Princess Alice" found that these were insufficient for the requirements of the role, and that they should be replaced by steam launches. The first two launches entered service in the mid 1880s; eight were working by 1898. The Royal Albert Dock, which opened in 1880, helped to separate heavy goods traffic from smaller boats; this and global adoption of emergency signalling lights on boats both helped avoid future tragedies.

After 23,000 people donated to a sixpenny fund, a memorial Celtic cross was erected in Woolwich Cemetery in May 1880. St Mary Magdalene Woolwich, the local parish church also later installed a stained glass memorial window. In 2008 a National Lottery grant funded the installation of a memorial plaque at Barking Creek to mark the 130th anniversary of the sinking.

"Princess Alice"s owners, the London Steamboat Co, purchased the wreck of the vessel from the Thames Conservancy for £350; the engines were salvaged and the remainder sent to a ship breaker. The London Steamboat Co were bankrupt within six years, and their successors went into financial difficulties three years after that. According to the historian Jerry White, along with competition from the railways and bus services, the sinking of "Princess Alice" "had some impact ... in blighting the tidal Thames as a pleasure-ground". "Bywell Castle" was reported missing on 29 January 1883 sailing between Alexandria and Hull; it carried a cargo of cottonseed and beans. In February 1883 newspapers carried a final report:

It is believed that the steamer "Bywell Castle", which ran down the saloon boat "Princess Alice", off Woolwich, some years ago, has been lost in the Bay of Biscay, in the gale which proved fatal to the "Kenmure Castle". The "Bywell Castle" carried a crew of 40 men and her cargo consisted of Egyptian produce.







</doc>
<doc id="324996" url="https://en.wikipedia.org/wiki?curid=324996" title="John Tyndall (politician)">
John Tyndall (politician)

John Hutchyns Tyndall (14 July 193419 July 2005) was a British fascist political activist. A leading member of various small neo-Nazi groups during the late 1950s and 1960s, he was chairman of the National Front from 1972 to 1974 and again from 1975 to 1980, and then chairman of the British National Party from 1982 to 1999. He unsuccessfully stood for election to the House of Commons and European Parliament on several occasions.

Born in Devon and educated in Kent, Tyndall undertook national service prior to embracing the extreme-right. In the mid-1950s, he joined the League of Empire Loyalists (LEL) and came under the influence of its leader, Arthur Chesterton. Finding the LEL too moderate, in 1957 he and John Bean founded the National Labour Party (NLP), an explicitly "National Socialist" (Nazi) group. In 1960, the NLP merged with Colin Jordan's White Defence League to found the first British National Party (BNP). Within the BNP, Tyndall and Jordan established a paramilitary wing called Spearhead, which angered Bean and other party members. They expelled Tyndall and Jordan, who went on to establish the National Socialist Movement and then the international World Union of National Socialists. In 1962, they were convicted and briefly imprisoned for their paramilitary activities. After a split with Jordan, Tyndall formed his Greater Britain Movement (GBM) in 1964. Although never changing his basic beliefs, by the mid-1960s, Tyndall was replacing his overt references to Nazism with appeals to British nationalism.

In 1967, Tyndall joined Chesterton's newly founded National Front (NF) and became its leader in 1972, overseeing growing membership and electoral growth. His leadership was threatened by various factions within the party which eventually led to him losing his position as leader in 1974. He resumed this position in 1975, although the latter part of the 1970s saw the party's prospects decline. Following an argument with long-term comrade Martin Webster, Tyndall resigned from the party in 1980 and formed his short-lived New National Front (NNF). In 1982, he merged the NNF into his own newly formed British National Party (BNP). Under Tyndall, the BNP established itself as the UK's most prominent extreme-right group during the 1980s, although electoral success eluded it. Tyndall's refusal to moderate the BNP's policies or image caused anger among a growing array of "modernisers" in the party, who ousted him in favour of Nick Griffin in 1999. In 2005, Tyndall was charged with incitement to racial hatred for comments made at a BNP meeting. He died two days before his trial was due to take place.

Tyndall promoted a racial nationalist belief in a distinct white "British race", arguing that this race was threatened by a Jewish conspiracy to encourage non-white migration into Britain. He called for the establishment of an authoritarian state which would deport all non-whites from the country, engage in a eugenics project, and re-establish the British Empire through the military conquest of parts of Africa. He never gained any mainstream political respectability in the United Kingdom although he proved popular among sectors of the British far-right.

John Tyndall was born at Stork Nest, Topsham Road in Exeter, Devon, on 14 July 1934. His mother was Nellie Tyndall, "née" Parker; his father was George Francis Tyndall. Through the Tyndall family line he was related to both the early English translator of the Bible, William Tyndale, and the physicist John Tyndall. His paternal family were British Unionists living in County Waterford, Ireland, who had a long line of service in the Royal Irish Constabulary. His grandfather had been a district inspector in the Constabulary and had fought against the Irish Republican Army in the Irish War of Independence. His father had moved to England, working as a Metropolitan Police officer, and then as a warden of St George's House, a YMCA hostel in Southwark. Tyndall later stated that despite his father having been raised in a British Unionist family, the latter had adopted internationalist views. He claimed that his mother exhibited "a kind of basic British patriotism" and that it was she who shaped his early political views. His upbringing was emotionally stable and materially secure. Tyndall studied at Beckenham and Penge Grammar School in west Kent, where he attained three O-levels, a "moderate" result. At the school, his achievements had been sporting rather than academic, for he enjoyed playing cricket and association football and developed a passion for fitness.

Tyndall did his national service in West Germany from 1952 to 1954. A member of the Royal Horse Artillery, he achieved the rank of lance-bombardier. On completion, he returned to Britain and turned his attention to political issues. Initially interested in socialism, he attended a world youth festival held in the Soviet Union in 1957. He nevertheless began to regard left-wing politics as being infused with "anti-British attitudes", moving swiftly to the political right. He had a devotion to the preservation of the British Empire and a hostility to what he regarded as the growing permissiveness of British society, stating that "the smell everywhere was one of decadence". During that decade he read "Mein Kampf", the autobiography and political manifesto of the late Nazi leader Adolf Hitler, growing sympathetic to Hitler's own political beliefs and Nazism. Tyndall approved in particular of "the descriptions of the workings of certain Jewish forces in Germany, which seemed uncannily similar to what I had observed of the same kinds of forces in Britain." He concluded that Britain's decision to go to war against Nazi Germany was ultimately the result of a conspiracy headed primarily by Jews, a conspiracy which he thought had also masterminded non-white immigration into Britain after the war.

Around 1957–58, Tyndall decided to commit himself full-time to his political cause, which he was able to do as his job as a salesman allowed him flexible working hours. He decided against joining the Union Movement led by the prominent British fascist Oswald Mosley, disagreeing with its promotion of the political union of Britain with continental Europe. Instead, he was attracted to the League of Empire Loyalists (LEL) — a right-wing group founded by Arthur Chesterton — after seeing coverage of one of their demonstrations on television. He visited their basement office in Westminster, where he was given some of their literature. He enjoyed Chesterton's writings and concurred with his conspiracy theory that Jewish people had been plotting to bring down the British Empire. Tyndall began associating with other young men who had joined the LEL. At a February 1957 by-election in Lewisham North, Tyndall aided the LEL campaign, during which he met another party member John Bean, an industrial chemist. Both Tyndall and Bean were frustrated by the LEL's attempts to exert pressure on the mainstream Conservative Party. They wanted to be involved in a more radical party, one that would combine "nationalism" with "popular socialism" and which would reach out to the white working class through appeals against immigration from the Caribbean.

In April 1958, Tyndall and Bean founded their own extreme-right group, the National Labour Party (NLP). The group was based at Thornton Heath, Croydon and attracted its early membership from former LEL members living in south and east London. According to the historian Richard Thurlow, the NLP promoted an "English" variant of Nazism, and was more pronounced in its "explicit racism" than the LEL had been, focusing less on bemoaning the decline of the British Empire and more on criticising the arrival of non-white immigrants from former British colonies.

The NLP began co-operating with another extreme-right group, the White Defence League, which had been established by Colin Jordan, a secondary school teacher. Together the two groups embarked on a project of stirring up racial tensions among white Britons and black Caribbean immigrants in Notting Hill. Tyndall briefly left the NLP, and in his absence Bean and Jordan merged their respective groups into the British National Party (BNP) in 1960. The BNP were racial nationalists, calling for the preservation of a "Nordic race"—of which the "British race" was considered a branch—by removing both immigrants and Jewish influences from Britain. Tyndall soon joined this new BNP, and became a close confidante of Jordan, who helped Tyndall to further embrace neo-Nazism. Tyndall also developed a friendship with Martin Webster, who became a long-term comrade after watching Tyndall speak at a Trafalgar Square rally in 1962.

In April 1961, Tyndall self-published his pamphlet, "The Authoritarian State: Its Meaning and Function", which helped to cement his reputation within the British far-right. In the pamphlet, he attacked democratic systems of government as part of a conspiracy orchestrated by Jews, quoting from "The Protocols of the Elders of Zion". It called for the replacement of the United Kingdom's liberal democratic system with an authoritarian one in which a "Leader" is given absolute power. 

Within the BNP, Tyndall established an elite group known as Spearhead, members of which wore military-style uniforms inspired by those of the Nazis and underwent paramilitary and ideological training. Tyndall had a great liking for wearing jackboots; Jordon related that on the way to a far-right meeting in Germany, Tyndall made his entourage look for a shoe shop so that he could purchase a pair of genuine German jackboots. It is likely that there were no more than sixty members of Spearhead. The group campaigned on behalf of imprisoned Nazi war criminals Rudolf Hess and Adolf Eichmann. According to the anti-fascist activist Gerry Gable, Spearhead represented the first "terrorist group" founded by neo-Nazis in Britain. Both Bean and another senior BNP member, Andrew Fountaine, were concerned about the overt neo-Nazism embraced by Tyndall and Jordan, instead thinking that the BNP should articulate a more British-oriented form of racial nationalism. In 1962, Bean held a meeting at which Tyndall and Jordan were expelled from the party.

Tyndall and Jordan then regrouped around twenty members of Spearhead and formed the National Socialist Movement (NSM) on 20 April 1962, a date symbolically chosen as the anniversary of Hitler's birthday. They celebrated the event with a cake decorated with a Nazi swastika. According to the historian Richard Thurlow, the NSM was "the most blatant Nazi" group active in Britain during the mid-20th century. The NSM gained few members; an estimate in August 1962 suggested that it had only thirty to fifty. The NSM gained the attention of the media as well as Special Branch. In July 1962, Tyndall was arrested for breaching the peace at a Trafalgar Square rally in which he had been attacked by Jewish military veterans and other anti-fascists after calling the Jewish community a "poisonous maggot feeding on a body in an advanced state of decay". His comments resulted in him being convicted of inciting racial hatred and he was sentenced to six weeks imprisonment, reduced to a fine on appeal. The police then raided the group's London headquarters, after which its leading members were brought to trial at the Old Bailey, where they were found guilty of establishing a paramilitary group in contravention of Section Two of the Public Order Act 1936. Tyndall received a six-month prison sentence, while Jordan received nine months.

Although the British authorities had prohibited the American neo-Nazi George Lincoln Rockwell from entering the UK, the NSM managed to smuggle him in via Ireland to attend a summer camp in August 1962. There, the NSM took part in the formation of the World Union of National Socialists (WUNS), at which Jordan was elected 'world führer' and Rockwell as his heir. Among those in attendance were the neo-Nazi Savitri Devi and the former SS officer Fred Borth.

Jordan had been courting the French socialite Françoise Dior, but while he had been imprisoned, she entered a relationship with Tyndall and they were engaged to be married. On Jordan's release, Dior left Tyndall and instead married Jordan in October 1963. This contributed to a growing personal feud between the two men, with Jordan accusing Tyndall and Webster of making obscene phone calls to Dior. Tyndall was also angry at what he perceived as Jordan's deviation from orthodox Nazi thought, and by the fact that Jordan's relationship with Dior had been attracting negative sensationalist press attention for the NSM. In the spring of 1964 Tyndall and Webster tried to oust Jordan as the head of the NSM but failed. In later years Tyndall expressed the view that his involvement in the NSM had been a "profound mistake", arguing that then he "still had a lot to learn" and that "when one sees one's nation and people in danger there is less dishonour in acting and acting wrongly than in not acting at all."

Now based in Battersea, Tyndall left Jordan and the NSM and formed his own rival, the Greater Britain Movement (GBM). According to Tyndall, "the Greater Britain Movement will uphold, and preach, pure National Socialism". According to the political scientist Stan Taylor, the GBM reflected Tyndall's desire for "a specifically British variant of National Socialism". It called for the criminalisation of sexual relations and marriages between white Britons and non-whites and called for the sterilisation of those it deemed unfit to reproduce. The group established its base in a run-down building in Notting Hill, with swastikas being sprayed onto the exterior and an image of Hitler decorating the interior. Tyndall tried to convince the WUNS to accept his GBM as its British representative, but Rockwell—concerned not to encourage schismatic dissenters in his own American Nazi Party—sided with Jordan and the NSM. Tyndall then established contact with Rockwell's main rival in the American neo-Nazi scene, the National States' Rights Party. 

Tyndall also a publishing company called Albion Press, and launched a new magazine, which he titled "Spearhead" after his former paramilitary group. "Spearhead" initially labelled itself "an organ of National Socialist opinion in Britain" and described Nazi Germany as "one of the greatest social experiments of our century". According to the historian Alan Sykes, this magazine became "increasingly influential" in the British far-right. The magazine advertised portraits of Hitler and swastika badges for sale. Much of the material that Tyndall wrote for the journal was less openly neo-Nazi and extreme than his previous writings, something which may have resulted from caution surrounding the Race Relations Act 1965. The GBM engaged in several stunts to raise publicity; in 1964 for instance Webster assaulted the Kenyan leader Jomo Kenyatta outside his London hotel while Tyndall hurled insults at him through a loudspeaker. In 1965, the group staged a shooting incident at its Norwood headquarters, claiming that it had been an attack by anti-fascists. In another instance they distributed stickers emblazoned with a portrait of Hitler and the slogan "he was right". In 1966, several GBM members were arrested for carrying out arson attacks against synagogues.

In the mid-1960s, there were five extreme-right groups operating in Britain, and Tyndall believed that they could achieve more if they united. To that end, "Spearhead" abandoned its open affiliation with neo-Nazism in 1966. That year, Tyndall issued a pamphlet titled "Six Principles of British Nationalism" which made no mention of neo-Nazism or Jewish conspiracies. It also dropped the insistence on armed takeovers present in his earlier thought, acknowledging the possibility that extreme-right nationalists could gain power through the British electoral process. Chesterton read the pamphlet and was impressed, entering into talks with Tyndall's GBM about a potential merger of their respective organisations. Independently, Chesterton had also been discussing the issue of a unification with Bean's BNP. This proved successful, as the LEL and BNP merged to form the National Front (NF) in 1967. According to Thurlow, the formation of the NF was "the most significant event on the radical right and fascist fringe of British politics" since the internment of the country's fascists during the Second World War.

The new NF initially excluded Tyndall and his GBM from joining, concerned that he might seek to mould it in a specifically neo-Nazi direction, although they soon agreed to allow both him and other GBM members to join on probation. On entering, the former GBM soon became the most influential faction within the NF, with many of its members rapidly rising to positions of influence. Tyndall became the party's vice chairman and remained loyal to Chesterton, who was the party's first chairman, for instance by supporting him when several members of the party directorate rebelled against his leadership in 1970. Although remaining Tyndall's private property, "Spearhead" became the "de facto" monthly magazine of the NF. Chesterton resigned as chairman in 1970, and was replaced by the Powellite John O'Brien. In 1972, O'Brien and eight other members of the party's directorate resigned in protest at Tyndall's links to neo-Nazi groups in Germany. This allowed Tyndall to take control as party chairman in 1972.

According to Thurlow, under Tyndall the NF represented "an attempt to portray the essentials of Nazi ideology in more rational language and seemingly reasonable arguments", functioning as an attempt to "convert racial populists" angry about immigration "into fascists". Capitalising on anger surrounding the arrival of Ugandan Asian migrants in the country in 1972, Tyndall oversaw the NF during the period of its largest growth. Membership of the party doubled between October 1972 and June 1973, possibly reaching as high as 17,500.
Relations had apparently warmed between Tyndall and Jordan, for they met up after the latter was released from prison in 1968, and Tyndall again met with Jordan in Coventry in 1972 and invited him to join the NF. A poor showing in the February 1974 general election resulted in Tyndall being challenged by two groups within the party, the 'Strasserites' and the 'Populists', the latter of whom were largely Powellite ex-members of the Conservative Party. The Populist challenge was successful and in October 1974 Tyndall was replaced as chairman by John Kingsley Read. Tyndall then used "Spearhead" as a vehicle to criticise rival factions with the NF. As a result, he was expelled from the party during a disciplinary tribunal in November 1975. Tyndall took the issue to the high court, who overturned the expulsion. The 'Populists' then left the party, splitting to form the National Party in January 1976, which for a short time proved more electorally successful than the NF. Back in the party and with his main rivals gone, Tyndall regained the position of chairman.

Encouraged by Webster and new confidante Richard Verrall, in the mid-1970s Tyndall returned to his openly hardline approach of promoting biological racist and antisemitic ideas. This did not help the NF's electoral prospects. In the 1979 general election, the NF mounted the largest challenge of any insurgent party since the Labour Party in 1918, with 303 candidates. Among them were Tyndall's wife, mother-in-law, and father-in-law. Tyndall stood in Hackney South and Shoreditch, securing 7.6%; this was the Front's best result that election, but was down from the 9.4% they had gained in that constituency in October 1974. In the election, the NF "flopped dismally", securing only 1.3% of the total vote, down from 3.1% in October 1974. This decline may have been due to the increased anti-fascist campaigning of the previous few years, or because the Conservative Party under Margaret Thatcher had adopted an increasingly tough stance on immigration which attracted many of the votes that had previously gone to the NF. NF membership had also declined, and by 1979 had fallen to approximately 5,000. Tyndall nevertheless refused to dilute or moderate his party's policies, stating that to do so would be the "naïve chasing of moonbeams". In November 1979, Fountaine unsuccessfully tried to oust Tyndall as leader, subsequently establishing the National Front Constitutional Movement.

Tyndall had grown distant from Webster over their differences, and in the late 1970s began blaming him for the party's problems. Webster had for instance disagreed with Tyndall's support for Chesterton's leadership, while Tyndall was upset with Webster's attempts to encourage more skinheads and football hooligans to join the party. Tyndall in particular began criticizing the fact that Webster was a homosexual, emphasising allegations that Webster had been making sexual advances toward young men in the party. More widely, he complained about a "homosexual network" among leading NF members. In October 1979, he called a meeting of the NF directorate at which he urged them to call for Webster's resignation. At the meeting, Webster apologised for his conduct, and the directorate stood by him against Tyndall. Angered, Tyndall then tried convincing the directorate to grant him greater powers in his position as chairman, but they refused. Tyndall resigned in January 1980, subsequently referring to the party as the "gay National Front".

In June 1980, Tyndall founded the New National Front (NNF). The NNF claimed that a third of the NF's membership defected to join them. Tyndall stated that "I have one wish in this operation and one wish alone, to cleanse the National Front of the foul stench of perversion which has politically crippled it". As his choice of party name suggested, he remained hopeful that his breakaway group could eventually be re-merged back into the NF. There developed a great rivalry between the two groups, and as the NF's new leadership moved it away from the Tyndallite approach, Tyndall realised that he may never have the opportunity to regain his position within it.

In January 1981, Tyndall was contacted by far-right activist Ray Hill, who had become an informant for the anti-fascist magazine "Searchlight". Hill suggested that Tyndall establish a new political party through which he could unite many smaller extreme-right groups. While Hill's real intention had been to cause a further schism among the British far-right and thus weaken it, Tyndall deemed his suggestion to be a good idea. Tyndall made suggestions of unity to a number of other small extreme-right groups and together they established a Committee for Nationalist Unity (CNU) in January 1982. 

In March 1982 the CNU held a conference at Charing Cross Hotel in central London, and while the NF officially refused to send a delegation, several NF members did attend. The fifty extreme-rightists in attendance agreed that they would establish a new political party, to be known as the British National Party (BNP). According to Tyndall, "The BNP is a racial nationalist party which believes in Britain for the British, that is to say racial separatism." Under Tyndall's leadership, in 1982 the BNP issued its first policy on immigration as "immigration into Britain by non-Europeans ... should be terminated forthwith, and we should organise a massive programme of repatriation and resettlement overseas of those peoples of non-European origin already resident in this country."

Tyndall was to be the leader of this new party, with the majority of its members coming from the NNF, although others were defectors from the NF, British Movement, British Democratic Party, and Nationalist Party. The party was formerly launched at a press conference held in a Victoria hotel on 7 April 1982. At the conference, Tyndall described the BNP as the "SDP of the far right", thereby referencing the recent growth of the centrist Social Democratic Party. The historian Nigel Copsey has noted that while the BNP under Tyndall could be described as "Neo-Nazi", it was not "crudely mimetic" of the original German Nazism. Its stated policy objectives were identical to those that the NF had had under Tyndall's leadership in the 1970s. But its constitution was very different. Whereas the NF had a directorate which helped to guide the direction of the party and could replace the leader, Tyndall's new BNP gave full executive powers to the chairman. Tyndall ran the BNP from his home, "Seacroft", in Hove, East Sussex, and he rarely left the county. 
In 1986 Tyndall was convicted of inciting racial hatred and sentenced to a year's imprisonment, although he served only four months before his release. In 1987, the BNP opened discussions with an NF faction, the National Front Support Group (NFSG), to discuss the possibility of a merger, but the NFSG decided against it, remaining cautious about Tyndall's total domination of the BNP.

By 1988, "Searchlight" reported that the party's membership had declined to around 1,000. Tyndall responded by trying to raise finances, calling for greater sales of their newspaper and increasing the price of membership by 50%. He also promised that he would make the BNP the largest extreme-right group in the UK and that he would establish a professional headquarters for the party. This was achieved in 1989, as a party headquarters was opened in Welling, Southeast London, an area chosen because it was a recipient of significant 'white flight' from inner London. That year also witnessed the BNP become the most prominent force on the British far-right as the NF collapsed amid internal arguments and schisms.

In the early 1990s, a paramilitary group known as Combat 18 (C18) was formed to protect BNP events from anti-fascist protesters. Tyndall was displeased that by 1992, C18 was having an increased influence over the BNP's street activities. Relations between the groups deteriorated such that by August 1993, activists from the BNP and C18 were physically fighting each other. In December 1993, Tyndall issued a bulletin to BNP branches declaring C18 to be a proscribed organisation, furthermore suggesting that it may have been established by agents of the state to discredit the party. To counter C18's influence, he secured the American white nationalist militant William Pierce as a guest speaker at the BNP's annual rally in November 1995.

Tyndall had observed the electoral success achieved by Jean-Marie Le Pen and the French National Front during the 1980s, and hoped that by learning from their activities he could improve the BNP's electoral prospects. He saw the issue as being one of credibility among the electorate, declaring that "we should be looking for ways to overcome our present image of weakness and smallness". He ignored the significant impact that had been achieved by the French NF through moderating its policies and thereby gaining greater respectability among the electorate. While Tyndall had sought to keep skinheads and football hooligans out of the BNP, he still kept a range of Holocaust deniers and convicted criminals close to him. He expressed the view that "we should not be looking for ways of applying ideological cosmetic surgery to ourselves in order to make our features more appealing to our public". Conversely, in the early 1990s a 'moderniser' faction emerged in the party that favoured a more electorally palatable strategy and an emphasis on building grassroots support to win local elections. They were impressed by Le Pen's move to disassociate his party from biological racism and focus on the perceived cultural incompatibility of different racial groups. Tyndall opposed many of the modernisers' ideas and sought to stem their growing influence in the party,

In the 1992 general election, the party stood 13 candidates. Tyndall stood in Bow and Poplar, gaining 3% of the vote.
At the 1993 local elections, the BNP gained one council seat—won by Derek Beackon in the East London neighbourhood of Millwall—after a campaign that targeted the anger of local whites over the perceived preferential treatment received by Bangladeshi migrants in social housing.
At the time Tyndall described this as the BNP's "moment in history", deeming it a sign that the party was entering the political mainstream. Following an anti-BNP campaign launched by anti-fascist and local religious groups it lost its Millwall seat during the 1994 local elections.

Tyndall stood as the BNP candidate in the 1994 Dagenham by-election, in which he gained 9% of the vote and had his electoral deposit returned. This was the first time that an extreme right candidate had retained their deposit since Webster's 1973 showing for the NF in West Bromwich. 
In the 1997 general election, the party stood over fifty candidates. Tyndall stood in the East London constituency of Poplar and Canning Town, where he received 7.26% of the vote. Tyndall claimed that following the election, the party received between 2,500 and 3,000 enquiries—roughly the same as they had received after the 1983 general election—although far fewer of these enquirers became members.
The party was stagnating, and Tyndall's "political career was now on borrowed time".

After the BNP's poor performance at the 1997 general election, opposition to Tyndall's leadership grew. His position was damaged by a lack of financial transparency in the party, with concerns being raised that large donations to the party had been used instead by Tyndall for personal expenses. The modernisers challenged his control of the party, resulting in its first ever leadership election, held in October 1999. Tyndall was challenged by Nick Griffin, who offered an improved administration, financial transparency, and greater support for local branches. 80% of party members voted, with two-thirds backing Griffin; Tyndall had secured only 411 votes, representing 30% of the total membership. Tyndall accepted his defeat with equanimity and stood down as chairman. He stated that he would become "an ordinary member", telling his supporters that "we have all got to pull together in the greater cause of race and nation".

Tyndall remained a member of the BNP and continued to support it in the pages of "Spearhead". But Griffin sought to restrain Tyndall's ongoing influence in the party, curtailing the distribution of "Spearhead" among BNP members and instead emphasising his own magazine, "Identity", which was established in January 2000. To combat the influence of declining sales, Tyndall established the group 'Friends of "Spearhead"', whose members were asked to contribute £10 a month.

By 2000, Tyndall was beginning to agitate against Griffin's leadership, criticising the establishment of the party's Ethnic Liaison Committee — which had one half-Turkish member (Lawrence Rustem) — as a move towards admitting non-whites into the party. He was also critical of Griffin's abandonment of the party's compulsory removal of migrants and non-whites from the country, believing that if they stayed in a segregated system then Britain would resemble apartheid-era South Africa, which he did not think was preferable. His main criticisms were focused not on the party's changing direction, but on Griffin's character itself, portraying him as unscrupulous and self-centred. Tyndall was determined to retake control of the party, and in this was supported by a group of party hardliners. During a proposed leadership challenge, Tyndall put forward his name, although withdrew it following the 2001 general election when Griffin led the BNP to a clear growth in electoral support. Tyndall nevertheless believed that the BNP's electoral success had less to do with Griffin's reforms and more to do with external factors such as the 2001 Oldham riots. In turn, Griffin criticised Tyndall in the pages of "Identity", claiming that the latter was committed to "the sub-Mosleyite wackiness of Arnold Leese's Imperial Fascist League and the Big Government mania of the 1930s". Griffin expelled Tyndall from the party in August 2003, but had to allow his return following an out-of-court settlement shortly after.

Tyndall gave a speech at a BNP event in which he claimed that Asians and Africans had only produced "black magic, witchcraft, voodoo, cannibalism and Aids", also attacking the Jewish leader of the Conservative Party, Michael Howard, as an "interloper, this immigrant or son of immigrants, who has no roots at all in Britain". The speech was filmed by undercover investigator Jason Gwynne and included in a 2004 BBC documentary, "The Secret Agent". On 12 December 2004, these comments resulted in Tyndall being arrested on suspicion of incitement to racial hatred. That month, Tyndall was again expelled from the BNP, this time permanently. The police then charged him, although he was granted unconditional bail in April 2005. Tyndall died of heart failure at his flat—52 Westbourne Villas in Hove—on 19 July 2005. He had been due to stand trial at Leeds Magistrates' Court two days later. He was survived by his wife and his daughter, Marina.

Tyndall has been described as a racial nationalist, and a British nationalist, as well as a fascist, neo-fascist, and a neo-Nazi. Tyndall adhered to neo-Nazism during the 1960s, although from the 1970s onward he increasingly concealed this behind the rhetoric of "British patriotism". According to Thurlow, this was because by this time Tyndall had realised that "open Nazism was counter-productive" to his cause. This was in accordance with a wider trend among Britain's far-right to avoid the term "British fascism", with its electorally unpalatable connotations, and instead refer to "British nationalism" in its public appeals. Sykes stated that Tyndall split with Jordan because—in contrast to the latter's neo-Nazi focus on pan-'Aryan' unity—he "thought more traditionally in terms of British nationalism, the British race and the British Empire". Jordan himself accused Tyndall of being "an extreme Tory imperialist, a John Bull, unable to recognise the call of race beyond Britain's frontiers".

Tyndall later described his membership of these openly neo-Nazi groups as a "youthful indiscretion". He expressed the view that while he regretted his involvement in them, he was not ashamed of having done so: "though some of my former beliefs were mistaken, I will never acknowledge that there was anything dishonourable about holding them." As leader of the NF he continued to openly approve of Hitler's social and economic programme and well as his policies of German territorial expansion. In his 1988 autobiography "The Eleventh Hour", he stated that while he thought that "many of [Hitler's] intentions were good ones and many of his achievements admirable", he did not think "that it is right for a British movement belonging to an entirely different phase of history to model itself on the movement of Hitler".

Following this shift away from overt allegiance to Nazism, Tyndall's supporters and detractors continued to dispute whether he remained a convinced Nazi. Academic commentators consider that his basic ideological world-view did not change. In 1981, Nigel Fielding stated that while Tyndall's views had "moderated remarkably", in the NF he had still "preserve[d] and defend[ed]" "those traits which were the hallmark" of earlier neo-Nazi groups. Walker noted that in October 1975 Tyndall wrote articles for "Spearhead" which had clearly "returned to the language and ideology of the Nazi days", and that another article printed the previous month was "pure Nazism in that it reflects exactly the mood and spirit of "Mein Kampf"." The historian Nicholas Goodrick-Clarke stated that Tyndall simply "cloaked his former extremism in British nationalism", while the journalist Daniel Trilling commented that "Tyndall's claim to have moderated his views was merely expedient". On his death, "The Guardian" stated that Tyndall had remained "a racist, violent neo-Nazi to the end", while Trilling described Tyndall as having had "a long pedigree in the most extreme and violent quarters of Britain's far right".

The political scientist Nigel Copsey believed that Chesterton had been the "seminal influence" on Tyndall's thought. Thurlow disagreed, arguing that Tyndall had been influenced less by Chesterton and Mosley and more by a third figure in Britain's "fascist tradition", Arnold Leese. Thurlow noted that Tyndall adopted Leese's "political intransigence ... his refusal to compromise with political reality and his willingness to martyr himself for his beliefs". According to Trilling, the "two guiding stars in ... Tyndall's political universe" were Hitler and the British Empire. In contrast to many of his contemporaries in the British far-right, Tyndall was "thoroughly indifferent" to the ideas of the Nouvelle Droite, a French extreme-right movement which had emerged in the 1960s. Whereas the Nouvelle Droite sought to move away from the approach adopted by the fascist movements of the 1930s and 1940s, Tyndall remained wedded to white racial nationalism, anti-Semitic conspiracy theories, and nostalgia for the British Empire, all approaches generally repudiated by the Nouvelle Droite.

Tyndall had "deeply entrenched" biologically racist views, akin to those of earlier fascists like Hitler and Leese. He believed that there was a biologically distinct white-skinned "British race" which was one branch of a wider Nordic race. Tyndall was of the view that race defined a nation and that "if that is lost we will have no nation in the future." He believed the Nordic race to be superior to others, and under his leadership, the BNP promoted a variety of pseudoscientific claims in support of white supremacy. Those parties he controlled restricted membership to people of Northern European ethnic heritage. 

Over the course of his career in far-right politics, Tyndall became less outspoken on race after his prosecution under the race relations legislation. In the mid-1970s, Tyndall used "Spearhead" to claim that "the negro has a smaller brain and a much less complex cerebral structure" than white Europeans. In 1988, Tyndall described his crime as having "dared to publish an honest and frank opinion on the relative merits of Whites and Negroes." Tyndall argued that non-whites were unassimilable to Britain and that those living in Britain should be repatriated. Tyndall strongly objected to interracial relationships and miscegenation and remarked in his book "The Eleventh Hour": "I feel deeply sorry for the child of a mixed marriage, but I can have no sympathy whatever for the parents ... They produced an offspring that will never wholly fit, and will undoubtedly face a life much harder than the normal person born of pure race." In contrast to his views on non-white migration, he spoke positively of white immigrants from Ireland, Poland, Hungary, and the Baltic states, regarding them as being racially similar and sharing the "same basic culture" as the British and were thus easily able to assimilate "within a generation or two". 

Tyndall was antisemitic. From earlier fascists like Chesterton, he had inherited a belief that there was a global conspiracy of Jews bent on world domination, opining that the "Protocols of the Elders of Zion" was genuine evidence for this. He believed that Jews were responsible for both communism and international finance capitalism, using both to their own ends, and that they were responsible for undermining the British Empire and the British race. Tyndall also believed that both democratic government and immigration into Europe were parts of a Jewish conspiracy to weaken other races. In an early edition of "Spearhead", he had expressed the view that "if Britain were to become Jew-clean she would have no nigger neighbours to worry about ... It is the Jews who are our misfortune: T-h-e J-e-w-s. Do you hear me? THE JEWS?" Another of his comments, made in 1963, was that "Jewry is a world pest wherever it is found in the world today. The Jews are more clever and more financially powerful than other people and have to be eradicated before they destroy the Aryan peoples".

Tyndall also engaged in Holocaust denial, declaring that the Holocaust was a hoax created by Jews to gain sympathy for themselves and thus aid their plot for world domination. In "The Eleventh Hour", Tyndall spoke approvingly of Holocaust denier David Irving. In promoting Holocaust denial, Tyndall and those close to him may have been seeking to rehabilitate Hitler and the Nazi government in the British public's view.

In the early 1960s, Tyndall espoused the idea of replacing Britain's liberal democratic government—which he regarded as a front for the Jewish world conspiracy—with an authoritarian system that he believed would be free of Jewish influence. Between 1961 and 1966 there was a shift in Tyndall's publicly espoused views. This focused largely on his beliefs about the structure of an ideal government for—while not rejecting the idea of an authoritarian dictatorship altogether—he placed greater emphasis on the need for the government to be more acceptable to the population. Rather than self-describing himself as an authoritarian, by the mid-1960s he was accusing the country's mainstream parties (and the "liberal minority" whom he alleged ran them) of being the real authoritarians, thus portraying himself as a champion of democracy. In this he presented his arguments in a populist manner.

Tyndall believed that liberal democracy was damaging to British society, claiming that liberalism was a "doctrine of decay and degeneration". Under Tyndall, the NF and BNP sought to dismantle the UK's liberal democratic system of parliamentary governance, although was vague about what they sought to replace this system with. In his 1988 work "The Eleventh Hour", Tyndall wrote of the need for "an utter rejection of liberalism and a dedication to the resurgence of authority". Tyndall's BNP perceived itself as a revolutionary force that would bring about a national rebirth in Britain, entailing a radical transformation of society. It proposed a state in which the Prime Minister would have full executive powers, and would be elected directly by the population for an indefinite period of time. This Prime Minister could be dismissed from office in a further election that could be called if Parliament passed a vote of no confidence. It stated that rather than having any political parties, candidates standing for election to the parliament would be independent.

Tyndall described his approach to the economy as "National Economics", expressing the view that "politics must lead, and not be led by, economic forces". His approach rejected economic liberalism because it did not serve "the national interest", although still saw advantages in a capitalist system, looking favourably on individual enterprise. He called on capitalist elements to be combined with socialist ones, with the government playing a role in planning the economy. He promoted the idea of the UK becoming an autarky which was economically self-sufficient, with domestic production protected from foreign competition. This attitude was heavily informed by the corporatist system that had been introduced in Benito Mussolini's Fascist Italy.

Under Tyndall, the NF alleged that internationalist institutions and organisations were part of the global Jewish conspiracy. Under Tyndall's leadership, the BNP had overt anti-Europeanist tendencies, and throughout the 1980s and 1990s he maintained the party's opposition to the European Economic Community. Arguing that Britain should establish a White Commonwealth bloc, Tyndall called for a better relationship with South Africa and Rhodesia, and urged those nations to permanently retain their systems of racial segregation. He claimed that "power and responsibility" should not be given to the indigenous Africans living in these countries because they were "ill-fitted to use [it] wisely". He expressed support for Hitler's "lebensraum" policy of territorial expansion and claimed that the British race required something similar. In "The Eleventh Hour", he called for the British to re-colonise parts of Africa.

During Tyndall's period of leadership the BNP promoted eugenics, calling for the forced sterilisation of those with genetically transmittable disabilities. In party literature, it talked of improving the British "racial stock" by removing "inferior strains within the indigenous races of the British Isles". In his magazine "Spearhead", Tyndall had stated that "sub-human elements", "perverts", and "asocials" should be eliminated from Britain through "the gas chamber system". When questioned as to whether Tyndall would seek to exterminate other races if he was in power, he denied it; although not objecting to said exterminations on moral grounds, he stated that such a programme would incur international unpopularity. It is unclear if these statements reflected his genuine views or were tactical justifications designed to not upset potential NF voters.

Tyndall presented himself as an agnostic although expressed admiration for what he claimed were the moral values of Christianity. Tyndall called for a "complete moral regeneration of the national life". He objected to homosexuality and advocated for it to be outlawed, writing that "the literary and artistic products of the homosexual mind can only flourish in a society where heterosexual values have been gravely weakened." He expressed the view that the NF "was itself by no means immune to this sickening cult", and he disapproved of the presence of homosexuals in the party. Under Tyndall, the BNP called for the re-criminalisation of homosexual activity.

The American journalist George Thayer, who met with Tyndall in the 1960s, described him as being "blonde and balding", with "cold, evasive eyes". Thayer stated that Tyndall "had not the slightest spark of humour. He was suspicious, nervous, and excitable, and moved with all the stiffness of a Prussian in Court." In his study of the National Front, the journalist Martin Walker described Tyndall as giving off "an impression of absolute, if brittle, self control". Nigel Fielding, another to have studied the NF, described Tyndall as "a rather small man with a hard, unlined face and pale blue eyes. His movements are abrupt and energetic, and he speaks in a loud voice with a clipped inflection." Walker described him as having a "keen political mind", with a "concern for organisation [and] meticulous planning". Tyndall lived a life of temperance and regular exercise, and—according to Walker—his early morning runs had "long been a joke in Nationalist circles".

Thurlow thought that Tyndall's oratorical style was learned from Mosley's example, while Trilling instead believed that it was based on that of Hitler. According to Trilling, Tyndall's "speeches were pompous but studied ... [he] copied the hand gestures, the rising delivery that ended in a crescendo of angry epithets [from Hitler] ... But it was flat and tedious, like a provincial PE teacher trying to show his bored pupils how the rugby or football greats might have done it." After Tyndall's death, the BNP spokesman Phil Edwards said that "he was a marvellous speaker. He could hold a room and mesmerise them, but he did not have the answer to the problems." Copsey stated that "Tyndall may have been a rousing speaker, but his tactical intelligence and vision left much to be desired". The East London BNP activist Eddy Butler noted that at a 1986 party rally in Dewsbury, Tyndall "lost them completely. He knew how to talk to a small room of nationalists, but he didn't know how to talk to a thousand Yorkshire young geezers. He hadn't got a clue about normal people or normal politics. He'd go on about the Britain of Sir Francis Drake; you'd think 'what's he on about?'".

Walker described Tyndall as being "very close to his mother", with whom he lived until 1977. On 19 November 1977 he married Valerie Dawn Olliff, a divorcee and fellow right-wing activist. The couple had a daughter named Marina.
Valerie died on 24 June 2011 in Hove.

Walker noted that during the 1960s, Tyndall was "well known" yet "unpopular within Nationalist circles because of his arrogance, his overbearing personal manner and the way he brought the authoritarianism of his politics into his personal life". In contrast, Fielding noted that within the NF of the late 1970s and early 1980s, Tyndall's standing among "ordinary members" was "very high", with some of them even chanting his name during his speeches. At Tyndall's death, the anti-fascist activist Nick Lowles stated that Tyndall had been "someone that the more hardline nationalists" in the BNP "have always looked up to and rallied around" and that he "still had a lot of support" in the party, particularly in the northwest and parts of south London. Despite his standing within the British far-right, "The Telegraph" noted that Tyndall's devotion to neo-Nazism "prevented his cause from acquiring the slightest veneer of political respectability."

UK Parliament elections
European Parliament elections



</doc>
<doc id="327421" url="https://en.wikipedia.org/wiki?curid=327421" title="A Momentary Lapse of Reason">
A Momentary Lapse of Reason

A Momentary Lapse of Reason is the thirteenth studio album by the English progressive rock band Pink Floyd. It was released in the UK and US on 7 September 1987 by EMI and Columbia. It was recorded primarily on guitarist David Gilmour's converted houseboat, "Astoria". Its production was marked by a legal dispute with former member Roger Waters, who departed in 1985, as to who owned the rights to the band's name, an issue resolved several months after the album was released.

Unlike much of their previous material, the record is not a concept album and is instead a collection of songs written by Gilmour, sometimes with outside songwriters, following his decision to include material recorded for his third solo album on a new Pink Floyd album with drummer Nick Mason and keyboardist Richard Wright. The album was promoted with three singles: the double A-side "Learning to Fly" / "Terminal Frost", "On the Turning Away", and "One Slip", as well as a world tour.

"A Momentary Lapse of Reason" received mixed reviews from critics, who praised the production and instrumentation but criticized Gilmour's writing, and was derided by Waters. Despite this, it outsold the band's previous album, reaching number three in the UK and US. Since then, it has sold nearly 5 million copies.

After the release of Pink Floyd's 1983 album "The Final Cut", viewed by some as a "de facto" solo record by bassist and songwriter Roger Waters, the band members worked on solo projects. Guitarist David Gilmour expressed feelings about his strained relationship with Waters on his second solo album, "About Face" (1984), and finished the accompanying tour as Waters began touring to promote his debut solo album, "The Pros and Cons of Hitch Hiking". Although both had enlisted a range of successful performers, including in Waters' case Eric Clapton, their solo acts attracted fewer fans than Pink Floyd; poor ticket sales forced Gilmour to cancel several concerts, and critic David Fricke felt that Waters' show was "a petulant echo, a transparent attempt to prove that Roger Waters "was" Pink Floyd". Waters returned to the US in March 1985 with a second tour, this time without the support of CBS Records, which had expressed its preference for a new Pink Floyd album; Waters criticised the corporation as "a machine".

After drummer Nick Mason attended one of Waters' London performances in 1985, he found he missed touring under the Pink Floyd name. His visit coincided with the release in August of his second solo album, "Profiles", on which Gilmour sang. With a shared love of aviation, Mason and Gilmour were taking flying lessons and together bought a de Havilland Dove aeroplane. Gilmour was working on other collaborations, including a performance for Bryan Ferry at 1985's Live Aid concert, and co-produced the Dream Academy's self-titled debut album.

In December 1985, Waters announced that he had left Pink Floyd, which he believed was "a spent force creatively". After the failure of his "About Face" tour, Gilmour hoped to continue with the Pink Floyd name. The threat of a lawsuit from Gilmour, Mason and CBS Records was meant to compel Waters to write and produce another Pink Floyd album with his bandmates, who had barely participated in making "The Final Cut"; Gilmour was especially critical of the album, labelling it "cheap filler" and "meandering rubbish". The lawsuit left Waters with only one other option: to formally resign from Pink Floyd in order to protect himself from a lawsuit that, he said, "would have wiped me out completely".

According to Gilmour, "I told [Waters] before he left, 'If you go, man, we're carrying on. Make no bones about it, "we would carry on", and Roger replied: 'You'll never fucking do it.'" Waters had written to EMI and Columbia declaring his intention to leave the group and asking them to release him from his contractual obligations. He also dispensed with the services of Pink Floyd manager Steve O'Rourke and employed Peter Rudge to manage his affairs. This left Gilmour and Mason, in their view, free to continue with the Pink Floyd name.
In Waters' absence, Gilmour had been recruiting musicians for a new project. Months previously, keyboardist Jon Carin had jammed with Gilmour at his Hookend studio, where he composed the chord progression that became "Learning to Fly", and so was invited onto the team. Gilmour invited Bob Ezrin (co-producer of 1979's "The Wall") to help consolidate their material; Ezrin had turned down Waters' offer of a role on the development of his new solo album, "Radio K.A.O.S.", saying it was "far easier for Dave and I to do "our" version of a Floyd record". Ezrin arrived in England in mid-1986 for what Gilmour later described as "mucking about with a lot of demos".

At this stage, there was no commitment to a new Pink Floyd release, and Gilmour maintained that the new material might become his third solo album. CBS representative Stephen Ralbovsky hoped for a new Pink Floyd album, but in a meeting in November 1986, told Gilmour and Ezrin that the music "doesn't sound a fucking thing like Pink Floyd". Gilmour later said that the new project was difficult without Waters. Gilmour had experimented with songwriters such as Eric Stewart and Roger McGough, but eventually settled on Anthony Moore, who was credited as co-writer of "Learning to Fly" and "On the Turning Away". Whereas many Pink Floyd albums were concept albums, Gilmour settled for the more conventional approach of a collection of songs without a thematic link. By the end of that year, he had decided to make the material into a Pink Floyd project.

"A Momentary Lapse of Reason "was recorded in several different studios, mainly Gilmour's houseboat studio "Astoria "moored on the Thames; according to Ezrin, "working there was just magical, so inspirational; kids sculling down the river, geese flying by ...". Andy Jackson was brought in to engineer. During sessions held between November 1986 and February 1987, Gilmour's band worked on new material, which in a marked change from previous Pink Floyd albums was recorded with a 24-track analogue machine and overdubbed onto a 32-track Mitsubishi digital recorder. This trend of using new technologies continued with the use of MIDI synchronisation, aided by an Apple Macintosh computer.

After agreeing to rework the material that Ralbovsky had found objectionable, Gilmour employed session musicians such as Carmine Appice and Jim Keltner. Both drummers, they replaced Mason on several songs; Mason was concerned that he was too out of practice to perform on the album, and instead busied himself with its sound effects. Some drum parts were also performed by drum machines. During the sessions, Gilmour was asked by the wife of Pink Floyd's former keyboardist, Richard Wright, if he could contribute. A founding member of the band, Wright had left in 1979, and there were legal obstacles to his return, but after a meeting in Hampstead he was recruited as a paid musician on a weekly wage of $11,000. Gilmour said in an interview with author Karl Dallas that Wright's presence "would make us stronger legally and musically". However, his contributions were minimal; most of the keyboard parts had already been recorded, and so from February 1987 Wright played some background reinforcement on a Hammond organ, and a Rhodes piano, and added vocal harmonies. He also performed a solo in "On the Turning Away", which was discarded, according to Wright, "not because they didn't like it ... they just thought it didn't fit." Gilmour later said: "Both Nick and Rick were catatonic in terms of their playing ability at the beginning. Neither of them played on this at all really. In my view, they'd been destroyed by Roger." Gilmour's comments angered Mason, who said: "I'd deny that I was catatonic. I'd expect that from the opposition, it's less attractive from one's allies. At some point, he made some sort of apology." Mason conceded that Gilmour was nervous about how the album would be perceived.
"Learning to Fly", with its lyrics of "circling sky, tongue-tied and twisted, just an earthbound misfit, I", was inspired by Gilmour's flying lessons, which occasionally conflicted with his studio duties. The track also contains a recording of Mason's voice during takeoff. The band experimented with audio samples, and Ezrin recorded the sound of Gilmour's boatman (Langley Iddens) rowing across the Thames. Iddens' presence at the sessions was made vital when "Astoria" began to lift in response to the rapidly rising river, which was pushing the boat against the pier on which it was moored.

"The Dogs of War" is a song about "physical and political mercenaries", according to Gilmour. Its creation came about through a mishap in the studio when a sampling machine began playing a sample of laughter, which Gilmour thought sounded like a dog's bark. "Terminal Frost" was one of Gilmour's older demos, which he considered adding lyrics to but decided to leave as an instrumental. Conversely, the lyrics for "Sorrow" were written before the music. The song's opening guitar solo was recorded in the Los Angeles Memorial Sports Arena. A 24-track mobile studio piped Gilmour's guitar tracks through a public address system, and the resulting mix was then recorded in surround sound.

The sessions were interrupted by the escalating disagreement between Waters and Pink Floyd over who had the rights to the Pink Floyd name. O'Rourke, believing that his contract with Waters had been terminated illegally, sued Waters for £25,000 of back-commission. In a late-1986 board meeting of Pink Floyd Music Ltd (Pink Floyd's clearing house for all financial transactions since 1973), Waters learnt that a bank account had been opened to deal exclusively with all monies related to "the new Pink Floyd project". He immediately applied to the High Court to prevent the Pink Floyd name from being used again, but his lawyers discovered that the partnership had never been formally confirmed. Waters returned to the High Court in an attempt to gain a veto over further use of the band's name. Gilmour's team responded by issuing a press release affirming that Pink Floyd would continue to exist; however, Gilmour told a "Sunday Times" reporter: "Roger is a dog in the manger and I'm going to fight him, no one else has claimed Pink Floyd was entirely them. Anybody who does is extremely arrogant."

Waters twice visited "Astoria", and with his wife had a meeting in August 1986 with Ezrin; Ezrin later suggested that he was being "checked out". As Waters was still a shareholder and director of Pink Floyd Music, he was able to block any decisions made by his former bandmates. Recording moved to Mayfair Studios in February 1987, and from February to March – under the terms of an agreement with Ezrin to record close to his home – to A&M Studios in Los Angeles: "It was fantastic because ... the lawyers couldn't call in the middle of recording unless they were calling in the middle of the night." The bitterness of the row between Waters and Pink Floyd was covered in a November 1987 issue of "Rolling Stone", which became the magazine's best-selling issue of that year. The legal disputes were resolved out-of-court by the end of 1987.

Careful consideration was given to the album's title, with the initial three contenders being "Signs of Life", "Of Promises Broken" and "Delusions of Maturity". The final title appears as a line in the chorus of "One Slip".

For the first time since 1977's "Animals", designer Storm Thorgerson was employed to work on a Pink Floyd studio album cover. His finished design was a long river of hospital beds arranged on a beach, inspired by a phrase from "Yet Another Movie" and Gilmour's vague hint of a design that included a bed in a Mediterranean house, as well as "vestiges of relationships that have evaporated, leaving only echoes". The cover shows hundreds of hospital beds, placed on Saunton Sands in Devon (where some of the scenes for "Pink Floyd – The Wall" were filmed). The beds were arranged by Thorgerson's colleague Colin Elgie. A hang glider can be seen in the sky, a clear reference to "Learning to Fly". The photographer, Robert Dowling, won a gold award at the Association of Photographers Awards for the image, which took about two weeks to create. To drive home the message that Waters had left the band, the inner gatefold featured a group photograph – of just Gilmour and Mason – shot by David Bailey. Its inclusion marked the first time since 1971's "Meddle" that a group photo had been used in the artwork of a Pink Floyd album. Richard Wright was represented only by name, on the credit list, although he also appears in photographs included in later reissues. 
"A Momentary Lapse of Reason" was released in the UK and US on 7 September 1987. It went straight to number three in both countries, held from the top spot by Michael Jackson's "Bad" and Whitesnake's self-titled album.

In comparison with "The Final Cut", Gilmour presented "A Momentary Lapse" as a return to the Floyd of older days, citing his belief that towards the end of Waters' tenure, lyrics were more important than music. Gilmour said: ""The Dark Side of the Moon" and "Wish You Were Here" were so successful not just because of Roger's contributions, but also because there was a better balance between the music and the lyrics [than on later albums.]" He added that with "A Momentary Lapse", he had tried to restore this earlier, more successful balance. Waters was scathing in his assessment of the new work, a view with which Wright later partly agreed, saying: "Roger's criticisms are fair. It's not a band album at all."

Writing in "Q" magazine, Phil Sutcliffe contended that it "does sound like a Pink Floyd album" and highlighted the two-part "A New Machine" as, variously, "a chillingly beautiful vocal exploration, a chorale of multitrack, echo and distortion broken into aching fragments by long moments of silence" and "[a] brilliant stroke of imagination". Sutcliffe concluded: ""A Momentary Lapse" is Gilmour's album to much the same degree that the previous four under Floyd's name were dominated by Waters … Clearly it wasn't only business sense and repressed ego but repressed talent which drove the guitarist to insist on continuing under the band brand-name." Recognising the return to the more music-oriented approach of Pink Floyd's classic works, "Sounds" said the album was "back over the wall to where diamonds are crazy, moons have dark sides, and mothers have atom hearts".

Conversely, Greg Quill of the "Toronto Star" wrote: "Something's missing here. This is, for all its lumbering weight, not a record that challenges and provokes as Pink Floyd should. A Momentary Lapse of Reason, sorry to say, is mundane, predictable." "Village Voice" critic Robert Christgau opined: "In short, you'd hardly know the group's conceptmaster was gone – except that they put out noticeably fewer ideas." Writing more recently, for AllMusic, William Ruhlmann refers to it as a "Gilmour solo album in all but name".

"A Momentary Lapse of Reason" was certified Silver and Gold in the UK on 1 October 1987, and Gold and Platinum in the US on 9 November. It went 2× Platinum on 18 January the following year, 3× Platinum on 10 March 1992, and 4× Platinum on 16 August 2001, easily outselling "The Final Cut". The album was reissued in 1988 as a limited-edition vinyl album, complete with posters, and a guaranteed ticket application for the band's upcoming UK concerts. The album was digitally remastered and re-released in 1994, and a tenth anniversary edition was issued in the US three years later. In 2011, "A Momentary Lapse" was again remastered for inclusion in the band's "Discovery" box set; this time Wright's name had been restored as being a member of the band and the band photo (of Gilmour and Mason) has been removed in favour of additional artwork by StormStudios.

The decision to tour in support of the album was made before it was even complete. Early rehearsals were chaotic; Mason and Wright were completely out of practice, and realising he had taken on too much work, Gilmour asked Bob Ezrin to take charge. Matters were complicated when Waters contacted several US promoters, and threatened to sue them if they used the Pink Floyd name. Gilmour and Mason funded the start-up costs (Mason, separated from his wife, used his Ferrari 250 GTO as collateral). Some promoters were offended by Waters' threat, and several months later 60,000 tickets went on sale in Toronto, selling out within hours.

As the new line-up (with Wright) toured throughout North America, Waters' "Radio K.A.O.S." tour was, on occasion, close by. The bassist had forbidden any members of Pink Floyd from attending his concerts, which were generally in smaller venues than those housing his former band's performances. Waters also issued a writ for copyright fees for the band's use of the flying pig, and Pink Floyd responded by attaching a huge set of male genitalia to the balloon's underside to distinguish it from Waters' design. By November 1987, Waters gave up, and on 23 December a legal settlement was finally reached at a meeting on "Astoria". Mason and Gilmour were allowed use of the Pink Floyd name in perpetuity, and Waters would be granted, among other things, rights to "The Wall". However, Waters claimed that they would never have the level of success that they had during his tenure again.
The "Momentary Lapse" tour was phenomenally successful. In every venue booked in the US it beat box office records, making it the most successful US tour by any band that year. Tours of Australia, Japan, and Europe soon followed, before the band returned twice to the US. Almost every venue was sold out. A live album, "Delicate Sound of Thunder", was released on 22 November 1988, followed in June 1989 by a concert video. A few days later, the live album was played in orbit, on board Soyuz TM-7. The tour eventually came to an end by closing the Silver Clef Award Winners Concert, at Knebworth Park on 30 June 1990, after 200 performances, a gross audience of 4.25 million fans, and box office receipts of more than £60 million (not including merchandising).

All lead vocals performed by David Gilmour except where noted.

Note

Pink Floyd
Production
Additional musicians

Singles

Notes
Footnotes
Bibliography


</doc>
